[01/24 22:55:36] detectron2 INFO: Rank of current process: 0. World size: 2
[01/24 22:55:39] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/24 22:55:39] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '32', 'OUTPUT_DIR', './work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_fullsemseg'], resume=False)
[01/24 22:55:39] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/24 22:55:39] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_fullsemseg[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/24 22:55:39] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_fullsemseg/config.yaml
[01/24 22:55:39] d2.utils.env INFO: Using a generated random seed 39595327
[01/24 22:55:40] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 1.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 1.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 1.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 1.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 1.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 1.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 1.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 1.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 1.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 1.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/24 22:55:40] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/24 22:55:45] d2.data.build INFO: Using training sampler TrainingSampler
[01/24 22:55:45] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/24 22:55:45] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/24 22:55:45] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/24 22:55:45] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/24 22:55:45] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/24 22:55:45] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/24 22:55:45] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/24 22:55:45] d2.engine.train_loop INFO: Starting training from iteration 0
[01/24 22:56:49] d2.utils.events INFO:  eta: 1 day, 12:47:09  iter: 19  total_loss: 2735  loss_ce: 5.876  loss_mask: 274  loss_ce_0: 4.926  loss_mask_0: 284.1  loss_ce_1: 5.066  loss_mask_1: 276.8  loss_ce_2: 5.168  loss_mask_2: 244.3  loss_ce_3: 5.206  loss_mask_3: 195.5  loss_ce_4: 5.316  loss_mask_4: 243.6  loss_ce_5: 5.359  loss_mask_5: 293.5  loss_ce_6: 5.543  loss_mask_6: 271.2  loss_ce_7: 5.604  loss_mask_7: 307.8  loss_ce_8: 5.705  loss_mask_8: 283.1  time: 2.2226  data_time: 0.7455  lr: 1.1707e-05  max_mem: 18863M
[01/24 22:57:34] d2.utils.events INFO:  eta: 1 day, 13:19:54  iter: 39  total_loss: 1691  loss_ce: 5.943  loss_mask: 166.2  loss_ce_0: 4.835  loss_mask_0: 284.5  loss_ce_1: 5.016  loss_mask_1: 153.1  loss_ce_2: 5.157  loss_mask_2: 163.5  loss_ce_3: 5.251  loss_mask_3: 163.4  loss_ce_4: 5.269  loss_mask_4: 143.9  loss_ce_5: 5.361  loss_mask_5: 141.7  loss_ce_6: 5.469  loss_mask_6: 141.6  loss_ce_7: 5.653  loss_mask_7: 136.7  loss_ce_8: 5.779  loss_mask_8: 151.9  time: 2.2304  data_time: 0.3901  lr: 1.3502e-05  max_mem: 18903M
[01/24 22:58:18] d2.utils.events INFO:  eta: 1 day, 12:23:28  iter: 59  total_loss: 1629  loss_ce: 5.891  loss_mask: 168.2  loss_ce_0: 4.839  loss_mask_0: 281.9  loss_ce_1: 5.011  loss_mask_1: 136.6  loss_ce_2: 5.13  loss_mask_2: 163  loss_ce_3: 5.202  loss_mask_3: 163  loss_ce_4: 5.22  loss_mask_4: 133.1  loss_ce_5: 5.271  loss_mask_5: 139.5  loss_ce_6: 5.403  loss_mask_6: 134.4  loss_ce_7: 5.617  loss_mask_7: 134.6  loss_ce_8: 5.735  loss_mask_8: 132.4  time: 2.2146  data_time: 0.3605  lr: 1.5296e-05  max_mem: 18903M
[01/24 22:59:02] d2.utils.events INFO:  eta: 1 day, 12:30:28  iter: 79  total_loss: 1582  loss_ce: 5.832  loss_mask: 161.2  loss_ce_0: 4.862  loss_mask_0: 289.3  loss_ce_1: 5.015  loss_mask_1: 130.2  loss_ce_2: 5.111  loss_mask_2: 161  loss_ce_3: 5.168  loss_mask_3: 161  loss_ce_4: 5.178  loss_mask_4: 125.2  loss_ce_5: 5.235  loss_mask_5: 136.5  loss_ce_6: 5.369  loss_mask_6: 125.6  loss_ce_7: 5.586  loss_mask_7: 122.7  loss_ce_8: 5.728  loss_mask_8: 124.3  time: 2.2083  data_time: 0.3553  lr: 1.709e-05  max_mem: 18903M
[01/24 22:59:45] d2.utils.events INFO:  eta: 1 day, 12:26:50  iter: 99  total_loss: 1533  loss_ce: 5.781  loss_mask: 162.4  loss_ce_0: 4.872  loss_mask_0: 284.7  loss_ce_1: 5.013  loss_mask_1: 118.2  loss_ce_2: 5.091  loss_mask_2: 159.5  loss_ce_3: 5.138  loss_mask_3: 159.5  loss_ce_4: 5.147  loss_mask_4: 117.8  loss_ce_5: 5.205  loss_mask_5: 134.6  loss_ce_6: 5.361  loss_mask_6: 118.8  loss_ce_7: 5.575  loss_mask_7: 118.7  loss_ce_8: 5.718  loss_mask_8: 116  time: 2.2007  data_time: 0.3600  lr: 1.8882e-05  max_mem: 18903M
[01/24 23:00:30] d2.utils.events INFO:  eta: 1 day, 12:30:14  iter: 119  total_loss: 1439  loss_ce: 5.703  loss_mask: 117.7  loss_ce_0: 4.89  loss_mask_0: 284.8  loss_ce_1: 5.034  loss_mask_1: 103.7  loss_ce_2: 5.064  loss_mask_2: 153.3  loss_ce_3: 5.083  loss_mask_3: 156.1  loss_ce_4: 5.112  loss_mask_4: 104.7  loss_ce_5: 5.181  loss_mask_5: 135.4  loss_ce_6: 5.347  loss_mask_6: 107.6  loss_ce_7: 5.55  loss_mask_7: 106  loss_ce_8: 5.707  loss_mask_8: 103.9  time: 2.2082  data_time: 0.3715  lr: 2.0673e-05  max_mem: 18903M
[01/24 23:01:13] d2.utils.events INFO:  eta: 1 day, 12:25:22  iter: 139  total_loss: 1389  loss_ce: 5.636  loss_mask: 114.6  loss_ce_0: 4.922  loss_mask_0: 283.2  loss_ce_1: 5.026  loss_mask_1: 110.4  loss_ce_2: 4.991  loss_mask_2: 114  loss_ce_3: 5.041  loss_mask_3: 142.7  loss_ce_4: 5.066  loss_mask_4: 115.1  loss_ce_5: 5.129  loss_mask_5: 131.4  loss_ce_6: 5.296  loss_mask_6: 109.5  loss_ce_7: 5.492  loss_mask_7: 116.3  loss_ce_8: 5.658  loss_mask_8: 105.7  time: 2.1998  data_time: 0.3441  lr: 2.2463e-05  max_mem: 18903M
[01/24 23:01:59] d2.utils.events INFO:  eta: 1 day, 12:30:44  iter: 159  total_loss: 1279  loss_ce: 5.609  loss_mask: 101.9  loss_ce_0: 4.905  loss_mask_0: 287.9  loss_ce_1: 4.999  loss_mask_1: 97.78  loss_ce_2: 4.943  loss_mask_2: 105  loss_ce_3: 5.011  loss_mask_3: 107.1  loss_ce_4: 5.032  loss_mask_4: 99.71  loss_ce_5: 5.103  loss_mask_5: 122.3  loss_ce_6: 5.285  loss_mask_6: 99.25  loss_ce_7: 5.496  loss_mask_7: 102.1  loss_ce_8: 5.653  loss_mask_8: 98.54  time: 2.2100  data_time: 0.3809  lr: 2.4252e-05  max_mem: 18903M
[01/24 23:02:44] d2.utils.events INFO:  eta: 1 day, 12:30:00  iter: 179  total_loss: 1281  loss_ce: 5.564  loss_mask: 104.1  loss_ce_0: 4.884  loss_mask_0: 284.2  loss_ce_1: 4.983  loss_mask_1: 97.76  loss_ce_2: 4.907  loss_mask_2: 107.3  loss_ce_3: 4.983  loss_mask_3: 108.7  loss_ce_4: 5.015  loss_mask_4: 99.42  loss_ce_5: 5.089  loss_mask_5: 122.3  loss_ce_6: 5.28  loss_mask_6: 98.12  loss_ce_7: 5.487  loss_mask_7: 100.1  loss_ce_8: 5.622  loss_mask_8: 99.89  time: 2.2146  data_time: 0.3642  lr: 2.604e-05  max_mem: 18907M
[01/24 23:03:29] d2.utils.events INFO:  eta: 1 day, 12:31:01  iter: 199  total_loss: 1211  loss_ce: 5.514  loss_mask: 96.29  loss_ce_0: 4.869  loss_mask_0: 285.6  loss_ce_1: 4.962  loss_mask_1: 92.25  loss_ce_2: 4.881  loss_mask_2: 93.16  loss_ce_3: 4.949  loss_mask_3: 99.51  loss_ce_4: 4.991  loss_mask_4: 90.55  loss_ce_5: 5.076  loss_mask_5: 121.2  loss_ce_6: 5.258  loss_mask_6: 93.23  loss_ce_7: 5.446  loss_mask_7: 93.37  loss_ce_8: 5.567  loss_mask_8: 95.36  time: 2.2177  data_time: 0.3572  lr: 2.7827e-05  max_mem: 18907M
[01/24 23:04:12] d2.utils.events INFO:  eta: 1 day, 12:24:38  iter: 219  total_loss: 1160  loss_ce: 5.485  loss_mask: 86.2  loss_ce_0: 4.914  loss_mask_0: 292.9  loss_ce_1: 4.938  loss_mask_1: 85.03  loss_ce_2: 4.841  loss_mask_2: 87.29  loss_ce_3: 4.893  loss_mask_3: 92.95  loss_ce_4: 4.939  loss_mask_4: 86.16  loss_ce_5: 5.022  loss_mask_5: 119  loss_ce_6: 5.202  loss_mask_6: 84.89  loss_ce_7: 5.398  loss_mask_7: 86.66  loss_ce_8: 5.531  loss_mask_8: 85.21  time: 2.2110  data_time: 0.3486  lr: 2.9612e-05  max_mem: 18907M
[01/24 23:04:57] d2.utils.events INFO:  eta: 1 day, 12:27:48  iter: 239  total_loss: 1182  loss_ce: 5.437  loss_mask: 90.18  loss_ce_0: 4.883  loss_mask_0: 287.9  loss_ce_1: 4.938  loss_mask_1: 87.37  loss_ce_2: 4.826  loss_mask_2: 85.75  loss_ce_3: 4.866  loss_mask_3: 89.06  loss_ce_4: 4.912  loss_mask_4: 89.03  loss_ce_5: 4.984  loss_mask_5: 117.3  loss_ce_6: 5.174  loss_mask_6: 91.6  loss_ce_7: 5.357  loss_mask_7: 91.44  loss_ce_8: 5.494  loss_mask_8: 88.23  time: 2.2145  data_time: 0.3859  lr: 3.1397e-05  max_mem: 18907M
[01/24 23:05:44] d2.utils.events INFO:  eta: 1 day, 12:35:25  iter: 259  total_loss: 1142  loss_ce: 5.395  loss_mask: 90.06  loss_ce_0: 4.879  loss_mask_0: 274.2  loss_ce_1: 4.943  loss_mask_1: 89.65  loss_ce_2: 4.833  loss_mask_2: 89.56  loss_ce_3: 4.881  loss_mask_3: 88.84  loss_ce_4: 4.923  loss_mask_4: 86.82  loss_ce_5: 4.968  loss_mask_5: 115.6  loss_ce_6: 5.154  loss_mask_6: 89.46  loss_ce_7: 5.332  loss_mask_7: 87.83  loss_ce_8: 5.458  loss_mask_8: 88.22  time: 2.2272  data_time: 0.3891  lr: 3.3181e-05  max_mem: 18907M
[01/24 23:06:30] d2.utils.events INFO:  eta: 1 day, 12:41:27  iter: 279  total_loss: 1156  loss_ce: 5.373  loss_mask: 92.07  loss_ce_0: 4.863  loss_mask_0: 284.4  loss_ce_1: 4.923  loss_mask_1: 87.77  loss_ce_2: 4.777  loss_mask_2: 87.98  loss_ce_3: 4.817  loss_mask_3: 90.92  loss_ce_4: 4.875  loss_mask_4: 88.73  loss_ce_5: 4.938  loss_mask_5: 111  loss_ce_6: 5.131  loss_mask_6: 89.99  loss_ce_7: 5.307  loss_mask_7: 92.25  loss_ce_8: 5.418  loss_mask_8: 92.24  time: 2.2311  data_time: 0.3895  lr: 3.4963e-05  max_mem: 18907M
[01/24 23:07:16] d2.utils.events INFO:  eta: 1 day, 12:50:08  iter: 299  total_loss: 1095  loss_ce: 5.32  loss_mask: 84.06  loss_ce_0: 4.855  loss_mask_0: 282.7  loss_ce_1: 4.906  loss_mask_1: 80.83  loss_ce_2: 4.778  loss_mask_2: 83.46  loss_ce_3: 4.827  loss_mask_3: 87.72  loss_ce_4: 4.857  loss_mask_4: 83.75  loss_ce_5: 4.917  loss_mask_5: 93.23  loss_ce_6: 5.113  loss_mask_6: 83.81  loss_ce_7: 5.3  loss_mask_7: 83.12  loss_ce_8: 5.384  loss_mask_8: 82.06  time: 2.2355  data_time: 0.3919  lr: 3.6744e-05  max_mem: 18907M
[01/24 23:08:01] d2.utils.events INFO:  eta: 1 day, 12:49:24  iter: 319  total_loss: 1090  loss_ce: 5.288  loss_mask: 83.99  loss_ce_0: 4.833  loss_mask_0: 284.7  loss_ce_1: 4.883  loss_mask_1: 80.34  loss_ce_2: 4.736  loss_mask_2: 83.59  loss_ce_3: 4.792  loss_mask_3: 82.55  loss_ce_4: 4.828  loss_mask_4: 85.28  loss_ce_5: 4.859  loss_mask_5: 83.19  loss_ce_6: 5.082  loss_mask_6: 87.65  loss_ce_7: 5.265  loss_mask_7: 81.53  loss_ce_8: 5.351  loss_mask_8: 84.76  time: 2.2348  data_time: 0.3809  lr: 3.8525e-05  max_mem: 18907M
[01/24 23:08:44] d2.utils.events INFO:  eta: 1 day, 12:47:04  iter: 339  total_loss: 1032  loss_ce: 5.221  loss_mask: 79.72  loss_ce_0: 4.862  loss_mask_0: 279.4  loss_ce_1: 4.862  loss_mask_1: 76.45  loss_ce_2: 4.7  loss_mask_2: 79.22  loss_ce_3: 4.764  loss_mask_3: 77.77  loss_ce_4: 4.783  loss_mask_4: 77.26  loss_ce_5: 4.836  loss_mask_5: 76.89  loss_ce_6: 5.042  loss_mask_6: 77.74  loss_ce_7: 5.231  loss_mask_7: 77.64  loss_ce_8: 5.322  loss_mask_8: 76.04  time: 2.2309  data_time: 0.3641  lr: 4.0304e-05  max_mem: 18907M
[01/24 23:09:30] d2.utils.events INFO:  eta: 1 day, 12:47:24  iter: 359  total_loss: 1083  loss_ce: 5.206  loss_mask: 85.83  loss_ce_0: 4.853  loss_mask_0: 277.3  loss_ce_1: 4.852  loss_mask_1: 81.42  loss_ce_2: 4.722  loss_mask_2: 82.84  loss_ce_3: 4.781  loss_mask_3: 83.76  loss_ce_4: 4.799  loss_mask_4: 85.54  loss_ce_5: 4.843  loss_mask_5: 83.5  loss_ce_6: 5.043  loss_mask_6: 85.09  loss_ce_7: 5.215  loss_mask_7: 80.75  loss_ce_8: 5.299  loss_mask_8: 82.12  time: 2.2339  data_time: 0.3580  lr: 4.2082e-05  max_mem: 18907M
[01/24 23:10:13] d2.utils.events INFO:  eta: 1 day, 12:38:00  iter: 379  total_loss: 1026  loss_ce: 5.167  loss_mask: 80.42  loss_ce_0: 4.859  loss_mask_0: 275.9  loss_ce_1: 4.839  loss_mask_1: 79.65  loss_ce_2: 4.679  loss_mask_2: 75.89  loss_ce_3: 4.724  loss_mask_3: 79.95  loss_ce_4: 4.746  loss_mask_4: 76.36  loss_ce_5: 4.814  loss_mask_5: 77.25  loss_ce_6: 5.011  loss_mask_6: 77.42  loss_ce_7: 5.192  loss_mask_7: 78.35  loss_ce_8: 5.26  loss_mask_8: 78.6  time: 2.2295  data_time: 0.3719  lr: 4.3859e-05  max_mem: 18907M
[01/24 23:10:57] d2.utils.events INFO:  eta: 1 day, 12:37:36  iter: 399  total_loss: 1109  loss_ce: 5.139  loss_mask: 87.12  loss_ce_0: 4.83  loss_mask_0: 272.3  loss_ce_1: 4.826  loss_mask_1: 86.86  loss_ce_2: 4.685  loss_mask_2: 85.02  loss_ce_3: 4.719  loss_mask_3: 87.41  loss_ce_4: 4.753  loss_mask_4: 87.81  loss_ce_5: 4.825  loss_mask_5: 89.62  loss_ce_6: 4.998  loss_mask_6: 83.96  loss_ce_7: 5.162  loss_mask_7: 85.36  loss_ce_8: 5.217  loss_mask_8: 84.96  time: 2.2292  data_time: 0.3851  lr: 4.5635e-05  max_mem: 18914M
[01/24 23:11:42] d2.utils.events INFO:  eta: 1 day, 12:36:51  iter: 419  total_loss: 1026  loss_ce: 5.088  loss_mask: 77.68  loss_ce_0: 4.859  loss_mask_0: 278.7  loss_ce_1: 4.815  loss_mask_1: 77.06  loss_ce_2: 4.663  loss_mask_2: 79.23  loss_ce_3: 4.699  loss_mask_3: 79.06  loss_ce_4: 4.753  loss_mask_4: 78.34  loss_ce_5: 4.807  loss_mask_5: 77.62  loss_ce_6: 4.962  loss_mask_6: 77.76  loss_ce_7: 5.132  loss_mask_7: 76.94  loss_ce_8: 5.197  loss_mask_8: 77.31  time: 2.2293  data_time: 0.3923  lr: 4.741e-05  max_mem: 18924M
[01/24 23:12:25] d2.utils.events INFO:  eta: 1 day, 12:35:33  iter: 439  total_loss: 1015  loss_ce: 5.036  loss_mask: 76.31  loss_ce_0: 4.822  loss_mask_0: 276.7  loss_ce_1: 4.793  loss_mask_1: 75.7  loss_ce_2: 4.657  loss_mask_2: 75.3  loss_ce_3: 4.703  loss_mask_3: 75.12  loss_ce_4: 4.742  loss_mask_4: 74.76  loss_ce_5: 4.787  loss_mask_5: 77.12  loss_ce_6: 4.925  loss_mask_6: 77.05  loss_ce_7: 5.08  loss_mask_7: 77.34  loss_ce_8: 5.135  loss_mask_8: 76.47  time: 2.2260  data_time: 0.3627  lr: 4.9184e-05  max_mem: 18924M
[01/24 23:13:08] d2.utils.events INFO:  eta: 1 day, 12:30:15  iter: 459  total_loss: 993.6  loss_ce: 5.007  loss_mask: 76.25  loss_ce_0: 4.84  loss_mask_0: 269.3  loss_ce_1: 4.779  loss_mask_1: 73.81  loss_ce_2: 4.633  loss_mask_2: 75.21  loss_ce_3: 4.681  loss_mask_3: 74.47  loss_ce_4: 4.728  loss_mask_4: 74.65  loss_ce_5: 4.748  loss_mask_5: 76.51  loss_ce_6: 4.879  loss_mask_6: 76.83  loss_ce_7: 5.037  loss_mask_7: 75.36  loss_ce_8: 5.101  loss_mask_8: 76.53  time: 2.2233  data_time: 0.3581  lr: 5.0957e-05  max_mem: 18924M
[01/24 23:13:53] d2.utils.events INFO:  eta: 1 day, 12:28:27  iter: 479  total_loss: 1037  loss_ce: 4.99  loss_mask: 82.66  loss_ce_0: 4.836  loss_mask_0: 273.2  loss_ce_1: 4.769  loss_mask_1: 77.37  loss_ce_2: 4.636  loss_mask_2: 79.92  loss_ce_3: 4.707  loss_mask_3: 77.98  loss_ce_4: 4.743  loss_mask_4: 79.02  loss_ce_5: 4.742  loss_mask_5: 81.21  loss_ce_6: 4.877  loss_mask_6: 78.58  loss_ce_7: 5.006  loss_mask_7: 80.44  loss_ce_8: 5.076  loss_mask_8: 77.17  time: 2.2244  data_time: 0.3758  lr: 5.2728e-05  max_mem: 18924M
[01/24 23:14:39] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 23:14:40] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 23:14:40] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 23:20:27] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 30.452643200830927, 'error_1pix': 0.9043201795860346, 'error_3pix': 0.8626451562630244, 'mIoU': 0.016911723573174435, 'fwIoU': 0.04179336300132778, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.4956240920054311, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 1.5225895591224572, 'IoU-19': 0.0, 'IoU-20': 1.2288372749216037, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.6982286684713256, 'pACC': 1.0835213943399722, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 72.34291611937472, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 30.240013395513426, 'ACC-19': 0.0, 'ACC-20': 31.47697483160637, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 23:20:27] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 23:20:27] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 23:20:27] d2.evaluation.testing INFO: copypaste: 30.4526,0.9043,0.8626,0.0169,0.0418,0.6982,1.0835
[01/24 23:20:27] d2.utils.events INFO:  eta: 1 day, 12:29:50  iter: 499  total_loss: 971.3  loss_ce: 4.956  loss_mask: 73.18  loss_ce_0: 4.828  loss_mask_0: 272.3  loss_ce_1: 4.751  loss_mask_1: 71.64  loss_ce_2: 4.626  loss_mask_2: 72.68  loss_ce_3: 4.687  loss_mask_3: 72.58  loss_ce_4: 4.735  loss_mask_4: 70.36  loss_ce_5: 4.735  loss_mask_5: 78.24  loss_ce_6: 4.853  loss_mask_6: 77.47  loss_ce_7: 4.965  loss_mask_7: 74.33  loss_ce_8: 5.034  loss_mask_8: 70.57  time: 2.2267  data_time: 0.4030  lr: 5.4499e-05  max_mem: 18924M
[01/24 23:21:12] d2.utils.events INFO:  eta: 1 day, 12:32:13  iter: 519  total_loss: 967.8  loss_ce: 4.957  loss_mask: 71.62  loss_ce_0: 4.785  loss_mask_0: 267.5  loss_ce_1: 4.765  loss_mask_1: 70.82  loss_ce_2: 4.651  loss_mask_2: 71.61  loss_ce_3: 4.718  loss_mask_3: 70.63  loss_ce_4: 4.753  loss_mask_4: 73.81  loss_ce_5: 4.741  loss_mask_5: 79.81  loss_ce_6: 4.87  loss_mask_6: 74.9  loss_ce_7: 4.987  loss_mask_7: 72.25  loss_ce_8: 5.038  loss_mask_8: 69.51  time: 2.2271  data_time: 0.3801  lr: 5.6268e-05  max_mem: 18924M
[01/24 23:21:56] d2.utils.events INFO:  eta: 1 day, 12:31:28  iter: 539  total_loss: 930.3  loss_ce: 4.897  loss_mask: 72.08  loss_ce_0: 4.822  loss_mask_0: 267.7  loss_ce_1: 4.74  loss_mask_1: 67.33  loss_ce_2: 4.614  loss_mask_2: 67.8  loss_ce_3: 4.674  loss_mask_3: 67.97  loss_ce_4: 4.713  loss_mask_4: 65.87  loss_ce_5: 4.703  loss_mask_5: 71.2  loss_ce_6: 4.826  loss_mask_6: 71.86  loss_ce_7: 4.93  loss_mask_7: 67.43  loss_ce_8: 4.964  loss_mask_8: 65.21  time: 2.2259  data_time: 0.3848  lr: 5.8037e-05  max_mem: 18924M
[01/24 23:22:41] d2.utils.events INFO:  eta: 1 day, 12:32:11  iter: 559  total_loss: 943  loss_ce: 4.857  loss_mask: 73.41  loss_ce_0: 4.83  loss_mask_0: 264.3  loss_ce_1: 4.719  loss_mask_1: 69.91  loss_ce_2: 4.564  loss_mask_2: 72.94  loss_ce_3: 4.635  loss_mask_3: 71.77  loss_ce_4: 4.677  loss_mask_4: 74.28  loss_ce_5: 4.679  loss_mask_5: 69.34  loss_ce_6: 4.8  loss_mask_6: 67.9  loss_ce_7: 4.882  loss_mask_7: 68.01  loss_ce_8: 4.918  loss_mask_8: 69.39  time: 2.2270  data_time: 0.3861  lr: 5.9804e-05  max_mem: 18924M
[01/24 23:23:25] d2.utils.events INFO:  eta: 1 day, 12:30:57  iter: 579  total_loss: 944.4  loss_ce: 4.856  loss_mask: 71.93  loss_ce_0: 4.826  loss_mask_0: 272.5  loss_ce_1: 4.69  loss_mask_1: 68.37  loss_ce_2: 4.566  loss_mask_2: 71.33  loss_ce_3: 4.643  loss_mask_3: 69.35  loss_ce_4: 4.695  loss_mask_4: 66.21  loss_ce_5: 4.667  loss_mask_5: 69.46  loss_ce_6: 4.765  loss_mask_6: 68.24  loss_ce_7: 4.861  loss_mask_7: 69.66  loss_ce_8: 4.891  loss_mask_8: 67.82  time: 2.2256  data_time: 0.3744  lr: 6.157e-05  max_mem: 18924M
[01/24 23:24:10] d2.utils.events INFO:  eta: 1 day, 12:31:44  iter: 599  total_loss: 966.6  loss_ce: 4.868  loss_mask: 70.35  loss_ce_0: 4.801  loss_mask_0: 260.7  loss_ce_1: 4.689  loss_mask_1: 71.33  loss_ce_2: 4.591  loss_mask_2: 70.32  loss_ce_3: 4.672  loss_mask_3: 70.24  loss_ce_4: 4.708  loss_mask_4: 68.42  loss_ce_5: 4.694  loss_mask_5: 72.55  loss_ce_6: 4.788  loss_mask_6: 71.94  loss_ce_7: 4.86  loss_mask_7: 73.72  loss_ce_8: 4.869  loss_mask_8: 71.25  time: 2.2259  data_time: 0.3867  lr: 6.3335e-05  max_mem: 18924M
[01/24 23:24:54] d2.utils.events INFO:  eta: 1 day, 12:32:26  iter: 619  total_loss: 926.8  loss_ce: 4.853  loss_mask: 72.14  loss_ce_0: 4.779  loss_mask_0: 261.5  loss_ce_1: 4.66  loss_mask_1: 67.16  loss_ce_2: 4.58  loss_mask_2: 67.67  loss_ce_3: 4.672  loss_mask_3: 69.94  loss_ce_4: 4.704  loss_mask_4: 66.7  loss_ce_5: 4.691  loss_mask_5: 68.79  loss_ce_6: 4.777  loss_mask_6: 67.6  loss_ce_7: 4.858  loss_mask_7: 70.59  loss_ce_8: 4.854  loss_mask_8: 69.99  time: 2.2258  data_time: 0.3649  lr: 6.51e-05  max_mem: 18924M
[01/24 23:25:38] d2.utils.events INFO:  eta: 1 day, 12:27:47  iter: 639  total_loss: 917.9  loss_ce: 4.776  loss_mask: 71.21  loss_ce_0: 4.802  loss_mask_0: 263.2  loss_ce_1: 4.632  loss_mask_1: 67.62  loss_ce_2: 4.551  loss_mask_2: 67.24  loss_ce_3: 4.645  loss_mask_3: 67  loss_ce_4: 4.698  loss_mask_4: 67.94  loss_ce_5: 4.669  loss_mask_5: 69.4  loss_ce_6: 4.758  loss_mask_6: 68.78  loss_ce_7: 4.842  loss_mask_7: 70.04  loss_ce_8: 4.802  loss_mask_8: 68.77  time: 2.2239  data_time: 0.3687  lr: 6.6863e-05  max_mem: 18924M
[01/24 23:26:22] d2.utils.events INFO:  eta: 1 day, 12:26:30  iter: 659  total_loss: 962.3  loss_ce: 4.776  loss_mask: 78.11  loss_ce_0: 4.799  loss_mask_0: 257.3  loss_ce_1: 4.653  loss_mask_1: 72.76  loss_ce_2: 4.581  loss_mask_2: 73.42  loss_ce_3: 4.66  loss_mask_3: 72.19  loss_ce_4: 4.703  loss_mask_4: 71.33  loss_ce_5: 4.673  loss_mask_5: 75.24  loss_ce_6: 4.778  loss_mask_6: 69.57  loss_ce_7: 4.856  loss_mask_7: 70.77  loss_ce_8: 4.816  loss_mask_8: 73.25  time: 2.2229  data_time: 0.3886  lr: 6.8624e-05  max_mem: 18924M
[01/24 23:27:06] d2.utils.events INFO:  eta: 1 day, 12:25:02  iter: 679  total_loss: 917.3  loss_ce: 4.758  loss_mask: 66.97  loss_ce_0: 4.778  loss_mask_0: 255.8  loss_ce_1: 4.629  loss_mask_1: 69.14  loss_ce_2: 4.589  loss_mask_2: 67.97  loss_ce_3: 4.671  loss_mask_3: 67.25  loss_ce_4: 4.728  loss_mask_4: 67.73  loss_ce_5: 4.689  loss_mask_5: 69.68  loss_ce_6: 4.741  loss_mask_6: 67.5  loss_ce_7: 4.822  loss_mask_7: 70.21  loss_ce_8: 4.771  loss_mask_8: 69.8  time: 2.2231  data_time: 0.3688  lr: 7.0385e-05  max_mem: 18924M
[01/24 23:27:50] d2.utils.events INFO:  eta: 1 day, 12:23:21  iter: 699  total_loss: 899.9  loss_ce: 4.713  loss_mask: 67.43  loss_ce_0: 4.767  loss_mask_0: 250.4  loss_ce_1: 4.621  loss_mask_1: 65.16  loss_ce_2: 4.581  loss_mask_2: 65.78  loss_ce_3: 4.653  loss_mask_3: 67.54  loss_ce_4: 4.697  loss_mask_4: 64.59  loss_ce_5: 4.666  loss_mask_5: 67.55  loss_ce_6: 4.715  loss_mask_6: 66.5  loss_ce_7: 4.811  loss_mask_7: 65.74  loss_ce_8: 4.745  loss_mask_8: 65.63  time: 2.2227  data_time: 0.3647  lr: 7.2145e-05  max_mem: 18924M
[01/24 23:28:34] d2.utils.events INFO:  eta: 1 day, 12:19:37  iter: 719  total_loss: 852.7  loss_ce: 4.661  loss_mask: 64.43  loss_ce_0: 4.793  loss_mask_0: 248.1  loss_ce_1: 4.599  loss_mask_1: 60.03  loss_ce_2: 4.54  loss_mask_2: 61.53  loss_ce_3: 4.606  loss_mask_3: 62.35  loss_ce_4: 4.643  loss_mask_4: 59.14  loss_ce_5: 4.628  loss_mask_5: 62.22  loss_ce_6: 4.681  loss_mask_6: 60.62  loss_ce_7: 4.761  loss_mask_7: 60.77  loss_ce_8: 4.701  loss_mask_8: 61.08  time: 2.2209  data_time: 0.3565  lr: 7.3904e-05  max_mem: 18924M
[01/24 23:29:18] d2.utils.events INFO:  eta: 1 day, 12:17:49  iter: 739  total_loss: 900.3  loss_ce: 4.658  loss_mask: 71.92  loss_ce_0: 4.794  loss_mask_0: 246  loss_ce_1: 4.572  loss_mask_1: 68.91  loss_ce_2: 4.537  loss_mask_2: 65.29  loss_ce_3: 4.595  loss_mask_3: 67.65  loss_ce_4: 4.652  loss_mask_4: 67.45  loss_ce_5: 4.64  loss_mask_5: 68.02  loss_ce_6: 4.671  loss_mask_6: 68.05  loss_ce_7: 4.74  loss_mask_7: 66.57  loss_ce_8: 4.699  loss_mask_8: 67.31  time: 2.2205  data_time: 0.3936  lr: 7.5661e-05  max_mem: 18924M
[01/24 23:30:03] d2.utils.events INFO:  eta: 1 day, 12:19:12  iter: 759  total_loss: 924.5  loss_ce: 4.657  loss_mask: 73.76  loss_ce_0: 4.783  loss_mask_0: 237.8  loss_ce_1: 4.589  loss_mask_1: 71.43  loss_ce_2: 4.57  loss_mask_2: 70.68  loss_ce_3: 4.604  loss_mask_3: 70.1  loss_ce_4: 4.676  loss_mask_4: 70.77  loss_ce_5: 4.637  loss_mask_5: 71.85  loss_ce_6: 4.688  loss_mask_6: 70.26  loss_ce_7: 4.716  loss_mask_7: 71.07  loss_ce_8: 4.676  loss_mask_8: 71.79  time: 2.2219  data_time: 0.3791  lr: 7.7418e-05  max_mem: 18924M
[01/24 23:30:48] d2.utils.events INFO:  eta: 1 day, 12:20:40  iter: 779  total_loss: 888.3  loss_ce: 4.676  loss_mask: 69.67  loss_ce_0: 4.762  loss_mask_0: 239.7  loss_ce_1: 4.604  loss_mask_1: 66.97  loss_ce_2: 4.58  loss_mask_2: 66.42  loss_ce_3: 4.61  loss_mask_3: 67.54  loss_ce_4: 4.678  loss_mask_4: 64.25  loss_ce_5: 4.654  loss_mask_5: 65.42  loss_ce_6: 4.703  loss_mask_6: 64.43  loss_ce_7: 4.712  loss_mask_7: 65.2  loss_ce_8: 4.692  loss_mask_8: 65.68  time: 2.2229  data_time: 0.3823  lr: 7.9173e-05  max_mem: 18924M
[01/24 23:31:34] d2.utils.events INFO:  eta: 1 day, 12:21:21  iter: 799  total_loss: 832.4  loss_ce: 4.644  loss_mask: 61.65  loss_ce_0: 4.748  loss_mask_0: 231.5  loss_ce_1: 4.537  loss_mask_1: 60.7  loss_ce_2: 4.544  loss_mask_2: 61.66  loss_ce_3: 4.578  loss_mask_3: 62.65  loss_ce_4: 4.635  loss_mask_4: 60.7  loss_ce_5: 4.605  loss_mask_5: 60.29  loss_ce_6: 4.639  loss_mask_6: 61.05  loss_ce_7: 4.701  loss_mask_7: 60.41  loss_ce_8: 4.662  loss_mask_8: 61.03  time: 2.2242  data_time: 0.3646  lr: 8.0928e-05  max_mem: 18924M
[01/24 23:32:19] d2.utils.events INFO:  eta: 1 day, 12:20:37  iter: 819  total_loss: 823.7  loss_ce: 4.664  loss_mask: 64.57  loss_ce_0: 4.733  loss_mask_0: 225.9  loss_ce_1: 4.513  loss_mask_1: 60.05  loss_ce_2: 4.572  loss_mask_2: 59.79  loss_ce_3: 4.615  loss_mask_3: 62.23  loss_ce_4: 4.656  loss_mask_4: 59.1  loss_ce_5: 4.644  loss_mask_5: 61.73  loss_ce_6: 4.668  loss_mask_6: 59.39  loss_ce_7: 4.713  loss_mask_7: 59.99  loss_ce_8: 4.663  loss_mask_8: 60.16  time: 2.2251  data_time: 0.3682  lr: 8.2681e-05  max_mem: 18924M
[01/24 23:33:02] d2.utils.events INFO:  eta: 1 day, 12:17:12  iter: 839  total_loss: 878.3  loss_ce: 4.645  loss_mask: 68.31  loss_ce_0: 4.764  loss_mask_0: 218.3  loss_ce_1: 4.496  loss_mask_1: 69.02  loss_ce_2: 4.563  loss_mask_2: 65.93  loss_ce_3: 4.597  loss_mask_3: 66.27  loss_ce_4: 4.633  loss_mask_4: 68.94  loss_ce_5: 4.619  loss_mask_5: 68.18  loss_ce_6: 4.641  loss_mask_6: 67.87  loss_ce_7: 4.691  loss_mask_7: 66.04  loss_ce_8: 4.631  loss_mask_8: 68.95  time: 2.2225  data_time: 0.3445  lr: 8.4433e-05  max_mem: 18931M
[01/24 23:33:46] d2.utils.events INFO:  eta: 1 day, 12:17:27  iter: 859  total_loss: 844.5  loss_ce: 4.658  loss_mask: 65.52  loss_ce_0: 4.74  loss_mask_0: 208  loss_ce_1: 4.507  loss_mask_1: 65.61  loss_ce_2: 4.594  loss_mask_2: 63.21  loss_ce_3: 4.63  loss_mask_3: 63.07  loss_ce_4: 4.668  loss_mask_4: 63.58  loss_ce_5: 4.635  loss_mask_5: 67.63  loss_ce_6: 4.676  loss_mask_6: 65.3  loss_ce_7: 4.705  loss_mask_7: 65.31  loss_ce_8: 4.65  loss_mask_8: 65.2  time: 2.2226  data_time: 0.3779  lr: 8.6184e-05  max_mem: 18931M
[01/24 23:34:29] d2.utils.events INFO:  eta: 1 day, 12:16:35  iter: 879  total_loss: 834  loss_ce: 4.62  loss_mask: 69.11  loss_ce_0: 4.737  loss_mask_0: 199.8  loss_ce_1: 4.432  loss_mask_1: 64.13  loss_ce_2: 4.522  loss_mask_2: 63.58  loss_ce_3: 4.576  loss_mask_3: 64.51  loss_ce_4: 4.622  loss_mask_4: 62.73  loss_ce_5: 4.577  loss_mask_5: 64.68  loss_ce_6: 4.613  loss_mask_6: 64.32  loss_ce_7: 4.671  loss_mask_7: 65.21  loss_ce_8: 4.619  loss_mask_8: 71.56  time: 2.2211  data_time: 0.3831  lr: 8.7934e-05  max_mem: 18931M
[01/24 23:35:13] d2.utils.events INFO:  eta: 1 day, 12:14:03  iter: 899  total_loss: 777.3  loss_ce: 4.665  loss_mask: 61.46  loss_ce_0: 4.733  loss_mask_0: 168.6  loss_ce_1: 4.442  loss_mask_1: 61.92  loss_ce_2: 4.57  loss_mask_2: 62.49  loss_ce_3: 4.624  loss_mask_3: 61.19  loss_ce_4: 4.645  loss_mask_4: 60.84  loss_ce_5: 4.598  loss_mask_5: 61.37  loss_ce_6: 4.635  loss_mask_6: 60.47  loss_ce_7: 4.692  loss_mask_7: 62.77  loss_ce_8: 4.684  loss_mask_8: 65.08  time: 2.2198  data_time: 0.3760  lr: 8.9683e-05  max_mem: 18931M
[01/24 23:35:57] d2.utils.events INFO:  eta: 1 day, 12:15:15  iter: 919  total_loss: 731.5  loss_ce: 4.74  loss_mask: 61.42  loss_ce_0: 4.729  loss_mask_0: 126.5  loss_ce_1: 4.493  loss_mask_1: 61.84  loss_ce_2: 4.659  loss_mask_2: 62.3  loss_ce_3: 4.695  loss_mask_3: 61.87  loss_ce_4: 4.71  loss_mask_4: 61.94  loss_ce_5: 4.672  loss_mask_5: 62.66  loss_ce_6: 4.712  loss_mask_6: 62.41  loss_ce_7: 4.75  loss_mask_7: 62.61  loss_ce_8: 4.75  loss_mask_8: 61.88  time: 2.2201  data_time: 0.4033  lr: 9.1431e-05  max_mem: 18931M
[01/24 23:36:42] d2.utils.events INFO:  eta: 1 day, 12:14:46  iter: 939  total_loss: 692.6  loss_ce: 4.694  loss_mask: 58.27  loss_ce_0: 4.693  loss_mask_0: 102.1  loss_ce_1: 4.449  loss_mask_1: 58.1  loss_ce_2: 4.604  loss_mask_2: 58.4  loss_ce_3: 4.639  loss_mask_3: 59.08  loss_ce_4: 4.673  loss_mask_4: 57.76  loss_ce_5: 4.63  loss_mask_5: 59.01  loss_ce_6: 4.663  loss_mask_6: 60.12  loss_ce_7: 4.693  loss_mask_7: 60.35  loss_ce_8: 4.695  loss_mask_8: 58.54  time: 2.2205  data_time: 0.3831  lr: 9.3178e-05  max_mem: 18931M
[01/24 23:37:25] d2.utils.events INFO:  eta: 1 day, 12:13:46  iter: 959  total_loss: 658.2  loss_ce: 4.665  loss_mask: 58.05  loss_ce_0: 4.733  loss_mask_0: 85.13  loss_ce_1: 4.441  loss_mask_1: 58.32  loss_ce_2: 4.576  loss_mask_2: 57.92  loss_ce_3: 4.61  loss_mask_3: 58.13  loss_ce_4: 4.633  loss_mask_4: 57.98  loss_ce_5: 4.576  loss_mask_5: 58.55  loss_ce_6: 4.633  loss_mask_6: 58.53  loss_ce_7: 4.671  loss_mask_7: 59.59  loss_ce_8: 4.65  loss_mask_8: 58.21  time: 2.2189  data_time: 0.3691  lr: 9.4923e-05  max_mem: 18931M
[01/24 23:38:09] d2.utils.events INFO:  eta: 1 day, 12:12:29  iter: 979  total_loss: 630.9  loss_ce: 4.655  loss_mask: 56.93  loss_ce_0: 4.766  loss_mask_0: 70.09  loss_ce_1: 4.44  loss_mask_1: 58.68  loss_ce_2: 4.568  loss_mask_2: 56.54  loss_ce_3: 4.609  loss_mask_3: 57.8  loss_ce_4: 4.637  loss_mask_4: 56.98  loss_ce_5: 4.575  loss_mask_5: 58.24  loss_ce_6: 4.633  loss_mask_6: 56.66  loss_ce_7: 4.669  loss_mask_7: 57.75  loss_ce_8: 4.647  loss_mask_8: 57.23  time: 2.2184  data_time: 0.3714  lr: 9.6668e-05  max_mem: 18931M
[01/24 23:38:53] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 23:38:53] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 23:38:54] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 23:44:35] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 36.33053192820739, 'error_1pix': 0.8879560460566542, 'error_3pix': 0.8781389831874702, 'mIoU': 0.013276284094095779, 'fwIoU': 0.034497937524381725, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.27969284198124383, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.30637978012625505, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 1.2972931342711789, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.6656807896877117, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5920809957808215, 'pACC': 0.45333577453718876, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 98.80616398641533, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.3824377946722121, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 13.610585604638084, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.8803638041921142, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 23:44:35] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 23:44:35] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 23:44:35] d2.evaluation.testing INFO: copypaste: 36.3305,0.8880,0.8781,0.0133,0.0345,0.5921,0.4533
[01/24 23:44:35] d2.utils.events INFO:  eta: 1 day, 12:12:10  iter: 999  total_loss: 635.2  loss_ce: 4.662  loss_mask: 58.24  loss_ce_0: 4.771  loss_mask_0: 67.39  loss_ce_1: 4.457  loss_mask_1: 57.99  loss_ce_2: 4.598  loss_mask_2: 57.93  loss_ce_3: 4.638  loss_mask_3: 58.34  loss_ce_4: 4.679  loss_mask_4: 57.21  loss_ce_5: 4.621  loss_mask_5: 58.89  loss_ce_6: 4.66  loss_mask_6: 57.82  loss_ce_7: 4.667  loss_mask_7: 58.24  loss_ce_8: 4.659  loss_mask_8: 57.93  time: 2.2179  data_time: 0.3723  lr: 9.8412e-05  max_mem: 18931M
[01/24 23:45:20] d2.utils.events INFO:  eta: 1 day, 12:11:34  iter: 1019  total_loss: 598.2  loss_ce: 4.646  loss_mask: 54.92  loss_ce_0: 4.809  loss_mask_0: 60.72  loss_ce_1: 4.435  loss_mask_1: 55.11  loss_ce_2: 4.581  loss_mask_2: 54.28  loss_ce_3: 4.619  loss_mask_3: 54.49  loss_ce_4: 4.665  loss_mask_4: 54.08  loss_ce_5: 4.604  loss_mask_5: 54.49  loss_ce_6: 4.635  loss_mask_6: 55.79  loss_ce_7: 4.655  loss_mask_7: 55.74  loss_ce_8: 4.632  loss_mask_8: 54.61  time: 2.2177  data_time: 0.3802  lr: 9.847e-05  max_mem: 18931M
[01/24 23:46:04] d2.utils.events INFO:  eta: 1 day, 12:07:51  iter: 1039  total_loss: 641  loss_ce: 4.67  loss_mask: 59.72  loss_ce_0: 4.804  loss_mask_0: 64.09  loss_ce_1: 4.452  loss_mask_1: 58.53  loss_ce_2: 4.611  loss_mask_2: 58.58  loss_ce_3: 4.652  loss_mask_3: 59.17  loss_ce_4: 4.683  loss_mask_4: 58.85  loss_ce_5: 4.635  loss_mask_5: 59.71  loss_ce_6: 4.669  loss_mask_6: 60.72  loss_ce_7: 4.679  loss_mask_7: 59.38  loss_ce_8: 4.664  loss_mask_8: 58.95  time: 2.2172  data_time: 0.3737  lr: 9.844e-05  max_mem: 18931M
[01/24 23:46:48] d2.utils.events INFO:  eta: 1 day, 12:10:21  iter: 1059  total_loss: 629.6  loss_ce: 4.68  loss_mask: 57.68  loss_ce_0: 4.834  loss_mask_0: 62.79  loss_ce_1: 4.465  loss_mask_1: 58.42  loss_ce_2: 4.642  loss_mask_2: 57.54  loss_ce_3: 4.674  loss_mask_3: 57.57  loss_ce_4: 4.719  loss_mask_4: 57.43  loss_ce_5: 4.659  loss_mask_5: 57.43  loss_ce_6: 4.694  loss_mask_6: 57.52  loss_ce_7: 4.688  loss_mask_7: 58.08  loss_ce_8: 4.678  loss_mask_8: 57.9  time: 2.2176  data_time: 0.3745  lr: 9.841e-05  max_mem: 18931M
[01/24 23:47:32] d2.utils.events INFO:  eta: 1 day, 12:09:55  iter: 1079  total_loss: 609.6  loss_ce: 4.611  loss_mask: 55.92  loss_ce_0: 4.852  loss_mask_0: 59.6  loss_ce_1: 4.4  loss_mask_1: 55.61  loss_ce_2: 4.551  loss_mask_2: 55.37  loss_ce_3: 4.595  loss_mask_3: 55.46  loss_ce_4: 4.627  loss_mask_4: 55.41  loss_ce_5: 4.581  loss_mask_5: 55.58  loss_ce_6: 4.612  loss_mask_6: 55.79  loss_ce_7: 4.608  loss_mask_7: 55.88  loss_ce_8: 4.609  loss_mask_8: 55.73  time: 2.2170  data_time: 0.3734  lr: 9.838e-05  max_mem: 18931M
[01/24 23:48:15] d2.utils.events INFO:  eta: 1 day, 12:08:37  iter: 1099  total_loss: 627.5  loss_ce: 4.583  loss_mask: 57.36  loss_ce_0: 4.857  loss_mask_0: 59.39  loss_ce_1: 4.363  loss_mask_1: 57.89  loss_ce_2: 4.503  loss_mask_2: 56.58  loss_ce_3: 4.559  loss_mask_3: 55.98  loss_ce_4: 4.59  loss_mask_4: 56.71  loss_ce_5: 4.558  loss_mask_5: 57.93  loss_ce_6: 4.581  loss_mask_6: 58.04  loss_ce_7: 4.592  loss_mask_7: 57.82  loss_ce_8: 4.577  loss_mask_8: 58.31  time: 2.2156  data_time: 0.3630  lr: 9.835e-05  max_mem: 18931M
[01/24 23:48:59] d2.utils.events INFO:  eta: 1 day, 12:07:20  iter: 1119  total_loss: 568.5  loss_ce: 4.675  loss_mask: 52.04  loss_ce_0: 4.863  loss_mask_0: 55.19  loss_ce_1: 4.431  loss_mask_1: 52  loss_ce_2: 4.618  loss_mask_2: 51.78  loss_ce_3: 4.669  loss_mask_3: 51.89  loss_ce_4: 4.685  loss_mask_4: 51.59  loss_ce_5: 4.647  loss_mask_5: 51.8  loss_ce_6: 4.678  loss_mask_6: 51.58  loss_ce_7: 4.669  loss_mask_7: 52.31  loss_ce_8: 4.664  loss_mask_8: 52.14  time: 2.2152  data_time: 0.3607  lr: 9.832e-05  max_mem: 18931M
[01/24 23:49:43] d2.utils.events INFO:  eta: 1 day, 12:07:04  iter: 1139  total_loss: 626.1  loss_ce: 4.568  loss_mask: 57.59  loss_ce_0: 4.886  loss_mask_0: 60.23  loss_ce_1: 4.387  loss_mask_1: 58.4  loss_ce_2: 4.521  loss_mask_2: 58.15  loss_ce_3: 4.569  loss_mask_3: 58.11  loss_ce_4: 4.583  loss_mask_4: 57.95  loss_ce_5: 4.532  loss_mask_5: 57.4  loss_ce_6: 4.559  loss_mask_6: 59.01  loss_ce_7: 4.569  loss_mask_7: 58.23  loss_ce_8: 4.552  loss_mask_8: 58.64  time: 2.2147  data_time: 0.3923  lr: 9.829e-05  max_mem: 18931M
[01/24 23:50:32] d2.utils.events INFO:  eta: 1 day, 12:08:05  iter: 1159  total_loss: 599.6  loss_ce: 4.594  loss_mask: 54.36  loss_ce_0: 4.915  loss_mask_0: 57.72  loss_ce_1: 4.368  loss_mask_1: 56.05  loss_ce_2: 4.524  loss_mask_2: 54.87  loss_ce_3: 4.588  loss_mask_3: 55.65  loss_ce_4: 4.621  loss_mask_4: 54.75  loss_ce_5: 4.558  loss_mask_5: 54.03  loss_ce_6: 4.592  loss_mask_6: 55.27  loss_ce_7: 4.599  loss_mask_7: 54.81  loss_ce_8: 4.591  loss_mask_8: 56.31  time: 2.2192  data_time: 0.3921  lr: 9.826e-05  max_mem: 18931M
[01/24 23:51:21] d2.utils.events INFO:  eta: 1 day, 12:10:16  iter: 1179  total_loss: 565  loss_ce: 4.611  loss_mask: 51.07  loss_ce_0: 4.89  loss_mask_0: 54.92  loss_ce_1: 4.382  loss_mask_1: 52.24  loss_ce_2: 4.548  loss_mask_2: 51.56  loss_ce_3: 4.609  loss_mask_3: 50.63  loss_ce_4: 4.634  loss_mask_4: 52.34  loss_ce_5: 4.594  loss_mask_5: 52.33  loss_ce_6: 4.614  loss_mask_6: 50.93  loss_ce_7: 4.607  loss_mask_7: 51.83  loss_ce_8: 4.6  loss_mask_8: 51.09  time: 2.2231  data_time: 0.4074  lr: 9.823e-05  max_mem: 18931M
[01/24 23:52:18] d2.utils.events INFO:  eta: 1 day, 12:12:35  iter: 1199  total_loss: 575.2  loss_ce: 4.637  loss_mask: 51.98  loss_ce_0: 4.865  loss_mask_0: 53.78  loss_ce_1: 4.4  loss_mask_1: 52.75  loss_ce_2: 4.573  loss_mask_2: 52.11  loss_ce_3: 4.628  loss_mask_3: 52.99  loss_ce_4: 4.64  loss_mask_4: 52.96  loss_ce_5: 4.602  loss_mask_5: 54.05  loss_ce_6: 4.635  loss_mask_6: 53.25  loss_ce_7: 4.622  loss_mask_7: 53.62  loss_ce_8: 4.63  loss_mask_8: 52.89  time: 2.2333  data_time: 0.6005  lr: 9.82e-05  max_mem: 18931M
[01/24 23:53:05] d2.utils.events INFO:  eta: 1 day, 12:14:23  iter: 1219  total_loss: 554.4  loss_ce: 4.628  loss_mask: 51.16  loss_ce_0: 4.889  loss_mask_0: 53.5  loss_ce_1: 4.379  loss_mask_1: 50.15  loss_ce_2: 4.566  loss_mask_2: 50.36  loss_ce_3: 4.607  loss_mask_3: 49.46  loss_ce_4: 4.648  loss_mask_4: 50.67  loss_ce_5: 4.607  loss_mask_5: 52.6  loss_ce_6: 4.624  loss_mask_6: 50.56  loss_ce_7: 4.602  loss_mask_7: 51.64  loss_ce_8: 4.623  loss_mask_8: 49.99  time: 2.2355  data_time: 0.4478  lr: 9.817e-05  max_mem: 18931M
[01/24 23:53:50] d2.utils.events INFO:  eta: 1 day, 12:11:51  iter: 1239  total_loss: 576.2  loss_ce: 4.641  loss_mask: 52.05  loss_ce_0: 4.883  loss_mask_0: 55.14  loss_ce_1: 4.393  loss_mask_1: 52.02  loss_ce_2: 4.567  loss_mask_2: 53.08  loss_ce_3: 4.624  loss_mask_3: 53.54  loss_ce_4: 4.663  loss_mask_4: 53.2  loss_ce_5: 4.625  loss_mask_5: 53.45  loss_ce_6: 4.632  loss_mask_6: 52.79  loss_ce_7: 4.638  loss_mask_7: 54.11  loss_ce_8: 4.646  loss_mask_8: 51.69  time: 2.2354  data_time: 0.3515  lr: 9.814e-05  max_mem: 18931M
[01/24 23:54:34] d2.utils.events INFO:  eta: 1 day, 12:08:22  iter: 1259  total_loss: 604.1  loss_ce: 4.677  loss_mask: 56.03  loss_ce_0: 4.901  loss_mask_0: 55.24  loss_ce_1: 4.425  loss_mask_1: 55.54  loss_ce_2: 4.624  loss_mask_2: 55.71  loss_ce_3: 4.679  loss_mask_3: 55.83  loss_ce_4: 4.708  loss_mask_4: 54.76  loss_ce_5: 4.665  loss_mask_5: 54.96  loss_ce_6: 4.677  loss_mask_6: 56.04  loss_ce_7: 4.677  loss_mask_7: 56.53  loss_ce_8: 4.676  loss_mask_8: 55.05  time: 2.2349  data_time: 0.3463  lr: 9.811e-05  max_mem: 18931M
[01/24 23:55:21] d2.utils.events INFO:  eta: 1 day, 12:09:38  iter: 1279  total_loss: 554.1  loss_ce: 4.688  loss_mask: 49.88  loss_ce_0: 4.891  loss_mask_0: 52.28  loss_ce_1: 4.404  loss_mask_1: 50.22  loss_ce_2: 4.623  loss_mask_2: 50.78  loss_ce_3: 4.692  loss_mask_3: 51.36  loss_ce_4: 4.702  loss_mask_4: 51.29  loss_ce_5: 4.661  loss_mask_5: 51.22  loss_ce_6: 4.679  loss_mask_6: 50.28  loss_ce_7: 4.683  loss_mask_7: 49.59  loss_ce_8: 4.684  loss_mask_8: 50.03  time: 2.2364  data_time: 0.4192  lr: 9.8079e-05  max_mem: 18931M
[01/24 23:56:08] d2.utils.events INFO:  eta: 1 day, 12:08:54  iter: 1299  total_loss: 638.5  loss_ce: 4.656  loss_mask: 56.79  loss_ce_0: 4.897  loss_mask_0: 58.79  loss_ce_1: 4.353  loss_mask_1: 59.08  loss_ce_2: 4.573  loss_mask_2: 59.29  loss_ce_3: 4.65  loss_mask_3: 58.17  loss_ce_4: 4.668  loss_mask_4: 59.88  loss_ce_5: 4.624  loss_mask_5: 57.58  loss_ce_6: 4.655  loss_mask_6: 58.55  loss_ce_7: 4.659  loss_mask_7: 60  loss_ce_8: 4.656  loss_mask_8: 58.67  time: 2.2384  data_time: 0.4299  lr: 9.8049e-05  max_mem: 18931M
[01/24 23:56:55] d2.utils.events INFO:  eta: 1 day, 12:09:37  iter: 1319  total_loss: 550.3  loss_ce: 4.615  loss_mask: 50.1  loss_ce_0: 4.912  loss_mask_0: 52.73  loss_ce_1: 4.365  loss_mask_1: 49.38  loss_ce_2: 4.532  loss_mask_2: 49.64  loss_ce_3: 4.587  loss_mask_3: 52.66  loss_ce_4: 4.644  loss_mask_4: 49.78  loss_ce_5: 4.6  loss_mask_5: 50.08  loss_ce_6: 4.623  loss_mask_6: 49.83  loss_ce_7: 4.623  loss_mask_7: 49.47  loss_ce_8: 4.614  loss_mask_8: 49.78  time: 2.2401  data_time: 0.4142  lr: 9.8019e-05  max_mem: 18932M
[01/24 23:57:41] d2.utils.events INFO:  eta: 1 day, 12:11:29  iter: 1339  total_loss: 509.4  loss_ce: 4.603  loss_mask: 46.28  loss_ce_0: 4.897  loss_mask_0: 47.23  loss_ce_1: 4.374  loss_mask_1: 45.83  loss_ce_2: 4.557  loss_mask_2: 46.48  loss_ce_3: 4.606  loss_mask_3: 46.97  loss_ce_4: 4.678  loss_mask_4: 45.6  loss_ce_5: 4.622  loss_mask_5: 46  loss_ce_6: 4.625  loss_mask_6: 46.18  loss_ce_7: 4.619  loss_mask_7: 46.06  loss_ce_8: 4.605  loss_mask_8: 45.99  time: 2.2411  data_time: 0.3945  lr: 9.7989e-05  max_mem: 18932M
[01/24 23:58:28] d2.utils.events INFO:  eta: 1 day, 12:12:14  iter: 1359  total_loss: 550.7  loss_ce: 4.581  loss_mask: 49.7  loss_ce_0: 4.921  loss_mask_0: 52.17  loss_ce_1: 4.363  loss_mask_1: 49.17  loss_ce_2: 4.54  loss_mask_2: 49.6  loss_ce_3: 4.578  loss_mask_3: 52.63  loss_ce_4: 4.649  loss_mask_4: 50.09  loss_ce_5: 4.605  loss_mask_5: 51.89  loss_ce_6: 4.613  loss_mask_6: 50.15  loss_ce_7: 4.599  loss_mask_7: 49.89  loss_ce_8: 4.584  loss_mask_8: 49.93  time: 2.2428  data_time: 0.3925  lr: 9.7959e-05  max_mem: 18932M
[01/24 23:59:10] d2.utils.events INFO:  eta: 1 day, 12:10:27  iter: 1379  total_loss: 513.8  loss_ce: 4.594  loss_mask: 46.23  loss_ce_0: 4.901  loss_mask_0: 47.24  loss_ce_1: 4.346  loss_mask_1: 46.38  loss_ce_2: 4.541  loss_mask_2: 46.11  loss_ce_3: 4.598  loss_mask_3: 49.57  loss_ce_4: 4.651  loss_mask_4: 46.21  loss_ce_5: 4.611  loss_mask_5: 47.23  loss_ce_6: 4.611  loss_mask_6: 46.25  loss_ce_7: 4.607  loss_mask_7: 46.72  loss_ce_8: 4.592  loss_mask_8: 46.58  time: 2.2405  data_time: 0.3690  lr: 9.7929e-05  max_mem: 18932M
[01/24 23:59:55] d2.utils.events INFO:  eta: 1 day, 12:09:42  iter: 1399  total_loss: 553.8  loss_ce: 4.664  loss_mask: 49.97  loss_ce_0: 4.905  loss_mask_0: 52.11  loss_ce_1: 4.403  loss_mask_1: 50.59  loss_ce_2: 4.616  loss_mask_2: 50.94  loss_ce_3: 4.652  loss_mask_3: 51.76  loss_ce_4: 4.717  loss_mask_4: 51.23  loss_ce_5: 4.676  loss_mask_5: 50.05  loss_ce_6: 4.674  loss_mask_6: 50.81  loss_ce_7: 4.668  loss_mask_7: 50.32  loss_ce_8: 4.656  loss_mask_8: 50.5  time: 2.2401  data_time: 0.3728  lr: 9.7899e-05  max_mem: 18932M
[01/25 00:00:38] d2.utils.events INFO:  eta: 1 day, 12:08:07  iter: 1419  total_loss: 566.9  loss_ce: 4.647  loss_mask: 52.35  loss_ce_0: 4.896  loss_mask_0: 54.18  loss_ce_1: 4.365  loss_mask_1: 51.08  loss_ce_2: 4.583  loss_mask_2: 51.88  loss_ce_3: 4.632  loss_mask_3: 53.52  loss_ce_4: 4.674  loss_mask_4: 51.1  loss_ce_5: 4.645  loss_mask_5: 51.51  loss_ce_6: 4.65  loss_mask_6: 51.44  loss_ce_7: 4.64  loss_mask_7: 52.23  loss_ce_8: 4.636  loss_mask_8: 52.54  time: 2.2394  data_time: 0.3499  lr: 9.7869e-05  max_mem: 18932M
[01/25 00:01:22] d2.utils.events INFO:  eta: 1 day, 12:07:03  iter: 1439  total_loss: 508.6  loss_ce: 4.607  loss_mask: 46.22  loss_ce_0: 4.893  loss_mask_0: 48.15  loss_ce_1: 4.335  loss_mask_1: 46.26  loss_ce_2: 4.563  loss_mask_2: 45.98  loss_ce_3: 4.634  loss_mask_3: 46.41  loss_ce_4: 4.65  loss_mask_4: 45.82  loss_ce_5: 4.611  loss_mask_5: 45.86  loss_ce_6: 4.613  loss_mask_6: 45.76  loss_ce_7: 4.606  loss_mask_7: 45.78  loss_ce_8: 4.601  loss_mask_8: 45.91  time: 2.2385  data_time: 0.3315  lr: 9.7839e-05  max_mem: 18932M
[01/25 00:02:06] d2.utils.events INFO:  eta: 1 day, 12:07:09  iter: 1459  total_loss: 564.9  loss_ce: 4.664  loss_mask: 52.11  loss_ce_0: 4.893  loss_mask_0: 52.26  loss_ce_1: 4.382  loss_mask_1: 51.84  loss_ce_2: 4.629  loss_mask_2: 49.48  loss_ce_3: 4.681  loss_mask_3: 50.53  loss_ce_4: 4.705  loss_mask_4: 50.19  loss_ce_5: 4.669  loss_mask_5: 51.69  loss_ce_6: 4.684  loss_mask_6: 51.83  loss_ce_7: 4.673  loss_mask_7: 49.78  loss_ce_8: 4.659  loss_mask_8: 50.73  time: 2.2382  data_time: 0.3565  lr: 9.7809e-05  max_mem: 18932M
[01/25 00:02:49] d2.utils.events INFO:  eta: 1 day, 12:05:35  iter: 1479  total_loss: 552  loss_ce: 4.578  loss_mask: 50.8  loss_ce_0: 4.946  loss_mask_0: 50.77  loss_ce_1: 4.314  loss_mask_1: 49.98  loss_ce_2: 4.544  loss_mask_2: 50.42  loss_ce_3: 4.597  loss_mask_3: 50.3  loss_ce_4: 4.612  loss_mask_4: 49.7  loss_ce_5: 4.57  loss_mask_5: 49.53  loss_ce_6: 4.586  loss_mask_6: 50.45  loss_ce_7: 4.579  loss_mask_7: 51.11  loss_ce_8: 4.562  loss_mask_8: 50.84  time: 2.2369  data_time: 0.3758  lr: 9.7779e-05  max_mem: 18932M
[01/25 00:03:33] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/25 00:03:33] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/25 00:03:33] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/25 00:09:14] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 39.4019442932063, 'error_1pix': 0.8938847542537454, 'error_3pix': 0.8932715490298251, 'mIoU': 0.0012577600780675146, 'fwIoU': 0.0005831738870097348, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.2414899349889628, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5208333333333333, 'pACC': 0.2414899349889628, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 100.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/25 00:09:14] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/25 00:09:14] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/25 00:09:14] d2.evaluation.testing INFO: copypaste: 39.4019,0.8939,0.8933,0.0013,0.0006,0.5208,0.2415
[01/25 00:09:14] d2.utils.events INFO:  eta: 1 day, 12:02:36  iter: 1499  total_loss: 541.6  loss_ce: 4.658  loss_mask: 50.52  loss_ce_0: 4.922  loss_mask_0: 51.03  loss_ce_1: 4.395  loss_mask_1: 49.8  loss_ce_2: 4.617  loss_mask_2: 48.91  loss_ce_3: 4.662  loss_mask_3: 49.22  loss_ce_4: 4.688  loss_mask_4: 49.28  loss_ce_5: 4.651  loss_mask_5: 50.43  loss_ce_6: 4.671  loss_mask_6: 49.53  loss_ce_7: 4.663  loss_mask_7: 49.18  loss_ce_8: 4.653  loss_mask_8: 48.96  time: 2.2360  data_time: 0.3725  lr: 9.7749e-05  max_mem: 18932M
[01/25 00:10:02] d2.utils.events INFO:  eta: 1 day, 12:04:16  iter: 1519  total_loss: 549.8  loss_ce: 4.653  loss_mask: 51.67  loss_ce_0: 4.924  loss_mask_0: 51.29  loss_ce_1: 4.378  loss_mask_1: 50.37  loss_ce_2: 4.599  loss_mask_2: 49.9  loss_ce_3: 4.648  loss_mask_3: 48.89  loss_ce_4: 4.678  loss_mask_4: 49.34  loss_ce_5: 4.652  loss_mask_5: 50.24  loss_ce_6: 4.663  loss_mask_6: 50  loss_ce_7: 4.653  loss_mask_7: 50.62  loss_ce_8: 4.636  loss_mask_8: 51.46  time: 2.2378  data_time: 0.4068  lr: 9.7719e-05  max_mem: 18932M
[01/25 00:10:49] d2.utils.events INFO:  eta: 1 day, 12:05:34  iter: 1539  total_loss: 512.8  loss_ce: 4.647  loss_mask: 46.32  loss_ce_0: 4.895  loss_mask_0: 48.56  loss_ce_1: 4.334  loss_mask_1: 46.53  loss_ce_2: 4.591  loss_mask_2: 46.53  loss_ce_3: 4.645  loss_mask_3: 46.33  loss_ce_4: 4.672  loss_mask_4: 46.71  loss_ce_5: 4.641  loss_mask_5: 46.5  loss_ce_6: 4.657  loss_mask_6: 46.29  loss_ce_7: 4.644  loss_mask_7: 46.65  loss_ce_8: 4.63  loss_mask_8: 46.3  time: 2.2390  data_time: 0.3882  lr: 9.7689e-05  max_mem: 18932M
[01/25 00:11:49] d2.utils.events INFO:  eta: 1 day, 12:06:20  iter: 1559  total_loss: 483.8  loss_ce: 4.626  loss_mask: 43.79  loss_ce_0: 4.898  loss_mask_0: 45.24  loss_ce_1: 4.334  loss_mask_1: 43.36  loss_ce_2: 4.574  loss_mask_2: 43  loss_ce_3: 4.629  loss_mask_3: 43.4  loss_ce_4: 4.653  loss_mask_4: 43.38  loss_ce_5: 4.625  loss_mask_5: 43.37  loss_ce_6: 4.637  loss_mask_6: 43.25  loss_ce_7: 4.623  loss_mask_7: 43.2  loss_ce_8: 4.612  loss_mask_8: 44.12  time: 2.2487  data_time: 0.5970  lr: 9.7658e-05  max_mem: 18932M
[01/25 00:12:49] d2.utils.events INFO:  eta: 1 day, 12:11:02  iter: 1579  total_loss: 496.7  loss_ce: 4.624  loss_mask: 44.39  loss_ce_0: 4.913  loss_mask_0: 46.11  loss_ce_1: 4.325  loss_mask_1: 45.39  loss_ce_2: 4.567  loss_mask_2: 44.69  loss_ce_3: 4.63  loss_mask_3: 44.98  loss_ce_4: 4.658  loss_mask_4: 45.4  loss_ce_5: 4.622  loss_mask_5: 45.77  loss_ce_6: 4.635  loss_mask_6: 45.11  loss_ce_7: 4.623  loss_mask_7: 43.99  loss_ce_8: 4.612  loss_mask_8: 46.44  time: 2.2582  data_time: 0.6755  lr: 9.7628e-05  max_mem: 18932M
[01/25 00:13:48] d2.utils.events INFO:  eta: 1 day, 12:15:46  iter: 1599  total_loss: 485.9  loss_ce: 4.616  loss_mask: 43.97  loss_ce_0: 4.935  loss_mask_0: 45.26  loss_ce_1: 4.332  loss_mask_1: 44.05  loss_ce_2: 4.556  loss_mask_2: 43.47  loss_ce_3: 4.61  loss_mask_3: 43.59  loss_ce_4: 4.647  loss_mask_4: 44.02  loss_ce_5: 4.604  loss_mask_5: 43.86  loss_ce_6: 4.617  loss_mask_6: 44.23  loss_ce_7: 4.615  loss_mask_7: 44.14  loss_ce_8: 4.61  loss_mask_8: 44.8  time: 2.2674  data_time: 0.6291  lr: 9.7598e-05  max_mem: 18932M
[01/25 00:14:51] d2.utils.events INFO:  eta: 1 day, 12:18:41  iter: 1619  total_loss: 502.9  loss_ce: 4.626  loss_mask: 45.51  loss_ce_0: 4.893  loss_mask_0: 48.28  loss_ce_1: 4.332  loss_mask_1: 46.23  loss_ce_2: 4.577  loss_mask_2: 45.39  loss_ce_3: 4.632  loss_mask_3: 45.4  loss_ce_4: 4.656  loss_mask_4: 45.55  loss_ce_5: 4.622  loss_mask_5: 45.95  loss_ce_6: 4.623  loss_mask_6: 45.33  loss_ce_7: 4.617  loss_mask_7: 45.64  loss_ce_8: 4.618  loss_mask_8: 45.89  time: 2.2782  data_time: 0.7155  lr: 9.7568e-05  max_mem: 18932M
[01/25 00:15:52] d2.utils.events INFO:  eta: 1 day, 12:26:23  iter: 1639  total_loss: 493  loss_ce: 4.623  loss_mask: 43.86  loss_ce_0: 4.904  loss_mask_0: 46.56  loss_ce_1: 4.32  loss_mask_1: 45.48  loss_ce_2: 4.555  loss_mask_2: 45.19  loss_ce_3: 4.609  loss_mask_3: 44.46  loss_ce_4: 4.64  loss_mask_4: 44.01  loss_ce_5: 4.618  loss_mask_5: 43.91  loss_ce_6: 4.619  loss_mask_6: 45.11  loss_ce_7: 4.617  loss_mask_7: 45.28  loss_ce_8: 4.601  loss_mask_8: 44.31  time: 2.2874  data_time: 0.6484  lr: 9.7538e-05  max_mem: 18932M
[01/25 00:16:54] d2.utils.events INFO:  eta: 1 day, 12:33:14  iter: 1659  total_loss: 539.3  loss_ce: 4.651  loss_mask: 48.63  loss_ce_0: 4.898  loss_mask_0: 51.51  loss_ce_1: 4.373  loss_mask_1: 48.6  loss_ce_2: 4.623  loss_mask_2: 50.35  loss_ce_3: 4.657  loss_mask_3: 49.57  loss_ce_4: 4.7  loss_mask_4: 48.7  loss_ce_5: 4.663  loss_mask_5: 48.81  loss_ce_6: 4.663  loss_mask_6: 48.84  loss_ce_7: 4.662  loss_mask_7: 49.44  loss_ce_8: 4.651  loss_mask_8: 49.53  time: 2.2969  data_time: 0.6298  lr: 9.7508e-05  max_mem: 18932M
[01/25 00:17:57] d2.utils.events INFO:  eta: 1 day, 12:37:14  iter: 1679  total_loss: 521.9  loss_ce: 4.699  loss_mask: 47.02  loss_ce_0: 4.869  loss_mask_0: 47.95  loss_ce_1: 4.4  loss_mask_1: 47.39  loss_ce_2: 4.655  loss_mask_2: 48.05  loss_ce_3: 4.695  loss_mask_3: 46.97  loss_ce_4: 4.741  loss_mask_4: 47.37  loss_ce_5: 4.71  loss_mask_5: 47.5  loss_ce_6: 4.718  loss_mask_6: 46.8  loss_ce_7: 4.706  loss_mask_7: 46.58  loss_ce_8: 4.689  loss_mask_8: 46.48  time: 2.3075  data_time: 0.6887  lr: 9.7478e-05  max_mem: 18932M
[01/25 00:18:59] d2.utils.events INFO:  eta: 1 day, 12:41:58  iter: 1699  total_loss: 514  loss_ce: 4.638  loss_mask: 45.89  loss_ce_0: 4.873  loss_mask_0: 48.35  loss_ce_1: 4.342  loss_mask_1: 47.18  loss_ce_2: 4.589  loss_mask_2: 46.66  loss_ce_3: 4.64  loss_mask_3: 46.09  loss_ce_4: 4.671  loss_mask_4: 45.89  loss_ce_5: 4.644  loss_mask_5: 45.99  loss_ce_6: 4.653  loss_mask_6: 46.27  loss_ce_7: 4.658  loss_mask_7: 46.2  loss_ce_8: 4.64  loss_mask_8: 45.21  time: 2.3167  data_time: 0.6615  lr: 9.7448e-05  max_mem: 18932M
[01/25 00:20:00] d2.utils.events INFO:  eta: 1 day, 12:50:14  iter: 1719  total_loss: 485.8  loss_ce: 4.575  loss_mask: 43.96  loss_ce_0: 4.906  loss_mask_0: 45.16  loss_ce_1: 4.309  loss_mask_1: 43.64  loss_ce_2: 4.519  loss_mask_2: 43.92  loss_ce_3: 4.574  loss_mask_3: 43.8  loss_ce_4: 4.61  loss_mask_4: 43.95  loss_ce_5: 4.581  loss_mask_5: 44  loss_ce_6: 4.596  loss_mask_6: 43.68  loss_ce_7: 4.593  loss_mask_7: 43.97  loss_ce_8: 4.574  loss_mask_8: 44.05  time: 2.3253  data_time: 0.6396  lr: 9.7418e-05  max_mem: 18932M
[01/25 00:21:00] d2.utils.events INFO:  eta: 1 day, 13:00:05  iter: 1739  total_loss: 474.6  loss_ce: 4.63  loss_mask: 43.38  loss_ce_0: 4.885  loss_mask_0: 43.98  loss_ce_1: 4.323  loss_mask_1: 42.47  loss_ce_2: 4.558  loss_mask_2: 42.41  loss_ce_3: 4.627  loss_mask_3: 42.58  loss_ce_4: 4.65  loss_mask_4: 42.69  loss_ce_5: 4.621  loss_mask_5: 42.57  loss_ce_6: 4.631  loss_mask_6: 42.68  loss_ce_7: 4.631  loss_mask_7: 43.31  loss_ce_8: 4.615  loss_mask_8: 43.56  time: 2.3329  data_time: 0.6451  lr: 9.7388e-05  max_mem: 18932M
[01/25 00:21:11] d2.engine.hooks INFO: Overall training speed: 1742 iterations in 1:07:45 (2.3337 s / it)
[01/25 00:21:11] d2.engine.hooks INFO: Total training time: 1:25:01 (0:17:16 on hooks)
[01/25 00:21:11] d2.utils.events INFO:  eta: 1 day, 13:00:22  iter: 1744  total_loss: 472.6  loss_ce: 4.637  loss_mask: 42.56  loss_ce_0: 4.88  loss_mask_0: 42.64  loss_ce_1: 4.327  loss_mask_1: 42.47  loss_ce_2: 4.569  loss_mask_2: 42.41  loss_ce_3: 4.633  loss_mask_3: 42.58  loss_ce_4: 4.66  loss_mask_4: 42.69  loss_ce_5: 4.632  loss_mask_5: 42.57  loss_ce_6: 4.636  loss_mask_6: 42.44  loss_ce_7: 4.64  loss_mask_7: 42.58  loss_ce_8: 4.626  loss_mask_8: 42.76  time: 2.3333  data_time: 0.6188  lr: 9.7382e-05  max_mem: 18932M
