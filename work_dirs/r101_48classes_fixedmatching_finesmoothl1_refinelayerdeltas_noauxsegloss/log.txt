[02/24 11:33:53] detectron2 INFO: Rank of current process: 0. World size: 4
[02/24 11:34:02] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/24 11:34:02] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[02/24 11:34:02] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m[38;5;15m [39m[38;5;242m#"/home/nstarli/Mask2Former/work_dirs/r101_48classes_fixedmatching/model_final.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[02/24 11:34:02] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSEG_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/r101_48classes_fixedmatching_finesmoothl1_refinelayerdeltas_noauxsegloss[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[02/24 11:34:02] detectron2 INFO: Full config saved to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_refinelayerdeltas_noauxsegloss/config.yaml
[02/24 11:34:02] d2.utils.env INFO: Using a generated random seed 2700102
[02/24 11:34:11] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(48, 256)
      (query_embed): Embedding(48, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=49, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (refinement_layer): DispRefineLayer(
    (conv2d_feature): Conv2d(
      257, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (residual_atrous_blocks): ModuleList(
      (0): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2)
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (2): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(4, 4)
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (3): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(8, 8)
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (4): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (5): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (conv2d_out): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher FixedMatcher
      losses: ['labels', 'masks', 'segs']
      weight_dict: {'loss_mask': 1.0, 'loss_ce': 0.0, 'loss_dice': 1.0, 'loss_seg': 1.0, 'loss_mask_0': 1.0, 'loss_ce_0': 0.0, 'loss_dice_0': 1.0, 'loss_mask_1': 1.0, 'loss_ce_1': 0.0, 'loss_dice_1': 1.0, 'loss_mask_2': 1.0, 'loss_ce_2': 0.0, 'loss_dice_2': 1.0, 'loss_mask_3': 1.0, 'loss_ce_3': 0.0, 'loss_dice_3': 1.0, 'loss_mask_4': 1.0, 'loss_ce_4': 0.0, 'loss_dice_4': 1.0, 'loss_mask_5': 1.0, 'loss_ce_5': 0.0, 'loss_dice_5': 1.0, 'loss_mask_6': 1.0, 'loss_ce_6': 0.0, 'loss_dice_6': 1.0, 'loss_mask_7': 1.0, 'loss_ce_7': 0.0, 'loss_dice_7': 1.0, 'loss_mask_8': 1.0, 'loss_ce_8': 0.0, 'loss_dice_8': 1.0}
      num_classes: 48
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[02/24 11:34:11] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[02/24 11:34:24] d2.data.build INFO: Using training sampler TrainingSampler
[02/24 11:34:25] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[02/24 11:34:28] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[02/24 11:34:29] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[02/24 11:34:29] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/24 11:34:30] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[02/24 11:34:34] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34mrefinement_layer.conv2d_feature.norm.{bias, weight}[0m
[34mrefinement_layer.conv2d_feature.{bias, weight}[0m
[34mrefinement_layer.conv2d_out.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.0.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.0.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.1.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.1.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.2.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.2.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.3.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.3.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.4.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.4.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.5.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.5.conv1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[02/24 11:34:34] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[02/24 11:34:34] d2.engine.train_loop INFO: Starting training from iteration 0
[02/24 11:34:57] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 395, in run_step
    loss_dict = self.model(data)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 799, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 791, in forward
    losses = self.criterion(outputs, targets)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/modeling/criterion.py", line 259, in forward
    losses.update(self.get_loss(loss, outputs, targets, indices, num_masks))
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 212, in get_loss
    return loss_map[loss](outputs, targets, indices, num_masks)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 191, in loss_segs
    semseg,
UnboundLocalError: local variable 'semseg' referenced before assignment
[02/24 11:34:57] d2.engine.hooks INFO: Total training time: 0:00:22 (0:00:00 on hooks)
[02/24 11:34:57] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 4509M
[02/24 11:37:47] detectron2 INFO: Rank of current process: 0. World size: 4
[02/24 11:37:54] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/24 11:37:54] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[02/24 11:37:54] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m[38;5;15m [39m[38;5;242m#"/home/nstarli/Mask2Former/work_dirs/r101_48classes_fixedmatching/model_final.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[02/24 11:37:54] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSEG_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/r101_48classes_fixedmatching_finesmoothl1_refinelayerdeltas_noauxsegloss[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[02/24 11:37:54] detectron2 INFO: Full config saved to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_refinelayerdeltas_noauxsegloss/config.yaml
[02/24 11:37:54] d2.utils.env INFO: Using a generated random seed 54740509
[02/24 11:38:02] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(48, 256)
      (query_embed): Embedding(48, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=49, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (refinement_layer): DispRefineLayer(
    (conv2d_feature): Conv2d(
      257, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (residual_atrous_blocks): ModuleList(
      (0): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2)
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (2): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(4, 4)
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (3): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(8, 8)
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (4): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (5): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (conv2d_out): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher FixedMatcher
      losses: ['labels', 'masks', 'segs']
      weight_dict: {'loss_mask': 1.0, 'loss_ce': 0.0, 'loss_dice': 1.0, 'loss_seg': 1.0, 'loss_mask_0': 1.0, 'loss_ce_0': 0.0, 'loss_dice_0': 1.0, 'loss_mask_1': 1.0, 'loss_ce_1': 0.0, 'loss_dice_1': 1.0, 'loss_mask_2': 1.0, 'loss_ce_2': 0.0, 'loss_dice_2': 1.0, 'loss_mask_3': 1.0, 'loss_ce_3': 0.0, 'loss_dice_3': 1.0, 'loss_mask_4': 1.0, 'loss_ce_4': 0.0, 'loss_dice_4': 1.0, 'loss_mask_5': 1.0, 'loss_ce_5': 0.0, 'loss_dice_5': 1.0, 'loss_mask_6': 1.0, 'loss_ce_6': 0.0, 'loss_dice_6': 1.0, 'loss_mask_7': 1.0, 'loss_ce_7': 0.0, 'loss_dice_7': 1.0, 'loss_mask_8': 1.0, 'loss_ce_8': 0.0, 'loss_dice_8': 1.0}
      num_classes: 48
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[02/24 11:38:02] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[02/24 11:38:15] d2.data.build INFO: Using training sampler TrainingSampler
[02/24 11:38:16] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[02/24 11:38:16] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[02/24 11:38:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[02/24 11:38:17] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/24 11:38:17] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[02/24 11:38:18] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34mrefinement_layer.conv2d_feature.norm.{bias, weight}[0m
[34mrefinement_layer.conv2d_feature.{bias, weight}[0m
[34mrefinement_layer.conv2d_out.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.0.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.0.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.1.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.1.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.2.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.2.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.3.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.3.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.4.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.4.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.5.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.5.conv1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[02/24 11:38:18] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[02/24 11:38:18] d2.engine.train_loop INFO: Starting training from iteration 0
[02/24 11:39:28] d2.utils.events INFO:  eta: 1 day, 16:50:24  iter: 19  total_loss: 44.26  loss_ce: 0  loss_mask: 0.2477  loss_dice: 0.9688  loss_seg: 32.45  loss_ce_0: 0  loss_mask_0: 0.2231  loss_dice_0: 0.957  loss_ce_1: 0  loss_mask_1: 0.2251  loss_dice_1: 0.9607  loss_ce_2: 0  loss_mask_2: 0.2191  loss_dice_2: 0.9616  loss_ce_3: 0  loss_mask_3: 0.2208  loss_dice_3: 0.9601  loss_ce_4: 0  loss_mask_4: 0.2375  loss_dice_4: 0.9505  loss_ce_5: 0  loss_mask_5: 0.2215  loss_dice_5: 0.9595  loss_ce_6: 0  loss_mask_6: 0.2261  loss_dice_6: 0.9584  loss_ce_7: 0  loss_mask_7: 0.2229  loss_dice_7: 0.96  loss_ce_8: 0  loss_mask_8: 0.2213  loss_dice_8: 0.9599  time: 2.4713  data_time: 0.8237  lr: 9.9971e-05  max_mem: 5689M
[02/24 11:40:10] d2.utils.events INFO:  eta: 1 day, 14:00:55  iter: 39  total_loss: 34.77  loss_ce: 0  loss_mask: 0.1959  loss_dice: 0.9666  loss_seg: 23.15  loss_ce_0: 0  loss_mask_0: 0.2068  loss_dice_0: 0.9555  loss_ce_1: 0  loss_mask_1: 0.2071  loss_dice_1: 0.9543  loss_ce_2: 0  loss_mask_2: 0.2025  loss_dice_2: 0.9584  loss_ce_3: 0  loss_mask_3: 0.203  loss_dice_3: 0.9649  loss_ce_4: 0  loss_mask_4: 0.2015  loss_dice_4: 0.9663  loss_ce_5: 0  loss_mask_5: 0.2017  loss_dice_5: 0.9653  loss_ce_6: 0  loss_mask_6: 0.2043  loss_dice_6: 0.9649  loss_ce_7: 0  loss_mask_7: 0.2016  loss_dice_7: 0.9644  loss_ce_8: 0  loss_mask_8: 0.2016  loss_dice_8: 0.9631  time: 2.2677  data_time: 0.0594  lr: 9.9941e-05  max_mem: 5800M
[02/24 11:40:45] d2.utils.events INFO:  eta: 1 day, 10:33:29  iter: 59  total_loss: 32.51  loss_ce: 0  loss_mask: 0.2107  loss_dice: 0.9606  loss_seg: 20.93  loss_ce_0: 0  loss_mask_0: 0.227  loss_dice_0: 0.9458  loss_ce_1: 0  loss_mask_1: 0.2345  loss_dice_1: 0.9431  loss_ce_2: 0  loss_mask_2: 0.23  loss_dice_2: 0.9437  loss_ce_3: 0  loss_mask_3: 0.2235  loss_dice_3: 0.9523  loss_ce_4: 0  loss_mask_4: 0.2153  loss_dice_4: 0.9555  loss_ce_5: 0  loss_mask_5: 0.2127  loss_dice_5: 0.9584  loss_ce_6: 0  loss_mask_6: 0.2123  loss_dice_6: 0.9564  loss_ce_7: 0  loss_mask_7: 0.2123  loss_dice_7: 0.9569  loss_ce_8: 0  loss_mask_8: 0.2146  loss_dice_8: 0.9617  time: 2.0830  data_time: 0.0586  lr: 9.9911e-05  max_mem: 5800M
[02/24 11:41:19] d2.utils.events INFO:  eta: 1 day, 6:46:45  iter: 79  total_loss: 31.1  loss_ce: 0  loss_mask: 0.2113  loss_dice: 0.9591  loss_seg: 19.49  loss_ce_0: 0  loss_mask_0: 0.2243  loss_dice_0: 0.9455  loss_ce_1: 0  loss_mask_1: 0.2314  loss_dice_1: 0.9425  loss_ce_2: 0  loss_mask_2: 0.229  loss_dice_2: 0.943  loss_ce_3: 0  loss_mask_3: 0.2245  loss_dice_3: 0.9457  loss_ce_4: 0  loss_mask_4: 0.2169  loss_dice_4: 0.9522  loss_ce_5: 0  loss_mask_5: 0.2082  loss_dice_5: 0.9573  loss_ce_6: 0  loss_mask_6: 0.2093  loss_dice_6: 0.959  loss_ce_7: 0  loss_mask_7: 0.2096  loss_dice_7: 0.9594  loss_ce_8: 0  loss_mask_8: 0.2092  loss_dice_8: 0.9588  time: 1.9895  data_time: 0.0630  lr: 9.9881e-05  max_mem: 5800M
[02/24 11:41:54] d2.utils.events INFO:  eta: 1 day, 6:05:16  iter: 99  total_loss: 28.3  loss_ce: 0  loss_mask: 0.2038  loss_dice: 0.9602  loss_seg: 16.65  loss_ce_0: 0  loss_mask_0: 0.2253  loss_dice_0: 0.9409  loss_ce_1: 0  loss_mask_1: 0.2385  loss_dice_1: 0.933  loss_ce_2: 0  loss_mask_2: 0.2353  loss_dice_2: 0.9353  loss_ce_3: 0  loss_mask_3: 0.2353  loss_dice_3: 0.9388  loss_ce_4: 0  loss_mask_4: 0.2208  loss_dice_4: 0.9451  loss_ce_5: 0  loss_mask_5: 0.2072  loss_dice_5: 0.9539  loss_ce_6: 0  loss_mask_6: 0.2026  loss_dice_6: 0.9581  loss_ce_7: 0  loss_mask_7: 0.2031  loss_dice_7: 0.9583  loss_ce_8: 0  loss_mask_8: 0.203  loss_dice_8: 0.9604  time: 1.9397  data_time: 0.0524  lr: 9.9851e-05  max_mem: 5800M
[02/24 11:42:29] d2.utils.events INFO:  eta: 1 day, 5:46:20  iter: 119  total_loss: 28.52  loss_ce: 0  loss_mask: 0.2056  loss_dice: 0.9614  loss_seg: 16.82  loss_ce_0: 0  loss_mask_0: 0.235  loss_dice_0: 0.9338  loss_ce_1: 0  loss_mask_1: 0.2431  loss_dice_1: 0.9271  loss_ce_2: 0  loss_mask_2: 0.2424  loss_dice_2: 0.9275  loss_ce_3: 0  loss_mask_3: 0.2411  loss_dice_3: 0.9314  loss_ce_4: 0  loss_mask_4: 0.2322  loss_dice_4: 0.9342  loss_ce_5: 0  loss_mask_5: 0.2249  loss_dice_5: 0.9425  loss_ce_6: 0  loss_mask_6: 0.2142  loss_dice_6: 0.9511  loss_ce_7: 0  loss_mask_7: 0.2098  loss_dice_7: 0.9554  loss_ce_8: 0  loss_mask_8: 0.2055  loss_dice_8: 0.9576  time: 1.9005  data_time: 0.0495  lr: 9.9821e-05  max_mem: 5800M
[02/24 11:43:04] d2.utils.events INFO:  eta: 1 day, 5:35:22  iter: 139  total_loss: 27.37  loss_ce: 0  loss_mask: 0.2142  loss_dice: 0.958  loss_seg: 15.45  loss_ce_0: 0  loss_mask_0: 0.2453  loss_dice_0: 0.9324  loss_ce_1: 0  loss_mask_1: 0.2552  loss_dice_1: 0.9238  loss_ce_2: 0  loss_mask_2: 0.2566  loss_dice_2: 0.9238  loss_ce_3: 0  loss_mask_3: 0.256  loss_dice_3: 0.9263  loss_ce_4: 0  loss_mask_4: 0.2491  loss_dice_4: 0.9306  loss_ce_5: 0  loss_mask_5: 0.2425  loss_dice_5: 0.9373  loss_ce_6: 0  loss_mask_6: 0.2234  loss_dice_6: 0.9437  loss_ce_7: 0  loss_mask_7: 0.2206  loss_dice_7: 0.9496  loss_ce_8: 0  loss_mask_8: 0.2148  loss_dice_8: 0.959  time: 1.8780  data_time: 0.0503  lr: 9.9791e-05  max_mem: 5800M
[02/24 11:43:38] d2.utils.events INFO:  eta: 1 day, 5:22:24  iter: 159  total_loss: 28.32  loss_ce: 0  loss_mask: 0.1989  loss_dice: 0.9618  loss_seg: 16.53  loss_ce_0: 0  loss_mask_0: 0.2353  loss_dice_0: 0.9307  loss_ce_1: 0  loss_mask_1: 0.2503  loss_dice_1: 0.9204  loss_ce_2: 0  loss_mask_2: 0.2534  loss_dice_2: 0.9233  loss_ce_3: 0  loss_mask_3: 0.2494  loss_dice_3: 0.9284  loss_ce_4: 0  loss_mask_4: 0.2437  loss_dice_4: 0.9278  loss_ce_5: 0  loss_mask_5: 0.2358  loss_dice_5: 0.9326  loss_ce_6: 0  loss_mask_6: 0.2287  loss_dice_6: 0.9414  loss_ce_7: 0  loss_mask_7: 0.2154  loss_dice_7: 0.9511  loss_ce_8: 0  loss_mask_8: 0.2033  loss_dice_8: 0.9579  time: 1.8584  data_time: 0.0542  lr: 9.9761e-05  max_mem: 5800M
[02/24 11:44:12] d2.utils.events INFO:  eta: 1 day, 5:12:32  iter: 179  total_loss: 29.84  loss_ce: 0  loss_mask: 0.2077  loss_dice: 0.9575  loss_seg: 18.18  loss_ce_0: 0  loss_mask_0: 0.2417  loss_dice_0: 0.9269  loss_ce_1: 0  loss_mask_1: 0.2603  loss_dice_1: 0.9172  loss_ce_2: 0  loss_mask_2: 0.2586  loss_dice_2: 0.9176  loss_ce_3: 0  loss_mask_3: 0.257  loss_dice_3: 0.9211  loss_ce_4: 0  loss_mask_4: 0.2544  loss_dice_4: 0.9232  loss_ce_5: 0  loss_mask_5: 0.2443  loss_dice_5: 0.9258  loss_ce_6: 0  loss_mask_6: 0.2328  loss_dice_6: 0.9357  loss_ce_7: 0  loss_mask_7: 0.2131  loss_dice_7: 0.9489  loss_ce_8: 0  loss_mask_8: 0.2045  loss_dice_8: 0.9562  time: 1.8404  data_time: 0.0518  lr: 9.9731e-05  max_mem: 5800M
[02/24 11:44:47] d2.utils.events INFO:  eta: 1 day, 5:05:10  iter: 199  total_loss: 27.88  loss_ce: 0  loss_mask: 0.1991  loss_dice: 0.9605  loss_seg: 16.24  loss_ce_0: 0  loss_mask_0: 0.2385  loss_dice_0: 0.9281  loss_ce_1: 0  loss_mask_1: 0.2498  loss_dice_1: 0.9198  loss_ce_2: 0  loss_mask_2: 0.25  loss_dice_2: 0.92  loss_ce_3: 0  loss_mask_3: 0.2482  loss_dice_3: 0.9223  loss_ce_4: 0  loss_mask_4: 0.2456  loss_dice_4: 0.9241  loss_ce_5: 0  loss_mask_5: 0.2399  loss_dice_5: 0.9299  loss_ce_6: 0  loss_mask_6: 0.2309  loss_dice_6: 0.9376  loss_ce_7: 0  loss_mask_7: 0.2173  loss_dice_7: 0.9449  loss_ce_8: 0  loss_mask_8: 0.2046  loss_dice_8: 0.9588  time: 1.8281  data_time: 0.0514  lr: 9.9701e-05  max_mem: 5800M
[02/24 11:45:22] d2.utils.events INFO:  eta: 1 day, 5:06:24  iter: 219  total_loss: 26.67  loss_ce: 0  loss_mask: 0.2031  loss_dice: 0.9644  loss_seg: 14.93  loss_ce_0: 0  loss_mask_0: 0.2489  loss_dice_0: 0.9229  loss_ce_1: 0  loss_mask_1: 0.2568  loss_dice_1: 0.9144  loss_ce_2: 0  loss_mask_2: 0.2524  loss_dice_2: 0.9174  loss_ce_3: 0  loss_mask_3: 0.249  loss_dice_3: 0.9233  loss_ce_4: 0  loss_mask_4: 0.2542  loss_dice_4: 0.9276  loss_ce_5: 0  loss_mask_5: 0.2474  loss_dice_5: 0.9271  loss_ce_6: 0  loss_mask_6: 0.2411  loss_dice_6: 0.9357  loss_ce_7: 0  loss_mask_7: 0.2317  loss_dice_7: 0.94  loss_ce_8: 0  loss_mask_8: 0.21  loss_dice_8: 0.9554  time: 1.8212  data_time: 0.0584  lr: 9.9671e-05  max_mem: 5800M
[02/24 11:45:58] d2.utils.events INFO:  eta: 1 day, 5:07:19  iter: 239  total_loss: 26.12  loss_ce: 0  loss_mask: 0.2155  loss_dice: 0.9514  loss_seg: 14.31  loss_ce_0: 0  loss_mask_0: 0.2541  loss_dice_0: 0.9172  loss_ce_1: 0  loss_mask_1: 0.2693  loss_dice_1: 0.9078  loss_ce_2: 0  loss_mask_2: 0.2705  loss_dice_2: 0.9053  loss_ce_3: 0  loss_mask_3: 0.2672  loss_dice_3: 0.9088  loss_ce_4: 0  loss_mask_4: 0.2654  loss_dice_4: 0.9121  loss_ce_5: 0  loss_mask_5: 0.2632  loss_dice_5: 0.9126  loss_ce_6: 0  loss_mask_6: 0.2614  loss_dice_6: 0.917  loss_ce_7: 0  loss_mask_7: 0.2458  loss_dice_7: 0.9304  loss_ce_8: 0  loss_mask_8: 0.2202  loss_dice_8: 0.9506  time: 1.8158  data_time: 0.0494  lr: 9.9641e-05  max_mem: 5800M
[02/24 11:46:33] d2.utils.events INFO:  eta: 1 day, 5:06:12  iter: 259  total_loss: 25.63  loss_ce: 0  loss_mask: 0.2189  loss_dice: 0.9555  loss_seg: 13.86  loss_ce_0: 0  loss_mask_0: 0.2704  loss_dice_0: 0.9108  loss_ce_1: 0  loss_mask_1: 0.2825  loss_dice_1: 0.9  loss_ce_2: 0  loss_mask_2: 0.2827  loss_dice_2: 0.9014  loss_ce_3: 0  loss_mask_3: 0.2762  loss_dice_3: 0.9065  loss_ce_4: 0  loss_mask_4: 0.2737  loss_dice_4: 0.9075  loss_ce_5: 0  loss_mask_5: 0.2714  loss_dice_5: 0.911  loss_ce_6: 0  loss_mask_6: 0.2579  loss_dice_6: 0.9184  loss_ce_7: 0  loss_mask_7: 0.2469  loss_dice_7: 0.9261  loss_ce_8: 0  loss_mask_8: 0.2309  loss_dice_8: 0.9443  time: 1.8097  data_time: 0.0461  lr: 9.9611e-05  max_mem: 5800M
[02/24 11:47:07] d2.utils.events INFO:  eta: 1 day, 5:02:50  iter: 279  total_loss: 25.41  loss_ce: 0  loss_mask: 0.2156  loss_dice: 0.9617  loss_seg: 13.66  loss_ce_0: 0  loss_mask_0: 0.252  loss_dice_0: 0.9159  loss_ce_1: 0  loss_mask_1: 0.2695  loss_dice_1: 0.9076  loss_ce_2: 0  loss_mask_2: 0.2689  loss_dice_2: 0.9064  loss_ce_3: 0  loss_mask_3: 0.2652  loss_dice_3: 0.9107  loss_ce_4: 0  loss_mask_4: 0.2627  loss_dice_4: 0.9126  loss_ce_5: 0  loss_mask_5: 0.2604  loss_dice_5: 0.9182  loss_ce_6: 0  loss_mask_6: 0.2568  loss_dice_6: 0.9232  loss_ce_7: 0  loss_mask_7: 0.2417  loss_dice_7: 0.9295  loss_ce_8: 0  loss_mask_8: 0.2202  loss_dice_8: 0.9542  time: 1.8045  data_time: 0.0576  lr: 9.9581e-05  max_mem: 5800M
[02/24 11:47:42] d2.utils.events INFO:  eta: 1 day, 4:51:41  iter: 299  total_loss: 25.75  loss_ce: 0  loss_mask: 0.2048  loss_dice: 0.9588  loss_seg: 14.07  loss_ce_0: 0  loss_mask_0: 0.2509  loss_dice_0: 0.9213  loss_ce_1: 0  loss_mask_1: 0.2648  loss_dice_1: 0.9133  loss_ce_2: 0  loss_mask_2: 0.2648  loss_dice_2: 0.9118  loss_ce_3: 0  loss_mask_3: 0.2632  loss_dice_3: 0.9138  loss_ce_4: 0  loss_mask_4: 0.2649  loss_dice_4: 0.9143  loss_ce_5: 0  loss_mask_5: 0.2612  loss_dice_5: 0.9138  loss_ce_6: 0  loss_mask_6: 0.2601  loss_dice_6: 0.919  loss_ce_7: 0  loss_mask_7: 0.2502  loss_dice_7: 0.9223  loss_ce_8: 0  loss_mask_8: 0.2184  loss_dice_8: 0.9451  time: 1.7991  data_time: 0.0508  lr: 9.9551e-05  max_mem: 5800M
[02/24 11:48:16] d2.utils.events INFO:  eta: 1 day, 4:49:32  iter: 319  total_loss: 25.22  loss_ce: 0  loss_mask: 0.2083  loss_dice: 0.9596  loss_seg: 13.49  loss_ce_0: 0  loss_mask_0: 0.2569  loss_dice_0: 0.9159  loss_ce_1: 0  loss_mask_1: 0.265  loss_dice_1: 0.9075  loss_ce_2: 0  loss_mask_2: 0.2668  loss_dice_2: 0.9068  loss_ce_3: 0  loss_mask_3: 0.2642  loss_dice_3: 0.9087  loss_ce_4: 0  loss_mask_4: 0.263  loss_dice_4: 0.9088  loss_ce_5: 0  loss_mask_5: 0.2603  loss_dice_5: 0.9122  loss_ce_6: 0  loss_mask_6: 0.2623  loss_dice_6: 0.9151  loss_ce_7: 0  loss_mask_7: 0.2515  loss_dice_7: 0.921  loss_ce_8: 0  loss_mask_8: 0.2184  loss_dice_8: 0.9451  time: 1.7926  data_time: 0.0571  lr: 9.9521e-05  max_mem: 5800M
[02/24 11:48:51] d2.utils.events INFO:  eta: 1 day, 4:48:08  iter: 339  total_loss: 25.51  loss_ce: 0  loss_mask: 0.2063  loss_dice: 0.962  loss_seg: 13.84  loss_ce_0: 0  loss_mask_0: 0.2654  loss_dice_0: 0.9086  loss_ce_1: 0  loss_mask_1: 0.2724  loss_dice_1: 0.8981  loss_ce_2: 0  loss_mask_2: 0.2736  loss_dice_2: 0.8955  loss_ce_3: 0  loss_mask_3: 0.2712  loss_dice_3: 0.8987  loss_ce_4: 0  loss_mask_4: 0.2731  loss_dice_4: 0.8987  loss_ce_5: 0  loss_mask_5: 0.271  loss_dice_5: 0.9024  loss_ce_6: 0  loss_mask_6: 0.2711  loss_dice_6: 0.9038  loss_ce_7: 0  loss_mask_7: 0.2624  loss_dice_7: 0.9139  loss_ce_8: 0  loss_mask_8: 0.223  loss_dice_8: 0.9423  time: 1.7889  data_time: 0.0481  lr: 9.9491e-05  max_mem: 5800M
[02/24 11:49:26] d2.utils.events INFO:  eta: 1 day, 4:46:54  iter: 359  total_loss: 24.03  loss_ce: 0  loss_mask: 0.2154  loss_dice: 0.9555  loss_seg: 12.3  loss_ce_0: 0  loss_mask_0: 0.2728  loss_dice_0: 0.9058  loss_ce_1: 0  loss_mask_1: 0.2858  loss_dice_1: 0.8974  loss_ce_2: 0  loss_mask_2: 0.2855  loss_dice_2: 0.8964  loss_ce_3: 0  loss_mask_3: 0.2909  loss_dice_3: 0.8972  loss_ce_4: 0  loss_mask_4: 0.2851  loss_dice_4: 0.9025  loss_ce_5: 0  loss_mask_5: 0.278  loss_dice_5: 0.9087  loss_ce_6: 0  loss_mask_6: 0.2733  loss_dice_6: 0.9097  loss_ce_7: 0  loss_mask_7: 0.2736  loss_dice_7: 0.9135  loss_ce_8: 0  loss_mask_8: 0.2368  loss_dice_8: 0.9381  time: 1.7868  data_time: 0.0636  lr: 9.9461e-05  max_mem: 5800M
[02/24 11:50:01] d2.utils.events INFO:  eta: 1 day, 4:45:17  iter: 379  total_loss: 25.17  loss_ce: 0  loss_mask: 0.2106  loss_dice: 0.9569  loss_seg: 13.47  loss_ce_0: 0  loss_mask_0: 0.2631  loss_dice_0: 0.9068  loss_ce_1: 0  loss_mask_1: 0.2749  loss_dice_1: 0.8957  loss_ce_2: 0  loss_mask_2: 0.275  loss_dice_2: 0.8957  loss_ce_3: 0  loss_mask_3: 0.2747  loss_dice_3: 0.8994  loss_ce_4: 0  loss_mask_4: 0.2715  loss_dice_4: 0.9048  loss_ce_5: 0  loss_mask_5: 0.2719  loss_dice_5: 0.9087  loss_ce_6: 0  loss_mask_6: 0.2698  loss_dice_6: 0.9084  loss_ce_7: 0  loss_mask_7: 0.2593  loss_dice_7: 0.9121  loss_ce_8: 0  loss_mask_8: 0.2283  loss_dice_8: 0.937  time: 1.7847  data_time: 0.0557  lr: 9.9431e-05  max_mem: 5800M
[02/24 11:50:36] d2.utils.events INFO:  eta: 1 day, 4:45:45  iter: 399  total_loss: 26.83  loss_ce: 0  loss_mask: 0.2046  loss_dice: 0.9569  loss_seg: 14.93  loss_ce_0: 0  loss_mask_0: 0.2535  loss_dice_0: 0.9076  loss_ce_1: 0  loss_mask_1: 0.2645  loss_dice_1: 0.8987  loss_ce_2: 0  loss_mask_2: 0.2632  loss_dice_2: 0.9005  loss_ce_3: 0  loss_mask_3: 0.2588  loss_dice_3: 0.9038  loss_ce_4: 0  loss_mask_4: 0.2577  loss_dice_4: 0.9058  loss_ce_5: 0  loss_mask_5: 0.2579  loss_dice_5: 0.909  loss_ce_6: 0  loss_mask_6: 0.2542  loss_dice_6: 0.9094  loss_ce_7: 0  loss_mask_7: 0.2516  loss_dice_7: 0.9155  loss_ce_8: 0  loss_mask_8: 0.2189  loss_dice_8: 0.9389  time: 1.7822  data_time: 0.0560  lr: 9.9401e-05  max_mem: 5800M
[02/24 11:51:11] d2.utils.events INFO:  eta: 1 day, 4:44:46  iter: 419  total_loss: 25.17  loss_ce: 0  loss_mask: 0.2101  loss_dice: 0.9542  loss_seg: 13.62  loss_ce_0: 0  loss_mask_0: 0.263  loss_dice_0: 0.9051  loss_ce_1: 0  loss_mask_1: 0.2714  loss_dice_1: 0.8955  loss_ce_2: 0  loss_mask_2: 0.2735  loss_dice_2: 0.8955  loss_ce_3: 0  loss_mask_3: 0.271  loss_dice_3: 0.8969  loss_ce_4: 0  loss_mask_4: 0.2704  loss_dice_4: 0.898  loss_ce_5: 0  loss_mask_5: 0.2709  loss_dice_5: 0.8974  loss_ce_6: 0  loss_mask_6: 0.2664  loss_dice_6: 0.9026  loss_ce_7: 0  loss_mask_7: 0.266  loss_dice_7: 0.9079  loss_ce_8: 0  loss_mask_8: 0.2493  loss_dice_8: 0.9316  time: 1.7799  data_time: 0.0600  lr: 9.9371e-05  max_mem: 5800M
[02/24 11:51:47] d2.utils.events INFO:  eta: 1 day, 4:45:14  iter: 439  total_loss: 23.3  loss_ce: 0  loss_mask: 0.207  loss_dice: 0.957  loss_seg: 11.62  loss_ce_0: 0  loss_mask_0: 0.2627  loss_dice_0: 0.9009  loss_ce_1: 0  loss_mask_1: 0.2773  loss_dice_1: 0.8927  loss_ce_2: 0  loss_mask_2: 0.2759  loss_dice_2: 0.8927  loss_ce_3: 0  loss_mask_3: 0.274  loss_dice_3: 0.8947  loss_ce_4: 0  loss_mask_4: 0.2714  loss_dice_4: 0.893  loss_ce_5: 0  loss_mask_5: 0.2704  loss_dice_5: 0.8957  loss_ce_6: 0  loss_mask_6: 0.2712  loss_dice_6: 0.898  loss_ce_7: 0  loss_mask_7: 0.2674  loss_dice_7: 0.9045  loss_ce_8: 0  loss_mask_8: 0.2431  loss_dice_8: 0.9247  time: 1.7798  data_time: 0.0477  lr: 9.9341e-05  max_mem: 5800M
[02/24 11:52:22] d2.utils.events INFO:  eta: 1 day, 4:46:41  iter: 459  total_loss: 23.04  loss_ce: 0  loss_mask: 0.211  loss_dice: 0.9544  loss_seg: 11.36  loss_ce_0: 0  loss_mask_0: 0.2685  loss_dice_0: 0.8996  loss_ce_1: 0  loss_mask_1: 0.2793  loss_dice_1: 0.8898  loss_ce_2: 0  loss_mask_2: 0.2768  loss_dice_2: 0.8893  loss_ce_3: 0  loss_mask_3: 0.2786  loss_dice_3: 0.8888  loss_ce_4: 0  loss_mask_4: 0.2766  loss_dice_4: 0.8908  loss_ce_5: 0  loss_mask_5: 0.2739  loss_dice_5: 0.8918  loss_ce_6: 0  loss_mask_6: 0.2757  loss_dice_6: 0.896  loss_ce_7: 0  loss_mask_7: 0.2709  loss_dice_7: 0.9039  loss_ce_8: 0  loss_mask_8: 0.2467  loss_dice_8: 0.9258  time: 1.7792  data_time: 0.0632  lr: 9.9311e-05  max_mem: 5800M
[02/24 11:52:56] d2.utils.events INFO:  eta: 1 day, 4:44:54  iter: 479  total_loss: 23.86  loss_ce: 0  loss_mask: 0.2146  loss_dice: 0.9548  loss_seg: 12.12  loss_ce_0: 0  loss_mask_0: 0.2703  loss_dice_0: 0.899  loss_ce_1: 0  loss_mask_1: 0.2866  loss_dice_1: 0.8928  loss_ce_2: 0  loss_mask_2: 0.2898  loss_dice_2: 0.892  loss_ce_3: 0  loss_mask_3: 0.283  loss_dice_3: 0.8965  loss_ce_4: 0  loss_mask_4: 0.2819  loss_dice_4: 0.8981  loss_ce_5: 0  loss_mask_5: 0.2775  loss_dice_5: 0.8987  loss_ce_6: 0  loss_mask_6: 0.2796  loss_dice_6: 0.8997  loss_ce_7: 0  loss_mask_7: 0.2768  loss_dice_7: 0.9032  loss_ce_8: 0  loss_mask_8: 0.2508  loss_dice_8: 0.9304  time: 1.7761  data_time: 0.0499  lr: 9.9281e-05  max_mem: 5800M
[02/24 11:53:32] d2.utils.events INFO:  eta: 1 day, 4:45:13  iter: 499  total_loss: 23.51  loss_ce: 0  loss_mask: 0.209  loss_dice: 0.9547  loss_seg: 11.81  loss_ce_0: 0  loss_mask_0: 0.2723  loss_dice_0: 0.8968  loss_ce_1: 0  loss_mask_1: 0.2846  loss_dice_1: 0.8892  loss_ce_2: 0  loss_mask_2: 0.2793  loss_dice_2: 0.8903  loss_ce_3: 0  loss_mask_3: 0.2816  loss_dice_3: 0.8905  loss_ce_4: 0  loss_mask_4: 0.279  loss_dice_4: 0.8901  loss_ce_5: 0  loss_mask_5: 0.2772  loss_dice_5: 0.8922  loss_ce_6: 0  loss_mask_6: 0.2751  loss_dice_6: 0.8962  loss_ce_7: 0  loss_mask_7: 0.2727  loss_dice_7: 0.9018  loss_ce_8: 0  loss_mask_8: 0.2537  loss_dice_8: 0.9213  time: 1.7762  data_time: 0.0570  lr: 9.9251e-05  max_mem: 5800M
[02/24 11:54:08] d2.utils.events INFO:  eta: 1 day, 4:45:44  iter: 519  total_loss: 24.15  loss_ce: 0  loss_mask: 0.2184  loss_dice: 0.9537  loss_seg: 12.5  loss_ce_0: 0  loss_mask_0: 0.2753  loss_dice_0: 0.8945  loss_ce_1: 0  loss_mask_1: 0.2832  loss_dice_1: 0.8883  loss_ce_2: 0  loss_mask_2: 0.2866  loss_dice_2: 0.8873  loss_ce_3: 0  loss_mask_3: 0.2849  loss_dice_3: 0.8876  loss_ce_4: 0  loss_mask_4: 0.2854  loss_dice_4: 0.8867  loss_ce_5: 0  loss_mask_5: 0.2863  loss_dice_5: 0.8902  loss_ce_6: 0  loss_mask_6: 0.2847  loss_dice_6: 0.8938  loss_ce_7: 0  loss_mask_7: 0.2802  loss_dice_7: 0.8992  loss_ce_8: 0  loss_mask_8: 0.2613  loss_dice_8: 0.9171  time: 1.7762  data_time: 0.0725  lr: 9.9221e-05  max_mem: 5800M
[02/24 11:54:41] d2.utils.events INFO:  eta: 1 day, 4:42:20  iter: 539  total_loss: 23.85  loss_ce: 0  loss_mask: 0.2129  loss_dice: 0.9573  loss_seg: 12.12  loss_ce_0: 0  loss_mask_0: 0.2766  loss_dice_0: 0.9003  loss_ce_1: 0  loss_mask_1: 0.2844  loss_dice_1: 0.8884  loss_ce_2: 0  loss_mask_2: 0.2817  loss_dice_2: 0.889  loss_ce_3: 0  loss_mask_3: 0.2849  loss_dice_3: 0.8878  loss_ce_4: 0  loss_mask_4: 0.2829  loss_dice_4: 0.8894  loss_ce_5: 0  loss_mask_5: 0.2847  loss_dice_5: 0.8905  loss_ce_6: 0  loss_mask_6: 0.2823  loss_dice_6: 0.8961  loss_ce_7: 0  loss_mask_7: 0.2792  loss_dice_7: 0.8977  loss_ce_8: 0  loss_mask_8: 0.2637  loss_dice_8: 0.9202  time: 1.7713  data_time: 0.0461  lr: 9.9191e-05  max_mem: 5800M
[02/24 11:55:16] d2.utils.events INFO:  eta: 1 day, 4:41:18  iter: 559  total_loss: 24.87  loss_ce: 0  loss_mask: 0.2079  loss_dice: 0.956  loss_seg: 13.23  loss_ce_0: 0  loss_mask_0: 0.2666  loss_dice_0: 0.8982  loss_ce_1: 0  loss_mask_1: 0.2755  loss_dice_1: 0.8904  loss_ce_2: 0  loss_mask_2: 0.2759  loss_dice_2: 0.8905  loss_ce_3: 0  loss_mask_3: 0.2759  loss_dice_3: 0.8918  loss_ce_4: 0  loss_mask_4: 0.2766  loss_dice_4: 0.8916  loss_ce_5: 0  loss_mask_5: 0.2755  loss_dice_5: 0.8938  loss_ce_6: 0  loss_mask_6: 0.2751  loss_dice_6: 0.8956  loss_ce_7: 0  loss_mask_7: 0.272  loss_dice_7: 0.8972  loss_ce_8: 0  loss_mask_8: 0.2607  loss_dice_8: 0.9125  time: 1.7697  data_time: 0.0507  lr: 9.9161e-05  max_mem: 5800M
[02/24 11:55:51] d2.utils.events INFO:  eta: 1 day, 4:40:43  iter: 579  total_loss: 22.26  loss_ce: 0  loss_mask: 0.2135  loss_dice: 0.953  loss_seg: 10.77  loss_ce_0: 0  loss_mask_0: 0.2671  loss_dice_0: 0.8903  loss_ce_1: 0  loss_mask_1: 0.2758  loss_dice_1: 0.8773  loss_ce_2: 0  loss_mask_2: 0.2778  loss_dice_2: 0.8759  loss_ce_3: 0  loss_mask_3: 0.2776  loss_dice_3: 0.8793  loss_ce_4: 0  loss_mask_4: 0.2778  loss_dice_4: 0.8785  loss_ce_5: 0  loss_mask_5: 0.2819  loss_dice_5: 0.8772  loss_ce_6: 0  loss_mask_6: 0.2784  loss_dice_6: 0.8817  loss_ce_7: 0  loss_mask_7: 0.2782  loss_dice_7: 0.886  loss_ce_8: 0  loss_mask_8: 0.2661  loss_dice_8: 0.9068  time: 1.7691  data_time: 0.0626  lr: 9.9131e-05  max_mem: 5807M
[02/24 11:56:25] d2.utils.events INFO:  eta: 1 day, 4:38:55  iter: 599  total_loss: 22.62  loss_ce: 0  loss_mask: 0.209  loss_dice: 0.9532  loss_seg: 11.06  loss_ce_0: 0  loss_mask_0: 0.2687  loss_dice_0: 0.8936  loss_ce_1: 0  loss_mask_1: 0.2756  loss_dice_1: 0.8824  loss_ce_2: 0  loss_mask_2: 0.2795  loss_dice_2: 0.8818  loss_ce_3: 0  loss_mask_3: 0.2807  loss_dice_3: 0.8814  loss_ce_4: 0  loss_mask_4: 0.2796  loss_dice_4: 0.8812  loss_ce_5: 0  loss_mask_5: 0.2792  loss_dice_5: 0.8819  loss_ce_6: 0  loss_mask_6: 0.277  loss_dice_6: 0.8858  loss_ce_7: 0  loss_mask_7: 0.2729  loss_dice_7: 0.8921  loss_ce_8: 0  loss_mask_8: 0.2624  loss_dice_8: 0.9065  time: 1.7677  data_time: 0.0512  lr: 9.9101e-05  max_mem: 5807M
[02/24 11:57:00] d2.utils.events INFO:  eta: 1 day, 4:35:19  iter: 619  total_loss: 23.9  loss_ce: 0  loss_mask: 0.2197  loss_dice: 0.9569  loss_seg: 12.14  loss_ce_0: 0  loss_mask_0: 0.286  loss_dice_0: 0.8888  loss_ce_1: 0  loss_mask_1: 0.2885  loss_dice_1: 0.8826  loss_ce_2: 0  loss_mask_2: 0.2899  loss_dice_2: 0.8821  loss_ce_3: 0  loss_mask_3: 0.2888  loss_dice_3: 0.8821  loss_ce_4: 0  loss_mask_4: 0.29  loss_dice_4: 0.8812  loss_ce_5: 0  loss_mask_5: 0.2885  loss_dice_5: 0.8838  loss_ce_6: 0  loss_mask_6: 0.2871  loss_dice_6: 0.8846  loss_ce_7: 0  loss_mask_7: 0.2828  loss_dice_7: 0.8885  loss_ce_8: 0  loss_mask_8: 0.273  loss_dice_8: 0.9103  time: 1.7655  data_time: 0.0480  lr: 9.9071e-05  max_mem: 5807M
[02/24 11:57:35] d2.utils.events INFO:  eta: 1 day, 4:34:44  iter: 639  total_loss: 21.57  loss_ce: 0  loss_mask: 0.2134  loss_dice: 0.9549  loss_seg: 9.803  loss_ce_0: 0  loss_mask_0: 0.28  loss_dice_0: 0.8856  loss_ce_1: 0  loss_mask_1: 0.2939  loss_dice_1: 0.8747  loss_ce_2: 0  loss_mask_2: 0.2968  loss_dice_2: 0.8724  loss_ce_3: 0  loss_mask_3: 0.2958  loss_dice_3: 0.876  loss_ce_4: 0  loss_mask_4: 0.294  loss_dice_4: 0.8785  loss_ce_5: 0  loss_mask_5: 0.2911  loss_dice_5: 0.8796  loss_ce_6: 0  loss_mask_6: 0.2938  loss_dice_6: 0.8796  loss_ce_7: 0  loss_mask_7: 0.2903  loss_dice_7: 0.8847  loss_ce_8: 0  loss_mask_8: 0.2658  loss_dice_8: 0.9098  time: 1.7650  data_time: 0.0525  lr: 9.9041e-05  max_mem: 5807M
[02/24 11:58:09] d2.utils.events INFO:  eta: 1 day, 4:33:24  iter: 659  total_loss: 22.33  loss_ce: 0  loss_mask: 0.205  loss_dice: 0.9605  loss_seg: 10.74  loss_ce_0: 0  loss_mask_0: 0.271  loss_dice_0: 0.8911  loss_ce_1: 0  loss_mask_1: 0.2817  loss_dice_1: 0.8796  loss_ce_2: 0  loss_mask_2: 0.2841  loss_dice_2: 0.8786  loss_ce_3: 0  loss_mask_3: 0.2852  loss_dice_3: 0.8781  loss_ce_4: 0  loss_mask_4: 0.283  loss_dice_4: 0.8783  loss_ce_5: 0  loss_mask_5: 0.2843  loss_dice_5: 0.8797  loss_ce_6: 0  loss_mask_6: 0.2832  loss_dice_6: 0.8795  loss_ce_7: 0  loss_mask_7: 0.2778  loss_dice_7: 0.8817  loss_ce_8: 0  loss_mask_8: 0.2726  loss_dice_8: 0.9001  time: 1.7636  data_time: 0.0572  lr: 9.9011e-05  max_mem: 5807M
[02/24 11:58:45] d2.utils.events INFO:  eta: 1 day, 4:35:26  iter: 679  total_loss: 22.88  loss_ce: 0  loss_mask: 0.2294  loss_dice: 0.9494  loss_seg: 11.23  loss_ce_0: 0  loss_mask_0: 0.2845  loss_dice_0: 0.8865  loss_ce_1: 0  loss_mask_1: 0.2909  loss_dice_1: 0.8778  loss_ce_2: 0  loss_mask_2: 0.2931  loss_dice_2: 0.8761  loss_ce_3: 0  loss_mask_3: 0.2922  loss_dice_3: 0.8772  loss_ce_4: 0  loss_mask_4: 0.2928  loss_dice_4: 0.877  loss_ce_5: 0  loss_mask_5: 0.2891  loss_dice_5: 0.88  loss_ce_6: 0  loss_mask_6: 0.2894  loss_dice_6: 0.8809  loss_ce_7: 0  loss_mask_7: 0.292  loss_dice_7: 0.8802  loss_ce_8: 0  loss_mask_8: 0.2791  loss_dice_8: 0.8951  time: 1.7636  data_time: 0.0477  lr: 9.8981e-05  max_mem: 5807M
[02/24 11:59:19] d2.utils.events INFO:  eta: 1 day, 4:34:24  iter: 699  total_loss: 22.2  loss_ce: 0  loss_mask: 0.2208  loss_dice: 0.9515  loss_seg: 10.64  loss_ce_0: 0  loss_mask_0: 0.2806  loss_dice_0: 0.8786  loss_ce_1: 0  loss_mask_1: 0.2859  loss_dice_1: 0.8661  loss_ce_2: 0  loss_mask_2: 0.2852  loss_dice_2: 0.8667  loss_ce_3: 0  loss_mask_3: 0.2862  loss_dice_3: 0.8685  loss_ce_4: 0  loss_mask_4: 0.2867  loss_dice_4: 0.8676  loss_ce_5: 0  loss_mask_5: 0.2847  loss_dice_5: 0.8694  loss_ce_6: 0  loss_mask_6: 0.2855  loss_dice_6: 0.8708  loss_ce_7: 0  loss_mask_7: 0.2879  loss_dice_7: 0.8738  loss_ce_8: 0  loss_mask_8: 0.2748  loss_dice_8: 0.8911  time: 1.7622  data_time: 0.0503  lr: 9.8951e-05  max_mem: 5807M
[02/24 11:59:53] d2.utils.events INFO:  eta: 1 day, 4:30:56  iter: 719  total_loss: 20.56  loss_ce: 0  loss_mask: 0.223  loss_dice: 0.9491  loss_seg: 8.794  loss_ce_0: 0  loss_mask_0: 0.2838  loss_dice_0: 0.8803  loss_ce_1: 0  loss_mask_1: 0.2931  loss_dice_1: 0.8673  loss_ce_2: 0  loss_mask_2: 0.2949  loss_dice_2: 0.8645  loss_ce_3: 0  loss_mask_3: 0.2913  loss_dice_3: 0.8653  loss_ce_4: 0  loss_mask_4: 0.2915  loss_dice_4: 0.866  loss_ce_5: 0  loss_mask_5: 0.2927  loss_dice_5: 0.8649  loss_ce_6: 0  loss_mask_6: 0.294  loss_dice_6: 0.8676  loss_ce_7: 0  loss_mask_7: 0.2898  loss_dice_7: 0.8706  loss_ce_8: 0  loss_mask_8: 0.2871  loss_dice_8: 0.8881  time: 1.7594  data_time: 0.0512  lr: 9.8921e-05  max_mem: 5807M
[02/24 12:00:28] d2.utils.events INFO:  eta: 1 day, 4:29:16  iter: 739  total_loss: 21.43  loss_ce: 0  loss_mask: 0.222  loss_dice: 0.9479  loss_seg: 9.681  loss_ce_0: 0  loss_mask_0: 0.2803  loss_dice_0: 0.8771  loss_ce_1: 0  loss_mask_1: 0.2862  loss_dice_1: 0.8644  loss_ce_2: 0  loss_mask_2: 0.2884  loss_dice_2: 0.8657  loss_ce_3: 0  loss_mask_3: 0.2877  loss_dice_3: 0.8668  loss_ce_4: 0  loss_mask_4: 0.2884  loss_dice_4: 0.8674  loss_ce_5: 0  loss_mask_5: 0.2883  loss_dice_5: 0.8682  loss_ce_6: 0  loss_mask_6: 0.288  loss_dice_6: 0.87  loss_ce_7: 0  loss_mask_7: 0.2889  loss_dice_7: 0.875  loss_ce_8: 0  loss_mask_8: 0.2738  loss_dice_8: 0.8896  time: 1.7590  data_time: 0.0599  lr: 9.8891e-05  max_mem: 5807M
[02/24 12:01:02] d2.utils.events INFO:  eta: 1 day, 4:28:23  iter: 759  total_loss: 21.55  loss_ce: 0  loss_mask: 0.2118  loss_dice: 0.9522  loss_seg: 9.897  loss_ce_0: 0  loss_mask_0: 0.2712  loss_dice_0: 0.8913  loss_ce_1: 0  loss_mask_1: 0.2823  loss_dice_1: 0.8803  loss_ce_2: 0  loss_mask_2: 0.2847  loss_dice_2: 0.8802  loss_ce_3: 0  loss_mask_3: 0.2841  loss_dice_3: 0.8817  loss_ce_4: 0  loss_mask_4: 0.2853  loss_dice_4: 0.8811  loss_ce_5: 0  loss_mask_5: 0.2859  loss_dice_5: 0.8806  loss_ce_6: 0  loss_mask_6: 0.285  loss_dice_6: 0.882  loss_ce_7: 0  loss_mask_7: 0.2808  loss_dice_7: 0.8855  loss_ce_8: 0  loss_mask_8: 0.271  loss_dice_8: 0.8999  time: 1.7581  data_time: 0.0460  lr: 9.8861e-05  max_mem: 5807M
[02/24 12:01:37] d2.utils.events INFO:  eta: 1 day, 4:28:44  iter: 779  total_loss: 21.4  loss_ce: 0  loss_mask: 0.2103  loss_dice: 0.9515  loss_seg: 9.837  loss_ce_0: 0  loss_mask_0: 0.2817  loss_dice_0: 0.8806  loss_ce_1: 0  loss_mask_1: 0.2916  loss_dice_1: 0.8721  loss_ce_2: 0  loss_mask_2: 0.2916  loss_dice_2: 0.8688  loss_ce_3: 0  loss_mask_3: 0.2941  loss_dice_3: 0.867  loss_ce_4: 0  loss_mask_4: 0.2937  loss_dice_4: 0.8693  loss_ce_5: 0  loss_mask_5: 0.2929  loss_dice_5: 0.8698  loss_ce_6: 0  loss_mask_6: 0.2919  loss_dice_6: 0.8709  loss_ce_7: 0  loss_mask_7: 0.2907  loss_dice_7: 0.8775  loss_ce_8: 0  loss_mask_8: 0.2754  loss_dice_8: 0.8955  time: 1.7579  data_time: 0.0646  lr: 9.8831e-05  max_mem: 5807M
[02/24 12:02:12] d2.utils.events INFO:  eta: 1 day, 4:27:14  iter: 799  total_loss: 20.27  loss_ce: 0  loss_mask: 0.219  loss_dice: 0.9481  loss_seg: 8.724  loss_ce_0: 0  loss_mask_0: 0.2895  loss_dice_0: 0.8748  loss_ce_1: 0  loss_mask_1: 0.2982  loss_dice_1: 0.8566  loss_ce_2: 0  loss_mask_2: 0.2977  loss_dice_2: 0.8558  loss_ce_3: 0  loss_mask_3: 0.2964  loss_dice_3: 0.8567  loss_ce_4: 0  loss_mask_4: 0.2976  loss_dice_4: 0.8549  loss_ce_5: 0  loss_mask_5: 0.2988  loss_dice_5: 0.8538  loss_ce_6: 0  loss_mask_6: 0.2969  loss_dice_6: 0.857  loss_ce_7: 0  loss_mask_7: 0.2955  loss_dice_7: 0.8602  loss_ce_8: 0  loss_mask_8: 0.2842  loss_dice_8: 0.8836  time: 1.7565  data_time: 0.0527  lr: 9.8801e-05  max_mem: 5807M
[02/24 12:02:47] d2.utils.events INFO:  eta: 1 day, 4:26:57  iter: 819  total_loss: 21.56  loss_ce: 0  loss_mask: 0.2202  loss_dice: 0.9481  loss_seg: 9.778  loss_ce_0: 0  loss_mask_0: 0.2928  loss_dice_0: 0.8788  loss_ce_1: 0  loss_mask_1: 0.3005  loss_dice_1: 0.8648  loss_ce_2: 0  loss_mask_2: 0.2992  loss_dice_2: 0.8678  loss_ce_3: 0  loss_mask_3: 0.2947  loss_dice_3: 0.8695  loss_ce_4: 0  loss_mask_4: 0.294  loss_dice_4: 0.8714  loss_ce_5: 0  loss_mask_5: 0.2945  loss_dice_5: 0.8722  loss_ce_6: 0  loss_mask_6: 0.3002  loss_dice_6: 0.8739  loss_ce_7: 0  loss_mask_7: 0.299  loss_dice_7: 0.8754  loss_ce_8: 0  loss_mask_8: 0.2831  loss_dice_8: 0.8958  time: 1.7565  data_time: 0.0489  lr: 9.8771e-05  max_mem: 5807M
[02/24 12:03:22] d2.utils.events INFO:  eta: 1 day, 4:27:44  iter: 839  total_loss: 21.46  loss_ce: 0  loss_mask: 0.2062  loss_dice: 0.9512  loss_seg: 9.889  loss_ce_0: 0  loss_mask_0: 0.2773  loss_dice_0: 0.8766  loss_ce_1: 0  loss_mask_1: 0.2875  loss_dice_1: 0.8624  loss_ce_2: 0  loss_mask_2: 0.2884  loss_dice_2: 0.863  loss_ce_3: 0  loss_mask_3: 0.2881  loss_dice_3: 0.8657  loss_ce_4: 0  loss_mask_4: 0.2871  loss_dice_4: 0.8676  loss_ce_5: 0  loss_mask_5: 0.2867  loss_dice_5: 0.8731  loss_ce_6: 0  loss_mask_6: 0.2841  loss_dice_6: 0.8777  loss_ce_7: 0  loss_mask_7: 0.2769  loss_dice_7: 0.8787  loss_ce_8: 0  loss_mask_8: 0.2629  loss_dice_8: 0.8939  time: 1.7565  data_time: 0.0491  lr: 9.8741e-05  max_mem: 5807M
[02/24 12:03:58] d2.utils.events INFO:  eta: 1 day, 4:27:38  iter: 859  total_loss: 21.14  loss_ce: 0  loss_mask: 0.2181  loss_dice: 0.9535  loss_seg: 9.54  loss_ce_0: 0  loss_mask_0: 0.2819  loss_dice_0: 0.8759  loss_ce_1: 0  loss_mask_1: 0.2924  loss_dice_1: 0.8624  loss_ce_2: 0  loss_mask_2: 0.2906  loss_dice_2: 0.8641  loss_ce_3: 0  loss_mask_3: 0.2901  loss_dice_3: 0.8649  loss_ce_4: 0  loss_mask_4: 0.2887  loss_dice_4: 0.8669  loss_ce_5: 0  loss_mask_5: 0.2897  loss_dice_5: 0.8673  loss_ce_6: 0  loss_mask_6: 0.2874  loss_dice_6: 0.8699  loss_ce_7: 0  loss_mask_7: 0.283  loss_dice_7: 0.8728  loss_ce_8: 0  loss_mask_8: 0.2793  loss_dice_8: 0.8898  time: 1.7566  data_time: 0.0554  lr: 9.8711e-05  max_mem: 5807M
[02/24 12:04:33] d2.utils.events INFO:  eta: 1 day, 4:26:35  iter: 879  total_loss: 19.82  loss_ce: 0  loss_mask: 0.2196  loss_dice: 0.9484  loss_seg: 8.373  loss_ce_0: 0  loss_mask_0: 0.2811  loss_dice_0: 0.8733  loss_ce_1: 0  loss_mask_1: 0.2848  loss_dice_1: 0.8563  loss_ce_2: 0  loss_mask_2: 0.2879  loss_dice_2: 0.8564  loss_ce_3: 0  loss_mask_3: 0.29  loss_dice_3: 0.8574  loss_ce_4: 0  loss_mask_4: 0.291  loss_dice_4: 0.8602  loss_ce_5: 0  loss_mask_5: 0.2901  loss_dice_5: 0.8636  loss_ce_6: 0  loss_mask_6: 0.2888  loss_dice_6: 0.8615  loss_ce_7: 0  loss_mask_7: 0.2888  loss_dice_7: 0.8629  loss_ce_8: 0  loss_mask_8: 0.2792  loss_dice_8: 0.8829  time: 1.7564  data_time: 0.0729  lr: 9.8681e-05  max_mem: 5807M
[02/24 12:05:08] d2.utils.events INFO:  eta: 1 day, 4:26:10  iter: 899  total_loss: 20.15  loss_ce: 0  loss_mask: 0.2057  loss_dice: 0.9536  loss_seg: 8.799  loss_ce_0: 0  loss_mask_0: 0.275  loss_dice_0: 0.8737  loss_ce_1: 0  loss_mask_1: 0.2856  loss_dice_1: 0.8571  loss_ce_2: 0  loss_mask_2: 0.2824  loss_dice_2: 0.855  loss_ce_3: 0  loss_mask_3: 0.2826  loss_dice_3: 0.855  loss_ce_4: 0  loss_mask_4: 0.2839  loss_dice_4: 0.8543  loss_ce_5: 0  loss_mask_5: 0.2851  loss_dice_5: 0.8562  loss_ce_6: 0  loss_mask_6: 0.2827  loss_dice_6: 0.8601  loss_ce_7: 0  loss_mask_7: 0.2847  loss_dice_7: 0.8604  loss_ce_8: 0  loss_mask_8: 0.2768  loss_dice_8: 0.874  time: 1.7564  data_time: 0.0421  lr: 9.865e-05  max_mem: 5807M
[02/24 12:05:42] d2.utils.events INFO:  eta: 1 day, 4:25:25  iter: 919  total_loss: 21.77  loss_ce: 0  loss_mask: 0.2164  loss_dice: 0.9478  loss_seg: 10.15  loss_ce_0: 0  loss_mask_0: 0.2944  loss_dice_0: 0.8658  loss_ce_1: 0  loss_mask_1: 0.2957  loss_dice_1: 0.8507  loss_ce_2: 0  loss_mask_2: 0.2986  loss_dice_2: 0.8502  loss_ce_3: 0  loss_mask_3: 0.2999  loss_dice_3: 0.8515  loss_ce_4: 0  loss_mask_4: 0.2986  loss_dice_4: 0.8528  loss_ce_5: 0  loss_mask_5: 0.3001  loss_dice_5: 0.8534  loss_ce_6: 0  loss_mask_6: 0.3013  loss_dice_6: 0.8568  loss_ce_7: 0  loss_mask_7: 0.299  loss_dice_7: 0.8592  loss_ce_8: 0  loss_mask_8: 0.2928  loss_dice_8: 0.8719  time: 1.7554  data_time: 0.0585  lr: 9.862e-05  max_mem: 5807M
[02/24 12:06:17] d2.utils.events INFO:  eta: 1 day, 4:25:01  iter: 939  total_loss: 19.57  loss_ce: 0  loss_mask: 0.2151  loss_dice: 0.9424  loss_seg: 8.027  loss_ce_0: 0  loss_mask_0: 0.2945  loss_dice_0: 0.8648  loss_ce_1: 0  loss_mask_1: 0.3013  loss_dice_1: 0.8527  loss_ce_2: 0  loss_mask_2: 0.301  loss_dice_2: 0.851  loss_ce_3: 0  loss_mask_3: 0.3003  loss_dice_3: 0.8487  loss_ce_4: 0  loss_mask_4: 0.3007  loss_dice_4: 0.851  loss_ce_5: 0  loss_mask_5: 0.3026  loss_dice_5: 0.8511  loss_ce_6: 0  loss_mask_6: 0.3011  loss_dice_6: 0.8521  loss_ce_7: 0  loss_mask_7: 0.3013  loss_dice_7: 0.8539  loss_ce_8: 0  loss_mask_8: 0.2956  loss_dice_8: 0.8659  time: 1.7550  data_time: 0.0445  lr: 9.859e-05  max_mem: 5807M
[02/24 12:06:52] d2.utils.events INFO:  eta: 1 day, 4:24:16  iter: 959  total_loss: 20.29  loss_ce: 0  loss_mask: 0.2228  loss_dice: 0.94  loss_seg: 8.793  loss_ce_0: 0  loss_mask_0: 0.3031  loss_dice_0: 0.8578  loss_ce_1: 0  loss_mask_1: 0.3127  loss_dice_1: 0.8448  loss_ce_2: 0  loss_mask_2: 0.3117  loss_dice_2: 0.8467  loss_ce_3: 0  loss_mask_3: 0.3094  loss_dice_3: 0.8476  loss_ce_4: 0  loss_mask_4: 0.3124  loss_dice_4: 0.8446  loss_ce_5: 0  loss_mask_5: 0.3097  loss_dice_5: 0.848  loss_ce_6: 0  loss_mask_6: 0.3086  loss_dice_6: 0.8494  loss_ce_7: 0  loss_mask_7: 0.3085  loss_dice_7: 0.8529  loss_ce_8: 0  loss_mask_8: 0.3061  loss_dice_8: 0.8644  time: 1.7543  data_time: 0.0499  lr: 9.856e-05  max_mem: 5807M
[02/24 12:07:26] d2.utils.events INFO:  eta: 1 day, 4:22:20  iter: 979  total_loss: 19.71  loss_ce: 0  loss_mask: 0.2238  loss_dice: 0.9403  loss_seg: 8.146  loss_ce_0: 0  loss_mask_0: 0.2935  loss_dice_0: 0.8609  loss_ce_1: 0  loss_mask_1: 0.3018  loss_dice_1: 0.846  loss_ce_2: 0  loss_mask_2: 0.302  loss_dice_2: 0.8461  loss_ce_3: 0  loss_mask_3: 0.302  loss_dice_3: 0.8469  loss_ce_4: 0  loss_mask_4: 0.3023  loss_dice_4: 0.8492  loss_ce_5: 0  loss_mask_5: 0.3009  loss_dice_5: 0.8514  loss_ce_6: 0  loss_mask_6: 0.299  loss_dice_6: 0.853  loss_ce_7: 0  loss_mask_7: 0.2982  loss_dice_7: 0.8538  loss_ce_8: 0  loss_mask_8: 0.2932  loss_dice_8: 0.8722  time: 1.7533  data_time: 0.0466  lr: 9.853e-05  max_mem: 5807M
[02/24 12:08:00] d2.utils.events INFO:  eta: 1 day, 4:21:27  iter: 999  total_loss: 20.43  loss_ce: 0  loss_mask: 0.2068  loss_dice: 0.9489  loss_seg: 8.992  loss_ce_0: 0  loss_mask_0: 0.2868  loss_dice_0: 0.8734  loss_ce_1: 0  loss_mask_1: 0.2936  loss_dice_1: 0.8623  loss_ce_2: 0  loss_mask_2: 0.2948  loss_dice_2: 0.8618  loss_ce_3: 0  loss_mask_3: 0.2946  loss_dice_3: 0.8628  loss_ce_4: 0  loss_mask_4: 0.2942  loss_dice_4: 0.8639  loss_ce_5: 0  loss_mask_5: 0.2939  loss_dice_5: 0.8636  loss_ce_6: 0  loss_mask_6: 0.2947  loss_dice_6: 0.8645  loss_ce_7: 0  loss_mask_7: 0.2952  loss_dice_7: 0.8642  loss_ce_8: 0  loss_mask_8: 0.2852  loss_dice_8: 0.8807  time: 1.7522  data_time: 0.0563  lr: 9.85e-05  max_mem: 5807M
[02/24 12:08:35] d2.utils.events INFO:  eta: 1 day, 4:19:16  iter: 1019  total_loss: 19.29  loss_ce: 0  loss_mask: 0.2215  loss_dice: 0.943  loss_seg: 7.858  loss_ce_0: 0  loss_mask_0: 0.2894  loss_dice_0: 0.8602  loss_ce_1: 0  loss_mask_1: 0.2965  loss_dice_1: 0.8465  loss_ce_2: 0  loss_mask_2: 0.2969  loss_dice_2: 0.8445  loss_ce_3: 0  loss_mask_3: 0.298  loss_dice_3: 0.8473  loss_ce_4: 0  loss_mask_4: 0.2958  loss_dice_4: 0.8458  loss_ce_5: 0  loss_mask_5: 0.2929  loss_dice_5: 0.8467  loss_ce_6: 0  loss_mask_6: 0.2919  loss_dice_6: 0.8489  loss_ce_7: 0  loss_mask_7: 0.2915  loss_dice_7: 0.8508  loss_ce_8: 0  loss_mask_8: 0.2859  loss_dice_8: 0.8651  time: 1.7523  data_time: 0.0583  lr: 9.847e-05  max_mem: 5807M
[02/24 12:09:10] d2.utils.events INFO:  eta: 1 day, 4:16:43  iter: 1039  total_loss: 19.16  loss_ce: 0  loss_mask: 0.2126  loss_dice: 0.9436  loss_seg: 7.697  loss_ce_0: 0  loss_mask_0: 0.2833  loss_dice_0: 0.8609  loss_ce_1: 0  loss_mask_1: 0.2932  loss_dice_1: 0.8429  loss_ce_2: 0  loss_mask_2: 0.2936  loss_dice_2: 0.8413  loss_ce_3: 0  loss_mask_3: 0.294  loss_dice_3: 0.8405  loss_ce_4: 0  loss_mask_4: 0.2919  loss_dice_4: 0.8419  loss_ce_5: 0  loss_mask_5: 0.2941  loss_dice_5: 0.8431  loss_ce_6: 0  loss_mask_6: 0.2949  loss_dice_6: 0.8444  loss_ce_7: 0  loss_mask_7: 0.291  loss_dice_7: 0.8487  loss_ce_8: 0  loss_mask_8: 0.2882  loss_dice_8: 0.8669  time: 1.7518  data_time: 0.0601  lr: 9.844e-05  max_mem: 5807M
[02/24 12:09:44] d2.utils.events INFO:  eta: 1 day, 4:13:44  iter: 1059  total_loss: 19.49  loss_ce: 0  loss_mask: 0.2128  loss_dice: 0.9396  loss_seg: 8.059  loss_ce_0: 0  loss_mask_0: 0.2948  loss_dice_0: 0.8603  loss_ce_1: 0  loss_mask_1: 0.3035  loss_dice_1: 0.8439  loss_ce_2: 0  loss_mask_2: 0.3039  loss_dice_2: 0.8421  loss_ce_3: 0  loss_mask_3: 0.3037  loss_dice_3: 0.8447  loss_ce_4: 0  loss_mask_4: 0.3018  loss_dice_4: 0.8431  loss_ce_5: 0  loss_mask_5: 0.3029  loss_dice_5: 0.8447  loss_ce_6: 0  loss_mask_6: 0.3022  loss_dice_6: 0.8452  loss_ce_7: 0  loss_mask_7: 0.3017  loss_dice_7: 0.8463  loss_ce_8: 0  loss_mask_8: 0.2972  loss_dice_8: 0.8528  time: 1.7505  data_time: 0.0512  lr: 9.841e-05  max_mem: 5807M
[02/24 12:10:19] d2.utils.events INFO:  eta: 1 day, 4:13:21  iter: 1079  total_loss: 18.97  loss_ce: 0  loss_mask: 0.2208  loss_dice: 0.9399  loss_seg: 7.519  loss_ce_0: 0  loss_mask_0: 0.297  loss_dice_0: 0.858  loss_ce_1: 0  loss_mask_1: 0.3064  loss_dice_1: 0.8479  loss_ce_2: 0  loss_mask_2: 0.3055  loss_dice_2: 0.8472  loss_ce_3: 0  loss_mask_3: 0.3058  loss_dice_3: 0.8475  loss_ce_4: 0  loss_mask_4: 0.3066  loss_dice_4: 0.8491  loss_ce_5: 0  loss_mask_5: 0.3053  loss_dice_5: 0.8517  loss_ce_6: 0  loss_mask_6: 0.3033  loss_dice_6: 0.853  loss_ce_7: 0  loss_mask_7: 0.3041  loss_dice_7: 0.8526  loss_ce_8: 0  loss_mask_8: 0.2927  loss_dice_8: 0.8688  time: 1.7507  data_time: 0.0512  lr: 9.838e-05  max_mem: 5807M
[02/24 12:10:54] d2.utils.events INFO:  eta: 1 day, 4:14:25  iter: 1099  total_loss: 19.73  loss_ce: 0  loss_mask: 0.2093  loss_dice: 0.9435  loss_seg: 8.351  loss_ce_0: 0  loss_mask_0: 0.2949  loss_dice_0: 0.8587  loss_ce_1: 0  loss_mask_1: 0.2959  loss_dice_1: 0.849  loss_ce_2: 0  loss_mask_2: 0.2966  loss_dice_2: 0.8476  loss_ce_3: 0  loss_mask_3: 0.2977  loss_dice_3: 0.8508  loss_ce_4: 0  loss_mask_4: 0.2991  loss_dice_4: 0.849  loss_ce_5: 0  loss_mask_5: 0.2995  loss_dice_5: 0.8506  loss_ce_6: 0  loss_mask_6: 0.299  loss_dice_6: 0.853  loss_ce_7: 0  loss_mask_7: 0.2984  loss_dice_7: 0.854  loss_ce_8: 0  loss_mask_8: 0.2898  loss_dice_8: 0.8665  time: 1.7507  data_time: 0.0545  lr: 9.835e-05  max_mem: 5807M
[02/24 12:10:58] d2.engine.hooks INFO: Overall training speed: 1100 iterations in 0:32:06 (1.7513 s / it)
[02/24 12:10:58] d2.engine.hooks INFO: Total training time: 0:32:14 (0:00:08 on hooks)
[02/24 12:10:58] d2.utils.events INFO:  eta: 1 day, 4:14:44  iter: 1102  total_loss: 20.67  loss_ce: 0  loss_mask: 0.2093  loss_dice: 0.9441  loss_seg: 8.986  loss_ce_0: 0  loss_mask_0: 0.2964  loss_dice_0: 0.8577  loss_ce_1: 0  loss_mask_1: 0.2987  loss_dice_1: 0.8457  loss_ce_2: 0  loss_mask_2: 0.2986  loss_dice_2: 0.845  loss_ce_3: 0  loss_mask_3: 0.2995  loss_dice_3: 0.8475  loss_ce_4: 0  loss_mask_4: 0.3018  loss_dice_4: 0.8468  loss_ce_5: 0  loss_mask_5: 0.3019  loss_dice_5: 0.8472  loss_ce_6: 0  loss_mask_6: 0.3022  loss_dice_6: 0.8503  loss_ce_7: 0  loss_mask_7: 0.3012  loss_dice_7: 0.8523  loss_ce_8: 0  loss_mask_8: 0.2918  loss_dice_8: 0.8682  time: 1.7505  data_time: 0.0524  lr: 9.8347e-05  max_mem: 5807M
[02/24 12:12:19] detectron2 INFO: Rank of current process: 0. World size: 4
[02/24 12:12:25] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/24 12:12:25] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[02/24 12:12:25] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m  [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m[38;5;15m [39m[38;5;242m#"/home/nstarli/Mask2Former/work_dirs/r101_48classes_fixedmatching/model_final.pth"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[02/24 12:12:25] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSEG_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/r101_48classes_fixedmatching_finesmoothl1_refinelayerdeltas_noauxsegloss[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2500[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[02/24 12:12:25] detectron2 INFO: Full config saved to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_refinelayerdeltas_noauxsegloss/config.yaml
[02/24 12:12:25] d2.utils.env INFO: Using a generated random seed 25782470
[02/24 12:12:31] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(48, 256)
      (query_embed): Embedding(48, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=49, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (refinement_layer): DispRefineLayer(
    (conv2d_feature): Conv2d(
      257, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (residual_atrous_blocks): ModuleList(
      (0): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2)
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (2): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(4, 4)
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (3): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(8, 8)
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (4): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (5): BasicBlock(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (conv2d_out): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher FixedMatcher
      losses: ['labels', 'masks', 'segs']
      weight_dict: {'loss_mask': 1.0, 'loss_ce': 0.0, 'loss_dice': 1.0, 'loss_seg': 0.1, 'loss_mask_0': 1.0, 'loss_ce_0': 0.0, 'loss_dice_0': 1.0, 'loss_mask_1': 1.0, 'loss_ce_1': 0.0, 'loss_dice_1': 1.0, 'loss_mask_2': 1.0, 'loss_ce_2': 0.0, 'loss_dice_2': 1.0, 'loss_mask_3': 1.0, 'loss_ce_3': 0.0, 'loss_dice_3': 1.0, 'loss_mask_4': 1.0, 'loss_ce_4': 0.0, 'loss_dice_4': 1.0, 'loss_mask_5': 1.0, 'loss_ce_5': 0.0, 'loss_dice_5': 1.0, 'loss_mask_6': 1.0, 'loss_ce_6': 0.0, 'loss_dice_6': 1.0, 'loss_mask_7': 1.0, 'loss_ce_7': 0.0, 'loss_dice_7': 1.0, 'loss_mask_8': 1.0, 'loss_ce_8': 0.0, 'loss_dice_8': 1.0}
      num_classes: 48
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[02/24 12:12:32] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[02/24 12:12:42] d2.data.build INFO: Using training sampler TrainingSampler
[02/24 12:12:44] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[02/24 12:12:53] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[02/24 12:12:53] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[02/24 12:12:53] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[02/24 12:12:53] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[02/24 12:12:54] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34mrefinement_layer.conv2d_feature.norm.{bias, weight}[0m
[34mrefinement_layer.conv2d_feature.{bias, weight}[0m
[34mrefinement_layer.conv2d_out.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.0.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.0.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.1.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.1.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.2.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.2.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.3.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.3.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.4.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.4.conv1.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.5.conv1.norm.{bias, weight}[0m
[34mrefinement_layer.residual_atrous_blocks.5.conv1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[02/24 12:12:54] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[02/24 12:12:54] d2.engine.train_loop INFO: Starting training from iteration 0
[02/24 12:14:05] d2.utils.events INFO:  eta: 1 day, 17:42:01  iter: 19  total_loss: 15.15  loss_ce: 0  loss_mask: 0.227  loss_dice: 0.9572  loss_seg: 3.382  loss_ce_0: 0  loss_mask_0: 0.222  loss_dice_0: 0.9576  loss_ce_1: 0  loss_mask_1: 0.2228  loss_dice_1: 0.9553  loss_ce_2: 0  loss_mask_2: 0.2229  loss_dice_2: 0.9567  loss_ce_3: 0  loss_mask_3: 0.2293  loss_dice_3: 0.9545  loss_ce_4: 0  loss_mask_4: 0.2387  loss_dice_4: 0.9549  loss_ce_5: 0  loss_mask_5: 0.2416  loss_dice_5: 0.9522  loss_ce_6: 0  loss_mask_6: 0.2407  loss_dice_6: 0.9562  loss_ce_7: 0  loss_mask_7: 0.2338  loss_dice_7: 0.9551  loss_ce_8: 0  loss_mask_8: 0.2356  loss_dice_8: 0.9561  time: 2.5553  data_time: 0.8126  lr: 9.9971e-05  max_mem: 5735M
[02/24 12:14:46] d2.utils.events INFO:  eta: 1 day, 15:52:34  iter: 39  total_loss: 14.35  loss_ce: 0  loss_mask: 0.2002  loss_dice: 0.9619  loss_seg: 2.755  loss_ce_0: 0  loss_mask_0: 0.2054  loss_dice_0: 0.9543  loss_ce_1: 0  loss_mask_1: 0.2024  loss_dice_1: 0.9551  loss_ce_2: 0  loss_mask_2: 0.2035  loss_dice_2: 0.9569  loss_ce_3: 0  loss_mask_3: 0.201  loss_dice_3: 0.9593  loss_ce_4: 0  loss_mask_4: 0.2009  loss_dice_4: 0.9604  loss_ce_5: 0  loss_mask_5: 0.2011  loss_dice_5: 0.9605  loss_ce_6: 0  loss_mask_6: 0.2003  loss_dice_6: 0.9604  loss_ce_7: 0  loss_mask_7: 0.2007  loss_dice_7: 0.9601  loss_ce_8: 0  loss_mask_8: 0.199  loss_dice_8: 0.9606  time: 2.2866  data_time: 0.0641  lr: 9.9941e-05  max_mem: 5761M
[02/24 12:15:20] d2.utils.events INFO:  eta: 1 day, 8:05:36  iter: 59  total_loss: 14.03  loss_ce: 0  loss_mask: 0.211  loss_dice: 0.9593  loss_seg: 2.345  loss_ce_0: 0  loss_mask_0: 0.2189  loss_dice_0: 0.9447  loss_ce_1: 0  loss_mask_1: 0.2327  loss_dice_1: 0.9402  loss_ce_2: 0  loss_mask_2: 0.2197  loss_dice_2: 0.9492  loss_ce_3: 0  loss_mask_3: 0.2188  loss_dice_3: 0.951  loss_ce_4: 0  loss_mask_4: 0.2142  loss_dice_4: 0.9549  loss_ce_5: 0  loss_mask_5: 0.2124  loss_dice_5: 0.9573  loss_ce_6: 0  loss_mask_6: 0.2094  loss_dice_6: 0.958  loss_ce_7: 0  loss_mask_7: 0.2099  loss_dice_7: 0.9578  loss_ce_8: 0  loss_mask_8: 0.2083  loss_dice_8: 0.9589  time: 2.0747  data_time: 0.0512  lr: 9.9911e-05  max_mem: 5761M
[02/24 12:15:53] d2.utils.events INFO:  eta: 1 day, 5:41:38  iter: 79  total_loss: 13.75  loss_ce: 0  loss_mask: 0.2084  loss_dice: 0.9555  loss_seg: 1.998  loss_ce_0: 0  loss_mask_0: 0.2332  loss_dice_0: 0.9377  loss_ce_1: 0  loss_mask_1: 0.2435  loss_dice_1: 0.9334  loss_ce_2: 0  loss_mask_2: 0.2464  loss_dice_2: 0.9345  loss_ce_3: 0  loss_mask_3: 0.2326  loss_dice_3: 0.9411  loss_ce_4: 0  loss_mask_4: 0.2303  loss_dice_4: 0.9461  loss_ce_5: 0  loss_mask_5: 0.2162  loss_dice_5: 0.9501  loss_ce_6: 0  loss_mask_6: 0.2105  loss_dice_6: 0.9539  loss_ce_7: 0  loss_mask_7: 0.2056  loss_dice_7: 0.9568  loss_ce_8: 0  loss_mask_8: 0.2045  loss_dice_8: 0.9579  time: 1.9632  data_time: 0.0572  lr: 9.9881e-05  max_mem: 5761M
[02/24 12:16:27] d2.utils.events INFO:  eta: 1 day, 5:01:05  iter: 99  total_loss: 13.64  loss_ce: 0  loss_mask: 0.2109  loss_dice: 0.9554  loss_seg: 1.953  loss_ce_0: 0  loss_mask_0: 0.2378  loss_dice_0: 0.932  loss_ce_1: 0  loss_mask_1: 0.2467  loss_dice_1: 0.932  loss_ce_2: 0  loss_mask_2: 0.2479  loss_dice_2: 0.932  loss_ce_3: 0  loss_mask_3: 0.2383  loss_dice_3: 0.9337  loss_ce_4: 0  loss_mask_4: 0.2393  loss_dice_4: 0.9391  loss_ce_5: 0  loss_mask_5: 0.2218  loss_dice_5: 0.9433  loss_ce_6: 0  loss_mask_6: 0.2096  loss_dice_6: 0.9493  loss_ce_7: 0  loss_mask_7: 0.2043  loss_dice_7: 0.9538  loss_ce_8: 0  loss_mask_8: 0.2029  loss_dice_8: 0.9569  time: 1.9042  data_time: 0.0514  lr: 9.9851e-05  max_mem: 5761M
[02/24 12:17:00] d2.utils.events INFO:  eta: 1 day, 4:33:47  iter: 119  total_loss: 13.51  loss_ce: 0  loss_mask: 0.2033  loss_dice: 0.9595  loss_seg: 1.766  loss_ce_0: 0  loss_mask_0: 0.2319  loss_dice_0: 0.9296  loss_ce_1: 0  loss_mask_1: 0.2438  loss_dice_1: 0.9213  loss_ce_2: 0  loss_mask_2: 0.2409  loss_dice_2: 0.9239  loss_ce_3: 0  loss_mask_3: 0.2424  loss_dice_3: 0.9262  loss_ce_4: 0  loss_mask_4: 0.2388  loss_dice_4: 0.929  loss_ce_5: 0  loss_mask_5: 0.234  loss_dice_5: 0.933  loss_ce_6: 0  loss_mask_6: 0.2299  loss_dice_6: 0.9371  loss_ce_7: 0  loss_mask_7: 0.2204  loss_dice_7: 0.9404  loss_ce_8: 0  loss_mask_8: 0.2098  loss_dice_8: 0.9484  time: 1.8633  data_time: 0.0577  lr: 9.9821e-05  max_mem: 5761M
[02/24 12:17:34] d2.utils.events INFO:  eta: 1 day, 4:23:21  iter: 139  total_loss: 13.34  loss_ce: 0  loss_mask: 0.2178  loss_dice: 0.9466  loss_seg: 1.727  loss_ce_0: 0  loss_mask_0: 0.2518  loss_dice_0: 0.9213  loss_ce_1: 0  loss_mask_1: 0.2593  loss_dice_1: 0.9179  loss_ce_2: 0  loss_mask_2: 0.2588  loss_dice_2: 0.9164  loss_ce_3: 0  loss_mask_3: 0.2566  loss_dice_3: 0.9162  loss_ce_4: 0  loss_mask_4: 0.2555  loss_dice_4: 0.9182  loss_ce_5: 0  loss_mask_5: 0.2554  loss_dice_5: 0.9216  loss_ce_6: 0  loss_mask_6: 0.253  loss_dice_6: 0.9227  loss_ce_7: 0  loss_mask_7: 0.2436  loss_dice_7: 0.9295  loss_ce_8: 0  loss_mask_8: 0.2231  loss_dice_8: 0.9383  time: 1.8377  data_time: 0.0637  lr: 9.9791e-05  max_mem: 5761M
[02/24 12:18:09] d2.utils.events INFO:  eta: 1 day, 4:32:38  iter: 159  total_loss: 13.2  loss_ce: 0  loss_mask: 0.2142  loss_dice: 0.9476  loss_seg: 1.466  loss_ce_0: 0  loss_mask_0: 0.2552  loss_dice_0: 0.9151  loss_ce_1: 0  loss_mask_1: 0.2651  loss_dice_1: 0.9071  loss_ce_2: 0  loss_mask_2: 0.2644  loss_dice_2: 0.9089  loss_ce_3: 0  loss_mask_3: 0.2655  loss_dice_3: 0.9097  loss_ce_4: 0  loss_mask_4: 0.2616  loss_dice_4: 0.9146  loss_ce_5: 0  loss_mask_5: 0.2575  loss_dice_5: 0.9135  loss_ce_6: 0  loss_mask_6: 0.2548  loss_dice_6: 0.9158  loss_ce_7: 0  loss_mask_7: 0.2556  loss_dice_7: 0.9189  loss_ce_8: 0  loss_mask_8: 0.2455  loss_dice_8: 0.9285  time: 1.8238  data_time: 0.0611  lr: 9.9761e-05  max_mem: 5761M
[02/24 12:18:41] d2.utils.events INFO:  eta: 1 day, 4:10:55  iter: 179  total_loss: 13.04  loss_ce: 0  loss_mask: 0.2173  loss_dice: 0.9421  loss_seg: 1.442  loss_ce_0: 0  loss_mask_0: 0.2512  loss_dice_0: 0.9077  loss_ce_1: 0  loss_mask_1: 0.2603  loss_dice_1: 0.9022  loss_ce_2: 0  loss_mask_2: 0.2622  loss_dice_2: 0.9047  loss_ce_3: 0  loss_mask_3: 0.2592  loss_dice_3: 0.9083  loss_ce_4: 0  loss_mask_4: 0.2575  loss_dice_4: 0.9073  loss_ce_5: 0  loss_mask_5: 0.2563  loss_dice_5: 0.9135  loss_ce_6: 0  loss_mask_6: 0.2576  loss_dice_6: 0.9157  loss_ce_7: 0  loss_mask_7: 0.2508  loss_dice_7: 0.919  loss_ce_8: 0  loss_mask_8: 0.2428  loss_dice_8: 0.922  time: 1.8024  data_time: 0.0504  lr: 9.9731e-05  max_mem: 5817M
[02/24 12:19:16] d2.utils.events INFO:  eta: 1 day, 4:11:52  iter: 199  total_loss: 13.15  loss_ce: 0  loss_mask: 0.2206  loss_dice: 0.9403  loss_seg: 1.463  loss_ce_0: 0  loss_mask_0: 0.2651  loss_dice_0: 0.9073  loss_ce_1: 0  loss_mask_1: 0.2729  loss_dice_1: 0.9022  loss_ce_2: 0  loss_mask_2: 0.2761  loss_dice_2: 0.9015  loss_ce_3: 0  loss_mask_3: 0.2773  loss_dice_3: 0.9011  loss_ce_4: 0  loss_mask_4: 0.2738  loss_dice_4: 0.9011  loss_ce_5: 0  loss_mask_5: 0.272  loss_dice_5: 0.9026  loss_ce_6: 0  loss_mask_6: 0.2715  loss_dice_6: 0.9064  loss_ce_7: 0  loss_mask_7: 0.269  loss_dice_7: 0.9072  loss_ce_8: 0  loss_mask_8: 0.2591  loss_dice_8: 0.915  time: 1.7940  data_time: 0.0553  lr: 9.9701e-05  max_mem: 5817M
[02/24 12:19:50] d2.utils.events INFO:  eta: 1 day, 4:20:57  iter: 219  total_loss: 13.13  loss_ce: 0  loss_mask: 0.2268  loss_dice: 0.9351  loss_seg: 1.507  loss_ce_0: 0  loss_mask_0: 0.268  loss_dice_0: 0.8986  loss_ce_1: 0  loss_mask_1: 0.275  loss_dice_1: 0.891  loss_ce_2: 0  loss_mask_2: 0.2782  loss_dice_2: 0.8929  loss_ce_3: 0  loss_mask_3: 0.2794  loss_dice_3: 0.893  loss_ce_4: 0  loss_mask_4: 0.2758  loss_dice_4: 0.8945  loss_ce_5: 0  loss_mask_5: 0.2739  loss_dice_5: 0.8984  loss_ce_6: 0  loss_mask_6: 0.2683  loss_dice_6: 0.8982  loss_ce_7: 0  loss_mask_7: 0.2683  loss_dice_7: 0.8992  loss_ce_8: 0  loss_mask_8: 0.261  loss_dice_8: 0.9067  time: 1.7876  data_time: 0.0655  lr: 9.9671e-05  max_mem: 5817M
[02/24 12:20:24] d2.utils.events INFO:  eta: 1 day, 4:14:37  iter: 239  total_loss: 13.09  loss_ce: 0  loss_mask: 0.223  loss_dice: 0.9361  loss_seg: 1.379  loss_ce_0: 0  loss_mask_0: 0.2594  loss_dice_0: 0.9047  loss_ce_1: 0  loss_mask_1: 0.2686  loss_dice_1: 0.8975  loss_ce_2: 0  loss_mask_2: 0.2708  loss_dice_2: 0.8972  loss_ce_3: 0  loss_mask_3: 0.2667  loss_dice_3: 0.8984  loss_ce_4: 0  loss_mask_4: 0.2663  loss_dice_4: 0.8991  loss_ce_5: 0  loss_mask_5: 0.2662  loss_dice_5: 0.8996  loss_ce_6: 0  loss_mask_6: 0.2681  loss_dice_6: 0.9009  loss_ce_7: 0  loss_mask_7: 0.2651  loss_dice_7: 0.9017  loss_ce_8: 0  loss_mask_8: 0.2568  loss_dice_8: 0.9071  time: 1.7763  data_time: 0.0590  lr: 9.9641e-05  max_mem: 5817M
[02/24 12:20:56] d2.utils.events INFO:  eta: 1 day, 4:07:21  iter: 259  total_loss: 13.02  loss_ce: 0  loss_mask: 0.2345  loss_dice: 0.9314  loss_seg: 1.34  loss_ce_0: 0  loss_mask_0: 0.2829  loss_dice_0: 0.8917  loss_ce_1: 0  loss_mask_1: 0.2898  loss_dice_1: 0.8864  loss_ce_2: 0  loss_mask_2: 0.2914  loss_dice_2: 0.8858  loss_ce_3: 0  loss_mask_3: 0.2874  loss_dice_3: 0.8863  loss_ce_4: 0  loss_mask_4: 0.2864  loss_dice_4: 0.887  loss_ce_5: 0  loss_mask_5: 0.2849  loss_dice_5: 0.8859  loss_ce_6: 0  loss_mask_6: 0.2834  loss_dice_6: 0.8875  loss_ce_7: 0  loss_mask_7: 0.2878  loss_dice_7: 0.8869  loss_ce_8: 0  loss_mask_8: 0.286  loss_dice_8: 0.8938  time: 1.7631  data_time: 0.0612  lr: 9.9611e-05  max_mem: 5817M
[02/24 12:21:30] d2.utils.events INFO:  eta: 1 day, 4:06:47  iter: 279  total_loss: 13.2  loss_ce: 0  loss_mask: 0.2362  loss_dice: 0.9359  loss_seg: 1.596  loss_ce_0: 0  loss_mask_0: 0.277  loss_dice_0: 0.8965  loss_ce_1: 0  loss_mask_1: 0.2853  loss_dice_1: 0.8882  loss_ce_2: 0  loss_mask_2: 0.2841  loss_dice_2: 0.8899  loss_ce_3: 0  loss_mask_3: 0.2822  loss_dice_3: 0.889  loss_ce_4: 0  loss_mask_4: 0.2809  loss_dice_4: 0.8918  loss_ce_5: 0  loss_mask_5: 0.2827  loss_dice_5: 0.8952  loss_ce_6: 0  loss_mask_6: 0.2821  loss_dice_6: 0.8957  loss_ce_7: 0  loss_mask_7: 0.2809  loss_dice_7: 0.897  loss_ce_8: 0  loss_mask_8: 0.2756  loss_dice_8: 0.9035  time: 1.7572  data_time: 0.0587  lr: 9.9581e-05  max_mem: 5817M
[02/24 12:22:04] d2.utils.events INFO:  eta: 1 day, 4:06:13  iter: 299  total_loss: 12.75  loss_ce: 0  loss_mask: 0.2228  loss_dice: 0.9312  loss_seg: 1.162  loss_ce_0: 0  loss_mask_0: 0.2617  loss_dice_0: 0.8955  loss_ce_1: 0  loss_mask_1: 0.2715  loss_dice_1: 0.8854  loss_ce_2: 0  loss_mask_2: 0.2736  loss_dice_2: 0.8857  loss_ce_3: 0  loss_mask_3: 0.2751  loss_dice_3: 0.8857  loss_ce_4: 0  loss_mask_4: 0.2741  loss_dice_4: 0.8859  loss_ce_5: 0  loss_mask_5: 0.2706  loss_dice_5: 0.888  loss_ce_6: 0  loss_mask_6: 0.2699  loss_dice_6: 0.8922  loss_ce_7: 0  loss_mask_7: 0.2686  loss_dice_7: 0.8931  loss_ce_8: 0  loss_mask_8: 0.2634  loss_dice_8: 0.9006  time: 1.7520  data_time: 0.0539  lr: 9.9551e-05  max_mem: 5851M
[02/24 12:22:37] d2.utils.events INFO:  eta: 1 day, 4:07:37  iter: 319  total_loss: 12.85  loss_ce: 0  loss_mask: 0.224  loss_dice: 0.9377  loss_seg: 1.163  loss_ce_0: 0  loss_mask_0: 0.2694  loss_dice_0: 0.8913  loss_ce_1: 0  loss_mask_1: 0.2804  loss_dice_1: 0.8821  loss_ce_2: 0  loss_mask_2: 0.282  loss_dice_2: 0.8806  loss_ce_3: 0  loss_mask_3: 0.2808  loss_dice_3: 0.8812  loss_ce_4: 0  loss_mask_4: 0.2826  loss_dice_4: 0.8833  loss_ce_5: 0  loss_mask_5: 0.2801  loss_dice_5: 0.8855  loss_ce_6: 0  loss_mask_6: 0.2798  loss_dice_6: 0.8852  loss_ce_7: 0  loss_mask_7: 0.2823  loss_dice_7: 0.8869  loss_ce_8: 0  loss_mask_8: 0.2734  loss_dice_8: 0.8934  time: 1.7473  data_time: 0.0523  lr: 9.9521e-05  max_mem: 5851M
[02/24 12:23:12] d2.utils.events INFO:  eta: 1 day, 4:09:46  iter: 339  total_loss: 13.06  loss_ce: 0  loss_mask: 0.2323  loss_dice: 0.927  loss_seg: 1.352  loss_ce_0: 0  loss_mask_0: 0.2689  loss_dice_0: 0.8915  loss_ce_1: 0  loss_mask_1: 0.2811  loss_dice_1: 0.8831  loss_ce_2: 0  loss_mask_2: 0.2833  loss_dice_2: 0.8838  loss_ce_3: 0  loss_mask_3: 0.2805  loss_dice_3: 0.8854  loss_ce_4: 0  loss_mask_4: 0.2834  loss_dice_4: 0.8845  loss_ce_5: 0  loss_mask_5: 0.282  loss_dice_5: 0.8861  loss_ce_6: 0  loss_mask_6: 0.2811  loss_dice_6: 0.8879  loss_ce_7: 0  loss_mask_7: 0.2808  loss_dice_7: 0.8889  loss_ce_8: 0  loss_mask_8: 0.2776  loss_dice_8: 0.8934  time: 1.7467  data_time: 0.0535  lr: 9.9491e-05  max_mem: 5851M
[02/24 12:23:46] d2.utils.events INFO:  eta: 1 day, 4:06:29  iter: 359  total_loss: 12.81  loss_ce: 0  loss_mask: 0.2369  loss_dice: 0.9263  loss_seg: 1.209  loss_ce_0: 0  loss_mask_0: 0.2753  loss_dice_0: 0.8877  loss_ce_1: 0  loss_mask_1: 0.2843  loss_dice_1: 0.8773  loss_ce_2: 0  loss_mask_2: 0.284  loss_dice_2: 0.8773  loss_ce_3: 0  loss_mask_3: 0.2831  loss_dice_3: 0.8762  loss_ce_4: 0  loss_mask_4: 0.2822  loss_dice_4: 0.877  loss_ce_5: 0  loss_mask_5: 0.2813  loss_dice_5: 0.8788  loss_ce_6: 0  loss_mask_6: 0.281  loss_dice_6: 0.879  loss_ce_7: 0  loss_mask_7: 0.2821  loss_dice_7: 0.8782  loss_ce_8: 0  loss_mask_8: 0.2769  loss_dice_8: 0.8817  time: 1.7422  data_time: 0.0516  lr: 9.9461e-05  max_mem: 5851M
[02/24 12:24:19] d2.utils.events INFO:  eta: 1 day, 4:06:38  iter: 379  total_loss: 12.97  loss_ce: 0  loss_mask: 0.2401  loss_dice: 0.9244  loss_seg: 1.315  loss_ce_0: 0  loss_mask_0: 0.2671  loss_dice_0: 0.8934  loss_ce_1: 0  loss_mask_1: 0.2735  loss_dice_1: 0.8856  loss_ce_2: 0  loss_mask_2: 0.2734  loss_dice_2: 0.8847  loss_ce_3: 0  loss_mask_3: 0.2754  loss_dice_3: 0.8846  loss_ce_4: 0  loss_mask_4: 0.2774  loss_dice_4: 0.8837  loss_ce_5: 0  loss_mask_5: 0.2729  loss_dice_5: 0.8846  loss_ce_6: 0  loss_mask_6: 0.2739  loss_dice_6: 0.8863  loss_ce_7: 0  loss_mask_7: 0.2741  loss_dice_7: 0.8857  loss_ce_8: 0  loss_mask_8: 0.2749  loss_dice_8: 0.8867  time: 1.7389  data_time: 0.0611  lr: 9.9431e-05  max_mem: 5851M
[02/24 12:24:54] d2.utils.events INFO:  eta: 1 day, 4:05:36  iter: 399  total_loss: 13.05  loss_ce: 0  loss_mask: 0.2394  loss_dice: 0.9283  loss_seg: 1.51  loss_ce_0: 0  loss_mask_0: 0.2681  loss_dice_0: 0.8968  loss_ce_1: 0  loss_mask_1: 0.2736  loss_dice_1: 0.8906  loss_ce_2: 0  loss_mask_2: 0.2741  loss_dice_2: 0.8896  loss_ce_3: 0  loss_mask_3: 0.2729  loss_dice_3: 0.8898  loss_ce_4: 0  loss_mask_4: 0.2715  loss_dice_4: 0.8909  loss_ce_5: 0  loss_mask_5: 0.2715  loss_dice_5: 0.8915  loss_ce_6: 0  loss_mask_6: 0.2696  loss_dice_6: 0.8944  loss_ce_7: 0  loss_mask_7: 0.2707  loss_dice_7: 0.8926  loss_ce_8: 0  loss_mask_8: 0.2674  loss_dice_8: 0.9011  time: 1.7379  data_time: 0.0632  lr: 9.9401e-05  max_mem: 5851M
[02/24 12:25:28] d2.utils.events INFO:  eta: 1 day, 4:02:53  iter: 419  total_loss: 12.74  loss_ce: 0  loss_mask: 0.2516  loss_dice: 0.9171  loss_seg: 1.108  loss_ce_0: 0  loss_mask_0: 0.2796  loss_dice_0: 0.8845  loss_ce_1: 0  loss_mask_1: 0.2851  loss_dice_1: 0.8723  loss_ce_2: 0  loss_mask_2: 0.2865  loss_dice_2: 0.8704  loss_ce_3: 0  loss_mask_3: 0.2864  loss_dice_3: 0.8694  loss_ce_4: 0  loss_mask_4: 0.2859  loss_dice_4: 0.8709  loss_ce_5: 0  loss_mask_5: 0.286  loss_dice_5: 0.8719  loss_ce_6: 0  loss_mask_6: 0.2876  loss_dice_6: 0.8723  loss_ce_7: 0  loss_mask_7: 0.2877  loss_dice_7: 0.8741  loss_ce_8: 0  loss_mask_8: 0.2853  loss_dice_8: 0.8769  time: 1.7348  data_time: 0.0641  lr: 9.9371e-05  max_mem: 5851M
[02/24 12:26:03] d2.utils.events INFO:  eta: 1 day, 4:02:00  iter: 439  total_loss: 12.54  loss_ce: 0  loss_mask: 0.2397  loss_dice: 0.9284  loss_seg: 1.027  loss_ce_0: 0  loss_mask_0: 0.2762  loss_dice_0: 0.877  loss_ce_1: 0  loss_mask_1: 0.2854  loss_dice_1: 0.8676  loss_ce_2: 0  loss_mask_2: 0.287  loss_dice_2: 0.8634  loss_ce_3: 0  loss_mask_3: 0.2869  loss_dice_3: 0.8653  loss_ce_4: 0  loss_mask_4: 0.2841  loss_dice_4: 0.8656  loss_ce_5: 0  loss_mask_5: 0.2848  loss_dice_5: 0.8661  loss_ce_6: 0  loss_mask_6: 0.2836  loss_dice_6: 0.8671  loss_ce_7: 0  loss_mask_7: 0.284  loss_dice_7: 0.8671  loss_ce_8: 0  loss_mask_8: 0.2813  loss_dice_8: 0.8702  time: 1.7370  data_time: 0.0532  lr: 9.9341e-05  max_mem: 5903M
[02/24 12:26:37] d2.utils.events INFO:  eta: 1 day, 4:00:29  iter: 459  total_loss: 12.57  loss_ce: 0  loss_mask: 0.2731  loss_dice: 0.9033  loss_seg: 0.9536  loss_ce_0: 0  loss_mask_0: 0.2965  loss_dice_0: 0.8648  loss_ce_1: 0  loss_mask_1: 0.2994  loss_dice_1: 0.8589  loss_ce_2: 0  loss_mask_2: 0.3011  loss_dice_2: 0.8594  loss_ce_3: 0  loss_mask_3: 0.3021  loss_dice_3: 0.8588  loss_ce_4: 0  loss_mask_4: 0.3039  loss_dice_4: 0.8574  loss_ce_5: 0  loss_mask_5: 0.3028  loss_dice_5: 0.8589  loss_ce_6: 0  loss_mask_6: 0.3042  loss_dice_6: 0.8584  loss_ce_7: 0  loss_mask_7: 0.3011  loss_dice_7: 0.8589  loss_ce_8: 0  loss_mask_8: 0.3016  loss_dice_8: 0.8586  time: 1.7339  data_time: 0.0608  lr: 9.9311e-05  max_mem: 5903M
[02/24 12:27:10] d2.utils.events INFO:  eta: 1 day, 3:59:04  iter: 479  total_loss: 12.8  loss_ce: 0  loss_mask: 0.2559  loss_dice: 0.9136  loss_seg: 1.171  loss_ce_0: 0  loss_mask_0: 0.2774  loss_dice_0: 0.8807  loss_ce_1: 0  loss_mask_1: 0.2846  loss_dice_1: 0.8712  loss_ce_2: 0  loss_mask_2: 0.2855  loss_dice_2: 0.87  loss_ce_3: 0  loss_mask_3: 0.2875  loss_dice_3: 0.8718  loss_ce_4: 0  loss_mask_4: 0.2884  loss_dice_4: 0.8731  loss_ce_5: 0  loss_mask_5: 0.2887  loss_dice_5: 0.875  loss_ce_6: 0  loss_mask_6: 0.2846  loss_dice_6: 0.8764  loss_ce_7: 0  loss_mask_7: 0.2852  loss_dice_7: 0.8775  loss_ce_8: 0  loss_mask_8: 0.2815  loss_dice_8: 0.8811  time: 1.7301  data_time: 0.0474  lr: 9.9281e-05  max_mem: 5903M
[02/24 12:27:44] d2.utils.events INFO:  eta: 1 day, 3:57:26  iter: 499  total_loss: 12.81  loss_ce: 0  loss_mask: 0.2458  loss_dice: 0.922  loss_seg: 1.242  loss_ce_0: 0  loss_mask_0: 0.2794  loss_dice_0: 0.8752  loss_ce_1: 0  loss_mask_1: 0.281  loss_dice_1: 0.8662  loss_ce_2: 0  loss_mask_2: 0.2828  loss_dice_2: 0.8659  loss_ce_3: 0  loss_mask_3: 0.282  loss_dice_3: 0.8668  loss_ce_4: 0  loss_mask_4: 0.2811  loss_dice_4: 0.8651  loss_ce_5: 0  loss_mask_5: 0.2822  loss_dice_5: 0.8681  loss_ce_6: 0  loss_mask_6: 0.2827  loss_dice_6: 0.8675  loss_ce_7: 0  loss_mask_7: 0.2828  loss_dice_7: 0.8698  loss_ce_8: 0  loss_mask_8: 0.2847  loss_dice_8: 0.8721  time: 1.7283  data_time: 0.0642  lr: 9.9251e-05  max_mem: 5903M
[02/24 12:28:17] d2.utils.events INFO:  eta: 1 day, 3:55:56  iter: 519  total_loss: 12.53  loss_ce: 0  loss_mask: 0.2596  loss_dice: 0.9073  loss_seg: 0.9631  loss_ce_0: 0  loss_mask_0: 0.2818  loss_dice_0: 0.8656  loss_ce_1: 0  loss_mask_1: 0.2879  loss_dice_1: 0.8544  loss_ce_2: 0  loss_mask_2: 0.2879  loss_dice_2: 0.853  loss_ce_3: 0  loss_mask_3: 0.2899  loss_dice_3: 0.8532  loss_ce_4: 0  loss_mask_4: 0.2882  loss_dice_4: 0.8542  loss_ce_5: 0  loss_mask_5: 0.2877  loss_dice_5: 0.8545  loss_ce_6: 0  loss_mask_6: 0.289  loss_dice_6: 0.8548  loss_ce_7: 0  loss_mask_7: 0.2874  loss_dice_7: 0.8569  loss_ce_8: 0  loss_mask_8: 0.2867  loss_dice_8: 0.8572  time: 1.7260  data_time: 0.0469  lr: 9.9221e-05  max_mem: 5903M
[02/24 12:28:51] d2.utils.events INFO:  eta: 1 day, 3:55:14  iter: 539  total_loss: 12.76  loss_ce: 0  loss_mask: 0.2606  loss_dice: 0.9036  loss_seg: 1.253  loss_ce_0: 0  loss_mask_0: 0.2818  loss_dice_0: 0.8607  loss_ce_1: 0  loss_mask_1: 0.2894  loss_dice_1: 0.8567  loss_ce_2: 0  loss_mask_2: 0.289  loss_dice_2: 0.8557  loss_ce_3: 0  loss_mask_3: 0.2893  loss_dice_3: 0.8554  loss_ce_4: 0  loss_mask_4: 0.2894  loss_dice_4: 0.8559  loss_ce_5: 0  loss_mask_5: 0.288  loss_dice_5: 0.86  loss_ce_6: 0  loss_mask_6: 0.2883  loss_dice_6: 0.8599  loss_ce_7: 0  loss_mask_7: 0.2914  loss_dice_7: 0.8606  loss_ce_8: 0  loss_mask_8: 0.2894  loss_dice_8: 0.8617  time: 1.7243  data_time: 0.0558  lr: 9.9191e-05  max_mem: 5903M
[02/24 12:29:24] d2.utils.events INFO:  eta: 1 day, 3:53:41  iter: 559  total_loss: 12.82  loss_ce: 0  loss_mask: 0.2708  loss_dice: 0.9057  loss_seg: 1.279  loss_ce_0: 0  loss_mask_0: 0.2909  loss_dice_0: 0.8671  loss_ce_1: 0  loss_mask_1: 0.2949  loss_dice_1: 0.8623  loss_ce_2: 0  loss_mask_2: 0.2939  loss_dice_2: 0.8622  loss_ce_3: 0  loss_mask_3: 0.2905  loss_dice_3: 0.8657  loss_ce_4: 0  loss_mask_4: 0.2923  loss_dice_4: 0.8651  loss_ce_5: 0  loss_mask_5: 0.2925  loss_dice_5: 0.866  loss_ce_6: 0  loss_mask_6: 0.293  loss_dice_6: 0.8659  loss_ce_7: 0  loss_mask_7: 0.2911  loss_dice_7: 0.8659  loss_ce_8: 0  loss_mask_8: 0.2925  loss_dice_8: 0.8688  time: 1.7224  data_time: 0.0535  lr: 9.9161e-05  max_mem: 5903M
[02/24 12:29:58] d2.utils.events INFO:  eta: 1 day, 3:53:07  iter: 579  total_loss: 12.45  loss_ce: 0  loss_mask: 0.2627  loss_dice: 0.9056  loss_seg: 0.9672  loss_ce_0: 0  loss_mask_0: 0.2796  loss_dice_0: 0.8676  loss_ce_1: 0  loss_mask_1: 0.2855  loss_dice_1: 0.8591  loss_ce_2: 0  loss_mask_2: 0.2841  loss_dice_2: 0.8597  loss_ce_3: 0  loss_mask_3: 0.2836  loss_dice_3: 0.8587  loss_ce_4: 0  loss_mask_4: 0.2823  loss_dice_4: 0.8613  loss_ce_5: 0  loss_mask_5: 0.2831  loss_dice_5: 0.8631  loss_ce_6: 0  loss_mask_6: 0.2825  loss_dice_6: 0.8633  loss_ce_7: 0  loss_mask_7: 0.2832  loss_dice_7: 0.863  loss_ce_8: 0  loss_mask_8: 0.2814  loss_dice_8: 0.8652  time: 1.7213  data_time: 0.0552  lr: 9.9131e-05  max_mem: 5903M
[02/24 12:30:32] d2.utils.events INFO:  eta: 1 day, 3:52:33  iter: 599  total_loss: 12.49  loss_ce: 0  loss_mask: 0.2807  loss_dice: 0.8945  loss_seg: 0.9553  loss_ce_0: 0  loss_mask_0: 0.2972  loss_dice_0: 0.8585  loss_ce_1: 0  loss_mask_1: 0.3026  loss_dice_1: 0.8483  loss_ce_2: 0  loss_mask_2: 0.3052  loss_dice_2: 0.8475  loss_ce_3: 0  loss_mask_3: 0.3075  loss_dice_3: 0.8463  loss_ce_4: 0  loss_mask_4: 0.3084  loss_dice_4: 0.8457  loss_ce_5: 0  loss_mask_5: 0.3051  loss_dice_5: 0.8478  loss_ce_6: 0  loss_mask_6: 0.3048  loss_dice_6: 0.8466  loss_ce_7: 0  loss_mask_7: 0.3067  loss_dice_7: 0.8468  loss_ce_8: 0  loss_mask_8: 0.3044  loss_dice_8: 0.8502  time: 1.7193  data_time: 0.0580  lr: 9.9101e-05  max_mem: 5903M
[02/24 12:31:06] d2.utils.events INFO:  eta: 1 day, 3:51:28  iter: 619  total_loss: 12.43  loss_ce: 0  loss_mask: 0.2663  loss_dice: 0.8996  loss_seg: 0.9511  loss_ce_0: 0  loss_mask_0: 0.2995  loss_dice_0: 0.8526  loss_ce_1: 0  loss_mask_1: 0.2988  loss_dice_1: 0.8443  loss_ce_2: 0  loss_mask_2: 0.2983  loss_dice_2: 0.8438  loss_ce_3: 0  loss_mask_3: 0.2984  loss_dice_3: 0.8454  loss_ce_4: 0  loss_mask_4: 0.3016  loss_dice_4: 0.8435  loss_ce_5: 0  loss_mask_5: 0.3003  loss_dice_5: 0.8458  loss_ce_6: 0  loss_mask_6: 0.3016  loss_dice_6: 0.8467  loss_ce_7: 0  loss_mask_7: 0.3027  loss_dice_7: 0.8466  loss_ce_8: 0  loss_mask_8: 0.3002  loss_dice_8: 0.849  time: 1.7189  data_time: 0.0497  lr: 9.9071e-05  max_mem: 5903M
[02/24 12:31:39] d2.utils.events INFO:  eta: 1 day, 3:48:50  iter: 639  total_loss: 12.41  loss_ce: 0  loss_mask: 0.2679  loss_dice: 0.8957  loss_seg: 0.9972  loss_ce_0: 0  loss_mask_0: 0.2871  loss_dice_0: 0.8542  loss_ce_1: 0  loss_mask_1: 0.2949  loss_dice_1: 0.8422  loss_ce_2: 0  loss_mask_2: 0.2937  loss_dice_2: 0.842  loss_ce_3: 0  loss_mask_3: 0.293  loss_dice_3: 0.8419  loss_ce_4: 0  loss_mask_4: 0.2944  loss_dice_4: 0.843  loss_ce_5: 0  loss_mask_5: 0.2924  loss_dice_5: 0.8448  loss_ce_6: 0  loss_mask_6: 0.2911  loss_dice_6: 0.8456  loss_ce_7: 0  loss_mask_7: 0.2916  loss_dice_7: 0.8466  loss_ce_8: 0  loss_mask_8: 0.2936  loss_dice_8: 0.8464  time: 1.7167  data_time: 0.0543  lr: 9.9041e-05  max_mem: 5903M
[02/24 12:32:13] d2.utils.events INFO:  eta: 1 day, 3:47:46  iter: 659  total_loss: 12.34  loss_ce: 0  loss_mask: 0.2796  loss_dice: 0.8956  loss_seg: 0.964  loss_ce_0: 0  loss_mask_0: 0.2884  loss_dice_0: 0.8552  loss_ce_1: 0  loss_mask_1: 0.2927  loss_dice_1: 0.8481  loss_ce_2: 0  loss_mask_2: 0.2923  loss_dice_2: 0.8466  loss_ce_3: 0  loss_mask_3: 0.2933  loss_dice_3: 0.8474  loss_ce_4: 0  loss_mask_4: 0.2939  loss_dice_4: 0.8462  loss_ce_5: 0  loss_mask_5: 0.294  loss_dice_5: 0.8474  loss_ce_6: 0  loss_mask_6: 0.2954  loss_dice_6: 0.8464  loss_ce_7: 0  loss_mask_7: 0.2946  loss_dice_7: 0.8467  loss_ce_8: 0  loss_mask_8: 0.2932  loss_dice_8: 0.8496  time: 1.7166  data_time: 0.0557  lr: 9.9011e-05  max_mem: 5903M
[02/24 12:32:47] d2.utils.events INFO:  eta: 1 day, 3:47:12  iter: 679  total_loss: 12.53  loss_ce: 0  loss_mask: 0.2567  loss_dice: 0.9026  loss_seg: 1.037  loss_ce_0: 0  loss_mask_0: 0.2811  loss_dice_0: 0.8579  loss_ce_1: 0  loss_mask_1: 0.2868  loss_dice_1: 0.8507  loss_ce_2: 0  loss_mask_2: 0.2883  loss_dice_2: 0.85  loss_ce_3: 0  loss_mask_3: 0.2858  loss_dice_3: 0.8499  loss_ce_4: 0  loss_mask_4: 0.2859  loss_dice_4: 0.8524  loss_ce_5: 0  loss_mask_5: 0.2847  loss_dice_5: 0.8545  loss_ce_6: 0  loss_mask_6: 0.2864  loss_dice_6: 0.8543  loss_ce_7: 0  loss_mask_7: 0.2854  loss_dice_7: 0.8547  loss_ce_8: 0  loss_mask_8: 0.2849  loss_dice_8: 0.8565  time: 1.7155  data_time: 0.0537  lr: 9.8981e-05  max_mem: 5903M
[02/24 12:33:21] d2.utils.events INFO:  eta: 1 day, 3:46:38  iter: 699  total_loss: 12.26  loss_ce: 0  loss_mask: 0.2545  loss_dice: 0.9057  loss_seg: 0.9569  loss_ce_0: 0  loss_mask_0: 0.2817  loss_dice_0: 0.8535  loss_ce_1: 0  loss_mask_1: 0.2855  loss_dice_1: 0.845  loss_ce_2: 0  loss_mask_2: 0.2875  loss_dice_2: 0.8436  loss_ce_3: 0  loss_mask_3: 0.2879  loss_dice_3: 0.8435  loss_ce_4: 0  loss_mask_4: 0.2873  loss_dice_4: 0.8455  loss_ce_5: 0  loss_mask_5: 0.2877  loss_dice_5: 0.8462  loss_ce_6: 0  loss_mask_6: 0.2871  loss_dice_6: 0.8475  loss_ce_7: 0  loss_mask_7: 0.2843  loss_dice_7: 0.8492  loss_ce_8: 0  loss_mask_8: 0.2815  loss_dice_8: 0.8526  time: 1.7143  data_time: 0.0490  lr: 9.8951e-05  max_mem: 5903M
[02/24 12:33:54] d2.utils.events INFO:  eta: 1 day, 3:44:59  iter: 719  total_loss: 12.21  loss_ce: 0  loss_mask: 0.289  loss_dice: 0.8829  loss_seg: 0.872  loss_ce_0: 0  loss_mask_0: 0.295  loss_dice_0: 0.8457  loss_ce_1: 0  loss_mask_1: 0.3009  loss_dice_1: 0.8333  loss_ce_2: 0  loss_mask_2: 0.3004  loss_dice_2: 0.8333  loss_ce_3: 0  loss_mask_3: 0.2993  loss_dice_3: 0.8337  loss_ce_4: 0  loss_mask_4: 0.2993  loss_dice_4: 0.8332  loss_ce_5: 0  loss_mask_5: 0.2994  loss_dice_5: 0.8357  loss_ce_6: 0  loss_mask_6: 0.2989  loss_dice_6: 0.8349  loss_ce_7: 0  loss_mask_7: 0.3  loss_dice_7: 0.834  loss_ce_8: 0  loss_mask_8: 0.2996  loss_dice_8: 0.8348  time: 1.7122  data_time: 0.0539  lr: 9.8921e-05  max_mem: 5903M
[02/24 12:34:27] d2.utils.events INFO:  eta: 1 day, 3:44:00  iter: 739  total_loss: 12.15  loss_ce: 0  loss_mask: 0.2685  loss_dice: 0.9005  loss_seg: 0.8368  loss_ce_0: 0  loss_mask_0: 0.2828  loss_dice_0: 0.8493  loss_ce_1: 0  loss_mask_1: 0.2864  loss_dice_1: 0.8367  loss_ce_2: 0  loss_mask_2: 0.2867  loss_dice_2: 0.8373  loss_ce_3: 0  loss_mask_3: 0.288  loss_dice_3: 0.8358  loss_ce_4: 0  loss_mask_4: 0.2863  loss_dice_4: 0.8364  loss_ce_5: 0  loss_mask_5: 0.2885  loss_dice_5: 0.8378  loss_ce_6: 0  loss_mask_6: 0.2871  loss_dice_6: 0.8368  loss_ce_7: 0  loss_mask_7: 0.2861  loss_dice_7: 0.8398  loss_ce_8: 0  loss_mask_8: 0.2852  loss_dice_8: 0.8411  time: 1.7113  data_time: 0.0518  lr: 9.8891e-05  max_mem: 5903M
[02/24 12:35:00] d2.utils.events INFO:  eta: 1 day, 3:42:06  iter: 759  total_loss: 12.15  loss_ce: 0  loss_mask: 0.293  loss_dice: 0.874  loss_seg: 0.8271  loss_ce_0: 0  loss_mask_0: 0.299  loss_dice_0: 0.8328  loss_ce_1: 0  loss_mask_1: 0.3059  loss_dice_1: 0.8213  loss_ce_2: 0  loss_mask_2: 0.3054  loss_dice_2: 0.8212  loss_ce_3: 0  loss_mask_3: 0.3048  loss_dice_3: 0.8221  loss_ce_4: 0  loss_mask_4: 0.3047  loss_dice_4: 0.8222  loss_ce_5: 0  loss_mask_5: 0.304  loss_dice_5: 0.8238  loss_ce_6: 0  loss_mask_6: 0.3065  loss_dice_6: 0.8259  loss_ce_7: 0  loss_mask_7: 0.306  loss_dice_7: 0.8258  loss_ce_8: 0  loss_mask_8: 0.3064  loss_dice_8: 0.8239  time: 1.7095  data_time: 0.0472  lr: 9.8861e-05  max_mem: 5903M
[02/24 12:35:34] d2.utils.events INFO:  eta: 1 day, 3:40:38  iter: 779  total_loss: 12.16  loss_ce: 0  loss_mask: 0.2736  loss_dice: 0.892  loss_seg: 0.8505  loss_ce_0: 0  loss_mask_0: 0.2916  loss_dice_0: 0.8377  loss_ce_1: 0  loss_mask_1: 0.2961  loss_dice_1: 0.8241  loss_ce_2: 0  loss_mask_2: 0.2936  loss_dice_2: 0.8206  loss_ce_3: 0  loss_mask_3: 0.293  loss_dice_3: 0.8215  loss_ce_4: 0  loss_mask_4: 0.2939  loss_dice_4: 0.8235  loss_ce_5: 0  loss_mask_5: 0.2934  loss_dice_5: 0.8218  loss_ce_6: 0  loss_mask_6: 0.2943  loss_dice_6: 0.8214  loss_ce_7: 0  loss_mask_7: 0.2918  loss_dice_7: 0.823  loss_ce_8: 0  loss_mask_8: 0.2919  loss_dice_8: 0.8262  time: 1.7081  data_time: 0.0509  lr: 9.8831e-05  max_mem: 5916M
[02/24 12:36:07] d2.utils.events INFO:  eta: 1 day, 3:40:36  iter: 799  total_loss: 12.16  loss_ce: 0  loss_mask: 0.2936  loss_dice: 0.8807  loss_seg: 0.8653  loss_ce_0: 0  loss_mask_0: 0.3054  loss_dice_0: 0.8285  loss_ce_1: 0  loss_mask_1: 0.3113  loss_dice_1: 0.8124  loss_ce_2: 0  loss_mask_2: 0.3139  loss_dice_2: 0.8117  loss_ce_3: 0  loss_mask_3: 0.3115  loss_dice_3: 0.8117  loss_ce_4: 0  loss_mask_4: 0.3113  loss_dice_4: 0.8119  loss_ce_5: 0  loss_mask_5: 0.3113  loss_dice_5: 0.8132  loss_ce_6: 0  loss_mask_6: 0.3087  loss_dice_6: 0.8148  loss_ce_7: 0  loss_mask_7: 0.3111  loss_dice_7: 0.815  loss_ce_8: 0  loss_mask_8: 0.31  loss_dice_8: 0.8192  time: 1.7071  data_time: 0.0647  lr: 9.8801e-05  max_mem: 5916M
[02/24 12:36:42] d2.utils.events INFO:  eta: 1 day, 3:40:25  iter: 819  total_loss: 11.96  loss_ce: 0  loss_mask: 0.2989  loss_dice: 0.8731  loss_seg: 0.7442  loss_ce_0: 0  loss_mask_0: 0.2965  loss_dice_0: 0.8239  loss_ce_1: 0  loss_mask_1: 0.3014  loss_dice_1: 0.8101  loss_ce_2: 0  loss_mask_2: 0.3054  loss_dice_2: 0.8093  loss_ce_3: 0  loss_mask_3: 0.3071  loss_dice_3: 0.8093  loss_ce_4: 0  loss_mask_4: 0.304  loss_dice_4: 0.8084  loss_ce_5: 0  loss_mask_5: 0.3046  loss_dice_5: 0.8098  loss_ce_6: 0  loss_mask_6: 0.3012  loss_dice_6: 0.8099  loss_ce_7: 0  loss_mask_7: 0.3046  loss_dice_7: 0.8109  loss_ce_8: 0  loss_mask_8: 0.3028  loss_dice_8: 0.8134  time: 1.7077  data_time: 0.0537  lr: 9.8771e-05  max_mem: 5916M
[02/24 12:37:15] d2.utils.events INFO:  eta: 1 day, 3:39:29  iter: 839  total_loss: 12.01  loss_ce: 0  loss_mask: 0.2868  loss_dice: 0.8784  loss_seg: 0.7707  loss_ce_0: 0  loss_mask_0: 0.2915  loss_dice_0: 0.8346  loss_ce_1: 0  loss_mask_1: 0.296  loss_dice_1: 0.8192  loss_ce_2: 0  loss_mask_2: 0.2957  loss_dice_2: 0.8176  loss_ce_3: 0  loss_mask_3: 0.2941  loss_dice_3: 0.8179  loss_ce_4: 0  loss_mask_4: 0.2987  loss_dice_4: 0.8176  loss_ce_5: 0  loss_mask_5: 0.2975  loss_dice_5: 0.821  loss_ce_6: 0  loss_mask_6: 0.2956  loss_dice_6: 0.8206  loss_ce_7: 0  loss_mask_7: 0.2963  loss_dice_7: 0.8197  loss_ce_8: 0  loss_mask_8: 0.2947  loss_dice_8: 0.8212  time: 1.7069  data_time: 0.0590  lr: 9.8741e-05  max_mem: 5916M
[02/24 12:37:49] d2.utils.events INFO:  eta: 1 day, 3:38:24  iter: 859  total_loss: 12.01  loss_ce: 0  loss_mask: 0.2899  loss_dice: 0.8722  loss_seg: 0.7361  loss_ce_0: 0  loss_mask_0: 0.29  loss_dice_0: 0.8311  loss_ce_1: 0  loss_mask_1: 0.2943  loss_dice_1: 0.8196  loss_ce_2: 0  loss_mask_2: 0.2949  loss_dice_2: 0.8173  loss_ce_3: 0  loss_mask_3: 0.2945  loss_dice_3: 0.8186  loss_ce_4: 0  loss_mask_4: 0.2958  loss_dice_4: 0.8209  loss_ce_5: 0  loss_mask_5: 0.2974  loss_dice_5: 0.8215  loss_ce_6: 0  loss_mask_6: 0.2959  loss_dice_6: 0.8216  loss_ce_7: 0  loss_mask_7: 0.2947  loss_dice_7: 0.8219  loss_ce_8: 0  loss_mask_8: 0.2954  loss_dice_8: 0.8225  time: 1.7054  data_time: 0.0624  lr: 9.8711e-05  max_mem: 5916M
[02/24 12:38:21] d2.utils.events INFO:  eta: 1 day, 3:36:14  iter: 879  total_loss: 11.98  loss_ce: 0  loss_mask: 0.2824  loss_dice: 0.8755  loss_seg: 0.7826  loss_ce_0: 0  loss_mask_0: 0.2954  loss_dice_0: 0.8252  loss_ce_1: 0  loss_mask_1: 0.3025  loss_dice_1: 0.8158  loss_ce_2: 0  loss_mask_2: 0.302  loss_dice_2: 0.8155  loss_ce_3: 0  loss_mask_3: 0.3023  loss_dice_3: 0.8178  loss_ce_4: 0  loss_mask_4: 0.3018  loss_dice_4: 0.8186  loss_ce_5: 0  loss_mask_5: 0.3014  loss_dice_5: 0.8214  loss_ce_6: 0  loss_mask_6: 0.3034  loss_dice_6: 0.8191  loss_ce_7: 0  loss_mask_7: 0.3027  loss_dice_7: 0.8197  loss_ce_8: 0  loss_mask_8: 0.3013  loss_dice_8: 0.8224  time: 1.7033  data_time: 0.0483  lr: 9.8681e-05  max_mem: 5916M
[02/24 12:38:55] d2.utils.events INFO:  eta: 1 day, 3:36:11  iter: 899  total_loss: 11.84  loss_ce: 0  loss_mask: 0.2924  loss_dice: 0.8627  loss_seg: 0.7313  loss_ce_0: 0  loss_mask_0: 0.2958  loss_dice_0: 0.8157  loss_ce_1: 0  loss_mask_1: 0.2993  loss_dice_1: 0.8036  loss_ce_2: 0  loss_mask_2: 0.3003  loss_dice_2: 0.8021  loss_ce_3: 0  loss_mask_3: 0.3017  loss_dice_3: 0.8004  loss_ce_4: 0  loss_mask_4: 0.3005  loss_dice_4: 0.8019  loss_ce_5: 0  loss_mask_5: 0.2999  loss_dice_5: 0.8041  loss_ce_6: 0  loss_mask_6: 0.3016  loss_dice_6: 0.8066  loss_ce_7: 0  loss_mask_7: 0.3008  loss_dice_7: 0.8045  loss_ce_8: 0  loss_mask_8: 0.3007  loss_dice_8: 0.8046  time: 1.7034  data_time: 0.0525  lr: 9.865e-05  max_mem: 5916M
[02/24 12:39:29] d2.utils.events INFO:  eta: 1 day, 3:34:30  iter: 919  total_loss: 11.84  loss_ce: 0  loss_mask: 0.2917  loss_dice: 0.869  loss_seg: 0.7463  loss_ce_0: 0  loss_mask_0: 0.2962  loss_dice_0: 0.816  loss_ce_1: 0  loss_mask_1: 0.3014  loss_dice_1: 0.8035  loss_ce_2: 0  loss_mask_2: 0.3021  loss_dice_2: 0.8  loss_ce_3: 0  loss_mask_3: 0.3007  loss_dice_3: 0.8006  loss_ce_4: 0  loss_mask_4: 0.3021  loss_dice_4: 0.7998  loss_ce_5: 0  loss_mask_5: 0.3026  loss_dice_5: 0.8037  loss_ce_6: 0  loss_mask_6: 0.3027  loss_dice_6: 0.8038  loss_ce_7: 0  loss_mask_7: 0.298  loss_dice_7: 0.804  loss_ce_8: 0  loss_mask_8: 0.2986  loss_dice_8: 0.8044  time: 1.7026  data_time: 0.0565  lr: 9.862e-05  max_mem: 5916M
[02/24 12:40:01] d2.utils.events INFO:  eta: 1 day, 3:31:25  iter: 939  total_loss: 11.75  loss_ce: 0  loss_mask: 0.29  loss_dice: 0.8592  loss_seg: 0.6971  loss_ce_0: 0  loss_mask_0: 0.2856  loss_dice_0: 0.809  loss_ce_1: 0  loss_mask_1: 0.2931  loss_dice_1: 0.7945  loss_ce_2: 0  loss_mask_2: 0.2928  loss_dice_2: 0.7926  loss_ce_3: 0  loss_mask_3: 0.2933  loss_dice_3: 0.7936  loss_ce_4: 0  loss_mask_4: 0.2935  loss_dice_4: 0.7929  loss_ce_5: 0  loss_mask_5: 0.2938  loss_dice_5: 0.7946  loss_ce_6: 0  loss_mask_6: 0.2938  loss_dice_6: 0.7941  loss_ce_7: 0  loss_mask_7: 0.292  loss_dice_7: 0.7944  loss_ce_8: 0  loss_mask_8: 0.2907  loss_dice_8: 0.7976  time: 1.7010  data_time: 0.0624  lr: 9.859e-05  max_mem: 5916M
[02/24 12:40:35] d2.utils.events INFO:  eta: 1 day, 3:30:18  iter: 959  total_loss: 11.75  loss_ce: 0  loss_mask: 0.2906  loss_dice: 0.862  loss_seg: 0.7275  loss_ce_0: 0  loss_mask_0: 0.291  loss_dice_0: 0.8071  loss_ce_1: 0  loss_mask_1: 0.297  loss_dice_1: 0.7943  loss_ce_2: 0  loss_mask_2: 0.2973  loss_dice_2: 0.792  loss_ce_3: 0  loss_mask_3: 0.2981  loss_dice_3: 0.7921  loss_ce_4: 0  loss_mask_4: 0.296  loss_dice_4: 0.7914  loss_ce_5: 0  loss_mask_5: 0.2969  loss_dice_5: 0.7923  loss_ce_6: 0  loss_mask_6: 0.2958  loss_dice_6: 0.7941  loss_ce_7: 0  loss_mask_7: 0.2966  loss_dice_7: 0.7931  loss_ce_8: 0  loss_mask_8: 0.297  loss_dice_8: 0.7963  time: 1.7000  data_time: 0.0568  lr: 9.856e-05  max_mem: 5916M
[02/24 12:41:07] d2.utils.events INFO:  eta: 1 day, 3:28:53  iter: 979  total_loss: 11.67  loss_ce: 0  loss_mask: 0.291  loss_dice: 0.8599  loss_seg: 0.6887  loss_ce_0: 0  loss_mask_0: 0.2921  loss_dice_0: 0.8115  loss_ce_1: 0  loss_mask_1: 0.2934  loss_dice_1: 0.7952  loss_ce_2: 0  loss_mask_2: 0.2945  loss_dice_2: 0.7927  loss_ce_3: 0  loss_mask_3: 0.2949  loss_dice_3: 0.7924  loss_ce_4: 0  loss_mask_4: 0.2957  loss_dice_4: 0.7928  loss_ce_5: 0  loss_mask_5: 0.2957  loss_dice_5: 0.7936  loss_ce_6: 0  loss_mask_6: 0.2951  loss_dice_6: 0.7931  loss_ce_7: 0  loss_mask_7: 0.2951  loss_dice_7: 0.7938  loss_ce_8: 0  loss_mask_8: 0.2944  loss_dice_8: 0.7965  time: 1.6986  data_time: 0.0504  lr: 9.853e-05  max_mem: 5916M
[02/24 12:41:41] d2.utils.events INFO:  eta: 1 day, 3:28:44  iter: 999  total_loss: 11.69  loss_ce: 0  loss_mask: 0.2936  loss_dice: 0.8563  loss_seg: 0.7408  loss_ce_0: 0  loss_mask_0: 0.2985  loss_dice_0: 0.8025  loss_ce_1: 0  loss_mask_1: 0.3028  loss_dice_1: 0.7858  loss_ce_2: 0  loss_mask_2: 0.3043  loss_dice_2: 0.7827  loss_ce_3: 0  loss_mask_3: 0.3069  loss_dice_3: 0.7824  loss_ce_4: 0  loss_mask_4: 0.3059  loss_dice_4: 0.7846  loss_ce_5: 0  loss_mask_5: 0.3061  loss_dice_5: 0.7843  loss_ce_6: 0  loss_mask_6: 0.3034  loss_dice_6: 0.7871  loss_ce_7: 0  loss_mask_7: 0.3042  loss_dice_7: 0.7867  loss_ce_8: 0  loss_mask_8: 0.3019  loss_dice_8: 0.789  time: 1.6983  data_time: 0.0567  lr: 9.85e-05  max_mem: 5916M
[02/24 12:42:15] d2.utils.events INFO:  eta: 1 day, 3:22:08  iter: 1019  total_loss: 11.63  loss_ce: 0  loss_mask: 0.2903  loss_dice: 0.8535  loss_seg: 0.7408  loss_ce_0: 0  loss_mask_0: 0.2893  loss_dice_0: 0.8062  loss_ce_1: 0  loss_mask_1: 0.2944  loss_dice_1: 0.7903  loss_ce_2: 0  loss_mask_2: 0.294  loss_dice_2: 0.7898  loss_ce_3: 0  loss_mask_3: 0.2944  loss_dice_3: 0.7883  loss_ce_4: 0  loss_mask_4: 0.2956  loss_dice_4: 0.7876  loss_ce_5: 0  loss_mask_5: 0.2953  loss_dice_5: 0.7873  loss_ce_6: 0  loss_mask_6: 0.296  loss_dice_6: 0.7876  loss_ce_7: 0  loss_mask_7: 0.294  loss_dice_7: 0.7906  loss_ce_8: 0  loss_mask_8: 0.2942  loss_dice_8: 0.7912  time: 1.6975  data_time: 0.0535  lr: 9.847e-05  max_mem: 5916M
[02/24 12:42:48] d2.utils.events INFO:  eta: 1 day, 3:15:56  iter: 1039  total_loss: 11.69  loss_ce: 0  loss_mask: 0.3093  loss_dice: 0.8406  loss_seg: 0.686  loss_ce_0: 0  loss_mask_0: 0.3084  loss_dice_0: 0.7863  loss_ce_1: 0  loss_mask_1: 0.3131  loss_dice_1: 0.7759  loss_ce_2: 0  loss_mask_2: 0.3135  loss_dice_2: 0.7779  loss_ce_3: 0  loss_mask_3: 0.3115  loss_dice_3: 0.7806  loss_ce_4: 0  loss_mask_4: 0.3129  loss_dice_4: 0.7797  loss_ce_5: 0  loss_mask_5: 0.3138  loss_dice_5: 0.7815  loss_ce_6: 0  loss_mask_6: 0.3136  loss_dice_6: 0.7788  loss_ce_7: 0  loss_mask_7: 0.3132  loss_dice_7: 0.7774  loss_ce_8: 0  loss_mask_8: 0.313  loss_dice_8: 0.778  time: 1.6972  data_time: 0.0609  lr: 9.844e-05  max_mem: 5916M
[02/24 12:43:21] d2.utils.events INFO:  eta: 1 day, 3:11:43  iter: 1059  total_loss: 11.5  loss_ce: 0  loss_mask: 0.2909  loss_dice: 0.8517  loss_seg: 0.6626  loss_ce_0: 0  loss_mask_0: 0.2875  loss_dice_0: 0.7996  loss_ce_1: 0  loss_mask_1: 0.2957  loss_dice_1: 0.7809  loss_ce_2: 0  loss_mask_2: 0.2946  loss_dice_2: 0.7787  loss_ce_3: 0  loss_mask_3: 0.2949  loss_dice_3: 0.7772  loss_ce_4: 0  loss_mask_4: 0.2947  loss_dice_4: 0.7787  loss_ce_5: 0  loss_mask_5: 0.2941  loss_dice_5: 0.7798  loss_ce_6: 0  loss_mask_6: 0.2936  loss_dice_6: 0.7812  loss_ce_7: 0  loss_mask_7: 0.292  loss_dice_7: 0.7841  loss_ce_8: 0  loss_mask_8: 0.294  loss_dice_8: 0.7828  time: 1.6954  data_time: 0.0463  lr: 9.841e-05  max_mem: 5916M
[02/24 12:43:57] d2.utils.events INFO:  eta: 1 day, 3:16:51  iter: 1079  total_loss: 11.5  loss_ce: 0  loss_mask: 0.2887  loss_dice: 0.8467  loss_seg: 0.6472  loss_ce_0: 0  loss_mask_0: 0.2802  loss_dice_0: 0.7967  loss_ce_1: 0  loss_mask_1: 0.2895  loss_dice_1: 0.7797  loss_ce_2: 0  loss_mask_2: 0.2899  loss_dice_2: 0.7792  loss_ce_3: 0  loss_mask_3: 0.2896  loss_dice_3: 0.7777  loss_ce_4: 0  loss_mask_4: 0.2904  loss_dice_4: 0.7787  loss_ce_5: 0  loss_mask_5: 0.2897  loss_dice_5: 0.7794  loss_ce_6: 0  loss_mask_6: 0.29  loss_dice_6: 0.7788  loss_ce_7: 0  loss_mask_7: 0.2898  loss_dice_7: 0.7791  loss_ce_8: 0  loss_mask_8: 0.2882  loss_dice_8: 0.7817  time: 1.6974  data_time: 0.0497  lr: 9.838e-05  max_mem: 5916M
[02/24 12:44:30] d2.utils.events INFO:  eta: 1 day, 3:15:39  iter: 1099  total_loss: 11.53  loss_ce: 0  loss_mask: 0.2786  loss_dice: 0.8554  loss_seg: 0.7341  loss_ce_0: 0  loss_mask_0: 0.2768  loss_dice_0: 0.8052  loss_ce_1: 0  loss_mask_1: 0.2802  loss_dice_1: 0.7895  loss_ce_2: 0  loss_mask_2: 0.2815  loss_dice_2: 0.787  loss_ce_3: 0  loss_mask_3: 0.2829  loss_dice_3: 0.785  loss_ce_4: 0  loss_mask_4: 0.2833  loss_dice_4: 0.7845  loss_ce_5: 0  loss_mask_5: 0.2846  loss_dice_5: 0.7847  loss_ce_6: 0  loss_mask_6: 0.2826  loss_dice_6: 0.7861  loss_ce_7: 0  loss_mask_7: 0.2826  loss_dice_7: 0.7877  loss_ce_8: 0  loss_mask_8: 0.2839  loss_dice_8: 0.7892  time: 1.6967  data_time: 0.0556  lr: 9.835e-05  max_mem: 5916M
[02/24 12:45:03] d2.utils.events INFO:  eta: 1 day, 3:16:50  iter: 1119  total_loss: 11.27  loss_ce: 0  loss_mask: 0.289  loss_dice: 0.8331  loss_seg: 0.6032  loss_ce_0: 0  loss_mask_0: 0.285  loss_dice_0: 0.7836  loss_ce_1: 0  loss_mask_1: 0.2879  loss_dice_1: 0.7653  loss_ce_2: 0  loss_mask_2: 0.2884  loss_dice_2: 0.7641  loss_ce_3: 0  loss_mask_3: 0.2871  loss_dice_3: 0.7638  loss_ce_4: 0  loss_mask_4: 0.2882  loss_dice_4: 0.7648  loss_ce_5: 0  loss_mask_5: 0.2903  loss_dice_5: 0.7662  loss_ce_6: 0  loss_mask_6: 0.2887  loss_dice_6: 0.7658  loss_ce_7: 0  loss_mask_7: 0.2894  loss_dice_7: 0.7648  loss_ce_8: 0  loss_mask_8: 0.2882  loss_dice_8: 0.7671  time: 1.6956  data_time: 0.0524  lr: 9.832e-05  max_mem: 5916M
[02/24 12:45:36] d2.utils.events INFO:  eta: 1 day, 3:18:47  iter: 1139  total_loss: 11.24  loss_ce: 0  loss_mask: 0.2797  loss_dice: 0.8409  loss_seg: 0.6258  loss_ce_0: 0  loss_mask_0: 0.2812  loss_dice_0: 0.7913  loss_ce_1: 0  loss_mask_1: 0.2841  loss_dice_1: 0.7718  loss_ce_2: 0  loss_mask_2: 0.2833  loss_dice_2: 0.7706  loss_ce_3: 0  loss_mask_3: 0.284  loss_dice_3: 0.7707  loss_ce_4: 0  loss_mask_4: 0.283  loss_dice_4: 0.7713  loss_ce_5: 0  loss_mask_5: 0.2819  loss_dice_5: 0.772  loss_ce_6: 0  loss_mask_6: 0.2831  loss_dice_6: 0.7717  loss_ce_7: 0  loss_mask_7: 0.284  loss_dice_7: 0.7718  loss_ce_8: 0  loss_mask_8: 0.2833  loss_dice_8: 0.7732  time: 1.6949  data_time: 0.0608  lr: 9.829e-05  max_mem: 5916M
[02/24 12:46:10] d2.utils.events INFO:  eta: 1 day, 3:12:57  iter: 1159  total_loss: 11.33  loss_ce: 0  loss_mask: 0.2884  loss_dice: 0.8281  loss_seg: 0.6396  loss_ce_0: 0  loss_mask_0: 0.2859  loss_dice_0: 0.7763  loss_ce_1: 0  loss_mask_1: 0.2918  loss_dice_1: 0.7622  loss_ce_2: 0  loss_mask_2: 0.29  loss_dice_2: 0.7609  loss_ce_3: 0  loss_mask_3: 0.2915  loss_dice_3: 0.7605  loss_ce_4: 0  loss_mask_4: 0.2911  loss_dice_4: 0.7618  loss_ce_5: 0  loss_mask_5: 0.2898  loss_dice_5: 0.7629  loss_ce_6: 0  loss_mask_6: 0.2912  loss_dice_6: 0.7637  loss_ce_7: 0  loss_mask_7: 0.2922  loss_dice_7: 0.7643  loss_ce_8: 0  loss_mask_8: 0.2947  loss_dice_8: 0.7656  time: 1.6946  data_time: 0.0515  lr: 9.826e-05  max_mem: 5916M
[02/24 12:46:43] d2.utils.events INFO:  eta: 1 day, 3:15:10  iter: 1179  total_loss: 11.48  loss_ce: 0  loss_mask: 0.2833  loss_dice: 0.8328  loss_seg: 0.7215  loss_ce_0: 0  loss_mask_0: 0.2833  loss_dice_0: 0.7888  loss_ce_1: 0  loss_mask_1: 0.2882  loss_dice_1: 0.7749  loss_ce_2: 0  loss_mask_2: 0.2869  loss_dice_2: 0.7768  loss_ce_3: 0  loss_mask_3: 0.2903  loss_dice_3: 0.7772  loss_ce_4: 0  loss_mask_4: 0.2913  loss_dice_4: 0.7774  loss_ce_5: 0  loss_mask_5: 0.2908  loss_dice_5: 0.7777  loss_ce_6: 0  loss_mask_6: 0.2899  loss_dice_6: 0.7782  loss_ce_7: 0  loss_mask_7: 0.2909  loss_dice_7: 0.7777  loss_ce_8: 0  loss_mask_8: 0.2888  loss_dice_8: 0.7782  time: 1.6940  data_time: 0.0486  lr: 9.823e-05  max_mem: 5916M
[02/24 12:47:16] d2.utils.events INFO:  eta: 1 day, 3:10:55  iter: 1199  total_loss: 11.2  loss_ce: 0  loss_mask: 0.2866  loss_dice: 0.8296  loss_seg: 0.6264  loss_ce_0: 0  loss_mask_0: 0.2802  loss_dice_0: 0.7842  loss_ce_1: 0  loss_mask_1: 0.2812  loss_dice_1: 0.7723  loss_ce_2: 0  loss_mask_2: 0.2823  loss_dice_2: 0.7731  loss_ce_3: 0  loss_mask_3: 0.2823  loss_dice_3: 0.7715  loss_ce_4: 0  loss_mask_4: 0.2822  loss_dice_4: 0.7704  loss_ce_5: 0  loss_mask_5: 0.2831  loss_dice_5: 0.7702  loss_ce_6: 0  loss_mask_6: 0.2808  loss_dice_6: 0.77  loss_ce_7: 0  loss_mask_7: 0.2818  loss_dice_7: 0.7709  loss_ce_8: 0  loss_mask_8: 0.2825  loss_dice_8: 0.7727  time: 1.6932  data_time: 0.0558  lr: 9.82e-05  max_mem: 5916M
[02/24 12:47:50] d2.utils.events INFO:  eta: 1 day, 3:06:40  iter: 1219  total_loss: 11.07  loss_ce: 0  loss_mask: 0.2918  loss_dice: 0.8202  loss_seg: 0.607  loss_ce_0: 0  loss_mask_0: 0.2839  loss_dice_0: 0.7797  loss_ce_1: 0  loss_mask_1: 0.2859  loss_dice_1: 0.76  loss_ce_2: 0  loss_mask_2: 0.2864  loss_dice_2: 0.7581  loss_ce_3: 0  loss_mask_3: 0.2869  loss_dice_3: 0.7575  loss_ce_4: 0  loss_mask_4: 0.2869  loss_dice_4: 0.7582  loss_ce_5: 0  loss_mask_5: 0.2871  loss_dice_5: 0.7577  loss_ce_6: 0  loss_mask_6: 0.2867  loss_dice_6: 0.7585  loss_ce_7: 0  loss_mask_7: 0.2869  loss_dice_7: 0.759  loss_ce_8: 0  loss_mask_8: 0.2861  loss_dice_8: 0.7609  time: 1.6931  data_time: 0.0614  lr: 9.817e-05  max_mem: 5916M
[02/24 12:48:23] d2.utils.events INFO:  eta: 1 day, 3:07:31  iter: 1239  total_loss: 11.43  loss_ce: 0  loss_mask: 0.2841  loss_dice: 0.8299  loss_seg: 0.6663  loss_ce_0: 0  loss_mask_0: 0.2815  loss_dice_0: 0.7826  loss_ce_1: 0  loss_mask_1: 0.2836  loss_dice_1: 0.7661  loss_ce_2: 0  loss_mask_2: 0.2825  loss_dice_2: 0.7657  loss_ce_3: 0  loss_mask_3: 0.2838  loss_dice_3: 0.7646  loss_ce_4: 0  loss_mask_4: 0.2839  loss_dice_4: 0.7679  loss_ce_5: 0  loss_mask_5: 0.2828  loss_dice_5: 0.7678  loss_ce_6: 0  loss_mask_6: 0.283  loss_dice_6: 0.7666  loss_ce_7: 0  loss_mask_7: 0.2833  loss_dice_7: 0.7668  loss_ce_8: 0  loss_mask_8: 0.2834  loss_dice_8: 0.7683  time: 1.6927  data_time: 0.0513  lr: 9.814e-05  max_mem: 5916M
[02/24 12:48:56] d2.utils.events INFO:  eta: 1 day, 3:06:57  iter: 1259  total_loss: 11.07  loss_ce: 0  loss_mask: 0.3004  loss_dice: 0.8102  loss_seg: 0.6569  loss_ce_0: 0  loss_mask_0: 0.2892  loss_dice_0: 0.7612  loss_ce_1: 0  loss_mask_1: 0.2925  loss_dice_1: 0.7387  loss_ce_2: 0  loss_mask_2: 0.2907  loss_dice_2: 0.7353  loss_ce_3: 0  loss_mask_3: 0.2926  loss_dice_3: 0.7369  loss_ce_4: 0  loss_mask_4: 0.2936  loss_dice_4: 0.7386  loss_ce_5: 0  loss_mask_5: 0.2938  loss_dice_5: 0.739  loss_ce_6: 0  loss_mask_6: 0.2926  loss_dice_6: 0.7409  loss_ce_7: 0  loss_mask_7: 0.294  loss_dice_7: 0.7403  loss_ce_8: 0  loss_mask_8: 0.294  loss_dice_8: 0.7428  time: 1.6919  data_time: 0.0600  lr: 9.811e-05  max_mem: 5916M
[02/24 12:49:28] d2.utils.events INFO:  eta: 1 day, 3:05:36  iter: 1279  total_loss: 11.19  loss_ce: 0  loss_mask: 0.2795  loss_dice: 0.8258  loss_seg: 0.6676  loss_ce_0: 0  loss_mask_0: 0.2763  loss_dice_0: 0.7783  loss_ce_1: 0  loss_mask_1: 0.2811  loss_dice_1: 0.7619  loss_ce_2: 0  loss_mask_2: 0.2809  loss_dice_2: 0.7593  loss_ce_3: 0  loss_mask_3: 0.2817  loss_dice_3: 0.7596  loss_ce_4: 0  loss_mask_4: 0.2812  loss_dice_4: 0.7597  loss_ce_5: 0  loss_mask_5: 0.2824  loss_dice_5: 0.7616  loss_ce_6: 0  loss_mask_6: 0.2817  loss_dice_6: 0.7615  loss_ce_7: 0  loss_mask_7: 0.2819  loss_dice_7: 0.7623  loss_ce_8: 0  loss_mask_8: 0.2817  loss_dice_8: 0.7636  time: 1.6899  data_time: 0.0587  lr: 9.8079e-05  max_mem: 5916M
[02/24 12:50:02] d2.utils.events INFO:  eta: 1 day, 3:08:08  iter: 1299  total_loss: 10.99  loss_ce: 0  loss_mask: 0.2876  loss_dice: 0.8124  loss_seg: 0.6589  loss_ce_0: 0  loss_mask_0: 0.2817  loss_dice_0: 0.7735  loss_ce_1: 0  loss_mask_1: 0.2858  loss_dice_1: 0.752  loss_ce_2: 0  loss_mask_2: 0.2851  loss_dice_2: 0.7489  loss_ce_3: 0  loss_mask_3: 0.2854  loss_dice_3: 0.7474  loss_ce_4: 0  loss_mask_4: 0.2835  loss_dice_4: 0.7471  loss_ce_5: 0  loss_mask_5: 0.2851  loss_dice_5: 0.7488  loss_ce_6: 0  loss_mask_6: 0.2843  loss_dice_6: 0.7505  loss_ce_7: 0  loss_mask_7: 0.2859  loss_dice_7: 0.7512  loss_ce_8: 0  loss_mask_8: 0.287  loss_dice_8: 0.7532  time: 1.6903  data_time: 0.0696  lr: 9.8049e-05  max_mem: 5916M
[02/24 12:50:36] d2.utils.events INFO:  eta: 1 day, 3:05:00  iter: 1319  total_loss: 11.02  loss_ce: 0  loss_mask: 0.2885  loss_dice: 0.8077  loss_seg: 0.5926  loss_ce_0: 0  loss_mask_0: 0.2881  loss_dice_0: 0.7658  loss_ce_1: 0  loss_mask_1: 0.2885  loss_dice_1: 0.75  loss_ce_2: 0  loss_mask_2: 0.2876  loss_dice_2: 0.7496  loss_ce_3: 0  loss_mask_3: 0.2897  loss_dice_3: 0.75  loss_ce_4: 0  loss_mask_4: 0.29  loss_dice_4: 0.7519  loss_ce_5: 0  loss_mask_5: 0.2903  loss_dice_5: 0.7517  loss_ce_6: 0  loss_mask_6: 0.2905  loss_dice_6: 0.752  loss_ce_7: 0  loss_mask_7: 0.2909  loss_dice_7: 0.7519  loss_ce_8: 0  loss_mask_8: 0.2891  loss_dice_8: 0.753  time: 1.6897  data_time: 0.0767  lr: 9.8019e-05  max_mem: 5916M
[02/24 12:51:09] d2.utils.events INFO:  eta: 1 day, 3:03:37  iter: 1339  total_loss: 11.07  loss_ce: 0  loss_mask: 0.292  loss_dice: 0.8009  loss_seg: 0.6318  loss_ce_0: 0  loss_mask_0: 0.2858  loss_dice_0: 0.7636  loss_ce_1: 0  loss_mask_1: 0.2912  loss_dice_1: 0.7483  loss_ce_2: 0  loss_mask_2: 0.2904  loss_dice_2: 0.7448  loss_ce_3: 0  loss_mask_3: 0.2908  loss_dice_3: 0.7469  loss_ce_4: 0  loss_mask_4: 0.2909  loss_dice_4: 0.7465  loss_ce_5: 0  loss_mask_5: 0.2896  loss_dice_5: 0.7466  loss_ce_6: 0  loss_mask_6: 0.2885  loss_dice_6: 0.7461  loss_ce_7: 0  loss_mask_7: 0.2896  loss_dice_7: 0.7472  loss_ce_8: 0  loss_mask_8: 0.292  loss_dice_8: 0.75  time: 1.6895  data_time: 0.0738  lr: 9.7989e-05  max_mem: 5916M
[02/24 12:51:44] d2.utils.events INFO:  eta: 1 day, 3:04:35  iter: 1359  total_loss: 11.03  loss_ce: 0  loss_mask: 0.2925  loss_dice: 0.7986  loss_seg: 0.6166  loss_ce_0: 0  loss_mask_0: 0.285  loss_dice_0: 0.7637  loss_ce_1: 0  loss_mask_1: 0.2892  loss_dice_1: 0.7477  loss_ce_2: 0  loss_mask_2: 0.2895  loss_dice_2: 0.7439  loss_ce_3: 0  loss_mask_3: 0.2918  loss_dice_3: 0.7437  loss_ce_4: 0  loss_mask_4: 0.29  loss_dice_4: 0.7428  loss_ce_5: 0  loss_mask_5: 0.2886  loss_dice_5: 0.7434  loss_ce_6: 0  loss_mask_6: 0.286  loss_dice_6: 0.7445  loss_ce_7: 0  loss_mask_7: 0.2856  loss_dice_7: 0.7469  loss_ce_8: 0  loss_mask_8: 0.2847  loss_dice_8: 0.7453  time: 1.6900  data_time: 0.0706  lr: 9.7959e-05  max_mem: 5916M
[02/24 12:52:18] d2.utils.events INFO:  eta: 1 day, 3:05:55  iter: 1379  total_loss: 10.89  loss_ce: 0  loss_mask: 0.2887  loss_dice: 0.8003  loss_seg: 0.6088  loss_ce_0: 0  loss_mask_0: 0.2796  loss_dice_0: 0.7648  loss_ce_1: 0  loss_mask_1: 0.283  loss_dice_1: 0.7442  loss_ce_2: 0  loss_mask_2: 0.2828  loss_dice_2: 0.7413  loss_ce_3: 0  loss_mask_3: 0.2807  loss_dice_3: 0.7409  loss_ce_4: 0  loss_mask_4: 0.2815  loss_dice_4: 0.7407  loss_ce_5: 0  loss_mask_5: 0.2837  loss_dice_5: 0.7397  loss_ce_6: 0  loss_mask_6: 0.2847  loss_dice_6: 0.7417  loss_ce_7: 0  loss_mask_7: 0.2839  loss_dice_7: 0.7409  loss_ce_8: 0  loss_mask_8: 0.2831  loss_dice_8: 0.745  time: 1.6902  data_time: 0.0695  lr: 9.7929e-05  max_mem: 5916M
[02/24 12:52:53] d2.utils.events INFO:  eta: 1 day, 3:07:58  iter: 1399  total_loss: 10.81  loss_ce: 0  loss_mask: 0.2777  loss_dice: 0.7982  loss_seg: 0.5756  loss_ce_0: 0  loss_mask_0: 0.2719  loss_dice_0: 0.7627  loss_ce_1: 0  loss_mask_1: 0.2799  loss_dice_1: 0.7424  loss_ce_2: 0  loss_mask_2: 0.2784  loss_dice_2: 0.737  loss_ce_3: 0  loss_mask_3: 0.278  loss_dice_3: 0.7378  loss_ce_4: 0  loss_mask_4: 0.2812  loss_dice_4: 0.738  loss_ce_5: 0  loss_mask_5: 0.2788  loss_dice_5: 0.7383  loss_ce_6: 0  loss_mask_6: 0.2789  loss_dice_6: 0.7424  loss_ce_7: 0  loss_mask_7: 0.2777  loss_dice_7: 0.7417  loss_ce_8: 0  loss_mask_8: 0.2771  loss_dice_8: 0.7418  time: 1.6908  data_time: 0.0632  lr: 9.7899e-05  max_mem: 5916M
[02/24 12:53:28] d2.utils.events INFO:  eta: 1 day, 3:08:30  iter: 1419  total_loss: 10.95  loss_ce: 0  loss_mask: 0.2904  loss_dice: 0.797  loss_seg: 0.6738  loss_ce_0: 0  loss_mask_0: 0.2836  loss_dice_0: 0.7631  loss_ce_1: 0  loss_mask_1: 0.2846  loss_dice_1: 0.7461  loss_ce_2: 0  loss_mask_2: 0.2851  loss_dice_2: 0.7451  loss_ce_3: 0  loss_mask_3: 0.2871  loss_dice_3: 0.7433  loss_ce_4: 0  loss_mask_4: 0.2851  loss_dice_4: 0.7449  loss_ce_5: 0  loss_mask_5: 0.287  loss_dice_5: 0.7465  loss_ce_6: 0  loss_mask_6: 0.2871  loss_dice_6: 0.7466  loss_ce_7: 0  loss_mask_7: 0.2865  loss_dice_7: 0.7465  loss_ce_8: 0  loss_mask_8: 0.2876  loss_dice_8: 0.7484  time: 1.6911  data_time: 0.0669  lr: 9.7869e-05  max_mem: 5916M
[02/24 12:54:01] d2.utils.events INFO:  eta: 1 day, 3:06:51  iter: 1439  total_loss: 10.77  loss_ce: 0  loss_mask: 0.273  loss_dice: 0.7953  loss_seg: 0.5981  loss_ce_0: 0  loss_mask_0: 0.2643  loss_dice_0: 0.7593  loss_ce_1: 0  loss_mask_1: 0.2674  loss_dice_1: 0.7371  loss_ce_2: 0  loss_mask_2: 0.2663  loss_dice_2: 0.7339  loss_ce_3: 0  loss_mask_3: 0.267  loss_dice_3: 0.7351  loss_ce_4: 0  loss_mask_4: 0.2688  loss_dice_4: 0.7345  loss_ce_5: 0  loss_mask_5: 0.267  loss_dice_5: 0.7351  loss_ce_6: 0  loss_mask_6: 0.2681  loss_dice_6: 0.736  loss_ce_7: 0  loss_mask_7: 0.2667  loss_dice_7: 0.7364  loss_ce_8: 0  loss_mask_8: 0.2666  loss_dice_8: 0.7368  time: 1.6910  data_time: 0.0654  lr: 9.7839e-05  max_mem: 5916M
[02/24 12:54:36] d2.utils.events INFO:  eta: 1 day, 3:09:54  iter: 1459  total_loss: 10.85  loss_ce: 0  loss_mask: 0.2948  loss_dice: 0.7821  loss_seg: 0.5543  loss_ce_0: 0  loss_mask_0: 0.2914  loss_dice_0: 0.7431  loss_ce_1: 0  loss_mask_1: 0.2967  loss_dice_1: 0.7244  loss_ce_2: 0  loss_mask_2: 0.2977  loss_dice_2: 0.7226  loss_ce_3: 0  loss_mask_3: 0.2978  loss_dice_3: 0.723  loss_ce_4: 0  loss_mask_4: 0.2972  loss_dice_4: 0.7247  loss_ce_5: 0  loss_mask_5: 0.2973  loss_dice_5: 0.7239  loss_ce_6: 0  loss_mask_6: 0.2988  loss_dice_6: 0.7247  loss_ce_7: 0  loss_mask_7: 0.2986  loss_dice_7: 0.725  loss_ce_8: 0  loss_mask_8: 0.2989  loss_dice_8: 0.7277  time: 1.6915  data_time: 0.0802  lr: 9.7809e-05  max_mem: 5916M
[02/24 12:55:11] d2.utils.events INFO:  eta: 1 day, 3:12:20  iter: 1479  total_loss: 10.85  loss_ce: 0  loss_mask: 0.2807  loss_dice: 0.782  loss_seg: 0.5834  loss_ce_0: 0  loss_mask_0: 0.2708  loss_dice_0: 0.7497  loss_ce_1: 0  loss_mask_1: 0.2736  loss_dice_1: 0.7336  loss_ce_2: 0  loss_mask_2: 0.273  loss_dice_2: 0.7325  loss_ce_3: 0  loss_mask_3: 0.2744  loss_dice_3: 0.7324  loss_ce_4: 0  loss_mask_4: 0.2742  loss_dice_4: 0.7311  loss_ce_5: 0  loss_mask_5: 0.2742  loss_dice_5: 0.7313  loss_ce_6: 0  loss_mask_6: 0.2745  loss_dice_6: 0.7342  loss_ce_7: 0  loss_mask_7: 0.2753  loss_dice_7: 0.7328  loss_ce_8: 0  loss_mask_8: 0.2765  loss_dice_8: 0.7334  time: 1.6918  data_time: 0.0686  lr: 9.7779e-05  max_mem: 5916M
[02/24 12:55:45] d2.utils.events INFO:  eta: 1 day, 3:12:41  iter: 1499  total_loss: 10.78  loss_ce: 0  loss_mask: 0.2768  loss_dice: 0.7774  loss_seg: 0.5571  loss_ce_0: 0  loss_mask_0: 0.2714  loss_dice_0: 0.7512  loss_ce_1: 0  loss_mask_1: 0.2733  loss_dice_1: 0.732  loss_ce_2: 0  loss_mask_2: 0.2744  loss_dice_2: 0.7286  loss_ce_3: 0  loss_mask_3: 0.2736  loss_dice_3: 0.7266  loss_ce_4: 0  loss_mask_4: 0.2725  loss_dice_4: 0.7275  loss_ce_5: 0  loss_mask_5: 0.2712  loss_dice_5: 0.7287  loss_ce_6: 0  loss_mask_6: 0.2741  loss_dice_6: 0.7279  loss_ce_7: 0  loss_mask_7: 0.2728  loss_dice_7: 0.7297  loss_ce_8: 0  loss_mask_8: 0.2727  loss_dice_8: 0.7306  time: 1.6923  data_time: 0.0533  lr: 9.7749e-05  max_mem: 5916M
[02/24 12:56:19] d2.utils.events INFO:  eta: 1 day, 3:13:48  iter: 1519  total_loss: 10.54  loss_ce: 0  loss_mask: 0.2704  loss_dice: 0.7809  loss_seg: 0.5707  loss_ce_0: 0  loss_mask_0: 0.2581  loss_dice_0: 0.7512  loss_ce_1: 0  loss_mask_1: 0.2631  loss_dice_1: 0.7263  loss_ce_2: 0  loss_mask_2: 0.2628  loss_dice_2: 0.7237  loss_ce_3: 0  loss_mask_3: 0.2637  loss_dice_3: 0.723  loss_ce_4: 0  loss_mask_4: 0.2631  loss_dice_4: 0.7227  loss_ce_5: 0  loss_mask_5: 0.2635  loss_dice_5: 0.7244  loss_ce_6: 0  loss_mask_6: 0.2643  loss_dice_6: 0.7241  loss_ce_7: 0  loss_mask_7: 0.2634  loss_dice_7: 0.7261  loss_ce_8: 0  loss_mask_8: 0.2623  loss_dice_8: 0.728  time: 1.6923  data_time: 0.0717  lr: 9.7719e-05  max_mem: 5916M
[02/24 12:56:53] d2.utils.events INFO:  eta: 1 day, 3:13:14  iter: 1539  total_loss: 10.6  loss_ce: 0  loss_mask: 0.27  loss_dice: 0.7719  loss_seg: 0.5495  loss_ce_0: 0  loss_mask_0: 0.262  loss_dice_0: 0.7434  loss_ce_1: 0  loss_mask_1: 0.2673  loss_dice_1: 0.7335  loss_ce_2: 0  loss_mask_2: 0.265  loss_dice_2: 0.7302  loss_ce_3: 0  loss_mask_3: 0.2641  loss_dice_3: 0.7283  loss_ce_4: 0  loss_mask_4: 0.2663  loss_dice_4: 0.7287  loss_ce_5: 0  loss_mask_5: 0.2666  loss_dice_5: 0.7302  loss_ce_6: 0  loss_mask_6: 0.2687  loss_dice_6: 0.733  loss_ce_7: 0  loss_mask_7: 0.2674  loss_dice_7: 0.7319  loss_ce_8: 0  loss_mask_8: 0.2685  loss_dice_8: 0.7324  time: 1.6921  data_time: 0.0758  lr: 9.7689e-05  max_mem: 5916M
[02/24 12:57:27] d2.utils.events INFO:  eta: 1 day, 3:13:20  iter: 1559  total_loss: 10.89  loss_ce: 0  loss_mask: 0.2871  loss_dice: 0.7675  loss_seg: 0.6476  loss_ce_0: 0  loss_mask_0: 0.2826  loss_dice_0: 0.7486  loss_ce_1: 0  loss_mask_1: 0.2847  loss_dice_1: 0.7259  loss_ce_2: 0  loss_mask_2: 0.2848  loss_dice_2: 0.7239  loss_ce_3: 0  loss_mask_3: 0.2851  loss_dice_3: 0.7239  loss_ce_4: 0  loss_mask_4: 0.2857  loss_dice_4: 0.7252  loss_ce_5: 0  loss_mask_5: 0.2884  loss_dice_5: 0.7276  loss_ce_6: 0  loss_mask_6: 0.2876  loss_dice_6: 0.7269  loss_ce_7: 0  loss_mask_7: 0.2859  loss_dice_7: 0.7288  loss_ce_8: 0  loss_mask_8: 0.2861  loss_dice_8: 0.7284  time: 1.6920  data_time: 0.0749  lr: 9.7658e-05  max_mem: 5916M
[02/24 12:58:02] d2.utils.events INFO:  eta: 1 day, 3:13:30  iter: 1579  total_loss: 10.68  loss_ce: 0  loss_mask: 0.2698  loss_dice: 0.7748  loss_seg: 0.5434  loss_ce_0: 0  loss_mask_0: 0.2636  loss_dice_0: 0.7534  loss_ce_1: 0  loss_mask_1: 0.2683  loss_dice_1: 0.7365  loss_ce_2: 0  loss_mask_2: 0.2675  loss_dice_2: 0.7349  loss_ce_3: 0  loss_mask_3: 0.2678  loss_dice_3: 0.7341  loss_ce_4: 0  loss_mask_4: 0.2678  loss_dice_4: 0.7347  loss_ce_5: 0  loss_mask_5: 0.2692  loss_dice_5: 0.7335  loss_ce_6: 0  loss_mask_6: 0.2684  loss_dice_6: 0.7344  loss_ce_7: 0  loss_mask_7: 0.2697  loss_dice_7: 0.7349  loss_ce_8: 0  loss_mask_8: 0.2673  loss_dice_8: 0.7355  time: 1.6928  data_time: 0.0721  lr: 9.7628e-05  max_mem: 5916M
[02/24 12:58:36] d2.utils.events INFO:  eta: 1 day, 3:12:43  iter: 1599  total_loss: 10.8  loss_ce: 0  loss_mask: 0.2753  loss_dice: 0.7787  loss_seg: 0.6005  loss_ce_0: 0  loss_mask_0: 0.268  loss_dice_0: 0.7596  loss_ce_1: 0  loss_mask_1: 0.2755  loss_dice_1: 0.7399  loss_ce_2: 0  loss_mask_2: 0.2774  loss_dice_2: 0.7382  loss_ce_3: 0  loss_mask_3: 0.2769  loss_dice_3: 0.7411  loss_ce_4: 0  loss_mask_4: 0.2726  loss_dice_4: 0.7439  loss_ce_5: 0  loss_mask_5: 0.2737  loss_dice_5: 0.7434  loss_ce_6: 0  loss_mask_6: 0.2734  loss_dice_6: 0.7422  loss_ce_7: 0  loss_mask_7: 0.2749  loss_dice_7: 0.7421  loss_ce_8: 0  loss_mask_8: 0.2773  loss_dice_8: 0.745  time: 1.6929  data_time: 0.0748  lr: 9.7598e-05  max_mem: 5916M
[02/24 12:59:11] d2.utils.events INFO:  eta: 1 day, 3:12:36  iter: 1619  total_loss: 10.78  loss_ce: 0  loss_mask: 0.2808  loss_dice: 0.7626  loss_seg: 0.6365  loss_ce_0: 0  loss_mask_0: 0.2718  loss_dice_0: 0.7414  loss_ce_1: 0  loss_mask_1: 0.2744  loss_dice_1: 0.7259  loss_ce_2: 0  loss_mask_2: 0.2742  loss_dice_2: 0.7232  loss_ce_3: 0  loss_mask_3: 0.2753  loss_dice_3: 0.7215  loss_ce_4: 0  loss_mask_4: 0.2755  loss_dice_4: 0.723  loss_ce_5: 0  loss_mask_5: 0.2766  loss_dice_5: 0.7243  loss_ce_6: 0  loss_mask_6: 0.2757  loss_dice_6: 0.7245  loss_ce_7: 0  loss_mask_7: 0.2753  loss_dice_7: 0.7268  loss_ce_8: 0  loss_mask_8: 0.2748  loss_dice_8: 0.7267  time: 1.6931  data_time: 0.0642  lr: 9.7568e-05  max_mem: 5916M
[02/24 12:59:45] d2.utils.events INFO:  eta: 1 day, 3:15:07  iter: 1639  total_loss: 10.61  loss_ce: 0  loss_mask: 0.2772  loss_dice: 0.766  loss_seg: 0.6012  loss_ce_0: 0  loss_mask_0: 0.2699  loss_dice_0: 0.7511  loss_ce_1: 0  loss_mask_1: 0.2731  loss_dice_1: 0.7367  loss_ce_2: 0  loss_mask_2: 0.2733  loss_dice_2: 0.734  loss_ce_3: 0  loss_mask_3: 0.2716  loss_dice_3: 0.7347  loss_ce_4: 0  loss_mask_4: 0.272  loss_dice_4: 0.7341  loss_ce_5: 0  loss_mask_5: 0.2727  loss_dice_5: 0.7341  loss_ce_6: 0  loss_mask_6: 0.2739  loss_dice_6: 0.7334  loss_ce_7: 0  loss_mask_7: 0.272  loss_dice_7: 0.7329  loss_ce_8: 0  loss_mask_8: 0.2735  loss_dice_8: 0.736  time: 1.6935  data_time: 0.0656  lr: 9.7538e-05  max_mem: 5916M
[02/24 13:00:19] d2.utils.events INFO:  eta: 1 day, 3:14:44  iter: 1659  total_loss: 10.29  loss_ce: 0  loss_mask: 0.2725  loss_dice: 0.7413  loss_seg: 0.5153  loss_ce_0: 0  loss_mask_0: 0.2648  loss_dice_0: 0.7268  loss_ce_1: 0  loss_mask_1: 0.2664  loss_dice_1: 0.7019  loss_ce_2: 0  loss_mask_2: 0.2665  loss_dice_2: 0.699  loss_ce_3: 0  loss_mask_3: 0.2666  loss_dice_3: 0.6963  loss_ce_4: 0  loss_mask_4: 0.2662  loss_dice_4: 0.6974  loss_ce_5: 0  loss_mask_5: 0.2672  loss_dice_5: 0.6953  loss_ce_6: 0  loss_mask_6: 0.2665  loss_dice_6: 0.6978  loss_ce_7: 0  loss_mask_7: 0.2657  loss_dice_7: 0.7003  loss_ce_8: 0  loss_mask_8: 0.2662  loss_dice_8: 0.7034  time: 1.6934  data_time: 0.0548  lr: 9.7508e-05  max_mem: 5916M
[02/24 13:00:54] d2.utils.events INFO:  eta: 1 day, 3:15:50  iter: 1679  total_loss: 10.42  loss_ce: 0  loss_mask: 0.272  loss_dice: 0.747  loss_seg: 0.5632  loss_ce_0: 0  loss_mask_0: 0.2684  loss_dice_0: 0.7285  loss_ce_1: 0  loss_mask_1: 0.2726  loss_dice_1: 0.7126  loss_ce_2: 0  loss_mask_2: 0.2716  loss_dice_2: 0.7098  loss_ce_3: 0  loss_mask_3: 0.2708  loss_dice_3: 0.709  loss_ce_4: 0  loss_mask_4: 0.2725  loss_dice_4: 0.7075  loss_ce_5: 0  loss_mask_5: 0.2713  loss_dice_5: 0.7076  loss_ce_6: 0  loss_mask_6: 0.2702  loss_dice_6: 0.7098  loss_ce_7: 0  loss_mask_7: 0.2708  loss_dice_7: 0.7104  loss_ce_8: 0  loss_mask_8: 0.2726  loss_dice_8: 0.7121  time: 1.6939  data_time: 0.0703  lr: 9.7478e-05  max_mem: 5916M
[02/24 13:01:28] d2.utils.events INFO:  eta: 1 day, 3:14:53  iter: 1699  total_loss: 10.28  loss_ce: 0  loss_mask: 0.2704  loss_dice: 0.7283  loss_seg: 0.4902  loss_ce_0: 0  loss_mask_0: 0.265  loss_dice_0: 0.7226  loss_ce_1: 0  loss_mask_1: 0.2671  loss_dice_1: 0.6996  loss_ce_2: 0  loss_mask_2: 0.2657  loss_dice_2: 0.696  loss_ce_3: 0  loss_mask_3: 0.2651  loss_dice_3: 0.6955  loss_ce_4: 0  loss_mask_4: 0.2664  loss_dice_4: 0.6964  loss_ce_5: 0  loss_mask_5: 0.2665  loss_dice_5: 0.6941  loss_ce_6: 0  loss_mask_6: 0.2663  loss_dice_6: 0.6952  loss_ce_7: 0  loss_mask_7: 0.2664  loss_dice_7: 0.6949  loss_ce_8: 0  loss_mask_8: 0.2666  loss_dice_8: 0.6963  time: 1.6939  data_time: 0.0718  lr: 9.7448e-05  max_mem: 5916M
[02/24 13:02:01] d2.utils.events INFO:  eta: 1 day, 3:15:17  iter: 1719  total_loss: 10.42  loss_ce: 0  loss_mask: 0.2726  loss_dice: 0.7363  loss_seg: 0.5299  loss_ce_0: 0  loss_mask_0: 0.2682  loss_dice_0: 0.7245  loss_ce_1: 0  loss_mask_1: 0.2751  loss_dice_1: 0.7055  loss_ce_2: 0  loss_mask_2: 0.277  loss_dice_2: 0.7033  loss_ce_3: 0  loss_mask_3: 0.2784  loss_dice_3: 0.702  loss_ce_4: 0  loss_mask_4: 0.2783  loss_dice_4: 0.7033  loss_ce_5: 0  loss_mask_5: 0.2776  loss_dice_5: 0.7041  loss_ce_6: 0  loss_mask_6: 0.2759  loss_dice_6: 0.7063  loss_ce_7: 0  loss_mask_7: 0.2778  loss_dice_7: 0.705  loss_ce_8: 0  loss_mask_8: 0.2781  loss_dice_8: 0.7081  time: 1.6931  data_time: 0.0485  lr: 9.7418e-05  max_mem: 5916M
[02/24 13:02:34] d2.utils.events INFO:  eta: 1 day, 3:14:17  iter: 1739  total_loss: 10.36  loss_ce: 0  loss_mask: 0.2692  loss_dice: 0.7317  loss_seg: 0.5474  loss_ce_0: 0  loss_mask_0: 0.2677  loss_dice_0: 0.722  loss_ce_1: 0  loss_mask_1: 0.2707  loss_dice_1: 0.7036  loss_ce_2: 0  loss_mask_2: 0.2692  loss_dice_2: 0.704  loss_ce_3: 0  loss_mask_3: 0.269  loss_dice_3: 0.7066  loss_ce_4: 0  loss_mask_4: 0.2696  loss_dice_4: 0.7086  loss_ce_5: 0  loss_mask_5: 0.2695  loss_dice_5: 0.7077  loss_ce_6: 0  loss_mask_6: 0.2678  loss_dice_6: 0.7087  loss_ce_7: 0  loss_mask_7: 0.2676  loss_dice_7: 0.7081  loss_ce_8: 0  loss_mask_8: 0.2702  loss_dice_8: 0.7063  time: 1.6926  data_time: 0.0566  lr: 9.7388e-05  max_mem: 5916M
[02/24 13:03:07] d2.utils.events INFO:  eta: 1 day, 3:14:01  iter: 1759  total_loss: 10.3  loss_ce: 0  loss_mask: 0.2734  loss_dice: 0.7244  loss_seg: 0.4918  loss_ce_0: 0  loss_mask_0: 0.2719  loss_dice_0: 0.7193  loss_ce_1: 0  loss_mask_1: 0.2742  loss_dice_1: 0.6991  loss_ce_2: 0  loss_mask_2: 0.2745  loss_dice_2: 0.6987  loss_ce_3: 0  loss_mask_3: 0.2745  loss_dice_3: 0.6976  loss_ce_4: 0  loss_mask_4: 0.2749  loss_dice_4: 0.6988  loss_ce_5: 0  loss_mask_5: 0.2763  loss_dice_5: 0.6992  loss_ce_6: 0  loss_mask_6: 0.2759  loss_dice_6: 0.6996  loss_ce_7: 0  loss_mask_7: 0.2761  loss_dice_7: 0.6982  loss_ce_8: 0  loss_mask_8: 0.276  loss_dice_8: 0.7  time: 1.6920  data_time: 0.0483  lr: 9.7358e-05  max_mem: 5916M
[02/24 13:03:40] d2.utils.events INFO:  eta: 1 day, 3:14:17  iter: 1779  total_loss: 10.46  loss_ce: 0  loss_mask: 0.2834  loss_dice: 0.7369  loss_seg: 0.5408  loss_ce_0: 0  loss_mask_0: 0.2689  loss_dice_0: 0.7302  loss_ce_1: 0  loss_mask_1: 0.2758  loss_dice_1: 0.7137  loss_ce_2: 0  loss_mask_2: 0.2777  loss_dice_2: 0.7139  loss_ce_3: 0  loss_mask_3: 0.2792  loss_dice_3: 0.7144  loss_ce_4: 0  loss_mask_4: 0.278  loss_dice_4: 0.7159  loss_ce_5: 0  loss_mask_5: 0.2772  loss_dice_5: 0.7169  loss_ce_6: 0  loss_mask_6: 0.2792  loss_dice_6: 0.7181  loss_ce_7: 0  loss_mask_7: 0.2783  loss_dice_7: 0.7162  loss_ce_8: 0  loss_mask_8: 0.2799  loss_dice_8: 0.7174  time: 1.6919  data_time: 0.0623  lr: 9.7328e-05  max_mem: 5916M
[02/24 13:04:14] d2.utils.events INFO:  eta: 1 day, 3:13:43  iter: 1799  total_loss: 10.14  loss_ce: 0  loss_mask: 0.2645  loss_dice: 0.7162  loss_seg: 0.498  loss_ce_0: 0  loss_mask_0: 0.2612  loss_dice_0: 0.7177  loss_ce_1: 0  loss_mask_1: 0.2618  loss_dice_1: 0.6977  loss_ce_2: 0  loss_mask_2: 0.2628  loss_dice_2: 0.6938  loss_ce_3: 0  loss_mask_3: 0.2631  loss_dice_3: 0.6932  loss_ce_4: 0  loss_mask_4: 0.263  loss_dice_4: 0.6943  loss_ce_5: 0  loss_mask_5: 0.2623  loss_dice_5: 0.6948  loss_ce_6: 0  loss_mask_6: 0.2654  loss_dice_6: 0.6958  loss_ce_7: 0  loss_mask_7: 0.2667  loss_dice_7: 0.697  loss_ce_8: 0  loss_mask_8: 0.2658  loss_dice_8: 0.6955  time: 1.6917  data_time: 0.0577  lr: 9.7297e-05  max_mem: 5916M
[02/24 13:04:47] d2.utils.events INFO:  eta: 1 day, 3:12:42  iter: 1819  total_loss: 10.15  loss_ce: 0  loss_mask: 0.265  loss_dice: 0.7146  loss_seg: 0.5109  loss_ce_0: 0  loss_mask_0: 0.2614  loss_dice_0: 0.7194  loss_ce_1: 0  loss_mask_1: 0.265  loss_dice_1: 0.6984  loss_ce_2: 0  loss_mask_2: 0.2654  loss_dice_2: 0.6949  loss_ce_3: 0  loss_mask_3: 0.2647  loss_dice_3: 0.6933  loss_ce_4: 0  loss_mask_4: 0.2656  loss_dice_4: 0.6935  loss_ce_5: 0  loss_mask_5: 0.2652  loss_dice_5: 0.6945  loss_ce_6: 0  loss_mask_6: 0.2644  loss_dice_6: 0.6947  loss_ce_7: 0  loss_mask_7: 0.264  loss_dice_7: 0.6944  loss_ce_8: 0  loss_mask_8: 0.2649  loss_dice_8: 0.6995  time: 1.6914  data_time: 0.0436  lr: 9.7267e-05  max_mem: 5916M
[02/24 13:05:22] d2.utils.events INFO:  eta: 1 day, 3:14:39  iter: 1839  total_loss: 10.22  loss_ce: 0  loss_mask: 0.2623  loss_dice: 0.7059  loss_seg: 0.4726  loss_ce_0: 0  loss_mask_0: 0.2641  loss_dice_0: 0.7086  loss_ce_1: 0  loss_mask_1: 0.265  loss_dice_1: 0.6928  loss_ce_2: 0  loss_mask_2: 0.2652  loss_dice_2: 0.6903  loss_ce_3: 0  loss_mask_3: 0.2657  loss_dice_3: 0.6914  loss_ce_4: 0  loss_mask_4: 0.2668  loss_dice_4: 0.6924  loss_ce_5: 0  loss_mask_5: 0.2675  loss_dice_5: 0.6909  loss_ce_6: 0  loss_mask_6: 0.2674  loss_dice_6: 0.6914  loss_ce_7: 0  loss_mask_7: 0.2689  loss_dice_7: 0.6916  loss_ce_8: 0  loss_mask_8: 0.2694  loss_dice_8: 0.6918  time: 1.6915  data_time: 0.0624  lr: 9.7237e-05  max_mem: 5916M
[02/24 13:05:56] d2.utils.events INFO:  eta: 1 day, 3:14:05  iter: 1859  total_loss: 10.05  loss_ce: 0  loss_mask: 0.2651  loss_dice: 0.7096  loss_seg: 0.4652  loss_ce_0: 0  loss_mask_0: 0.263  loss_dice_0: 0.7129  loss_ce_1: 0  loss_mask_1: 0.2649  loss_dice_1: 0.696  loss_ce_2: 0  loss_mask_2: 0.265  loss_dice_2: 0.6911  loss_ce_3: 0  loss_mask_3: 0.2645  loss_dice_3: 0.6909  loss_ce_4: 0  loss_mask_4: 0.2646  loss_dice_4: 0.6924  loss_ce_5: 0  loss_mask_5: 0.2653  loss_dice_5: 0.6929  loss_ce_6: 0  loss_mask_6: 0.2652  loss_dice_6: 0.6933  loss_ce_7: 0  loss_mask_7: 0.2659  loss_dice_7: 0.6934  loss_ce_8: 0  loss_mask_8: 0.267  loss_dice_8: 0.693  time: 1.6915  data_time: 0.0454  lr: 9.7207e-05  max_mem: 5916M
[02/24 13:06:29] d2.utils.events INFO:  eta: 1 day, 3:14:17  iter: 1879  total_loss: 10.26  loss_ce: 0  loss_mask: 0.2707  loss_dice: 0.7138  loss_seg: 0.491  loss_ce_0: 0  loss_mask_0: 0.2694  loss_dice_0: 0.7167  loss_ce_1: 0  loss_mask_1: 0.2707  loss_dice_1: 0.6996  loss_ce_2: 0  loss_mask_2: 0.2706  loss_dice_2: 0.7013  loss_ce_3: 0  loss_mask_3: 0.2706  loss_dice_3: 0.7017  loss_ce_4: 0  loss_mask_4: 0.2692  loss_dice_4: 0.7032  loss_ce_5: 0  loss_mask_5: 0.2697  loss_dice_5: 0.7035  loss_ce_6: 0  loss_mask_6: 0.2703  loss_dice_6: 0.7034  loss_ce_7: 0  loss_mask_7: 0.2711  loss_dice_7: 0.7046  loss_ce_8: 0  loss_mask_8: 0.2715  loss_dice_8: 0.7047  time: 1.6914  data_time: 0.0579  lr: 9.7177e-05  max_mem: 5916M
[02/24 13:07:02] d2.utils.events INFO:  eta: 1 day, 3:10:27  iter: 1899  total_loss: 10.19  loss_ce: 0  loss_mask: 0.2755  loss_dice: 0.7088  loss_seg: 0.4601  loss_ce_0: 0  loss_mask_0: 0.2723  loss_dice_0: 0.7142  loss_ce_1: 0  loss_mask_1: 0.2743  loss_dice_1: 0.6971  loss_ce_2: 0  loss_mask_2: 0.2726  loss_dice_2: 0.696  loss_ce_3: 0  loss_mask_3: 0.2723  loss_dice_3: 0.6948  loss_ce_4: 0  loss_mask_4: 0.2716  loss_dice_4: 0.6961  loss_ce_5: 0  loss_mask_5: 0.2732  loss_dice_5: 0.6962  loss_ce_6: 0  loss_mask_6: 0.2738  loss_dice_6: 0.6964  loss_ce_7: 0  loss_mask_7: 0.2738  loss_dice_7: 0.6961  loss_ce_8: 0  loss_mask_8: 0.2757  loss_dice_8: 0.698  time: 1.6905  data_time: 0.0450  lr: 9.7147e-05  max_mem: 5916M
[02/24 13:07:34] d2.utils.events INFO:  eta: 1 day, 3:09:53  iter: 1919  total_loss: 10.53  loss_ce: 0  loss_mask: 0.2608  loss_dice: 0.7372  loss_seg: 0.5624  loss_ce_0: 0  loss_mask_0: 0.2498  loss_dice_0: 0.7426  loss_ce_1: 0  loss_mask_1: 0.2595  loss_dice_1: 0.7237  loss_ce_2: 0  loss_mask_2: 0.26  loss_dice_2: 0.7216  loss_ce_3: 0  loss_mask_3: 0.2612  loss_dice_3: 0.7206  loss_ce_4: 0  loss_mask_4: 0.2621  loss_dice_4: 0.722  loss_ce_5: 0  loss_mask_5: 0.2622  loss_dice_5: 0.7224  loss_ce_6: 0  loss_mask_6: 0.2627  loss_dice_6: 0.7244  loss_ce_7: 0  loss_mask_7: 0.2632  loss_dice_7: 0.7243  loss_ce_8: 0  loss_mask_8: 0.2634  loss_dice_8: 0.7255  time: 1.6898  data_time: 0.0521  lr: 9.7117e-05  max_mem: 5916M
[02/24 13:08:09] d2.utils.events INFO:  eta: 1 day, 3:12:36  iter: 1939  total_loss: 10.1  loss_ce: 0  loss_mask: 0.2635  loss_dice: 0.7103  loss_seg: 0.4641  loss_ce_0: 0  loss_mask_0: 0.2601  loss_dice_0: 0.7145  loss_ce_1: 0  loss_mask_1: 0.2626  loss_dice_1: 0.6995  loss_ce_2: 0  loss_mask_2: 0.2618  loss_dice_2: 0.6949  loss_ce_3: 0  loss_mask_3: 0.2604  loss_dice_3: 0.6934  loss_ce_4: 0  loss_mask_4: 0.2605  loss_dice_4: 0.6919  loss_ce_5: 0  loss_mask_5: 0.2602  loss_dice_5: 0.6935  loss_ce_6: 0  loss_mask_6: 0.2619  loss_dice_6: 0.6954  loss_ce_7: 0  loss_mask_7: 0.2625  loss_dice_7: 0.6977  loss_ce_8: 0  loss_mask_8: 0.2631  loss_dice_8: 0.6986  time: 1.6900  data_time: 0.0530  lr: 9.7087e-05  max_mem: 5916M
[02/24 13:08:42] d2.utils.events INFO:  eta: 1 day, 3:12:31  iter: 1959  total_loss: 10.03  loss_ce: 0  loss_mask: 0.2603  loss_dice: 0.7162  loss_seg: 0.4489  loss_ce_0: 0  loss_mask_0: 0.2584  loss_dice_0: 0.7224  loss_ce_1: 0  loss_mask_1: 0.2585  loss_dice_1: 0.7048  loss_ce_2: 0  loss_mask_2: 0.2592  loss_dice_2: 0.7041  loss_ce_3: 0  loss_mask_3: 0.2606  loss_dice_3: 0.7044  loss_ce_4: 0  loss_mask_4: 0.2608  loss_dice_4: 0.7058  loss_ce_5: 0  loss_mask_5: 0.2611  loss_dice_5: 0.7054  loss_ce_6: 0  loss_mask_6: 0.2605  loss_dice_6: 0.7065  loss_ce_7: 0  loss_mask_7: 0.2602  loss_dice_7: 0.7055  loss_ce_8: 0  loss_mask_8: 0.2611  loss_dice_8: 0.7059  time: 1.6898  data_time: 0.0568  lr: 9.7057e-05  max_mem: 5916M
[02/24 13:09:14] d2.utils.events INFO:  eta: 1 day, 3:10:51  iter: 1979  total_loss: 9.992  loss_ce: 0  loss_mask: 0.2689  loss_dice: 0.6911  loss_seg: 0.4166  loss_ce_0: 0  loss_mask_0: 0.2672  loss_dice_0: 0.7033  loss_ce_1: 0  loss_mask_1: 0.2695  loss_dice_1: 0.6788  loss_ce_2: 0  loss_mask_2: 0.2699  loss_dice_2: 0.6791  loss_ce_3: 0  loss_mask_3: 0.2691  loss_dice_3: 0.6777  loss_ce_4: 0  loss_mask_4: 0.2688  loss_dice_4: 0.6796  loss_ce_5: 0  loss_mask_5: 0.2684  loss_dice_5: 0.6798  loss_ce_6: 0  loss_mask_6: 0.2691  loss_dice_6: 0.6813  loss_ce_7: 0  loss_mask_7: 0.2696  loss_dice_7: 0.6814  loss_ce_8: 0  loss_mask_8: 0.2704  loss_dice_8: 0.6816  time: 1.6890  data_time: 0.0557  lr: 9.7027e-05  max_mem: 5916M
[02/24 13:09:49] d2.utils.events INFO:  eta: 1 day, 3:10:55  iter: 1999  total_loss: 10.13  loss_ce: 0  loss_mask: 0.2599  loss_dice: 0.7178  loss_seg: 0.5034  loss_ce_0: 0  loss_mask_0: 0.2544  loss_dice_0: 0.7259  loss_ce_1: 0  loss_mask_1: 0.2543  loss_dice_1: 0.7079  loss_ce_2: 0  loss_mask_2: 0.2547  loss_dice_2: 0.7038  loss_ce_3: 0  loss_mask_3: 0.2559  loss_dice_3: 0.7033  loss_ce_4: 0  loss_mask_4: 0.2568  loss_dice_4: 0.7042  loss_ce_5: 0  loss_mask_5: 0.2579  loss_dice_5: 0.7043  loss_ce_6: 0  loss_mask_6: 0.259  loss_dice_6: 0.7071  loss_ce_7: 0  loss_mask_7: 0.2608  loss_dice_7: 0.7061  loss_ce_8: 0  loss_mask_8: 0.2597  loss_dice_8: 0.7077  time: 1.6892  data_time: 0.0583  lr: 9.6996e-05  max_mem: 5916M
[02/24 13:10:22] d2.utils.events INFO:  eta: 1 day, 3:08:20  iter: 2019  total_loss: 10.03  loss_ce: 0  loss_mask: 0.2605  loss_dice: 0.6995  loss_seg: 0.4797  loss_ce_0: 0  loss_mask_0: 0.2577  loss_dice_0: 0.7059  loss_ce_1: 0  loss_mask_1: 0.2619  loss_dice_1: 0.6871  loss_ce_2: 0  loss_mask_2: 0.2615  loss_dice_2: 0.6873  loss_ce_3: 0  loss_mask_3: 0.2607  loss_dice_3: 0.6875  loss_ce_4: 0  loss_mask_4: 0.2621  loss_dice_4: 0.6877  loss_ce_5: 0  loss_mask_5: 0.2624  loss_dice_5: 0.686  loss_ce_6: 0  loss_mask_6: 0.2615  loss_dice_6: 0.685  loss_ce_7: 0  loss_mask_7: 0.2617  loss_dice_7: 0.6866  loss_ce_8: 0  loss_mask_8: 0.2605  loss_dice_8: 0.6879  time: 1.6887  data_time: 0.0412  lr: 9.6966e-05  max_mem: 5916M
[02/24 13:10:54] d2.utils.events INFO:  eta: 1 day, 3:06:02  iter: 2039  total_loss: 9.921  loss_ce: 0  loss_mask: 0.2651  loss_dice: 0.6966  loss_seg: 0.4524  loss_ce_0: 0  loss_mask_0: 0.2581  loss_dice_0: 0.7065  loss_ce_1: 0  loss_mask_1: 0.2601  loss_dice_1: 0.6847  loss_ce_2: 0  loss_mask_2: 0.2609  loss_dice_2: 0.6817  loss_ce_3: 0  loss_mask_3: 0.2613  loss_dice_3: 0.6814  loss_ce_4: 0  loss_mask_4: 0.262  loss_dice_4: 0.6822  loss_ce_5: 0  loss_mask_5: 0.2624  loss_dice_5: 0.6841  loss_ce_6: 0  loss_mask_6: 0.2622  loss_dice_6: 0.6831  loss_ce_7: 0  loss_mask_7: 0.2629  loss_dice_7: 0.6835  loss_ce_8: 0  loss_mask_8: 0.2633  loss_dice_8: 0.6843  time: 1.6881  data_time: 0.0534  lr: 9.6936e-05  max_mem: 5916M
[02/24 13:11:28] d2.utils.events INFO:  eta: 1 day, 3:05:48  iter: 2059  total_loss: 9.878  loss_ce: 0  loss_mask: 0.2679  loss_dice: 0.6782  loss_seg: 0.4221  loss_ce_0: 0  loss_mask_0: 0.262  loss_dice_0: 0.6995  loss_ce_1: 0  loss_mask_1: 0.2651  loss_dice_1: 0.6723  loss_ce_2: 0  loss_mask_2: 0.2654  loss_dice_2: 0.67  loss_ce_3: 0  loss_mask_3: 0.2672  loss_dice_3: 0.6683  loss_ce_4: 0  loss_mask_4: 0.2663  loss_dice_4: 0.6683  loss_ce_5: 0  loss_mask_5: 0.2664  loss_dice_5: 0.6686  loss_ce_6: 0  loss_mask_6: 0.2652  loss_dice_6: 0.6694  loss_ce_7: 0  loss_mask_7: 0.2654  loss_dice_7: 0.6697  loss_ce_8: 0  loss_mask_8: 0.2662  loss_dice_8: 0.6705  time: 1.6878  data_time: 0.0442  lr: 9.6906e-05  max_mem: 5916M
[02/24 13:12:01] d2.utils.events INFO:  eta: 1 day, 3:04:55  iter: 2079  total_loss: 9.863  loss_ce: 0  loss_mask: 0.2572  loss_dice: 0.688  loss_seg: 0.4871  loss_ce_0: 0  loss_mask_0: 0.2539  loss_dice_0: 0.6975  loss_ce_1: 0  loss_mask_1: 0.2545  loss_dice_1: 0.6754  loss_ce_2: 0  loss_mask_2: 0.2558  loss_dice_2: 0.6731  loss_ce_3: 0  loss_mask_3: 0.2541  loss_dice_3: 0.6722  loss_ce_4: 0  loss_mask_4: 0.253  loss_dice_4: 0.6719  loss_ce_5: 0  loss_mask_5: 0.2546  loss_dice_5: 0.6731  loss_ce_6: 0  loss_mask_6: 0.2566  loss_dice_6: 0.675  loss_ce_7: 0  loss_mask_7: 0.2554  loss_dice_7: 0.6741  loss_ce_8: 0  loss_mask_8: 0.2556  loss_dice_8: 0.675  time: 1.6875  data_time: 0.0525  lr: 9.6876e-05  max_mem: 5916M
[02/24 13:12:34] d2.utils.events INFO:  eta: 1 day, 3:04:11  iter: 2099  total_loss: 10  loss_ce: 0  loss_mask: 0.2654  loss_dice: 0.6775  loss_seg: 0.4372  loss_ce_0: 0  loss_mask_0: 0.2627  loss_dice_0: 0.6907  loss_ce_1: 0  loss_mask_1: 0.2656  loss_dice_1: 0.6689  loss_ce_2: 0  loss_mask_2: 0.2636  loss_dice_2: 0.6691  loss_ce_3: 0  loss_mask_3: 0.2634  loss_dice_3: 0.6681  loss_ce_4: 0  loss_mask_4: 0.2656  loss_dice_4: 0.6678  loss_ce_5: 0  loss_mask_5: 0.2667  loss_dice_5: 0.668  loss_ce_6: 0  loss_mask_6: 0.2667  loss_dice_6: 0.6684  loss_ce_7: 0  loss_mask_7: 0.2677  loss_dice_7: 0.6684  loss_ce_8: 0  loss_mask_8: 0.2682  loss_dice_8: 0.67  time: 1.6873  data_time: 0.0648  lr: 9.6846e-05  max_mem: 5916M
[02/24 13:13:08] d2.utils.events INFO:  eta: 1 day, 3:03:38  iter: 2119  total_loss: 9.721  loss_ce: 0  loss_mask: 0.2569  loss_dice: 0.6884  loss_seg: 0.4414  loss_ce_0: 0  loss_mask_0: 0.2495  loss_dice_0: 0.6988  loss_ce_1: 0  loss_mask_1: 0.2551  loss_dice_1: 0.6799  loss_ce_2: 0  loss_mask_2: 0.2554  loss_dice_2: 0.679  loss_ce_3: 0  loss_mask_3: 0.2555  loss_dice_3: 0.6772  loss_ce_4: 0  loss_mask_4: 0.2557  loss_dice_4: 0.6775  loss_ce_5: 0  loss_mask_5: 0.2575  loss_dice_5: 0.6774  loss_ce_6: 0  loss_mask_6: 0.2563  loss_dice_6: 0.6781  loss_ce_7: 0  loss_mask_7: 0.2572  loss_dice_7: 0.6788  loss_ce_8: 0  loss_mask_8: 0.2578  loss_dice_8: 0.6794  time: 1.6873  data_time: 0.0519  lr: 9.6816e-05  max_mem: 5916M
[02/24 13:13:41] d2.utils.events INFO:  eta: 1 day, 3:01:07  iter: 2139  total_loss: 9.921  loss_ce: 0  loss_mask: 0.2674  loss_dice: 0.6868  loss_seg: 0.4538  loss_ce_0: 0  loss_mask_0: 0.2627  loss_dice_0: 0.6935  loss_ce_1: 0  loss_mask_1: 0.2659  loss_dice_1: 0.6796  loss_ce_2: 0  loss_mask_2: 0.2651  loss_dice_2: 0.6777  loss_ce_3: 0  loss_mask_3: 0.266  loss_dice_3: 0.6772  loss_ce_4: 0  loss_mask_4: 0.2656  loss_dice_4: 0.6772  loss_ce_5: 0  loss_mask_5: 0.267  loss_dice_5: 0.6775  loss_ce_6: 0  loss_mask_6: 0.2668  loss_dice_6: 0.6778  loss_ce_7: 0  loss_mask_7: 0.2681  loss_dice_7: 0.679  loss_ce_8: 0  loss_mask_8: 0.267  loss_dice_8: 0.6812  time: 1.6869  data_time: 0.0551  lr: 9.6786e-05  max_mem: 5916M
[02/24 13:14:15] d2.utils.events INFO:  eta: 1 day, 3:02:22  iter: 2159  total_loss: 9.802  loss_ce: 0  loss_mask: 0.2603  loss_dice: 0.6873  loss_seg: 0.4279  loss_ce_0: 0  loss_mask_0: 0.253  loss_dice_0: 0.6946  loss_ce_1: 0  loss_mask_1: 0.2546  loss_dice_1: 0.68  loss_ce_2: 0  loss_mask_2: 0.2535  loss_dice_2: 0.6804  loss_ce_3: 0  loss_mask_3: 0.2547  loss_dice_3: 0.6788  loss_ce_4: 0  loss_mask_4: 0.2548  loss_dice_4: 0.6796  loss_ce_5: 0  loss_mask_5: 0.2531  loss_dice_5: 0.681  loss_ce_6: 0  loss_mask_6: 0.2538  loss_dice_6: 0.6817  loss_ce_7: 0  loss_mask_7: 0.256  loss_dice_7: 0.6826  loss_ce_8: 0  loss_mask_8: 0.2547  loss_dice_8: 0.6823  time: 1.6869  data_time: 0.0554  lr: 9.6756e-05  max_mem: 5916M
[02/24 13:14:49] d2.utils.events INFO:  eta: 1 day, 3:02:07  iter: 2179  total_loss: 10.05  loss_ce: 0  loss_mask: 0.2562  loss_dice: 0.7056  loss_seg: 0.4764  loss_ce_0: 0  loss_mask_0: 0.2481  loss_dice_0: 0.712  loss_ce_1: 0  loss_mask_1: 0.2528  loss_dice_1: 0.6939  loss_ce_2: 0  loss_mask_2: 0.2535  loss_dice_2: 0.6924  loss_ce_3: 0  loss_mask_3: 0.2537  loss_dice_3: 0.692  loss_ce_4: 0  loss_mask_4: 0.2539  loss_dice_4: 0.6933  loss_ce_5: 0  loss_mask_5: 0.2539  loss_dice_5: 0.6949  loss_ce_6: 0  loss_mask_6: 0.254  loss_dice_6: 0.6938  loss_ce_7: 0  loss_mask_7: 0.2543  loss_dice_7: 0.696  loss_ce_8: 0  loss_mask_8: 0.2533  loss_dice_8: 0.699  time: 1.6869  data_time: 0.0558  lr: 9.6725e-05  max_mem: 5916M
[02/24 13:15:22] d2.utils.events INFO:  eta: 1 day, 3:01:15  iter: 2199  total_loss: 10.02  loss_ce: 0  loss_mask: 0.2749  loss_dice: 0.6804  loss_seg: 0.4197  loss_ce_0: 0  loss_mask_0: 0.2696  loss_dice_0: 0.6852  loss_ce_1: 0  loss_mask_1: 0.2728  loss_dice_1: 0.6721  loss_ce_2: 0  loss_mask_2: 0.2714  loss_dice_2: 0.6715  loss_ce_3: 0  loss_mask_3: 0.2711  loss_dice_3: 0.6718  loss_ce_4: 0  loss_mask_4: 0.2719  loss_dice_4: 0.6733  loss_ce_5: 0  loss_mask_5: 0.2717  loss_dice_5: 0.6735  loss_ce_6: 0  loss_mask_6: 0.2726  loss_dice_6: 0.6739  loss_ce_7: 0  loss_mask_7: 0.2747  loss_dice_7: 0.6734  loss_ce_8: 0  loss_mask_8: 0.2738  loss_dice_8: 0.6748  time: 1.6867  data_time: 0.0722  lr: 9.6695e-05  max_mem: 5916M
[02/24 13:15:56] d2.utils.events INFO:  eta: 1 day, 3:00:08  iter: 2219  total_loss: 9.789  loss_ce: 0  loss_mask: 0.267  loss_dice: 0.6776  loss_seg: 0.4137  loss_ce_0: 0  loss_mask_0: 0.2601  loss_dice_0: 0.685  loss_ce_1: 0  loss_mask_1: 0.2637  loss_dice_1: 0.6728  loss_ce_2: 0  loss_mask_2: 0.2638  loss_dice_2: 0.671  loss_ce_3: 0  loss_mask_3: 0.2627  loss_dice_3: 0.6701  loss_ce_4: 0  loss_mask_4: 0.2643  loss_dice_4: 0.6701  loss_ce_5: 0  loss_mask_5: 0.2642  loss_dice_5: 0.671  loss_ce_6: 0  loss_mask_6: 0.2647  loss_dice_6: 0.6709  loss_ce_7: 0  loss_mask_7: 0.2637  loss_dice_7: 0.669  loss_ce_8: 0  loss_mask_8: 0.266  loss_dice_8: 0.6694  time: 1.6864  data_time: 0.0566  lr: 9.6665e-05  max_mem: 5916M
[02/24 13:16:29] d2.utils.events INFO:  eta: 1 day, 2:59:16  iter: 2239  total_loss: 9.873  loss_ce: 0  loss_mask: 0.2504  loss_dice: 0.6937  loss_seg: 0.4664  loss_ce_0: 0  loss_mask_0: 0.2467  loss_dice_0: 0.7062  loss_ce_1: 0  loss_mask_1: 0.2507  loss_dice_1: 0.6869  loss_ce_2: 0  loss_mask_2: 0.2502  loss_dice_2: 0.6837  loss_ce_3: 0  loss_mask_3: 0.2503  loss_dice_3: 0.6826  loss_ce_4: 0  loss_mask_4: 0.2511  loss_dice_4: 0.6827  loss_ce_5: 0  loss_mask_5: 0.2513  loss_dice_5: 0.684  loss_ce_6: 0  loss_mask_6: 0.2504  loss_dice_6: 0.6853  loss_ce_7: 0  loss_mask_7: 0.2525  loss_dice_7: 0.6863  loss_ce_8: 0  loss_mask_8: 0.2515  loss_dice_8: 0.6863  time: 1.6860  data_time: 0.0546  lr: 9.6635e-05  max_mem: 5916M
[02/24 13:17:01] d2.utils.events INFO:  eta: 1 day, 2:58:30  iter: 2259  total_loss: 9.504  loss_ce: 0  loss_mask: 0.2519  loss_dice: 0.6583  loss_seg: 0.4344  loss_ce_0: 0  loss_mask_0: 0.2521  loss_dice_0: 0.6739  loss_ce_1: 0  loss_mask_1: 0.2528  loss_dice_1: 0.6526  loss_ce_2: 0  loss_mask_2: 0.2526  loss_dice_2: 0.6516  loss_ce_3: 0  loss_mask_3: 0.2526  loss_dice_3: 0.6493  loss_ce_4: 0  loss_mask_4: 0.2533  loss_dice_4: 0.6496  loss_ce_5: 0  loss_mask_5: 0.2523  loss_dice_5: 0.6507  loss_ce_6: 0  loss_mask_6: 0.2532  loss_dice_6: 0.6512  loss_ce_7: 0  loss_mask_7: 0.2539  loss_dice_7: 0.6528  loss_ce_8: 0  loss_mask_8: 0.2527  loss_dice_8: 0.6529  time: 1.6854  data_time: 0.0576  lr: 9.6605e-05  max_mem: 5916M
[02/24 13:17:36] d2.utils.events INFO:  eta: 1 day, 2:58:27  iter: 2279  total_loss: 9.691  loss_ce: 0  loss_mask: 0.2613  loss_dice: 0.6672  loss_seg: 0.4203  loss_ce_0: 0  loss_mask_0: 0.2558  loss_dice_0: 0.6759  loss_ce_1: 0  loss_mask_1: 0.2601  loss_dice_1: 0.6585  loss_ce_2: 0  loss_mask_2: 0.2602  loss_dice_2: 0.6583  loss_ce_3: 0  loss_mask_3: 0.2613  loss_dice_3: 0.6587  loss_ce_4: 0  loss_mask_4: 0.2605  loss_dice_4: 0.6605  loss_ce_5: 0  loss_mask_5: 0.2622  loss_dice_5: 0.6604  loss_ce_6: 0  loss_mask_6: 0.2621  loss_dice_6: 0.6607  loss_ce_7: 0  loss_mask_7: 0.2621  loss_dice_7: 0.6633  loss_ce_8: 0  loss_mask_8: 0.2624  loss_dice_8: 0.6633  time: 1.6856  data_time: 0.0500  lr: 9.6575e-05  max_mem: 5916M
[02/24 13:18:09] d2.utils.events INFO:  eta: 1 day, 2:56:37  iter: 2299  total_loss: 9.481  loss_ce: 0  loss_mask: 0.251  loss_dice: 0.6595  loss_seg: 0.4135  loss_ce_0: 0  loss_mask_0: 0.2439  loss_dice_0: 0.6809  loss_ce_1: 0  loss_mask_1: 0.2506  loss_dice_1: 0.6557  loss_ce_2: 0  loss_mask_2: 0.2507  loss_dice_2: 0.6533  loss_ce_3: 0  loss_mask_3: 0.2502  loss_dice_3: 0.6515  loss_ce_4: 0  loss_mask_4: 0.2505  loss_dice_4: 0.6506  loss_ce_5: 0  loss_mask_5: 0.2502  loss_dice_5: 0.6537  loss_ce_6: 0  loss_mask_6: 0.2508  loss_dice_6: 0.6524  loss_ce_7: 0  loss_mask_7: 0.2513  loss_dice_7: 0.6536  loss_ce_8: 0  loss_mask_8: 0.251  loss_dice_8: 0.6552  time: 1.6854  data_time: 0.0514  lr: 9.6545e-05  max_mem: 5916M
[02/24 13:18:43] d2.utils.events INFO:  eta: 1 day, 2:56:04  iter: 2319  total_loss: 9.527  loss_ce: 0  loss_mask: 0.2627  loss_dice: 0.6616  loss_seg: 0.4296  loss_ce_0: 0  loss_mask_0: 0.2522  loss_dice_0: 0.6784  loss_ce_1: 0  loss_mask_1: 0.2561  loss_dice_1: 0.6571  loss_ce_2: 0  loss_mask_2: 0.2563  loss_dice_2: 0.652  loss_ce_3: 0  loss_mask_3: 0.2571  loss_dice_3: 0.6523  loss_ce_4: 0  loss_mask_4: 0.2574  loss_dice_4: 0.6523  loss_ce_5: 0  loss_mask_5: 0.2564  loss_dice_5: 0.6534  loss_ce_6: 0  loss_mask_6: 0.2571  loss_dice_6: 0.6555  loss_ce_7: 0  loss_mask_7: 0.2605  loss_dice_7: 0.6558  loss_ce_8: 0  loss_mask_8: 0.2622  loss_dice_8: 0.6564  time: 1.6854  data_time: 0.0622  lr: 9.6515e-05  max_mem: 5916M
[02/24 13:19:14] d2.utils.events INFO:  eta: 1 day, 2:53:32  iter: 2339  total_loss: 9.592  loss_ce: 0  loss_mask: 0.2613  loss_dice: 0.6613  loss_seg: 0.4151  loss_ce_0: 0  loss_mask_0: 0.2545  loss_dice_0: 0.6793  loss_ce_1: 0  loss_mask_1: 0.257  loss_dice_1: 0.658  loss_ce_2: 0  loss_mask_2: 0.256  loss_dice_2: 0.6555  loss_ce_3: 0  loss_mask_3: 0.2567  loss_dice_3: 0.6545  loss_ce_4: 0  loss_mask_4: 0.2561  loss_dice_4: 0.6548  loss_ce_5: 0  loss_mask_5: 0.2575  loss_dice_5: 0.656  loss_ce_6: 0  loss_mask_6: 0.2575  loss_dice_6: 0.6567  loss_ce_7: 0  loss_mask_7: 0.2575  loss_dice_7: 0.6558  loss_ce_8: 0  loss_mask_8: 0.2585  loss_dice_8: 0.6561  time: 1.6845  data_time: 0.0593  lr: 9.6485e-05  max_mem: 5916M
[02/24 13:19:49] d2.utils.events INFO:  eta: 1 day, 2:51:59  iter: 2359  total_loss: 9.428  loss_ce: 0  loss_mask: 0.2564  loss_dice: 0.6684  loss_seg: 0.3913  loss_ce_0: 0  loss_mask_0: 0.2504  loss_dice_0: 0.6821  loss_ce_1: 0  loss_mask_1: 0.253  loss_dice_1: 0.6604  loss_ce_2: 0  loss_mask_2: 0.251  loss_dice_2: 0.6575  loss_ce_3: 0  loss_mask_3: 0.2535  loss_dice_3: 0.6555  loss_ce_4: 0  loss_mask_4: 0.2537  loss_dice_4: 0.6569  loss_ce_5: 0  loss_mask_5: 0.2536  loss_dice_5: 0.6574  loss_ce_6: 0  loss_mask_6: 0.253  loss_dice_6: 0.6581  loss_ce_7: 0  loss_mask_7: 0.2554  loss_dice_7: 0.6592  loss_ce_8: 0  loss_mask_8: 0.257  loss_dice_8: 0.6615  time: 1.6849  data_time: 0.0624  lr: 9.6454e-05  max_mem: 5916M
[02/24 13:20:23] d2.utils.events INFO:  eta: 1 day, 2:48:41  iter: 2379  total_loss: 9.389  loss_ce: 0  loss_mask: 0.259  loss_dice: 0.6464  loss_seg: 0.3795  loss_ce_0: 0  loss_mask_0: 0.2532  loss_dice_0: 0.6638  loss_ce_1: 0  loss_mask_1: 0.2559  loss_dice_1: 0.6388  loss_ce_2: 0  loss_mask_2: 0.2548  loss_dice_2: 0.6378  loss_ce_3: 0  loss_mask_3: 0.2555  loss_dice_3: 0.6345  loss_ce_4: 0  loss_mask_4: 0.2567  loss_dice_4: 0.6364  loss_ce_5: 0  loss_mask_5: 0.2569  loss_dice_5: 0.6381  loss_ce_6: 0  loss_mask_6: 0.2582  loss_dice_6: 0.6385  loss_ce_7: 0  loss_mask_7: 0.2596  loss_dice_7: 0.6396  loss_ce_8: 0  loss_mask_8: 0.2578  loss_dice_8: 0.6402  time: 1.6850  data_time: 0.0579  lr: 9.6424e-05  max_mem: 5916M
[02/24 13:20:58] d2.utils.events INFO:  eta: 1 day, 2:47:58  iter: 2399  total_loss: 9.626  loss_ce: 0  loss_mask: 0.2534  loss_dice: 0.6614  loss_seg: 0.4226  loss_ce_0: 0  loss_mask_0: 0.2486  loss_dice_0: 0.6778  loss_ce_1: 0  loss_mask_1: 0.2482  loss_dice_1: 0.6554  loss_ce_2: 0  loss_mask_2: 0.2506  loss_dice_2: 0.6522  loss_ce_3: 0  loss_mask_3: 0.252  loss_dice_3: 0.6524  loss_ce_4: 0  loss_mask_4: 0.2525  loss_dice_4: 0.652  loss_ce_5: 0  loss_mask_5: 0.2523  loss_dice_5: 0.6517  loss_ce_6: 0  loss_mask_6: 0.252  loss_dice_6: 0.6534  loss_ce_7: 0  loss_mask_7: 0.2518  loss_dice_7: 0.6525  loss_ce_8: 0  loss_mask_8: 0.2514  loss_dice_8: 0.653  time: 1.6852  data_time: 0.0621  lr: 9.6394e-05  max_mem: 5916M
[02/24 13:21:30] d2.utils.events INFO:  eta: 1 day, 2:45:13  iter: 2419  total_loss: 9.549  loss_ce: 0  loss_mask: 0.2548  loss_dice: 0.6537  loss_seg: 0.4046  loss_ce_0: 0  loss_mask_0: 0.255  loss_dice_0: 0.6734  loss_ce_1: 0  loss_mask_1: 0.2566  loss_dice_1: 0.651  loss_ce_2: 0  loss_mask_2: 0.2563  loss_dice_2: 0.6504  loss_ce_3: 0  loss_mask_3: 0.2561  loss_dice_3: 0.6478  loss_ce_4: 0  loss_mask_4: 0.2557  loss_dice_4: 0.6487  loss_ce_5: 0  loss_mask_5: 0.2551  loss_dice_5: 0.6486  loss_ce_6: 0  loss_mask_6: 0.2542  loss_dice_6: 0.648  loss_ce_7: 0  loss_mask_7: 0.2544  loss_dice_7: 0.6495  loss_ce_8: 0  loss_mask_8: 0.2554  loss_dice_8: 0.6499  time: 1.6848  data_time: 0.0624  lr: 9.6364e-05  max_mem: 5916M
[02/24 13:22:04] d2.utils.events INFO:  eta: 1 day, 2:44:18  iter: 2439  total_loss: 9.569  loss_ce: 0  loss_mask: 0.2563  loss_dice: 0.6619  loss_seg: 0.4051  loss_ce_0: 0  loss_mask_0: 0.2509  loss_dice_0: 0.673  loss_ce_1: 0  loss_mask_1: 0.2549  loss_dice_1: 0.6581  loss_ce_2: 0  loss_mask_2: 0.256  loss_dice_2: 0.6566  loss_ce_3: 0  loss_mask_3: 0.2556  loss_dice_3: 0.6555  loss_ce_4: 0  loss_mask_4: 0.2543  loss_dice_4: 0.6572  loss_ce_5: 0  loss_mask_5: 0.2556  loss_dice_5: 0.6566  loss_ce_6: 0  loss_mask_6: 0.2544  loss_dice_6: 0.6575  loss_ce_7: 0  loss_mask_7: 0.2547  loss_dice_7: 0.6576  loss_ce_8: 0  loss_mask_8: 0.2562  loss_dice_8: 0.6577  time: 1.6848  data_time: 0.0552  lr: 9.6334e-05  max_mem: 5916M
[02/24 13:22:39] d2.utils.events INFO:  eta: 1 day, 2:43:17  iter: 2459  total_loss: 9.59  loss_ce: 0  loss_mask: 0.2526  loss_dice: 0.6678  loss_seg: 0.4571  loss_ce_0: 0  loss_mask_0: 0.253  loss_dice_0: 0.6776  loss_ce_1: 0  loss_mask_1: 0.2556  loss_dice_1: 0.6611  loss_ce_2: 0  loss_mask_2: 0.2547  loss_dice_2: 0.6588  loss_ce_3: 0  loss_mask_3: 0.2552  loss_dice_3: 0.6586  loss_ce_4: 0  loss_mask_4: 0.2545  loss_dice_4: 0.6584  loss_ce_5: 0  loss_mask_5: 0.2545  loss_dice_5: 0.661  loss_ce_6: 0  loss_mask_6: 0.2537  loss_dice_6: 0.661  loss_ce_7: 0  loss_mask_7: 0.2556  loss_dice_7: 0.6589  loss_ce_8: 0  loss_mask_8: 0.2552  loss_dice_8: 0.6614  time: 1.6851  data_time: 0.0522  lr: 9.6304e-05  max_mem: 5916M
[02/24 13:23:13] d2.utils.events INFO:  eta: 1 day, 2:41:12  iter: 2479  total_loss: 9.443  loss_ce: 0  loss_mask: 0.2555  loss_dice: 0.6543  loss_seg: 0.387  loss_ce_0: 0  loss_mask_0: 0.2523  loss_dice_0: 0.6696  loss_ce_1: 0  loss_mask_1: 0.2535  loss_dice_1: 0.6488  loss_ce_2: 0  loss_mask_2: 0.2529  loss_dice_2: 0.647  loss_ce_3: 0  loss_mask_3: 0.2537  loss_dice_3: 0.646  loss_ce_4: 0  loss_mask_4: 0.2529  loss_dice_4: 0.6463  loss_ce_5: 0  loss_mask_5: 0.2545  loss_dice_5: 0.6464  loss_ce_6: 0  loss_mask_6: 0.2551  loss_dice_6: 0.6458  loss_ce_7: 0  loss_mask_7: 0.2546  loss_dice_7: 0.6465  loss_ce_8: 0  loss_mask_8: 0.2547  loss_dice_8: 0.6485  time: 1.6851  data_time: 0.0592  lr: 9.6274e-05  max_mem: 5916M
[02/24 13:23:46] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_refinelayerdeltas_noauxsegloss/model_0002499.pth
[02/24 13:23:48] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/24 13:23:50] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/24 13:23:50] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/24 13:24:11] mask2former INFO: Inference done 11/1093. Dataloading: 0.0105 s/iter. Inference: 0.3526 s/iter. Eval: 0.2649 s/iter. Total: 0.6281 s/iter. ETA=0:11:19
[02/24 13:24:17] mask2former INFO: Inference done 20/1093. Dataloading: 0.0096 s/iter. Inference: 0.3677 s/iter. Eval: 0.2488 s/iter. Total: 0.6262 s/iter. ETA=0:11:11
[02/24 13:24:22] mask2former INFO: Inference done 28/1093. Dataloading: 0.0128 s/iter. Inference: 0.3740 s/iter. Eval: 0.2527 s/iter. Total: 0.6397 s/iter. ETA=0:11:21
[02/24 13:24:28] mask2former INFO: Inference done 37/1093. Dataloading: 0.0122 s/iter. Inference: 0.3624 s/iter. Eval: 0.2545 s/iter. Total: 0.6293 s/iter. ETA=0:11:04
[02/24 13:24:33] mask2former INFO: Inference done 45/1093. Dataloading: 0.0118 s/iter. Inference: 0.3684 s/iter. Eval: 0.2587 s/iter. Total: 0.6390 s/iter. ETA=0:11:09
[02/24 13:24:39] mask2former INFO: Inference done 54/1093. Dataloading: 0.0114 s/iter. Inference: 0.3676 s/iter. Eval: 0.2583 s/iter. Total: 0.6374 s/iter. ETA=0:11:02
[02/24 13:24:44] mask2former INFO: Inference done 62/1093. Dataloading: 0.0114 s/iter. Inference: 0.3694 s/iter. Eval: 0.2569 s/iter. Total: 0.6378 s/iter. ETA=0:10:57
[02/24 13:24:49] mask2former INFO: Inference done 70/1093. Dataloading: 0.0115 s/iter. Inference: 0.3691 s/iter. Eval: 0.2563 s/iter. Total: 0.6370 s/iter. ETA=0:10:51
[02/24 13:24:55] mask2former INFO: Inference done 79/1093. Dataloading: 0.0117 s/iter. Inference: 0.3673 s/iter. Eval: 0.2535 s/iter. Total: 0.6328 s/iter. ETA=0:10:41
[02/24 13:25:00] mask2former INFO: Inference done 87/1093. Dataloading: 0.0116 s/iter. Inference: 0.3693 s/iter. Eval: 0.2518 s/iter. Total: 0.6329 s/iter. ETA=0:10:36
[02/24 13:25:05] mask2former INFO: Inference done 96/1093. Dataloading: 0.0114 s/iter. Inference: 0.3671 s/iter. Eval: 0.2486 s/iter. Total: 0.6273 s/iter. ETA=0:10:25
[02/24 13:25:10] mask2former INFO: Inference done 107/1093. Dataloading: 0.0110 s/iter. Inference: 0.3614 s/iter. Eval: 0.2424 s/iter. Total: 0.6151 s/iter. ETA=0:10:06
[02/24 13:25:16] mask2former INFO: Inference done 113/1093. Dataloading: 0.0112 s/iter. Inference: 0.3682 s/iter. Eval: 0.2512 s/iter. Total: 0.6308 s/iter. ETA=0:10:18
[02/24 13:25:21] mask2former INFO: Inference done 120/1093. Dataloading: 0.0120 s/iter. Inference: 0.3731 s/iter. Eval: 0.2558 s/iter. Total: 0.6411 s/iter. ETA=0:10:23
[02/24 13:25:27] mask2former INFO: Inference done 130/1093. Dataloading: 0.0121 s/iter. Inference: 0.3702 s/iter. Eval: 0.2527 s/iter. Total: 0.6353 s/iter. ETA=0:10:11
[02/24 13:25:33] mask2former INFO: Inference done 137/1093. Dataloading: 0.0120 s/iter. Inference: 0.3737 s/iter. Eval: 0.2588 s/iter. Total: 0.6449 s/iter. ETA=0:10:16
[02/24 13:25:38] mask2former INFO: Inference done 145/1093. Dataloading: 0.0121 s/iter. Inference: 0.3776 s/iter. Eval: 0.2580 s/iter. Total: 0.6481 s/iter. ETA=0:10:14
[02/24 13:25:43] mask2former INFO: Inference done 153/1093. Dataloading: 0.0121 s/iter. Inference: 0.3783 s/iter. Eval: 0.2564 s/iter. Total: 0.6471 s/iter. ETA=0:10:08
[02/24 13:25:48] mask2former INFO: Inference done 161/1093. Dataloading: 0.0121 s/iter. Inference: 0.3782 s/iter. Eval: 0.2554 s/iter. Total: 0.6460 s/iter. ETA=0:10:02
[02/24 13:25:54] mask2former INFO: Inference done 169/1093. Dataloading: 0.0120 s/iter. Inference: 0.3801 s/iter. Eval: 0.2542 s/iter. Total: 0.6466 s/iter. ETA=0:09:57
[02/24 13:25:59] mask2former INFO: Inference done 178/1093. Dataloading: 0.0119 s/iter. Inference: 0.3779 s/iter. Eval: 0.2533 s/iter. Total: 0.6434 s/iter. ETA=0:09:48
[02/24 13:26:04] mask2former INFO: Inference done 186/1093. Dataloading: 0.0121 s/iter. Inference: 0.3774 s/iter. Eval: 0.2531 s/iter. Total: 0.6428 s/iter. ETA=0:09:42
[02/24 13:26:09] mask2former INFO: Inference done 195/1093. Dataloading: 0.0119 s/iter. Inference: 0.3768 s/iter. Eval: 0.2517 s/iter. Total: 0.6407 s/iter. ETA=0:09:35
[02/24 13:26:15] mask2former INFO: Inference done 203/1093. Dataloading: 0.0119 s/iter. Inference: 0.3779 s/iter. Eval: 0.2533 s/iter. Total: 0.6434 s/iter. ETA=0:09:32
[02/24 13:26:21] mask2former INFO: Inference done 212/1093. Dataloading: 0.0118 s/iter. Inference: 0.3775 s/iter. Eval: 0.2530 s/iter. Total: 0.6426 s/iter. ETA=0:09:26
[02/24 13:26:26] mask2former INFO: Inference done 219/1093. Dataloading: 0.0118 s/iter. Inference: 0.3786 s/iter. Eval: 0.2544 s/iter. Total: 0.6451 s/iter. ETA=0:09:23
[02/24 13:26:31] mask2former INFO: Inference done 228/1093. Dataloading: 0.0118 s/iter. Inference: 0.3773 s/iter. Eval: 0.2541 s/iter. Total: 0.6436 s/iter. ETA=0:09:16
[02/24 13:26:36] mask2former INFO: Inference done 236/1093. Dataloading: 0.0117 s/iter. Inference: 0.3793 s/iter. Eval: 0.2527 s/iter. Total: 0.6440 s/iter. ETA=0:09:11
[02/24 13:26:42] mask2former INFO: Inference done 243/1093. Dataloading: 0.0117 s/iter. Inference: 0.3803 s/iter. Eval: 0.2539 s/iter. Total: 0.6463 s/iter. ETA=0:09:09
[02/24 13:26:47] mask2former INFO: Inference done 251/1093. Dataloading: 0.0117 s/iter. Inference: 0.3802 s/iter. Eval: 0.2537 s/iter. Total: 0.6459 s/iter. ETA=0:09:03
[02/24 13:26:52] mask2former INFO: Inference done 259/1093. Dataloading: 0.0119 s/iter. Inference: 0.3813 s/iter. Eval: 0.2538 s/iter. Total: 0.6474 s/iter. ETA=0:08:59
[02/24 13:26:58] mask2former INFO: Inference done 267/1093. Dataloading: 0.0119 s/iter. Inference: 0.3813 s/iter. Eval: 0.2547 s/iter. Total: 0.6483 s/iter. ETA=0:08:55
[02/24 13:27:03] mask2former INFO: Inference done 275/1093. Dataloading: 0.0119 s/iter. Inference: 0.3812 s/iter. Eval: 0.2552 s/iter. Total: 0.6487 s/iter. ETA=0:08:50
[02/24 13:27:08] mask2former INFO: Inference done 283/1093. Dataloading: 0.0119 s/iter. Inference: 0.3804 s/iter. Eval: 0.2558 s/iter. Total: 0.6484 s/iter. ETA=0:08:45
[02/24 13:27:13] mask2former INFO: Inference done 292/1093. Dataloading: 0.0119 s/iter. Inference: 0.3795 s/iter. Eval: 0.2553 s/iter. Total: 0.6470 s/iter. ETA=0:08:38
[02/24 13:27:19] mask2former INFO: Inference done 300/1093. Dataloading: 0.0119 s/iter. Inference: 0.3796 s/iter. Eval: 0.2553 s/iter. Total: 0.6471 s/iter. ETA=0:08:33
[02/24 13:27:24] mask2former INFO: Inference done 308/1093. Dataloading: 0.0119 s/iter. Inference: 0.3798 s/iter. Eval: 0.2554 s/iter. Total: 0.6474 s/iter. ETA=0:08:28
[02/24 13:27:29] mask2former INFO: Inference done 316/1093. Dataloading: 0.0119 s/iter. Inference: 0.3802 s/iter. Eval: 0.2547 s/iter. Total: 0.6471 s/iter. ETA=0:08:22
[02/24 13:27:35] mask2former INFO: Inference done 324/1093. Dataloading: 0.0118 s/iter. Inference: 0.3817 s/iter. Eval: 0.2551 s/iter. Total: 0.6490 s/iter. ETA=0:08:19
[02/24 13:27:40] mask2former INFO: Inference done 332/1093. Dataloading: 0.0118 s/iter. Inference: 0.3823 s/iter. Eval: 0.2555 s/iter. Total: 0.6500 s/iter. ETA=0:08:14
[02/24 13:27:46] mask2former INFO: Inference done 340/1093. Dataloading: 0.0117 s/iter. Inference: 0.3823 s/iter. Eval: 0.2566 s/iter. Total: 0.6510 s/iter. ETA=0:08:10
[02/24 13:27:51] mask2former INFO: Inference done 348/1093. Dataloading: 0.0118 s/iter. Inference: 0.3822 s/iter. Eval: 0.2566 s/iter. Total: 0.6509 s/iter. ETA=0:08:04
[02/24 13:27:56] mask2former INFO: Inference done 356/1093. Dataloading: 0.0118 s/iter. Inference: 0.3825 s/iter. Eval: 0.2569 s/iter. Total: 0.6516 s/iter. ETA=0:08:00
[02/24 13:28:02] mask2former INFO: Inference done 365/1093. Dataloading: 0.0118 s/iter. Inference: 0.3817 s/iter. Eval: 0.2562 s/iter. Total: 0.6500 s/iter. ETA=0:07:53
[02/24 13:28:07] mask2former INFO: Inference done 373/1093. Dataloading: 0.0117 s/iter. Inference: 0.3817 s/iter. Eval: 0.2557 s/iter. Total: 0.6495 s/iter. ETA=0:07:47
[02/24 13:28:12] mask2former INFO: Inference done 382/1093. Dataloading: 0.0116 s/iter. Inference: 0.3816 s/iter. Eval: 0.2551 s/iter. Total: 0.6487 s/iter. ETA=0:07:41
[02/24 13:28:18] mask2former INFO: Inference done 391/1093. Dataloading: 0.0115 s/iter. Inference: 0.3813 s/iter. Eval: 0.2545 s/iter. Total: 0.6477 s/iter. ETA=0:07:34
[02/24 13:28:23] mask2former INFO: Inference done 399/1093. Dataloading: 0.0114 s/iter. Inference: 0.3814 s/iter. Eval: 0.2542 s/iter. Total: 0.6475 s/iter. ETA=0:07:29
[02/24 13:28:28] mask2former INFO: Inference done 407/1093. Dataloading: 0.0114 s/iter. Inference: 0.3819 s/iter. Eval: 0.2542 s/iter. Total: 0.6479 s/iter. ETA=0:07:24
[02/24 13:28:34] mask2former INFO: Inference done 416/1093. Dataloading: 0.0114 s/iter. Inference: 0.3817 s/iter. Eval: 0.2534 s/iter. Total: 0.6468 s/iter. ETA=0:07:17
[02/24 13:28:39] mask2former INFO: Inference done 424/1093. Dataloading: 0.0114 s/iter. Inference: 0.3815 s/iter. Eval: 0.2532 s/iter. Total: 0.6464 s/iter. ETA=0:07:12
[02/24 13:28:44] mask2former INFO: Inference done 431/1093. Dataloading: 0.0114 s/iter. Inference: 0.3829 s/iter. Eval: 0.2533 s/iter. Total: 0.6480 s/iter. ETA=0:07:08
[02/24 13:28:49] mask2former INFO: Inference done 440/1093. Dataloading: 0.0115 s/iter. Inference: 0.3825 s/iter. Eval: 0.2525 s/iter. Total: 0.6468 s/iter. ETA=0:07:02
[02/24 13:28:54] mask2former INFO: Inference done 448/1093. Dataloading: 0.0115 s/iter. Inference: 0.3830 s/iter. Eval: 0.2523 s/iter. Total: 0.6471 s/iter. ETA=0:06:57
[02/24 13:29:00] mask2former INFO: Inference done 456/1093. Dataloading: 0.0116 s/iter. Inference: 0.3834 s/iter. Eval: 0.2525 s/iter. Total: 0.6478 s/iter. ETA=0:06:52
[02/24 13:29:05] mask2former INFO: Inference done 464/1093. Dataloading: 0.0116 s/iter. Inference: 0.3833 s/iter. Eval: 0.2526 s/iter. Total: 0.6480 s/iter. ETA=0:06:47
[02/24 13:29:10] mask2former INFO: Inference done 472/1093. Dataloading: 0.0116 s/iter. Inference: 0.3834 s/iter. Eval: 0.2522 s/iter. Total: 0.6476 s/iter. ETA=0:06:42
[02/24 13:29:16] mask2former INFO: Inference done 481/1093. Dataloading: 0.0115 s/iter. Inference: 0.3829 s/iter. Eval: 0.2521 s/iter. Total: 0.6470 s/iter. ETA=0:06:35
[02/24 13:29:21] mask2former INFO: Inference done 489/1093. Dataloading: 0.0119 s/iter. Inference: 0.3833 s/iter. Eval: 0.2521 s/iter. Total: 0.6477 s/iter. ETA=0:06:31
[02/24 13:29:26] mask2former INFO: Inference done 497/1093. Dataloading: 0.0119 s/iter. Inference: 0.3833 s/iter. Eval: 0.2520 s/iter. Total: 0.6476 s/iter. ETA=0:06:25
[02/24 13:29:31] mask2former INFO: Inference done 505/1093. Dataloading: 0.0119 s/iter. Inference: 0.3829 s/iter. Eval: 0.2521 s/iter. Total: 0.6473 s/iter. ETA=0:06:20
[02/24 13:29:37] mask2former INFO: Inference done 514/1093. Dataloading: 0.0118 s/iter. Inference: 0.3825 s/iter. Eval: 0.2521 s/iter. Total: 0.6468 s/iter. ETA=0:06:14
[02/24 13:29:42] mask2former INFO: Inference done 522/1093. Dataloading: 0.0119 s/iter. Inference: 0.3824 s/iter. Eval: 0.2524 s/iter. Total: 0.6471 s/iter. ETA=0:06:09
[02/24 13:29:48] mask2former INFO: Inference done 531/1093. Dataloading: 0.0118 s/iter. Inference: 0.3823 s/iter. Eval: 0.2523 s/iter. Total: 0.6468 s/iter. ETA=0:06:03
[02/24 13:29:53] mask2former INFO: Inference done 539/1093. Dataloading: 0.0119 s/iter. Inference: 0.3821 s/iter. Eval: 0.2523 s/iter. Total: 0.6467 s/iter. ETA=0:05:58
[02/24 13:29:58] mask2former INFO: Inference done 547/1093. Dataloading: 0.0119 s/iter. Inference: 0.3826 s/iter. Eval: 0.2519 s/iter. Total: 0.6468 s/iter. ETA=0:05:53
[02/24 13:30:04] mask2former INFO: Inference done 556/1093. Dataloading: 0.0119 s/iter. Inference: 0.3821 s/iter. Eval: 0.2514 s/iter. Total: 0.6458 s/iter. ETA=0:05:46
[02/24 13:30:09] mask2former INFO: Inference done 564/1093. Dataloading: 0.0119 s/iter. Inference: 0.3817 s/iter. Eval: 0.2518 s/iter. Total: 0.6457 s/iter. ETA=0:05:41
[02/24 13:30:14] mask2former INFO: Inference done 572/1093. Dataloading: 0.0119 s/iter. Inference: 0.3818 s/iter. Eval: 0.2519 s/iter. Total: 0.6460 s/iter. ETA=0:05:36
[02/24 13:30:19] mask2former INFO: Inference done 580/1093. Dataloading: 0.0119 s/iter. Inference: 0.3821 s/iter. Eval: 0.2521 s/iter. Total: 0.6465 s/iter. ETA=0:05:31
[02/24 13:30:25] mask2former INFO: Inference done 588/1093. Dataloading: 0.0118 s/iter. Inference: 0.3821 s/iter. Eval: 0.2520 s/iter. Total: 0.6463 s/iter. ETA=0:05:26
[02/24 13:30:30] mask2former INFO: Inference done 596/1093. Dataloading: 0.0118 s/iter. Inference: 0.3820 s/iter. Eval: 0.2525 s/iter. Total: 0.6467 s/iter. ETA=0:05:21
[02/24 13:30:35] mask2former INFO: Inference done 604/1093. Dataloading: 0.0118 s/iter. Inference: 0.3818 s/iter. Eval: 0.2526 s/iter. Total: 0.6466 s/iter. ETA=0:05:16
[02/24 13:30:40] mask2former INFO: Inference done 612/1093. Dataloading: 0.0118 s/iter. Inference: 0.3819 s/iter. Eval: 0.2524 s/iter. Total: 0.6465 s/iter. ETA=0:05:10
[02/24 13:30:45] mask2former INFO: Inference done 620/1093. Dataloading: 0.0118 s/iter. Inference: 0.3819 s/iter. Eval: 0.2525 s/iter. Total: 0.6465 s/iter. ETA=0:05:05
[02/24 13:30:51] mask2former INFO: Inference done 628/1093. Dataloading: 0.0119 s/iter. Inference: 0.3817 s/iter. Eval: 0.2525 s/iter. Total: 0.6465 s/iter. ETA=0:05:00
[02/24 13:30:56] mask2former INFO: Inference done 636/1093. Dataloading: 0.0119 s/iter. Inference: 0.3819 s/iter. Eval: 0.2527 s/iter. Total: 0.6469 s/iter. ETA=0:04:55
[02/24 13:31:01] mask2former INFO: Inference done 644/1093. Dataloading: 0.0119 s/iter. Inference: 0.3820 s/iter. Eval: 0.2526 s/iter. Total: 0.6468 s/iter. ETA=0:04:50
[02/24 13:31:06] mask2former INFO: Inference done 652/1093. Dataloading: 0.0119 s/iter. Inference: 0.3816 s/iter. Eval: 0.2528 s/iter. Total: 0.6466 s/iter. ETA=0:04:45
[02/24 13:31:11] mask2former INFO: Inference done 660/1093. Dataloading: 0.0118 s/iter. Inference: 0.3816 s/iter. Eval: 0.2529 s/iter. Total: 0.6468 s/iter. ETA=0:04:40
[02/24 13:31:17] mask2former INFO: Inference done 668/1093. Dataloading: 0.0119 s/iter. Inference: 0.3815 s/iter. Eval: 0.2535 s/iter. Total: 0.6472 s/iter. ETA=0:04:35
[02/24 13:31:23] mask2former INFO: Inference done 676/1093. Dataloading: 0.0118 s/iter. Inference: 0.3822 s/iter. Eval: 0.2537 s/iter. Total: 0.6481 s/iter. ETA=0:04:30
[02/24 13:31:28] mask2former INFO: Inference done 685/1093. Dataloading: 0.0119 s/iter. Inference: 0.3819 s/iter. Eval: 0.2537 s/iter. Total: 0.6478 s/iter. ETA=0:04:24
[02/24 13:31:33] mask2former INFO: Inference done 697/1093. Dataloading: 0.0118 s/iter. Inference: 0.3800 s/iter. Eval: 0.2518 s/iter. Total: 0.6439 s/iter. ETA=0:04:14
[02/24 13:31:39] mask2former INFO: Inference done 706/1093. Dataloading: 0.0118 s/iter. Inference: 0.3793 s/iter. Eval: 0.2519 s/iter. Total: 0.6433 s/iter. ETA=0:04:08
[02/24 13:31:44] mask2former INFO: Inference done 712/1093. Dataloading: 0.0118 s/iter. Inference: 0.3809 s/iter. Eval: 0.2526 s/iter. Total: 0.6457 s/iter. ETA=0:04:05
[02/24 13:31:49] mask2former INFO: Inference done 720/1093. Dataloading: 0.0119 s/iter. Inference: 0.3810 s/iter. Eval: 0.2524 s/iter. Total: 0.6456 s/iter. ETA=0:04:00
[02/24 13:31:55] mask2former INFO: Inference done 728/1093. Dataloading: 0.0118 s/iter. Inference: 0.3811 s/iter. Eval: 0.2527 s/iter. Total: 0.6460 s/iter. ETA=0:03:55
[02/24 13:32:00] mask2former INFO: Inference done 735/1093. Dataloading: 0.0118 s/iter. Inference: 0.3816 s/iter. Eval: 0.2533 s/iter. Total: 0.6471 s/iter. ETA=0:03:51
[02/24 13:32:05] mask2former INFO: Inference done 743/1093. Dataloading: 0.0118 s/iter. Inference: 0.3820 s/iter. Eval: 0.2531 s/iter. Total: 0.6472 s/iter. ETA=0:03:46
[02/24 13:32:10] mask2former INFO: Inference done 751/1093. Dataloading: 0.0118 s/iter. Inference: 0.3819 s/iter. Eval: 0.2531 s/iter. Total: 0.6471 s/iter. ETA=0:03:41
[02/24 13:32:16] mask2former INFO: Inference done 760/1093. Dataloading: 0.0117 s/iter. Inference: 0.3814 s/iter. Eval: 0.2529 s/iter. Total: 0.6464 s/iter. ETA=0:03:35
[02/24 13:32:21] mask2former INFO: Inference done 768/1093. Dataloading: 0.0118 s/iter. Inference: 0.3813 s/iter. Eval: 0.2530 s/iter. Total: 0.6464 s/iter. ETA=0:03:30
[02/24 13:32:26] mask2former INFO: Inference done 776/1093. Dataloading: 0.0118 s/iter. Inference: 0.3814 s/iter. Eval: 0.2529 s/iter. Total: 0.6464 s/iter. ETA=0:03:24
[02/24 13:32:32] mask2former INFO: Inference done 785/1093. Dataloading: 0.0117 s/iter. Inference: 0.3810 s/iter. Eval: 0.2530 s/iter. Total: 0.6462 s/iter. ETA=0:03:19
[02/24 13:32:37] mask2former INFO: Inference done 793/1093. Dataloading: 0.0117 s/iter. Inference: 0.3810 s/iter. Eval: 0.2530 s/iter. Total: 0.6461 s/iter. ETA=0:03:13
[02/24 13:32:42] mask2former INFO: Inference done 801/1093. Dataloading: 0.0117 s/iter. Inference: 0.3809 s/iter. Eval: 0.2530 s/iter. Total: 0.6459 s/iter. ETA=0:03:08
[02/24 13:32:47] mask2former INFO: Inference done 809/1093. Dataloading: 0.0118 s/iter. Inference: 0.3808 s/iter. Eval: 0.2529 s/iter. Total: 0.6458 s/iter. ETA=0:03:03
[02/24 13:32:52] mask2former INFO: Inference done 817/1093. Dataloading: 0.0118 s/iter. Inference: 0.3812 s/iter. Eval: 0.2528 s/iter. Total: 0.6462 s/iter. ETA=0:02:58
[02/24 13:32:58] mask2former INFO: Inference done 825/1093. Dataloading: 0.0118 s/iter. Inference: 0.3811 s/iter. Eval: 0.2529 s/iter. Total: 0.6461 s/iter. ETA=0:02:53
[02/24 13:33:03] mask2former INFO: Inference done 833/1093. Dataloading: 0.0118 s/iter. Inference: 0.3812 s/iter. Eval: 0.2530 s/iter. Total: 0.6463 s/iter. ETA=0:02:48
[02/24 13:33:08] mask2former INFO: Inference done 842/1093. Dataloading: 0.0118 s/iter. Inference: 0.3809 s/iter. Eval: 0.2528 s/iter. Total: 0.6459 s/iter. ETA=0:02:42
[02/24 13:33:13] mask2former INFO: Inference done 850/1093. Dataloading: 0.0118 s/iter. Inference: 0.3807 s/iter. Eval: 0.2529 s/iter. Total: 0.6458 s/iter. ETA=0:02:36
[02/24 13:33:19] mask2former INFO: Inference done 858/1093. Dataloading: 0.0118 s/iter. Inference: 0.3808 s/iter. Eval: 0.2529 s/iter. Total: 0.6459 s/iter. ETA=0:02:31
[02/24 13:33:24] mask2former INFO: Inference done 866/1093. Dataloading: 0.0118 s/iter. Inference: 0.3812 s/iter. Eval: 0.2529 s/iter. Total: 0.6462 s/iter. ETA=0:02:26
[02/24 13:33:30] mask2former INFO: Inference done 875/1093. Dataloading: 0.0118 s/iter. Inference: 0.3811 s/iter. Eval: 0.2527 s/iter. Total: 0.6458 s/iter. ETA=0:02:20
[02/24 13:33:35] mask2former INFO: Inference done 883/1093. Dataloading: 0.0118 s/iter. Inference: 0.3812 s/iter. Eval: 0.2524 s/iter. Total: 0.6457 s/iter. ETA=0:02:15
[02/24 13:33:40] mask2former INFO: Inference done 892/1093. Dataloading: 0.0118 s/iter. Inference: 0.3813 s/iter. Eval: 0.2521 s/iter. Total: 0.6455 s/iter. ETA=0:02:09
[02/24 13:33:46] mask2former INFO: Inference done 900/1093. Dataloading: 0.0118 s/iter. Inference: 0.3815 s/iter. Eval: 0.2521 s/iter. Total: 0.6457 s/iter. ETA=0:02:04
[02/24 13:33:51] mask2former INFO: Inference done 909/1093. Dataloading: 0.0117 s/iter. Inference: 0.3811 s/iter. Eval: 0.2521 s/iter. Total: 0.6453 s/iter. ETA=0:01:58
[02/24 13:33:56] mask2former INFO: Inference done 917/1093. Dataloading: 0.0118 s/iter. Inference: 0.3813 s/iter. Eval: 0.2521 s/iter. Total: 0.6454 s/iter. ETA=0:01:53
[02/24 13:34:02] mask2former INFO: Inference done 925/1093. Dataloading: 0.0118 s/iter. Inference: 0.3816 s/iter. Eval: 0.2517 s/iter. Total: 0.6454 s/iter. ETA=0:01:48
[02/24 13:34:07] mask2former INFO: Inference done 933/1093. Dataloading: 0.0118 s/iter. Inference: 0.3816 s/iter. Eval: 0.2518 s/iter. Total: 0.6454 s/iter. ETA=0:01:43
[02/24 13:34:12] mask2former INFO: Inference done 941/1093. Dataloading: 0.0118 s/iter. Inference: 0.3818 s/iter. Eval: 0.2516 s/iter. Total: 0.6454 s/iter. ETA=0:01:38
[02/24 13:34:17] mask2former INFO: Inference done 949/1093. Dataloading: 0.0118 s/iter. Inference: 0.3818 s/iter. Eval: 0.2518 s/iter. Total: 0.6457 s/iter. ETA=0:01:32
[02/24 13:34:23] mask2former INFO: Inference done 958/1093. Dataloading: 0.0118 s/iter. Inference: 0.3817 s/iter. Eval: 0.2515 s/iter. Total: 0.6453 s/iter. ETA=0:01:27
[02/24 13:34:28] mask2former INFO: Inference done 966/1093. Dataloading: 0.0118 s/iter. Inference: 0.3819 s/iter. Eval: 0.2514 s/iter. Total: 0.6454 s/iter. ETA=0:01:21
[02/24 13:34:33] mask2former INFO: Inference done 974/1093. Dataloading: 0.0118 s/iter. Inference: 0.3820 s/iter. Eval: 0.2513 s/iter. Total: 0.6455 s/iter. ETA=0:01:16
[02/24 13:34:38] mask2former INFO: Inference done 982/1093. Dataloading: 0.0118 s/iter. Inference: 0.3819 s/iter. Eval: 0.2514 s/iter. Total: 0.6455 s/iter. ETA=0:01:11
[02/24 13:34:44] mask2former INFO: Inference done 990/1093. Dataloading: 0.0118 s/iter. Inference: 0.3821 s/iter. Eval: 0.2514 s/iter. Total: 0.6457 s/iter. ETA=0:01:06
[02/24 13:34:49] mask2former INFO: Inference done 998/1093. Dataloading: 0.0119 s/iter. Inference: 0.3822 s/iter. Eval: 0.2514 s/iter. Total: 0.6459 s/iter. ETA=0:01:01
[02/24 13:34:54] mask2former INFO: Inference done 1005/1093. Dataloading: 0.0119 s/iter. Inference: 0.3826 s/iter. Eval: 0.2516 s/iter. Total: 0.6464 s/iter. ETA=0:00:56
[02/24 13:34:59] mask2former INFO: Inference done 1013/1093. Dataloading: 0.0119 s/iter. Inference: 0.3828 s/iter. Eval: 0.2516 s/iter. Total: 0.6466 s/iter. ETA=0:00:51
[02/24 13:35:05] mask2former INFO: Inference done 1020/1093. Dataloading: 0.0119 s/iter. Inference: 0.3831 s/iter. Eval: 0.2520 s/iter. Total: 0.6473 s/iter. ETA=0:00:47
[02/24 13:35:10] mask2former INFO: Inference done 1028/1093. Dataloading: 0.0118 s/iter. Inference: 0.3831 s/iter. Eval: 0.2521 s/iter. Total: 0.6474 s/iter. ETA=0:00:42
[02/24 13:35:15] mask2former INFO: Inference done 1036/1093. Dataloading: 0.0118 s/iter. Inference: 0.3830 s/iter. Eval: 0.2521 s/iter. Total: 0.6473 s/iter. ETA=0:00:36
[02/24 13:35:21] mask2former INFO: Inference done 1045/1093. Dataloading: 0.0118 s/iter. Inference: 0.3831 s/iter. Eval: 0.2519 s/iter. Total: 0.6471 s/iter. ETA=0:00:31
[02/24 13:35:26] mask2former INFO: Inference done 1054/1093. Dataloading: 0.0118 s/iter. Inference: 0.3828 s/iter. Eval: 0.2517 s/iter. Total: 0.6467 s/iter. ETA=0:00:25
[02/24 13:35:32] mask2former INFO: Inference done 1063/1093. Dataloading: 0.0118 s/iter. Inference: 0.3827 s/iter. Eval: 0.2515 s/iter. Total: 0.6463 s/iter. ETA=0:00:19
[02/24 13:35:37] mask2former INFO: Inference done 1071/1093. Dataloading: 0.0118 s/iter. Inference: 0.3827 s/iter. Eval: 0.2515 s/iter. Total: 0.6462 s/iter. ETA=0:00:14
[02/24 13:35:42] mask2former INFO: Inference done 1079/1093. Dataloading: 0.0117 s/iter. Inference: 0.3830 s/iter. Eval: 0.2514 s/iter. Total: 0.6465 s/iter. ETA=0:00:09
[02/24 13:35:47] mask2former INFO: Inference done 1089/1093. Dataloading: 0.0117 s/iter. Inference: 0.3824 s/iter. Eval: 0.2511 s/iter. Total: 0.6455 s/iter. ETA=0:00:02
[02/24 13:37:14] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.6483751241483535, 'error_1pix': 0.45237440057721867, 'error_3pix': 0.19217815435472316, 'mIoU': 8.876119292561064, 'fwIoU': 34.49385842146888, 'IoU-1': 91.7755868070271, 'IoU-2': 15.290642843257604, 'IoU-3': 0.1915548635509939, 'IoU-4': 1.5403697079353766, 'IoU-5': 2.9616477272727275, 'IoU-6': 1.925934885365364, 'IoU-7': 0.9909893009140313, 'IoU-8': 1.8949243439954033, 'IoU-9': 2.364210791075258, 'IoU-10': 1.2879177049982549, 'IoU-11': 1.0503560952668567, 'IoU-12': 2.604326052657736, 'IoU-13': 9.24372819953706, 'IoU-14': 4.24872513835438, 'IoU-15': 2.0815960463504735, 'IoU-16': 5.530539897487771, 'IoU-17': 8.471726974248105, 'IoU-18': 4.474317096200017, 'IoU-19': 3.222986314837656, 'IoU-20': 8.932366927433387, 'IoU-21': 14.290750262559046, 'IoU-22': 8.12160864541997, 'IoU-23': 4.8914114669988695, 'IoU-24': 13.603014448215509, 'IoU-25': 15.241721046423265, 'IoU-26': 7.703680864502738, 'IoU-27': 5.47455855943623, 'IoU-28': 15.245839369193238, 'IoU-29': 15.612330789612274, 'IoU-30': 6.844161112324361, 'IoU-31': 4.225198951438723, 'IoU-32': 9.964351924305879, 'IoU-33': 9.803628466905892, 'IoU-34': 4.835536255010359, 'IoU-35': 3.523975036668908, 'IoU-36': 7.782941044943301, 'IoU-37': 9.162931652433802, 'IoU-38': 4.743324884690076, 'IoU-39': 3.337710984254256, 'IoU-40': 8.754375051544764, 'IoU-41': 11.69448379203611, 'IoU-42': 6.893518710085564, 'IoU-43': 5.085974309159382, 'IoU-44': 12.34616519676738, 'IoU-45': 14.386448798321103, 'IoU-46': 8.620040317031968, 'IoU-47': 7.476460048347139, 'IoU-48': 16.303136336535445, 'mACC': 17.77932647860352, 'pACC': 40.52383131207394, 'ACC-1': 96.62592690825264, 'ACC-2': 15.293358107607693, 'ACC-3': 32.10748958311301, 'ACC-4': 44.30957938692322, 'ACC-5': 20.54631322409226, 'ACC-6': 8.866615265998458, 'ACC-7': 4.229737549907737, 'ACC-8': 6.107972084615422, 'ACC-9': 3.690704241886489, 'ACC-10': 1.5033282520153257, 'ACC-11': 1.1341820848914017, 'ACC-12': 2.980761952435222, 'ACC-13': 17.61163711988947, 'ACC-14': 6.486490183229823, 'ACC-15': 2.9566837568769846, 'ACC-16': 14.505000454202161, 'ACC-17': 22.39265871156618, 'ACC-18': 6.958528982130659, 'ACC-19': 4.975559381936304, 'ACC-20': 20.74304455905366, 'ACC-21': 33.69389486217986, 'ACC-22': 11.708997107357577, 'ACC-23': 7.513110182827582, 'ACC-24': 34.08476815161261, 'ACC-25': 28.95776268971309, 'ACC-26': 11.379597984427631, 'ACC-27': 8.439867295117292, 'ACC-28': 35.009989883054146, 'ACC-29': 27.440687738571008, 'ACC-30': 9.619374518916453, 'ACC-31': 6.233248377644177, 'ACC-32': 21.905315670623793, 'ACC-33': 18.730285985013058, 'ACC-34': 7.458993716907016, 'ACC-35': 5.629859548610531, 'ACC-36': 18.062996980761465, 'ACC-37': 18.460393135132936, 'ACC-38': 7.3283342533802625, 'ACC-39': 5.3215427367632175, 'ACC-40': 22.473096722682364, 'ACC-41': 27.873244819088494, 'ACC-42': 11.120351706155315, 'ACC-43': 8.552365330765586, 'ACC-44': 31.598823653229896, 'ACC-45': 29.781135817462008, 'ACC-46': 13.911854442347673, 'ACC-47': 13.330056813711483, 'ACC-48': 43.7621490582884})])
[02/24 13:37:14] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/24 13:37:14] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/24 13:37:14] d2.evaluation.testing INFO: copypaste: 3.6484,0.4524,0.1922,8.8761,34.4939,17.7793,40.5238
[02/24 13:37:14] d2.utils.events INFO:  eta: 1 day, 2:38:58  iter: 2499  total_loss: 9.433  loss_ce: 0  loss_mask: 0.2532  loss_dice: 0.6503  loss_seg: 0.3882  loss_ce_0: 0  loss_mask_0: 0.2478  loss_dice_0: 0.6618  loss_ce_1: 0  loss_mask_1: 0.2524  loss_dice_1: 0.6448  loss_ce_2: 0  loss_mask_2: 0.252  loss_dice_2: 0.6436  loss_ce_3: 0  loss_mask_3: 0.2502  loss_dice_3: 0.6434  loss_ce_4: 0  loss_mask_4: 0.2519  loss_dice_4: 0.6423  loss_ce_5: 0  loss_mask_5: 0.2523  loss_dice_5: 0.6417  loss_ce_6: 0  loss_mask_6: 0.2519  loss_dice_6: 0.643  loss_ce_7: 0  loss_mask_7: 0.2523  loss_dice_7: 0.6447  loss_ce_8: 0  loss_mask_8: 0.2507  loss_dice_8: 0.6451  time: 1.6848  data_time: 0.0563  lr: 9.6244e-05  max_mem: 5916M
[02/24 13:37:50] d2.utils.events INFO:  eta: 1 day, 2:37:29  iter: 2519  total_loss: 9.693  loss_ce: 0  loss_mask: 0.2681  loss_dice: 0.6571  loss_seg: 0.4006  loss_ce_0: 0  loss_mask_0: 0.2665  loss_dice_0: 0.6703  loss_ce_1: 0  loss_mask_1: 0.2649  loss_dice_1: 0.6517  loss_ce_2: 0  loss_mask_2: 0.2656  loss_dice_2: 0.6503  loss_ce_3: 0  loss_mask_3: 0.2651  loss_dice_3: 0.6502  loss_ce_4: 0  loss_mask_4: 0.2644  loss_dice_4: 0.652  loss_ce_5: 0  loss_mask_5: 0.2651  loss_dice_5: 0.6539  loss_ce_6: 0  loss_mask_6: 0.2663  loss_dice_6: 0.6522  loss_ce_7: 0  loss_mask_7: 0.2651  loss_dice_7: 0.6515  loss_ce_8: 0  loss_mask_8: 0.2661  loss_dice_8: 0.6532  time: 1.6855  data_time: 0.0610  lr: 9.6213e-05  max_mem: 5916M
[02/24 13:38:24] d2.utils.events INFO:  eta: 1 day, 2:37:19  iter: 2539  total_loss: 9.65  loss_ce: 0  loss_mask: 0.255  loss_dice: 0.6622  loss_seg: 0.4425  loss_ce_0: 0  loss_mask_0: 0.2525  loss_dice_0: 0.678  loss_ce_1: 0  loss_mask_1: 0.2534  loss_dice_1: 0.659  loss_ce_2: 0  loss_mask_2: 0.2548  loss_dice_2: 0.6539  loss_ce_3: 0  loss_mask_3: 0.2538  loss_dice_3: 0.6536  loss_ce_4: 0  loss_mask_4: 0.2554  loss_dice_4: 0.6526  loss_ce_5: 0  loss_mask_5: 0.2546  loss_dice_5: 0.6532  loss_ce_6: 0  loss_mask_6: 0.2557  loss_dice_6: 0.6538  loss_ce_7: 0  loss_mask_7: 0.2546  loss_dice_7: 0.6553  loss_ce_8: 0  loss_mask_8: 0.2552  loss_dice_8: 0.6558  time: 1.6856  data_time: 0.0654  lr: 9.6183e-05  max_mem: 5916M
[02/24 13:38:58] d2.utils.events INFO:  eta: 1 day, 2:36:22  iter: 2559  total_loss: 9.419  loss_ce: 0  loss_mask: 0.2552  loss_dice: 0.644  loss_seg: 0.3811  loss_ce_0: 0  loss_mask_0: 0.2511  loss_dice_0: 0.6624  loss_ce_1: 0  loss_mask_1: 0.2522  loss_dice_1: 0.6433  loss_ce_2: 0  loss_mask_2: 0.2532  loss_dice_2: 0.6409  loss_ce_3: 0  loss_mask_3: 0.2558  loss_dice_3: 0.6411  loss_ce_4: 0  loss_mask_4: 0.255  loss_dice_4: 0.6414  loss_ce_5: 0  loss_mask_5: 0.2557  loss_dice_5: 0.6414  loss_ce_6: 0  loss_mask_6: 0.2559  loss_dice_6: 0.6398  loss_ce_7: 0  loss_mask_7: 0.2564  loss_dice_7: 0.6394  loss_ce_8: 0  loss_mask_8: 0.2568  loss_dice_8: 0.6407  time: 1.6855  data_time: 0.0616  lr: 9.6153e-05  max_mem: 5916M
[02/24 13:39:30] d2.utils.events INFO:  eta: 1 day, 2:34:52  iter: 2579  total_loss: 9.414  loss_ce: 0  loss_mask: 0.2419  loss_dice: 0.6608  loss_seg: 0.3738  loss_ce_0: 0  loss_mask_0: 0.2398  loss_dice_0: 0.6714  loss_ce_1: 0  loss_mask_1: 0.239  loss_dice_1: 0.6565  loss_ce_2: 0  loss_mask_2: 0.2402  loss_dice_2: 0.6524  loss_ce_3: 0  loss_mask_3: 0.2403  loss_dice_3: 0.6515  loss_ce_4: 0  loss_mask_4: 0.2403  loss_dice_4: 0.6522  loss_ce_5: 0  loss_mask_5: 0.2401  loss_dice_5: 0.6545  loss_ce_6: 0  loss_mask_6: 0.241  loss_dice_6: 0.6529  loss_ce_7: 0  loss_mask_7: 0.2416  loss_dice_7: 0.6554  loss_ce_8: 0  loss_mask_8: 0.2427  loss_dice_8: 0.6562  time: 1.6851  data_time: 0.0664  lr: 9.6123e-05  max_mem: 5916M
[02/24 13:40:04] d2.utils.events INFO:  eta: 1 day, 2:33:33  iter: 2599  total_loss: 9.193  loss_ce: 0  loss_mask: 0.2397  loss_dice: 0.6456  loss_seg: 0.3735  loss_ce_0: 0  loss_mask_0: 0.2366  loss_dice_0: 0.6645  loss_ce_1: 0  loss_mask_1: 0.2381  loss_dice_1: 0.642  loss_ce_2: 0  loss_mask_2: 0.2389  loss_dice_2: 0.6392  loss_ce_3: 0  loss_mask_3: 0.2393  loss_dice_3: 0.6382  loss_ce_4: 0  loss_mask_4: 0.239  loss_dice_4: 0.6389  loss_ce_5: 0  loss_mask_5: 0.2392  loss_dice_5: 0.6394  loss_ce_6: 0  loss_mask_6: 0.239  loss_dice_6: 0.6402  loss_ce_7: 0  loss_mask_7: 0.2399  loss_dice_7: 0.6419  loss_ce_8: 0  loss_mask_8: 0.2391  loss_dice_8: 0.6418  time: 1.6851  data_time: 0.0598  lr: 9.6093e-05  max_mem: 5916M
[02/24 13:40:39] d2.utils.events INFO:  eta: 1 day, 2:33:14  iter: 2619  total_loss: 9.519  loss_ce: 0  loss_mask: 0.2505  loss_dice: 0.6661  loss_seg: 0.4237  loss_ce_0: 0  loss_mask_0: 0.2424  loss_dice_0: 0.6733  loss_ce_1: 0  loss_mask_1: 0.2471  loss_dice_1: 0.6599  loss_ce_2: 0  loss_mask_2: 0.2479  loss_dice_2: 0.6609  loss_ce_3: 0  loss_mask_3: 0.2489  loss_dice_3: 0.6596  loss_ce_4: 0  loss_mask_4: 0.2486  loss_dice_4: 0.6587  loss_ce_5: 0  loss_mask_5: 0.2485  loss_dice_5: 0.6596  loss_ce_6: 0  loss_mask_6: 0.2484  loss_dice_6: 0.66  loss_ce_7: 0  loss_mask_7: 0.2489  loss_dice_7: 0.6601  loss_ce_8: 0  loss_mask_8: 0.249  loss_dice_8: 0.662  time: 1.6853  data_time: 0.0598  lr: 9.6063e-05  max_mem: 5916M
[02/24 13:41:12] d2.utils.events INFO:  eta: 1 day, 2:31:35  iter: 2639  total_loss: 9.454  loss_ce: 0  loss_mask: 0.2624  loss_dice: 0.6604  loss_seg: 0.403  loss_ce_0: 0  loss_mask_0: 0.2564  loss_dice_0: 0.6759  loss_ce_1: 0  loss_mask_1: 0.2563  loss_dice_1: 0.6568  loss_ce_2: 0  loss_mask_2: 0.2555  loss_dice_2: 0.6556  loss_ce_3: 0  loss_mask_3: 0.2557  loss_dice_3: 0.6562  loss_ce_4: 0  loss_mask_4: 0.2546  loss_dice_4: 0.6554  loss_ce_5: 0  loss_mask_5: 0.2569  loss_dice_5: 0.6567  loss_ce_6: 0  loss_mask_6: 0.2583  loss_dice_6: 0.6561  loss_ce_7: 0  loss_mask_7: 0.2565  loss_dice_7: 0.6556  loss_ce_8: 0  loss_mask_8: 0.2578  loss_dice_8: 0.6571  time: 1.6850  data_time: 0.0514  lr: 9.6033e-05  max_mem: 5916M
[02/24 13:41:45] d2.utils.events INFO:  eta: 1 day, 2:31:02  iter: 2659  total_loss: 9.246  loss_ce: 0  loss_mask: 0.2518  loss_dice: 0.6452  loss_seg: 0.4041  loss_ce_0: 0  loss_mask_0: 0.2483  loss_dice_0: 0.663  loss_ce_1: 0  loss_mask_1: 0.2503  loss_dice_1: 0.6423  loss_ce_2: 0  loss_mask_2: 0.2485  loss_dice_2: 0.6396  loss_ce_3: 0  loss_mask_3: 0.2479  loss_dice_3: 0.6406  loss_ce_4: 0  loss_mask_4: 0.2482  loss_dice_4: 0.6414  loss_ce_5: 0  loss_mask_5: 0.2488  loss_dice_5: 0.6422  loss_ce_6: 0  loss_mask_6: 0.2501  loss_dice_6: 0.6436  loss_ce_7: 0  loss_mask_7: 0.2491  loss_dice_7: 0.645  loss_ce_8: 0  loss_mask_8: 0.2508  loss_dice_8: 0.6437  time: 1.6849  data_time: 0.0544  lr: 9.6003e-05  max_mem: 5916M
[02/24 13:42:18] d2.utils.events INFO:  eta: 1 day, 2:28:01  iter: 2679  total_loss: 9.191  loss_ce: 0  loss_mask: 0.257  loss_dice: 0.6319  loss_seg: 0.3614  loss_ce_0: 0  loss_mask_0: 0.2532  loss_dice_0: 0.6465  loss_ce_1: 0  loss_mask_1: 0.2576  loss_dice_1: 0.6215  loss_ce_2: 0  loss_mask_2: 0.2563  loss_dice_2: 0.6215  loss_ce_3: 0  loss_mask_3: 0.2565  loss_dice_3: 0.622  loss_ce_4: 0  loss_mask_4: 0.2571  loss_dice_4: 0.6215  loss_ce_5: 0  loss_mask_5: 0.2562  loss_dice_5: 0.6227  loss_ce_6: 0  loss_mask_6: 0.256  loss_dice_6: 0.6248  loss_ce_7: 0  loss_mask_7: 0.2577  loss_dice_7: 0.6251  loss_ce_8: 0  loss_mask_8: 0.2576  loss_dice_8: 0.6256  time: 1.6847  data_time: 0.0526  lr: 9.5972e-05  max_mem: 5916M
[02/24 13:42:52] d2.utils.events INFO:  eta: 1 day, 2:27:45  iter: 2699  total_loss: 9.528  loss_ce: 0  loss_mask: 0.2526  loss_dice: 0.6696  loss_seg: 0.4399  loss_ce_0: 0  loss_mask_0: 0.2458  loss_dice_0: 0.671  loss_ce_1: 0  loss_mask_1: 0.2501  loss_dice_1: 0.662  loss_ce_2: 0  loss_mask_2: 0.2495  loss_dice_2: 0.6626  loss_ce_3: 0  loss_mask_3: 0.2495  loss_dice_3: 0.6624  loss_ce_4: 0  loss_mask_4: 0.2511  loss_dice_4: 0.6618  loss_ce_5: 0  loss_mask_5: 0.2513  loss_dice_5: 0.6624  loss_ce_6: 0  loss_mask_6: 0.2521  loss_dice_6: 0.6616  loss_ce_7: 0  loss_mask_7: 0.2513  loss_dice_7: 0.661  loss_ce_8: 0  loss_mask_8: 0.2512  loss_dice_8: 0.6642  time: 1.6848  data_time: 0.0672  lr: 9.5942e-05  max_mem: 5916M
[02/24 13:43:26] d2.utils.events INFO:  eta: 1 day, 2:25:03  iter: 2719  total_loss: 9.202  loss_ce: 0  loss_mask: 0.241  loss_dice: 0.6436  loss_seg: 0.4188  loss_ce_0: 0  loss_mask_0: 0.2418  loss_dice_0: 0.6589  loss_ce_1: 0  loss_mask_1: 0.2422  loss_dice_1: 0.64  loss_ce_2: 0  loss_mask_2: 0.2418  loss_dice_2: 0.6378  loss_ce_3: 0  loss_mask_3: 0.2416  loss_dice_3: 0.6363  loss_ce_4: 0  loss_mask_4: 0.2417  loss_dice_4: 0.637  loss_ce_5: 0  loss_mask_5: 0.2418  loss_dice_5: 0.6376  loss_ce_6: 0  loss_mask_6: 0.2418  loss_dice_6: 0.6382  loss_ce_7: 0  loss_mask_7: 0.2423  loss_dice_7: 0.638  loss_ce_8: 0  loss_mask_8: 0.2417  loss_dice_8: 0.6371  time: 1.6845  data_time: 0.0505  lr: 9.5912e-05  max_mem: 5916M
[02/24 13:44:01] d2.utils.events INFO:  eta: 1 day, 2:24:30  iter: 2739  total_loss: 9.131  loss_ce: 0  loss_mask: 0.2523  loss_dice: 0.6396  loss_seg: 0.3859  loss_ce_0: 0  loss_mask_0: 0.246  loss_dice_0: 0.6566  loss_ce_1: 0  loss_mask_1: 0.2507  loss_dice_1: 0.6357  loss_ce_2: 0  loss_mask_2: 0.2509  loss_dice_2: 0.6336  loss_ce_3: 0  loss_mask_3: 0.2517  loss_dice_3: 0.6331  loss_ce_4: 0  loss_mask_4: 0.2512  loss_dice_4: 0.6321  loss_ce_5: 0  loss_mask_5: 0.2512  loss_dice_5: 0.6329  loss_ce_6: 0  loss_mask_6: 0.2517  loss_dice_6: 0.6355  loss_ce_7: 0  loss_mask_7: 0.2516  loss_dice_7: 0.6367  loss_ce_8: 0  loss_mask_8: 0.2527  loss_dice_8: 0.6373  time: 1.6850  data_time: 0.0603  lr: 9.5882e-05  max_mem: 5916M
[02/24 13:44:34] d2.utils.events INFO:  eta: 1 day, 2:22:36  iter: 2759  total_loss: 9.214  loss_ce: 0  loss_mask: 0.2416  loss_dice: 0.6408  loss_seg: 0.3917  loss_ce_0: 0  loss_mask_0: 0.2417  loss_dice_0: 0.6528  loss_ce_1: 0  loss_mask_1: 0.2428  loss_dice_1: 0.6383  loss_ce_2: 0  loss_mask_2: 0.2442  loss_dice_2: 0.6355  loss_ce_3: 0  loss_mask_3: 0.2451  loss_dice_3: 0.6339  loss_ce_4: 0  loss_mask_4: 0.2449  loss_dice_4: 0.6344  loss_ce_5: 0  loss_mask_5: 0.2451  loss_dice_5: 0.6348  loss_ce_6: 0  loss_mask_6: 0.2454  loss_dice_6: 0.6348  loss_ce_7: 0  loss_mask_7: 0.2449  loss_dice_7: 0.6346  loss_ce_8: 0  loss_mask_8: 0.2449  loss_dice_8: 0.6348  time: 1.6848  data_time: 0.0488  lr: 9.5852e-05  max_mem: 5916M
[02/24 13:45:07] d2.utils.events INFO:  eta: 1 day, 2:21:46  iter: 2779  total_loss: 9.402  loss_ce: 0  loss_mask: 0.2478  loss_dice: 0.6518  loss_seg: 0.4004  loss_ce_0: 0  loss_mask_0: 0.247  loss_dice_0: 0.664  loss_ce_1: 0  loss_mask_1: 0.2471  loss_dice_1: 0.6486  loss_ce_2: 0  loss_mask_2: 0.2467  loss_dice_2: 0.6477  loss_ce_3: 0  loss_mask_3: 0.2466  loss_dice_3: 0.6487  loss_ce_4: 0  loss_mask_4: 0.2478  loss_dice_4: 0.6489  loss_ce_5: 0  loss_mask_5: 0.247  loss_dice_5: 0.6493  loss_ce_6: 0  loss_mask_6: 0.2483  loss_dice_6: 0.6485  loss_ce_7: 0  loss_mask_7: 0.2498  loss_dice_7: 0.6495  loss_ce_8: 0  loss_mask_8: 0.2489  loss_dice_8: 0.648  time: 1.6845  data_time: 0.0508  lr: 9.5822e-05  max_mem: 5916M
[02/24 13:45:40] d2.utils.events INFO:  eta: 1 day, 2:21:13  iter: 2799  total_loss: 8.92  loss_ce: 0  loss_mask: 0.2404  loss_dice: 0.6202  loss_seg: 0.3621  loss_ce_0: 0  loss_mask_0: 0.2349  loss_dice_0: 0.6425  loss_ce_1: 0  loss_mask_1: 0.2372  loss_dice_1: 0.6182  loss_ce_2: 0  loss_mask_2: 0.2375  loss_dice_2: 0.6149  loss_ce_3: 0  loss_mask_3: 0.2371  loss_dice_3: 0.6137  loss_ce_4: 0  loss_mask_4: 0.2375  loss_dice_4: 0.6139  loss_ce_5: 0  loss_mask_5: 0.2386  loss_dice_5: 0.6147  loss_ce_6: 0  loss_mask_6: 0.2369  loss_dice_6: 0.6142  loss_ce_7: 0  loss_mask_7: 0.2368  loss_dice_7: 0.6159  loss_ce_8: 0  loss_mask_8: 0.2384  loss_dice_8: 0.617  time: 1.6843  data_time: 0.0453  lr: 9.5792e-05  max_mem: 5916M
[02/24 13:46:15] d2.utils.events INFO:  eta: 1 day, 2:20:39  iter: 2819  total_loss: 9.323  loss_ce: 0  loss_mask: 0.2477  loss_dice: 0.6439  loss_seg: 0.3635  loss_ce_0: 0  loss_mask_0: 0.2426  loss_dice_0: 0.6649  loss_ce_1: 0  loss_mask_1: 0.2448  loss_dice_1: 0.6414  loss_ce_2: 0  loss_mask_2: 0.2454  loss_dice_2: 0.6358  loss_ce_3: 0  loss_mask_3: 0.2472  loss_dice_3: 0.6358  loss_ce_4: 0  loss_mask_4: 0.2471  loss_dice_4: 0.6387  loss_ce_5: 0  loss_mask_5: 0.2481  loss_dice_5: 0.6389  loss_ce_6: 0  loss_mask_6: 0.2476  loss_dice_6: 0.6388  loss_ce_7: 0  loss_mask_7: 0.2486  loss_dice_7: 0.6388  loss_ce_8: 0  loss_mask_8: 0.2485  loss_dice_8: 0.6396  time: 1.6844  data_time: 0.0562  lr: 9.5761e-05  max_mem: 5916M
[02/24 13:46:48] d2.utils.events INFO:  eta: 1 day, 2:19:35  iter: 2839  total_loss: 9.26  loss_ce: 0  loss_mask: 0.2419  loss_dice: 0.6442  loss_seg: 0.3882  loss_ce_0: 0  loss_mask_0: 0.2342  loss_dice_0: 0.6602  loss_ce_1: 0  loss_mask_1: 0.2395  loss_dice_1: 0.6404  loss_ce_2: 0  loss_mask_2: 0.2416  loss_dice_2: 0.6363  loss_ce_3: 0  loss_mask_3: 0.242  loss_dice_3: 0.6367  loss_ce_4: 0  loss_mask_4: 0.2416  loss_dice_4: 0.6357  loss_ce_5: 0  loss_mask_5: 0.2424  loss_dice_5: 0.6372  loss_ce_6: 0  loss_mask_6: 0.2399  loss_dice_6: 0.638  loss_ce_7: 0  loss_mask_7: 0.2411  loss_dice_7: 0.6382  loss_ce_8: 0  loss_mask_8: 0.2405  loss_dice_8: 0.6393  time: 1.6842  data_time: 0.0467  lr: 9.5731e-05  max_mem: 5916M
[02/24 13:47:21] d2.utils.events INFO:  eta: 1 day, 2:18:36  iter: 2859  total_loss: 9.276  loss_ce: 0  loss_mask: 0.2496  loss_dice: 0.6449  loss_seg: 0.3994  loss_ce_0: 0  loss_mask_0: 0.2479  loss_dice_0: 0.6581  loss_ce_1: 0  loss_mask_1: 0.2491  loss_dice_1: 0.639  loss_ce_2: 0  loss_mask_2: 0.2481  loss_dice_2: 0.6382  loss_ce_3: 0  loss_mask_3: 0.2477  loss_dice_3: 0.6369  loss_ce_4: 0  loss_mask_4: 0.2488  loss_dice_4: 0.6357  loss_ce_5: 0  loss_mask_5: 0.2484  loss_dice_5: 0.6371  loss_ce_6: 0  loss_mask_6: 0.2492  loss_dice_6: 0.6375  loss_ce_7: 0  loss_mask_7: 0.2517  loss_dice_7: 0.6378  loss_ce_8: 0  loss_mask_8: 0.2518  loss_dice_8: 0.6391  time: 1.6841  data_time: 0.0524  lr: 9.5701e-05  max_mem: 5916M
[02/24 13:47:55] d2.utils.events INFO:  eta: 1 day, 2:16:03  iter: 2879  total_loss: 9.251  loss_ce: 0  loss_mask: 0.2464  loss_dice: 0.6336  loss_seg: 0.3844  loss_ce_0: 0  loss_mask_0: 0.2396  loss_dice_0: 0.6587  loss_ce_1: 0  loss_mask_1: 0.2434  loss_dice_1: 0.6315  loss_ce_2: 0  loss_mask_2: 0.2458  loss_dice_2: 0.628  loss_ce_3: 0  loss_mask_3: 0.2449  loss_dice_3: 0.6258  loss_ce_4: 0  loss_mask_4: 0.2461  loss_dice_4: 0.6262  loss_ce_5: 0  loss_mask_5: 0.2462  loss_dice_5: 0.6269  loss_ce_6: 0  loss_mask_6: 0.2441  loss_dice_6: 0.627  loss_ce_7: 0  loss_mask_7: 0.2449  loss_dice_7: 0.6298  loss_ce_8: 0  loss_mask_8: 0.245  loss_dice_8: 0.6281  time: 1.6839  data_time: 0.0550  lr: 9.5671e-05  max_mem: 5916M
[02/24 13:48:29] d2.utils.events INFO:  eta: 1 day, 2:18:10  iter: 2899  total_loss: 9.224  loss_ce: 0  loss_mask: 0.2426  loss_dice: 0.6407  loss_seg: 0.3819  loss_ce_0: 0  loss_mask_0: 0.2396  loss_dice_0: 0.6533  loss_ce_1: 0  loss_mask_1: 0.2436  loss_dice_1: 0.6388  loss_ce_2: 0  loss_mask_2: 0.2413  loss_dice_2: 0.6391  loss_ce_3: 0  loss_mask_3: 0.2411  loss_dice_3: 0.6398  loss_ce_4: 0  loss_mask_4: 0.2418  loss_dice_4: 0.6388  loss_ce_5: 0  loss_mask_5: 0.2406  loss_dice_5: 0.6387  loss_ce_6: 0  loss_mask_6: 0.2416  loss_dice_6: 0.6393  loss_ce_7: 0  loss_mask_7: 0.2433  loss_dice_7: 0.6393  loss_ce_8: 0  loss_mask_8: 0.2422  loss_dice_8: 0.6374  time: 1.6839  data_time: 0.0639  lr: 9.5641e-05  max_mem: 5916M
[02/24 13:49:03] d2.utils.events INFO:  eta: 1 day, 2:18:19  iter: 2919  total_loss: 9.274  loss_ce: 0  loss_mask: 0.2448  loss_dice: 0.645  loss_seg: 0.3996  loss_ce_0: 0  loss_mask_0: 0.2358  loss_dice_0: 0.656  loss_ce_1: 0  loss_mask_1: 0.2401  loss_dice_1: 0.6381  loss_ce_2: 0  loss_mask_2: 0.2405  loss_dice_2: 0.6377  loss_ce_3: 0  loss_mask_3: 0.2414  loss_dice_3: 0.6363  loss_ce_4: 0  loss_mask_4: 0.2414  loss_dice_4: 0.6376  loss_ce_5: 0  loss_mask_5: 0.2416  loss_dice_5: 0.6386  loss_ce_6: 0  loss_mask_6: 0.2419  loss_dice_6: 0.6382  loss_ce_7: 0  loss_mask_7: 0.243  loss_dice_7: 0.638  loss_ce_8: 0  loss_mask_8: 0.242  loss_dice_8: 0.6383  time: 1.6840  data_time: 0.0545  lr: 9.5611e-05  max_mem: 5916M
[02/24 13:49:36] d2.utils.events INFO:  eta: 1 day, 2:16:38  iter: 2939  total_loss: 9.081  loss_ce: 0  loss_mask: 0.2492  loss_dice: 0.6334  loss_seg: 0.3637  loss_ce_0: 0  loss_mask_0: 0.2413  loss_dice_0: 0.6473  loss_ce_1: 0  loss_mask_1: 0.2458  loss_dice_1: 0.6343  loss_ce_2: 0  loss_mask_2: 0.2458  loss_dice_2: 0.6285  loss_ce_3: 0  loss_mask_3: 0.2454  loss_dice_3: 0.6268  loss_ce_4: 0  loss_mask_4: 0.2455  loss_dice_4: 0.6287  loss_ce_5: 0  loss_mask_5: 0.2456  loss_dice_5: 0.6274  loss_ce_6: 0  loss_mask_6: 0.2457  loss_dice_6: 0.6268  loss_ce_7: 0  loss_mask_7: 0.2465  loss_dice_7: 0.6283  loss_ce_8: 0  loss_mask_8: 0.2478  loss_dice_8: 0.6264  time: 1.6838  data_time: 0.0545  lr: 9.5581e-05  max_mem: 5916M
[02/24 13:50:09] d2.utils.events INFO:  eta: 1 day, 2:15:51  iter: 2959  total_loss: 9.286  loss_ce: 0  loss_mask: 0.2455  loss_dice: 0.6408  loss_seg: 0.3872  loss_ce_0: 0  loss_mask_0: 0.2387  loss_dice_0: 0.6576  loss_ce_1: 0  loss_mask_1: 0.2423  loss_dice_1: 0.6395  loss_ce_2: 0  loss_mask_2: 0.2434  loss_dice_2: 0.6359  loss_ce_3: 0  loss_mask_3: 0.2433  loss_dice_3: 0.635  loss_ce_4: 0  loss_mask_4: 0.2432  loss_dice_4: 0.6364  loss_ce_5: 0  loss_mask_5: 0.2425  loss_dice_5: 0.6363  loss_ce_6: 0  loss_mask_6: 0.2433  loss_dice_6: 0.6384  loss_ce_7: 0  loss_mask_7: 0.245  loss_dice_7: 0.6374  loss_ce_8: 0  loss_mask_8: 0.2444  loss_dice_8: 0.6386  time: 1.6836  data_time: 0.0510  lr: 9.555e-05  max_mem: 5916M
[02/24 13:50:42] d2.utils.events INFO:  eta: 1 day, 2:14:56  iter: 2979  total_loss: 9.337  loss_ce: 0  loss_mask: 0.2452  loss_dice: 0.6393  loss_seg: 0.4089  loss_ce_0: 0  loss_mask_0: 0.2402  loss_dice_0: 0.6543  loss_ce_1: 0  loss_mask_1: 0.2421  loss_dice_1: 0.636  loss_ce_2: 0  loss_mask_2: 0.2432  loss_dice_2: 0.6354  loss_ce_3: 0  loss_mask_3: 0.2429  loss_dice_3: 0.6344  loss_ce_4: 0  loss_mask_4: 0.2445  loss_dice_4: 0.6331  loss_ce_5: 0  loss_mask_5: 0.2438  loss_dice_5: 0.6327  loss_ce_6: 0  loss_mask_6: 0.2448  loss_dice_6: 0.6312  loss_ce_7: 0  loss_mask_7: 0.2446  loss_dice_7: 0.6337  loss_ce_8: 0  loss_mask_8: 0.2456  loss_dice_8: 0.6353  time: 1.6832  data_time: 0.0531  lr: 9.552e-05  max_mem: 5916M
[02/24 13:51:15] d2.utils.events INFO:  eta: 1 day, 2:13:17  iter: 2999  total_loss: 9.124  loss_ce: 0  loss_mask: 0.2368  loss_dice: 0.6278  loss_seg: 0.3957  loss_ce_0: 0  loss_mask_0: 0.237  loss_dice_0: 0.6393  loss_ce_1: 0  loss_mask_1: 0.2359  loss_dice_1: 0.627  loss_ce_2: 0  loss_mask_2: 0.2346  loss_dice_2: 0.6251  loss_ce_3: 0  loss_mask_3: 0.2344  loss_dice_3: 0.6236  loss_ce_4: 0  loss_mask_4: 0.2344  loss_dice_4: 0.6239  loss_ce_5: 0  loss_mask_5: 0.2355  loss_dice_5: 0.6237  loss_ce_6: 0  loss_mask_6: 0.2344  loss_dice_6: 0.6233  loss_ce_7: 0  loss_mask_7: 0.2353  loss_dice_7: 0.6248  loss_ce_8: 0  loss_mask_8: 0.235  loss_dice_8: 0.625  time: 1.6831  data_time: 0.0570  lr: 9.549e-05  max_mem: 5916M
[02/24 13:51:50] d2.utils.events INFO:  eta: 1 day, 2:14:36  iter: 3019  total_loss: 8.95  loss_ce: 0  loss_mask: 0.2443  loss_dice: 0.621  loss_seg: 0.3751  loss_ce_0: 0  loss_mask_0: 0.2389  loss_dice_0: 0.6393  loss_ce_1: 0  loss_mask_1: 0.2406  loss_dice_1: 0.6184  loss_ce_2: 0  loss_mask_2: 0.2421  loss_dice_2: 0.6167  loss_ce_3: 0  loss_mask_3: 0.242  loss_dice_3: 0.6142  loss_ce_4: 0  loss_mask_4: 0.2405  loss_dice_4: 0.6132  loss_ce_5: 0  loss_mask_5: 0.2424  loss_dice_5: 0.6147  loss_ce_6: 0  loss_mask_6: 0.2431  loss_dice_6: 0.6154  loss_ce_7: 0  loss_mask_7: 0.2408  loss_dice_7: 0.6161  loss_ce_8: 0  loss_mask_8: 0.242  loss_dice_8: 0.6182  time: 1.6833  data_time: 0.0623  lr: 9.546e-05  max_mem: 5916M
[02/24 13:52:24] d2.utils.events INFO:  eta: 1 day, 2:15:42  iter: 3039  total_loss: 9.135  loss_ce: 0  loss_mask: 0.2431  loss_dice: 0.6299  loss_seg: 0.386  loss_ce_0: 0  loss_mask_0: 0.2392  loss_dice_0: 0.6422  loss_ce_1: 0  loss_mask_1: 0.2392  loss_dice_1: 0.6235  loss_ce_2: 0  loss_mask_2: 0.2405  loss_dice_2: 0.6245  loss_ce_3: 0  loss_mask_3: 0.2407  loss_dice_3: 0.6234  loss_ce_4: 0  loss_mask_4: 0.2407  loss_dice_4: 0.6227  loss_ce_5: 0  loss_mask_5: 0.2424  loss_dice_5: 0.6228  loss_ce_6: 0  loss_mask_6: 0.2428  loss_dice_6: 0.6233  loss_ce_7: 0  loss_mask_7: 0.2421  loss_dice_7: 0.6221  loss_ce_8: 0  loss_mask_8: 0.2422  loss_dice_8: 0.6238  time: 1.6834  data_time: 0.0658  lr: 9.543e-05  max_mem: 5916M
[02/24 13:52:57] d2.utils.events INFO:  eta: 1 day, 2:14:27  iter: 3059  total_loss: 8.992  loss_ce: 0  loss_mask: 0.235  loss_dice: 0.6279  loss_seg: 0.3808  loss_ce_0: 0  loss_mask_0: 0.2334  loss_dice_0: 0.6466  loss_ce_1: 0  loss_mask_1: 0.2368  loss_dice_1: 0.6255  loss_ce_2: 0  loss_mask_2: 0.2372  loss_dice_2: 0.6241  loss_ce_3: 0  loss_mask_3: 0.2364  loss_dice_3: 0.6245  loss_ce_4: 0  loss_mask_4: 0.2352  loss_dice_4: 0.6249  loss_ce_5: 0  loss_mask_5: 0.2341  loss_dice_5: 0.6255  loss_ce_6: 0  loss_mask_6: 0.2371  loss_dice_6: 0.6249  loss_ce_7: 0  loss_mask_7: 0.2369  loss_dice_7: 0.6261  loss_ce_8: 0  loss_mask_8: 0.2363  loss_dice_8: 0.6244  time: 1.6832  data_time: 0.0506  lr: 9.54e-05  max_mem: 5916M
[02/24 13:53:32] d2.utils.events INFO:  eta: 1 day, 2:16:41  iter: 3079  total_loss: 8.877  loss_ce: 0  loss_mask: 0.2463  loss_dice: 0.6196  loss_seg: 0.3608  loss_ce_0: 0  loss_mask_0: 0.2447  loss_dice_0: 0.6383  loss_ce_1: 0  loss_mask_1: 0.2424  loss_dice_1: 0.6174  loss_ce_2: 0  loss_mask_2: 0.2423  loss_dice_2: 0.6131  loss_ce_3: 0  loss_mask_3: 0.2426  loss_dice_3: 0.6117  loss_ce_4: 0  loss_mask_4: 0.243  loss_dice_4: 0.6123  loss_ce_5: 0  loss_mask_5: 0.243  loss_dice_5: 0.6132  loss_ce_6: 0  loss_mask_6: 0.2417  loss_dice_6: 0.6142  loss_ce_7: 0  loss_mask_7: 0.2425  loss_dice_7: 0.614  loss_ce_8: 0  loss_mask_8: 0.2433  loss_dice_8: 0.6148  time: 1.6836  data_time: 0.0458  lr: 9.5369e-05  max_mem: 5916M
[02/24 13:54:06] d2.utils.events INFO:  eta: 1 day, 2:17:05  iter: 3099  total_loss: 9.415  loss_ce: 0  loss_mask: 0.2408  loss_dice: 0.6532  loss_seg: 0.3902  loss_ce_0: 0  loss_mask_0: 0.234  loss_dice_0: 0.6589  loss_ce_1: 0  loss_mask_1: 0.2399  loss_dice_1: 0.6464  loss_ce_2: 0  loss_mask_2: 0.2393  loss_dice_2: 0.6449  loss_ce_3: 0  loss_mask_3: 0.2404  loss_dice_3: 0.6454  loss_ce_4: 0  loss_mask_4: 0.2395  loss_dice_4: 0.6467  loss_ce_5: 0  loss_mask_5: 0.2396  loss_dice_5: 0.645  loss_ce_6: 0  loss_mask_6: 0.2405  loss_dice_6: 0.6452  loss_ce_7: 0  loss_mask_7: 0.2406  loss_dice_7: 0.6466  loss_ce_8: 0  loss_mask_8: 0.2411  loss_dice_8: 0.6465  time: 1.6835  data_time: 0.0655  lr: 9.5339e-05  max_mem: 5916M
[02/24 13:54:40] d2.utils.events INFO:  eta: 1 day, 2:18:18  iter: 3119  total_loss: 8.98  loss_ce: 0  loss_mask: 0.2362  loss_dice: 0.6356  loss_seg: 0.3622  loss_ce_0: 0  loss_mask_0: 0.2308  loss_dice_0: 0.6449  loss_ce_1: 0  loss_mask_1: 0.2359  loss_dice_1: 0.6294  loss_ce_2: 0  loss_mask_2: 0.2344  loss_dice_2: 0.629  loss_ce_3: 0  loss_mask_3: 0.2349  loss_dice_3: 0.6288  loss_ce_4: 0  loss_mask_4: 0.2356  loss_dice_4: 0.628  loss_ce_5: 0  loss_mask_5: 0.2363  loss_dice_5: 0.6304  loss_ce_6: 0  loss_mask_6: 0.2371  loss_dice_6: 0.6327  loss_ce_7: 0  loss_mask_7: 0.2344  loss_dice_7: 0.6317  loss_ce_8: 0  loss_mask_8: 0.2346  loss_dice_8: 0.6303  time: 1.6835  data_time: 0.0540  lr: 9.5309e-05  max_mem: 5916M
[02/24 13:55:11] d2.utils.events INFO:  eta: 1 day, 2:17:24  iter: 3139  total_loss: 9.105  loss_ce: 0  loss_mask: 0.2419  loss_dice: 0.6287  loss_seg: 0.3659  loss_ce_0: 0  loss_mask_0: 0.2387  loss_dice_0: 0.6422  loss_ce_1: 0  loss_mask_1: 0.242  loss_dice_1: 0.6268  loss_ce_2: 0  loss_mask_2: 0.2413  loss_dice_2: 0.6241  loss_ce_3: 0  loss_mask_3: 0.2437  loss_dice_3: 0.6243  loss_ce_4: 0  loss_mask_4: 0.2449  loss_dice_4: 0.6239  loss_ce_5: 0  loss_mask_5: 0.2442  loss_dice_5: 0.6246  loss_ce_6: 0  loss_mask_6: 0.2429  loss_dice_6: 0.6268  loss_ce_7: 0  loss_mask_7: 0.2444  loss_dice_7: 0.6246  loss_ce_8: 0  loss_mask_8: 0.2424  loss_dice_8: 0.6254  time: 1.6827  data_time: 0.0505  lr: 9.5279e-05  max_mem: 5916M
[02/24 13:55:46] d2.utils.events INFO:  eta: 1 day, 2:17:11  iter: 3159  total_loss: 9.183  loss_ce: 0  loss_mask: 0.233  loss_dice: 0.6263  loss_seg: 0.3916  loss_ce_0: 0  loss_mask_0: 0.2261  loss_dice_0: 0.6498  loss_ce_1: 0  loss_mask_1: 0.2312  loss_dice_1: 0.6276  loss_ce_2: 0  loss_mask_2: 0.2306  loss_dice_2: 0.6249  loss_ce_3: 0  loss_mask_3: 0.2309  loss_dice_3: 0.6249  loss_ce_4: 0  loss_mask_4: 0.2311  loss_dice_4: 0.624  loss_ce_5: 0  loss_mask_5: 0.2294  loss_dice_5: 0.6244  loss_ce_6: 0  loss_mask_6: 0.2295  loss_dice_6: 0.6254  loss_ce_7: 0  loss_mask_7: 0.2307  loss_dice_7: 0.6242  loss_ce_8: 0  loss_mask_8: 0.232  loss_dice_8: 0.6237  time: 1.6830  data_time: 0.0567  lr: 9.5249e-05  max_mem: 5916M
[02/24 13:56:20] d2.utils.events INFO:  eta: 1 day, 2:16:58  iter: 3179  total_loss: 9.119  loss_ce: 0  loss_mask: 0.2393  loss_dice: 0.631  loss_seg: 0.3804  loss_ce_0: 0  loss_mask_0: 0.2349  loss_dice_0: 0.6496  loss_ce_1: 0  loss_mask_1: 0.2364  loss_dice_1: 0.6289  loss_ce_2: 0  loss_mask_2: 0.2363  loss_dice_2: 0.6261  loss_ce_3: 0  loss_mask_3: 0.2358  loss_dice_3: 0.6262  loss_ce_4: 0  loss_mask_4: 0.2356  loss_dice_4: 0.6262  loss_ce_5: 0  loss_mask_5: 0.2358  loss_dice_5: 0.627  loss_ce_6: 0  loss_mask_6: 0.2358  loss_dice_6: 0.6263  loss_ce_7: 0  loss_mask_7: 0.2355  loss_dice_7: 0.6274  loss_ce_8: 0  loss_mask_8: 0.2361  loss_dice_8: 0.6274  time: 1.6831  data_time: 0.0607  lr: 9.5219e-05  max_mem: 5916M
[02/24 13:56:53] d2.utils.events INFO:  eta: 1 day, 2:15:37  iter: 3199  total_loss: 9.148  loss_ce: 0  loss_mask: 0.2444  loss_dice: 0.6493  loss_seg: 0.3986  loss_ce_0: 0  loss_mask_0: 0.2376  loss_dice_0: 0.657  loss_ce_1: 0  loss_mask_1: 0.2388  loss_dice_1: 0.6415  loss_ce_2: 0  loss_mask_2: 0.2394  loss_dice_2: 0.6418  loss_ce_3: 0  loss_mask_3: 0.241  loss_dice_3: 0.641  loss_ce_4: 0  loss_mask_4: 0.242  loss_dice_4: 0.6432  loss_ce_5: 0  loss_mask_5: 0.2425  loss_dice_5: 0.6448  loss_ce_6: 0  loss_mask_6: 0.2429  loss_dice_6: 0.6434  loss_ce_7: 0  loss_mask_7: 0.2441  loss_dice_7: 0.644  loss_ce_8: 0  loss_mask_8: 0.2435  loss_dice_8: 0.6443  time: 1.6829  data_time: 0.0566  lr: 9.5188e-05  max_mem: 5916M
[02/24 13:57:25] d2.utils.events INFO:  eta: 1 day, 2:13:44  iter: 3219  total_loss: 8.891  loss_ce: 0  loss_mask: 0.2422  loss_dice: 0.6124  loss_seg: 0.3658  loss_ce_0: 0  loss_mask_0: 0.2405  loss_dice_0: 0.6321  loss_ce_1: 0  loss_mask_1: 0.2424  loss_dice_1: 0.6101  loss_ce_2: 0  loss_mask_2: 0.2416  loss_dice_2: 0.608  loss_ce_3: 0  loss_mask_3: 0.2422  loss_dice_3: 0.6078  loss_ce_4: 0  loss_mask_4: 0.2417  loss_dice_4: 0.6088  loss_ce_5: 0  loss_mask_5: 0.2417  loss_dice_5: 0.6091  loss_ce_6: 0  loss_mask_6: 0.2429  loss_dice_6: 0.6085  loss_ce_7: 0  loss_mask_7: 0.2426  loss_dice_7: 0.6081  loss_ce_8: 0  loss_mask_8: 0.2411  loss_dice_8: 0.6092  time: 1.6825  data_time: 0.0567  lr: 9.5158e-05  max_mem: 5916M
[02/24 13:57:59] d2.utils.events INFO:  eta: 1 day, 2:13:25  iter: 3239  total_loss: 8.863  loss_ce: 0  loss_mask: 0.2313  loss_dice: 0.6038  loss_seg: 0.3446  loss_ce_0: 0  loss_mask_0: 0.2299  loss_dice_0: 0.625  loss_ce_1: 0  loss_mask_1: 0.2296  loss_dice_1: 0.5999  loss_ce_2: 0  loss_mask_2: 0.2304  loss_dice_2: 0.5993  loss_ce_3: 0  loss_mask_3: 0.2318  loss_dice_3: 0.5969  loss_ce_4: 0  loss_mask_4: 0.232  loss_dice_4: 0.5965  loss_ce_5: 0  loss_mask_5: 0.2313  loss_dice_5: 0.5975  loss_ce_6: 0  loss_mask_6: 0.2329  loss_dice_6: 0.5995  loss_ce_7: 0  loss_mask_7: 0.2325  loss_dice_7: 0.5987  loss_ce_8: 0  loss_mask_8: 0.233  loss_dice_8: 0.5979  time: 1.6826  data_time: 0.0580  lr: 9.5128e-05  max_mem: 5916M
[02/24 13:58:33] d2.utils.events INFO:  eta: 1 day, 2:12:38  iter: 3259  total_loss: 9.065  loss_ce: 0  loss_mask: 0.2384  loss_dice: 0.632  loss_seg: 0.3484  loss_ce_0: 0  loss_mask_0: 0.2378  loss_dice_0: 0.637  loss_ce_1: 0  loss_mask_1: 0.24  loss_dice_1: 0.6284  loss_ce_2: 0  loss_mask_2: 0.2372  loss_dice_2: 0.6269  loss_ce_3: 0  loss_mask_3: 0.2378  loss_dice_3: 0.627  loss_ce_4: 0  loss_mask_4: 0.2381  loss_dice_4: 0.6264  loss_ce_5: 0  loss_mask_5: 0.2383  loss_dice_5: 0.6263  loss_ce_6: 0  loss_mask_6: 0.2383  loss_dice_6: 0.6252  loss_ce_7: 0  loss_mask_7: 0.2401  loss_dice_7: 0.6249  loss_ce_8: 0  loss_mask_8: 0.239  loss_dice_8: 0.6252  time: 1.6824  data_time: 0.0565  lr: 9.5098e-05  max_mem: 5916M
[02/24 13:59:07] d2.utils.events INFO:  eta: 1 day, 2:11:18  iter: 3279  total_loss: 9.062  loss_ce: 0  loss_mask: 0.2308  loss_dice: 0.6348  loss_seg: 0.426  loss_ce_0: 0  loss_mask_0: 0.2271  loss_dice_0: 0.6562  loss_ce_1: 0  loss_mask_1: 0.2292  loss_dice_1: 0.6352  loss_ce_2: 0  loss_mask_2: 0.23  loss_dice_2: 0.632  loss_ce_3: 0  loss_mask_3: 0.2307  loss_dice_3: 0.6308  loss_ce_4: 0  loss_mask_4: 0.2302  loss_dice_4: 0.6311  loss_ce_5: 0  loss_mask_5: 0.2303  loss_dice_5: 0.631  loss_ce_6: 0  loss_mask_6: 0.2311  loss_dice_6: 0.6325  loss_ce_7: 0  loss_mask_7: 0.2298  loss_dice_7: 0.6336  loss_ce_8: 0  loss_mask_8: 0.229  loss_dice_8: 0.6342  time: 1.6824  data_time: 0.0529  lr: 9.5068e-05  max_mem: 5916M
[02/24 13:59:40] d2.utils.events INFO:  eta: 1 day, 2:11:09  iter: 3299  total_loss: 8.91  loss_ce: 0  loss_mask: 0.2379  loss_dice: 0.6144  loss_seg: 0.3956  loss_ce_0: 0  loss_mask_0: 0.2371  loss_dice_0: 0.6303  loss_ce_1: 0  loss_mask_1: 0.2378  loss_dice_1: 0.6102  loss_ce_2: 0  loss_mask_2: 0.2362  loss_dice_2: 0.6083  loss_ce_3: 0  loss_mask_3: 0.237  loss_dice_3: 0.6095  loss_ce_4: 0  loss_mask_4: 0.2372  loss_dice_4: 0.6101  loss_ce_5: 0  loss_mask_5: 0.2372  loss_dice_5: 0.6105  loss_ce_6: 0  loss_mask_6: 0.2371  loss_dice_6: 0.6113  loss_ce_7: 0  loss_mask_7: 0.2374  loss_dice_7: 0.6103  loss_ce_8: 0  loss_mask_8: 0.2374  loss_dice_8: 0.612  time: 1.6824  data_time: 0.0558  lr: 9.5038e-05  max_mem: 5916M
[02/24 14:00:14] d2.utils.events INFO:  eta: 1 day, 2:09:39  iter: 3319  total_loss: 8.901  loss_ce: 0  loss_mask: 0.2336  loss_dice: 0.613  loss_seg: 0.3471  loss_ce_0: 0  loss_mask_0: 0.2284  loss_dice_0: 0.63  loss_ce_1: 0  loss_mask_1: 0.2292  loss_dice_1: 0.609  loss_ce_2: 0  loss_mask_2: 0.23  loss_dice_2: 0.607  loss_ce_3: 0  loss_mask_3: 0.2302  loss_dice_3: 0.607  loss_ce_4: 0  loss_mask_4: 0.231  loss_dice_4: 0.6079  loss_ce_5: 0  loss_mask_5: 0.2304  loss_dice_5: 0.6086  loss_ce_6: 0  loss_mask_6: 0.2306  loss_dice_6: 0.6088  loss_ce_7: 0  loss_mask_7: 0.2313  loss_dice_7: 0.6085  loss_ce_8: 0  loss_mask_8: 0.2317  loss_dice_8: 0.6101  time: 1.6824  data_time: 0.0490  lr: 9.5007e-05  max_mem: 5916M
[02/24 14:00:49] d2.utils.events INFO:  eta: 1 day, 2:10:39  iter: 3339  total_loss: 8.934  loss_ce: 0  loss_mask: 0.2423  loss_dice: 0.6309  loss_seg: 0.3604  loss_ce_0: 0  loss_mask_0: 0.2324  loss_dice_0: 0.6382  loss_ce_1: 0  loss_mask_1: 0.2406  loss_dice_1: 0.6255  loss_ce_2: 0  loss_mask_2: 0.2404  loss_dice_2: 0.625  loss_ce_3: 0  loss_mask_3: 0.2414  loss_dice_3: 0.6237  loss_ce_4: 0  loss_mask_4: 0.2421  loss_dice_4: 0.6236  loss_ce_5: 0  loss_mask_5: 0.2428  loss_dice_5: 0.6235  loss_ce_6: 0  loss_mask_6: 0.2419  loss_dice_6: 0.6237  loss_ce_7: 0  loss_mask_7: 0.2417  loss_dice_7: 0.6227  loss_ce_8: 0  loss_mask_8: 0.2426  loss_dice_8: 0.625  time: 1.6827  data_time: 0.0513  lr: 9.4977e-05  max_mem: 5916M
[02/24 14:01:23] d2.utils.events INFO:  eta: 1 day, 2:10:06  iter: 3359  total_loss: 9.218  loss_ce: 0  loss_mask: 0.2352  loss_dice: 0.6416  loss_seg: 0.4074  loss_ce_0: 0  loss_mask_0: 0.2337  loss_dice_0: 0.6532  loss_ce_1: 0  loss_mask_1: 0.2335  loss_dice_1: 0.6323  loss_ce_2: 0  loss_mask_2: 0.2336  loss_dice_2: 0.6302  loss_ce_3: 0  loss_mask_3: 0.2332  loss_dice_3: 0.6291  loss_ce_4: 0  loss_mask_4: 0.2343  loss_dice_4: 0.629  loss_ce_5: 0  loss_mask_5: 0.2352  loss_dice_5: 0.6303  loss_ce_6: 0  loss_mask_6: 0.2349  loss_dice_6: 0.6327  loss_ce_7: 0  loss_mask_7: 0.2339  loss_dice_7: 0.632  loss_ce_8: 0  loss_mask_8: 0.2338  loss_dice_8: 0.6342  time: 1.6827  data_time: 0.0569  lr: 9.4947e-05  max_mem: 5916M
[02/24 14:01:56] d2.utils.events INFO:  eta: 1 day, 2:08:56  iter: 3379  total_loss: 8.846  loss_ce: 0  loss_mask: 0.2314  loss_dice: 0.6247  loss_seg: 0.3723  loss_ce_0: 0  loss_mask_0: 0.2232  loss_dice_0: 0.6376  loss_ce_1: 0  loss_mask_1: 0.2251  loss_dice_1: 0.622  loss_ce_2: 0  loss_mask_2: 0.2266  loss_dice_2: 0.6197  loss_ce_3: 0  loss_mask_3: 0.2278  loss_dice_3: 0.618  loss_ce_4: 0  loss_mask_4: 0.23  loss_dice_4: 0.6174  loss_ce_5: 0  loss_mask_5: 0.2288  loss_dice_5: 0.6183  loss_ce_6: 0  loss_mask_6: 0.2298  loss_dice_6: 0.6193  loss_ce_7: 0  loss_mask_7: 0.2315  loss_dice_7: 0.6191  loss_ce_8: 0  loss_mask_8: 0.2319  loss_dice_8: 0.6205  time: 1.6826  data_time: 0.0579  lr: 9.4917e-05  max_mem: 5916M
[02/24 14:02:29] d2.utils.events INFO:  eta: 1 day, 2:06:46  iter: 3399  total_loss: 8.964  loss_ce: 0  loss_mask: 0.2308  loss_dice: 0.623  loss_seg: 0.357  loss_ce_0: 0  loss_mask_0: 0.2305  loss_dice_0: 0.6394  loss_ce_1: 0  loss_mask_1: 0.2331  loss_dice_1: 0.6206  loss_ce_2: 0  loss_mask_2: 0.2338  loss_dice_2: 0.6178  loss_ce_3: 0  loss_mask_3: 0.2353  loss_dice_3: 0.6157  loss_ce_4: 0  loss_mask_4: 0.2336  loss_dice_4: 0.6173  loss_ce_5: 0  loss_mask_5: 0.2342  loss_dice_5: 0.6176  loss_ce_6: 0  loss_mask_6: 0.234  loss_dice_6: 0.617  loss_ce_7: 0  loss_mask_7: 0.2332  loss_dice_7: 0.6175  loss_ce_8: 0  loss_mask_8: 0.2326  loss_dice_8: 0.6177  time: 1.6823  data_time: 0.0531  lr: 9.4887e-05  max_mem: 5916M
[02/24 14:03:03] d2.utils.events INFO:  eta: 1 day, 2:07:34  iter: 3419  total_loss: 8.917  loss_ce: 0  loss_mask: 0.2338  loss_dice: 0.6243  loss_seg: 0.3658  loss_ce_0: 0  loss_mask_0: 0.2333  loss_dice_0: 0.6349  loss_ce_1: 0  loss_mask_1: 0.2333  loss_dice_1: 0.6217  loss_ce_2: 0  loss_mask_2: 0.2353  loss_dice_2: 0.6198  loss_ce_3: 0  loss_mask_3: 0.2368  loss_dice_3: 0.6201  loss_ce_4: 0  loss_mask_4: 0.2361  loss_dice_4: 0.6189  loss_ce_5: 0  loss_mask_5: 0.2361  loss_dice_5: 0.6189  loss_ce_6: 0  loss_mask_6: 0.2366  loss_dice_6: 0.6199  loss_ce_7: 0  loss_mask_7: 0.234  loss_dice_7: 0.6196  loss_ce_8: 0  loss_mask_8: 0.2348  loss_dice_8: 0.6189  time: 1.6824  data_time: 0.0526  lr: 9.4857e-05  max_mem: 5916M
[02/24 14:03:35] d2.utils.events INFO:  eta: 1 day, 2:05:39  iter: 3439  total_loss: 8.856  loss_ce: 0  loss_mask: 0.2403  loss_dice: 0.6064  loss_seg: 0.3641  loss_ce_0: 0  loss_mask_0: 0.2378  loss_dice_0: 0.6266  loss_ce_1: 0  loss_mask_1: 0.2373  loss_dice_1: 0.6049  loss_ce_2: 0  loss_mask_2: 0.2371  loss_dice_2: 0.6036  loss_ce_3: 0  loss_mask_3: 0.2378  loss_dice_3: 0.6024  loss_ce_4: 0  loss_mask_4: 0.2398  loss_dice_4: 0.6016  loss_ce_5: 0  loss_mask_5: 0.2395  loss_dice_5: 0.6025  loss_ce_6: 0  loss_mask_6: 0.24  loss_dice_6: 0.6039  loss_ce_7: 0  loss_mask_7: 0.2396  loss_dice_7: 0.6028  loss_ce_8: 0  loss_mask_8: 0.2393  loss_dice_8: 0.6027  time: 1.6818  data_time: 0.0635  lr: 9.4826e-05  max_mem: 5916M
[02/24 14:04:08] d2.utils.events INFO:  eta: 1 day, 2:04:28  iter: 3459  total_loss: 8.926  loss_ce: 0  loss_mask: 0.241  loss_dice: 0.6158  loss_seg: 0.3601  loss_ce_0: 0  loss_mask_0: 0.2374  loss_dice_0: 0.6384  loss_ce_1: 0  loss_mask_1: 0.2389  loss_dice_1: 0.612  loss_ce_2: 0  loss_mask_2: 0.2393  loss_dice_2: 0.6096  loss_ce_3: 0  loss_mask_3: 0.2391  loss_dice_3: 0.6077  loss_ce_4: 0  loss_mask_4: 0.2383  loss_dice_4: 0.6102  loss_ce_5: 0  loss_mask_5: 0.2383  loss_dice_5: 0.6096  loss_ce_6: 0  loss_mask_6: 0.239  loss_dice_6: 0.6099  loss_ce_7: 0  loss_mask_7: 0.2398  loss_dice_7: 0.61  loss_ce_8: 0  loss_mask_8: 0.2396  loss_dice_8: 0.6116  time: 1.6817  data_time: 0.0675  lr: 9.4796e-05  max_mem: 5916M
[02/24 14:04:42] d2.utils.events INFO:  eta: 1 day, 2:03:55  iter: 3479  total_loss: 9.016  loss_ce: 0  loss_mask: 0.2357  loss_dice: 0.6246  loss_seg: 0.404  loss_ce_0: 0  loss_mask_0: 0.2322  loss_dice_0: 0.642  loss_ce_1: 0  loss_mask_1: 0.2343  loss_dice_1: 0.6237  loss_ce_2: 0  loss_mask_2: 0.2345  loss_dice_2: 0.6198  loss_ce_3: 0  loss_mask_3: 0.2326  loss_dice_3: 0.6177  loss_ce_4: 0  loss_mask_4: 0.2334  loss_dice_4: 0.6173  loss_ce_5: 0  loss_mask_5: 0.2335  loss_dice_5: 0.6182  loss_ce_6: 0  loss_mask_6: 0.2339  loss_dice_6: 0.6191  loss_ce_7: 0  loss_mask_7: 0.2355  loss_dice_7: 0.6193  loss_ce_8: 0  loss_mask_8: 0.2354  loss_dice_8: 0.6185  time: 1.6817  data_time: 0.0647  lr: 9.4766e-05  max_mem: 5916M
[02/24 14:05:16] d2.utils.events INFO:  eta: 1 day, 2:03:22  iter: 3499  total_loss: 8.751  loss_ce: 0  loss_mask: 0.2327  loss_dice: 0.6175  loss_seg: 0.3311  loss_ce_0: 0  loss_mask_0: 0.2281  loss_dice_0: 0.6332  loss_ce_1: 0  loss_mask_1: 0.2309  loss_dice_1: 0.6141  loss_ce_2: 0  loss_mask_2: 0.2299  loss_dice_2: 0.6123  loss_ce_3: 0  loss_mask_3: 0.2317  loss_dice_3: 0.6125  loss_ce_4: 0  loss_mask_4: 0.2311  loss_dice_4: 0.6128  loss_ce_5: 0  loss_mask_5: 0.2302  loss_dice_5: 0.613  loss_ce_6: 0  loss_mask_6: 0.2306  loss_dice_6: 0.6131  loss_ce_7: 0  loss_mask_7: 0.2302  loss_dice_7: 0.6133  loss_ce_8: 0  loss_mask_8: 0.2308  loss_dice_8: 0.6137  time: 1.6817  data_time: 0.0498  lr: 9.4736e-05  max_mem: 5916M
[02/24 14:05:49] d2.utils.events INFO:  eta: 1 day, 2:02:48  iter: 3519  total_loss: 8.791  loss_ce: 0  loss_mask: 0.2412  loss_dice: 0.6209  loss_seg: 0.3534  loss_ce_0: 0  loss_mask_0: 0.2369  loss_dice_0: 0.6389  loss_ce_1: 0  loss_mask_1: 0.2386  loss_dice_1: 0.619  loss_ce_2: 0  loss_mask_2: 0.239  loss_dice_2: 0.617  loss_ce_3: 0  loss_mask_3: 0.2385  loss_dice_3: 0.6165  loss_ce_4: 0  loss_mask_4: 0.2395  loss_dice_4: 0.6171  loss_ce_5: 0  loss_mask_5: 0.2397  loss_dice_5: 0.6169  loss_ce_6: 0  loss_mask_6: 0.2404  loss_dice_6: 0.6158  loss_ce_7: 0  loss_mask_7: 0.2409  loss_dice_7: 0.6164  loss_ce_8: 0  loss_mask_8: 0.2417  loss_dice_8: 0.6176  time: 1.6815  data_time: 0.0466  lr: 9.4706e-05  max_mem: 5916M
[02/24 14:06:23] d2.utils.events INFO:  eta: 1 day, 2:01:59  iter: 3539  total_loss: 8.744  loss_ce: 0  loss_mask: 0.2372  loss_dice: 0.6034  loss_seg: 0.3754  loss_ce_0: 0  loss_mask_0: 0.232  loss_dice_0: 0.6248  loss_ce_1: 0  loss_mask_1: 0.2367  loss_dice_1: 0.6025  loss_ce_2: 0  loss_mask_2: 0.2361  loss_dice_2: 0.6015  loss_ce_3: 0  loss_mask_3: 0.2363  loss_dice_3: 0.6005  loss_ce_4: 0  loss_mask_4: 0.2363  loss_dice_4: 0.6003  loss_ce_5: 0  loss_mask_5: 0.2368  loss_dice_5: 0.6015  loss_ce_6: 0  loss_mask_6: 0.2359  loss_dice_6: 0.6003  loss_ce_7: 0  loss_mask_7: 0.2354  loss_dice_7: 0.602  loss_ce_8: 0  loss_mask_8: 0.2357  loss_dice_8: 0.6016  time: 1.6816  data_time: 0.0519  lr: 9.4675e-05  max_mem: 5916M
[02/24 14:06:57] d2.utils.events INFO:  eta: 1 day, 2:00:12  iter: 3559  total_loss: 8.848  loss_ce: 0  loss_mask: 0.2215  loss_dice: 0.6146  loss_seg: 0.3484  loss_ce_0: 0  loss_mask_0: 0.2204  loss_dice_0: 0.6425  loss_ce_1: 0  loss_mask_1: 0.2194  loss_dice_1: 0.6149  loss_ce_2: 0  loss_mask_2: 0.2194  loss_dice_2: 0.6112  loss_ce_3: 0  loss_mask_3: 0.2199  loss_dice_3: 0.6114  loss_ce_4: 0  loss_mask_4: 0.2199  loss_dice_4: 0.6112  loss_ce_5: 0  loss_mask_5: 0.2188  loss_dice_5: 0.6125  loss_ce_6: 0  loss_mask_6: 0.2196  loss_dice_6: 0.612  loss_ce_7: 0  loss_mask_7: 0.2209  loss_dice_7: 0.6114  loss_ce_8: 0  loss_mask_8: 0.2211  loss_dice_8: 0.612  time: 1.6817  data_time: 0.0551  lr: 9.4645e-05  max_mem: 5916M
[02/24 14:07:31] d2.utils.events INFO:  eta: 1 day, 2:01:09  iter: 3579  total_loss: 8.855  loss_ce: 0  loss_mask: 0.2339  loss_dice: 0.6118  loss_seg: 0.3702  loss_ce_0: 0  loss_mask_0: 0.2316  loss_dice_0: 0.617  loss_ce_1: 0  loss_mask_1: 0.2315  loss_dice_1: 0.6038  loss_ce_2: 0  loss_mask_2: 0.2328  loss_dice_2: 0.6021  loss_ce_3: 0  loss_mask_3: 0.2314  loss_dice_3: 0.6016  loss_ce_4: 0  loss_mask_4: 0.2333  loss_dice_4: 0.6017  loss_ce_5: 0  loss_mask_5: 0.2325  loss_dice_5: 0.6017  loss_ce_6: 0  loss_mask_6: 0.2325  loss_dice_6: 0.6042  loss_ce_7: 0  loss_mask_7: 0.2338  loss_dice_7: 0.6034  loss_ce_8: 0  loss_mask_8: 0.2321  loss_dice_8: 0.606  time: 1.6818  data_time: 0.0453  lr: 9.4615e-05  max_mem: 5916M
[02/24 14:08:04] d2.utils.events INFO:  eta: 1 day, 2:00:36  iter: 3599  total_loss: 8.809  loss_ce: 0  loss_mask: 0.236  loss_dice: 0.6182  loss_seg: 0.3372  loss_ce_0: 0  loss_mask_0: 0.232  loss_dice_0: 0.6293  loss_ce_1: 0  loss_mask_1: 0.2347  loss_dice_1: 0.6177  loss_ce_2: 0  loss_mask_2: 0.234  loss_dice_2: 0.616  loss_ce_3: 0  loss_mask_3: 0.2355  loss_dice_3: 0.6153  loss_ce_4: 0  loss_mask_4: 0.2347  loss_dice_4: 0.6152  loss_ce_5: 0  loss_mask_5: 0.2354  loss_dice_5: 0.6151  loss_ce_6: 0  loss_mask_6: 0.2355  loss_dice_6: 0.615  loss_ce_7: 0  loss_mask_7: 0.2368  loss_dice_7: 0.6154  loss_ce_8: 0  loss_mask_8: 0.2356  loss_dice_8: 0.6152  time: 1.6816  data_time: 0.0607  lr: 9.4585e-05  max_mem: 5916M
[02/24 14:08:37] d2.utils.events INFO:  eta: 1 day, 1:58:31  iter: 3619  total_loss: 8.891  loss_ce: 0  loss_mask: 0.2373  loss_dice: 0.6233  loss_seg: 0.3476  loss_ce_0: 0  loss_mask_0: 0.2311  loss_dice_0: 0.6371  loss_ce_1: 0  loss_mask_1: 0.2339  loss_dice_1: 0.6212  loss_ce_2: 0  loss_mask_2: 0.2358  loss_dice_2: 0.6203  loss_ce_3: 0  loss_mask_3: 0.2377  loss_dice_3: 0.618  loss_ce_4: 0  loss_mask_4: 0.2365  loss_dice_4: 0.6192  loss_ce_5: 0  loss_mask_5: 0.2368  loss_dice_5: 0.6201  loss_ce_6: 0  loss_mask_6: 0.2367  loss_dice_6: 0.6206  loss_ce_7: 0  loss_mask_7: 0.2372  loss_dice_7: 0.6204  loss_ce_8: 0  loss_mask_8: 0.2354  loss_dice_8: 0.6198  time: 1.6814  data_time: 0.0534  lr: 9.4555e-05  max_mem: 5916M
[02/24 14:09:10] d2.utils.events INFO:  eta: 1 day, 1:58:00  iter: 3639  total_loss: 8.854  loss_ce: 0  loss_mask: 0.2493  loss_dice: 0.615  loss_seg: 0.353  loss_ce_0: 0  loss_mask_0: 0.245  loss_dice_0: 0.6293  loss_ce_1: 0  loss_mask_1: 0.2478  loss_dice_1: 0.6141  loss_ce_2: 0  loss_mask_2: 0.2484  loss_dice_2: 0.6108  loss_ce_3: 0  loss_mask_3: 0.2479  loss_dice_3: 0.6095  loss_ce_4: 0  loss_mask_4: 0.2473  loss_dice_4: 0.6087  loss_ce_5: 0  loss_mask_5: 0.2471  loss_dice_5: 0.6094  loss_ce_6: 0  loss_mask_6: 0.2481  loss_dice_6: 0.6089  loss_ce_7: 0  loss_mask_7: 0.2481  loss_dice_7: 0.6113  loss_ce_8: 0  loss_mask_8: 0.2475  loss_dice_8: 0.6132  time: 1.6812  data_time: 0.0580  lr: 9.4525e-05  max_mem: 5916M
[02/24 14:09:45] d2.utils.events INFO:  eta: 1 day, 1:57:41  iter: 3659  total_loss: 8.721  loss_ce: 0  loss_mask: 0.229  loss_dice: 0.6085  loss_seg: 0.3752  loss_ce_0: 0  loss_mask_0: 0.2292  loss_dice_0: 0.6247  loss_ce_1: 0  loss_mask_1: 0.2262  loss_dice_1: 0.6075  loss_ce_2: 0  loss_mask_2: 0.2269  loss_dice_2: 0.6045  loss_ce_3: 0  loss_mask_3: 0.2271  loss_dice_3: 0.6017  loss_ce_4: 0  loss_mask_4: 0.227  loss_dice_4: 0.6019  loss_ce_5: 0  loss_mask_5: 0.2275  loss_dice_5: 0.6023  loss_ce_6: 0  loss_mask_6: 0.2268  loss_dice_6: 0.603  loss_ce_7: 0  loss_mask_7: 0.2274  loss_dice_7: 0.6046  loss_ce_8: 0  loss_mask_8: 0.2269  loss_dice_8: 0.6041  time: 1.6814  data_time: 0.0646  lr: 9.4494e-05  max_mem: 5916M
[02/24 14:10:19] d2.utils.events INFO:  eta: 1 day, 1:57:07  iter: 3679  total_loss: 8.818  loss_ce: 0  loss_mask: 0.2303  loss_dice: 0.6054  loss_seg: 0.3272  loss_ce_0: 0  loss_mask_0: 0.2288  loss_dice_0: 0.6275  loss_ce_1: 0  loss_mask_1: 0.2276  loss_dice_1: 0.6072  loss_ce_2: 0  loss_mask_2: 0.2275  loss_dice_2: 0.6043  loss_ce_3: 0  loss_mask_3: 0.2285  loss_dice_3: 0.6024  loss_ce_4: 0  loss_mask_4: 0.2293  loss_dice_4: 0.6015  loss_ce_5: 0  loss_mask_5: 0.2285  loss_dice_5: 0.602  loss_ce_6: 0  loss_mask_6: 0.2281  loss_dice_6: 0.6028  loss_ce_7: 0  loss_mask_7: 0.228  loss_dice_7: 0.6032  loss_ce_8: 0  loss_mask_8: 0.2293  loss_dice_8: 0.6038  time: 1.6814  data_time: 0.0418  lr: 9.4464e-05  max_mem: 5916M
[02/24 14:10:52] d2.utils.events INFO:  eta: 1 day, 1:56:18  iter: 3699  total_loss: 8.86  loss_ce: 0  loss_mask: 0.2291  loss_dice: 0.6178  loss_seg: 0.3892  loss_ce_0: 0  loss_mask_0: 0.2269  loss_dice_0: 0.6361  loss_ce_1: 0  loss_mask_1: 0.2251  loss_dice_1: 0.6138  loss_ce_2: 0  loss_mask_2: 0.2237  loss_dice_2: 0.6124  loss_ce_3: 0  loss_mask_3: 0.2259  loss_dice_3: 0.6106  loss_ce_4: 0  loss_mask_4: 0.2261  loss_dice_4: 0.6108  loss_ce_5: 0  loss_mask_5: 0.2255  loss_dice_5: 0.6103  loss_ce_6: 0  loss_mask_6: 0.2266  loss_dice_6: 0.6112  loss_ce_7: 0  loss_mask_7: 0.2271  loss_dice_7: 0.6132  loss_ce_8: 0  loss_mask_8: 0.2273  loss_dice_8: 0.6123  time: 1.6814  data_time: 0.0605  lr: 9.4434e-05  max_mem: 5916M
[02/24 14:11:26] d2.utils.events INFO:  eta: 1 day, 1:57:00  iter: 3719  total_loss: 8.848  loss_ce: 0  loss_mask: 0.2305  loss_dice: 0.6144  loss_seg: 0.364  loss_ce_0: 0  loss_mask_0: 0.2262  loss_dice_0: 0.6319  loss_ce_1: 0  loss_mask_1: 0.2294  loss_dice_1: 0.6163  loss_ce_2: 0  loss_mask_2: 0.2279  loss_dice_2: 0.6132  loss_ce_3: 0  loss_mask_3: 0.2281  loss_dice_3: 0.6107  loss_ce_4: 0  loss_mask_4: 0.2287  loss_dice_4: 0.61  loss_ce_5: 0  loss_mask_5: 0.2285  loss_dice_5: 0.6118  loss_ce_6: 0  loss_mask_6: 0.2284  loss_dice_6: 0.6131  loss_ce_7: 0  loss_mask_7: 0.2289  loss_dice_7: 0.6134  loss_ce_8: 0  loss_mask_8: 0.2284  loss_dice_8: 0.6134  time: 1.6814  data_time: 0.0491  lr: 9.4404e-05  max_mem: 5916M
[02/24 14:11:59] d2.utils.events INFO:  eta: 1 day, 1:56:27  iter: 3739  total_loss: 8.967  loss_ce: 0  loss_mask: 0.2358  loss_dice: 0.6124  loss_seg: 0.3695  loss_ce_0: 0  loss_mask_0: 0.2349  loss_dice_0: 0.6215  loss_ce_1: 0  loss_mask_1: 0.2359  loss_dice_1: 0.6098  loss_ce_2: 0  loss_mask_2: 0.2342  loss_dice_2: 0.6081  loss_ce_3: 0  loss_mask_3: 0.2358  loss_dice_3: 0.608  loss_ce_4: 0  loss_mask_4: 0.2356  loss_dice_4: 0.6087  loss_ce_5: 0  loss_mask_5: 0.235  loss_dice_5: 0.6105  loss_ce_6: 0  loss_mask_6: 0.2362  loss_dice_6: 0.6083  loss_ce_7: 0  loss_mask_7: 0.2374  loss_dice_7: 0.6075  loss_ce_8: 0  loss_mask_8: 0.2366  loss_dice_8: 0.608  time: 1.6812  data_time: 0.0462  lr: 9.4374e-05  max_mem: 5916M
[02/24 14:12:33] d2.utils.events INFO:  eta: 1 day, 1:56:29  iter: 3759  total_loss: 8.783  loss_ce: 0  loss_mask: 0.2333  loss_dice: 0.6016  loss_seg: 0.3438  loss_ce_0: 0  loss_mask_0: 0.2326  loss_dice_0: 0.6146  loss_ce_1: 0  loss_mask_1: 0.2323  loss_dice_1: 0.6009  loss_ce_2: 0  loss_mask_2: 0.2316  loss_dice_2: 0.6003  loss_ce_3: 0  loss_mask_3: 0.2315  loss_dice_3: 0.599  loss_ce_4: 0  loss_mask_4: 0.2324  loss_dice_4: 0.5997  loss_ce_5: 0  loss_mask_5: 0.2322  loss_dice_5: 0.6  loss_ce_6: 0  loss_mask_6: 0.2321  loss_dice_6: 0.5996  loss_ce_7: 0  loss_mask_7: 0.2322  loss_dice_7: 0.6012  loss_ce_8: 0  loss_mask_8: 0.2328  loss_dice_8: 0.6009  time: 1.6810  data_time: 0.0486  lr: 9.4343e-05  max_mem: 5916M
[02/24 14:13:05] d2.utils.events INFO:  eta: 1 day, 1:55:56  iter: 3779  total_loss: 8.649  loss_ce: 0  loss_mask: 0.2429  loss_dice: 0.5965  loss_seg: 0.3758  loss_ce_0: 0  loss_mask_0: 0.2392  loss_dice_0: 0.6116  loss_ce_1: 0  loss_mask_1: 0.2417  loss_dice_1: 0.5911  loss_ce_2: 0  loss_mask_2: 0.2422  loss_dice_2: 0.5908  loss_ce_3: 0  loss_mask_3: 0.2416  loss_dice_3: 0.5905  loss_ce_4: 0  loss_mask_4: 0.2428  loss_dice_4: 0.5897  loss_ce_5: 0  loss_mask_5: 0.2417  loss_dice_5: 0.5907  loss_ce_6: 0  loss_mask_6: 0.2413  loss_dice_6: 0.5921  loss_ce_7: 0  loss_mask_7: 0.2413  loss_dice_7: 0.5912  loss_ce_8: 0  loss_mask_8: 0.243  loss_dice_8: 0.5919  time: 1.6807  data_time: 0.0563  lr: 9.4313e-05  max_mem: 5916M
[02/24 14:13:39] d2.utils.events INFO:  eta: 1 day, 1:55:33  iter: 3799  total_loss: 8.712  loss_ce: 0  loss_mask: 0.2353  loss_dice: 0.6077  loss_seg: 0.3192  loss_ce_0: 0  loss_mask_0: 0.2349  loss_dice_0: 0.6171  loss_ce_1: 0  loss_mask_1: 0.235  loss_dice_1: 0.6042  loss_ce_2: 0  loss_mask_2: 0.2349  loss_dice_2: 0.6024  loss_ce_3: 0  loss_mask_3: 0.235  loss_dice_3: 0.6006  loss_ce_4: 0  loss_mask_4: 0.2339  loss_dice_4: 0.6009  loss_ce_5: 0  loss_mask_5: 0.2331  loss_dice_5: 0.6017  loss_ce_6: 0  loss_mask_6: 0.2334  loss_dice_6: 0.6005  loss_ce_7: 0  loss_mask_7: 0.2345  loss_dice_7: 0.6004  loss_ce_8: 0  loss_mask_8: 0.2365  loss_dice_8: 0.601  time: 1.6806  data_time: 0.0501  lr: 9.4283e-05  max_mem: 5916M
[02/24 14:14:11] d2.utils.events INFO:  eta: 1 day, 1:53:01  iter: 3819  total_loss: 9.003  loss_ce: 0  loss_mask: 0.2381  loss_dice: 0.6255  loss_seg: 0.3524  loss_ce_0: 0  loss_mask_0: 0.2347  loss_dice_0: 0.635  loss_ce_1: 0  loss_mask_1: 0.2333  loss_dice_1: 0.6222  loss_ce_2: 0  loss_mask_2: 0.233  loss_dice_2: 0.6188  loss_ce_3: 0  loss_mask_3: 0.233  loss_dice_3: 0.6181  loss_ce_4: 0  loss_mask_4: 0.2351  loss_dice_4: 0.6211  loss_ce_5: 0  loss_mask_5: 0.2339  loss_dice_5: 0.6198  loss_ce_6: 0  loss_mask_6: 0.2345  loss_dice_6: 0.6195  loss_ce_7: 0  loss_mask_7: 0.2357  loss_dice_7: 0.6216  loss_ce_8: 0  loss_mask_8: 0.236  loss_dice_8: 0.6215  time: 1.6802  data_time: 0.0580  lr: 9.4253e-05  max_mem: 5916M
[02/24 14:14:44] d2.utils.events INFO:  eta: 1 day, 1:53:04  iter: 3839  total_loss: 9.294  loss_ce: 0  loss_mask: 0.2444  loss_dice: 0.6421  loss_seg: 0.3701  loss_ce_0: 0  loss_mask_0: 0.2426  loss_dice_0: 0.6406  loss_ce_1: 0  loss_mask_1: 0.2411  loss_dice_1: 0.6354  loss_ce_2: 0  loss_mask_2: 0.2436  loss_dice_2: 0.6354  loss_ce_3: 0  loss_mask_3: 0.2426  loss_dice_3: 0.6342  loss_ce_4: 0  loss_mask_4: 0.244  loss_dice_4: 0.6341  loss_ce_5: 0  loss_mask_5: 0.2433  loss_dice_5: 0.6359  loss_ce_6: 0  loss_mask_6: 0.2422  loss_dice_6: 0.6365  loss_ce_7: 0  loss_mask_7: 0.2422  loss_dice_7: 0.6369  loss_ce_8: 0  loss_mask_8: 0.244  loss_dice_8: 0.6373  time: 1.6801  data_time: 0.0619  lr: 9.4223e-05  max_mem: 5916M
[02/24 14:15:18] d2.utils.events INFO:  eta: 1 day, 1:53:28  iter: 3859  total_loss: 8.793  loss_ce: 0  loss_mask: 0.2427  loss_dice: 0.594  loss_seg: 0.324  loss_ce_0: 0  loss_mask_0: 0.2395  loss_dice_0: 0.6093  loss_ce_1: 0  loss_mask_1: 0.2417  loss_dice_1: 0.5898  loss_ce_2: 0  loss_mask_2: 0.2421  loss_dice_2: 0.5876  loss_ce_3: 0  loss_mask_3: 0.243  loss_dice_3: 0.5869  loss_ce_4: 0  loss_mask_4: 0.2436  loss_dice_4: 0.5851  loss_ce_5: 0  loss_mask_5: 0.2424  loss_dice_5: 0.5856  loss_ce_6: 0  loss_mask_6: 0.2437  loss_dice_6: 0.5875  loss_ce_7: 0  loss_mask_7: 0.2455  loss_dice_7: 0.588  loss_ce_8: 0  loss_mask_8: 0.2445  loss_dice_8: 0.588  time: 1.6801  data_time: 0.0520  lr: 9.4192e-05  max_mem: 5916M
[02/24 14:15:51] d2.utils.events INFO:  eta: 1 day, 1:53:20  iter: 3879  total_loss: 8.617  loss_ce: 0  loss_mask: 0.241  loss_dice: 0.5952  loss_seg: 0.308  loss_ce_0: 0  loss_mask_0: 0.2393  loss_dice_0: 0.6104  loss_ce_1: 0  loss_mask_1: 0.2418  loss_dice_1: 0.5931  loss_ce_2: 0  loss_mask_2: 0.2421  loss_dice_2: 0.5922  loss_ce_3: 0  loss_mask_3: 0.2438  loss_dice_3: 0.5893  loss_ce_4: 0  loss_mask_4: 0.2442  loss_dice_4: 0.5904  loss_ce_5: 0  loss_mask_5: 0.2439  loss_dice_5: 0.5904  loss_ce_6: 0  loss_mask_6: 0.2445  loss_dice_6: 0.5891  loss_ce_7: 0  loss_mask_7: 0.2421  loss_dice_7: 0.5907  loss_ce_8: 0  loss_mask_8: 0.2414  loss_dice_8: 0.5918  time: 1.6799  data_time: 0.0487  lr: 9.4162e-05  max_mem: 5916M
[02/24 14:16:23] d2.utils.events INFO:  eta: 1 day, 1:51:24  iter: 3899  total_loss: 8.662  loss_ce: 0  loss_mask: 0.229  loss_dice: 0.5934  loss_seg: 0.3515  loss_ce_0: 0  loss_mask_0: 0.2327  loss_dice_0: 0.6075  loss_ce_1: 0  loss_mask_1: 0.2301  loss_dice_1: 0.5915  loss_ce_2: 0  loss_mask_2: 0.2307  loss_dice_2: 0.587  loss_ce_3: 0  loss_mask_3: 0.2305  loss_dice_3: 0.5866  loss_ce_4: 0  loss_mask_4: 0.2296  loss_dice_4: 0.587  loss_ce_5: 0  loss_mask_5: 0.2305  loss_dice_5: 0.5866  loss_ce_6: 0  loss_mask_6: 0.2295  loss_dice_6: 0.5863  loss_ce_7: 0  loss_mask_7: 0.2296  loss_dice_7: 0.5894  loss_ce_8: 0  loss_mask_8: 0.2294  loss_dice_8: 0.5907  time: 1.6796  data_time: 0.0674  lr: 9.4132e-05  max_mem: 5916M
[02/24 14:16:56] d2.utils.events INFO:  eta: 1 day, 1:50:13  iter: 3919  total_loss: 8.563  loss_ce: 0  loss_mask: 0.2197  loss_dice: 0.5863  loss_seg: 0.3751  loss_ce_0: 0  loss_mask_0: 0.2196  loss_dice_0: 0.6106  loss_ce_1: 0  loss_mask_1: 0.2184  loss_dice_1: 0.5855  loss_ce_2: 0  loss_mask_2: 0.2185  loss_dice_2: 0.5823  loss_ce_3: 0  loss_mask_3: 0.2188  loss_dice_3: 0.581  loss_ce_4: 0  loss_mask_4: 0.2195  loss_dice_4: 0.5825  loss_ce_5: 0  loss_mask_5: 0.2199  loss_dice_5: 0.5836  loss_ce_6: 0  loss_mask_6: 0.2188  loss_dice_6: 0.5836  loss_ce_7: 0  loss_mask_7: 0.2203  loss_dice_7: 0.5834  loss_ce_8: 0  loss_mask_8: 0.2204  loss_dice_8: 0.5827  time: 1.6794  data_time: 0.0646  lr: 9.4102e-05  max_mem: 5916M
[02/24 14:17:30] d2.utils.events INFO:  eta: 1 day, 1:50:18  iter: 3939  total_loss: 8.817  loss_ce: 0  loss_mask: 0.2304  loss_dice: 0.6086  loss_seg: 0.3399  loss_ce_0: 0  loss_mask_0: 0.2246  loss_dice_0: 0.6196  loss_ce_1: 0  loss_mask_1: 0.2266  loss_dice_1: 0.6063  loss_ce_2: 0  loss_mask_2: 0.2266  loss_dice_2: 0.6065  loss_ce_3: 0  loss_mask_3: 0.2253  loss_dice_3: 0.6064  loss_ce_4: 0  loss_mask_4: 0.2274  loss_dice_4: 0.6069  loss_ce_5: 0  loss_mask_5: 0.2263  loss_dice_5: 0.608  loss_ce_6: 0  loss_mask_6: 0.2277  loss_dice_6: 0.6075  loss_ce_7: 0  loss_mask_7: 0.2275  loss_dice_7: 0.606  loss_ce_8: 0  loss_mask_8: 0.2275  loss_dice_8: 0.6076  time: 1.6794  data_time: 0.0579  lr: 9.4072e-05  max_mem: 5916M
[02/24 14:18:04] d2.utils.events INFO:  eta: 1 day, 1:51:04  iter: 3959  total_loss: 8.515  loss_ce: 0  loss_mask: 0.2297  loss_dice: 0.5901  loss_seg: 0.3228  loss_ce_0: 0  loss_mask_0: 0.2266  loss_dice_0: 0.6086  loss_ce_1: 0  loss_mask_1: 0.2275  loss_dice_1: 0.5893  loss_ce_2: 0  loss_mask_2: 0.226  loss_dice_2: 0.5877  loss_ce_3: 0  loss_mask_3: 0.2253  loss_dice_3: 0.5858  loss_ce_4: 0  loss_mask_4: 0.2267  loss_dice_4: 0.5864  loss_ce_5: 0  loss_mask_5: 0.2273  loss_dice_5: 0.5881  loss_ce_6: 0  loss_mask_6: 0.2281  loss_dice_6: 0.5865  loss_ce_7: 0  loss_mask_7: 0.2291  loss_dice_7: 0.586  loss_ce_8: 0  loss_mask_8: 0.2297  loss_dice_8: 0.5881  time: 1.6795  data_time: 0.0737  lr: 9.4041e-05  max_mem: 5916M
[02/24 14:18:37] d2.utils.events INFO:  eta: 1 day, 1:50:43  iter: 3979  total_loss: 8.976  loss_ce: 0  loss_mask: 0.2538  loss_dice: 0.6218  loss_seg: 0.3533  loss_ce_0: 0  loss_mask_0: 0.245  loss_dice_0: 0.6286  loss_ce_1: 0  loss_mask_1: 0.2504  loss_dice_1: 0.6175  loss_ce_2: 0  loss_mask_2: 0.2522  loss_dice_2: 0.6167  loss_ce_3: 0  loss_mask_3: 0.2531  loss_dice_3: 0.616  loss_ce_4: 0  loss_mask_4: 0.2541  loss_dice_4: 0.6148  loss_ce_5: 0  loss_mask_5: 0.2538  loss_dice_5: 0.6144  loss_ce_6: 0  loss_mask_6: 0.2534  loss_dice_6: 0.6165  loss_ce_7: 0  loss_mask_7: 0.2543  loss_dice_7: 0.6172  loss_ce_8: 0  loss_mask_8: 0.2552  loss_dice_8: 0.6172  time: 1.6792  data_time: 0.0714  lr: 9.4011e-05  max_mem: 5916M
[02/24 14:19:12] d2.utils.events INFO:  eta: 1 day, 1:51:20  iter: 3999  total_loss: 8.815  loss_ce: 0  loss_mask: 0.2283  loss_dice: 0.6177  loss_seg: 0.3295  loss_ce_0: 0  loss_mask_0: 0.2279  loss_dice_0: 0.6246  loss_ce_1: 0  loss_mask_1: 0.2277  loss_dice_1: 0.6151  loss_ce_2: 0  loss_mask_2: 0.2282  loss_dice_2: 0.6147  loss_ce_3: 0  loss_mask_3: 0.228  loss_dice_3: 0.6126  loss_ce_4: 0  loss_mask_4: 0.228  loss_dice_4: 0.6125  loss_ce_5: 0  loss_mask_5: 0.2301  loss_dice_5: 0.6129  loss_ce_6: 0  loss_mask_6: 0.2291  loss_dice_6: 0.6127  loss_ce_7: 0  loss_mask_7: 0.2293  loss_dice_7: 0.6131  loss_ce_8: 0  loss_mask_8: 0.2281  loss_dice_8: 0.6133  time: 1.6796  data_time: 0.0669  lr: 9.3981e-05  max_mem: 5916M
[02/24 14:19:46] d2.utils.events INFO:  eta: 1 day, 1:50:33  iter: 4019  total_loss: 8.556  loss_ce: 0  loss_mask: 0.2361  loss_dice: 0.5953  loss_seg: 0.3105  loss_ce_0: 0  loss_mask_0: 0.2336  loss_dice_0: 0.6027  loss_ce_1: 0  loss_mask_1: 0.2335  loss_dice_1: 0.5926  loss_ce_2: 0  loss_mask_2: 0.2352  loss_dice_2: 0.5911  loss_ce_3: 0  loss_mask_3: 0.2346  loss_dice_3: 0.5892  loss_ce_4: 0  loss_mask_4: 0.2352  loss_dice_4: 0.5917  loss_ce_5: 0  loss_mask_5: 0.2352  loss_dice_5: 0.5896  loss_ce_6: 0  loss_mask_6: 0.2343  loss_dice_6: 0.5907  loss_ce_7: 0  loss_mask_7: 0.2353  loss_dice_7: 0.5911  loss_ce_8: 0  loss_mask_8: 0.2351  loss_dice_8: 0.5918  time: 1.6797  data_time: 0.0638  lr: 9.3951e-05  max_mem: 5916M
[02/24 14:20:20] d2.utils.events INFO:  eta: 1 day, 1:48:54  iter: 4039  total_loss: 8.617  loss_ce: 0  loss_mask: 0.2297  loss_dice: 0.6037  loss_seg: 0.3664  loss_ce_0: 0  loss_mask_0: 0.2332  loss_dice_0: 0.6231  loss_ce_1: 0  loss_mask_1: 0.2301  loss_dice_1: 0.601  loss_ce_2: 0  loss_mask_2: 0.2295  loss_dice_2: 0.6003  loss_ce_3: 0  loss_mask_3: 0.2292  loss_dice_3: 0.5986  loss_ce_4: 0  loss_mask_4: 0.2288  loss_dice_4: 0.598  loss_ce_5: 0  loss_mask_5: 0.2297  loss_dice_5: 0.5985  loss_ce_6: 0  loss_mask_6: 0.2304  loss_dice_6: 0.5987  loss_ce_7: 0  loss_mask_7: 0.2294  loss_dice_7: 0.5986  loss_ce_8: 0  loss_mask_8: 0.2301  loss_dice_8: 0.5993  time: 1.6796  data_time: 0.0625  lr: 9.3921e-05  max_mem: 5916M
[02/24 14:20:54] d2.utils.events INFO:  eta: 1 day, 1:50:34  iter: 4059  total_loss: 8.905  loss_ce: 0  loss_mask: 0.232  loss_dice: 0.6206  loss_seg: 0.3921  loss_ce_0: 0  loss_mask_0: 0.2272  loss_dice_0: 0.628  loss_ce_1: 0  loss_mask_1: 0.2272  loss_dice_1: 0.6192  loss_ce_2: 0  loss_mask_2: 0.2282  loss_dice_2: 0.6168  loss_ce_3: 0  loss_mask_3: 0.2293  loss_dice_3: 0.6138  loss_ce_4: 0  loss_mask_4: 0.2299  loss_dice_4: 0.6149  loss_ce_5: 0  loss_mask_5: 0.23  loss_dice_5: 0.6148  loss_ce_6: 0  loss_mask_6: 0.2301  loss_dice_6: 0.615  loss_ce_7: 0  loss_mask_7: 0.2303  loss_dice_7: 0.6158  loss_ce_8: 0  loss_mask_8: 0.2311  loss_dice_8: 0.6162  time: 1.6797  data_time: 0.0781  lr: 9.389e-05  max_mem: 5916M
[02/24 14:21:28] d2.utils.events INFO:  eta: 1 day, 1:48:16  iter: 4079  total_loss: 8.702  loss_ce: 0  loss_mask: 0.2376  loss_dice: 0.6041  loss_seg: 0.3556  loss_ce_0: 0  loss_mask_0: 0.2344  loss_dice_0: 0.6142  loss_ce_1: 0  loss_mask_1: 0.236  loss_dice_1: 0.6013  loss_ce_2: 0  loss_mask_2: 0.2378  loss_dice_2: 0.5982  loss_ce_3: 0  loss_mask_3: 0.2367  loss_dice_3: 0.5975  loss_ce_4: 0  loss_mask_4: 0.2374  loss_dice_4: 0.5985  loss_ce_5: 0  loss_mask_5: 0.2382  loss_dice_5: 0.5982  loss_ce_6: 0  loss_mask_6: 0.2399  loss_dice_6: 0.5971  loss_ce_7: 0  loss_mask_7: 0.2378  loss_dice_7: 0.5988  loss_ce_8: 0  loss_mask_8: 0.2372  loss_dice_8: 0.5985  time: 1.6798  data_time: 0.0655  lr: 9.386e-05  max_mem: 5916M
[02/24 14:22:01] d2.utils.events INFO:  eta: 1 day, 1:47:24  iter: 4099  total_loss: 8.762  loss_ce: 0  loss_mask: 0.2343  loss_dice: 0.5965  loss_seg: 0.3562  loss_ce_0: 0  loss_mask_0: 0.2258  loss_dice_0: 0.6099  loss_ce_1: 0  loss_mask_1: 0.2296  loss_dice_1: 0.5944  loss_ce_2: 0  loss_mask_2: 0.2314  loss_dice_2: 0.5936  loss_ce_3: 0  loss_mask_3: 0.2332  loss_dice_3: 0.5936  loss_ce_4: 0  loss_mask_4: 0.2331  loss_dice_4: 0.5945  loss_ce_5: 0  loss_mask_5: 0.2339  loss_dice_5: 0.5946  loss_ce_6: 0  loss_mask_6: 0.2335  loss_dice_6: 0.5959  loss_ce_7: 0  loss_mask_7: 0.2337  loss_dice_7: 0.5944  loss_ce_8: 0  loss_mask_8: 0.2351  loss_dice_8: 0.5943  time: 1.6796  data_time: 0.0701  lr: 9.383e-05  max_mem: 5916M
[02/24 14:22:34] d2.utils.events INFO:  eta: 1 day, 1:44:37  iter: 4119  total_loss: 8.603  loss_ce: 0  loss_mask: 0.231  loss_dice: 0.6  loss_seg: 0.3398  loss_ce_0: 0  loss_mask_0: 0.2299  loss_dice_0: 0.6129  loss_ce_1: 0  loss_mask_1: 0.2331  loss_dice_1: 0.5985  loss_ce_2: 0  loss_mask_2: 0.2323  loss_dice_2: 0.5959  loss_ce_3: 0  loss_mask_3: 0.2333  loss_dice_3: 0.5943  loss_ce_4: 0  loss_mask_4: 0.2319  loss_dice_4: 0.5945  loss_ce_5: 0  loss_mask_5: 0.2318  loss_dice_5: 0.5952  loss_ce_6: 0  loss_mask_6: 0.2329  loss_dice_6: 0.5961  loss_ce_7: 0  loss_mask_7: 0.235  loss_dice_7: 0.5966  loss_ce_8: 0  loss_mask_8: 0.2335  loss_dice_8: 0.5968  time: 1.6795  data_time: 0.0538  lr: 9.38e-05  max_mem: 5916M
[02/24 14:23:08] d2.utils.events INFO:  eta: 1 day, 1:47:14  iter: 4139  total_loss: 8.596  loss_ce: 0  loss_mask: 0.2312  loss_dice: 0.5911  loss_seg: 0.3336  loss_ce_0: 0  loss_mask_0: 0.223  loss_dice_0: 0.6088  loss_ce_1: 0  loss_mask_1: 0.2272  loss_dice_1: 0.5896  loss_ce_2: 0  loss_mask_2: 0.2291  loss_dice_2: 0.5853  loss_ce_3: 0  loss_mask_3: 0.229  loss_dice_3: 0.5853  loss_ce_4: 0  loss_mask_4: 0.2302  loss_dice_4: 0.5867  loss_ce_5: 0  loss_mask_5: 0.2277  loss_dice_5: 0.5866  loss_ce_6: 0  loss_mask_6: 0.227  loss_dice_6: 0.589  loss_ce_7: 0  loss_mask_7: 0.2285  loss_dice_7: 0.5888  loss_ce_8: 0  loss_mask_8: 0.2284  loss_dice_8: 0.588  time: 1.6796  data_time: 0.0757  lr: 9.377e-05  max_mem: 5916M
[02/24 14:23:43] d2.utils.events INFO:  eta: 1 day, 1:47:48  iter: 4159  total_loss: 8.886  loss_ce: 0  loss_mask: 0.2279  loss_dice: 0.618  loss_seg: 0.3349  loss_ce_0: 0  loss_mask_0: 0.2267  loss_dice_0: 0.6305  loss_ce_1: 0  loss_mask_1: 0.2283  loss_dice_1: 0.6166  loss_ce_2: 0  loss_mask_2: 0.2286  loss_dice_2: 0.6147  loss_ce_3: 0  loss_mask_3: 0.228  loss_dice_3: 0.6126  loss_ce_4: 0  loss_mask_4: 0.2277  loss_dice_4: 0.6131  loss_ce_5: 0  loss_mask_5: 0.2278  loss_dice_5: 0.6133  loss_ce_6: 0  loss_mask_6: 0.2281  loss_dice_6: 0.6111  loss_ce_7: 0  loss_mask_7: 0.2263  loss_dice_7: 0.6117  loss_ce_8: 0  loss_mask_8: 0.2268  loss_dice_8: 0.6142  time: 1.6798  data_time: 0.0675  lr: 9.3739e-05  max_mem: 5916M
[02/24 14:24:17] d2.utils.events INFO:  eta: 1 day, 1:47:21  iter: 4179  total_loss: 8.742  loss_ce: 0  loss_mask: 0.2337  loss_dice: 0.602  loss_seg: 0.3381  loss_ce_0: 0  loss_mask_0: 0.235  loss_dice_0: 0.6128  loss_ce_1: 0  loss_mask_1: 0.2317  loss_dice_1: 0.6008  loss_ce_2: 0  loss_mask_2: 0.2311  loss_dice_2: 0.5978  loss_ce_3: 0  loss_mask_3: 0.2314  loss_dice_3: 0.5992  loss_ce_4: 0  loss_mask_4: 0.2318  loss_dice_4: 0.5974  loss_ce_5: 0  loss_mask_5: 0.2318  loss_dice_5: 0.5973  loss_ce_6: 0  loss_mask_6: 0.2319  loss_dice_6: 0.5975  loss_ce_7: 0  loss_mask_7: 0.2336  loss_dice_7: 0.5986  loss_ce_8: 0  loss_mask_8: 0.2325  loss_dice_8: 0.5984  time: 1.6798  data_time: 0.0659  lr: 9.3709e-05  max_mem: 5916M
[02/24 14:24:52] d2.utils.events INFO:  eta: 1 day, 1:50:18  iter: 4199  total_loss: 8.472  loss_ce: 0  loss_mask: 0.23  loss_dice: 0.5931  loss_seg: 0.3198  loss_ce_0: 0  loss_mask_0: 0.2304  loss_dice_0: 0.5992  loss_ce_1: 0  loss_mask_1: 0.2301  loss_dice_1: 0.5861  loss_ce_2: 0  loss_mask_2: 0.2304  loss_dice_2: 0.5844  loss_ce_3: 0  loss_mask_3: 0.2309  loss_dice_3: 0.5834  loss_ce_4: 0  loss_mask_4: 0.2317  loss_dice_4: 0.585  loss_ce_5: 0  loss_mask_5: 0.2319  loss_dice_5: 0.5848  loss_ce_6: 0  loss_mask_6: 0.2309  loss_dice_6: 0.5846  loss_ce_7: 0  loss_mask_7: 0.2304  loss_dice_7: 0.5864  loss_ce_8: 0  loss_mask_8: 0.2321  loss_dice_8: 0.5868  time: 1.6802  data_time: 0.0761  lr: 9.3679e-05  max_mem: 5916M
[02/24 14:25:29] d2.utils.events INFO:  eta: 1 day, 1:53:08  iter: 4219  total_loss: 8.581  loss_ce: 0  loss_mask: 0.2324  loss_dice: 0.5966  loss_seg: 0.3769  loss_ce_0: 0  loss_mask_0: 0.2252  loss_dice_0: 0.6117  loss_ce_1: 0  loss_mask_1: 0.2286  loss_dice_1: 0.5949  loss_ce_2: 0  loss_mask_2: 0.2296  loss_dice_2: 0.5917  loss_ce_3: 0  loss_mask_3: 0.2297  loss_dice_3: 0.5912  loss_ce_4: 0  loss_mask_4: 0.23  loss_dice_4: 0.5923  loss_ce_5: 0  loss_mask_5: 0.23  loss_dice_5: 0.5932  loss_ce_6: 0  loss_mask_6: 0.2311  loss_dice_6: 0.5913  loss_ce_7: 0  loss_mask_7: 0.2307  loss_dice_7: 0.593  loss_ce_8: 0  loss_mask_8: 0.2307  loss_dice_8: 0.594  time: 1.6810  data_time: 0.0635  lr: 9.3649e-05  max_mem: 5916M
[02/24 14:26:03] d2.utils.events INFO:  eta: 1 day, 1:52:43  iter: 4239  total_loss: 8.468  loss_ce: 0  loss_mask: 0.2194  loss_dice: 0.5836  loss_seg: 0.3644  loss_ce_0: 0  loss_mask_0: 0.2172  loss_dice_0: 0.6088  loss_ce_1: 0  loss_mask_1: 0.2157  loss_dice_1: 0.5836  loss_ce_2: 0  loss_mask_2: 0.2179  loss_dice_2: 0.5816  loss_ce_3: 0  loss_mask_3: 0.2176  loss_dice_3: 0.5789  loss_ce_4: 0  loss_mask_4: 0.2184  loss_dice_4: 0.5779  loss_ce_5: 0  loss_mask_5: 0.219  loss_dice_5: 0.5793  loss_ce_6: 0  loss_mask_6: 0.2171  loss_dice_6: 0.5805  loss_ce_7: 0  loss_mask_7: 0.2178  loss_dice_7: 0.5803  loss_ce_8: 0  loss_mask_8: 0.2186  loss_dice_8: 0.5804  time: 1.6810  data_time: 0.0705  lr: 9.3618e-05  max_mem: 5916M
[02/24 14:26:37] d2.utils.events INFO:  eta: 1 day, 1:54:31  iter: 4259  total_loss: 8.624  loss_ce: 0  loss_mask: 0.2192  loss_dice: 0.6023  loss_seg: 0.3161  loss_ce_0: 0  loss_mask_0: 0.2165  loss_dice_0: 0.6294  loss_ce_1: 0  loss_mask_1: 0.2184  loss_dice_1: 0.6034  loss_ce_2: 0  loss_mask_2: 0.2194  loss_dice_2: 0.5997  loss_ce_3: 0  loss_mask_3: 0.2201  loss_dice_3: 0.599  loss_ce_4: 0  loss_mask_4: 0.2208  loss_dice_4: 0.5972  loss_ce_5: 0  loss_mask_5: 0.2198  loss_dice_5: 0.597  loss_ce_6: 0  loss_mask_6: 0.2205  loss_dice_6: 0.5982  loss_ce_7: 0  loss_mask_7: 0.2212  loss_dice_7: 0.5981  loss_ce_8: 0  loss_mask_8: 0.2201  loss_dice_8: 0.5998  time: 1.6811  data_time: 0.0670  lr: 9.3588e-05  max_mem: 5916M
[02/24 14:27:10] d2.utils.events INFO:  eta: 1 day, 1:53:07  iter: 4279  total_loss: 8.462  loss_ce: 0  loss_mask: 0.2286  loss_dice: 0.5759  loss_seg: 0.3123  loss_ce_0: 0  loss_mask_0: 0.2265  loss_dice_0: 0.5931  loss_ce_1: 0  loss_mask_1: 0.2273  loss_dice_1: 0.5774  loss_ce_2: 0  loss_mask_2: 0.2274  loss_dice_2: 0.5737  loss_ce_3: 0  loss_mask_3: 0.2295  loss_dice_3: 0.5713  loss_ce_4: 0  loss_mask_4: 0.2286  loss_dice_4: 0.5699  loss_ce_5: 0  loss_mask_5: 0.2279  loss_dice_5: 0.5712  loss_ce_6: 0  loss_mask_6: 0.2283  loss_dice_6: 0.5706  loss_ce_7: 0  loss_mask_7: 0.2296  loss_dice_7: 0.5721  loss_ce_8: 0  loss_mask_8: 0.2287  loss_dice_8: 0.5738  time: 1.6809  data_time: 0.0620  lr: 9.3558e-05  max_mem: 5916M
[02/24 14:27:44] d2.utils.events INFO:  eta: 1 day, 1:51:29  iter: 4299  total_loss: 8.494  loss_ce: 0  loss_mask: 0.2295  loss_dice: 0.5911  loss_seg: 0.3049  loss_ce_0: 0  loss_mask_0: 0.2257  loss_dice_0: 0.6  loss_ce_1: 0  loss_mask_1: 0.2257  loss_dice_1: 0.5893  loss_ce_2: 0  loss_mask_2: 0.2262  loss_dice_2: 0.5865  loss_ce_3: 0  loss_mask_3: 0.2278  loss_dice_3: 0.5869  loss_ce_4: 0  loss_mask_4: 0.2279  loss_dice_4: 0.5876  loss_ce_5: 0  loss_mask_5: 0.2281  loss_dice_5: 0.5864  loss_ce_6: 0  loss_mask_6: 0.2274  loss_dice_6: 0.5862  loss_ce_7: 0  loss_mask_7: 0.2292  loss_dice_7: 0.588  loss_ce_8: 0  loss_mask_8: 0.2299  loss_dice_8: 0.5873  time: 1.6810  data_time: 0.0621  lr: 9.3528e-05  max_mem: 5916M
[02/24 14:28:18] d2.utils.events INFO:  eta: 1 day, 1:50:55  iter: 4319  total_loss: 8.393  loss_ce: 0  loss_mask: 0.222  loss_dice: 0.592  loss_seg: 0.3194  loss_ce_0: 0  loss_mask_0: 0.2183  loss_dice_0: 0.6035  loss_ce_1: 0  loss_mask_1: 0.2217  loss_dice_1: 0.59  loss_ce_2: 0  loss_mask_2: 0.2223  loss_dice_2: 0.5865  loss_ce_3: 0  loss_mask_3: 0.2219  loss_dice_3: 0.5853  loss_ce_4: 0  loss_mask_4: 0.2209  loss_dice_4: 0.5868  loss_ce_5: 0  loss_mask_5: 0.2219  loss_dice_5: 0.5857  loss_ce_6: 0  loss_mask_6: 0.2206  loss_dice_6: 0.5867  loss_ce_7: 0  loss_mask_7: 0.2221  loss_dice_7: 0.5869  loss_ce_8: 0  loss_mask_8: 0.2219  loss_dice_8: 0.5882  time: 1.6809  data_time: 0.0676  lr: 9.3498e-05  max_mem: 5916M
[02/24 14:28:51] d2.utils.events INFO:  eta: 1 day, 1:49:56  iter: 4339  total_loss: 8.446  loss_ce: 0  loss_mask: 0.2266  loss_dice: 0.5801  loss_seg: 0.312  loss_ce_0: 0  loss_mask_0: 0.2243  loss_dice_0: 0.5971  loss_ce_1: 0  loss_mask_1: 0.2233  loss_dice_1: 0.5788  loss_ce_2: 0  loss_mask_2: 0.2242  loss_dice_2: 0.5787  loss_ce_3: 0  loss_mask_3: 0.2265  loss_dice_3: 0.5777  loss_ce_4: 0  loss_mask_4: 0.2259  loss_dice_4: 0.5767  loss_ce_5: 0  loss_mask_5: 0.2262  loss_dice_5: 0.5788  loss_ce_6: 0  loss_mask_6: 0.2257  loss_dice_6: 0.5792  loss_ce_7: 0  loss_mask_7: 0.2249  loss_dice_7: 0.5805  loss_ce_8: 0  loss_mask_8: 0.2257  loss_dice_8: 0.5798  time: 1.6807  data_time: 0.0685  lr: 9.3467e-05  max_mem: 5916M
[02/24 14:29:23] d2.utils.events INFO:  eta: 1 day, 1:49:06  iter: 4359  total_loss: 8.262  loss_ce: 0  loss_mask: 0.221  loss_dice: 0.5642  loss_seg: 0.2853  loss_ce_0: 0  loss_mask_0: 0.2203  loss_dice_0: 0.5895  loss_ce_1: 0  loss_mask_1: 0.2206  loss_dice_1: 0.5652  loss_ce_2: 0  loss_mask_2: 0.2213  loss_dice_2: 0.5602  loss_ce_3: 0  loss_mask_3: 0.2217  loss_dice_3: 0.557  loss_ce_4: 0  loss_mask_4: 0.2206  loss_dice_4: 0.5588  loss_ce_5: 0  loss_mask_5: 0.2214  loss_dice_5: 0.5577  loss_ce_6: 0  loss_mask_6: 0.2223  loss_dice_6: 0.5571  loss_ce_7: 0  loss_mask_7: 0.2219  loss_dice_7: 0.5609  loss_ce_8: 0  loss_mask_8: 0.2216  loss_dice_8: 0.561  time: 1.6803  data_time: 0.0624  lr: 9.3437e-05  max_mem: 5916M
[02/24 14:29:56] d2.utils.events INFO:  eta: 1 day, 1:49:28  iter: 4379  total_loss: 8.648  loss_ce: 0  loss_mask: 0.2266  loss_dice: 0.5938  loss_seg: 0.3343  loss_ce_0: 0  loss_mask_0: 0.2255  loss_dice_0: 0.603  loss_ce_1: 0  loss_mask_1: 0.2249  loss_dice_1: 0.5928  loss_ce_2: 0  loss_mask_2: 0.225  loss_dice_2: 0.5933  loss_ce_3: 0  loss_mask_3: 0.2244  loss_dice_3: 0.5912  loss_ce_4: 0  loss_mask_4: 0.2247  loss_dice_4: 0.5916  loss_ce_5: 0  loss_mask_5: 0.2251  loss_dice_5: 0.5925  loss_ce_6: 0  loss_mask_6: 0.2253  loss_dice_6: 0.5918  loss_ce_7: 0  loss_mask_7: 0.2255  loss_dice_7: 0.5921  loss_ce_8: 0  loss_mask_8: 0.2254  loss_dice_8: 0.593  time: 1.6803  data_time: 0.0576  lr: 9.3407e-05  max_mem: 5916M
[02/24 14:30:30] d2.utils.events INFO:  eta: 1 day, 1:49:39  iter: 4399  total_loss: 8.72  loss_ce: 0  loss_mask: 0.2316  loss_dice: 0.6044  loss_seg: 0.3736  loss_ce_0: 0  loss_mask_0: 0.23  loss_dice_0: 0.6178  loss_ce_1: 0  loss_mask_1: 0.2302  loss_dice_1: 0.6012  loss_ce_2: 0  loss_mask_2: 0.2307  loss_dice_2: 0.5986  loss_ce_3: 0  loss_mask_3: 0.2313  loss_dice_3: 0.5987  loss_ce_4: 0  loss_mask_4: 0.2314  loss_dice_4: 0.601  loss_ce_5: 0  loss_mask_5: 0.2313  loss_dice_5: 0.6005  loss_ce_6: 0  loss_mask_6: 0.2312  loss_dice_6: 0.6008  loss_ce_7: 0  loss_mask_7: 0.2319  loss_dice_7: 0.6013  loss_ce_8: 0  loss_mask_8: 0.2316  loss_dice_8: 0.6016  time: 1.6802  data_time: 0.0649  lr: 9.3377e-05  max_mem: 5916M
[02/24 14:31:02] d2.utils.events INFO:  eta: 1 day, 1:47:57  iter: 4419  total_loss: 8.544  loss_ce: 0  loss_mask: 0.2303  loss_dice: 0.5929  loss_seg: 0.3382  loss_ce_0: 0  loss_mask_0: 0.2299  loss_dice_0: 0.6053  loss_ce_1: 0  loss_mask_1: 0.2317  loss_dice_1: 0.5945  loss_ce_2: 0  loss_mask_2: 0.232  loss_dice_2: 0.5921  loss_ce_3: 0  loss_mask_3: 0.2315  loss_dice_3: 0.5897  loss_ce_4: 0  loss_mask_4: 0.2318  loss_dice_4: 0.5899  loss_ce_5: 0  loss_mask_5: 0.2321  loss_dice_5: 0.5908  loss_ce_6: 0  loss_mask_6: 0.2316  loss_dice_6: 0.5911  loss_ce_7: 0  loss_mask_7: 0.233  loss_dice_7: 0.5895  loss_ce_8: 0  loss_mask_8: 0.2335  loss_dice_8: 0.5896  time: 1.6798  data_time: 0.0527  lr: 9.3346e-05  max_mem: 5916M
[02/24 14:31:35] d2.utils.events INFO:  eta: 1 day, 1:49:25  iter: 4439  total_loss: 8.453  loss_ce: 0  loss_mask: 0.2333  loss_dice: 0.5797  loss_seg: 0.3153  loss_ce_0: 0  loss_mask_0: 0.2277  loss_dice_0: 0.5943  loss_ce_1: 0  loss_mask_1: 0.2285  loss_dice_1: 0.5796  loss_ce_2: 0  loss_mask_2: 0.2304  loss_dice_2: 0.5779  loss_ce_3: 0  loss_mask_3: 0.2327  loss_dice_3: 0.5757  loss_ce_4: 0  loss_mask_4: 0.2317  loss_dice_4: 0.5764  loss_ce_5: 0  loss_mask_5: 0.2322  loss_dice_5: 0.5771  loss_ce_6: 0  loss_mask_6: 0.2318  loss_dice_6: 0.577  loss_ce_7: 0  loss_mask_7: 0.2319  loss_dice_7: 0.5771  loss_ce_8: 0  loss_mask_8: 0.2316  loss_dice_8: 0.5784  time: 1.6798  data_time: 0.0562  lr: 9.3316e-05  max_mem: 5916M
[02/24 14:32:09] d2.utils.events INFO:  eta: 1 day, 1:48:43  iter: 4459  total_loss: 8.085  loss_ce: 0  loss_mask: 0.2108  loss_dice: 0.553  loss_seg: 0.3417  loss_ce_0: 0  loss_mask_0: 0.2151  loss_dice_0: 0.5757  loss_ce_1: 0  loss_mask_1: 0.21  loss_dice_1: 0.5514  loss_ce_2: 0  loss_mask_2: 0.2097  loss_dice_2: 0.5496  loss_ce_3: 0  loss_mask_3: 0.2103  loss_dice_3: 0.5486  loss_ce_4: 0  loss_mask_4: 0.2097  loss_dice_4: 0.5502  loss_ce_5: 0  loss_mask_5: 0.2094  loss_dice_5: 0.5503  loss_ce_6: 0  loss_mask_6: 0.2106  loss_dice_6: 0.5503  loss_ce_7: 0  loss_mask_7: 0.2099  loss_dice_7: 0.5496  loss_ce_8: 0  loss_mask_8: 0.2101  loss_dice_8: 0.5508  time: 1.6797  data_time: 0.0556  lr: 9.3286e-05  max_mem: 5916M
[02/24 14:32:42] d2.utils.events INFO:  eta: 1 day, 1:47:00  iter: 4479  total_loss: 8.421  loss_ce: 0  loss_mask: 0.2235  loss_dice: 0.5996  loss_seg: 0.3896  loss_ce_0: 0  loss_mask_0: 0.2236  loss_dice_0: 0.6188  loss_ce_1: 0  loss_mask_1: 0.2246  loss_dice_1: 0.5982  loss_ce_2: 0  loss_mask_2: 0.2242  loss_dice_2: 0.5957  loss_ce_3: 0  loss_mask_3: 0.2242  loss_dice_3: 0.594  loss_ce_4: 0  loss_mask_4: 0.2236  loss_dice_4: 0.595  loss_ce_5: 0  loss_mask_5: 0.2238  loss_dice_5: 0.5954  loss_ce_6: 0  loss_mask_6: 0.2243  loss_dice_6: 0.5936  loss_ce_7: 0  loss_mask_7: 0.2252  loss_dice_7: 0.5948  loss_ce_8: 0  loss_mask_8: 0.2242  loss_dice_8: 0.595  time: 1.6796  data_time: 0.0504  lr: 9.3256e-05  max_mem: 5916M
[02/24 14:33:15] d2.utils.events INFO:  eta: 1 day, 1:45:30  iter: 4499  total_loss: 8.238  loss_ce: 0  loss_mask: 0.2164  loss_dice: 0.5811  loss_seg: 0.3192  loss_ce_0: 0  loss_mask_0: 0.2135  loss_dice_0: 0.5966  loss_ce_1: 0  loss_mask_1: 0.2126  loss_dice_1: 0.58  loss_ce_2: 0  loss_mask_2: 0.2133  loss_dice_2: 0.5767  loss_ce_3: 0  loss_mask_3: 0.2131  loss_dice_3: 0.5749  loss_ce_4: 0  loss_mask_4: 0.2131  loss_dice_4: 0.576  loss_ce_5: 0  loss_mask_5: 0.2133  loss_dice_5: 0.5769  loss_ce_6: 0  loss_mask_6: 0.214  loss_dice_6: 0.5766  loss_ce_7: 0  loss_mask_7: 0.2141  loss_dice_7: 0.5765  loss_ce_8: 0  loss_mask_8: 0.2152  loss_dice_8: 0.5767  time: 1.6794  data_time: 0.0488  lr: 9.3225e-05  max_mem: 5916M
[02/24 14:33:49] d2.utils.events INFO:  eta: 1 day, 1:45:53  iter: 4519  total_loss: 8.387  loss_ce: 0  loss_mask: 0.2216  loss_dice: 0.5847  loss_seg: 0.3288  loss_ce_0: 0  loss_mask_0: 0.219  loss_dice_0: 0.6  loss_ce_1: 0  loss_mask_1: 0.2209  loss_dice_1: 0.5839  loss_ce_2: 0  loss_mask_2: 0.2226  loss_dice_2: 0.5821  loss_ce_3: 0  loss_mask_3: 0.2239  loss_dice_3: 0.5804  loss_ce_4: 0  loss_mask_4: 0.2234  loss_dice_4: 0.581  loss_ce_5: 0  loss_mask_5: 0.2239  loss_dice_5: 0.5799  loss_ce_6: 0  loss_mask_6: 0.2221  loss_dice_6: 0.5797  loss_ce_7: 0  loss_mask_7: 0.2218  loss_dice_7: 0.5814  loss_ce_8: 0  loss_mask_8: 0.2218  loss_dice_8: 0.5823  time: 1.6795  data_time: 0.0552  lr: 9.3195e-05  max_mem: 5916M
[02/24 14:34:22] d2.utils.events INFO:  eta: 1 day, 1:44:23  iter: 4539  total_loss: 8.559  loss_ce: 0  loss_mask: 0.2389  loss_dice: 0.6006  loss_seg: 0.3293  loss_ce_0: 0  loss_mask_0: 0.2339  loss_dice_0: 0.6079  loss_ce_1: 0  loss_mask_1: 0.2367  loss_dice_1: 0.6023  loss_ce_2: 0  loss_mask_2: 0.2372  loss_dice_2: 0.5994  loss_ce_3: 0  loss_mask_3: 0.2377  loss_dice_3: 0.5982  loss_ce_4: 0  loss_mask_4: 0.2384  loss_dice_4: 0.5975  loss_ce_5: 0  loss_mask_5: 0.2379  loss_dice_5: 0.5979  loss_ce_6: 0  loss_mask_6: 0.2386  loss_dice_6: 0.5968  loss_ce_7: 0  loss_mask_7: 0.2397  loss_dice_7: 0.5976  loss_ce_8: 0  loss_mask_8: 0.2392  loss_dice_8: 0.6001  time: 1.6793  data_time: 0.0517  lr: 9.3165e-05  max_mem: 5916M
[02/24 14:34:57] d2.utils.events INFO:  eta: 1 day, 1:45:55  iter: 4559  total_loss: 8.562  loss_ce: 0  loss_mask: 0.2323  loss_dice: 0.5959  loss_seg: 0.3408  loss_ce_0: 0  loss_mask_0: 0.2306  loss_dice_0: 0.6049  loss_ce_1: 0  loss_mask_1: 0.2304  loss_dice_1: 0.5941  loss_ce_2: 0  loss_mask_2: 0.2302  loss_dice_2: 0.5913  loss_ce_3: 0  loss_mask_3: 0.2296  loss_dice_3: 0.5899  loss_ce_4: 0  loss_mask_4: 0.23  loss_dice_4: 0.5902  loss_ce_5: 0  loss_mask_5: 0.2311  loss_dice_5: 0.5906  loss_ce_6: 0  loss_mask_6: 0.2309  loss_dice_6: 0.5893  loss_ce_7: 0  loss_mask_7: 0.2304  loss_dice_7: 0.5896  loss_ce_8: 0  loss_mask_8: 0.23  loss_dice_8: 0.5927  time: 1.6796  data_time: 0.0559  lr: 9.3135e-05  max_mem: 5916M
[02/24 14:35:30] d2.utils.events INFO:  eta: 1 day, 1:44:49  iter: 4579  total_loss: 8.324  loss_ce: 0  loss_mask: 0.2167  loss_dice: 0.5828  loss_seg: 0.3238  loss_ce_0: 0  loss_mask_0: 0.2135  loss_dice_0: 0.6045  loss_ce_1: 0  loss_mask_1: 0.2141  loss_dice_1: 0.5821  loss_ce_2: 0  loss_mask_2: 0.2139  loss_dice_2: 0.5778  loss_ce_3: 0  loss_mask_3: 0.2153  loss_dice_3: 0.5774  loss_ce_4: 0  loss_mask_4: 0.2156  loss_dice_4: 0.5766  loss_ce_5: 0  loss_mask_5: 0.216  loss_dice_5: 0.5769  loss_ce_6: 0  loss_mask_6: 0.2164  loss_dice_6: 0.5774  loss_ce_7: 0  loss_mask_7: 0.2159  loss_dice_7: 0.5778  loss_ce_8: 0  loss_mask_8: 0.2153  loss_dice_8: 0.5782  time: 1.6795  data_time: 0.0551  lr: 9.3105e-05  max_mem: 5916M
[02/24 14:36:01] d2.utils.events INFO:  eta: 1 day, 1:43:10  iter: 4599  total_loss: 8.527  loss_ce: 0  loss_mask: 0.222  loss_dice: 0.5888  loss_seg: 0.3394  loss_ce_0: 0  loss_mask_0: 0.221  loss_dice_0: 0.6004  loss_ce_1: 0  loss_mask_1: 0.2203  loss_dice_1: 0.5896  loss_ce_2: 0  loss_mask_2: 0.2201  loss_dice_2: 0.5872  loss_ce_3: 0  loss_mask_3: 0.2216  loss_dice_3: 0.5853  loss_ce_4: 0  loss_mask_4: 0.2225  loss_dice_4: 0.5852  loss_ce_5: 0  loss_mask_5: 0.2227  loss_dice_5: 0.5856  loss_ce_6: 0  loss_mask_6: 0.2217  loss_dice_6: 0.5866  loss_ce_7: 0  loss_mask_7: 0.2203  loss_dice_7: 0.5882  loss_ce_8: 0  loss_mask_8: 0.222  loss_dice_8: 0.5864  time: 1.6790  data_time: 0.0560  lr: 9.3074e-05  max_mem: 5916M
[02/24 14:36:33] d2.utils.events INFO:  eta: 1 day, 1:42:31  iter: 4619  total_loss: 8.181  loss_ce: 0  loss_mask: 0.2239  loss_dice: 0.563  loss_seg: 0.322  loss_ce_0: 0  loss_mask_0: 0.2249  loss_dice_0: 0.5865  loss_ce_1: 0  loss_mask_1: 0.2234  loss_dice_1: 0.5636  loss_ce_2: 0  loss_mask_2: 0.2228  loss_dice_2: 0.5599  loss_ce_3: 0  loss_mask_3: 0.2217  loss_dice_3: 0.5588  loss_ce_4: 0  loss_mask_4: 0.2227  loss_dice_4: 0.5584  loss_ce_5: 0  loss_mask_5: 0.222  loss_dice_5: 0.5595  loss_ce_6: 0  loss_mask_6: 0.222  loss_dice_6: 0.5597  loss_ce_7: 0  loss_mask_7: 0.2214  loss_dice_7: 0.5608  loss_ce_8: 0  loss_mask_8: 0.2233  loss_dice_8: 0.5605  time: 1.6784  data_time: 0.0524  lr: 9.3044e-05  max_mem: 5916M
[02/24 14:37:08] d2.utils.events INFO:  eta: 1 day, 1:42:17  iter: 4639  total_loss: 8.425  loss_ce: 0  loss_mask: 0.2244  loss_dice: 0.5797  loss_seg: 0.3326  loss_ce_0: 0  loss_mask_0: 0.2184  loss_dice_0: 0.5902  loss_ce_1: 0  loss_mask_1: 0.2233  loss_dice_1: 0.5778  loss_ce_2: 0  loss_mask_2: 0.224  loss_dice_2: 0.5751  loss_ce_3: 0  loss_mask_3: 0.2245  loss_dice_3: 0.5746  loss_ce_4: 0  loss_mask_4: 0.2235  loss_dice_4: 0.5735  loss_ce_5: 0  loss_mask_5: 0.2237  loss_dice_5: 0.573  loss_ce_6: 0  loss_mask_6: 0.2227  loss_dice_6: 0.5744  loss_ce_7: 0  loss_mask_7: 0.2235  loss_dice_7: 0.5748  loss_ce_8: 0  loss_mask_8: 0.2246  loss_dice_8: 0.5749  time: 1.6788  data_time: 0.0494  lr: 9.3014e-05  max_mem: 5916M
[02/24 14:37:42] d2.utils.events INFO:  eta: 1 day, 1:42:35  iter: 4659  total_loss: 8.825  loss_ce: 0  loss_mask: 0.23  loss_dice: 0.6144  loss_seg: 0.3618  loss_ce_0: 0  loss_mask_0: 0.2232  loss_dice_0: 0.6278  loss_ce_1: 0  loss_mask_1: 0.2248  loss_dice_1: 0.6104  loss_ce_2: 0  loss_mask_2: 0.2251  loss_dice_2: 0.6085  loss_ce_3: 0  loss_mask_3: 0.2255  loss_dice_3: 0.6074  loss_ce_4: 0  loss_mask_4: 0.2249  loss_dice_4: 0.6069  loss_ce_5: 0  loss_mask_5: 0.2264  loss_dice_5: 0.6084  loss_ce_6: 0  loss_mask_6: 0.2266  loss_dice_6: 0.6091  loss_ce_7: 0  loss_mask_7: 0.2267  loss_dice_7: 0.6094  loss_ce_8: 0  loss_mask_8: 0.2256  loss_dice_8: 0.6121  time: 1.6788  data_time: 0.0511  lr: 9.2984e-05  max_mem: 5916M
[02/24 14:38:15] d2.utils.events INFO:  eta: 1 day, 1:42:02  iter: 4679  total_loss: 8.209  loss_ce: 0  loss_mask: 0.2333  loss_dice: 0.569  loss_seg: 0.3323  loss_ce_0: 0  loss_mask_0: 0.2293  loss_dice_0: 0.5802  loss_ce_1: 0  loss_mask_1: 0.2312  loss_dice_1: 0.5647  loss_ce_2: 0  loss_mask_2: 0.2307  loss_dice_2: 0.5634  loss_ce_3: 0  loss_mask_3: 0.2305  loss_dice_3: 0.5646  loss_ce_4: 0  loss_mask_4: 0.2305  loss_dice_4: 0.564  loss_ce_5: 0  loss_mask_5: 0.2306  loss_dice_5: 0.5647  loss_ce_6: 0  loss_mask_6: 0.2302  loss_dice_6: 0.5642  loss_ce_7: 0  loss_mask_7: 0.2304  loss_dice_7: 0.5642  loss_ce_8: 0  loss_mask_8: 0.231  loss_dice_8: 0.5648  time: 1.6787  data_time: 0.0585  lr: 9.2953e-05  max_mem: 5916M
[02/24 14:38:50] d2.utils.events INFO:  eta: 1 day, 1:42:16  iter: 4699  total_loss: 8.26  loss_ce: 0  loss_mask: 0.217  loss_dice: 0.5883  loss_seg: 0.3295  loss_ce_0: 0  loss_mask_0: 0.2155  loss_dice_0: 0.5937  loss_ce_1: 0  loss_mask_1: 0.2134  loss_dice_1: 0.5828  loss_ce_2: 0  loss_mask_2: 0.2144  loss_dice_2: 0.5823  loss_ce_3: 0  loss_mask_3: 0.2147  loss_dice_3: 0.5813  loss_ce_4: 0  loss_mask_4: 0.2151  loss_dice_4: 0.5816  loss_ce_5: 0  loss_mask_5: 0.2148  loss_dice_5: 0.5825  loss_ce_6: 0  loss_mask_6: 0.2151  loss_dice_6: 0.5818  loss_ce_7: 0  loss_mask_7: 0.2158  loss_dice_7: 0.5834  loss_ce_8: 0  loss_mask_8: 0.2164  loss_dice_8: 0.5838  time: 1.6790  data_time: 0.0565  lr: 9.2923e-05  max_mem: 5916M
[02/24 14:39:24] d2.utils.events INFO:  eta: 1 day, 1:42:17  iter: 4719  total_loss: 8.264  loss_ce: 0  loss_mask: 0.2223  loss_dice: 0.5761  loss_seg: 0.3071  loss_ce_0: 0  loss_mask_0: 0.2194  loss_dice_0: 0.591  loss_ce_1: 0  loss_mask_1: 0.2208  loss_dice_1: 0.5765  loss_ce_2: 0  loss_mask_2: 0.2199  loss_dice_2: 0.5728  loss_ce_3: 0  loss_mask_3: 0.2212  loss_dice_3: 0.5691  loss_ce_4: 0  loss_mask_4: 0.221  loss_dice_4: 0.5705  loss_ce_5: 0  loss_mask_5: 0.2202  loss_dice_5: 0.5703  loss_ce_6: 0  loss_mask_6: 0.2206  loss_dice_6: 0.5695  loss_ce_7: 0  loss_mask_7: 0.221  loss_dice_7: 0.5708  loss_ce_8: 0  loss_mask_8: 0.2213  loss_dice_8: 0.571  time: 1.6791  data_time: 0.0598  lr: 9.2893e-05  max_mem: 5916M
[02/24 14:39:57] d2.utils.events INFO:  eta: 1 day, 1:41:58  iter: 4739  total_loss: 8.454  loss_ce: 0  loss_mask: 0.2205  loss_dice: 0.5927  loss_seg: 0.3455  loss_ce_0: 0  loss_mask_0: 0.2226  loss_dice_0: 0.6072  loss_ce_1: 0  loss_mask_1: 0.22  loss_dice_1: 0.5893  loss_ce_2: 0  loss_mask_2: 0.2206  loss_dice_2: 0.5888  loss_ce_3: 0  loss_mask_3: 0.2213  loss_dice_3: 0.5871  loss_ce_4: 0  loss_mask_4: 0.2209  loss_dice_4: 0.5887  loss_ce_5: 0  loss_mask_5: 0.2209  loss_dice_5: 0.5884  loss_ce_6: 0  loss_mask_6: 0.2209  loss_dice_6: 0.588  loss_ce_7: 0  loss_mask_7: 0.2202  loss_dice_7: 0.5883  loss_ce_8: 0  loss_mask_8: 0.2199  loss_dice_8: 0.5883  time: 1.6789  data_time: 0.0529  lr: 9.2863e-05  max_mem: 5916M
[02/24 14:40:30] d2.utils.events INFO:  eta: 1 day, 1:40:52  iter: 4759  total_loss: 8.142  loss_ce: 0  loss_mask: 0.215  loss_dice: 0.5632  loss_seg: 0.3335  loss_ce_0: 0  loss_mask_0: 0.2125  loss_dice_0: 0.5811  loss_ce_1: 0  loss_mask_1: 0.2126  loss_dice_1: 0.5621  loss_ce_2: 0  loss_mask_2: 0.2138  loss_dice_2: 0.5615  loss_ce_3: 0  loss_mask_3: 0.214  loss_dice_3: 0.5588  loss_ce_4: 0  loss_mask_4: 0.2141  loss_dice_4: 0.5587  loss_ce_5: 0  loss_mask_5: 0.2142  loss_dice_5: 0.5583  loss_ce_6: 0  loss_mask_6: 0.2142  loss_dice_6: 0.5581  loss_ce_7: 0  loss_mask_7: 0.2138  loss_dice_7: 0.5587  loss_ce_8: 0  loss_mask_8: 0.2136  loss_dice_8: 0.558  time: 1.6787  data_time: 0.0524  lr: 9.2832e-05  max_mem: 5916M
[02/24 14:41:04] d2.utils.events INFO:  eta: 1 day, 1:40:18  iter: 4779  total_loss: 8.172  loss_ce: 0  loss_mask: 0.2276  loss_dice: 0.5687  loss_seg: 0.3251  loss_ce_0: 0  loss_mask_0: 0.2264  loss_dice_0: 0.5848  loss_ce_1: 0  loss_mask_1: 0.2253  loss_dice_1: 0.5659  loss_ce_2: 0  loss_mask_2: 0.2246  loss_dice_2: 0.5654  loss_ce_3: 0  loss_mask_3: 0.2267  loss_dice_3: 0.5644  loss_ce_4: 0  loss_mask_4: 0.2267  loss_dice_4: 0.5647  loss_ce_5: 0  loss_mask_5: 0.2253  loss_dice_5: 0.5645  loss_ce_6: 0  loss_mask_6: 0.2252  loss_dice_6: 0.5651  loss_ce_7: 0  loss_mask_7: 0.2265  loss_dice_7: 0.5649  loss_ce_8: 0  loss_mask_8: 0.2266  loss_dice_8: 0.566  time: 1.6788  data_time: 0.0547  lr: 9.2802e-05  max_mem: 5916M
[02/24 14:41:38] d2.utils.events INFO:  eta: 1 day, 1:40:42  iter: 4799  total_loss: 8.241  loss_ce: 0  loss_mask: 0.2221  loss_dice: 0.5759  loss_seg: 0.3302  loss_ce_0: 0  loss_mask_0: 0.2194  loss_dice_0: 0.5907  loss_ce_1: 0  loss_mask_1: 0.22  loss_dice_1: 0.5731  loss_ce_2: 0  loss_mask_2: 0.221  loss_dice_2: 0.5706  loss_ce_3: 0  loss_mask_3: 0.2202  loss_dice_3: 0.5694  loss_ce_4: 0  loss_mask_4: 0.2213  loss_dice_4: 0.5707  loss_ce_5: 0  loss_mask_5: 0.221  loss_dice_5: 0.5714  loss_ce_6: 0  loss_mask_6: 0.2215  loss_dice_6: 0.5721  loss_ce_7: 0  loss_mask_7: 0.2203  loss_dice_7: 0.5728  loss_ce_8: 0  loss_mask_8: 0.2205  loss_dice_8: 0.5726  time: 1.6788  data_time: 0.0514  lr: 9.2772e-05  max_mem: 5916M
[02/24 14:42:12] d2.utils.events INFO:  eta: 1 day, 1:41:01  iter: 4819  total_loss: 8.296  loss_ce: 0  loss_mask: 0.2287  loss_dice: 0.5707  loss_seg: 0.3141  loss_ce_0: 0  loss_mask_0: 0.2283  loss_dice_0: 0.5835  loss_ce_1: 0  loss_mask_1: 0.2281  loss_dice_1: 0.5715  loss_ce_2: 0  loss_mask_2: 0.2274  loss_dice_2: 0.569  loss_ce_3: 0  loss_mask_3: 0.2264  loss_dice_3: 0.5671  loss_ce_4: 0  loss_mask_4: 0.2277  loss_dice_4: 0.5689  loss_ce_5: 0  loss_mask_5: 0.2278  loss_dice_5: 0.5691  loss_ce_6: 0  loss_mask_6: 0.2283  loss_dice_6: 0.5685  loss_ce_7: 0  loss_mask_7: 0.2301  loss_dice_7: 0.5692  loss_ce_8: 0  loss_mask_8: 0.2285  loss_dice_8: 0.5681  time: 1.6788  data_time: 0.0649  lr: 9.2742e-05  max_mem: 5916M
[02/24 14:42:46] d2.utils.events INFO:  eta: 1 day, 1:39:35  iter: 4839  total_loss: 8.125  loss_ce: 0  loss_mask: 0.2261  loss_dice: 0.5555  loss_seg: 0.2876  loss_ce_0: 0  loss_mask_0: 0.2228  loss_dice_0: 0.5694  loss_ce_1: 0  loss_mask_1: 0.2231  loss_dice_1: 0.5564  loss_ce_2: 0  loss_mask_2: 0.2234  loss_dice_2: 0.5532  loss_ce_3: 0  loss_mask_3: 0.2239  loss_dice_3: 0.5521  loss_ce_4: 0  loss_mask_4: 0.2229  loss_dice_4: 0.5519  loss_ce_5: 0  loss_mask_5: 0.2221  loss_dice_5: 0.5531  loss_ce_6: 0  loss_mask_6: 0.2226  loss_dice_6: 0.5534  loss_ce_7: 0  loss_mask_7: 0.2226  loss_dice_7: 0.5534  loss_ce_8: 0  loss_mask_8: 0.2242  loss_dice_8: 0.5538  time: 1.6790  data_time: 0.0583  lr: 9.2711e-05  max_mem: 5916M
[02/24 14:43:20] d2.utils.events INFO:  eta: 1 day, 1:39:02  iter: 4859  total_loss: 8.521  loss_ce: 0  loss_mask: 0.2309  loss_dice: 0.5917  loss_seg: 0.3589  loss_ce_0: 0  loss_mask_0: 0.229  loss_dice_0: 0.5982  loss_ce_1: 0  loss_mask_1: 0.2297  loss_dice_1: 0.5896  loss_ce_2: 0  loss_mask_2: 0.2287  loss_dice_2: 0.5885  loss_ce_3: 0  loss_mask_3: 0.2295  loss_dice_3: 0.5872  loss_ce_4: 0  loss_mask_4: 0.2303  loss_dice_4: 0.586  loss_ce_5: 0  loss_mask_5: 0.2302  loss_dice_5: 0.5873  loss_ce_6: 0  loss_mask_6: 0.2303  loss_dice_6: 0.5871  loss_ce_7: 0  loss_mask_7: 0.2316  loss_dice_7: 0.588  loss_ce_8: 0  loss_mask_8: 0.2309  loss_dice_8: 0.5885  time: 1.6789  data_time: 0.0627  lr: 9.2681e-05  max_mem: 5916M
[02/24 14:43:53] d2.utils.events INFO:  eta: 1 day, 1:38:28  iter: 4879  total_loss: 7.954  loss_ce: 0  loss_mask: 0.2119  loss_dice: 0.5546  loss_seg: 0.3071  loss_ce_0: 0  loss_mask_0: 0.209  loss_dice_0: 0.5741  loss_ce_1: 0  loss_mask_1: 0.2101  loss_dice_1: 0.5543  loss_ce_2: 0  loss_mask_2: 0.2117  loss_dice_2: 0.5497  loss_ce_3: 0  loss_mask_3: 0.2117  loss_dice_3: 0.5483  loss_ce_4: 0  loss_mask_4: 0.2117  loss_dice_4: 0.5473  loss_ce_5: 0  loss_mask_5: 0.2124  loss_dice_5: 0.5475  loss_ce_6: 0  loss_mask_6: 0.2118  loss_dice_6: 0.5483  loss_ce_7: 0  loss_mask_7: 0.2119  loss_dice_7: 0.5487  loss_ce_8: 0  loss_mask_8: 0.2111  loss_dice_8: 0.5488  time: 1.6789  data_time: 0.0525  lr: 9.2651e-05  max_mem: 5916M
[02/24 14:44:28] d2.utils.events INFO:  eta: 1 day, 1:39:02  iter: 4899  total_loss: 8.345  loss_ce: 0  loss_mask: 0.2142  loss_dice: 0.5937  loss_seg: 0.3622  loss_ce_0: 0  loss_mask_0: 0.2135  loss_dice_0: 0.6024  loss_ce_1: 0  loss_mask_1: 0.2161  loss_dice_1: 0.593  loss_ce_2: 0  loss_mask_2: 0.2166  loss_dice_2: 0.5907  loss_ce_3: 0  loss_mask_3: 0.2164  loss_dice_3: 0.5903  loss_ce_4: 0  loss_mask_4: 0.2171  loss_dice_4: 0.5904  loss_ce_5: 0  loss_mask_5: 0.2162  loss_dice_5: 0.5912  loss_ce_6: 0  loss_mask_6: 0.215  loss_dice_6: 0.5895  loss_ce_7: 0  loss_mask_7: 0.2166  loss_dice_7: 0.5909  loss_ce_8: 0  loss_mask_8: 0.2159  loss_dice_8: 0.592  time: 1.6790  data_time: 0.0583  lr: 9.2621e-05  max_mem: 5916M
[02/24 14:45:01] d2.utils.events INFO:  eta: 1 day, 1:38:39  iter: 4919  total_loss: 7.868  loss_ce: 0  loss_mask: 0.2194  loss_dice: 0.5527  loss_seg: 0.2906  loss_ce_0: 0  loss_mask_0: 0.2144  loss_dice_0: 0.5726  loss_ce_1: 0  loss_mask_1: 0.2165  loss_dice_1: 0.5531  loss_ce_2: 0  loss_mask_2: 0.2172  loss_dice_2: 0.55  loss_ce_3: 0  loss_mask_3: 0.2185  loss_dice_3: 0.5503  loss_ce_4: 0  loss_mask_4: 0.2183  loss_dice_4: 0.5503  loss_ce_5: 0  loss_mask_5: 0.2172  loss_dice_5: 0.5517  loss_ce_6: 0  loss_mask_6: 0.2179  loss_dice_6: 0.5505  loss_ce_7: 0  loss_mask_7: 0.2189  loss_dice_7: 0.5508  loss_ce_8: 0  loss_mask_8: 0.2195  loss_dice_8: 0.5525  time: 1.6789  data_time: 0.0530  lr: 9.259e-05  max_mem: 5916M
[02/24 14:45:34] d2.utils.events INFO:  eta: 1 day, 1:37:58  iter: 4939  total_loss: 8.455  loss_ce: 0  loss_mask: 0.2229  loss_dice: 0.5819  loss_seg: 0.3298  loss_ce_0: 0  loss_mask_0: 0.2218  loss_dice_0: 0.5916  loss_ce_1: 0  loss_mask_1: 0.2226  loss_dice_1: 0.5823  loss_ce_2: 0  loss_mask_2: 0.2205  loss_dice_2: 0.5812  loss_ce_3: 0  loss_mask_3: 0.2204  loss_dice_3: 0.5771  loss_ce_4: 0  loss_mask_4: 0.2204  loss_dice_4: 0.5768  loss_ce_5: 0  loss_mask_5: 0.2206  loss_dice_5: 0.5779  loss_ce_6: 0  loss_mask_6: 0.2209  loss_dice_6: 0.5768  loss_ce_7: 0  loss_mask_7: 0.2211  loss_dice_7: 0.577  loss_ce_8: 0  loss_mask_8: 0.2204  loss_dice_8: 0.5774  time: 1.6788  data_time: 0.0635  lr: 9.256e-05  max_mem: 5916M
[02/24 14:46:08] d2.utils.events INFO:  eta: 1 day, 1:38:29  iter: 4959  total_loss: 8.293  loss_ce: 0  loss_mask: 0.2205  loss_dice: 0.5748  loss_seg: 0.3315  loss_ce_0: 0  loss_mask_0: 0.2162  loss_dice_0: 0.591  loss_ce_1: 0  loss_mask_1: 0.2172  loss_dice_1: 0.5739  loss_ce_2: 0  loss_mask_2: 0.2187  loss_dice_2: 0.5707  loss_ce_3: 0  loss_mask_3: 0.2184  loss_dice_3: 0.5687  loss_ce_4: 0  loss_mask_4: 0.2197  loss_dice_4: 0.5692  loss_ce_5: 0  loss_mask_5: 0.2192  loss_dice_5: 0.5693  loss_ce_6: 0  loss_mask_6: 0.218  loss_dice_6: 0.5687  loss_ce_7: 0  loss_mask_7: 0.2191  loss_dice_7: 0.5712  loss_ce_8: 0  loss_mask_8: 0.2207  loss_dice_8: 0.5716  time: 1.6789  data_time: 0.0527  lr: 9.253e-05  max_mem: 5916M
[02/24 14:46:43] d2.utils.events INFO:  eta: 1 day, 1:38:06  iter: 4979  total_loss: 8.255  loss_ce: 0  loss_mask: 0.2251  loss_dice: 0.5702  loss_seg: 0.291  loss_ce_0: 0  loss_mask_0: 0.2213  loss_dice_0: 0.5838  loss_ce_1: 0  loss_mask_1: 0.2231  loss_dice_1: 0.5694  loss_ce_2: 0  loss_mask_2: 0.2235  loss_dice_2: 0.5672  loss_ce_3: 0  loss_mask_3: 0.2239  loss_dice_3: 0.5659  loss_ce_4: 0  loss_mask_4: 0.225  loss_dice_4: 0.5662  loss_ce_5: 0  loss_mask_5: 0.2247  loss_dice_5: 0.5665  loss_ce_6: 0  loss_mask_6: 0.2245  loss_dice_6: 0.5669  loss_ce_7: 0  loss_mask_7: 0.2245  loss_dice_7: 0.5675  loss_ce_8: 0  loss_mask_8: 0.2256  loss_dice_8: 0.5662  time: 1.6790  data_time: 0.0599  lr: 9.25e-05  max_mem: 5916M
[02/24 14:47:16] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_refinelayerdeltas_noauxsegloss/model_0004999.pth
[02/24 14:47:18] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/24 14:47:20] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/24 14:47:20] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/24 14:47:44] mask2former INFO: Inference done 11/1093. Dataloading: 0.0067 s/iter. Inference: 0.3401 s/iter. Eval: 0.2610 s/iter. Total: 0.6077 s/iter. ETA=0:10:57
[02/24 14:47:49] mask2former INFO: Inference done 19/1093. Dataloading: 0.0116 s/iter. Inference: 0.3751 s/iter. Eval: 0.2775 s/iter. Total: 0.6643 s/iter. ETA=0:11:53
[02/24 14:47:55] mask2former INFO: Inference done 27/1093. Dataloading: 0.0108 s/iter. Inference: 0.3918 s/iter. Eval: 0.2675 s/iter. Total: 0.6703 s/iter. ETA=0:11:54
[02/24 14:48:01] mask2former INFO: Inference done 35/1093. Dataloading: 0.0130 s/iter. Inference: 0.3940 s/iter. Eval: 0.2735 s/iter. Total: 0.6806 s/iter. ETA=0:12:00
[02/24 14:48:06] mask2former INFO: Inference done 43/1093. Dataloading: 0.0129 s/iter. Inference: 0.3999 s/iter. Eval: 0.2654 s/iter. Total: 0.6791 s/iter. ETA=0:11:53
[02/24 14:48:11] mask2former INFO: Inference done 50/1093. Dataloading: 0.0133 s/iter. Inference: 0.4064 s/iter. Eval: 0.2678 s/iter. Total: 0.6884 s/iter. ETA=0:11:58
[02/24 14:48:16] mask2former INFO: Inference done 58/1093. Dataloading: 0.0133 s/iter. Inference: 0.4074 s/iter. Eval: 0.2593 s/iter. Total: 0.6810 s/iter. ETA=0:11:44
[02/24 14:48:22] mask2former INFO: Inference done 67/1093. Dataloading: 0.0132 s/iter. Inference: 0.4009 s/iter. Eval: 0.2557 s/iter. Total: 0.6706 s/iter. ETA=0:11:28
[02/24 14:48:27] mask2former INFO: Inference done 75/1093. Dataloading: 0.0136 s/iter. Inference: 0.3978 s/iter. Eval: 0.2612 s/iter. Total: 0.6733 s/iter. ETA=0:11:25
[02/24 14:48:33] mask2former INFO: Inference done 83/1093. Dataloading: 0.0138 s/iter. Inference: 0.3976 s/iter. Eval: 0.2594 s/iter. Total: 0.6715 s/iter. ETA=0:11:18
[02/24 14:48:38] mask2former INFO: Inference done 94/1093. Dataloading: 0.0130 s/iter. Inference: 0.3853 s/iter. Eval: 0.2460 s/iter. Total: 0.6450 s/iter. ETA=0:10:44
[02/24 14:48:43] mask2former INFO: Inference done 102/1093. Dataloading: 0.0131 s/iter. Inference: 0.3866 s/iter. Eval: 0.2515 s/iter. Total: 0.6517 s/iter. ETA=0:10:45
[02/24 14:48:49] mask2former INFO: Inference done 108/1093. Dataloading: 0.0130 s/iter. Inference: 0.3933 s/iter. Eval: 0.2580 s/iter. Total: 0.6650 s/iter. ETA=0:10:55
[02/24 14:48:54] mask2former INFO: Inference done 115/1093. Dataloading: 0.0133 s/iter. Inference: 0.3968 s/iter. Eval: 0.2584 s/iter. Total: 0.6690 s/iter. ETA=0:10:54
[02/24 14:48:59] mask2former INFO: Inference done 122/1093. Dataloading: 0.0130 s/iter. Inference: 0.3971 s/iter. Eval: 0.2617 s/iter. Total: 0.6724 s/iter. ETA=0:10:52
[02/24 14:49:04] mask2former INFO: Inference done 128/1093. Dataloading: 0.0135 s/iter. Inference: 0.4034 s/iter. Eval: 0.2646 s/iter. Total: 0.6820 s/iter. ETA=0:10:58
[02/24 14:49:10] mask2former INFO: Inference done 136/1093. Dataloading: 0.0134 s/iter. Inference: 0.4039 s/iter. Eval: 0.2648 s/iter. Total: 0.6828 s/iter. ETA=0:10:53
[02/24 14:49:15] mask2former INFO: Inference done 144/1093. Dataloading: 0.0135 s/iter. Inference: 0.4036 s/iter. Eval: 0.2648 s/iter. Total: 0.6824 s/iter. ETA=0:10:47
[02/24 14:49:20] mask2former INFO: Inference done 152/1093. Dataloading: 0.0135 s/iter. Inference: 0.4010 s/iter. Eval: 0.2655 s/iter. Total: 0.6805 s/iter. ETA=0:10:40
[02/24 14:49:25] mask2former INFO: Inference done 160/1093. Dataloading: 0.0134 s/iter. Inference: 0.3993 s/iter. Eval: 0.2661 s/iter. Total: 0.6793 s/iter. ETA=0:10:33
[02/24 14:49:31] mask2former INFO: Inference done 168/1093. Dataloading: 0.0133 s/iter. Inference: 0.3984 s/iter. Eval: 0.2652 s/iter. Total: 0.6773 s/iter. ETA=0:10:26
[02/24 14:49:36] mask2former INFO: Inference done 176/1093. Dataloading: 0.0137 s/iter. Inference: 0.3988 s/iter. Eval: 0.2659 s/iter. Total: 0.6789 s/iter. ETA=0:10:22
[02/24 14:49:42] mask2former INFO: Inference done 184/1093. Dataloading: 0.0135 s/iter. Inference: 0.3989 s/iter. Eval: 0.2659 s/iter. Total: 0.6788 s/iter. ETA=0:10:17
[02/24 14:49:47] mask2former INFO: Inference done 192/1093. Dataloading: 0.0135 s/iter. Inference: 0.3990 s/iter. Eval: 0.2661 s/iter. Total: 0.6792 s/iter. ETA=0:10:11
[02/24 14:49:52] mask2former INFO: Inference done 200/1093. Dataloading: 0.0135 s/iter. Inference: 0.3981 s/iter. Eval: 0.2666 s/iter. Total: 0.6787 s/iter. ETA=0:10:06
[02/24 14:49:58] mask2former INFO: Inference done 208/1093. Dataloading: 0.0136 s/iter. Inference: 0.3973 s/iter. Eval: 0.2661 s/iter. Total: 0.6776 s/iter. ETA=0:09:59
[02/24 14:50:03] mask2former INFO: Inference done 217/1093. Dataloading: 0.0135 s/iter. Inference: 0.3954 s/iter. Eval: 0.2645 s/iter. Total: 0.6739 s/iter. ETA=0:09:50
[02/24 14:50:08] mask2former INFO: Inference done 226/1093. Dataloading: 0.0133 s/iter. Inference: 0.3939 s/iter. Eval: 0.2630 s/iter. Total: 0.6706 s/iter. ETA=0:09:41
[02/24 14:50:14] mask2former INFO: Inference done 234/1093. Dataloading: 0.0132 s/iter. Inference: 0.3936 s/iter. Eval: 0.2634 s/iter. Total: 0.6706 s/iter. ETA=0:09:36
[02/24 14:50:19] mask2former INFO: Inference done 242/1093. Dataloading: 0.0130 s/iter. Inference: 0.3935 s/iter. Eval: 0.2625 s/iter. Total: 0.6695 s/iter. ETA=0:09:29
[02/24 14:50:24] mask2former INFO: Inference done 250/1093. Dataloading: 0.0130 s/iter. Inference: 0.3928 s/iter. Eval: 0.2632 s/iter. Total: 0.6695 s/iter. ETA=0:09:24
[02/24 14:50:29] mask2former INFO: Inference done 258/1093. Dataloading: 0.0135 s/iter. Inference: 0.3912 s/iter. Eval: 0.2638 s/iter. Total: 0.6690 s/iter. ETA=0:09:18
[02/24 14:50:35] mask2former INFO: Inference done 266/1093. Dataloading: 0.0134 s/iter. Inference: 0.3908 s/iter. Eval: 0.2636 s/iter. Total: 0.6682 s/iter. ETA=0:09:12
[02/24 14:50:40] mask2former INFO: Inference done 274/1093. Dataloading: 0.0132 s/iter. Inference: 0.3907 s/iter. Eval: 0.2636 s/iter. Total: 0.6680 s/iter. ETA=0:09:07
[02/24 14:50:45] mask2former INFO: Inference done 281/1093. Dataloading: 0.0134 s/iter. Inference: 0.3912 s/iter. Eval: 0.2651 s/iter. Total: 0.6701 s/iter. ETA=0:09:04
[02/24 14:50:50] mask2former INFO: Inference done 289/1093. Dataloading: 0.0135 s/iter. Inference: 0.3897 s/iter. Eval: 0.2654 s/iter. Total: 0.6690 s/iter. ETA=0:08:57
[02/24 14:50:55] mask2former INFO: Inference done 297/1093. Dataloading: 0.0135 s/iter. Inference: 0.3889 s/iter. Eval: 0.2659 s/iter. Total: 0.6688 s/iter. ETA=0:08:52
[02/24 14:51:01] mask2former INFO: Inference done 305/1093. Dataloading: 0.0135 s/iter. Inference: 0.3899 s/iter. Eval: 0.2654 s/iter. Total: 0.6692 s/iter. ETA=0:08:47
[02/24 14:51:06] mask2former INFO: Inference done 313/1093. Dataloading: 0.0134 s/iter. Inference: 0.3904 s/iter. Eval: 0.2648 s/iter. Total: 0.6690 s/iter. ETA=0:08:41
[02/24 14:51:12] mask2former INFO: Inference done 322/1093. Dataloading: 0.0133 s/iter. Inference: 0.3904 s/iter. Eval: 0.2643 s/iter. Total: 0.6685 s/iter. ETA=0:08:35
[02/24 14:51:17] mask2former INFO: Inference done 330/1093. Dataloading: 0.0135 s/iter. Inference: 0.3900 s/iter. Eval: 0.2643 s/iter. Total: 0.6683 s/iter. ETA=0:08:29
[02/24 14:51:22] mask2former INFO: Inference done 338/1093. Dataloading: 0.0134 s/iter. Inference: 0.3895 s/iter. Eval: 0.2644 s/iter. Total: 0.6677 s/iter. ETA=0:08:24
[02/24 14:51:28] mask2former INFO: Inference done 347/1093. Dataloading: 0.0133 s/iter. Inference: 0.3888 s/iter. Eval: 0.2635 s/iter. Total: 0.6661 s/iter. ETA=0:08:16
[02/24 14:51:33] mask2former INFO: Inference done 356/1093. Dataloading: 0.0132 s/iter. Inference: 0.3883 s/iter. Eval: 0.2626 s/iter. Total: 0.6646 s/iter. ETA=0:08:09
[02/24 14:51:39] mask2former INFO: Inference done 364/1093. Dataloading: 0.0132 s/iter. Inference: 0.3880 s/iter. Eval: 0.2625 s/iter. Total: 0.6641 s/iter. ETA=0:08:04
[02/24 14:51:44] mask2former INFO: Inference done 372/1093. Dataloading: 0.0130 s/iter. Inference: 0.3887 s/iter. Eval: 0.2628 s/iter. Total: 0.6650 s/iter. ETA=0:07:59
[02/24 14:51:50] mask2former INFO: Inference done 380/1093. Dataloading: 0.0130 s/iter. Inference: 0.3892 s/iter. Eval: 0.2630 s/iter. Total: 0.6657 s/iter. ETA=0:07:54
[02/24 14:51:55] mask2former INFO: Inference done 388/1093. Dataloading: 0.0130 s/iter. Inference: 0.3897 s/iter. Eval: 0.2628 s/iter. Total: 0.6660 s/iter. ETA=0:07:49
[02/24 14:52:00] mask2former INFO: Inference done 395/1093. Dataloading: 0.0130 s/iter. Inference: 0.3912 s/iter. Eval: 0.2627 s/iter. Total: 0.6674 s/iter. ETA=0:07:45
[02/24 14:52:06] mask2former INFO: Inference done 403/1093. Dataloading: 0.0130 s/iter. Inference: 0.3907 s/iter. Eval: 0.2629 s/iter. Total: 0.6669 s/iter. ETA=0:07:40
[02/24 14:52:11] mask2former INFO: Inference done 410/1093. Dataloading: 0.0129 s/iter. Inference: 0.3910 s/iter. Eval: 0.2636 s/iter. Total: 0.6680 s/iter. ETA=0:07:36
[02/24 14:52:16] mask2former INFO: Inference done 418/1093. Dataloading: 0.0129 s/iter. Inference: 0.3907 s/iter. Eval: 0.2642 s/iter. Total: 0.6683 s/iter. ETA=0:07:31
[02/24 14:52:21] mask2former INFO: Inference done 426/1093. Dataloading: 0.0130 s/iter. Inference: 0.3912 s/iter. Eval: 0.2636 s/iter. Total: 0.6682 s/iter. ETA=0:07:25
[02/24 14:52:27] mask2former INFO: Inference done 434/1093. Dataloading: 0.0130 s/iter. Inference: 0.3911 s/iter. Eval: 0.2635 s/iter. Total: 0.6680 s/iter. ETA=0:07:20
[02/24 14:52:32] mask2former INFO: Inference done 442/1093. Dataloading: 0.0130 s/iter. Inference: 0.3912 s/iter. Eval: 0.2635 s/iter. Total: 0.6682 s/iter. ETA=0:07:14
[02/24 14:52:38] mask2former INFO: Inference done 450/1093. Dataloading: 0.0130 s/iter. Inference: 0.3913 s/iter. Eval: 0.2636 s/iter. Total: 0.6684 s/iter. ETA=0:07:09
[02/24 14:52:43] mask2former INFO: Inference done 458/1093. Dataloading: 0.0130 s/iter. Inference: 0.3908 s/iter. Eval: 0.2638 s/iter. Total: 0.6681 s/iter. ETA=0:07:04
[02/24 14:52:48] mask2former INFO: Inference done 465/1093. Dataloading: 0.0130 s/iter. Inference: 0.3918 s/iter. Eval: 0.2640 s/iter. Total: 0.6692 s/iter. ETA=0:07:00
[02/24 14:52:54] mask2former INFO: Inference done 474/1093. Dataloading: 0.0130 s/iter. Inference: 0.3918 s/iter. Eval: 0.2632 s/iter. Total: 0.6684 s/iter. ETA=0:06:53
[02/24 14:52:59] mask2former INFO: Inference done 481/1093. Dataloading: 0.0131 s/iter. Inference: 0.3919 s/iter. Eval: 0.2641 s/iter. Total: 0.6695 s/iter. ETA=0:06:49
[02/24 14:53:04] mask2former INFO: Inference done 490/1093. Dataloading: 0.0130 s/iter. Inference: 0.3915 s/iter. Eval: 0.2635 s/iter. Total: 0.6685 s/iter. ETA=0:06:43
[02/24 14:53:10] mask2former INFO: Inference done 498/1093. Dataloading: 0.0130 s/iter. Inference: 0.3913 s/iter. Eval: 0.2637 s/iter. Total: 0.6683 s/iter. ETA=0:06:37
[02/24 14:53:15] mask2former INFO: Inference done 506/1093. Dataloading: 0.0130 s/iter. Inference: 0.3915 s/iter. Eval: 0.2630 s/iter. Total: 0.6680 s/iter. ETA=0:06:32
[02/24 14:53:20] mask2former INFO: Inference done 514/1093. Dataloading: 0.0130 s/iter. Inference: 0.3923 s/iter. Eval: 0.2628 s/iter. Total: 0.6685 s/iter. ETA=0:06:27
[02/24 14:53:26] mask2former INFO: Inference done 522/1093. Dataloading: 0.0131 s/iter. Inference: 0.3918 s/iter. Eval: 0.2628 s/iter. Total: 0.6681 s/iter. ETA=0:06:21
[02/24 14:53:31] mask2former INFO: Inference done 530/1093. Dataloading: 0.0130 s/iter. Inference: 0.3918 s/iter. Eval: 0.2623 s/iter. Total: 0.6675 s/iter. ETA=0:06:15
[02/24 14:53:36] mask2former INFO: Inference done 539/1093. Dataloading: 0.0130 s/iter. Inference: 0.3915 s/iter. Eval: 0.2614 s/iter. Total: 0.6663 s/iter. ETA=0:06:09
[02/24 14:53:41] mask2former INFO: Inference done 547/1093. Dataloading: 0.0130 s/iter. Inference: 0.3912 s/iter. Eval: 0.2612 s/iter. Total: 0.6658 s/iter. ETA=0:06:03
[02/24 14:53:47] mask2former INFO: Inference done 556/1093. Dataloading: 0.0130 s/iter. Inference: 0.3909 s/iter. Eval: 0.2609 s/iter. Total: 0.6651 s/iter. ETA=0:05:57
[02/24 14:53:52] mask2former INFO: Inference done 565/1093. Dataloading: 0.0129 s/iter. Inference: 0.3906 s/iter. Eval: 0.2606 s/iter. Total: 0.6645 s/iter. ETA=0:05:50
[02/24 14:53:58] mask2former INFO: Inference done 573/1093. Dataloading: 0.0129 s/iter. Inference: 0.3908 s/iter. Eval: 0.2607 s/iter. Total: 0.6647 s/iter. ETA=0:05:45
[02/24 14:54:03] mask2former INFO: Inference done 581/1093. Dataloading: 0.0128 s/iter. Inference: 0.3909 s/iter. Eval: 0.2606 s/iter. Total: 0.6648 s/iter. ETA=0:05:40
[02/24 14:54:09] mask2former INFO: Inference done 589/1093. Dataloading: 0.0128 s/iter. Inference: 0.3915 s/iter. Eval: 0.2606 s/iter. Total: 0.6653 s/iter. ETA=0:05:35
[02/24 14:54:14] mask2former INFO: Inference done 597/1093. Dataloading: 0.0128 s/iter. Inference: 0.3922 s/iter. Eval: 0.2603 s/iter. Total: 0.6656 s/iter. ETA=0:05:30
[02/24 14:54:20] mask2former INFO: Inference done 606/1093. Dataloading: 0.0128 s/iter. Inference: 0.3917 s/iter. Eval: 0.2600 s/iter. Total: 0.6649 s/iter. ETA=0:05:23
[02/24 14:54:25] mask2former INFO: Inference done 613/1093. Dataloading: 0.0128 s/iter. Inference: 0.3918 s/iter. Eval: 0.2605 s/iter. Total: 0.6655 s/iter. ETA=0:05:19
[02/24 14:54:30] mask2former INFO: Inference done 621/1093. Dataloading: 0.0129 s/iter. Inference: 0.3916 s/iter. Eval: 0.2608 s/iter. Total: 0.6657 s/iter. ETA=0:05:14
[02/24 14:54:35] mask2former INFO: Inference done 629/1093. Dataloading: 0.0128 s/iter. Inference: 0.3912 s/iter. Eval: 0.2611 s/iter. Total: 0.6655 s/iter. ETA=0:05:08
[02/24 14:54:41] mask2former INFO: Inference done 637/1093. Dataloading: 0.0129 s/iter. Inference: 0.3914 s/iter. Eval: 0.2612 s/iter. Total: 0.6659 s/iter. ETA=0:05:03
[02/24 14:54:46] mask2former INFO: Inference done 645/1093. Dataloading: 0.0129 s/iter. Inference: 0.3907 s/iter. Eval: 0.2617 s/iter. Total: 0.6657 s/iter. ETA=0:04:58
[02/24 14:54:51] mask2former INFO: Inference done 653/1093. Dataloading: 0.0129 s/iter. Inference: 0.3903 s/iter. Eval: 0.2619 s/iter. Total: 0.6655 s/iter. ETA=0:04:52
[02/24 14:54:57] mask2former INFO: Inference done 661/1093. Dataloading: 0.0129 s/iter. Inference: 0.3906 s/iter. Eval: 0.2619 s/iter. Total: 0.6658 s/iter. ETA=0:04:47
[02/24 14:55:02] mask2former INFO: Inference done 669/1093. Dataloading: 0.0130 s/iter. Inference: 0.3903 s/iter. Eval: 0.2622 s/iter. Total: 0.6658 s/iter. ETA=0:04:42
[02/24 14:55:08] mask2former INFO: Inference done 677/1093. Dataloading: 0.0131 s/iter. Inference: 0.3901 s/iter. Eval: 0.2626 s/iter. Total: 0.6662 s/iter. ETA=0:04:37
[02/24 14:55:13] mask2former INFO: Inference done 685/1093. Dataloading: 0.0131 s/iter. Inference: 0.3903 s/iter. Eval: 0.2628 s/iter. Total: 0.6666 s/iter. ETA=0:04:31
[02/24 14:55:19] mask2former INFO: Inference done 693/1093. Dataloading: 0.0130 s/iter. Inference: 0.3906 s/iter. Eval: 0.2626 s/iter. Total: 0.6666 s/iter. ETA=0:04:26
[02/24 14:55:24] mask2former INFO: Inference done 706/1093. Dataloading: 0.0129 s/iter. Inference: 0.3884 s/iter. Eval: 0.2603 s/iter. Total: 0.6620 s/iter. ETA=0:04:16
[02/24 14:55:30] mask2former INFO: Inference done 713/1093. Dataloading: 0.0129 s/iter. Inference: 0.3893 s/iter. Eval: 0.2609 s/iter. Total: 0.6635 s/iter. ETA=0:04:12
[02/24 14:55:35] mask2former INFO: Inference done 718/1093. Dataloading: 0.0130 s/iter. Inference: 0.3912 s/iter. Eval: 0.2620 s/iter. Total: 0.6666 s/iter. ETA=0:04:09
[02/24 14:55:41] mask2former INFO: Inference done 727/1093. Dataloading: 0.0130 s/iter. Inference: 0.3906 s/iter. Eval: 0.2617 s/iter. Total: 0.6656 s/iter. ETA=0:04:03
[02/24 14:55:46] mask2former INFO: Inference done 734/1093. Dataloading: 0.0130 s/iter. Inference: 0.3910 s/iter. Eval: 0.2627 s/iter. Total: 0.6671 s/iter. ETA=0:03:59
[02/24 14:55:52] mask2former INFO: Inference done 741/1093. Dataloading: 0.0131 s/iter. Inference: 0.3916 s/iter. Eval: 0.2627 s/iter. Total: 0.6677 s/iter. ETA=0:03:55
[02/24 14:55:57] mask2former INFO: Inference done 749/1093. Dataloading: 0.0130 s/iter. Inference: 0.3917 s/iter. Eval: 0.2625 s/iter. Total: 0.6676 s/iter. ETA=0:03:49
[02/24 14:56:02] mask2former INFO: Inference done 756/1093. Dataloading: 0.0130 s/iter. Inference: 0.3922 s/iter. Eval: 0.2627 s/iter. Total: 0.6682 s/iter. ETA=0:03:45
[02/24 14:56:07] mask2former INFO: Inference done 764/1093. Dataloading: 0.0131 s/iter. Inference: 0.3921 s/iter. Eval: 0.2625 s/iter. Total: 0.6681 s/iter. ETA=0:03:39
[02/24 14:56:13] mask2former INFO: Inference done 772/1093. Dataloading: 0.0130 s/iter. Inference: 0.3922 s/iter. Eval: 0.2625 s/iter. Total: 0.6682 s/iter. ETA=0:03:34
[02/24 14:56:18] mask2former INFO: Inference done 780/1093. Dataloading: 0.0130 s/iter. Inference: 0.3924 s/iter. Eval: 0.2625 s/iter. Total: 0.6684 s/iter. ETA=0:03:29
[02/24 14:56:23] mask2former INFO: Inference done 787/1093. Dataloading: 0.0131 s/iter. Inference: 0.3930 s/iter. Eval: 0.2624 s/iter. Total: 0.6689 s/iter. ETA=0:03:24
[02/24 14:56:28] mask2former INFO: Inference done 795/1093. Dataloading: 0.0130 s/iter. Inference: 0.3925 s/iter. Eval: 0.2627 s/iter. Total: 0.6686 s/iter. ETA=0:03:19
[02/24 14:56:34] mask2former INFO: Inference done 804/1093. Dataloading: 0.0130 s/iter. Inference: 0.3923 s/iter. Eval: 0.2623 s/iter. Total: 0.6680 s/iter. ETA=0:03:13
[02/24 14:56:40] mask2former INFO: Inference done 813/1093. Dataloading: 0.0131 s/iter. Inference: 0.3920 s/iter. Eval: 0.2621 s/iter. Total: 0.6676 s/iter. ETA=0:03:06
[02/24 14:56:45] mask2former INFO: Inference done 821/1093. Dataloading: 0.0131 s/iter. Inference: 0.3923 s/iter. Eval: 0.2623 s/iter. Total: 0.6681 s/iter. ETA=0:03:01
[02/24 14:56:51] mask2former INFO: Inference done 829/1093. Dataloading: 0.0131 s/iter. Inference: 0.3922 s/iter. Eval: 0.2624 s/iter. Total: 0.6681 s/iter. ETA=0:02:56
[02/24 14:56:56] mask2former INFO: Inference done 837/1093. Dataloading: 0.0131 s/iter. Inference: 0.3920 s/iter. Eval: 0.2628 s/iter. Total: 0.6683 s/iter. ETA=0:02:51
[02/24 14:57:01] mask2former INFO: Inference done 845/1093. Dataloading: 0.0132 s/iter. Inference: 0.3920 s/iter. Eval: 0.2626 s/iter. Total: 0.6681 s/iter. ETA=0:02:45
[02/24 14:57:07] mask2former INFO: Inference done 854/1093. Dataloading: 0.0132 s/iter. Inference: 0.3919 s/iter. Eval: 0.2620 s/iter. Total: 0.6675 s/iter. ETA=0:02:39
[02/24 14:57:13] mask2former INFO: Inference done 862/1093. Dataloading: 0.0132 s/iter. Inference: 0.3921 s/iter. Eval: 0.2623 s/iter. Total: 0.6679 s/iter. ETA=0:02:34
[02/24 14:57:18] mask2former INFO: Inference done 871/1093. Dataloading: 0.0131 s/iter. Inference: 0.3918 s/iter. Eval: 0.2619 s/iter. Total: 0.6672 s/iter. ETA=0:02:28
[02/24 14:57:23] mask2former INFO: Inference done 880/1093. Dataloading: 0.0131 s/iter. Inference: 0.3914 s/iter. Eval: 0.2613 s/iter. Total: 0.6663 s/iter. ETA=0:02:21
[02/24 14:57:29] mask2former INFO: Inference done 888/1093. Dataloading: 0.0131 s/iter. Inference: 0.3915 s/iter. Eval: 0.2614 s/iter. Total: 0.6664 s/iter. ETA=0:02:16
[02/24 14:57:34] mask2former INFO: Inference done 897/1093. Dataloading: 0.0131 s/iter. Inference: 0.3913 s/iter. Eval: 0.2611 s/iter. Total: 0.6659 s/iter. ETA=0:02:10
[02/24 14:57:39] mask2former INFO: Inference done 905/1093. Dataloading: 0.0132 s/iter. Inference: 0.3912 s/iter. Eval: 0.2611 s/iter. Total: 0.6659 s/iter. ETA=0:02:05
[02/24 14:57:45] mask2former INFO: Inference done 913/1093. Dataloading: 0.0132 s/iter. Inference: 0.3914 s/iter. Eval: 0.2611 s/iter. Total: 0.6660 s/iter. ETA=0:01:59
[02/24 14:57:50] mask2former INFO: Inference done 921/1093. Dataloading: 0.0131 s/iter. Inference: 0.3914 s/iter. Eval: 0.2612 s/iter. Total: 0.6661 s/iter. ETA=0:01:54
[02/24 14:57:56] mask2former INFO: Inference done 930/1093. Dataloading: 0.0131 s/iter. Inference: 0.3911 s/iter. Eval: 0.2610 s/iter. Total: 0.6656 s/iter. ETA=0:01:48
[02/24 14:58:01] mask2former INFO: Inference done 938/1093. Dataloading: 0.0131 s/iter. Inference: 0.3911 s/iter. Eval: 0.2608 s/iter. Total: 0.6654 s/iter. ETA=0:01:43
[02/24 14:58:06] mask2former INFO: Inference done 946/1093. Dataloading: 0.0131 s/iter. Inference: 0.3912 s/iter. Eval: 0.2607 s/iter. Total: 0.6654 s/iter. ETA=0:01:37
[02/24 14:58:12] mask2former INFO: Inference done 954/1093. Dataloading: 0.0131 s/iter. Inference: 0.3911 s/iter. Eval: 0.2608 s/iter. Total: 0.6654 s/iter. ETA=0:01:32
[02/24 14:58:17] mask2former INFO: Inference done 962/1093. Dataloading: 0.0131 s/iter. Inference: 0.3910 s/iter. Eval: 0.2610 s/iter. Total: 0.6655 s/iter. ETA=0:01:27
[02/24 14:58:23] mask2former INFO: Inference done 971/1093. Dataloading: 0.0131 s/iter. Inference: 0.3906 s/iter. Eval: 0.2609 s/iter. Total: 0.6650 s/iter. ETA=0:01:21
[02/24 14:58:28] mask2former INFO: Inference done 979/1093. Dataloading: 0.0131 s/iter. Inference: 0.3907 s/iter. Eval: 0.2611 s/iter. Total: 0.6652 s/iter. ETA=0:01:15
[02/24 14:58:33] mask2former INFO: Inference done 987/1093. Dataloading: 0.0131 s/iter. Inference: 0.3906 s/iter. Eval: 0.2611 s/iter. Total: 0.6652 s/iter. ETA=0:01:10
[02/24 14:58:39] mask2former INFO: Inference done 995/1093. Dataloading: 0.0131 s/iter. Inference: 0.3907 s/iter. Eval: 0.2608 s/iter. Total: 0.6650 s/iter. ETA=0:01:05
[02/24 14:58:44] mask2former INFO: Inference done 1003/1093. Dataloading: 0.0131 s/iter. Inference: 0.3908 s/iter. Eval: 0.2610 s/iter. Total: 0.6653 s/iter. ETA=0:00:59
[02/24 14:58:49] mask2former INFO: Inference done 1011/1093. Dataloading: 0.0131 s/iter. Inference: 0.3907 s/iter. Eval: 0.2610 s/iter. Total: 0.6652 s/iter. ETA=0:00:54
[02/24 14:58:55] mask2former INFO: Inference done 1019/1093. Dataloading: 0.0131 s/iter. Inference: 0.3905 s/iter. Eval: 0.2611 s/iter. Total: 0.6651 s/iter. ETA=0:00:49
[02/24 14:59:00] mask2former INFO: Inference done 1028/1093. Dataloading: 0.0132 s/iter. Inference: 0.3904 s/iter. Eval: 0.2608 s/iter. Total: 0.6647 s/iter. ETA=0:00:43
[02/24 14:59:06] mask2former INFO: Inference done 1036/1093. Dataloading: 0.0132 s/iter. Inference: 0.3904 s/iter. Eval: 0.2609 s/iter. Total: 0.6649 s/iter. ETA=0:00:37
[02/24 14:59:11] mask2former INFO: Inference done 1044/1093. Dataloading: 0.0132 s/iter. Inference: 0.3903 s/iter. Eval: 0.2612 s/iter. Total: 0.6651 s/iter. ETA=0:00:32
[02/24 14:59:16] mask2former INFO: Inference done 1052/1093. Dataloading: 0.0132 s/iter. Inference: 0.3902 s/iter. Eval: 0.2612 s/iter. Total: 0.6650 s/iter. ETA=0:00:27
[02/24 14:59:22] mask2former INFO: Inference done 1060/1093. Dataloading: 0.0132 s/iter. Inference: 0.3902 s/iter. Eval: 0.2611 s/iter. Total: 0.6648 s/iter. ETA=0:00:21
[02/24 14:59:27] mask2former INFO: Inference done 1068/1093. Dataloading: 0.0132 s/iter. Inference: 0.3900 s/iter. Eval: 0.2610 s/iter. Total: 0.6646 s/iter. ETA=0:00:16
[02/24 14:59:32] mask2former INFO: Inference done 1076/1093. Dataloading: 0.0132 s/iter. Inference: 0.3900 s/iter. Eval: 0.2611 s/iter. Total: 0.6647 s/iter. ETA=0:00:11
[02/24 14:59:37] mask2former INFO: Inference done 1084/1093. Dataloading: 0.0133 s/iter. Inference: 0.3902 s/iter. Eval: 0.2609 s/iter. Total: 0.6647 s/iter. ETA=0:00:05
[02/24 14:59:42] mask2former INFO: Inference done 1091/1093. Dataloading: 0.0134 s/iter. Inference: 0.3905 s/iter. Eval: 0.2609 s/iter. Total: 0.6652 s/iter. ETA=0:00:01
[02/24 15:00:59] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.814157620084807, 'error_1pix': 0.3274155305699209, 'error_3pix': 0.13899927529124537, 'mIoU': 11.850341689696053, 'fwIoU': 36.17521710006, 'IoU-1': 93.1438735714895, 'IoU-2': 3.87531762086748, 'IoU-3': 0.1826368758122661, 'IoU-4': 1.1144091678060966, 'IoU-5': 4.451251542367851, 'IoU-6': 1.3567276909209585, 'IoU-7': 0.5792509053113489, 'IoU-8': 3.087083455610763, 'IoU-9': 9.386277730425164, 'IoU-10': 4.759692594499318, 'IoU-11': 2.9686530990857576, 'IoU-12': 13.321463592730737, 'IoU-13': 18.127843111100155, 'IoU-14': 7.9874777506389325, 'IoU-15': 10.226421700046703, 'IoU-16': 11.617072748791433, 'IoU-17': 19.707309722019247, 'IoU-18': 5.507906649091857, 'IoU-19': 7.014008501482039, 'IoU-20': 14.620498095527243, 'IoU-21': 19.28876107464718, 'IoU-22': 4.263635417019483, 'IoU-23': 4.233915984324407, 'IoU-24': 12.388550015557417, 'IoU-25': 18.60463174597757, 'IoU-26': 4.7360920834938565, 'IoU-27': 6.787633746684254, 'IoU-28': 22.15103425638038, 'IoU-29': 19.56823979333378, 'IoU-30': 6.736968690989737, 'IoU-31': 8.109831477166567, 'IoU-32': 16.03397252653934, 'IoU-33': 22.826956184111875, 'IoU-34': 6.545444431913892, 'IoU-35': 4.0028011838073665, 'IoU-36': 13.172355395572378, 'IoU-37': 21.131675707897035, 'IoU-38': 7.189931578986745, 'IoU-39': 4.625782676509746, 'IoU-40': 15.075647585923447, 'IoU-41': 21.77589456573938, 'IoU-42': 9.19034405099435, 'IoU-43': 5.751874783445002, 'IoU-44': 14.393349792007697, 'IoU-45': 17.578134263252025, 'IoU-46': 7.604767644401086, 'IoU-47': 5.260227850104336, 'IoU-48': 16.752770473005356, 'mACC': 23.2700519272856, 'pACC': 43.63983951229905, 'ACC-1': 96.95559788439866, 'ACC-2': 3.876000081876291, 'ACC-3': 34.16692309888555, 'ACC-4': 47.84107097311992, 'ACC-5': 24.463458718713095, 'ACC-6': 5.608719073137222, 'ACC-7': 2.4155336555257945, 'ACC-8': 12.050408778208043, 'ACC-9': 16.51323355267, 'ACC-10': 5.803919476052421, 'ACC-11': 3.425623265259472, 'ACC-12': 20.188035919406776, 'ACC-13': 31.124206700670182, 'ACC-14': 12.346730428670922, 'ACC-15': 19.02204367820174, 'ACC-16': 23.58991902319465, 'ACC-17': 40.659558968803836, 'ACC-18': 7.649992475594036, 'ACC-19': 11.288958039488794, 'ACC-20': 34.14438775868111, 'ACC-21': 33.68881293834542, 'ACC-22': 5.454160598642399, 'ACC-23': 6.803025308624458, 'ACC-24': 32.31777796675256, 'ACC-25': 34.81250987927891, 'ACC-26': 6.33055854189222, 'ACC-27': 11.364323465299279, 'ACC-28': 57.86757206216513, 'ACC-29': 30.175744905950292, 'ACC-30': 8.627927189476612, 'ACC-31': 13.622901228658444, 'ACC-32': 34.6070278953676, 'ACC-33': 42.799127889866114, 'ACC-34': 8.86732093234067, 'ACC-35': 5.912550089172681, 'ACC-36': 32.06924794762484, 'ACC-37': 41.28732937801712, 'ACC-38': 9.977115062209437, 'ACC-39': 6.863268293045523, 'ACC-40': 39.47284323186587, 'ACC-41': 43.698641010878156, 'ACC-42': 12.737472025869293, 'ACC-43': 8.45274961903788, 'ACC-44': 32.53117682457394, 'ACC-45': 33.12755932534729, 'ACC-46': 11.002470959549521, 'ACC-47': 8.686335011817956, 'ACC-48': 50.67062137748051})])
[02/24 15:00:59] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/24 15:00:59] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/24 15:00:59] d2.evaluation.testing INFO: copypaste: 2.8142,0.3274,0.1390,11.8503,36.1752,23.2701,43.6398
[02/24 15:00:59] d2.utils.events INFO:  eta: 1 day, 1:36:00  iter: 4999  total_loss: 8.116  loss_ce: 0  loss_mask: 0.2237  loss_dice: 0.5576  loss_seg: 0.3215  loss_ce_0: 0  loss_mask_0: 0.2227  loss_dice_0: 0.5696  loss_ce_1: 0  loss_mask_1: 0.2203  loss_dice_1: 0.5552  loss_ce_2: 0  loss_mask_2: 0.2208  loss_dice_2: 0.5532  loss_ce_3: 0  loss_mask_3: 0.2203  loss_dice_3: 0.5527  loss_ce_4: 0  loss_mask_4: 0.2217  loss_dice_4: 0.5534  loss_ce_5: 0  loss_mask_5: 0.2212  loss_dice_5: 0.5527  loss_ce_6: 0  loss_mask_6: 0.2205  loss_dice_6: 0.5534  loss_ce_7: 0  loss_mask_7: 0.2222  loss_dice_7: 0.5534  loss_ce_8: 0  loss_mask_8: 0.2216  loss_dice_8: 0.5547  time: 1.6789  data_time: 0.0651  lr: 9.2469e-05  max_mem: 5916M
[02/24 15:01:33] d2.utils.events INFO:  eta: 1 day, 1:34:34  iter: 5019  total_loss: 7.987  loss_ce: 0  loss_mask: 0.212  loss_dice: 0.5601  loss_seg: 0.2943  loss_ce_0: 0  loss_mask_0: 0.2123  loss_dice_0: 0.5784  loss_ce_1: 0  loss_mask_1: 0.2082  loss_dice_1: 0.559  loss_ce_2: 0  loss_mask_2: 0.2088  loss_dice_2: 0.5567  loss_ce_3: 0  loss_mask_3: 0.2097  loss_dice_3: 0.556  loss_ce_4: 0  loss_mask_4: 0.2099  loss_dice_4: 0.557  loss_ce_5: 0  loss_mask_5: 0.2092  loss_dice_5: 0.5563  loss_ce_6: 0  loss_mask_6: 0.2092  loss_dice_6: 0.5559  loss_ce_7: 0  loss_mask_7: 0.2099  loss_dice_7: 0.5564  loss_ce_8: 0  loss_mask_8: 0.2105  loss_dice_8: 0.5565  time: 1.6789  data_time: 0.0687  lr: 9.2439e-05  max_mem: 5916M
[02/24 15:02:07] d2.utils.events INFO:  eta: 1 day, 1:34:53  iter: 5039  total_loss: 8.411  loss_ce: 0  loss_mask: 0.2198  loss_dice: 0.5889  loss_seg: 0.3571  loss_ce_0: 0  loss_mask_0: 0.2168  loss_dice_0: 0.598  loss_ce_1: 0  loss_mask_1: 0.2182  loss_dice_1: 0.5876  loss_ce_2: 0  loss_mask_2: 0.219  loss_dice_2: 0.5867  loss_ce_3: 0  loss_mask_3: 0.219  loss_dice_3: 0.586  loss_ce_4: 0  loss_mask_4: 0.2184  loss_dice_4: 0.5866  loss_ce_5: 0  loss_mask_5: 0.2177  loss_dice_5: 0.5872  loss_ce_6: 0  loss_mask_6: 0.2175  loss_dice_6: 0.5861  loss_ce_7: 0  loss_mask_7: 0.2172  loss_dice_7: 0.587  loss_ce_8: 0  loss_mask_8: 0.2176  loss_dice_8: 0.5864  time: 1.6789  data_time: 0.0624  lr: 9.2409e-05  max_mem: 5916M
[02/24 15:02:41] d2.utils.events INFO:  eta: 1 day, 1:32:30  iter: 5059  total_loss: 8.161  loss_ce: 0  loss_mask: 0.2237  loss_dice: 0.5622  loss_seg: 0.3059  loss_ce_0: 0  loss_mask_0: 0.2224  loss_dice_0: 0.5734  loss_ce_1: 0  loss_mask_1: 0.2254  loss_dice_1: 0.5618  loss_ce_2: 0  loss_mask_2: 0.2245  loss_dice_2: 0.5594  loss_ce_3: 0  loss_mask_3: 0.2239  loss_dice_3: 0.5582  loss_ce_4: 0  loss_mask_4: 0.2233  loss_dice_4: 0.5586  loss_ce_5: 0  loss_mask_5: 0.2234  loss_dice_5: 0.5575  loss_ce_6: 0  loss_mask_6: 0.2244  loss_dice_6: 0.5577  loss_ce_7: 0  loss_mask_7: 0.2241  loss_dice_7: 0.5605  loss_ce_8: 0  loss_mask_8: 0.2226  loss_dice_8: 0.5603  time: 1.6789  data_time: 0.0544  lr: 9.2378e-05  max_mem: 5916M
[02/24 15:03:13] d2.utils.events INFO:  eta: 1 day, 1:30:17  iter: 5079  total_loss: 8.297  loss_ce: 0  loss_mask: 0.2227  loss_dice: 0.5724  loss_seg: 0.2864  loss_ce_0: 0  loss_mask_0: 0.2175  loss_dice_0: 0.5797  loss_ce_1: 0  loss_mask_1: 0.223  loss_dice_1: 0.5711  loss_ce_2: 0  loss_mask_2: 0.2228  loss_dice_2: 0.5683  loss_ce_3: 0  loss_mask_3: 0.2235  loss_dice_3: 0.567  loss_ce_4: 0  loss_mask_4: 0.2241  loss_dice_4: 0.5668  loss_ce_5: 0  loss_mask_5: 0.224  loss_dice_5: 0.568  loss_ce_6: 0  loss_mask_6: 0.2239  loss_dice_6: 0.5673  loss_ce_7: 0  loss_mask_7: 0.2239  loss_dice_7: 0.569  loss_ce_8: 0  loss_mask_8: 0.2232  loss_dice_8: 0.5692  time: 1.6786  data_time: 0.0544  lr: 9.2348e-05  max_mem: 5916M
[02/24 15:03:47] d2.utils.events INFO:  eta: 1 day, 1:29:43  iter: 5099  total_loss: 8.001  loss_ce: 0  loss_mask: 0.2141  loss_dice: 0.5498  loss_seg: 0.314  loss_ce_0: 0  loss_mask_0: 0.2107  loss_dice_0: 0.5638  loss_ce_1: 0  loss_mask_1: 0.2115  loss_dice_1: 0.5439  loss_ce_2: 0  loss_mask_2: 0.2109  loss_dice_2: 0.5438  loss_ce_3: 0  loss_mask_3: 0.2123  loss_dice_3: 0.544  loss_ce_4: 0  loss_mask_4: 0.2107  loss_dice_4: 0.5455  loss_ce_5: 0  loss_mask_5: 0.2118  loss_dice_5: 0.5455  loss_ce_6: 0  loss_mask_6: 0.2123  loss_dice_6: 0.546  loss_ce_7: 0  loss_mask_7: 0.2115  loss_dice_7: 0.5461  loss_ce_8: 0  loss_mask_8: 0.2131  loss_dice_8: 0.5474  time: 1.6787  data_time: 0.0491  lr: 9.2318e-05  max_mem: 5916M
[02/24 15:04:21] d2.utils.events INFO:  eta: 1 day, 1:30:29  iter: 5119  total_loss: 7.94  loss_ce: 0  loss_mask: 0.219  loss_dice: 0.5505  loss_seg: 0.3054  loss_ce_0: 0  loss_mask_0: 0.2138  loss_dice_0: 0.567  loss_ce_1: 0  loss_mask_1: 0.2167  loss_dice_1: 0.5482  loss_ce_2: 0  loss_mask_2: 0.2167  loss_dice_2: 0.5467  loss_ce_3: 0  loss_mask_3: 0.2184  loss_dice_3: 0.5456  loss_ce_4: 0  loss_mask_4: 0.2182  loss_dice_4: 0.5452  loss_ce_5: 0  loss_mask_5: 0.2181  loss_dice_5: 0.5453  loss_ce_6: 0  loss_mask_6: 0.2173  loss_dice_6: 0.546  loss_ce_7: 0  loss_mask_7: 0.2178  loss_dice_7: 0.546  loss_ce_8: 0  loss_mask_8: 0.2192  loss_dice_8: 0.549  time: 1.6787  data_time: 0.0476  lr: 9.2288e-05  max_mem: 5916M
[02/24 15:04:55] d2.utils.events INFO:  eta: 1 day, 1:29:43  iter: 5139  total_loss: 7.884  loss_ce: 0  loss_mask: 0.2102  loss_dice: 0.5466  loss_seg: 0.2929  loss_ce_0: 0  loss_mask_0: 0.2083  loss_dice_0: 0.5633  loss_ce_1: 0  loss_mask_1: 0.2089  loss_dice_1: 0.5444  loss_ce_2: 0  loss_mask_2: 0.2084  loss_dice_2: 0.5426  loss_ce_3: 0  loss_mask_3: 0.2098  loss_dice_3: 0.5432  loss_ce_4: 0  loss_mask_4: 0.2099  loss_dice_4: 0.5433  loss_ce_5: 0  loss_mask_5: 0.209  loss_dice_5: 0.5441  loss_ce_6: 0  loss_mask_6: 0.2095  loss_dice_6: 0.5434  loss_ce_7: 0  loss_mask_7: 0.2104  loss_dice_7: 0.5444  loss_ce_8: 0  loss_mask_8: 0.2111  loss_dice_8: 0.5438  time: 1.6787  data_time: 0.0584  lr: 9.2257e-05  max_mem: 5916M
[02/24 15:05:28] d2.utils.events INFO:  eta: 1 day, 1:25:49  iter: 5159  total_loss: 8.461  loss_ce: 0  loss_mask: 0.2232  loss_dice: 0.5831  loss_seg: 0.3353  loss_ce_0: 0  loss_mask_0: 0.2248  loss_dice_0: 0.5926  loss_ce_1: 0  loss_mask_1: 0.2215  loss_dice_1: 0.5836  loss_ce_2: 0  loss_mask_2: 0.2221  loss_dice_2: 0.582  loss_ce_3: 0  loss_mask_3: 0.2224  loss_dice_3: 0.5809  loss_ce_4: 0  loss_mask_4: 0.2224  loss_dice_4: 0.5793  loss_ce_5: 0  loss_mask_5: 0.2227  loss_dice_5: 0.5803  loss_ce_6: 0  loss_mask_6: 0.2227  loss_dice_6: 0.5813  loss_ce_7: 0  loss_mask_7: 0.2234  loss_dice_7: 0.5799  loss_ce_8: 0  loss_mask_8: 0.2232  loss_dice_8: 0.5795  time: 1.6787  data_time: 0.0525  lr: 9.2227e-05  max_mem: 5916M
[02/24 15:06:03] d2.utils.events INFO:  eta: 1 day, 1:25:15  iter: 5179  total_loss: 8.33  loss_ce: 0  loss_mask: 0.2254  loss_dice: 0.5761  loss_seg: 0.3905  loss_ce_0: 0  loss_mask_0: 0.223  loss_dice_0: 0.586  loss_ce_1: 0  loss_mask_1: 0.2237  loss_dice_1: 0.5752  loss_ce_2: 0  loss_mask_2: 0.2232  loss_dice_2: 0.5735  loss_ce_3: 0  loss_mask_3: 0.2248  loss_dice_3: 0.5722  loss_ce_4: 0  loss_mask_4: 0.2236  loss_dice_4: 0.5719  loss_ce_5: 0  loss_mask_5: 0.2228  loss_dice_5: 0.5724  loss_ce_6: 0  loss_mask_6: 0.2244  loss_dice_6: 0.5726  loss_ce_7: 0  loss_mask_7: 0.2259  loss_dice_7: 0.573  loss_ce_8: 0  loss_mask_8: 0.2255  loss_dice_8: 0.5754  time: 1.6789  data_time: 0.0691  lr: 9.2197e-05  max_mem: 5916M
[02/24 15:06:37] d2.utils.events INFO:  eta: 1 day, 1:23:22  iter: 5199  total_loss: 8.126  loss_ce: 0  loss_mask: 0.2131  loss_dice: 0.5654  loss_seg: 0.34  loss_ce_0: 0  loss_mask_0: 0.2124  loss_dice_0: 0.5791  loss_ce_1: 0  loss_mask_1: 0.2121  loss_dice_1: 0.5662  loss_ce_2: 0  loss_mask_2: 0.2128  loss_dice_2: 0.5641  loss_ce_3: 0  loss_mask_3: 0.213  loss_dice_3: 0.5613  loss_ce_4: 0  loss_mask_4: 0.2134  loss_dice_4: 0.5614  loss_ce_5: 0  loss_mask_5: 0.2138  loss_dice_5: 0.5609  loss_ce_6: 0  loss_mask_6: 0.2132  loss_dice_6: 0.5611  loss_ce_7: 0  loss_mask_7: 0.213  loss_dice_7: 0.5618  loss_ce_8: 0  loss_mask_8: 0.2117  loss_dice_8: 0.5643  time: 1.6791  data_time: 0.0633  lr: 9.2167e-05  max_mem: 5916M
[02/24 15:07:11] d2.utils.events INFO:  eta: 1 day, 1:21:23  iter: 5219  total_loss: 8.448  loss_ce: 0  loss_mask: 0.2217  loss_dice: 0.5858  loss_seg: 0.3532  loss_ce_0: 0  loss_mask_0: 0.2239  loss_dice_0: 0.5957  loss_ce_1: 0  loss_mask_1: 0.22  loss_dice_1: 0.5832  loss_ce_2: 0  loss_mask_2: 0.2189  loss_dice_2: 0.5837  loss_ce_3: 0  loss_mask_3: 0.2195  loss_dice_3: 0.5826  loss_ce_4: 0  loss_mask_4: 0.2187  loss_dice_4: 0.5833  loss_ce_5: 0  loss_mask_5: 0.2182  loss_dice_5: 0.5823  loss_ce_6: 0  loss_mask_6: 0.2194  loss_dice_6: 0.5831  loss_ce_7: 0  loss_mask_7: 0.2196  loss_dice_7: 0.5839  loss_ce_8: 0  loss_mask_8: 0.2206  loss_dice_8: 0.5843  time: 1.6790  data_time: 0.0712  lr: 9.2136e-05  max_mem: 5916M
[02/24 15:07:44] d2.utils.events INFO:  eta: 1 day, 1:18:52  iter: 5239  total_loss: 8.032  loss_ce: 0  loss_mask: 0.2172  loss_dice: 0.5575  loss_seg: 0.2873  loss_ce_0: 0  loss_mask_0: 0.2132  loss_dice_0: 0.5701  loss_ce_1: 0  loss_mask_1: 0.2128  loss_dice_1: 0.5554  loss_ce_2: 0  loss_mask_2: 0.2134  loss_dice_2: 0.5539  loss_ce_3: 0  loss_mask_3: 0.2149  loss_dice_3: 0.5525  loss_ce_4: 0  loss_mask_4: 0.2154  loss_dice_4: 0.5521  loss_ce_5: 0  loss_mask_5: 0.2147  loss_dice_5: 0.5515  loss_ce_6: 0  loss_mask_6: 0.2145  loss_dice_6: 0.5524  loss_ce_7: 0  loss_mask_7: 0.2149  loss_dice_7: 0.5522  loss_ce_8: 0  loss_mask_8: 0.2156  loss_dice_8: 0.5546  time: 1.6788  data_time: 0.0622  lr: 9.2106e-05  max_mem: 5916M
[02/24 15:08:16] d2.utils.events INFO:  eta: 1 day, 1:16:37  iter: 5259  total_loss: 8.161  loss_ce: 0  loss_mask: 0.2202  loss_dice: 0.5643  loss_seg: 0.3118  loss_ce_0: 0  loss_mask_0: 0.2205  loss_dice_0: 0.5706  loss_ce_1: 0  loss_mask_1: 0.2191  loss_dice_1: 0.5652  loss_ce_2: 0  loss_mask_2: 0.2193  loss_dice_2: 0.5642  loss_ce_3: 0  loss_mask_3: 0.2184  loss_dice_3: 0.5622  loss_ce_4: 0  loss_mask_4: 0.2204  loss_dice_4: 0.5622  loss_ce_5: 0  loss_mask_5: 0.22  loss_dice_5: 0.561  loss_ce_6: 0  loss_mask_6: 0.2193  loss_dice_6: 0.5615  loss_ce_7: 0  loss_mask_7: 0.2206  loss_dice_7: 0.5612  loss_ce_8: 0  loss_mask_8: 0.2207  loss_dice_8: 0.562  time: 1.6785  data_time: 0.0522  lr: 9.2076e-05  max_mem: 5916M
[02/24 15:08:50] d2.utils.events INFO:  eta: 1 day, 1:18:00  iter: 5279  total_loss: 8.374  loss_ce: 0  loss_mask: 0.2314  loss_dice: 0.5741  loss_seg: 0.321  loss_ce_0: 0  loss_mask_0: 0.2343  loss_dice_0: 0.5842  loss_ce_1: 0  loss_mask_1: 0.2347  loss_dice_1: 0.5724  loss_ce_2: 0  loss_mask_2: 0.2323  loss_dice_2: 0.57  loss_ce_3: 0  loss_mask_3: 0.2326  loss_dice_3: 0.5701  loss_ce_4: 0  loss_mask_4: 0.2332  loss_dice_4: 0.5695  loss_ce_5: 0  loss_mask_5: 0.2333  loss_dice_5: 0.5693  loss_ce_6: 0  loss_mask_6: 0.233  loss_dice_6: 0.5699  loss_ce_7: 0  loss_mask_7: 0.2339  loss_dice_7: 0.5699  loss_ce_8: 0  loss_mask_8: 0.2329  loss_dice_8: 0.5715  time: 1.6785  data_time: 0.0517  lr: 9.2045e-05  max_mem: 5916M
[02/24 15:09:23] d2.utils.events INFO:  eta: 1 day, 1:17:27  iter: 5299  total_loss: 8.03  loss_ce: 0  loss_mask: 0.2126  loss_dice: 0.5691  loss_seg: 0.3314  loss_ce_0: 0  loss_mask_0: 0.2089  loss_dice_0: 0.5767  loss_ce_1: 0  loss_mask_1: 0.2091  loss_dice_1: 0.5677  loss_ce_2: 0  loss_mask_2: 0.2116  loss_dice_2: 0.5657  loss_ce_3: 0  loss_mask_3: 0.2115  loss_dice_3: 0.5627  loss_ce_4: 0  loss_mask_4: 0.2118  loss_dice_4: 0.5629  loss_ce_5: 0  loss_mask_5: 0.2116  loss_dice_5: 0.5632  loss_ce_6: 0  loss_mask_6: 0.2107  loss_dice_6: 0.5635  loss_ce_7: 0  loss_mask_7: 0.2096  loss_dice_7: 0.5646  loss_ce_8: 0  loss_mask_8: 0.2111  loss_dice_8: 0.5648  time: 1.6784  data_time: 0.0512  lr: 9.2015e-05  max_mem: 5916M
[02/24 15:09:56] d2.utils.events INFO:  eta: 1 day, 1:16:03  iter: 5319  total_loss: 8.231  loss_ce: 0  loss_mask: 0.2161  loss_dice: 0.5702  loss_seg: 0.3278  loss_ce_0: 0  loss_mask_0: 0.2161  loss_dice_0: 0.5854  loss_ce_1: 0  loss_mask_1: 0.2141  loss_dice_1: 0.5679  loss_ce_2: 0  loss_mask_2: 0.2153  loss_dice_2: 0.5656  loss_ce_3: 0  loss_mask_3: 0.2163  loss_dice_3: 0.5645  loss_ce_4: 0  loss_mask_4: 0.2166  loss_dice_4: 0.5652  loss_ce_5: 0  loss_mask_5: 0.2166  loss_dice_5: 0.5649  loss_ce_6: 0  loss_mask_6: 0.2162  loss_dice_6: 0.5651  loss_ce_7: 0  loss_mask_7: 0.2154  loss_dice_7: 0.5667  loss_ce_8: 0  loss_mask_8: 0.2146  loss_dice_8: 0.5672  time: 1.6783  data_time: 0.0677  lr: 9.1985e-05  max_mem: 5916M
[02/24 15:10:28] d2.utils.events INFO:  eta: 1 day, 1:14:59  iter: 5339  total_loss: 8.078  loss_ce: 0  loss_mask: 0.2226  loss_dice: 0.5617  loss_seg: 0.2994  loss_ce_0: 0  loss_mask_0: 0.2209  loss_dice_0: 0.5689  loss_ce_1: 0  loss_mask_1: 0.2197  loss_dice_1: 0.56  loss_ce_2: 0  loss_mask_2: 0.2194  loss_dice_2: 0.5579  loss_ce_3: 0  loss_mask_3: 0.2219  loss_dice_3: 0.5572  loss_ce_4: 0  loss_mask_4: 0.2226  loss_dice_4: 0.558  loss_ce_5: 0  loss_mask_5: 0.2225  loss_dice_5: 0.5577  loss_ce_6: 0  loss_mask_6: 0.2238  loss_dice_6: 0.5572  loss_ce_7: 0  loss_mask_7: 0.2238  loss_dice_7: 0.5584  loss_ce_8: 0  loss_mask_8: 0.2243  loss_dice_8: 0.5578  time: 1.6781  data_time: 0.0557  lr: 9.1955e-05  max_mem: 5916M
[02/24 15:11:02] d2.utils.events INFO:  eta: 1 day, 1:15:21  iter: 5359  total_loss: 8.068  loss_ce: 0  loss_mask: 0.2209  loss_dice: 0.5499  loss_seg: 0.291  loss_ce_0: 0  loss_mask_0: 0.2168  loss_dice_0: 0.5675  loss_ce_1: 0  loss_mask_1: 0.2153  loss_dice_1: 0.5482  loss_ce_2: 0  loss_mask_2: 0.2164  loss_dice_2: 0.5457  loss_ce_3: 0  loss_mask_3: 0.2167  loss_dice_3: 0.5465  loss_ce_4: 0  loss_mask_4: 0.2152  loss_dice_4: 0.5455  loss_ce_5: 0  loss_mask_5: 0.2154  loss_dice_5: 0.5459  loss_ce_6: 0  loss_mask_6: 0.2166  loss_dice_6: 0.5452  loss_ce_7: 0  loss_mask_7: 0.2176  loss_dice_7: 0.5453  loss_ce_8: 0  loss_mask_8: 0.2179  loss_dice_8: 0.5474  time: 1.6782  data_time: 0.0562  lr: 9.1924e-05  max_mem: 5916M
[02/24 15:11:36] d2.utils.events INFO:  eta: 1 day, 1:12:13  iter: 5379  total_loss: 8.197  loss_ce: 0  loss_mask: 0.2181  loss_dice: 0.5682  loss_seg: 0.3176  loss_ce_0: 0  loss_mask_0: 0.2189  loss_dice_0: 0.5877  loss_ce_1: 0  loss_mask_1: 0.2175  loss_dice_1: 0.5652  loss_ce_2: 0  loss_mask_2: 0.2182  loss_dice_2: 0.5634  loss_ce_3: 0  loss_mask_3: 0.2179  loss_dice_3: 0.5616  loss_ce_4: 0  loss_mask_4: 0.2183  loss_dice_4: 0.561  loss_ce_5: 0  loss_mask_5: 0.2184  loss_dice_5: 0.5606  loss_ce_6: 0  loss_mask_6: 0.218  loss_dice_6: 0.5609  loss_ce_7: 0  loss_mask_7: 0.2176  loss_dice_7: 0.5623  loss_ce_8: 0  loss_mask_8: 0.2165  loss_dice_8: 0.5625  time: 1.6782  data_time: 0.0551  lr: 9.1894e-05  max_mem: 5916M
[02/24 15:12:10] d2.utils.events INFO:  eta: 1 day, 1:14:15  iter: 5399  total_loss: 7.903  loss_ce: 0  loss_mask: 0.2105  loss_dice: 0.5583  loss_seg: 0.2895  loss_ce_0: 0  loss_mask_0: 0.2111  loss_dice_0: 0.5722  loss_ce_1: 0  loss_mask_1: 0.2115  loss_dice_1: 0.5555  loss_ce_2: 0  loss_mask_2: 0.2117  loss_dice_2: 0.5531  loss_ce_3: 0  loss_mask_3: 0.2119  loss_dice_3: 0.5509  loss_ce_4: 0  loss_mask_4: 0.2115  loss_dice_4: 0.5508  loss_ce_5: 0  loss_mask_5: 0.2123  loss_dice_5: 0.5508  loss_ce_6: 0  loss_mask_6: 0.211  loss_dice_6: 0.553  loss_ce_7: 0  loss_mask_7: 0.2106  loss_dice_7: 0.5528  loss_ce_8: 0  loss_mask_8: 0.2115  loss_dice_8: 0.5533  time: 1.6781  data_time: 0.0466  lr: 9.1864e-05  max_mem: 5916M
[02/24 15:12:42] d2.utils.events INFO:  eta: 1 day, 1:14:07  iter: 5419  total_loss: 8.09  loss_ce: 0  loss_mask: 0.221  loss_dice: 0.5633  loss_seg: 0.3032  loss_ce_0: 0  loss_mask_0: 0.2232  loss_dice_0: 0.5761  loss_ce_1: 0  loss_mask_1: 0.2219  loss_dice_1: 0.5613  loss_ce_2: 0  loss_mask_2: 0.221  loss_dice_2: 0.5598  loss_ce_3: 0  loss_mask_3: 0.2207  loss_dice_3: 0.5588  loss_ce_4: 0  loss_mask_4: 0.2192  loss_dice_4: 0.5583  loss_ce_5: 0  loss_mask_5: 0.2206  loss_dice_5: 0.5587  loss_ce_6: 0  loss_mask_6: 0.2201  loss_dice_6: 0.5586  loss_ce_7: 0  loss_mask_7: 0.2202  loss_dice_7: 0.5593  loss_ce_8: 0  loss_mask_8: 0.2211  loss_dice_8: 0.5586  time: 1.6780  data_time: 0.0672  lr: 9.1834e-05  max_mem: 5916M
[02/24 15:13:15] d2.utils.events INFO:  eta: 1 day, 1:13:03  iter: 5439  total_loss: 8.033  loss_ce: 0  loss_mask: 0.2239  loss_dice: 0.5593  loss_seg: 0.3161  loss_ce_0: 0  loss_mask_0: 0.219  loss_dice_0: 0.5729  loss_ce_1: 0  loss_mask_1: 0.2213  loss_dice_1: 0.56  loss_ce_2: 0  loss_mask_2: 0.2224  loss_dice_2: 0.5579  loss_ce_3: 0  loss_mask_3: 0.222  loss_dice_3: 0.5534  loss_ce_4: 0  loss_mask_4: 0.2218  loss_dice_4: 0.5592  loss_ce_5: 0  loss_mask_5: 0.2214  loss_dice_5: 0.5574  loss_ce_6: 0  loss_mask_6: 0.2226  loss_dice_6: 0.5567  loss_ce_7: 0  loss_mask_7: 0.2236  loss_dice_7: 0.5574  loss_ce_8: 0  loss_mask_8: 0.2247  loss_dice_8: 0.5563  time: 1.6778  data_time: 0.0509  lr: 9.1803e-05  max_mem: 5916M
[02/24 15:13:50] d2.utils.events INFO:  eta: 1 day, 1:13:01  iter: 5459  total_loss: 7.724  loss_ce: 0  loss_mask: 0.2176  loss_dice: 0.5392  loss_seg: 0.2629  loss_ce_0: 0  loss_mask_0: 0.2138  loss_dice_0: 0.5521  loss_ce_1: 0  loss_mask_1: 0.2142  loss_dice_1: 0.5366  loss_ce_2: 0  loss_mask_2: 0.2158  loss_dice_2: 0.5345  loss_ce_3: 0  loss_mask_3: 0.2172  loss_dice_3: 0.533  loss_ce_4: 0  loss_mask_4: 0.2178  loss_dice_4: 0.5338  loss_ce_5: 0  loss_mask_5: 0.2182  loss_dice_5: 0.5353  loss_ce_6: 0  loss_mask_6: 0.2179  loss_dice_6: 0.5355  loss_ce_7: 0  loss_mask_7: 0.217  loss_dice_7: 0.537  loss_ce_8: 0  loss_mask_8: 0.2171  loss_dice_8: 0.5364  time: 1.6780  data_time: 0.0577  lr: 9.1773e-05  max_mem: 5916M
[02/24 15:14:24] d2.utils.events INFO:  eta: 1 day, 1:12:59  iter: 5479  total_loss: 7.688  loss_ce: 0  loss_mask: 0.2071  loss_dice: 0.5394  loss_seg: 0.2959  loss_ce_0: 0  loss_mask_0: 0.2082  loss_dice_0: 0.5604  loss_ce_1: 0  loss_mask_1: 0.2062  loss_dice_1: 0.5343  loss_ce_2: 0  loss_mask_2: 0.2069  loss_dice_2: 0.5327  loss_ce_3: 0  loss_mask_3: 0.2057  loss_dice_3: 0.5312  loss_ce_4: 0  loss_mask_4: 0.206  loss_dice_4: 0.5325  loss_ce_5: 0  loss_mask_5: 0.2061  loss_dice_5: 0.5325  loss_ce_6: 0  loss_mask_6: 0.2058  loss_dice_6: 0.5333  loss_ce_7: 0  loss_mask_7: 0.2067  loss_dice_7: 0.5334  loss_ce_8: 0  loss_mask_8: 0.2073  loss_dice_8: 0.5343  time: 1.6781  data_time: 0.0606  lr: 9.1743e-05  max_mem: 5916M
[02/24 15:14:58] d2.utils.events INFO:  eta: 1 day, 1:13:00  iter: 5499  total_loss: 8.069  loss_ce: 0  loss_mask: 0.2223  loss_dice: 0.5619  loss_seg: 0.3115  loss_ce_0: 0  loss_mask_0: 0.2218  loss_dice_0: 0.5735  loss_ce_1: 0  loss_mask_1: 0.2225  loss_dice_1: 0.5571  loss_ce_2: 0  loss_mask_2: 0.2217  loss_dice_2: 0.5556  loss_ce_3: 0  loss_mask_3: 0.2216  loss_dice_3: 0.5548  loss_ce_4: 0  loss_mask_4: 0.2224  loss_dice_4: 0.5548  loss_ce_5: 0  loss_mask_5: 0.2237  loss_dice_5: 0.5552  loss_ce_6: 0  loss_mask_6: 0.2243  loss_dice_6: 0.5558  loss_ce_7: 0  loss_mask_7: 0.2238  loss_dice_7: 0.5562  loss_ce_8: 0  loss_mask_8: 0.2239  loss_dice_8: 0.5572  time: 1.6781  data_time: 0.0688  lr: 9.1712e-05  max_mem: 5916M
[02/24 15:15:32] d2.utils.events INFO:  eta: 1 day, 1:11:52  iter: 5519  total_loss: 8.133  loss_ce: 0  loss_mask: 0.2145  loss_dice: 0.5562  loss_seg: 0.3175  loss_ce_0: 0  loss_mask_0: 0.2112  loss_dice_0: 0.5751  loss_ce_1: 0  loss_mask_1: 0.2105  loss_dice_1: 0.5529  loss_ce_2: 0  loss_mask_2: 0.2116  loss_dice_2: 0.5515  loss_ce_3: 0  loss_mask_3: 0.21  loss_dice_3: 0.5515  loss_ce_4: 0  loss_mask_4: 0.2128  loss_dice_4: 0.5515  loss_ce_5: 0  loss_mask_5: 0.211  loss_dice_5: 0.5539  loss_ce_6: 0  loss_mask_6: 0.2114  loss_dice_6: 0.5536  loss_ce_7: 0  loss_mask_7: 0.2138  loss_dice_7: 0.5539  loss_ce_8: 0  loss_mask_8: 0.2132  loss_dice_8: 0.5533  time: 1.6782  data_time: 0.0693  lr: 9.1682e-05  max_mem: 5916M
[02/24 15:16:05] d2.utils.events INFO:  eta: 1 day, 1:10:48  iter: 5539  total_loss: 8.332  loss_ce: 0  loss_mask: 0.2206  loss_dice: 0.5795  loss_seg: 0.3196  loss_ce_0: 0  loss_mask_0: 0.214  loss_dice_0: 0.5922  loss_ce_1: 0  loss_mask_1: 0.2159  loss_dice_1: 0.5794  loss_ce_2: 0  loss_mask_2: 0.2163  loss_dice_2: 0.5756  loss_ce_3: 0  loss_mask_3: 0.2177  loss_dice_3: 0.5738  loss_ce_4: 0  loss_mask_4: 0.219  loss_dice_4: 0.5727  loss_ce_5: 0  loss_mask_5: 0.2178  loss_dice_5: 0.5726  loss_ce_6: 0  loss_mask_6: 0.2173  loss_dice_6: 0.5743  loss_ce_7: 0  loss_mask_7: 0.2172  loss_dice_7: 0.5744  loss_ce_8: 0  loss_mask_8: 0.2175  loss_dice_8: 0.5743  time: 1.6781  data_time: 0.0637  lr: 9.1652e-05  max_mem: 5916M
[02/24 15:16:40] d2.utils.events INFO:  eta: 1 day, 1:09:23  iter: 5559  total_loss: 7.978  loss_ce: 0  loss_mask: 0.218  loss_dice: 0.5561  loss_seg: 0.2913  loss_ce_0: 0  loss_mask_0: 0.2157  loss_dice_0: 0.5692  loss_ce_1: 0  loss_mask_1: 0.2172  loss_dice_1: 0.5515  loss_ce_2: 0  loss_mask_2: 0.2185  loss_dice_2: 0.5509  loss_ce_3: 0  loss_mask_3: 0.2192  loss_dice_3: 0.5511  loss_ce_4: 0  loss_mask_4: 0.2183  loss_dice_4: 0.5512  loss_ce_5: 0  loss_mask_5: 0.2176  loss_dice_5: 0.5512  loss_ce_6: 0  loss_mask_6: 0.218  loss_dice_6: 0.5521  loss_ce_7: 0  loss_mask_7: 0.2183  loss_dice_7: 0.5534  loss_ce_8: 0  loss_mask_8: 0.2172  loss_dice_8: 0.5524  time: 1.6782  data_time: 0.0674  lr: 9.1621e-05  max_mem: 5916M
[02/24 15:17:14] d2.utils.events INFO:  eta: 1 day, 1:09:10  iter: 5579  total_loss: 8.189  loss_ce: 0  loss_mask: 0.2141  loss_dice: 0.5781  loss_seg: 0.3206  loss_ce_0: 0  loss_mask_0: 0.2163  loss_dice_0: 0.577  loss_ce_1: 0  loss_mask_1: 0.2119  loss_dice_1: 0.5751  loss_ce_2: 0  loss_mask_2: 0.2109  loss_dice_2: 0.5746  loss_ce_3: 0  loss_mask_3: 0.2131  loss_dice_3: 0.5722  loss_ce_4: 0  loss_mask_4: 0.2132  loss_dice_4: 0.5724  loss_ce_5: 0  loss_mask_5: 0.2128  loss_dice_5: 0.5719  loss_ce_6: 0  loss_mask_6: 0.2122  loss_dice_6: 0.5717  loss_ce_7: 0  loss_mask_7: 0.2122  loss_dice_7: 0.5732  loss_ce_8: 0  loss_mask_8: 0.2136  loss_dice_8: 0.5734  time: 1.6783  data_time: 0.0564  lr: 9.1591e-05  max_mem: 5916M
[02/24 15:17:48] d2.utils.events INFO:  eta: 1 day, 1:10:50  iter: 5599  total_loss: 8.174  loss_ce: 0  loss_mask: 0.2194  loss_dice: 0.5649  loss_seg: 0.2915  loss_ce_0: 0  loss_mask_0: 0.2146  loss_dice_0: 0.5728  loss_ce_1: 0  loss_mask_1: 0.2146  loss_dice_1: 0.5638  loss_ce_2: 0  loss_mask_2: 0.218  loss_dice_2: 0.5627  loss_ce_3: 0  loss_mask_3: 0.2178  loss_dice_3: 0.5609  loss_ce_4: 0  loss_mask_4: 0.2194  loss_dice_4: 0.5616  loss_ce_5: 0  loss_mask_5: 0.2184  loss_dice_5: 0.5614  loss_ce_6: 0  loss_mask_6: 0.2184  loss_dice_6: 0.5591  loss_ce_7: 0  loss_mask_7: 0.219  loss_dice_7: 0.56  loss_ce_8: 0  loss_mask_8: 0.2195  loss_dice_8: 0.5606  time: 1.6783  data_time: 0.0508  lr: 9.1561e-05  max_mem: 5916M
[02/24 15:18:21] d2.utils.events INFO:  eta: 1 day, 1:11:29  iter: 5619  total_loss: 8.167  loss_ce: 0  loss_mask: 0.2182  loss_dice: 0.5704  loss_seg: 0.3138  loss_ce_0: 0  loss_mask_0: 0.2176  loss_dice_0: 0.5743  loss_ce_1: 0  loss_mask_1: 0.2187  loss_dice_1: 0.5682  loss_ce_2: 0  loss_mask_2: 0.22  loss_dice_2: 0.5662  loss_ce_3: 0  loss_mask_3: 0.2216  loss_dice_3: 0.564  loss_ce_4: 0  loss_mask_4: 0.2205  loss_dice_4: 0.565  loss_ce_5: 0  loss_mask_5: 0.2202  loss_dice_5: 0.5656  loss_ce_6: 0  loss_mask_6: 0.2214  loss_dice_6: 0.5658  loss_ce_7: 0  loss_mask_7: 0.22  loss_dice_7: 0.566  loss_ce_8: 0  loss_mask_8: 0.22  loss_dice_8: 0.5674  time: 1.6783  data_time: 0.0586  lr: 9.1531e-05  max_mem: 5916M
[02/24 15:18:55] d2.utils.events INFO:  eta: 1 day, 1:11:42  iter: 5639  total_loss: 8.002  loss_ce: 0  loss_mask: 0.2218  loss_dice: 0.5461  loss_seg: 0.2898  loss_ce_0: 0  loss_mask_0: 0.2178  loss_dice_0: 0.558  loss_ce_1: 0  loss_mask_1: 0.2213  loss_dice_1: 0.5446  loss_ce_2: 0  loss_mask_2: 0.2223  loss_dice_2: 0.5437  loss_ce_3: 0  loss_mask_3: 0.2219  loss_dice_3: 0.5421  loss_ce_4: 0  loss_mask_4: 0.2225  loss_dice_4: 0.5424  loss_ce_5: 0  loss_mask_5: 0.2235  loss_dice_5: 0.5427  loss_ce_6: 0  loss_mask_6: 0.2222  loss_dice_6: 0.5417  loss_ce_7: 0  loss_mask_7: 0.2222  loss_dice_7: 0.5438  loss_ce_8: 0  loss_mask_8: 0.2222  loss_dice_8: 0.5428  time: 1.6782  data_time: 0.0525  lr: 9.15e-05  max_mem: 5916M
[02/24 15:19:29] d2.utils.events INFO:  eta: 1 day, 1:12:45  iter: 5659  total_loss: 7.867  loss_ce: 0  loss_mask: 0.2154  loss_dice: 0.5405  loss_seg: 0.3364  loss_ce_0: 0  loss_mask_0: 0.2117  loss_dice_0: 0.5602  loss_ce_1: 0  loss_mask_1: 0.213  loss_dice_1: 0.5408  loss_ce_2: 0  loss_mask_2: 0.2147  loss_dice_2: 0.5375  loss_ce_3: 0  loss_mask_3: 0.2135  loss_dice_3: 0.5375  loss_ce_4: 0  loss_mask_4: 0.2147  loss_dice_4: 0.5377  loss_ce_5: 0  loss_mask_5: 0.2139  loss_dice_5: 0.538  loss_ce_6: 0  loss_mask_6: 0.2138  loss_dice_6: 0.5379  loss_ce_7: 0  loss_mask_7: 0.2143  loss_dice_7: 0.537  loss_ce_8: 0  loss_mask_8: 0.2146  loss_dice_8: 0.5373  time: 1.6784  data_time: 0.0585  lr: 9.147e-05  max_mem: 5916M
[02/24 15:20:02] d2.utils.events INFO:  eta: 1 day, 1:09:01  iter: 5679  total_loss: 7.941  loss_ce: 0  loss_mask: 0.2126  loss_dice: 0.5585  loss_seg: 0.306  loss_ce_0: 0  loss_mask_0: 0.2112  loss_dice_0: 0.5712  loss_ce_1: 0  loss_mask_1: 0.211  loss_dice_1: 0.5571  loss_ce_2: 0  loss_mask_2: 0.211  loss_dice_2: 0.5555  loss_ce_3: 0  loss_mask_3: 0.2107  loss_dice_3: 0.554  loss_ce_4: 0  loss_mask_4: 0.2113  loss_dice_4: 0.5541  loss_ce_5: 0  loss_mask_5: 0.2114  loss_dice_5: 0.5548  loss_ce_6: 0  loss_mask_6: 0.2126  loss_dice_6: 0.5542  loss_ce_7: 0  loss_mask_7: 0.2122  loss_dice_7: 0.5546  loss_ce_8: 0  loss_mask_8: 0.2118  loss_dice_8: 0.5545  time: 1.6782  data_time: 0.0608  lr: 9.144e-05  max_mem: 5916M
[02/24 15:20:37] d2.utils.events INFO:  eta: 1 day, 1:08:04  iter: 5699  total_loss: 8.165  loss_ce: 0  loss_mask: 0.2285  loss_dice: 0.563  loss_seg: 0.3129  loss_ce_0: 0  loss_mask_0: 0.2299  loss_dice_0: 0.5778  loss_ce_1: 0  loss_mask_1: 0.2285  loss_dice_1: 0.5636  loss_ce_2: 0  loss_mask_2: 0.2275  loss_dice_2: 0.5627  loss_ce_3: 0  loss_mask_3: 0.2271  loss_dice_3: 0.5604  loss_ce_4: 0  loss_mask_4: 0.2269  loss_dice_4: 0.5605  loss_ce_5: 0  loss_mask_5: 0.227  loss_dice_5: 0.5615  loss_ce_6: 0  loss_mask_6: 0.2281  loss_dice_6: 0.5613  loss_ce_7: 0  loss_mask_7: 0.2281  loss_dice_7: 0.5615  loss_ce_8: 0  loss_mask_8: 0.2277  loss_dice_8: 0.5623  time: 1.6784  data_time: 0.0493  lr: 9.1409e-05  max_mem: 5916M
[02/24 15:21:10] d2.utils.events INFO:  eta: 1 day, 1:05:48  iter: 5719  total_loss: 8.163  loss_ce: 0  loss_mask: 0.2181  loss_dice: 0.5523  loss_seg: 0.3438  loss_ce_0: 0  loss_mask_0: 0.2153  loss_dice_0: 0.5633  loss_ce_1: 0  loss_mask_1: 0.215  loss_dice_1: 0.5535  loss_ce_2: 0  loss_mask_2: 0.2157  loss_dice_2: 0.5504  loss_ce_3: 0  loss_mask_3: 0.2163  loss_dice_3: 0.5486  loss_ce_4: 0  loss_mask_4: 0.2171  loss_dice_4: 0.5474  loss_ce_5: 0  loss_mask_5: 0.2167  loss_dice_5: 0.547  loss_ce_6: 0  loss_mask_6: 0.2179  loss_dice_6: 0.547  loss_ce_7: 0  loss_mask_7: 0.2173  loss_dice_7: 0.5469  loss_ce_8: 0  loss_mask_8: 0.2178  loss_dice_8: 0.547  time: 1.6783  data_time: 0.0562  lr: 9.1379e-05  max_mem: 5916M
[02/24 15:21:44] d2.utils.events INFO:  eta: 1 day, 1:05:43  iter: 5739  total_loss: 8.03  loss_ce: 0  loss_mask: 0.2052  loss_dice: 0.5652  loss_seg: 0.3247  loss_ce_0: 0  loss_mask_0: 0.2028  loss_dice_0: 0.587  loss_ce_1: 0  loss_mask_1: 0.2004  loss_dice_1: 0.567  loss_ce_2: 0  loss_mask_2: 0.2008  loss_dice_2: 0.564  loss_ce_3: 0  loss_mask_3: 0.2027  loss_dice_3: 0.5614  loss_ce_4: 0  loss_mask_4: 0.2037  loss_dice_4: 0.5613  loss_ce_5: 0  loss_mask_5: 0.2047  loss_dice_5: 0.5613  loss_ce_6: 0  loss_mask_6: 0.2049  loss_dice_6: 0.5617  loss_ce_7: 0  loss_mask_7: 0.2048  loss_dice_7: 0.5628  loss_ce_8: 0  loss_mask_8: 0.205  loss_dice_8: 0.5607  time: 1.6784  data_time: 0.0540  lr: 9.1349e-05  max_mem: 5916M
[02/24 15:22:18] d2.utils.events INFO:  eta: 1 day, 1:04:41  iter: 5759  total_loss: 7.771  loss_ce: 0  loss_mask: 0.2132  loss_dice: 0.5402  loss_seg: 0.3089  loss_ce_0: 0  loss_mask_0: 0.2103  loss_dice_0: 0.5532  loss_ce_1: 0  loss_mask_1: 0.2142  loss_dice_1: 0.538  loss_ce_2: 0  loss_mask_2: 0.2148  loss_dice_2: 0.5344  loss_ce_3: 0  loss_mask_3: 0.2147  loss_dice_3: 0.5341  loss_ce_4: 0  loss_mask_4: 0.2136  loss_dice_4: 0.534  loss_ce_5: 0  loss_mask_5: 0.213  loss_dice_5: 0.5338  loss_ce_6: 0  loss_mask_6: 0.213  loss_dice_6: 0.5346  loss_ce_7: 0  loss_mask_7: 0.2132  loss_dice_7: 0.5354  loss_ce_8: 0  loss_mask_8: 0.2124  loss_dice_8: 0.5355  time: 1.6784  data_time: 0.0599  lr: 9.1319e-05  max_mem: 5916M
[02/24 15:22:51] d2.utils.events INFO:  eta: 1 day, 1:03:57  iter: 5779  total_loss: 8.034  loss_ce: 0  loss_mask: 0.2157  loss_dice: 0.5508  loss_seg: 0.3044  loss_ce_0: 0  loss_mask_0: 0.2083  loss_dice_0: 0.561  loss_ce_1: 0  loss_mask_1: 0.2148  loss_dice_1: 0.5523  loss_ce_2: 0  loss_mask_2: 0.2156  loss_dice_2: 0.5483  loss_ce_3: 0  loss_mask_3: 0.216  loss_dice_3: 0.5466  loss_ce_4: 0  loss_mask_4: 0.2148  loss_dice_4: 0.5474  loss_ce_5: 0  loss_mask_5: 0.2159  loss_dice_5: 0.5462  loss_ce_6: 0  loss_mask_6: 0.2165  loss_dice_6: 0.5468  loss_ce_7: 0  loss_mask_7: 0.2169  loss_dice_7: 0.5462  loss_ce_8: 0  loss_mask_8: 0.2181  loss_dice_8: 0.5471  time: 1.6783  data_time: 0.0689  lr: 9.1288e-05  max_mem: 5916M
[02/24 15:23:26] d2.utils.events INFO:  eta: 1 day, 1:02:38  iter: 5799  total_loss: 8.275  loss_ce: 0  loss_mask: 0.2173  loss_dice: 0.5864  loss_seg: 0.3333  loss_ce_0: 0  loss_mask_0: 0.219  loss_dice_0: 0.5972  loss_ce_1: 0  loss_mask_1: 0.2147  loss_dice_1: 0.5893  loss_ce_2: 0  loss_mask_2: 0.215  loss_dice_2: 0.5908  loss_ce_3: 0  loss_mask_3: 0.2146  loss_dice_3: 0.5882  loss_ce_4: 0  loss_mask_4: 0.2139  loss_dice_4: 0.5884  loss_ce_5: 0  loss_mask_5: 0.2153  loss_dice_5: 0.5886  loss_ce_6: 0  loss_mask_6: 0.2156  loss_dice_6: 0.5875  loss_ce_7: 0  loss_mask_7: 0.2148  loss_dice_7: 0.5876  loss_ce_8: 0  loss_mask_8: 0.2158  loss_dice_8: 0.5884  time: 1.6784  data_time: 0.0650  lr: 9.1258e-05  max_mem: 5916M
[02/24 15:23:59] d2.utils.events INFO:  eta: 1 day, 1:00:05  iter: 5819  total_loss: 8.086  loss_ce: 0  loss_mask: 0.2184  loss_dice: 0.5597  loss_seg: 0.2927  loss_ce_0: 0  loss_mask_0: 0.215  loss_dice_0: 0.571  loss_ce_1: 0  loss_mask_1: 0.2175  loss_dice_1: 0.5561  loss_ce_2: 0  loss_mask_2: 0.2189  loss_dice_2: 0.5545  loss_ce_3: 0  loss_mask_3: 0.2185  loss_dice_3: 0.5546  loss_ce_4: 0  loss_mask_4: 0.2187  loss_dice_4: 0.5542  loss_ce_5: 0  loss_mask_5: 0.2181  loss_dice_5: 0.5557  loss_ce_6: 0  loss_mask_6: 0.2184  loss_dice_6: 0.5549  loss_ce_7: 0  loss_mask_7: 0.2184  loss_dice_7: 0.5543  loss_ce_8: 0  loss_mask_8: 0.2176  loss_dice_8: 0.556  time: 1.6784  data_time: 0.0605  lr: 9.1228e-05  max_mem: 5916M
[02/24 15:24:34] d2.utils.events INFO:  eta: 1 day, 1:02:28  iter: 5839  total_loss: 8.242  loss_ce: 0  loss_mask: 0.2165  loss_dice: 0.5695  loss_seg: 0.296  loss_ce_0: 0  loss_mask_0: 0.2197  loss_dice_0: 0.5822  loss_ce_1: 0  loss_mask_1: 0.217  loss_dice_1: 0.5681  loss_ce_2: 0  loss_mask_2: 0.217  loss_dice_2: 0.5655  loss_ce_3: 0  loss_mask_3: 0.2167  loss_dice_3: 0.5648  loss_ce_4: 0  loss_mask_4: 0.2161  loss_dice_4: 0.5657  loss_ce_5: 0  loss_mask_5: 0.2157  loss_dice_5: 0.565  loss_ce_6: 0  loss_mask_6: 0.2178  loss_dice_6: 0.5649  loss_ce_7: 0  loss_mask_7: 0.2188  loss_dice_7: 0.5643  loss_ce_8: 0  loss_mask_8: 0.2169  loss_dice_8: 0.5667  time: 1.6785  data_time: 0.0540  lr: 9.1197e-05  max_mem: 5916M
[02/24 15:25:08] d2.utils.events INFO:  eta: 1 day, 1:01:44  iter: 5859  total_loss: 8.141  loss_ce: 0  loss_mask: 0.2175  loss_dice: 0.5609  loss_seg: 0.2999  loss_ce_0: 0  loss_mask_0: 0.2121  loss_dice_0: 0.5704  loss_ce_1: 0  loss_mask_1: 0.2156  loss_dice_1: 0.5612  loss_ce_2: 0  loss_mask_2: 0.2156  loss_dice_2: 0.5592  loss_ce_3: 0  loss_mask_3: 0.2169  loss_dice_3: 0.5589  loss_ce_4: 0  loss_mask_4: 0.2159  loss_dice_4: 0.5565  loss_ce_5: 0  loss_mask_5: 0.2171  loss_dice_5: 0.5554  loss_ce_6: 0  loss_mask_6: 0.2167  loss_dice_6: 0.5551  loss_ce_7: 0  loss_mask_7: 0.2169  loss_dice_7: 0.5567  loss_ce_8: 0  loss_mask_8: 0.218  loss_dice_8: 0.5571  time: 1.6787  data_time: 0.0639  lr: 9.1167e-05  max_mem: 5916M
[02/24 15:25:43] d2.utils.events INFO:  eta: 1 day, 1:04:09  iter: 5879  total_loss: 8.214  loss_ce: 0  loss_mask: 0.2186  loss_dice: 0.5751  loss_seg: 0.3362  loss_ce_0: 0  loss_mask_0: 0.2182  loss_dice_0: 0.5841  loss_ce_1: 0  loss_mask_1: 0.2181  loss_dice_1: 0.5743  loss_ce_2: 0  loss_mask_2: 0.2199  loss_dice_2: 0.5715  loss_ce_3: 0  loss_mask_3: 0.2207  loss_dice_3: 0.5708  loss_ce_4: 0  loss_mask_4: 0.2205  loss_dice_4: 0.5701  loss_ce_5: 0  loss_mask_5: 0.2207  loss_dice_5: 0.5703  loss_ce_6: 0  loss_mask_6: 0.2206  loss_dice_6: 0.5702  loss_ce_7: 0  loss_mask_7: 0.2205  loss_dice_7: 0.5719  loss_ce_8: 0  loss_mask_8: 0.2206  loss_dice_8: 0.5709  time: 1.6788  data_time: 0.0682  lr: 9.1137e-05  max_mem: 5916M
[02/24 15:26:17] d2.utils.events INFO:  eta: 1 day, 1:05:09  iter: 5899  total_loss: 8.169  loss_ce: 0  loss_mask: 0.2192  loss_dice: 0.5614  loss_seg: 0.2999  loss_ce_0: 0  loss_mask_0: 0.2153  loss_dice_0: 0.5703  loss_ce_1: 0  loss_mask_1: 0.2164  loss_dice_1: 0.5602  loss_ce_2: 0  loss_mask_2: 0.2169  loss_dice_2: 0.5585  loss_ce_3: 0  loss_mask_3: 0.2166  loss_dice_3: 0.5566  loss_ce_4: 0  loss_mask_4: 0.2171  loss_dice_4: 0.5578  loss_ce_5: 0  loss_mask_5: 0.2174  loss_dice_5: 0.5582  loss_ce_6: 0  loss_mask_6: 0.2172  loss_dice_6: 0.5572  loss_ce_7: 0  loss_mask_7: 0.2158  loss_dice_7: 0.5581  loss_ce_8: 0  loss_mask_8: 0.2178  loss_dice_8: 0.5579  time: 1.6789  data_time: 0.0670  lr: 9.1106e-05  max_mem: 5916M
[02/24 15:26:52] d2.utils.events INFO:  eta: 1 day, 1:06:03  iter: 5919  total_loss: 7.962  loss_ce: 0  loss_mask: 0.2198  loss_dice: 0.5441  loss_seg: 0.303  loss_ce_0: 0  loss_mask_0: 0.212  loss_dice_0: 0.5538  loss_ce_1: 0  loss_mask_1: 0.2173  loss_dice_1: 0.5444  loss_ce_2: 0  loss_mask_2: 0.2194  loss_dice_2: 0.5451  loss_ce_3: 0  loss_mask_3: 0.2193  loss_dice_3: 0.5445  loss_ce_4: 0  loss_mask_4: 0.22  loss_dice_4: 0.5434  loss_ce_5: 0  loss_mask_5: 0.2203  loss_dice_5: 0.5432  loss_ce_6: 0  loss_mask_6: 0.2199  loss_dice_6: 0.5448  loss_ce_7: 0  loss_mask_7: 0.2199  loss_dice_7: 0.5447  loss_ce_8: 0  loss_mask_8: 0.2197  loss_dice_8: 0.5457  time: 1.6792  data_time: 0.0516  lr: 9.1076e-05  max_mem: 5916M
[02/24 15:27:27] d2.utils.events INFO:  eta: 1 day, 1:05:54  iter: 5939  total_loss: 8.18  loss_ce: 0  loss_mask: 0.2219  loss_dice: 0.572  loss_seg: 0.3129  loss_ce_0: 0  loss_mask_0: 0.2201  loss_dice_0: 0.5816  loss_ce_1: 0  loss_mask_1: 0.2232  loss_dice_1: 0.5714  loss_ce_2: 0  loss_mask_2: 0.2231  loss_dice_2: 0.5695  loss_ce_3: 0  loss_mask_3: 0.2218  loss_dice_3: 0.5663  loss_ce_4: 0  loss_mask_4: 0.2222  loss_dice_4: 0.5676  loss_ce_5: 0  loss_mask_5: 0.2214  loss_dice_5: 0.5676  loss_ce_6: 0  loss_mask_6: 0.2224  loss_dice_6: 0.5674  loss_ce_7: 0  loss_mask_7: 0.2224  loss_dice_7: 0.5673  loss_ce_8: 0  loss_mask_8: 0.2232  loss_dice_8: 0.5675  time: 1.6793  data_time: 0.0512  lr: 9.1046e-05  max_mem: 5916M
[02/24 15:28:00] d2.utils.events INFO:  eta: 1 day, 1:01:57  iter: 5959  total_loss: 8.169  loss_ce: 0  loss_mask: 0.2197  loss_dice: 0.5677  loss_seg: 0.319  loss_ce_0: 0  loss_mask_0: 0.2157  loss_dice_0: 0.5761  loss_ce_1: 0  loss_mask_1: 0.2197  loss_dice_1: 0.5644  loss_ce_2: 0  loss_mask_2: 0.219  loss_dice_2: 0.5663  loss_ce_3: 0  loss_mask_3: 0.2186  loss_dice_3: 0.5665  loss_ce_4: 0  loss_mask_4: 0.2198  loss_dice_4: 0.5671  loss_ce_5: 0  loss_mask_5: 0.2197  loss_dice_5: 0.5674  loss_ce_6: 0  loss_mask_6: 0.2192  loss_dice_6: 0.5658  loss_ce_7: 0  loss_mask_7: 0.2196  loss_dice_7: 0.5666  loss_ce_8: 0  loss_mask_8: 0.2188  loss_dice_8: 0.5673  time: 1.6792  data_time: 0.0566  lr: 9.1015e-05  max_mem: 5916M
[02/24 15:28:34] d2.utils.events INFO:  eta: 1 day, 1:03:28  iter: 5979  total_loss: 8.069  loss_ce: 0  loss_mask: 0.2099  loss_dice: 0.5652  loss_seg: 0.3487  loss_ce_0: 0  loss_mask_0: 0.2091  loss_dice_0: 0.5763  loss_ce_1: 0  loss_mask_1: 0.209  loss_dice_1: 0.5651  loss_ce_2: 0  loss_mask_2: 0.2086  loss_dice_2: 0.5631  loss_ce_3: 0  loss_mask_3: 0.2092  loss_dice_3: 0.5597  loss_ce_4: 0  loss_mask_4: 0.2092  loss_dice_4: 0.5602  loss_ce_5: 0  loss_mask_5: 0.2097  loss_dice_5: 0.5604  loss_ce_6: 0  loss_mask_6: 0.2094  loss_dice_6: 0.5578  loss_ce_7: 0  loss_mask_7: 0.2103  loss_dice_7: 0.5593  loss_ce_8: 0  loss_mask_8: 0.2103  loss_dice_8: 0.5606  time: 1.6792  data_time: 0.0646  lr: 9.0985e-05  max_mem: 5916M
[02/24 15:29:08] d2.utils.events INFO:  eta: 1 day, 1:05:36  iter: 5999  total_loss: 8.162  loss_ce: 0  loss_mask: 0.2035  loss_dice: 0.5568  loss_seg: 0.3543  loss_ce_0: 0  loss_mask_0: 0.2037  loss_dice_0: 0.5752  loss_ce_1: 0  loss_mask_1: 0.2046  loss_dice_1: 0.558  loss_ce_2: 0  loss_mask_2: 0.2057  loss_dice_2: 0.5547  loss_ce_3: 0  loss_mask_3: 0.2055  loss_dice_3: 0.5533  loss_ce_4: 0  loss_mask_4: 0.2055  loss_dice_4: 0.5536  loss_ce_5: 0  loss_mask_5: 0.2047  loss_dice_5: 0.553  loss_ce_6: 0  loss_mask_6: 0.2046  loss_dice_6: 0.5537  loss_ce_7: 0  loss_mask_7: 0.2049  loss_dice_7: 0.5546  loss_ce_8: 0  loss_mask_8: 0.2039  loss_dice_8: 0.5543  time: 1.6793  data_time: 0.0612  lr: 9.0955e-05  max_mem: 5916M
[02/24 15:29:43] d2.utils.events INFO:  eta: 1 day, 1:06:31  iter: 6019  total_loss: 7.915  loss_ce: 0  loss_mask: 0.2063  loss_dice: 0.5437  loss_seg: 0.3161  loss_ce_0: 0  loss_mask_0: 0.2071  loss_dice_0: 0.5617  loss_ce_1: 0  loss_mask_1: 0.2016  loss_dice_1: 0.5423  loss_ce_2: 0  loss_mask_2: 0.205  loss_dice_2: 0.5414  loss_ce_3: 0  loss_mask_3: 0.2059  loss_dice_3: 0.539  loss_ce_4: 0  loss_mask_4: 0.2053  loss_dice_4: 0.5403  loss_ce_5: 0  loss_mask_5: 0.2057  loss_dice_5: 0.5396  loss_ce_6: 0  loss_mask_6: 0.2055  loss_dice_6: 0.5385  loss_ce_7: 0  loss_mask_7: 0.2056  loss_dice_7: 0.5386  loss_ce_8: 0  loss_mask_8: 0.2056  loss_dice_8: 0.5405  time: 1.6794  data_time: 0.0601  lr: 9.0924e-05  max_mem: 5916M
[02/24 15:30:16] d2.utils.events INFO:  eta: 1 day, 1:05:07  iter: 6039  total_loss: 7.974  loss_ce: 0  loss_mask: 0.2079  loss_dice: 0.5534  loss_seg: 0.3225  loss_ce_0: 0  loss_mask_0: 0.2066  loss_dice_0: 0.5614  loss_ce_1: 0  loss_mask_1: 0.2046  loss_dice_1: 0.5527  loss_ce_2: 0  loss_mask_2: 0.2049  loss_dice_2: 0.5516  loss_ce_3: 0  loss_mask_3: 0.204  loss_dice_3: 0.5507  loss_ce_4: 0  loss_mask_4: 0.2043  loss_dice_4: 0.5502  loss_ce_5: 0  loss_mask_5: 0.2049  loss_dice_5: 0.5506  loss_ce_6: 0  loss_mask_6: 0.2043  loss_dice_6: 0.551  loss_ce_7: 0  loss_mask_7: 0.2047  loss_dice_7: 0.5519  loss_ce_8: 0  loss_mask_8: 0.2048  loss_dice_8: 0.5523  time: 1.6793  data_time: 0.0573  lr: 9.0894e-05  max_mem: 5916M
[02/24 15:30:50] d2.utils.events INFO:  eta: 1 day, 1:05:14  iter: 6059  total_loss: 7.857  loss_ce: 0  loss_mask: 0.2196  loss_dice: 0.5336  loss_seg: 0.3036  loss_ce_0: 0  loss_mask_0: 0.2178  loss_dice_0: 0.553  loss_ce_1: 0  loss_mask_1: 0.2179  loss_dice_1: 0.5363  loss_ce_2: 0  loss_mask_2: 0.2182  loss_dice_2: 0.5336  loss_ce_3: 0  loss_mask_3: 0.2194  loss_dice_3: 0.5316  loss_ce_4: 0  loss_mask_4: 0.218  loss_dice_4: 0.5323  loss_ce_5: 0  loss_mask_5: 0.2188  loss_dice_5: 0.5329  loss_ce_6: 0  loss_mask_6: 0.2199  loss_dice_6: 0.5337  loss_ce_7: 0  loss_mask_7: 0.2201  loss_dice_7: 0.5339  loss_ce_8: 0  loss_mask_8: 0.2193  loss_dice_8: 0.5339  time: 1.6795  data_time: 0.0572  lr: 9.0864e-05  max_mem: 5916M
[02/24 15:31:24] d2.utils.events INFO:  eta: 1 day, 1:04:54  iter: 6079  total_loss: 8.349  loss_ce: 0  loss_mask: 0.2274  loss_dice: 0.5735  loss_seg: 0.2937  loss_ce_0: 0  loss_mask_0: 0.2302  loss_dice_0: 0.5783  loss_ce_1: 0  loss_mask_1: 0.2278  loss_dice_1: 0.5738  loss_ce_2: 0  loss_mask_2: 0.229  loss_dice_2: 0.5738  loss_ce_3: 0  loss_mask_3: 0.2292  loss_dice_3: 0.5723  loss_ce_4: 0  loss_mask_4: 0.2293  loss_dice_4: 0.5729  loss_ce_5: 0  loss_mask_5: 0.2286  loss_dice_5: 0.572  loss_ce_6: 0  loss_mask_6: 0.2293  loss_dice_6: 0.5712  loss_ce_7: 0  loss_mask_7: 0.2298  loss_dice_7: 0.5718  loss_ce_8: 0  loss_mask_8: 0.2294  loss_dice_8: 0.5734  time: 1.6794  data_time: 0.0624  lr: 9.0833e-05  max_mem: 5916M
[02/24 15:31:57] d2.utils.events INFO:  eta: 1 day, 1:04:07  iter: 6099  total_loss: 8.038  loss_ce: 0  loss_mask: 0.2105  loss_dice: 0.5646  loss_seg: 0.3022  loss_ce_0: 0  loss_mask_0: 0.2096  loss_dice_0: 0.5738  loss_ce_1: 0  loss_mask_1: 0.2097  loss_dice_1: 0.5598  loss_ce_2: 0  loss_mask_2: 0.209  loss_dice_2: 0.5572  loss_ce_3: 0  loss_mask_3: 0.2104  loss_dice_3: 0.556  loss_ce_4: 0  loss_mask_4: 0.2096  loss_dice_4: 0.5566  loss_ce_5: 0  loss_mask_5: 0.2092  loss_dice_5: 0.5587  loss_ce_6: 0  loss_mask_6: 0.2106  loss_dice_6: 0.5574  loss_ce_7: 0  loss_mask_7: 0.2103  loss_dice_7: 0.5573  loss_ce_8: 0  loss_mask_8: 0.2096  loss_dice_8: 0.5588  time: 1.6794  data_time: 0.0553  lr: 9.0803e-05  max_mem: 5916M
[02/24 15:32:31] d2.utils.events INFO:  eta: 1 day, 1:02:15  iter: 6119  total_loss: 8.055  loss_ce: 0  loss_mask: 0.2168  loss_dice: 0.5563  loss_seg: 0.3449  loss_ce_0: 0  loss_mask_0: 0.2175  loss_dice_0: 0.568  loss_ce_1: 0  loss_mask_1: 0.215  loss_dice_1: 0.5551  loss_ce_2: 0  loss_mask_2: 0.2165  loss_dice_2: 0.5516  loss_ce_3: 0  loss_mask_3: 0.2162  loss_dice_3: 0.5512  loss_ce_4: 0  loss_mask_4: 0.2183  loss_dice_4: 0.5511  loss_ce_5: 0  loss_mask_5: 0.219  loss_dice_5: 0.5507  loss_ce_6: 0  loss_mask_6: 0.218  loss_dice_6: 0.5525  loss_ce_7: 0  loss_mask_7: 0.2175  loss_dice_7: 0.5524  loss_ce_8: 0  loss_mask_8: 0.2176  loss_dice_8: 0.553  time: 1.6794  data_time: 0.0535  lr: 9.0773e-05  max_mem: 5916M
[02/24 15:33:06] d2.utils.events INFO:  eta: 1 day, 1:01:42  iter: 6139  total_loss: 7.76  loss_ce: 0  loss_mask: 0.2067  loss_dice: 0.5466  loss_seg: 0.3331  loss_ce_0: 0  loss_mask_0: 0.206  loss_dice_0: 0.5588  loss_ce_1: 0  loss_mask_1: 0.2046  loss_dice_1: 0.5439  loss_ce_2: 0  loss_mask_2: 0.2058  loss_dice_2: 0.543  loss_ce_3: 0  loss_mask_3: 0.2061  loss_dice_3: 0.5407  loss_ce_4: 0  loss_mask_4: 0.2041  loss_dice_4: 0.5415  loss_ce_5: 0  loss_mask_5: 0.2054  loss_dice_5: 0.5421  loss_ce_6: 0  loss_mask_6: 0.2057  loss_dice_6: 0.5421  loss_ce_7: 0  loss_mask_7: 0.2051  loss_dice_7: 0.5416  loss_ce_8: 0  loss_mask_8: 0.2066  loss_dice_8: 0.543  time: 1.6795  data_time: 0.0543  lr: 9.0743e-05  max_mem: 5916M
[02/24 15:33:40] d2.utils.events INFO:  eta: 1 day, 1:02:13  iter: 6159  total_loss: 7.741  loss_ce: 0  loss_mask: 0.2067  loss_dice: 0.5483  loss_seg: 0.2798  loss_ce_0: 0  loss_mask_0: 0.2076  loss_dice_0: 0.5721  loss_ce_1: 0  loss_mask_1: 0.2083  loss_dice_1: 0.5489  loss_ce_2: 0  loss_mask_2: 0.207  loss_dice_2: 0.545  loss_ce_3: 0  loss_mask_3: 0.2064  loss_dice_3: 0.5431  loss_ce_4: 0  loss_mask_4: 0.2065  loss_dice_4: 0.5439  loss_ce_5: 0  loss_mask_5: 0.2063  loss_dice_5: 0.5443  loss_ce_6: 0  loss_mask_6: 0.2061  loss_dice_6: 0.5439  loss_ce_7: 0  loss_mask_7: 0.2077  loss_dice_7: 0.5441  loss_ce_8: 0  loss_mask_8: 0.2057  loss_dice_8: 0.5446  time: 1.6796  data_time: 0.0498  lr: 9.0712e-05  max_mem: 5916M
[02/24 15:34:13] d2.utils.events INFO:  eta: 1 day, 0:55:50  iter: 6179  total_loss: 7.956  loss_ce: 0  loss_mask: 0.2084  loss_dice: 0.5533  loss_seg: 0.2777  loss_ce_0: 0  loss_mask_0: 0.2066  loss_dice_0: 0.5637  loss_ce_1: 0  loss_mask_1: 0.2077  loss_dice_1: 0.5536  loss_ce_2: 0  loss_mask_2: 0.2087  loss_dice_2: 0.5534  loss_ce_3: 0  loss_mask_3: 0.2101  loss_dice_3: 0.5509  loss_ce_4: 0  loss_mask_4: 0.2107  loss_dice_4: 0.5514  loss_ce_5: 0  loss_mask_5: 0.2092  loss_dice_5: 0.5518  loss_ce_6: 0  loss_mask_6: 0.2098  loss_dice_6: 0.5509  loss_ce_7: 0  loss_mask_7: 0.2088  loss_dice_7: 0.5515  loss_ce_8: 0  loss_mask_8: 0.2088  loss_dice_8: 0.55  time: 1.6794  data_time: 0.0629  lr: 9.0682e-05  max_mem: 5916M
[02/24 15:34:46] d2.utils.events INFO:  eta: 1 day, 0:55:17  iter: 6199  total_loss: 7.702  loss_ce: 0  loss_mask: 0.2047  loss_dice: 0.5369  loss_seg: 0.2767  loss_ce_0: 0  loss_mask_0: 0.2047  loss_dice_0: 0.5512  loss_ce_1: 0  loss_mask_1: 0.2062  loss_dice_1: 0.5342  loss_ce_2: 0  loss_mask_2: 0.2063  loss_dice_2: 0.534  loss_ce_3: 0  loss_mask_3: 0.2084  loss_dice_3: 0.531  loss_ce_4: 0  loss_mask_4: 0.207  loss_dice_4: 0.5305  loss_ce_5: 0  loss_mask_5: 0.2062  loss_dice_5: 0.5323  loss_ce_6: 0  loss_mask_6: 0.206  loss_dice_6: 0.5334  loss_ce_7: 0  loss_mask_7: 0.207  loss_dice_7: 0.5338  loss_ce_8: 0  loss_mask_8: 0.2069  loss_dice_8: 0.5351  time: 1.6794  data_time: 0.0584  lr: 9.0652e-05  max_mem: 5916M
[02/24 15:35:20] d2.utils.events INFO:  eta: 1 day, 0:58:06  iter: 6219  total_loss: 8.234  loss_ce: 0  loss_mask: 0.2233  loss_dice: 0.5766  loss_seg: 0.3243  loss_ce_0: 0  loss_mask_0: 0.221  loss_dice_0: 0.5817  loss_ce_1: 0  loss_mask_1: 0.2193  loss_dice_1: 0.5767  loss_ce_2: 0  loss_mask_2: 0.2188  loss_dice_2: 0.5739  loss_ce_3: 0  loss_mask_3: 0.2194  loss_dice_3: 0.5706  loss_ce_4: 0  loss_mask_4: 0.2202  loss_dice_4: 0.5715  loss_ce_5: 0  loss_mask_5: 0.2215  loss_dice_5: 0.5721  loss_ce_6: 0  loss_mask_6: 0.2199  loss_dice_6: 0.5701  loss_ce_7: 0  loss_mask_7: 0.2205  loss_dice_7: 0.5706  loss_ce_8: 0  loss_mask_8: 0.2211  loss_dice_8: 0.5722  time: 1.6795  data_time: 0.0655  lr: 9.0621e-05  max_mem: 5916M
[02/24 15:35:54] d2.utils.events INFO:  eta: 1 day, 1:00:16  iter: 6239  total_loss: 7.741  loss_ce: 0  loss_mask: 0.2044  loss_dice: 0.5434  loss_seg: 0.2906  loss_ce_0: 0  loss_mask_0: 0.2057  loss_dice_0: 0.5524  loss_ce_1: 0  loss_mask_1: 0.2042  loss_dice_1: 0.5393  loss_ce_2: 0  loss_mask_2: 0.2045  loss_dice_2: 0.5386  loss_ce_3: 0  loss_mask_3: 0.2045  loss_dice_3: 0.5381  loss_ce_4: 0  loss_mask_4: 0.204  loss_dice_4: 0.5383  loss_ce_5: 0  loss_mask_5: 0.2036  loss_dice_5: 0.5387  loss_ce_6: 0  loss_mask_6: 0.2041  loss_dice_6: 0.5387  loss_ce_7: 0  loss_mask_7: 0.2036  loss_dice_7: 0.5396  loss_ce_8: 0  loss_mask_8: 0.2044  loss_dice_8: 0.5422  time: 1.6795  data_time: 0.0619  lr: 9.0591e-05  max_mem: 5916M
[02/24 15:36:28] d2.utils.events INFO:  eta: 1 day, 1:00:39  iter: 6259  total_loss: 8.058  loss_ce: 0  loss_mask: 0.219  loss_dice: 0.561  loss_seg: 0.3206  loss_ce_0: 0  loss_mask_0: 0.2141  loss_dice_0: 0.5762  loss_ce_1: 0  loss_mask_1: 0.216  loss_dice_1: 0.5618  loss_ce_2: 0  loss_mask_2: 0.2163  loss_dice_2: 0.5594  loss_ce_3: 0  loss_mask_3: 0.2158  loss_dice_3: 0.5582  loss_ce_4: 0  loss_mask_4: 0.2149  loss_dice_4: 0.5567  loss_ce_5: 0  loss_mask_5: 0.2165  loss_dice_5: 0.5564  loss_ce_6: 0  loss_mask_6: 0.217  loss_dice_6: 0.5553  loss_ce_7: 0  loss_mask_7: 0.2167  loss_dice_7: 0.5565  loss_ce_8: 0  loss_mask_8: 0.2187  loss_dice_8: 0.5578  time: 1.6795  data_time: 0.0609  lr: 9.0561e-05  max_mem: 5916M
[02/24 15:37:03] d2.utils.events INFO:  eta: 1 day, 0:59:32  iter: 6279  total_loss: 8.112  loss_ce: 0  loss_mask: 0.2154  loss_dice: 0.5675  loss_seg: 0.3153  loss_ce_0: 0  loss_mask_0: 0.2128  loss_dice_0: 0.576  loss_ce_1: 0  loss_mask_1: 0.2133  loss_dice_1: 0.5671  loss_ce_2: 0  loss_mask_2: 0.215  loss_dice_2: 0.5659  loss_ce_3: 0  loss_mask_3: 0.2159  loss_dice_3: 0.5643  loss_ce_4: 0  loss_mask_4: 0.2155  loss_dice_4: 0.5656  loss_ce_5: 0  loss_mask_5: 0.2152  loss_dice_5: 0.5656  loss_ce_6: 0  loss_mask_6: 0.215  loss_dice_6: 0.5667  loss_ce_7: 0  loss_mask_7: 0.215  loss_dice_7: 0.5651  loss_ce_8: 0  loss_mask_8: 0.2148  loss_dice_8: 0.5655  time: 1.6797  data_time: 0.0811  lr: 9.053e-05  max_mem: 5916M
[02/24 15:37:39] d2.utils.events INFO:  eta: 1 day, 1:00:03  iter: 6299  total_loss: 7.751  loss_ce: 0  loss_mask: 0.209  loss_dice: 0.5441  loss_seg: 0.2935  loss_ce_0: 0  loss_mask_0: 0.2052  loss_dice_0: 0.5604  loss_ce_1: 0  loss_mask_1: 0.2063  loss_dice_1: 0.5429  loss_ce_2: 0  loss_mask_2: 0.2068  loss_dice_2: 0.5397  loss_ce_3: 0  loss_mask_3: 0.2085  loss_dice_3: 0.5386  loss_ce_4: 0  loss_mask_4: 0.2077  loss_dice_4: 0.5378  loss_ce_5: 0  loss_mask_5: 0.2079  loss_dice_5: 0.5393  loss_ce_6: 0  loss_mask_6: 0.2074  loss_dice_6: 0.5383  loss_ce_7: 0  loss_mask_7: 0.2075  loss_dice_7: 0.5391  loss_ce_8: 0  loss_mask_8: 0.2074  loss_dice_8: 0.5402  time: 1.6800  data_time: 0.0734  lr: 9.05e-05  max_mem: 5916M
[02/24 15:38:13] d2.utils.events INFO:  eta: 1 day, 0:59:52  iter: 6319  total_loss: 7.787  loss_ce: 0  loss_mask: 0.1953  loss_dice: 0.5377  loss_seg: 0.3023  loss_ce_0: 0  loss_mask_0: 0.1947  loss_dice_0: 0.5504  loss_ce_1: 0  loss_mask_1: 0.1932  loss_dice_1: 0.5375  loss_ce_2: 0  loss_mask_2: 0.1924  loss_dice_2: 0.5367  loss_ce_3: 0  loss_mask_3: 0.1932  loss_dice_3: 0.5361  loss_ce_4: 0  loss_mask_4: 0.1934  loss_dice_4: 0.5365  loss_ce_5: 0  loss_mask_5: 0.1932  loss_dice_5: 0.5376  loss_ce_6: 0  loss_mask_6: 0.1937  loss_dice_6: 0.5364  loss_ce_7: 0  loss_mask_7: 0.1938  loss_dice_7: 0.5356  loss_ce_8: 0  loss_mask_8: 0.1941  loss_dice_8: 0.5357  time: 1.6801  data_time: 0.0705  lr: 9.047e-05  max_mem: 5916M
[02/24 15:38:49] d2.utils.events INFO:  eta: 1 day, 1:01:40  iter: 6339  total_loss: 8.015  loss_ce: 0  loss_mask: 0.222  loss_dice: 0.5539  loss_seg: 0.3114  loss_ce_0: 0  loss_mask_0: 0.2172  loss_dice_0: 0.5699  loss_ce_1: 0  loss_mask_1: 0.2206  loss_dice_1: 0.5549  loss_ce_2: 0  loss_mask_2: 0.2208  loss_dice_2: 0.5519  loss_ce_3: 0  loss_mask_3: 0.2214  loss_dice_3: 0.5517  loss_ce_4: 0  loss_mask_4: 0.2225  loss_dice_4: 0.5509  loss_ce_5: 0  loss_mask_5: 0.2229  loss_dice_5: 0.5517  loss_ce_6: 0  loss_mask_6: 0.2227  loss_dice_6: 0.5521  loss_ce_7: 0  loss_mask_7: 0.2216  loss_dice_7: 0.5522  loss_ce_8: 0  loss_mask_8: 0.2215  loss_dice_8: 0.5522  time: 1.6804  data_time: 0.0627  lr: 9.0439e-05  max_mem: 5916M
[02/24 15:39:23] d2.utils.events INFO:  eta: 1 day, 1:01:32  iter: 6359  total_loss: 7.946  loss_ce: 0  loss_mask: 0.2131  loss_dice: 0.5542  loss_seg: 0.2921  loss_ce_0: 0  loss_mask_0: 0.212  loss_dice_0: 0.5645  loss_ce_1: 0  loss_mask_1: 0.2112  loss_dice_1: 0.5523  loss_ce_2: 0  loss_mask_2: 0.2122  loss_dice_2: 0.5512  loss_ce_3: 0  loss_mask_3: 0.2126  loss_dice_3: 0.5499  loss_ce_4: 0  loss_mask_4: 0.2125  loss_dice_4: 0.5505  loss_ce_5: 0  loss_mask_5: 0.2124  loss_dice_5: 0.5498  loss_ce_6: 0  loss_mask_6: 0.2132  loss_dice_6: 0.5497  loss_ce_7: 0  loss_mask_7: 0.2131  loss_dice_7: 0.5507  loss_ce_8: 0  loss_mask_8: 0.2123  loss_dice_8: 0.5495  time: 1.6805  data_time: 0.0663  lr: 9.0409e-05  max_mem: 5916M
[02/24 15:39:57] d2.utils.events INFO:  eta: 1 day, 1:00:05  iter: 6379  total_loss: 7.923  loss_ce: 0  loss_mask: 0.2092  loss_dice: 0.5676  loss_seg: 0.3187  loss_ce_0: 0  loss_mask_0: 0.2066  loss_dice_0: 0.5757  loss_ce_1: 0  loss_mask_1: 0.2064  loss_dice_1: 0.5654  loss_ce_2: 0  loss_mask_2: 0.2079  loss_dice_2: 0.5626  loss_ce_3: 0  loss_mask_3: 0.2101  loss_dice_3: 0.5617  loss_ce_4: 0  loss_mask_4: 0.2089  loss_dice_4: 0.5631  loss_ce_5: 0  loss_mask_5: 0.2075  loss_dice_5: 0.5627  loss_ce_6: 0  loss_mask_6: 0.2096  loss_dice_6: 0.5617  loss_ce_7: 0  loss_mask_7: 0.2084  loss_dice_7: 0.5626  loss_ce_8: 0  loss_mask_8: 0.2093  loss_dice_8: 0.5632  time: 1.6805  data_time: 0.0799  lr: 9.0379e-05  max_mem: 5916M
[02/24 15:40:31] d2.utils.events INFO:  eta: 1 day, 1:00:25  iter: 6399  total_loss: 7.768  loss_ce: 0  loss_mask: 0.2009  loss_dice: 0.5385  loss_seg: 0.2939  loss_ce_0: 0  loss_mask_0: 0.198  loss_dice_0: 0.5556  loss_ce_1: 0  loss_mask_1: 0.1997  loss_dice_1: 0.5405  loss_ce_2: 0  loss_mask_2: 0.199  loss_dice_2: 0.5388  loss_ce_3: 0  loss_mask_3: 0.2006  loss_dice_3: 0.5374  loss_ce_4: 0  loss_mask_4: 0.2  loss_dice_4: 0.5372  loss_ce_5: 0  loss_mask_5: 0.2007  loss_dice_5: 0.537  loss_ce_6: 0  loss_mask_6: 0.2005  loss_dice_6: 0.5375  loss_ce_7: 0  loss_mask_7: 0.2008  loss_dice_7: 0.5374  loss_ce_8: 0  loss_mask_8: 0.2007  loss_dice_8: 0.5361  time: 1.6806  data_time: 0.0751  lr: 9.0348e-05  max_mem: 5916M
[02/24 15:41:06] d2.utils.events INFO:  eta: 1 day, 1:00:46  iter: 6419  total_loss: 7.936  loss_ce: 0  loss_mask: 0.2084  loss_dice: 0.5507  loss_seg: 0.2784  loss_ce_0: 0  loss_mask_0: 0.2107  loss_dice_0: 0.5588  loss_ce_1: 0  loss_mask_1: 0.2077  loss_dice_1: 0.5503  loss_ce_2: 0  loss_mask_2: 0.2081  loss_dice_2: 0.5503  loss_ce_3: 0  loss_mask_3: 0.2077  loss_dice_3: 0.5484  loss_ce_4: 0  loss_mask_4: 0.2075  loss_dice_4: 0.5471  loss_ce_5: 0  loss_mask_5: 0.207  loss_dice_5: 0.5479  loss_ce_6: 0  loss_mask_6: 0.2085  loss_dice_6: 0.5468  loss_ce_7: 0  loss_mask_7: 0.2085  loss_dice_7: 0.5484  loss_ce_8: 0  loss_mask_8: 0.2082  loss_dice_8: 0.548  time: 1.6807  data_time: 0.0743  lr: 9.0318e-05  max_mem: 5916M
[02/24 15:41:41] d2.utils.events INFO:  eta: 1 day, 1:00:16  iter: 6439  total_loss: 8.282  loss_ce: 0  loss_mask: 0.2174  loss_dice: 0.5711  loss_seg: 0.3177  loss_ce_0: 0  loss_mask_0: 0.214  loss_dice_0: 0.5784  loss_ce_1: 0  loss_mask_1: 0.2152  loss_dice_1: 0.5709  loss_ce_2: 0  loss_mask_2: 0.2151  loss_dice_2: 0.5688  loss_ce_3: 0  loss_mask_3: 0.2154  loss_dice_3: 0.5655  loss_ce_4: 0  loss_mask_4: 0.2168  loss_dice_4: 0.5653  loss_ce_5: 0  loss_mask_5: 0.2164  loss_dice_5: 0.5657  loss_ce_6: 0  loss_mask_6: 0.2176  loss_dice_6: 0.566  loss_ce_7: 0  loss_mask_7: 0.2169  loss_dice_7: 0.5657  loss_ce_8: 0  loss_mask_8: 0.2178  loss_dice_8: 0.5677  time: 1.6809  data_time: 0.0776  lr: 9.0288e-05  max_mem: 5916M
[02/24 15:42:16] d2.utils.events INFO:  eta: 1 day, 0:59:43  iter: 6459  total_loss: 7.69  loss_ce: 0  loss_mask: 0.1961  loss_dice: 0.5402  loss_seg: 0.2735  loss_ce_0: 0  loss_mask_0: 0.1979  loss_dice_0: 0.5573  loss_ce_1: 0  loss_mask_1: 0.196  loss_dice_1: 0.5402  loss_ce_2: 0  loss_mask_2: 0.1975  loss_dice_2: 0.5372  loss_ce_3: 0  loss_mask_3: 0.1982  loss_dice_3: 0.5345  loss_ce_4: 0  loss_mask_4: 0.1985  loss_dice_4: 0.5351  loss_ce_5: 0  loss_mask_5: 0.1981  loss_dice_5: 0.536  loss_ce_6: 0  loss_mask_6: 0.1974  loss_dice_6: 0.5372  loss_ce_7: 0  loss_mask_7: 0.1968  loss_dice_7: 0.5381  loss_ce_8: 0  loss_mask_8: 0.1961  loss_dice_8: 0.539  time: 1.6811  data_time: 0.0748  lr: 9.0257e-05  max_mem: 5916M
[02/24 15:42:51] d2.utils.events INFO:  eta: 1 day, 1:00:17  iter: 6479  total_loss: 7.949  loss_ce: 0  loss_mask: 0.2171  loss_dice: 0.5518  loss_seg: 0.3069  loss_ce_0: 0  loss_mask_0: 0.2144  loss_dice_0: 0.5673  loss_ce_1: 0  loss_mask_1: 0.2154  loss_dice_1: 0.551  loss_ce_2: 0  loss_mask_2: 0.2154  loss_dice_2: 0.5478  loss_ce_3: 0  loss_mask_3: 0.2159  loss_dice_3: 0.5449  loss_ce_4: 0  loss_mask_4: 0.2169  loss_dice_4: 0.5466  loss_ce_5: 0  loss_mask_5: 0.2162  loss_dice_5: 0.5473  loss_ce_6: 0  loss_mask_6: 0.2169  loss_dice_6: 0.5456  loss_ce_7: 0  loss_mask_7: 0.2161  loss_dice_7: 0.5467  loss_ce_8: 0  loss_mask_8: 0.2171  loss_dice_8: 0.5472  time: 1.6812  data_time: 0.0700  lr: 9.0227e-05  max_mem: 5916M
[02/24 15:43:27] d2.utils.events INFO:  eta: 1 day, 1:02:58  iter: 6499  total_loss: 7.923  loss_ce: 0  loss_mask: 0.2024  loss_dice: 0.5542  loss_seg: 0.2912  loss_ce_0: 0  loss_mask_0: 0.2013  loss_dice_0: 0.5631  loss_ce_1: 0  loss_mask_1: 0.2017  loss_dice_1: 0.5537  loss_ce_2: 0  loss_mask_2: 0.2019  loss_dice_2: 0.5528  loss_ce_3: 0  loss_mask_3: 0.2018  loss_dice_3: 0.5522  loss_ce_4: 0  loss_mask_4: 0.2013  loss_dice_4: 0.5528  loss_ce_5: 0  loss_mask_5: 0.201  loss_dice_5: 0.5524  loss_ce_6: 0  loss_mask_6: 0.2019  loss_dice_6: 0.5525  loss_ce_7: 0  loss_mask_7: 0.2019  loss_dice_7: 0.5515  loss_ce_8: 0  loss_mask_8: 0.2024  loss_dice_8: 0.5523  time: 1.6815  data_time: 0.0877  lr: 9.0196e-05  max_mem: 5916M
[02/24 15:44:02] d2.utils.events INFO:  eta: 1 day, 1:03:01  iter: 6519  total_loss: 8.295  loss_ce: 0  loss_mask: 0.2215  loss_dice: 0.5827  loss_seg: 0.3055  loss_ce_0: 0  loss_mask_0: 0.2244  loss_dice_0: 0.589  loss_ce_1: 0  loss_mask_1: 0.2263  loss_dice_1: 0.5826  loss_ce_2: 0  loss_mask_2: 0.2255  loss_dice_2: 0.5812  loss_ce_3: 0  loss_mask_3: 0.2257  loss_dice_3: 0.5771  loss_ce_4: 0  loss_mask_4: 0.2241  loss_dice_4: 0.5783  loss_ce_5: 0  loss_mask_5: 0.2255  loss_dice_5: 0.5794  loss_ce_6: 0  loss_mask_6: 0.2236  loss_dice_6: 0.5789  loss_ce_7: 0  loss_mask_7: 0.2241  loss_dice_7: 0.5787  loss_ce_8: 0  loss_mask_8: 0.2228  loss_dice_8: 0.5801  time: 1.6817  data_time: 0.0702  lr: 9.0166e-05  max_mem: 5916M
[02/24 15:44:37] d2.utils.events INFO:  eta: 1 day, 1:06:43  iter: 6539  total_loss: 8.165  loss_ce: 0  loss_mask: 0.217  loss_dice: 0.5694  loss_seg: 0.3218  loss_ce_0: 0  loss_mask_0: 0.2179  loss_dice_0: 0.5701  loss_ce_1: 0  loss_mask_1: 0.2148  loss_dice_1: 0.5644  loss_ce_2: 0  loss_mask_2: 0.2162  loss_dice_2: 0.5635  loss_ce_3: 0  loss_mask_3: 0.2168  loss_dice_3: 0.5628  loss_ce_4: 0  loss_mask_4: 0.2172  loss_dice_4: 0.563  loss_ce_5: 0  loss_mask_5: 0.2162  loss_dice_5: 0.5644  loss_ce_6: 0  loss_mask_6: 0.2166  loss_dice_6: 0.5644  loss_ce_7: 0  loss_mask_7: 0.2173  loss_dice_7: 0.5664  loss_ce_8: 0  loss_mask_8: 0.2167  loss_dice_8: 0.5651  time: 1.6820  data_time: 0.0727  lr: 9.0136e-05  max_mem: 5916M
[02/24 15:45:12] d2.utils.events INFO:  eta: 1 day, 1:07:25  iter: 6559  total_loss: 7.851  loss_ce: 0  loss_mask: 0.2099  loss_dice: 0.5485  loss_seg: 0.3108  loss_ce_0: 0  loss_mask_0: 0.2065  loss_dice_0: 0.5627  loss_ce_1: 0  loss_mask_1: 0.2082  loss_dice_1: 0.5471  loss_ce_2: 0  loss_mask_2: 0.2062  loss_dice_2: 0.5443  loss_ce_3: 0  loss_mask_3: 0.2063  loss_dice_3: 0.5451  loss_ce_4: 0  loss_mask_4: 0.2071  loss_dice_4: 0.5438  loss_ce_5: 0  loss_mask_5: 0.2073  loss_dice_5: 0.5448  loss_ce_6: 0  loss_mask_6: 0.2071  loss_dice_6: 0.5443  loss_ce_7: 0  loss_mask_7: 0.2086  loss_dice_7: 0.5446  loss_ce_8: 0  loss_mask_8: 0.2091  loss_dice_8: 0.5449  time: 1.6821  data_time: 0.0615  lr: 9.0105e-05  max_mem: 5916M
[02/24 15:45:48] d2.utils.events INFO:  eta: 1 day, 1:06:51  iter: 6579  total_loss: 7.749  loss_ce: 0  loss_mask: 0.2043  loss_dice: 0.5226  loss_seg: 0.2673  loss_ce_0: 0  loss_mask_0: 0.2035  loss_dice_0: 0.5359  loss_ce_1: 0  loss_mask_1: 0.2039  loss_dice_1: 0.5193  loss_ce_2: 0  loss_mask_2: 0.2048  loss_dice_2: 0.5173  loss_ce_3: 0  loss_mask_3: 0.2058  loss_dice_3: 0.5156  loss_ce_4: 0  loss_mask_4: 0.205  loss_dice_4: 0.517  loss_ce_5: 0  loss_mask_5: 0.2054  loss_dice_5: 0.5179  loss_ce_6: 0  loss_mask_6: 0.2039  loss_dice_6: 0.5182  loss_ce_7: 0  loss_mask_7: 0.2038  loss_dice_7: 0.5178  loss_ce_8: 0  loss_mask_8: 0.2036  loss_dice_8: 0.5186  time: 1.6825  data_time: 0.0712  lr: 9.0075e-05  max_mem: 5916M
[02/24 15:46:23] d2.utils.events INFO:  eta: 1 day, 1:06:37  iter: 6599  total_loss: 8.109  loss_ce: 0  loss_mask: 0.2097  loss_dice: 0.5675  loss_seg: 0.3058  loss_ce_0: 0  loss_mask_0: 0.2019  loss_dice_0: 0.5823  loss_ce_1: 0  loss_mask_1: 0.2062  loss_dice_1: 0.5716  loss_ce_2: 0  loss_mask_2: 0.2074  loss_dice_2: 0.5683  loss_ce_3: 0  loss_mask_3: 0.2075  loss_dice_3: 0.5668  loss_ce_4: 0  loss_mask_4: 0.2071  loss_dice_4: 0.5673  loss_ce_5: 0  loss_mask_5: 0.2076  loss_dice_5: 0.5658  loss_ce_6: 0  loss_mask_6: 0.2086  loss_dice_6: 0.5644  loss_ce_7: 0  loss_mask_7: 0.2084  loss_dice_7: 0.5668  loss_ce_8: 0  loss_mask_8: 0.2085  loss_dice_8: 0.5662  time: 1.6827  data_time: 0.0701  lr: 9.0045e-05  max_mem: 5916M
[02/24 15:46:57] d2.utils.events INFO:  eta: 1 day, 1:06:04  iter: 6619  total_loss: 7.795  loss_ce: 0  loss_mask: 0.2108  loss_dice: 0.545  loss_seg: 0.3119  loss_ce_0: 0  loss_mask_0: 0.2082  loss_dice_0: 0.5591  loss_ce_1: 0  loss_mask_1: 0.2102  loss_dice_1: 0.5427  loss_ce_2: 0  loss_mask_2: 0.2111  loss_dice_2: 0.5397  loss_ce_3: 0  loss_mask_3: 0.211  loss_dice_3: 0.5386  loss_ce_4: 0  loss_mask_4: 0.2118  loss_dice_4: 0.5374  loss_ce_5: 0  loss_mask_5: 0.2105  loss_dice_5: 0.5396  loss_ce_6: 0  loss_mask_6: 0.211  loss_dice_6: 0.5384  loss_ce_7: 0  loss_mask_7: 0.2107  loss_dice_7: 0.5382  loss_ce_8: 0  loss_mask_8: 0.2111  loss_dice_8: 0.5404  time: 1.6827  data_time: 0.0632  lr: 9.0014e-05  max_mem: 5916M
[02/24 15:47:30] d2.utils.events INFO:  eta: 1 day, 1:03:53  iter: 6639  total_loss: 7.472  loss_ce: 0  loss_mask: 0.2115  loss_dice: 0.5124  loss_seg: 0.2732  loss_ce_0: 0  loss_mask_0: 0.2062  loss_dice_0: 0.5332  loss_ce_1: 0  loss_mask_1: 0.2101  loss_dice_1: 0.5112  loss_ce_2: 0  loss_mask_2: 0.2118  loss_dice_2: 0.5102  loss_ce_3: 0  loss_mask_3: 0.2123  loss_dice_3: 0.5084  loss_ce_4: 0  loss_mask_4: 0.2139  loss_dice_4: 0.5082  loss_ce_5: 0  loss_mask_5: 0.2139  loss_dice_5: 0.5088  loss_ce_6: 0  loss_mask_6: 0.2134  loss_dice_6: 0.5076  loss_ce_7: 0  loss_mask_7: 0.2119  loss_dice_7: 0.5096  loss_ce_8: 0  loss_mask_8: 0.2123  loss_dice_8: 0.5099  time: 1.6825  data_time: 0.0575  lr: 8.9984e-05  max_mem: 5916M
[02/24 15:48:05] d2.utils.events INFO:  eta: 1 day, 1:02:41  iter: 6659  total_loss: 7.879  loss_ce: 0  loss_mask: 0.2183  loss_dice: 0.5395  loss_seg: 0.2837  loss_ce_0: 0  loss_mask_0: 0.2151  loss_dice_0: 0.5525  loss_ce_1: 0  loss_mask_1: 0.2162  loss_dice_1: 0.5384  loss_ce_2: 0  loss_mask_2: 0.2165  loss_dice_2: 0.5351  loss_ce_3: 0  loss_mask_3: 0.2172  loss_dice_3: 0.5327  loss_ce_4: 0  loss_mask_4: 0.2173  loss_dice_4: 0.5346  loss_ce_5: 0  loss_mask_5: 0.2181  loss_dice_5: 0.5346  loss_ce_6: 0  loss_mask_6: 0.2173  loss_dice_6: 0.5354  loss_ce_7: 0  loss_mask_7: 0.2173  loss_dice_7: 0.5367  loss_ce_8: 0  loss_mask_8: 0.2181  loss_dice_8: 0.5347  time: 1.6826  data_time: 0.0583  lr: 8.9954e-05  max_mem: 5916M
[02/24 15:48:39] d2.utils.events INFO:  eta: 1 day, 1:02:28  iter: 6679  total_loss: 7.728  loss_ce: 0  loss_mask: 0.2103  loss_dice: 0.527  loss_seg: 0.2822  loss_ce_0: 0  loss_mask_0: 0.2063  loss_dice_0: 0.5424  loss_ce_1: 0  loss_mask_1: 0.2071  loss_dice_1: 0.5274  loss_ce_2: 0  loss_mask_2: 0.2077  loss_dice_2: 0.5256  loss_ce_3: 0  loss_mask_3: 0.2074  loss_dice_3: 0.5227  loss_ce_4: 0  loss_mask_4: 0.2095  loss_dice_4: 0.5232  loss_ce_5: 0  loss_mask_5: 0.209  loss_dice_5: 0.5242  loss_ce_6: 0  loss_mask_6: 0.209  loss_dice_6: 0.5226  loss_ce_7: 0  loss_mask_7: 0.2099  loss_dice_7: 0.5231  loss_ce_8: 0  loss_mask_8: 0.2094  loss_dice_8: 0.5244  time: 1.6827  data_time: 0.0567  lr: 8.9923e-05  max_mem: 5916M
[02/24 15:49:13] d2.utils.events INFO:  eta: 1 day, 1:01:34  iter: 6699  total_loss: 7.52  loss_ce: 0  loss_mask: 0.2087  loss_dice: 0.5344  loss_seg: 0.2746  loss_ce_0: 0  loss_mask_0: 0.2108  loss_dice_0: 0.5507  loss_ce_1: 0  loss_mask_1: 0.208  loss_dice_1: 0.5361  loss_ce_2: 0  loss_mask_2: 0.2083  loss_dice_2: 0.5342  loss_ce_3: 0  loss_mask_3: 0.21  loss_dice_3: 0.5329  loss_ce_4: 0  loss_mask_4: 0.2091  loss_dice_4: 0.533  loss_ce_5: 0  loss_mask_5: 0.2079  loss_dice_5: 0.5338  loss_ce_6: 0  loss_mask_6: 0.2076  loss_dice_6: 0.534  loss_ce_7: 0  loss_mask_7: 0.2085  loss_dice_7: 0.534  loss_ce_8: 0  loss_mask_8: 0.2085  loss_dice_8: 0.5333  time: 1.6827  data_time: 0.0606  lr: 8.9893e-05  max_mem: 5916M
[02/24 15:49:46] d2.utils.events INFO:  eta: 1 day, 1:01:05  iter: 6719  total_loss: 7.653  loss_ce: 0  loss_mask: 0.1941  loss_dice: 0.5493  loss_seg: 0.316  loss_ce_0: 0  loss_mask_0: 0.1918  loss_dice_0: 0.5607  loss_ce_1: 0  loss_mask_1: 0.1932  loss_dice_1: 0.549  loss_ce_2: 0  loss_mask_2: 0.1926  loss_dice_2: 0.5464  loss_ce_3: 0  loss_mask_3: 0.1933  loss_dice_3: 0.5461  loss_ce_4: 0  loss_mask_4: 0.1925  loss_dice_4: 0.5463  loss_ce_5: 0  loss_mask_5: 0.1927  loss_dice_5: 0.5475  loss_ce_6: 0  loss_mask_6: 0.1931  loss_dice_6: 0.5463  loss_ce_7: 0  loss_mask_7: 0.193  loss_dice_7: 0.5477  loss_ce_8: 0  loss_mask_8: 0.1926  loss_dice_8: 0.5475  time: 1.6827  data_time: 0.0543  lr: 8.9863e-05  max_mem: 5916M
[02/24 15:50:22] d2.utils.events INFO:  eta: 1 day, 1:01:04  iter: 6739  total_loss: 7.921  loss_ce: 0  loss_mask: 0.2093  loss_dice: 0.556  loss_seg: 0.2917  loss_ce_0: 0  loss_mask_0: 0.2058  loss_dice_0: 0.5711  loss_ce_1: 0  loss_mask_1: 0.2088  loss_dice_1: 0.5553  loss_ce_2: 0  loss_mask_2: 0.2089  loss_dice_2: 0.5524  loss_ce_3: 0  loss_mask_3: 0.2095  loss_dice_3: 0.5509  loss_ce_4: 0  loss_mask_4: 0.2085  loss_dice_4: 0.5516  loss_ce_5: 0  loss_mask_5: 0.209  loss_dice_5: 0.5522  loss_ce_6: 0  loss_mask_6: 0.2099  loss_dice_6: 0.5503  loss_ce_7: 0  loss_mask_7: 0.2097  loss_dice_7: 0.5508  loss_ce_8: 0  loss_mask_8: 0.2097  loss_dice_8: 0.5514  time: 1.6829  data_time: 0.0641  lr: 8.9832e-05  max_mem: 5916M
[02/24 15:50:59] d2.utils.events INFO:  eta: 1 day, 1:03:43  iter: 6759  total_loss: 8.037  loss_ce: 0  loss_mask: 0.207  loss_dice: 0.5495  loss_seg: 0.3129  loss_ce_0: 0  loss_mask_0: 0.2084  loss_dice_0: 0.5635  loss_ce_1: 0  loss_mask_1: 0.2074  loss_dice_1: 0.5476  loss_ce_2: 0  loss_mask_2: 0.2084  loss_dice_2: 0.5455  loss_ce_3: 0  loss_mask_3: 0.2068  loss_dice_3: 0.5441  loss_ce_4: 0  loss_mask_4: 0.2072  loss_dice_4: 0.544  loss_ce_5: 0  loss_mask_5: 0.2078  loss_dice_5: 0.5436  loss_ce_6: 0  loss_mask_6: 0.2085  loss_dice_6: 0.5425  loss_ce_7: 0  loss_mask_7: 0.208  loss_dice_7: 0.5444  loss_ce_8: 0  loss_mask_8: 0.208  loss_dice_8: 0.5456  time: 1.6834  data_time: 0.0589  lr: 8.9802e-05  max_mem: 5916M
[02/24 15:51:35] d2.utils.events INFO:  eta: 1 day, 1:05:06  iter: 6779  total_loss: 7.615  loss_ce: 0  loss_mask: 0.2045  loss_dice: 0.5387  loss_seg: 0.3154  loss_ce_0: 0  loss_mask_0: 0.2047  loss_dice_0: 0.5456  loss_ce_1: 0  loss_mask_1: 0.2042  loss_dice_1: 0.5379  loss_ce_2: 0  loss_mask_2: 0.2048  loss_dice_2: 0.5349  loss_ce_3: 0  loss_mask_3: 0.2042  loss_dice_3: 0.5336  loss_ce_4: 0  loss_mask_4: 0.2055  loss_dice_4: 0.5334  loss_ce_5: 0  loss_mask_5: 0.2065  loss_dice_5: 0.5355  loss_ce_6: 0  loss_mask_6: 0.2047  loss_dice_6: 0.5342  loss_ce_7: 0  loss_mask_7: 0.2056  loss_dice_7: 0.5341  loss_ce_8: 0  loss_mask_8: 0.2041  loss_dice_8: 0.5342  time: 1.6837  data_time: 0.0564  lr: 8.9772e-05  max_mem: 5916M
[02/24 15:52:10] d2.utils.events INFO:  eta: 1 day, 1:04:11  iter: 6799  total_loss: 7.818  loss_ce: 0  loss_mask: 0.2052  loss_dice: 0.5442  loss_seg: 0.3016  loss_ce_0: 0  loss_mask_0: 0.2052  loss_dice_0: 0.5574  loss_ce_1: 0  loss_mask_1: 0.2043  loss_dice_1: 0.5432  loss_ce_2: 0  loss_mask_2: 0.2054  loss_dice_2: 0.5408  loss_ce_3: 0  loss_mask_3: 0.2056  loss_dice_3: 0.5394  loss_ce_4: 0  loss_mask_4: 0.2057  loss_dice_4: 0.5398  loss_ce_5: 0  loss_mask_5: 0.2054  loss_dice_5: 0.5398  loss_ce_6: 0  loss_mask_6: 0.2065  loss_dice_6: 0.5393  loss_ce_7: 0  loss_mask_7: 0.2068  loss_dice_7: 0.5388  loss_ce_8: 0  loss_mask_8: 0.207  loss_dice_8: 0.5383  time: 1.6839  data_time: 0.0635  lr: 8.9741e-05  max_mem: 5916M
[02/24 15:52:45] d2.utils.events INFO:  eta: 1 day, 1:06:35  iter: 6819  total_loss: 7.772  loss_ce: 0  loss_mask: 0.2  loss_dice: 0.5431  loss_seg: 0.286  loss_ce_0: 0  loss_mask_0: 0.202  loss_dice_0: 0.5525  loss_ce_1: 0  loss_mask_1: 0.2015  loss_dice_1: 0.5424  loss_ce_2: 0  loss_mask_2: 0.2014  loss_dice_2: 0.5387  loss_ce_3: 0  loss_mask_3: 0.2022  loss_dice_3: 0.5375  loss_ce_4: 0  loss_mask_4: 0.2008  loss_dice_4: 0.5378  loss_ce_5: 0  loss_mask_5: 0.2007  loss_dice_5: 0.539  loss_ce_6: 0  loss_mask_6: 0.2027  loss_dice_6: 0.5371  loss_ce_7: 0  loss_mask_7: 0.201  loss_dice_7: 0.5386  loss_ce_8: 0  loss_mask_8: 0.2014  loss_dice_8: 0.5397  time: 1.6841  data_time: 0.0582  lr: 8.9711e-05  max_mem: 5916M
[02/24 15:53:19] d2.utils.events INFO:  eta: 1 day, 1:04:56  iter: 6839  total_loss: 7.622  loss_ce: 0  loss_mask: 0.2108  loss_dice: 0.5297  loss_seg: 0.2773  loss_ce_0: 0  loss_mask_0: 0.2089  loss_dice_0: 0.536  loss_ce_1: 0  loss_mask_1: 0.2084  loss_dice_1: 0.5279  loss_ce_2: 0  loss_mask_2: 0.2088  loss_dice_2: 0.5261  loss_ce_3: 0  loss_mask_3: 0.2095  loss_dice_3: 0.5234  loss_ce_4: 0  loss_mask_4: 0.2083  loss_dice_4: 0.525  loss_ce_5: 0  loss_mask_5: 0.2085  loss_dice_5: 0.5256  loss_ce_6: 0  loss_mask_6: 0.2092  loss_dice_6: 0.5254  loss_ce_7: 0  loss_mask_7: 0.2089  loss_dice_7: 0.5255  loss_ce_8: 0  loss_mask_8: 0.2094  loss_dice_8: 0.526  time: 1.6841  data_time: 0.0598  lr: 8.968e-05  max_mem: 5916M
[02/24 15:53:59] d2.utils.events INFO:  eta: 1 day, 1:09:49  iter: 6859  total_loss: 7.83  loss_ce: 0  loss_mask: 0.2032  loss_dice: 0.5468  loss_seg: 0.2947  loss_ce_0: 0  loss_mask_0: 0.1983  loss_dice_0: 0.5561  loss_ce_1: 0  loss_mask_1: 0.2032  loss_dice_1: 0.5453  loss_ce_2: 0  loss_mask_2: 0.2033  loss_dice_2: 0.5441  loss_ce_3: 0  loss_mask_3: 0.2019  loss_dice_3: 0.5425  loss_ce_4: 0  loss_mask_4: 0.2035  loss_dice_4: 0.5417  loss_ce_5: 0  loss_mask_5: 0.2022  loss_dice_5: 0.5424  loss_ce_6: 0  loss_mask_6: 0.2029  loss_dice_6: 0.5428  loss_ce_7: 0  loss_mask_7: 0.2037  loss_dice_7: 0.5435  loss_ce_8: 0  loss_mask_8: 0.2035  loss_dice_8: 0.5442  time: 1.6851  data_time: 0.0729  lr: 8.965e-05  max_mem: 5916M
[02/24 15:54:34] d2.utils.events INFO:  eta: 1 day, 1:07:53  iter: 6879  total_loss: 7.859  loss_ce: 0  loss_mask: 0.2104  loss_dice: 0.559  loss_seg: 0.3128  loss_ce_0: 0  loss_mask_0: 0.2054  loss_dice_0: 0.5681  loss_ce_1: 0  loss_mask_1: 0.2083  loss_dice_1: 0.5557  loss_ce_2: 0  loss_mask_2: 0.2087  loss_dice_2: 0.5544  loss_ce_3: 0  loss_mask_3: 0.2094  loss_dice_3: 0.5526  loss_ce_4: 0  loss_mask_4: 0.2087  loss_dice_4: 0.5537  loss_ce_5: 0  loss_mask_5: 0.2088  loss_dice_5: 0.5531  loss_ce_6: 0  loss_mask_6: 0.2096  loss_dice_6: 0.5533  loss_ce_7: 0  loss_mask_7: 0.2097  loss_dice_7: 0.5545  loss_ce_8: 0  loss_mask_8: 0.2089  loss_dice_8: 0.5545  time: 1.6852  data_time: 0.0586  lr: 8.962e-05  max_mem: 5916M
[02/24 15:55:12] d2.utils.events INFO:  eta: 1 day, 1:09:36  iter: 6899  total_loss: 7.579  loss_ce: 0  loss_mask: 0.2048  loss_dice: 0.5306  loss_seg: 0.2911  loss_ce_0: 0  loss_mask_0: 0.2038  loss_dice_0: 0.551  loss_ce_1: 0  loss_mask_1: 0.2027  loss_dice_1: 0.5311  loss_ce_2: 0  loss_mask_2: 0.2026  loss_dice_2: 0.5274  loss_ce_3: 0  loss_mask_3: 0.2028  loss_dice_3: 0.5246  loss_ce_4: 0  loss_mask_4: 0.204  loss_dice_4: 0.5244  loss_ce_5: 0  loss_mask_5: 0.2031  loss_dice_5: 0.5246  loss_ce_6: 0  loss_mask_6: 0.2045  loss_dice_6: 0.525  loss_ce_7: 0  loss_mask_7: 0.2047  loss_dice_7: 0.5261  loss_ce_8: 0  loss_mask_8: 0.2042  loss_dice_8: 0.5266  time: 1.6858  data_time: 0.0595  lr: 8.9589e-05  max_mem: 5916M
[02/24 15:55:49] d2.utils.events INFO:  eta: 1 day, 1:11:30  iter: 6919  total_loss: 7.62  loss_ce: 0  loss_mask: 0.2061  loss_dice: 0.5243  loss_seg: 0.2885  loss_ce_0: 0  loss_mask_0: 0.2011  loss_dice_0: 0.5403  loss_ce_1: 0  loss_mask_1: 0.2046  loss_dice_1: 0.5218  loss_ce_2: 0  loss_mask_2: 0.2058  loss_dice_2: 0.5214  loss_ce_3: 0  loss_mask_3: 0.2063  loss_dice_3: 0.5191  loss_ce_4: 0  loss_mask_4: 0.2057  loss_dice_4: 0.5202  loss_ce_5: 0  loss_mask_5: 0.2071  loss_dice_5: 0.5197  loss_ce_6: 0  loss_mask_6: 0.2078  loss_dice_6: 0.5199  loss_ce_7: 0  loss_mask_7: 0.2074  loss_dice_7: 0.5211  loss_ce_8: 0  loss_mask_8: 0.2081  loss_dice_8: 0.5212  time: 1.6862  data_time: 0.0545  lr: 8.9559e-05  max_mem: 5916M
[02/24 15:56:27] d2.utils.events INFO:  eta: 1 day, 1:11:34  iter: 6939  total_loss: 7.922  loss_ce: 0  loss_mask: 0.2104  loss_dice: 0.5489  loss_seg: 0.3145  loss_ce_0: 0  loss_mask_0: 0.2075  loss_dice_0: 0.5615  loss_ce_1: 0  loss_mask_1: 0.2088  loss_dice_1: 0.5495  loss_ce_2: 0  loss_mask_2: 0.2079  loss_dice_2: 0.5476  loss_ce_3: 0  loss_mask_3: 0.2104  loss_dice_3: 0.5432  loss_ce_4: 0  loss_mask_4: 0.2097  loss_dice_4: 0.5444  loss_ce_5: 0  loss_mask_5: 0.2101  loss_dice_5: 0.5448  loss_ce_6: 0  loss_mask_6: 0.2102  loss_dice_6: 0.5452  loss_ce_7: 0  loss_mask_7: 0.2103  loss_dice_7: 0.5447  loss_ce_8: 0  loss_mask_8: 0.2108  loss_dice_8: 0.5457  time: 1.6868  data_time: 0.0587  lr: 8.9529e-05  max_mem: 5916M
[02/24 15:57:02] d2.utils.events INFO:  eta: 1 day, 1:11:47  iter: 6959  total_loss: 7.897  loss_ce: 0  loss_mask: 0.2163  loss_dice: 0.551  loss_seg: 0.2931  loss_ce_0: 0  loss_mask_0: 0.2179  loss_dice_0: 0.5586  loss_ce_1: 0  loss_mask_1: 0.2152  loss_dice_1: 0.5492  loss_ce_2: 0  loss_mask_2: 0.2154  loss_dice_2: 0.5472  loss_ce_3: 0  loss_mask_3: 0.2157  loss_dice_3: 0.5465  loss_ce_4: 0  loss_mask_4: 0.2153  loss_dice_4: 0.5461  loss_ce_5: 0  loss_mask_5: 0.2151  loss_dice_5: 0.5466  loss_ce_6: 0  loss_mask_6: 0.2151  loss_dice_6: 0.5464  loss_ce_7: 0  loss_mask_7: 0.2158  loss_dice_7: 0.5467  loss_ce_8: 0  loss_mask_8: 0.2167  loss_dice_8: 0.5465  time: 1.6870  data_time: 0.0581  lr: 8.9498e-05  max_mem: 5916M
[02/24 15:57:35] d2.utils.events INFO:  eta: 1 day, 1:11:37  iter: 6979  total_loss: 7.561  loss_ce: 0  loss_mask: 0.2016  loss_dice: 0.5215  loss_seg: 0.2815  loss_ce_0: 0  loss_mask_0: 0.2021  loss_dice_0: 0.5431  loss_ce_1: 0  loss_mask_1: 0.2009  loss_dice_1: 0.5213  loss_ce_2: 0  loss_mask_2: 0.2003  loss_dice_2: 0.5212  loss_ce_3: 0  loss_mask_3: 0.2006  loss_dice_3: 0.5206  loss_ce_4: 0  loss_mask_4: 0.2013  loss_dice_4: 0.5189  loss_ce_5: 0  loss_mask_5: 0.2011  loss_dice_5: 0.5193  loss_ce_6: 0  loss_mask_6: 0.2015  loss_dice_6: 0.5182  loss_ce_7: 0  loss_mask_7: 0.2006  loss_dice_7: 0.518  loss_ce_8: 0  loss_mask_8: 0.2015  loss_dice_8: 0.5192  time: 1.6869  data_time: 0.0638  lr: 8.9468e-05  max_mem: 5916M
[02/24 15:58:09] d2.utils.events INFO:  eta: 1 day, 1:10:09  iter: 6999  total_loss: 7.851  loss_ce: 0  loss_mask: 0.2112  loss_dice: 0.5274  loss_seg: 0.3153  loss_ce_0: 0  loss_mask_0: 0.2124  loss_dice_0: 0.5429  loss_ce_1: 0  loss_mask_1: 0.2093  loss_dice_1: 0.5276  loss_ce_2: 0  loss_mask_2: 0.21  loss_dice_2: 0.5248  loss_ce_3: 0  loss_mask_3: 0.2105  loss_dice_3: 0.5232  loss_ce_4: 0  loss_mask_4: 0.2113  loss_dice_4: 0.5224  loss_ce_5: 0  loss_mask_5: 0.2115  loss_dice_5: 0.5237  loss_ce_6: 0  loss_mask_6: 0.2104  loss_dice_6: 0.5239  loss_ce_7: 0  loss_mask_7: 0.2103  loss_dice_7: 0.5243  loss_ce_8: 0  loss_mask_8: 0.2095  loss_dice_8: 0.5252  time: 1.6869  data_time: 0.0631  lr: 8.9437e-05  max_mem: 5916M
[02/24 15:58:43] d2.utils.events INFO:  eta: 1 day, 1:09:05  iter: 7019  total_loss: 7.831  loss_ce: 0  loss_mask: 0.2062  loss_dice: 0.5426  loss_seg: 0.2954  loss_ce_0: 0  loss_mask_0: 0.2094  loss_dice_0: 0.5526  loss_ce_1: 0  loss_mask_1: 0.2086  loss_dice_1: 0.5413  loss_ce_2: 0  loss_mask_2: 0.208  loss_dice_2: 0.5383  loss_ce_3: 0  loss_mask_3: 0.2072  loss_dice_3: 0.538  loss_ce_4: 0  loss_mask_4: 0.2055  loss_dice_4: 0.5389  loss_ce_5: 0  loss_mask_5: 0.2056  loss_dice_5: 0.5384  loss_ce_6: 0  loss_mask_6: 0.2066  loss_dice_6: 0.5364  loss_ce_7: 0  loss_mask_7: 0.2074  loss_dice_7: 0.5385  loss_ce_8: 0  loss_mask_8: 0.2069  loss_dice_8: 0.5383  time: 1.6869  data_time: 0.0638  lr: 8.9407e-05  max_mem: 5916M
[02/24 15:59:21] d2.utils.events INFO:  eta: 1 day, 1:10:11  iter: 7039  total_loss: 7.838  loss_ce: 0  loss_mask: 0.1877  loss_dice: 0.5546  loss_seg: 0.297  loss_ce_0: 0  loss_mask_0: 0.1913  loss_dice_0: 0.5637  loss_ce_1: 0  loss_mask_1: 0.1875  loss_dice_1: 0.5576  loss_ce_2: 0  loss_mask_2: 0.1886  loss_dice_2: 0.5558  loss_ce_3: 0  loss_mask_3: 0.1886  loss_dice_3: 0.554  loss_ce_4: 0  loss_mask_4: 0.1878  loss_dice_4: 0.5549  loss_ce_5: 0  loss_mask_5: 0.19  loss_dice_5: 0.5534  loss_ce_6: 0  loss_mask_6: 0.1902  loss_dice_6: 0.5529  loss_ce_7: 0  loss_mask_7: 0.189  loss_dice_7: 0.5534  loss_ce_8: 0  loss_mask_8: 0.189  loss_dice_8: 0.5533  time: 1.6874  data_time: 0.0694  lr: 8.9377e-05  max_mem: 5916M
[02/24 15:59:58] d2.utils.events INFO:  eta: 1 day, 1:14:23  iter: 7059  total_loss: 7.748  loss_ce: 0  loss_mask: 0.2048  loss_dice: 0.5408  loss_seg: 0.292  loss_ce_0: 0  loss_mask_0: 0.2051  loss_dice_0: 0.5527  loss_ce_1: 0  loss_mask_1: 0.204  loss_dice_1: 0.5395  loss_ce_2: 0  loss_mask_2: 0.2037  loss_dice_2: 0.536  loss_ce_3: 0  loss_mask_3: 0.2054  loss_dice_3: 0.5348  loss_ce_4: 0  loss_mask_4: 0.2047  loss_dice_4: 0.5354  loss_ce_5: 0  loss_mask_5: 0.2048  loss_dice_5: 0.5351  loss_ce_6: 0  loss_mask_6: 0.2048  loss_dice_6: 0.5364  loss_ce_7: 0  loss_mask_7: 0.2044  loss_dice_7: 0.5367  loss_ce_8: 0  loss_mask_8: 0.2054  loss_dice_8: 0.5361  time: 1.6880  data_time: 0.0647  lr: 8.9346e-05  max_mem: 5916M
[02/24 16:00:36] d2.utils.events INFO:  eta: 1 day, 1:18:13  iter: 7079  total_loss: 7.765  loss_ce: 0  loss_mask: 0.2071  loss_dice: 0.5397  loss_seg: 0.2635  loss_ce_0: 0  loss_mask_0: 0.1948  loss_dice_0: 0.5543  loss_ce_1: 0  loss_mask_1: 0.206  loss_dice_1: 0.54  loss_ce_2: 0  loss_mask_2: 0.2063  loss_dice_2: 0.5368  loss_ce_3: 0  loss_mask_3: 0.2061  loss_dice_3: 0.534  loss_ce_4: 0  loss_mask_4: 0.205  loss_dice_4: 0.5353  loss_ce_5: 0  loss_mask_5: 0.2056  loss_dice_5: 0.534  loss_ce_6: 0  loss_mask_6: 0.2061  loss_dice_6: 0.534  loss_ce_7: 0  loss_mask_7: 0.2055  loss_dice_7: 0.5367  loss_ce_8: 0  loss_mask_8: 0.205  loss_dice_8: 0.5372  time: 1.6886  data_time: 0.0576  lr: 8.9316e-05  max_mem: 5916M
[02/24 16:01:14] d2.utils.events INFO:  eta: 1 day, 1:20:13  iter: 7099  total_loss: 7.811  loss_ce: 0  loss_mask: 0.2085  loss_dice: 0.5363  loss_seg: 0.2979  loss_ce_0: 0  loss_mask_0: 0.2091  loss_dice_0: 0.546  loss_ce_1: 0  loss_mask_1: 0.2085  loss_dice_1: 0.5329  loss_ce_2: 0  loss_mask_2: 0.2087  loss_dice_2: 0.5314  loss_ce_3: 0  loss_mask_3: 0.2084  loss_dice_3: 0.5305  loss_ce_4: 0  loss_mask_4: 0.2085  loss_dice_4: 0.5316  loss_ce_5: 0  loss_mask_5: 0.208  loss_dice_5: 0.5322  loss_ce_6: 0  loss_mask_6: 0.2099  loss_dice_6: 0.5308  loss_ce_7: 0  loss_mask_7: 0.2074  loss_dice_7: 0.5313  loss_ce_8: 0  loss_mask_8: 0.2073  loss_dice_8: 0.5331  time: 1.6891  data_time: 0.0636  lr: 8.9286e-05  max_mem: 5916M
[02/24 16:01:48] d2.utils.events INFO:  eta: 1 day, 1:19:39  iter: 7119  total_loss: 7.636  loss_ce: 0  loss_mask: 0.2002  loss_dice: 0.5226  loss_seg: 0.2735  loss_ce_0: 0  loss_mask_0: 0.1994  loss_dice_0: 0.536  loss_ce_1: 0  loss_mask_1: 0.2016  loss_dice_1: 0.5212  loss_ce_2: 0  loss_mask_2: 0.2025  loss_dice_2: 0.5182  loss_ce_3: 0  loss_mask_3: 0.2005  loss_dice_3: 0.5191  loss_ce_4: 0  loss_mask_4: 0.2012  loss_dice_4: 0.5197  loss_ce_5: 0  loss_mask_5: 0.2022  loss_dice_5: 0.5182  loss_ce_6: 0  loss_mask_6: 0.2015  loss_dice_6: 0.5192  loss_ce_7: 0  loss_mask_7: 0.2018  loss_dice_7: 0.5191  loss_ce_8: 0  loss_mask_8: 0.2017  loss_dice_8: 0.5202  time: 1.6890  data_time: 0.0575  lr: 8.9255e-05  max_mem: 5916M
[02/24 16:02:22] d2.utils.events INFO:  eta: 1 day, 1:18:48  iter: 7139  total_loss: 7.782  loss_ce: 0  loss_mask: 0.213  loss_dice: 0.5386  loss_seg: 0.2814  loss_ce_0: 0  loss_mask_0: 0.2147  loss_dice_0: 0.5517  loss_ce_1: 0  loss_mask_1: 0.2112  loss_dice_1: 0.5415  loss_ce_2: 0  loss_mask_2: 0.2118  loss_dice_2: 0.5378  loss_ce_3: 0  loss_mask_3: 0.2125  loss_dice_3: 0.5368  loss_ce_4: 0  loss_mask_4: 0.213  loss_dice_4: 0.5344  loss_ce_5: 0  loss_mask_5: 0.2119  loss_dice_5: 0.5355  loss_ce_6: 0  loss_mask_6: 0.2126  loss_dice_6: 0.5357  loss_ce_7: 0  loss_mask_7: 0.2128  loss_dice_7: 0.5364  loss_ce_8: 0  loss_mask_8: 0.2138  loss_dice_8: 0.5351  time: 1.6891  data_time: 0.0598  lr: 8.9225e-05  max_mem: 5916M
[02/24 16:02:56] d2.utils.events INFO:  eta: 1 day, 1:18:13  iter: 7159  total_loss: 7.808  loss_ce: 0  loss_mask: 0.2072  loss_dice: 0.5397  loss_seg: 0.3007  loss_ce_0: 0  loss_mask_0: 0.2051  loss_dice_0: 0.5556  loss_ce_1: 0  loss_mask_1: 0.2041  loss_dice_1: 0.5374  loss_ce_2: 0  loss_mask_2: 0.2057  loss_dice_2: 0.5363  loss_ce_3: 0  loss_mask_3: 0.207  loss_dice_3: 0.5341  loss_ce_4: 0  loss_mask_4: 0.2072  loss_dice_4: 0.5358  loss_ce_5: 0  loss_mask_5: 0.208  loss_dice_5: 0.5372  loss_ce_6: 0  loss_mask_6: 0.2084  loss_dice_6: 0.5354  loss_ce_7: 0  loss_mask_7: 0.2078  loss_dice_7: 0.536  loss_ce_8: 0  loss_mask_8: 0.2075  loss_dice_8: 0.5375  time: 1.6891  data_time: 0.0535  lr: 8.9194e-05  max_mem: 5916M
[02/24 16:03:33] d2.utils.events INFO:  eta: 1 day, 1:21:58  iter: 7179  total_loss: 7.78  loss_ce: 0  loss_mask: 0.2027  loss_dice: 0.5422  loss_seg: 0.2881  loss_ce_0: 0  loss_mask_0: 0.2036  loss_dice_0: 0.5577  loss_ce_1: 0  loss_mask_1: 0.201  loss_dice_1: 0.5422  loss_ce_2: 0  loss_mask_2: 0.201  loss_dice_2: 0.5403  loss_ce_3: 0  loss_mask_3: 0.2019  loss_dice_3: 0.5394  loss_ce_4: 0  loss_mask_4: 0.2004  loss_dice_4: 0.5388  loss_ce_5: 0  loss_mask_5: 0.2006  loss_dice_5: 0.5399  loss_ce_6: 0  loss_mask_6: 0.2022  loss_dice_6: 0.5388  loss_ce_7: 0  loss_mask_7: 0.2012  loss_dice_7: 0.5393  loss_ce_8: 0  loss_mask_8: 0.2018  loss_dice_8: 0.5389  time: 1.6896  data_time: 0.0699  lr: 8.9164e-05  max_mem: 5916M
[02/24 16:04:16] d2.utils.events INFO:  eta: 1 day, 1:28:39  iter: 7199  total_loss: 7.588  loss_ce: 0  loss_mask: 0.1961  loss_dice: 0.5192  loss_seg: 0.3044  loss_ce_0: 0  loss_mask_0: 0.1912  loss_dice_0: 0.5312  loss_ce_1: 0  loss_mask_1: 0.1946  loss_dice_1: 0.5204  loss_ce_2: 0  loss_mask_2: 0.1947  loss_dice_2: 0.519  loss_ce_3: 0  loss_mask_3: 0.1965  loss_dice_3: 0.517  loss_ce_4: 0  loss_mask_4: 0.1971  loss_dice_4: 0.5162  loss_ce_5: 0  loss_mask_5: 0.1958  loss_dice_5: 0.5159  loss_ce_6: 0  loss_mask_6: 0.1972  loss_dice_6: 0.516  loss_ce_7: 0  loss_mask_7: 0.1962  loss_dice_7: 0.5168  loss_ce_8: 0  loss_mask_8: 0.1979  loss_dice_8: 0.5165  time: 1.6908  data_time: 0.0662  lr: 8.9134e-05  max_mem: 5916M
[02/24 16:05:04] d2.utils.events INFO:  eta: 1 day, 1:29:23  iter: 7219  total_loss: 7.89  loss_ce: 0  loss_mask: 0.2099  loss_dice: 0.5428  loss_seg: 0.3165  loss_ce_0: 0  loss_mask_0: 0.2096  loss_dice_0: 0.5582  loss_ce_1: 0  loss_mask_1: 0.2085  loss_dice_1: 0.5444  loss_ce_2: 0  loss_mask_2: 0.2084  loss_dice_2: 0.5425  loss_ce_3: 0  loss_mask_3: 0.2091  loss_dice_3: 0.5407  loss_ce_4: 0  loss_mask_4: 0.208  loss_dice_4: 0.5403  loss_ce_5: 0  loss_mask_5: 0.208  loss_dice_5: 0.5411  loss_ce_6: 0  loss_mask_6: 0.2078  loss_dice_6: 0.5406  loss_ce_7: 0  loss_mask_7: 0.2078  loss_dice_7: 0.5411  loss_ce_8: 0  loss_mask_8: 0.2081  loss_dice_8: 0.5397  time: 1.6928  data_time: 0.0723  lr: 8.9103e-05  max_mem: 5916M
[02/24 16:05:55] d2.utils.events INFO:  eta: 1 day, 1:34:31  iter: 7239  total_loss: 7.474  loss_ce: 0  loss_mask: 0.2007  loss_dice: 0.5218  loss_seg: 0.2512  loss_ce_0: 0  loss_mask_0: 0.1995  loss_dice_0: 0.5342  loss_ce_1: 0  loss_mask_1: 0.1988  loss_dice_1: 0.5191  loss_ce_2: 0  loss_mask_2: 0.1994  loss_dice_2: 0.517  loss_ce_3: 0  loss_mask_3: 0.1999  loss_dice_3: 0.5146  loss_ce_4: 0  loss_mask_4: 0.2  loss_dice_4: 0.5154  loss_ce_5: 0  loss_mask_5: 0.2  loss_dice_5: 0.5159  loss_ce_6: 0  loss_mask_6: 0.2003  loss_dice_6: 0.5172  loss_ce_7: 0  loss_mask_7: 0.2002  loss_dice_7: 0.5167  loss_ce_8: 0  loss_mask_8: 0.2012  loss_dice_8: 0.5166  time: 1.6950  data_time: 0.0842  lr: 8.9073e-05  max_mem: 5916M
[02/24 16:06:47] d2.utils.events INFO:  eta: 1 day, 1:40:56  iter: 7259  total_loss: 7.492  loss_ce: 0  loss_mask: 0.2036  loss_dice: 0.5311  loss_seg: 0.2644  loss_ce_0: 0  loss_mask_0: 0.2015  loss_dice_0: 0.5458  loss_ce_1: 0  loss_mask_1: 0.2026  loss_dice_1: 0.5305  loss_ce_2: 0  loss_mask_2: 0.2028  loss_dice_2: 0.5289  loss_ce_3: 0  loss_mask_3: 0.2033  loss_dice_3: 0.528  loss_ce_4: 0  loss_mask_4: 0.2027  loss_dice_4: 0.5285  loss_ce_5: 0  loss_mask_5: 0.2026  loss_dice_5: 0.5304  loss_ce_6: 0  loss_mask_6: 0.2034  loss_dice_6: 0.5285  loss_ce_7: 0  loss_mask_7: 0.2031  loss_dice_7: 0.5301  loss_ce_8: 0  loss_mask_8: 0.2031  loss_dice_8: 0.5299  time: 1.6975  data_time: 0.0911  lr: 8.9043e-05  max_mem: 5916M
[02/24 16:07:45] d2.utils.events INFO:  eta: 1 day, 1:43:34  iter: 7279  total_loss: 7.823  loss_ce: 0  loss_mask: 0.2105  loss_dice: 0.5431  loss_seg: 0.3145  loss_ce_0: 0  loss_mask_0: 0.2103  loss_dice_0: 0.5578  loss_ce_1: 0  loss_mask_1: 0.2077  loss_dice_1: 0.5423  loss_ce_2: 0  loss_mask_2: 0.2074  loss_dice_2: 0.5429  loss_ce_3: 0  loss_mask_3: 0.2083  loss_dice_3: 0.5404  loss_ce_4: 0  loss_mask_4: 0.2077  loss_dice_4: 0.5418  loss_ce_5: 0  loss_mask_5: 0.2067  loss_dice_5: 0.5416  loss_ce_6: 0  loss_mask_6: 0.2066  loss_dice_6: 0.5405  loss_ce_7: 0  loss_mask_7: 0.2066  loss_dice_7: 0.5421  loss_ce_8: 0  loss_mask_8: 0.2075  loss_dice_8: 0.5424  time: 1.7008  data_time: 0.0855  lr: 8.9012e-05  max_mem: 5916M
[02/24 16:08:51] d2.utils.events INFO:  eta: 1 day, 1:45:41  iter: 7299  total_loss: 7.687  loss_ce: 0  loss_mask: 0.2007  loss_dice: 0.5353  loss_seg: 0.2899  loss_ce_0: 0  loss_mask_0: 0.2002  loss_dice_0: 0.5516  loss_ce_1: 0  loss_mask_1: 0.1994  loss_dice_1: 0.5348  loss_ce_2: 0  loss_mask_2: 0.2002  loss_dice_2: 0.5344  loss_ce_3: 0  loss_mask_3: 0.2003  loss_dice_3: 0.5352  loss_ce_4: 0  loss_mask_4: 0.2015  loss_dice_4: 0.5341  loss_ce_5: 0  loss_mask_5: 0.2006  loss_dice_5: 0.5334  loss_ce_6: 0  loss_mask_6: 0.2009  loss_dice_6: 0.5344  loss_ce_7: 0  loss_mask_7: 0.2007  loss_dice_7: 0.5342  loss_ce_8: 0  loss_mask_8: 0.2006  loss_dice_8: 0.5341  time: 1.7051  data_time: 0.0989  lr: 8.8982e-05  max_mem: 5916M
[02/24 16:10:02] d2.utils.events INFO:  eta: 1 day, 1:49:32  iter: 7319  total_loss: 7.561  loss_ce: 0  loss_mask: 0.2103  loss_dice: 0.514  loss_seg: 0.2872  loss_ce_0: 0  loss_mask_0: 0.2103  loss_dice_0: 0.5252  loss_ce_1: 0  loss_mask_1: 0.2101  loss_dice_1: 0.5162  loss_ce_2: 0  loss_mask_2: 0.2081  loss_dice_2: 0.5143  loss_ce_3: 0  loss_mask_3: 0.2085  loss_dice_3: 0.5126  loss_ce_4: 0  loss_mask_4: 0.2091  loss_dice_4: 0.5123  loss_ce_5: 0  loss_mask_5: 0.2094  loss_dice_5: 0.5107  loss_ce_6: 0  loss_mask_6: 0.2089  loss_dice_6: 0.5123  loss_ce_7: 0  loss_mask_7: 0.21  loss_dice_7: 0.5099  loss_ce_8: 0  loss_mask_8: 0.2101  loss_dice_8: 0.5111  time: 1.7101  data_time: 0.0947  lr: 8.8951e-05  max_mem: 5916M
[02/24 16:11:14] d2.utils.events INFO:  eta: 1 day, 1:56:27  iter: 7339  total_loss: 7.619  loss_ce: 0  loss_mask: 0.2082  loss_dice: 0.5324  loss_seg: 0.2898  loss_ce_0: 0  loss_mask_0: 0.2117  loss_dice_0: 0.5403  loss_ce_1: 0  loss_mask_1: 0.2068  loss_dice_1: 0.5317  loss_ce_2: 0  loss_mask_2: 0.2078  loss_dice_2: 0.5291  loss_ce_3: 0  loss_mask_3: 0.2079  loss_dice_3: 0.5259  loss_ce_4: 0  loss_mask_4: 0.2081  loss_dice_4: 0.5265  loss_ce_5: 0  loss_mask_5: 0.2087  loss_dice_5: 0.526  loss_ce_6: 0  loss_mask_6: 0.2087  loss_dice_6: 0.526  loss_ce_7: 0  loss_mask_7: 0.2085  loss_dice_7: 0.5278  loss_ce_8: 0  loss_mask_8: 0.2084  loss_dice_8: 0.5281  time: 1.7152  data_time: 0.1024  lr: 8.8921e-05  max_mem: 5916M
[02/24 16:12:24] d2.utils.events INFO:  eta: 1 day, 2:04:56  iter: 7359  total_loss: 7.621  loss_ce: 0  loss_mask: 0.2033  loss_dice: 0.5293  loss_seg: 0.2925  loss_ce_0: 0  loss_mask_0: 0.2017  loss_dice_0: 0.5498  loss_ce_1: 0  loss_mask_1: 0.203  loss_dice_1: 0.5303  loss_ce_2: 0  loss_mask_2: 0.204  loss_dice_2: 0.5276  loss_ce_3: 0  loss_mask_3: 0.2027  loss_dice_3: 0.5244  loss_ce_4: 0  loss_mask_4: 0.2032  loss_dice_4: 0.5257  loss_ce_5: 0  loss_mask_5: 0.2036  loss_dice_5: 0.5258  loss_ce_6: 0  loss_mask_6: 0.2041  loss_dice_6: 0.5257  loss_ce_7: 0  loss_mask_7: 0.204  loss_dice_7: 0.5257  loss_ce_8: 0  loss_mask_8: 0.2031  loss_dice_8: 0.5265  time: 1.7201  data_time: 0.1046  lr: 8.8891e-05  max_mem: 5916M
[02/24 16:13:35] d2.utils.events INFO:  eta: 1 day, 2:14:22  iter: 7379  total_loss: 7.463  loss_ce: 0  loss_mask: 0.196  loss_dice: 0.5126  loss_seg: 0.2838  loss_ce_0: 0  loss_mask_0: 0.1958  loss_dice_0: 0.5254  loss_ce_1: 0  loss_mask_1: 0.1961  loss_dice_1: 0.513  loss_ce_2: 0  loss_mask_2: 0.1957  loss_dice_2: 0.511  loss_ce_3: 0  loss_mask_3: 0.1951  loss_dice_3: 0.5084  loss_ce_4: 0  loss_mask_4: 0.1954  loss_dice_4: 0.5083  loss_ce_5: 0  loss_mask_5: 0.195  loss_dice_5: 0.5088  loss_ce_6: 0  loss_mask_6: 0.1956  loss_dice_6: 0.5093  loss_ce_7: 0  loss_mask_7: 0.1965  loss_dice_7: 0.5082  loss_ce_8: 0  loss_mask_8: 0.1962  loss_dice_8: 0.5099  time: 1.7249  data_time: 0.0923  lr: 8.886e-05  max_mem: 5916M
[02/24 16:14:47] d2.utils.events INFO:  eta: 1 day, 2:23:02  iter: 7399  total_loss: 7.452  loss_ce: 0  loss_mask: 0.1945  loss_dice: 0.5029  loss_seg: 0.3006  loss_ce_0: 0  loss_mask_0: 0.1921  loss_dice_0: 0.534  loss_ce_1: 0  loss_mask_1: 0.1938  loss_dice_1: 0.5063  loss_ce_2: 0  loss_mask_2: 0.1936  loss_dice_2: 0.5024  loss_ce_3: 0  loss_mask_3: 0.1943  loss_dice_3: 0.502  loss_ce_4: 0  loss_mask_4: 0.1941  loss_dice_4: 0.5031  loss_ce_5: 0  loss_mask_5: 0.1941  loss_dice_5: 0.5034  loss_ce_6: 0  loss_mask_6: 0.1944  loss_dice_6: 0.5025  loss_ce_7: 0  loss_mask_7: 0.194  loss_dice_7: 0.5012  loss_ce_8: 0  loss_mask_8: 0.1938  loss_dice_8: 0.5019  time: 1.7299  data_time: 0.1084  lr: 8.883e-05  max_mem: 5916M
[02/24 16:15:58] d2.utils.events INFO:  eta: 1 day, 2:29:26  iter: 7419  total_loss: 7.702  loss_ce: 0  loss_mask: 0.2058  loss_dice: 0.5382  loss_seg: 0.316  loss_ce_0: 0  loss_mask_0: 0.1994  loss_dice_0: 0.5414  loss_ce_1: 0  loss_mask_1: 0.2008  loss_dice_1: 0.5342  loss_ce_2: 0  loss_mask_2: 0.2019  loss_dice_2: 0.5328  loss_ce_3: 0  loss_mask_3: 0.2031  loss_dice_3: 0.5324  loss_ce_4: 0  loss_mask_4: 0.2029  loss_dice_4: 0.5326  loss_ce_5: 0  loss_mask_5: 0.2034  loss_dice_5: 0.531  loss_ce_6: 0  loss_mask_6: 0.2045  loss_dice_6: 0.5319  loss_ce_7: 0  loss_mask_7: 0.2027  loss_dice_7: 0.5318  loss_ce_8: 0  loss_mask_8: 0.2034  loss_dice_8: 0.5327  time: 1.7349  data_time: 0.1141  lr: 8.8799e-05  max_mem: 5916M
[02/24 16:17:10] d2.utils.events INFO:  eta: 1 day, 2:41:11  iter: 7439  total_loss: 7.574  loss_ce: 0  loss_mask: 0.2091  loss_dice: 0.5301  loss_seg: 0.2867  loss_ce_0: 0  loss_mask_0: 0.2077  loss_dice_0: 0.5474  loss_ce_1: 0  loss_mask_1: 0.2073  loss_dice_1: 0.5284  loss_ce_2: 0  loss_mask_2: 0.2083  loss_dice_2: 0.5269  loss_ce_3: 0  loss_mask_3: 0.2086  loss_dice_3: 0.5247  loss_ce_4: 0  loss_mask_4: 0.2083  loss_dice_4: 0.5259  loss_ce_5: 0  loss_mask_5: 0.2079  loss_dice_5: 0.5253  loss_ce_6: 0  loss_mask_6: 0.2095  loss_dice_6: 0.5257  loss_ce_7: 0  loss_mask_7: 0.2081  loss_dice_7: 0.5258  loss_ce_8: 0  loss_mask_8: 0.2089  loss_dice_8: 0.5268  time: 1.7398  data_time: 0.1229  lr: 8.8769e-05  max_mem: 5916M
[02/24 16:18:21] d2.utils.events INFO:  eta: 1 day, 2:48:06  iter: 7459  total_loss: 7.645  loss_ce: 0  loss_mask: 0.1968  loss_dice: 0.5385  loss_seg: 0.274  loss_ce_0: 0  loss_mask_0: 0.1972  loss_dice_0: 0.5503  loss_ce_1: 0  loss_mask_1: 0.1974  loss_dice_1: 0.537  loss_ce_2: 0  loss_mask_2: 0.1977  loss_dice_2: 0.5361  loss_ce_3: 0  loss_mask_3: 0.1983  loss_dice_3: 0.5378  loss_ce_4: 0  loss_mask_4: 0.1994  loss_dice_4: 0.5367  loss_ce_5: 0  loss_mask_5: 0.198  loss_dice_5: 0.5367  loss_ce_6: 0  loss_mask_6: 0.1983  loss_dice_6: 0.5375  loss_ce_7: 0  loss_mask_7: 0.1989  loss_dice_7: 0.5377  loss_ce_8: 0  loss_mask_8: 0.1985  loss_dice_8: 0.5356  time: 1.7447  data_time: 0.0964  lr: 8.8739e-05  max_mem: 5916M
[02/24 16:19:31] d2.utils.events INFO:  eta: 1 day, 3:04:42  iter: 7479  total_loss: 7.925  loss_ce: 0  loss_mask: 0.2121  loss_dice: 0.5595  loss_seg: 0.2781  loss_ce_0: 0  loss_mask_0: 0.2111  loss_dice_0: 0.566  loss_ce_1: 0  loss_mask_1: 0.2119  loss_dice_1: 0.5602  loss_ce_2: 0  loss_mask_2: 0.2119  loss_dice_2: 0.5556  loss_ce_3: 0  loss_mask_3: 0.2124  loss_dice_3: 0.553  loss_ce_4: 0  loss_mask_4: 0.2125  loss_dice_4: 0.5525  loss_ce_5: 0  loss_mask_5: 0.2123  loss_dice_5: 0.5536  loss_ce_6: 0  loss_mask_6: 0.2131  loss_dice_6: 0.5534  loss_ce_7: 0  loss_mask_7: 0.2142  loss_dice_7: 0.5541  loss_ce_8: 0  loss_mask_8: 0.2126  loss_dice_8: 0.555  time: 1.7493  data_time: 0.0914  lr: 8.8708e-05  max_mem: 5916M
[02/24 16:20:44] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/r101_48classes_fixedmatching_finesmoothl1_refinelayerdeltas_noauxsegloss/model_0007499.pth
[02/24 16:20:51] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[02/24 16:20:54] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[02/24 16:20:54] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[02/24 16:21:45] mask2former INFO: Inference done 11/1093. Dataloading: 0.0145 s/iter. Inference: 0.7717 s/iter. Eval: 0.5313 s/iter. Total: 1.3176 s/iter. ETA=0:23:45
[02/24 16:21:51] mask2former INFO: Inference done 15/1093. Dataloading: 0.0214 s/iter. Inference: 0.7718 s/iter. Eval: 0.5909 s/iter. Total: 1.3842 s/iter. ETA=0:24:52
[02/24 16:21:58] mask2former INFO: Inference done 19/1093. Dataloading: 0.0247 s/iter. Inference: 0.8482 s/iter. Eval: 0.6167 s/iter. Total: 1.4898 s/iter. ETA=0:26:40
[02/24 16:22:04] mask2former INFO: Inference done 24/1093. Dataloading: 0.0259 s/iter. Inference: 0.8051 s/iter. Eval: 0.5835 s/iter. Total: 1.4147 s/iter. ETA=0:25:12
[02/24 16:22:09] mask2former INFO: Inference done 28/1093. Dataloading: 0.0267 s/iter. Inference: 0.8108 s/iter. Eval: 0.5711 s/iter. Total: 1.4089 s/iter. ETA=0:25:00
[02/24 16:22:15] mask2former INFO: Inference done 32/1093. Dataloading: 0.0244 s/iter. Inference: 0.7914 s/iter. Eval: 0.5845 s/iter. Total: 1.4006 s/iter. ETA=0:24:46
[02/24 16:22:20] mask2former INFO: Inference done 36/1093. Dataloading: 0.0250 s/iter. Inference: 0.7984 s/iter. Eval: 0.5814 s/iter. Total: 1.4052 s/iter. ETA=0:24:45
[02/24 16:22:25] mask2former INFO: Inference done 39/1093. Dataloading: 0.0245 s/iter. Inference: 0.8053 s/iter. Eval: 0.5998 s/iter. Total: 1.4299 s/iter. ETA=0:25:07
[02/24 16:22:31] mask2former INFO: Inference done 43/1093. Dataloading: 0.0255 s/iter. Inference: 0.8061 s/iter. Eval: 0.5838 s/iter. Total: 1.4159 s/iter. ETA=0:24:46
[02/24 16:22:36] mask2former INFO: Inference done 47/1093. Dataloading: 0.0258 s/iter. Inference: 0.8014 s/iter. Eval: 0.5856 s/iter. Total: 1.4132 s/iter. ETA=0:24:38
[02/24 16:22:42] mask2former INFO: Inference done 51/1093. Dataloading: 0.0266 s/iter. Inference: 0.7869 s/iter. Eval: 0.6018 s/iter. Total: 1.4158 s/iter. ETA=0:24:35
[02/24 16:22:48] mask2former INFO: Inference done 55/1093. Dataloading: 0.0270 s/iter. Inference: 0.7770 s/iter. Eval: 0.6102 s/iter. Total: 1.4149 s/iter. ETA=0:24:28
[02/24 16:22:53] mask2former INFO: Inference done 59/1093. Dataloading: 0.0262 s/iter. Inference: 0.7795 s/iter. Eval: 0.5992 s/iter. Total: 1.4058 s/iter. ETA=0:24:13
[02/24 16:22:59] mask2former INFO: Inference done 63/1093. Dataloading: 0.0266 s/iter. Inference: 0.7837 s/iter. Eval: 0.6003 s/iter. Total: 1.4115 s/iter. ETA=0:24:13
[02/24 16:23:04] mask2former INFO: Inference done 67/1093. Dataloading: 0.0272 s/iter. Inference: 0.7809 s/iter. Eval: 0.5991 s/iter. Total: 1.4080 s/iter. ETA=0:24:04
[02/24 16:23:10] mask2former INFO: Inference done 71/1093. Dataloading: 0.0272 s/iter. Inference: 0.7832 s/iter. Eval: 0.5962 s/iter. Total: 1.4075 s/iter. ETA=0:23:58
[02/24 16:23:16] mask2former INFO: Inference done 76/1093. Dataloading: 0.0273 s/iter. Inference: 0.7832 s/iter. Eval: 0.5878 s/iter. Total: 1.3991 s/iter. ETA=0:23:42
[02/24 16:23:21] mask2former INFO: Inference done 80/1093. Dataloading: 0.0271 s/iter. Inference: 0.7855 s/iter. Eval: 0.5792 s/iter. Total: 1.3926 s/iter. ETA=0:23:30
[02/24 16:23:26] mask2former INFO: Inference done 84/1093. Dataloading: 0.0265 s/iter. Inference: 0.7824 s/iter. Eval: 0.5766 s/iter. Total: 1.3863 s/iter. ETA=0:23:18
[02/24 16:23:33] mask2former INFO: Inference done 88/1093. Dataloading: 0.0263 s/iter. Inference: 0.7877 s/iter. Eval: 0.5802 s/iter. Total: 1.3950 s/iter. ETA=0:23:21
[02/24 16:23:38] mask2former INFO: Inference done 92/1093. Dataloading: 0.0266 s/iter. Inference: 0.7832 s/iter. Eval: 0.5816 s/iter. Total: 1.3922 s/iter. ETA=0:23:13
[02/24 16:23:44] mask2former INFO: Inference done 96/1093. Dataloading: 0.0271 s/iter. Inference: 0.7855 s/iter. Eval: 0.5828 s/iter. Total: 1.3962 s/iter. ETA=0:23:12
[02/24 16:23:50] mask2former INFO: Inference done 100/1093. Dataloading: 0.0268 s/iter. Inference: 0.7910 s/iter. Eval: 0.5837 s/iter. Total: 1.4022 s/iter. ETA=0:23:12
[02/24 16:23:56] mask2former INFO: Inference done 106/1093. Dataloading: 0.0265 s/iter. Inference: 0.7806 s/iter. Eval: 0.5695 s/iter. Total: 1.3774 s/iter. ETA=0:22:39
[02/24 16:24:01] mask2former INFO: Inference done 110/1093. Dataloading: 0.0261 s/iter. Inference: 0.7780 s/iter. Eval: 0.5677 s/iter. Total: 1.3726 s/iter. ETA=0:22:29
[02/24 16:24:06] mask2former INFO: Inference done 113/1093. Dataloading: 0.0273 s/iter. Inference: 0.7846 s/iter. Eval: 0.5697 s/iter. Total: 1.3824 s/iter. ETA=0:22:34
[02/24 16:24:11] mask2former INFO: Inference done 116/1093. Dataloading: 0.0275 s/iter. Inference: 0.7918 s/iter. Eval: 0.5710 s/iter. Total: 1.3910 s/iter. ETA=0:22:39
[02/24 16:24:17] mask2former INFO: Inference done 120/1093. Dataloading: 0.0269 s/iter. Inference: 0.7928 s/iter. Eval: 0.5689 s/iter. Total: 1.3894 s/iter. ETA=0:22:31
[02/24 16:24:23] mask2former INFO: Inference done 125/1093. Dataloading: 0.0262 s/iter. Inference: 0.7897 s/iter. Eval: 0.5682 s/iter. Total: 1.3849 s/iter. ETA=0:22:20
[02/24 16:24:29] mask2former INFO: Inference done 130/1093. Dataloading: 0.0262 s/iter. Inference: 0.7862 s/iter. Eval: 0.5668 s/iter. Total: 1.3800 s/iter. ETA=0:22:08
[02/24 16:24:35] mask2former INFO: Inference done 134/1093. Dataloading: 0.0268 s/iter. Inference: 0.7896 s/iter. Eval: 0.5674 s/iter. Total: 1.3848 s/iter. ETA=0:22:07
[02/24 16:24:41] mask2former INFO: Inference done 138/1093. Dataloading: 0.0273 s/iter. Inference: 0.7905 s/iter. Eval: 0.5699 s/iter. Total: 1.3886 s/iter. ETA=0:22:06
[02/24 16:24:48] mask2former INFO: Inference done 142/1093. Dataloading: 0.0274 s/iter. Inference: 0.7922 s/iter. Eval: 0.5741 s/iter. Total: 1.3947 s/iter. ETA=0:22:06
[02/24 16:24:54] mask2former INFO: Inference done 146/1093. Dataloading: 0.0274 s/iter. Inference: 0.7936 s/iter. Eval: 0.5791 s/iter. Total: 1.4011 s/iter. ETA=0:22:06
[02/24 16:25:00] mask2former INFO: Inference done 150/1093. Dataloading: 0.0272 s/iter. Inference: 0.7948 s/iter. Eval: 0.5789 s/iter. Total: 1.4020 s/iter. ETA=0:22:02
[02/24 16:25:06] mask2former INFO: Inference done 154/1093. Dataloading: 0.0275 s/iter. Inference: 0.7934 s/iter. Eval: 0.5799 s/iter. Total: 1.4019 s/iter. ETA=0:21:56
[02/24 16:25:11] mask2former INFO: Inference done 158/1093. Dataloading: 0.0274 s/iter. Inference: 0.7920 s/iter. Eval: 0.5784 s/iter. Total: 1.3988 s/iter. ETA=0:21:47
[02/24 16:25:17] mask2former INFO: Inference done 162/1093. Dataloading: 0.0276 s/iter. Inference: 0.7940 s/iter. Eval: 0.5786 s/iter. Total: 1.4012 s/iter. ETA=0:21:44
[02/24 16:25:22] mask2former INFO: Inference done 166/1093. Dataloading: 0.0274 s/iter. Inference: 0.7907 s/iter. Eval: 0.5819 s/iter. Total: 1.4010 s/iter. ETA=0:21:38
[02/24 16:25:28] mask2former INFO: Inference done 169/1093. Dataloading: 0.0274 s/iter. Inference: 0.7939 s/iter. Eval: 0.5853 s/iter. Total: 1.4076 s/iter. ETA=0:21:40
[02/24 16:25:33] mask2former INFO: Inference done 172/1093. Dataloading: 0.0274 s/iter. Inference: 0.7974 s/iter. Eval: 0.5866 s/iter. Total: 1.4124 s/iter. ETA=0:21:40
[02/24 16:25:38] mask2former INFO: Inference done 176/1093. Dataloading: 0.0274 s/iter. Inference: 0.7973 s/iter. Eval: 0.5846 s/iter. Total: 1.4103 s/iter. ETA=0:21:33
[02/24 16:25:43] mask2former INFO: Inference done 180/1093. Dataloading: 0.0273 s/iter. Inference: 0.7975 s/iter. Eval: 0.5813 s/iter. Total: 1.4072 s/iter. ETA=0:21:24
[02/24 16:25:48] mask2former INFO: Inference done 184/1093. Dataloading: 0.0271 s/iter. Inference: 0.7965 s/iter. Eval: 0.5808 s/iter. Total: 1.4056 s/iter. ETA=0:21:17
[02/24 16:25:54] mask2former INFO: Inference done 189/1093. Dataloading: 0.0268 s/iter. Inference: 0.7906 s/iter. Eval: 0.5782 s/iter. Total: 1.3968 s/iter. ETA=0:21:02
[02/24 16:25:59] mask2former INFO: Inference done 193/1093. Dataloading: 0.0265 s/iter. Inference: 0.7883 s/iter. Eval: 0.5785 s/iter. Total: 1.3948 s/iter. ETA=0:20:55
[02/24 16:26:05] mask2former INFO: Inference done 197/1093. Dataloading: 0.0263 s/iter. Inference: 0.7886 s/iter. Eval: 0.5802 s/iter. Total: 1.3965 s/iter. ETA=0:20:51
[02/24 16:26:11] mask2former INFO: Inference done 201/1093. Dataloading: 0.0262 s/iter. Inference: 0.7891 s/iter. Eval: 0.5822 s/iter. Total: 1.3991 s/iter. ETA=0:20:47
[02/24 16:26:16] mask2former INFO: Inference done 205/1093. Dataloading: 0.0264 s/iter. Inference: 0.7892 s/iter. Eval: 0.5811 s/iter. Total: 1.3981 s/iter. ETA=0:20:41
[02/24 16:26:22] mask2former INFO: Inference done 209/1093. Dataloading: 0.0264 s/iter. Inference: 0.7861 s/iter. Eval: 0.5819 s/iter. Total: 1.3959 s/iter. ETA=0:20:33
[02/24 16:26:28] mask2former INFO: Inference done 214/1093. Dataloading: 0.0264 s/iter. Inference: 0.7837 s/iter. Eval: 0.5813 s/iter. Total: 1.3928 s/iter. ETA=0:20:24
[02/24 16:26:33] mask2former INFO: Inference done 218/1093. Dataloading: 0.0263 s/iter. Inference: 0.7833 s/iter. Eval: 0.5814 s/iter. Total: 1.3925 s/iter. ETA=0:20:18
[02/24 16:26:39] mask2former INFO: Inference done 221/1093. Dataloading: 0.0265 s/iter. Inference: 0.7853 s/iter. Eval: 0.5851 s/iter. Total: 1.3985 s/iter. ETA=0:20:19
[02/24 16:26:44] mask2former INFO: Inference done 224/1093. Dataloading: 0.0265 s/iter. Inference: 0.7882 s/iter. Eval: 0.5883 s/iter. Total: 1.4046 s/iter. ETA=0:20:20
[02/24 16:26:50] mask2former INFO: Inference done 228/1093. Dataloading: 0.0265 s/iter. Inference: 0.7881 s/iter. Eval: 0.5869 s/iter. Total: 1.4031 s/iter. ETA=0:20:13
[02/24 16:26:55] mask2former INFO: Inference done 233/1093. Dataloading: 0.0264 s/iter. Inference: 0.7859 s/iter. Eval: 0.5841 s/iter. Total: 1.3980 s/iter. ETA=0:20:02
[02/24 16:27:01] mask2former INFO: Inference done 237/1093. Dataloading: 0.0264 s/iter. Inference: 0.7866 s/iter. Eval: 0.5831 s/iter. Total: 1.3976 s/iter. ETA=0:19:56
[02/24 16:27:07] mask2former INFO: Inference done 241/1093. Dataloading: 0.0264 s/iter. Inference: 0.7897 s/iter. Eval: 0.5824 s/iter. Total: 1.4000 s/iter. ETA=0:19:52
[02/24 16:27:13] mask2former INFO: Inference done 244/1093. Dataloading: 0.0263 s/iter. Inference: 0.7933 s/iter. Eval: 0.5870 s/iter. Total: 1.4081 s/iter. ETA=0:19:55
[02/24 16:27:19] mask2former INFO: Inference done 248/1093. Dataloading: 0.0263 s/iter. Inference: 0.7939 s/iter. Eval: 0.5865 s/iter. Total: 1.4082 s/iter. ETA=0:19:49
[02/24 16:27:25] mask2former INFO: Inference done 252/1093. Dataloading: 0.0264 s/iter. Inference: 0.7948 s/iter. Eval: 0.5867 s/iter. Total: 1.4094 s/iter. ETA=0:19:45
[02/24 16:27:30] mask2former INFO: Inference done 255/1093. Dataloading: 0.0266 s/iter. Inference: 0.7970 s/iter. Eval: 0.5884 s/iter. Total: 1.4134 s/iter. ETA=0:19:44
[02/24 16:27:36] mask2former INFO: Inference done 259/1093. Dataloading: 0.0269 s/iter. Inference: 0.7954 s/iter. Eval: 0.5897 s/iter. Total: 1.4134 s/iter. ETA=0:19:38
[02/24 16:27:42] mask2former INFO: Inference done 264/1093. Dataloading: 0.0268 s/iter. Inference: 0.7928 s/iter. Eval: 0.5874 s/iter. Total: 1.4083 s/iter. ETA=0:19:27
[02/24 16:27:47] mask2former INFO: Inference done 267/1093. Dataloading: 0.0268 s/iter. Inference: 0.7955 s/iter. Eval: 0.5878 s/iter. Total: 1.4115 s/iter. ETA=0:19:25
[02/24 16:27:52] mask2former INFO: Inference done 271/1093. Dataloading: 0.0270 s/iter. Inference: 0.7940 s/iter. Eval: 0.5880 s/iter. Total: 1.4104 s/iter. ETA=0:19:19
[02/24 16:27:57] mask2former INFO: Inference done 274/1093. Dataloading: 0.0269 s/iter. Inference: 0.7964 s/iter. Eval: 0.5895 s/iter. Total: 1.4142 s/iter. ETA=0:19:18
[02/24 16:28:02] mask2former INFO: Inference done 278/1093. Dataloading: 0.0271 s/iter. Inference: 0.7940 s/iter. Eval: 0.5903 s/iter. Total: 1.4127 s/iter. ETA=0:19:11
[02/24 16:28:09] mask2former INFO: Inference done 282/1093. Dataloading: 0.0270 s/iter. Inference: 0.7947 s/iter. Eval: 0.5917 s/iter. Total: 1.4149 s/iter. ETA=0:19:07
[02/24 16:28:15] mask2former INFO: Inference done 286/1093. Dataloading: 0.0269 s/iter. Inference: 0.7972 s/iter. Eval: 0.5909 s/iter. Total: 1.4164 s/iter. ETA=0:19:03
[02/24 16:28:21] mask2former INFO: Inference done 290/1093. Dataloading: 0.0269 s/iter. Inference: 0.7995 s/iter. Eval: 0.5913 s/iter. Total: 1.4192 s/iter. ETA=0:18:59
[02/24 16:28:27] mask2former INFO: Inference done 294/1093. Dataloading: 0.0267 s/iter. Inference: 0.7980 s/iter. Eval: 0.5920 s/iter. Total: 1.4182 s/iter. ETA=0:18:53
[02/24 16:28:33] mask2former INFO: Inference done 298/1093. Dataloading: 0.0271 s/iter. Inference: 0.8010 s/iter. Eval: 0.5911 s/iter. Total: 1.4207 s/iter. ETA=0:18:49
[02/24 16:28:39] mask2former INFO: Inference done 302/1093. Dataloading: 0.0270 s/iter. Inference: 0.8009 s/iter. Eval: 0.5918 s/iter. Total: 1.4212 s/iter. ETA=0:18:44
[02/24 16:28:45] mask2former INFO: Inference done 306/1093. Dataloading: 0.0270 s/iter. Inference: 0.8011 s/iter. Eval: 0.5915 s/iter. Total: 1.4211 s/iter. ETA=0:18:38
[02/24 16:28:50] mask2former INFO: Inference done 310/1093. Dataloading: 0.0270 s/iter. Inference: 0.8023 s/iter. Eval: 0.5910 s/iter. Total: 1.4216 s/iter. ETA=0:18:33
[02/24 16:28:56] mask2former INFO: Inference done 314/1093. Dataloading: 0.0270 s/iter. Inference: 0.8024 s/iter. Eval: 0.5911 s/iter. Total: 1.4218 s/iter. ETA=0:18:27
[02/24 16:29:02] mask2former INFO: Inference done 318/1093. Dataloading: 0.0272 s/iter. Inference: 0.8032 s/iter. Eval: 0.5911 s/iter. Total: 1.4230 s/iter. ETA=0:18:22
[02/24 16:29:08] mask2former INFO: Inference done 323/1093. Dataloading: 0.0270 s/iter. Inference: 0.8007 s/iter. Eval: 0.5905 s/iter. Total: 1.4197 s/iter. ETA=0:18:13
[02/24 16:29:15] mask2former INFO: Inference done 327/1093. Dataloading: 0.0272 s/iter. Inference: 0.8025 s/iter. Eval: 0.5913 s/iter. Total: 1.4225 s/iter. ETA=0:18:09
[02/24 16:29:20] mask2former INFO: Inference done 330/1093. Dataloading: 0.0272 s/iter. Inference: 0.8055 s/iter. Eval: 0.5910 s/iter. Total: 1.4252 s/iter. ETA=0:18:07
[02/24 16:29:25] mask2former INFO: Inference done 334/1093. Dataloading: 0.0274 s/iter. Inference: 0.8037 s/iter. Eval: 0.5920 s/iter. Total: 1.4247 s/iter. ETA=0:18:01
[02/24 16:29:31] mask2former INFO: Inference done 339/1093. Dataloading: 0.0273 s/iter. Inference: 0.8025 s/iter. Eval: 0.5897 s/iter. Total: 1.4210 s/iter. ETA=0:17:51
[02/24 16:29:37] mask2former INFO: Inference done 343/1093. Dataloading: 0.0273 s/iter. Inference: 0.8011 s/iter. Eval: 0.5899 s/iter. Total: 1.4198 s/iter. ETA=0:17:44
[02/24 16:29:43] mask2former INFO: Inference done 347/1093. Dataloading: 0.0275 s/iter. Inference: 0.8023 s/iter. Eval: 0.5910 s/iter. Total: 1.4222 s/iter. ETA=0:17:40
[02/24 16:29:49] mask2former INFO: Inference done 350/1093. Dataloading: 0.0275 s/iter. Inference: 0.8037 s/iter. Eval: 0.5934 s/iter. Total: 1.4261 s/iter. ETA=0:17:39
[02/24 16:29:56] mask2former INFO: Inference done 355/1093. Dataloading: 0.0274 s/iter. Inference: 0.8032 s/iter. Eval: 0.5940 s/iter. Total: 1.4261 s/iter. ETA=0:17:32
[02/24 16:30:02] mask2former INFO: Inference done 359/1093. Dataloading: 0.0273 s/iter. Inference: 0.8036 s/iter. Eval: 0.5936 s/iter. Total: 1.4261 s/iter. ETA=0:17:26
[02/24 16:30:07] mask2former INFO: Inference done 363/1093. Dataloading: 0.0274 s/iter. Inference: 0.8021 s/iter. Eval: 0.5943 s/iter. Total: 1.4252 s/iter. ETA=0:17:20
[02/24 16:30:12] mask2former INFO: Inference done 367/1093. Dataloading: 0.0273 s/iter. Inference: 0.8018 s/iter. Eval: 0.5939 s/iter. Total: 1.4245 s/iter. ETA=0:17:14
[02/24 16:30:18] mask2former INFO: Inference done 372/1093. Dataloading: 0.0273 s/iter. Inference: 0.7993 s/iter. Eval: 0.5910 s/iter. Total: 1.4191 s/iter. ETA=0:17:03
[02/24 16:30:23] mask2former INFO: Inference done 375/1093. Dataloading: 0.0272 s/iter. Inference: 0.8006 s/iter. Eval: 0.5925 s/iter. Total: 1.4219 s/iter. ETA=0:17:00
[02/24 16:30:29] mask2former INFO: Inference done 380/1093. Dataloading: 0.0271 s/iter. Inference: 0.7984 s/iter. Eval: 0.5919 s/iter. Total: 1.4188 s/iter. ETA=0:16:51
[02/24 16:30:34] mask2former INFO: Inference done 384/1093. Dataloading: 0.0270 s/iter. Inference: 0.7995 s/iter. Eval: 0.5900 s/iter. Total: 1.4180 s/iter. ETA=0:16:45
[02/24 16:30:41] mask2former INFO: Inference done 389/1093. Dataloading: 0.0268 s/iter. Inference: 0.8001 s/iter. Eval: 0.5888 s/iter. Total: 1.4172 s/iter. ETA=0:16:37
[02/24 16:30:48] mask2former INFO: Inference done 393/1093. Dataloading: 0.0268 s/iter. Inference: 0.8012 s/iter. Eval: 0.5904 s/iter. Total: 1.4199 s/iter. ETA=0:16:33
[02/24 16:30:54] mask2former INFO: Inference done 397/1093. Dataloading: 0.0267 s/iter. Inference: 0.8016 s/iter. Eval: 0.5913 s/iter. Total: 1.4211 s/iter. ETA=0:16:29
[02/24 16:30:59] mask2former INFO: Inference done 400/1093. Dataloading: 0.0267 s/iter. Inference: 0.8027 s/iter. Eval: 0.5926 s/iter. Total: 1.4237 s/iter. ETA=0:16:26
[02/24 16:31:05] mask2former INFO: Inference done 404/1093. Dataloading: 0.0268 s/iter. Inference: 0.8034 s/iter. Eval: 0.5926 s/iter. Total: 1.4245 s/iter. ETA=0:16:21
[02/24 16:31:12] mask2former INFO: Inference done 409/1093. Dataloading: 0.0267 s/iter. Inference: 0.8039 s/iter. Eval: 0.5917 s/iter. Total: 1.4239 s/iter. ETA=0:16:13
[02/24 16:31:18] mask2former INFO: Inference done 412/1093. Dataloading: 0.0267 s/iter. Inference: 0.8056 s/iter. Eval: 0.5929 s/iter. Total: 1.4269 s/iter. ETA=0:16:11
[02/24 16:31:24] mask2former INFO: Inference done 416/1093. Dataloading: 0.0267 s/iter. Inference: 0.8065 s/iter. Eval: 0.5929 s/iter. Total: 1.4277 s/iter. ETA=0:16:06
[02/24 16:31:29] mask2former INFO: Inference done 419/1093. Dataloading: 0.0269 s/iter. Inference: 0.8070 s/iter. Eval: 0.5954 s/iter. Total: 1.4309 s/iter. ETA=0:16:04
[02/24 16:31:34] mask2former INFO: Inference done 422/1093. Dataloading: 0.0269 s/iter. Inference: 0.8079 s/iter. Eval: 0.5968 s/iter. Total: 1.4333 s/iter. ETA=0:16:01
[02/24 16:31:40] mask2former INFO: Inference done 426/1093. Dataloading: 0.0269 s/iter. Inference: 0.8080 s/iter. Eval: 0.5960 s/iter. Total: 1.4326 s/iter. ETA=0:15:55
[02/24 16:31:46] mask2former INFO: Inference done 431/1093. Dataloading: 0.0268 s/iter. Inference: 0.8073 s/iter. Eval: 0.5936 s/iter. Total: 1.4294 s/iter. ETA=0:15:46
[02/24 16:31:51] mask2former INFO: Inference done 435/1093. Dataloading: 0.0267 s/iter. Inference: 0.8068 s/iter. Eval: 0.5930 s/iter. Total: 1.4282 s/iter. ETA=0:15:39
[02/24 16:31:57] mask2former INFO: Inference done 440/1093. Dataloading: 0.0266 s/iter. Inference: 0.8058 s/iter. Eval: 0.5912 s/iter. Total: 1.4253 s/iter. ETA=0:15:30
[02/24 16:32:03] mask2former INFO: Inference done 444/1093. Dataloading: 0.0266 s/iter. Inference: 0.8054 s/iter. Eval: 0.5919 s/iter. Total: 1.4257 s/iter. ETA=0:15:25
[02/24 16:32:09] mask2former INFO: Inference done 448/1093. Dataloading: 0.0266 s/iter. Inference: 0.8069 s/iter. Eval: 0.5918 s/iter. Total: 1.4271 s/iter. ETA=0:15:20
[02/24 16:32:14] mask2former INFO: Inference done 452/1093. Dataloading: 0.0265 s/iter. Inference: 0.8070 s/iter. Eval: 0.5913 s/iter. Total: 1.4266 s/iter. ETA=0:15:14
[02/24 16:32:21] mask2former INFO: Inference done 456/1093. Dataloading: 0.0268 s/iter. Inference: 0.8063 s/iter. Eval: 0.5930 s/iter. Total: 1.4279 s/iter. ETA=0:15:09
[02/24 16:32:26] mask2former INFO: Inference done 460/1093. Dataloading: 0.0269 s/iter. Inference: 0.8061 s/iter. Eval: 0.5924 s/iter. Total: 1.4271 s/iter. ETA=0:15:03
[02/24 16:32:32] mask2former INFO: Inference done 464/1093. Dataloading: 0.0269 s/iter. Inference: 0.8071 s/iter. Eval: 0.5923 s/iter. Total: 1.4279 s/iter. ETA=0:14:58
[02/24 16:32:38] mask2former INFO: Inference done 468/1093. Dataloading: 0.0269 s/iter. Inference: 0.8068 s/iter. Eval: 0.5933 s/iter. Total: 1.4288 s/iter. ETA=0:14:52
[02/24 16:32:45] mask2former INFO: Inference done 473/1093. Dataloading: 0.0269 s/iter. Inference: 0.8053 s/iter. Eval: 0.5931 s/iter. Total: 1.4270 s/iter. ETA=0:14:44
[02/24 16:32:51] mask2former INFO: Inference done 477/1093. Dataloading: 0.0268 s/iter. Inference: 0.8051 s/iter. Eval: 0.5938 s/iter. Total: 1.4275 s/iter. ETA=0:14:39
[02/24 16:32:56] mask2former INFO: Inference done 481/1093. Dataloading: 0.0268 s/iter. Inference: 0.8054 s/iter. Eval: 0.5932 s/iter. Total: 1.4272 s/iter. ETA=0:14:33
[02/24 16:33:02] mask2former INFO: Inference done 486/1093. Dataloading: 0.0267 s/iter. Inference: 0.8033 s/iter. Eval: 0.5936 s/iter. Total: 1.4254 s/iter. ETA=0:14:25
[02/24 16:33:09] mask2former INFO: Inference done 490/1093. Dataloading: 0.0267 s/iter. Inference: 0.8047 s/iter. Eval: 0.5935 s/iter. Total: 1.4267 s/iter. ETA=0:14:20
[02/24 16:33:15] mask2former INFO: Inference done 494/1093. Dataloading: 0.0266 s/iter. Inference: 0.8059 s/iter. Eval: 0.5934 s/iter. Total: 1.4277 s/iter. ETA=0:14:15
[02/24 16:33:21] mask2former INFO: Inference done 498/1093. Dataloading: 0.0267 s/iter. Inference: 0.8052 s/iter. Eval: 0.5939 s/iter. Total: 1.4276 s/iter. ETA=0:14:09
[02/24 16:33:27] mask2former INFO: Inference done 502/1093. Dataloading: 0.0285 s/iter. Inference: 0.8058 s/iter. Eval: 0.5935 s/iter. Total: 1.4295 s/iter. ETA=0:14:04
[02/24 16:33:33] mask2former INFO: Inference done 506/1093. Dataloading: 0.0287 s/iter. Inference: 0.8051 s/iter. Eval: 0.5934 s/iter. Total: 1.4290 s/iter. ETA=0:13:58
[02/24 16:33:39] mask2former INFO: Inference done 510/1093. Dataloading: 0.0287 s/iter. Inference: 0.8056 s/iter. Eval: 0.5940 s/iter. Total: 1.4302 s/iter. ETA=0:13:53
[02/24 16:33:45] mask2former INFO: Inference done 514/1093. Dataloading: 0.0289 s/iter. Inference: 0.8052 s/iter. Eval: 0.5946 s/iter. Total: 1.4306 s/iter. ETA=0:13:48
[02/24 16:33:50] mask2former INFO: Inference done 517/1093. Dataloading: 0.0290 s/iter. Inference: 0.8057 s/iter. Eval: 0.5960 s/iter. Total: 1.4325 s/iter. ETA=0:13:45
[02/24 16:33:56] mask2former INFO: Inference done 521/1093. Dataloading: 0.0292 s/iter. Inference: 0.8061 s/iter. Eval: 0.5956 s/iter. Total: 1.4328 s/iter. ETA=0:13:39
[02/24 16:34:02] mask2former INFO: Inference done 526/1093. Dataloading: 0.0292 s/iter. Inference: 0.8048 s/iter. Eval: 0.5938 s/iter. Total: 1.4296 s/iter. ETA=0:13:30
[02/24 16:34:08] mask2former INFO: Inference done 530/1093. Dataloading: 0.0291 s/iter. Inference: 0.8051 s/iter. Eval: 0.5947 s/iter. Total: 1.4307 s/iter. ETA=0:13:25
[02/24 16:34:14] mask2former INFO: Inference done 534/1093. Dataloading: 0.0292 s/iter. Inference: 0.8049 s/iter. Eval: 0.5959 s/iter. Total: 1.4318 s/iter. ETA=0:13:20
[02/24 16:34:20] mask2former INFO: Inference done 538/1093. Dataloading: 0.0292 s/iter. Inference: 0.8046 s/iter. Eval: 0.5964 s/iter. Total: 1.4319 s/iter. ETA=0:13:14
[02/24 16:34:25] mask2former INFO: Inference done 541/1093. Dataloading: 0.0292 s/iter. Inference: 0.8053 s/iter. Eval: 0.5974 s/iter. Total: 1.4336 s/iter. ETA=0:13:11
[02/24 16:34:31] mask2former INFO: Inference done 544/1093. Dataloading: 0.0292 s/iter. Inference: 0.8079 s/iter. Eval: 0.5984 s/iter. Total: 1.4373 s/iter. ETA=0:13:09
[02/24 16:34:37] mask2former INFO: Inference done 548/1093. Dataloading: 0.0292 s/iter. Inference: 0.8082 s/iter. Eval: 0.5987 s/iter. Total: 1.4378 s/iter. ETA=0:13:03
[02/24 16:34:43] mask2former INFO: Inference done 552/1093. Dataloading: 0.0291 s/iter. Inference: 0.8087 s/iter. Eval: 0.5980 s/iter. Total: 1.4376 s/iter. ETA=0:12:57
[02/24 16:34:49] mask2former INFO: Inference done 556/1093. Dataloading: 0.0291 s/iter. Inference: 0.8088 s/iter. Eval: 0.5977 s/iter. Total: 1.4374 s/iter. ETA=0:12:51
[02/24 16:34:54] mask2former INFO: Inference done 560/1093. Dataloading: 0.0292 s/iter. Inference: 0.8087 s/iter. Eval: 0.5975 s/iter. Total: 1.4371 s/iter. ETA=0:12:45
[02/24 16:35:00] mask2former INFO: Inference done 564/1093. Dataloading: 0.0291 s/iter. Inference: 0.8084 s/iter. Eval: 0.5969 s/iter. Total: 1.4362 s/iter. ETA=0:12:39
[02/24 16:35:05] mask2former INFO: Inference done 568/1093. Dataloading: 0.0291 s/iter. Inference: 0.8087 s/iter. Eval: 0.5965 s/iter. Total: 1.4360 s/iter. ETA=0:12:33
[02/24 16:35:11] mask2former INFO: Inference done 572/1093. Dataloading: 0.0291 s/iter. Inference: 0.8080 s/iter. Eval: 0.5967 s/iter. Total: 1.4355 s/iter. ETA=0:12:27
[02/24 16:35:18] mask2former INFO: Inference done 576/1093. Dataloading: 0.0292 s/iter. Inference: 0.8097 s/iter. Eval: 0.5967 s/iter. Total: 1.4374 s/iter. ETA=0:12:23
[02/24 16:35:23] mask2former INFO: Inference done 580/1093. Dataloading: 0.0293 s/iter. Inference: 0.8097 s/iter. Eval: 0.5967 s/iter. Total: 1.4375 s/iter. ETA=0:12:17
[02/24 16:35:29] mask2former INFO: Inference done 583/1093. Dataloading: 0.0294 s/iter. Inference: 0.8109 s/iter. Eval: 0.5971 s/iter. Total: 1.4391 s/iter. ETA=0:12:13
[02/24 16:35:34] mask2former INFO: Inference done 586/1093. Dataloading: 0.0293 s/iter. Inference: 0.8122 s/iter. Eval: 0.5976 s/iter. Total: 1.4410 s/iter. ETA=0:12:10
[02/24 16:35:39] mask2former INFO: Inference done 589/1093. Dataloading: 0.0293 s/iter. Inference: 0.8134 s/iter. Eval: 0.5979 s/iter. Total: 1.4425 s/iter. ETA=0:12:07
[02/24 16:35:44] mask2former INFO: Inference done 592/1093. Dataloading: 0.0293 s/iter. Inference: 0.8144 s/iter. Eval: 0.5983 s/iter. Total: 1.4438 s/iter. ETA=0:12:03
[02/24 16:35:50] mask2former INFO: Inference done 596/1093. Dataloading: 0.0293 s/iter. Inference: 0.8139 s/iter. Eval: 0.5985 s/iter. Total: 1.4436 s/iter. ETA=0:11:57
[02/24 16:35:56] mask2former INFO: Inference done 600/1093. Dataloading: 0.0293 s/iter. Inference: 0.8137 s/iter. Eval: 0.5995 s/iter. Total: 1.4443 s/iter. ETA=0:11:52
[02/24 16:36:02] mask2former INFO: Inference done 604/1093. Dataloading: 0.0292 s/iter. Inference: 0.8130 s/iter. Eval: 0.6008 s/iter. Total: 1.4450 s/iter. ETA=0:11:46
[02/24 16:36:09] mask2former INFO: Inference done 608/1093. Dataloading: 0.0293 s/iter. Inference: 0.8130 s/iter. Eval: 0.6020 s/iter. Total: 1.4461 s/iter. ETA=0:11:41
[02/24 16:36:14] mask2former INFO: Inference done 612/1093. Dataloading: 0.0292 s/iter. Inference: 0.8127 s/iter. Eval: 0.6018 s/iter. Total: 1.4456 s/iter. ETA=0:11:35
[02/24 16:36:20] mask2former INFO: Inference done 616/1093. Dataloading: 0.0292 s/iter. Inference: 0.8137 s/iter. Eval: 0.6016 s/iter. Total: 1.4464 s/iter. ETA=0:11:29
[02/24 16:36:26] mask2former INFO: Inference done 619/1093. Dataloading: 0.0293 s/iter. Inference: 0.8145 s/iter. Eval: 0.6020 s/iter. Total: 1.4477 s/iter. ETA=0:11:26
[02/24 16:36:31] mask2former INFO: Inference done 623/1093. Dataloading: 0.0291 s/iter. Inference: 0.8146 s/iter. Eval: 0.6020 s/iter. Total: 1.4477 s/iter. ETA=0:11:20
[02/24 16:36:37] mask2former INFO: Inference done 626/1093. Dataloading: 0.0293 s/iter. Inference: 0.8154 s/iter. Eval: 0.6027 s/iter. Total: 1.4493 s/iter. ETA=0:11:16
[02/24 16:36:42] mask2former INFO: Inference done 629/1093. Dataloading: 0.0293 s/iter. Inference: 0.8158 s/iter. Eval: 0.6036 s/iter. Total: 1.4506 s/iter. ETA=0:11:13
[02/24 16:36:47] mask2former INFO: Inference done 632/1093. Dataloading: 0.0294 s/iter. Inference: 0.8171 s/iter. Eval: 0.6039 s/iter. Total: 1.4523 s/iter. ETA=0:11:09
[02/24 16:36:53] mask2former INFO: Inference done 636/1093. Dataloading: 0.0293 s/iter. Inference: 0.8171 s/iter. Eval: 0.6032 s/iter. Total: 1.4516 s/iter. ETA=0:11:03
[02/24 16:36:59] mask2former INFO: Inference done 640/1093. Dataloading: 0.0293 s/iter. Inference: 0.8174 s/iter. Eval: 0.6036 s/iter. Total: 1.4523 s/iter. ETA=0:10:57
[02/24 16:37:04] mask2former INFO: Inference done 644/1093. Dataloading: 0.0293 s/iter. Inference: 0.8166 s/iter. Eval: 0.6033 s/iter. Total: 1.4513 s/iter. ETA=0:10:51
[02/24 16:37:10] mask2former INFO: Inference done 648/1093. Dataloading: 0.0293 s/iter. Inference: 0.8167 s/iter. Eval: 0.6030 s/iter. Total: 1.4511 s/iter. ETA=0:10:45
[02/24 16:37:16] mask2former INFO: Inference done 652/1093. Dataloading: 0.0293 s/iter. Inference: 0.8175 s/iter. Eval: 0.6026 s/iter. Total: 1.4514 s/iter. ETA=0:10:40
[02/24 16:37:21] mask2former INFO: Inference done 657/1093. Dataloading: 0.0293 s/iter. Inference: 0.8158 s/iter. Eval: 0.6010 s/iter. Total: 1.4481 s/iter. ETA=0:10:31
[02/24 16:37:27] mask2former INFO: Inference done 661/1093. Dataloading: 0.0292 s/iter. Inference: 0.8155 s/iter. Eval: 0.6014 s/iter. Total: 1.4481 s/iter. ETA=0:10:25
[02/24 16:37:32] mask2former INFO: Inference done 664/1093. Dataloading: 0.0293 s/iter. Inference: 0.8157 s/iter. Eval: 0.6027 s/iter. Total: 1.4496 s/iter. ETA=0:10:21
[02/24 16:37:37] mask2former INFO: Inference done 667/1093. Dataloading: 0.0293 s/iter. Inference: 0.8158 s/iter. Eval: 0.6038 s/iter. Total: 1.4508 s/iter. ETA=0:10:18
[02/24 16:37:43] mask2former INFO: Inference done 670/1093. Dataloading: 0.0293 s/iter. Inference: 0.8166 s/iter. Eval: 0.6048 s/iter. Total: 1.4528 s/iter. ETA=0:10:14
[02/24 16:37:49] mask2former INFO: Inference done 674/1093. Dataloading: 0.0293 s/iter. Inference: 0.8164 s/iter. Eval: 0.6056 s/iter. Total: 1.4533 s/iter. ETA=0:10:08
[02/24 16:37:54] mask2former INFO: Inference done 678/1093. Dataloading: 0.0292 s/iter. Inference: 0.8166 s/iter. Eval: 0.6048 s/iter. Total: 1.4527 s/iter. ETA=0:10:02
[02/24 16:38:00] mask2former INFO: Inference done 683/1093. Dataloading: 0.0293 s/iter. Inference: 0.8152 s/iter. Eval: 0.6042 s/iter. Total: 1.4507 s/iter. ETA=0:09:54
[02/24 16:38:06] mask2former INFO: Inference done 687/1093. Dataloading: 0.0293 s/iter. Inference: 0.8153 s/iter. Eval: 0.6034 s/iter. Total: 1.4500 s/iter. ETA=0:09:48
[02/24 16:38:11] mask2former INFO: Inference done 691/1093. Dataloading: 0.0292 s/iter. Inference: 0.8156 s/iter. Eval: 0.6026 s/iter. Total: 1.4494 s/iter. ETA=0:09:42
[02/24 16:38:17] mask2former INFO: Inference done 695/1093. Dataloading: 0.0291 s/iter. Inference: 0.8155 s/iter. Eval: 0.6027 s/iter. Total: 1.4494 s/iter. ETA=0:09:36
[02/24 16:38:22] mask2former INFO: Inference done 699/1093. Dataloading: 0.0292 s/iter. Inference: 0.8148 s/iter. Eval: 0.6026 s/iter. Total: 1.4486 s/iter. ETA=0:09:30
[02/24 16:38:28] mask2former INFO: Inference done 703/1093. Dataloading: 0.0292 s/iter. Inference: 0.8147 s/iter. Eval: 0.6032 s/iter. Total: 1.4492 s/iter. ETA=0:09:25
[02/24 16:38:33] mask2former INFO: Inference done 706/1093. Dataloading: 0.0292 s/iter. Inference: 0.8158 s/iter. Eval: 0.6032 s/iter. Total: 1.4502 s/iter. ETA=0:09:21
[02/24 16:38:39] mask2former INFO: Inference done 710/1093. Dataloading: 0.0291 s/iter. Inference: 0.8158 s/iter. Eval: 0.6035 s/iter. Total: 1.4504 s/iter. ETA=0:09:15
[02/24 16:38:45] mask2former INFO: Inference done 714/1093. Dataloading: 0.0293 s/iter. Inference: 0.8169 s/iter. Eval: 0.6027 s/iter. Total: 1.4510 s/iter. ETA=0:09:09
[02/24 16:38:51] mask2former INFO: Inference done 718/1093. Dataloading: 0.0293 s/iter. Inference: 0.8169 s/iter. Eval: 0.6025 s/iter. Total: 1.4507 s/iter. ETA=0:09:04
[02/24 16:38:56] mask2former INFO: Inference done 721/1093. Dataloading: 0.0293 s/iter. Inference: 0.8174 s/iter. Eval: 0.6031 s/iter. Total: 1.4518 s/iter. ETA=0:09:00
[02/24 16:39:02] mask2former INFO: Inference done 726/1093. Dataloading: 0.0293 s/iter. Inference: 0.8168 s/iter. Eval: 0.6021 s/iter. Total: 1.4503 s/iter. ETA=0:08:52
[02/24 16:39:08] mask2former INFO: Inference done 730/1093. Dataloading: 0.0294 s/iter. Inference: 0.8171 s/iter. Eval: 0.6018 s/iter. Total: 1.4504 s/iter. ETA=0:08:46
[02/24 16:39:14] mask2former INFO: Inference done 734/1093. Dataloading: 0.0293 s/iter. Inference: 0.8176 s/iter. Eval: 0.6013 s/iter. Total: 1.4503 s/iter. ETA=0:08:40
[02/24 16:39:20] mask2former INFO: Inference done 737/1093. Dataloading: 0.0293 s/iter. Inference: 0.8189 s/iter. Eval: 0.6027 s/iter. Total: 1.4530 s/iter. ETA=0:08:37
[02/24 16:39:26] mask2former INFO: Inference done 741/1093. Dataloading: 0.0293 s/iter. Inference: 0.8192 s/iter. Eval: 0.6020 s/iter. Total: 1.4526 s/iter. ETA=0:08:31
[02/24 16:39:31] mask2former INFO: Inference done 745/1093. Dataloading: 0.0293 s/iter. Inference: 0.8186 s/iter. Eval: 0.6018 s/iter. Total: 1.4518 s/iter. ETA=0:08:25
[02/24 16:39:37] mask2former INFO: Inference done 749/1093. Dataloading: 0.0293 s/iter. Inference: 0.8186 s/iter. Eval: 0.6014 s/iter. Total: 1.4514 s/iter. ETA=0:08:19
[02/24 16:39:42] mask2former INFO: Inference done 753/1093. Dataloading: 0.0292 s/iter. Inference: 0.8186 s/iter. Eval: 0.6008 s/iter. Total: 1.4507 s/iter. ETA=0:08:13
[02/24 16:39:48] mask2former INFO: Inference done 758/1093. Dataloading: 0.0292 s/iter. Inference: 0.8177 s/iter. Eval: 0.6005 s/iter. Total: 1.4494 s/iter. ETA=0:08:05
[02/24 16:39:54] mask2former INFO: Inference done 762/1093. Dataloading: 0.0291 s/iter. Inference: 0.8186 s/iter. Eval: 0.6001 s/iter. Total: 1.4499 s/iter. ETA=0:07:59
[02/24 16:40:00] mask2former INFO: Inference done 766/1093. Dataloading: 0.0291 s/iter. Inference: 0.8184 s/iter. Eval: 0.6007 s/iter. Total: 1.4503 s/iter. ETA=0:07:54
[02/24 16:40:06] mask2former INFO: Inference done 769/1093. Dataloading: 0.0291 s/iter. Inference: 0.8191 s/iter. Eval: 0.6010 s/iter. Total: 1.4513 s/iter. ETA=0:07:50
[02/24 16:40:12] mask2former INFO: Inference done 774/1093. Dataloading: 0.0292 s/iter. Inference: 0.8181 s/iter. Eval: 0.6004 s/iter. Total: 1.4497 s/iter. ETA=0:07:42
[02/24 16:40:17] mask2former INFO: Inference done 778/1093. Dataloading: 0.0292 s/iter. Inference: 0.8177 s/iter. Eval: 0.6001 s/iter. Total: 1.4491 s/iter. ETA=0:07:36
[02/24 16:40:22] mask2former INFO: Inference done 782/1093. Dataloading: 0.0292 s/iter. Inference: 0.8175 s/iter. Eval: 0.5999 s/iter. Total: 1.4487 s/iter. ETA=0:07:30
[02/24 16:40:27] mask2former INFO: Inference done 785/1093. Dataloading: 0.0291 s/iter. Inference: 0.8184 s/iter. Eval: 0.6000 s/iter. Total: 1.4496 s/iter. ETA=0:07:26
[02/24 16:40:33] mask2former INFO: Inference done 788/1093. Dataloading: 0.0291 s/iter. Inference: 0.8195 s/iter. Eval: 0.6007 s/iter. Total: 1.4514 s/iter. ETA=0:07:22
[02/24 16:40:39] mask2former INFO: Inference done 792/1093. Dataloading: 0.0291 s/iter. Inference: 0.8201 s/iter. Eval: 0.6006 s/iter. Total: 1.4519 s/iter. ETA=0:07:17
[02/24 16:40:45] mask2former INFO: Inference done 796/1093. Dataloading: 0.0291 s/iter. Inference: 0.8202 s/iter. Eval: 0.6000 s/iter. Total: 1.4514 s/iter. ETA=0:07:11
[02/24 16:40:51] mask2former INFO: Inference done 801/1093. Dataloading: 0.0291 s/iter. Inference: 0.8185 s/iter. Eval: 0.5999 s/iter. Total: 1.4496 s/iter. ETA=0:07:03
[02/24 16:40:56] mask2former INFO: Inference done 805/1093. Dataloading: 0.0290 s/iter. Inference: 0.8183 s/iter. Eval: 0.6002 s/iter. Total: 1.4497 s/iter. ETA=0:06:57
[02/24 16:41:03] mask2former INFO: Inference done 809/1093. Dataloading: 0.0291 s/iter. Inference: 0.8187 s/iter. Eval: 0.6003 s/iter. Total: 1.4502 s/iter. ETA=0:06:51
[02/24 16:41:09] mask2former INFO: Inference done 813/1093. Dataloading: 0.0291 s/iter. Inference: 0.8186 s/iter. Eval: 0.6008 s/iter. Total: 1.4507 s/iter. ETA=0:06:46
[02/24 16:41:15] mask2former INFO: Inference done 818/1093. Dataloading: 0.0291 s/iter. Inference: 0.8184 s/iter. Eval: 0.5995 s/iter. Total: 1.4491 s/iter. ETA=0:06:38
[02/24 16:41:21] mask2former INFO: Inference done 822/1093. Dataloading: 0.0290 s/iter. Inference: 0.8182 s/iter. Eval: 0.6000 s/iter. Total: 1.4494 s/iter. ETA=0:06:32
[02/24 16:41:28] mask2former INFO: Inference done 826/1093. Dataloading: 0.0290 s/iter. Inference: 0.8196 s/iter. Eval: 0.5997 s/iter. Total: 1.4504 s/iter. ETA=0:06:27
[02/24 16:41:33] mask2former INFO: Inference done 831/1093. Dataloading: 0.0290 s/iter. Inference: 0.8187 s/iter. Eval: 0.5986 s/iter. Total: 1.4484 s/iter. ETA=0:06:19
[02/24 16:41:38] mask2former INFO: Inference done 835/1093. Dataloading: 0.0289 s/iter. Inference: 0.8188 s/iter. Eval: 0.5980 s/iter. Total: 1.4478 s/iter. ETA=0:06:13
[02/24 16:41:45] mask2former INFO: Inference done 839/1093. Dataloading: 0.0290 s/iter. Inference: 0.8186 s/iter. Eval: 0.5986 s/iter. Total: 1.4483 s/iter. ETA=0:06:07
[02/24 16:41:51] mask2former INFO: Inference done 843/1093. Dataloading: 0.0290 s/iter. Inference: 0.8189 s/iter. Eval: 0.5985 s/iter. Total: 1.4485 s/iter. ETA=0:06:02
[02/24 16:41:56] mask2former INFO: Inference done 847/1093. Dataloading: 0.0289 s/iter. Inference: 0.8182 s/iter. Eval: 0.5984 s/iter. Total: 1.4476 s/iter. ETA=0:05:56
[02/24 16:42:01] mask2former INFO: Inference done 851/1093. Dataloading: 0.0289 s/iter. Inference: 0.8184 s/iter. Eval: 0.5976 s/iter. Total: 1.4469 s/iter. ETA=0:05:50
[02/24 16:42:07] mask2former INFO: Inference done 855/1093. Dataloading: 0.0289 s/iter. Inference: 0.8185 s/iter. Eval: 0.5973 s/iter. Total: 1.4469 s/iter. ETA=0:05:44
[02/24 16:42:12] mask2former INFO: Inference done 859/1093. Dataloading: 0.0288 s/iter. Inference: 0.8177 s/iter. Eval: 0.5976 s/iter. Total: 1.4464 s/iter. ETA=0:05:38
[02/24 16:42:17] mask2former INFO: Inference done 863/1093. Dataloading: 0.0288 s/iter. Inference: 0.8176 s/iter. Eval: 0.5975 s/iter. Total: 1.4460 s/iter. ETA=0:05:32
[02/24 16:42:23] mask2former INFO: Inference done 867/1093. Dataloading: 0.0288 s/iter. Inference: 0.8174 s/iter. Eval: 0.5974 s/iter. Total: 1.4457 s/iter. ETA=0:05:26
[02/24 16:42:29] mask2former INFO: Inference done 871/1093. Dataloading: 0.0288 s/iter. Inference: 0.8174 s/iter. Eval: 0.5972 s/iter. Total: 1.4456 s/iter. ETA=0:05:20
[02/24 16:42:34] mask2former INFO: Inference done 875/1093. Dataloading: 0.0288 s/iter. Inference: 0.8179 s/iter. Eval: 0.5966 s/iter. Total: 1.4454 s/iter. ETA=0:05:15
[02/24 16:42:40] mask2former INFO: Inference done 879/1093. Dataloading: 0.0288 s/iter. Inference: 0.8181 s/iter. Eval: 0.5967 s/iter. Total: 1.4458 s/iter. ETA=0:05:09
[02/24 16:42:47] mask2former INFO: Inference done 883/1093. Dataloading: 0.0288 s/iter. Inference: 0.8185 s/iter. Eval: 0.5969 s/iter. Total: 1.4464 s/iter. ETA=0:05:03
[02/24 16:42:54] mask2former INFO: Inference done 887/1093. Dataloading: 0.0288 s/iter. Inference: 0.8195 s/iter. Eval: 0.5973 s/iter. Total: 1.4478 s/iter. ETA=0:04:58
[02/24 16:42:59] mask2former INFO: Inference done 891/1093. Dataloading: 0.0288 s/iter. Inference: 0.8192 s/iter. Eval: 0.5976 s/iter. Total: 1.4477 s/iter. ETA=0:04:52
[02/24 16:43:06] mask2former INFO: Inference done 895/1093. Dataloading: 0.0287 s/iter. Inference: 0.8198 s/iter. Eval: 0.5974 s/iter. Total: 1.4481 s/iter. ETA=0:04:46
[02/24 16:43:12] mask2former INFO: Inference done 900/1093. Dataloading: 0.0287 s/iter. Inference: 0.8192 s/iter. Eval: 0.5968 s/iter. Total: 1.4468 s/iter. ETA=0:04:39
[02/24 16:43:18] mask2former INFO: Inference done 904/1093. Dataloading: 0.0286 s/iter. Inference: 0.8193 s/iter. Eval: 0.5969 s/iter. Total: 1.4470 s/iter. ETA=0:04:33
[02/24 16:43:23] mask2former INFO: Inference done 908/1093. Dataloading: 0.0286 s/iter. Inference: 0.8191 s/iter. Eval: 0.5970 s/iter. Total: 1.4468 s/iter. ETA=0:04:27
[02/24 16:43:29] mask2former INFO: Inference done 913/1093. Dataloading: 0.0286 s/iter. Inference: 0.8187 s/iter. Eval: 0.5961 s/iter. Total: 1.4455 s/iter. ETA=0:04:20
[02/24 16:43:34] mask2former INFO: Inference done 917/1093. Dataloading: 0.0285 s/iter. Inference: 0.8178 s/iter. Eval: 0.5963 s/iter. Total: 1.4449 s/iter. ETA=0:04:14
[02/24 16:43:40] mask2former INFO: Inference done 921/1093. Dataloading: 0.0284 s/iter. Inference: 0.8176 s/iter. Eval: 0.5962 s/iter. Total: 1.4443 s/iter. ETA=0:04:08
[02/24 16:43:45] mask2former INFO: Inference done 925/1093. Dataloading: 0.0284 s/iter. Inference: 0.8173 s/iter. Eval: 0.5964 s/iter. Total: 1.4443 s/iter. ETA=0:04:02
[02/24 16:43:51] mask2former INFO: Inference done 929/1093. Dataloading: 0.0284 s/iter. Inference: 0.8171 s/iter. Eval: 0.5965 s/iter. Total: 1.4442 s/iter. ETA=0:03:56
[02/24 16:43:57] mask2former INFO: Inference done 933/1093. Dataloading: 0.0284 s/iter. Inference: 0.8171 s/iter. Eval: 0.5967 s/iter. Total: 1.4444 s/iter. ETA=0:03:51
[02/24 16:44:03] mask2former INFO: Inference done 937/1093. Dataloading: 0.0284 s/iter. Inference: 0.8172 s/iter. Eval: 0.5964 s/iter. Total: 1.4441 s/iter. ETA=0:03:45
[02/24 16:44:08] mask2former INFO: Inference done 941/1093. Dataloading: 0.0284 s/iter. Inference: 0.8170 s/iter. Eval: 0.5966 s/iter. Total: 1.4441 s/iter. ETA=0:03:39
[02/24 16:44:15] mask2former INFO: Inference done 945/1093. Dataloading: 0.0285 s/iter. Inference: 0.8172 s/iter. Eval: 0.5972 s/iter. Total: 1.4450 s/iter. ETA=0:03:33
[02/24 16:44:21] mask2former INFO: Inference done 950/1093. Dataloading: 0.0284 s/iter. Inference: 0.8164 s/iter. Eval: 0.5969 s/iter. Total: 1.4439 s/iter. ETA=0:03:26
[02/24 16:44:28] mask2former INFO: Inference done 955/1093. Dataloading: 0.0283 s/iter. Inference: 0.8158 s/iter. Eval: 0.5967 s/iter. Total: 1.4430 s/iter. ETA=0:03:19
[02/24 16:44:34] mask2former INFO: Inference done 959/1093. Dataloading: 0.0283 s/iter. Inference: 0.8165 s/iter. Eval: 0.5966 s/iter. Total: 1.4435 s/iter. ETA=0:03:13
[02/24 16:44:40] mask2former INFO: Inference done 963/1093. Dataloading: 0.0283 s/iter. Inference: 0.8170 s/iter. Eval: 0.5964 s/iter. Total: 1.4439 s/iter. ETA=0:03:07
[02/24 16:44:45] mask2former INFO: Inference done 967/1093. Dataloading: 0.0283 s/iter. Inference: 0.8167 s/iter. Eval: 0.5960 s/iter. Total: 1.4432 s/iter. ETA=0:03:01
[02/24 16:44:51] mask2former INFO: Inference done 972/1093. Dataloading: 0.0282 s/iter. Inference: 0.8158 s/iter. Eval: 0.5957 s/iter. Total: 1.4419 s/iter. ETA=0:02:54
[02/24 16:44:56] mask2former INFO: Inference done 976/1093. Dataloading: 0.0282 s/iter. Inference: 0.8156 s/iter. Eval: 0.5952 s/iter. Total: 1.4412 s/iter. ETA=0:02:48
[02/24 16:45:02] mask2former INFO: Inference done 981/1093. Dataloading: 0.0282 s/iter. Inference: 0.8147 s/iter. Eval: 0.5944 s/iter. Total: 1.4395 s/iter. ETA=0:02:41
[02/24 16:45:07] mask2former INFO: Inference done 986/1093. Dataloading: 0.0281 s/iter. Inference: 0.8140 s/iter. Eval: 0.5937 s/iter. Total: 1.4380 s/iter. ETA=0:02:33
[02/24 16:45:13] mask2former INFO: Inference done 991/1093. Dataloading: 0.0281 s/iter. Inference: 0.8132 s/iter. Eval: 0.5931 s/iter. Total: 1.4366 s/iter. ETA=0:02:26
[02/24 16:45:19] mask2former INFO: Inference done 995/1093. Dataloading: 0.0280 s/iter. Inference: 0.8131 s/iter. Eval: 0.5929 s/iter. Total: 1.4363 s/iter. ETA=0:02:20
[02/24 16:45:25] mask2former INFO: Inference done 999/1093. Dataloading: 0.0280 s/iter. Inference: 0.8131 s/iter. Eval: 0.5936 s/iter. Total: 1.4370 s/iter. ETA=0:02:15
[02/24 16:45:31] mask2former INFO: Inference done 1002/1093. Dataloading: 0.0281 s/iter. Inference: 0.8139 s/iter. Eval: 0.5939 s/iter. Total: 1.4381 s/iter. ETA=0:02:10
[02/24 16:45:36] mask2former INFO: Inference done 1006/1093. Dataloading: 0.0281 s/iter. Inference: 0.8141 s/iter. Eval: 0.5939 s/iter. Total: 1.4383 s/iter. ETA=0:02:05
[02/24 16:45:42] mask2former INFO: Inference done 1010/1093. Dataloading: 0.0280 s/iter. Inference: 0.8138 s/iter. Eval: 0.5938 s/iter. Total: 1.4378 s/iter. ETA=0:01:59
[02/24 16:45:48] mask2former INFO: Inference done 1014/1093. Dataloading: 0.0280 s/iter. Inference: 0.8135 s/iter. Eval: 0.5943 s/iter. Total: 1.4380 s/iter. ETA=0:01:53
[02/24 16:45:54] mask2former INFO: Inference done 1018/1093. Dataloading: 0.0280 s/iter. Inference: 0.8137 s/iter. Eval: 0.5943 s/iter. Total: 1.4382 s/iter. ETA=0:01:47
[02/24 16:45:59] mask2former INFO: Inference done 1022/1093. Dataloading: 0.0280 s/iter. Inference: 0.8138 s/iter. Eval: 0.5940 s/iter. Total: 1.4379 s/iter. ETA=0:01:42
[02/24 16:46:05] mask2former INFO: Inference done 1026/1093. Dataloading: 0.0280 s/iter. Inference: 0.8140 s/iter. Eval: 0.5940 s/iter. Total: 1.4381 s/iter. ETA=0:01:36
[02/24 16:46:11] mask2former INFO: Inference done 1030/1093. Dataloading: 0.0279 s/iter. Inference: 0.8144 s/iter. Eval: 0.5941 s/iter. Total: 1.4385 s/iter. ETA=0:01:30
[02/24 16:46:17] mask2former INFO: Inference done 1033/1093. Dataloading: 0.0279 s/iter. Inference: 0.8158 s/iter. Eval: 0.5941 s/iter. Total: 1.4400 s/iter. ETA=0:01:26
[02/24 16:46:23] mask2former INFO: Inference done 1037/1093. Dataloading: 0.0280 s/iter. Inference: 0.8160 s/iter. Eval: 0.5937 s/iter. Total: 1.4399 s/iter. ETA=0:01:20
[02/24 16:46:29] mask2former INFO: Inference done 1041/1093. Dataloading: 0.0280 s/iter. Inference: 0.8165 s/iter. Eval: 0.5942 s/iter. Total: 1.4408 s/iter. ETA=0:01:14
[02/24 16:46:35] mask2former INFO: Inference done 1045/1093. Dataloading: 0.0280 s/iter. Inference: 0.8160 s/iter. Eval: 0.5940 s/iter. Total: 1.4402 s/iter. ETA=0:01:09
[02/24 16:46:41] mask2former INFO: Inference done 1049/1093. Dataloading: 0.0280 s/iter. Inference: 0.8160 s/iter. Eval: 0.5947 s/iter. Total: 1.4408 s/iter. ETA=0:01:03
[02/24 16:46:47] mask2former INFO: Inference done 1053/1093. Dataloading: 0.0280 s/iter. Inference: 0.8163 s/iter. Eval: 0.5946 s/iter. Total: 1.4410 s/iter. ETA=0:00:57
[02/24 16:46:52] mask2former INFO: Inference done 1057/1093. Dataloading: 0.0280 s/iter. Inference: 0.8163 s/iter. Eval: 0.5940 s/iter. Total: 1.4404 s/iter. ETA=0:00:51
[02/24 16:46:58] mask2former INFO: Inference done 1061/1093. Dataloading: 0.0279 s/iter. Inference: 0.8169 s/iter. Eval: 0.5939 s/iter. Total: 1.4409 s/iter. ETA=0:00:46
[02/24 16:47:04] mask2former INFO: Inference done 1065/1093. Dataloading: 0.0280 s/iter. Inference: 0.8168 s/iter. Eval: 0.5939 s/iter. Total: 1.4407 s/iter. ETA=0:00:40
[02/24 16:47:09] mask2former INFO: Inference done 1069/1093. Dataloading: 0.0280 s/iter. Inference: 0.8167 s/iter. Eval: 0.5933 s/iter. Total: 1.4402 s/iter. ETA=0:00:34
[02/24 16:47:15] mask2former INFO: Inference done 1074/1093. Dataloading: 0.0279 s/iter. Inference: 0.8162 s/iter. Eval: 0.5931 s/iter. Total: 1.4394 s/iter. ETA=0:00:27
[02/24 16:47:21] mask2former INFO: Inference done 1078/1093. Dataloading: 0.0279 s/iter. Inference: 0.8162 s/iter. Eval: 0.5931 s/iter. Total: 1.4392 s/iter. ETA=0:00:21
[02/24 16:47:26] mask2former INFO: Inference done 1082/1093. Dataloading: 0.0279 s/iter. Inference: 0.8156 s/iter. Eval: 0.5933 s/iter. Total: 1.4389 s/iter. ETA=0:00:15
[02/24 16:47:32] mask2former INFO: Inference done 1086/1093. Dataloading: 0.0278 s/iter. Inference: 0.8156 s/iter. Eval: 0.5930 s/iter. Total: 1.4386 s/iter. ETA=0:00:10
[02/24 16:47:38] mask2former INFO: Inference done 1090/1093. Dataloading: 0.0278 s/iter. Inference: 0.8160 s/iter. Eval: 0.5930 s/iter. Total: 1.4389 s/iter. ETA=0:00:04
[02/24 16:50:41] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.752643926517327, 'error_1pix': 0.3673337375537235, 'error_3pix': 0.13329752371989567, 'mIoU': 23.343274145570845, 'fwIoU': 51.6709261106208, 'IoU-1': 92.87255322065768, 'IoU-2': 86.52556516262105, 'IoU-3': 2.152275549258099, 'IoU-4': 4.636814584354894, 'IoU-5': 2.9881801392463974, 'IoU-6': 7.546101977597545, 'IoU-7': 5.229244066480348, 'IoU-8': 2.973556525469644, 'IoU-9': 4.060316706277205, 'IoU-10': 14.008687929215805, 'IoU-11': 24.13701103911687, 'IoU-12': 22.665839903836336, 'IoU-13': 21.885424526702295, 'IoU-14': 37.88146287950587, 'IoU-15': 33.17629649551406, 'IoU-16': 28.626050264486707, 'IoU-17': 14.069789043352051, 'IoU-18': 33.509229345785776, 'IoU-19': 27.18269241379381, 'IoU-20': 24.563681892370674, 'IoU-21': 15.896053331901511, 'IoU-22': 31.213791116525762, 'IoU-23': 31.3049621869933, 'IoU-24': 26.964399465981703, 'IoU-25': 21.827686983420815, 'IoU-26': 26.84217925967598, 'IoU-27': 27.138545168341295, 'IoU-28': 22.54979446789004, 'IoU-29': 14.667487902778003, 'IoU-30': 26.7491762210564, 'IoU-31': 20.632935221815256, 'IoU-32': 19.550246317246838, 'IoU-33': 16.364958123790625, 'IoU-34': 26.161960578145344, 'IoU-35': 29.247028869512658, 'IoU-36': 28.575893521174816, 'IoU-37': 22.06397334684933, 'IoU-38': 25.943821458163384, 'IoU-39': 27.958592544347844, 'IoU-40': 22.434947675160917, 'IoU-41': 10.002931005772757, 'IoU-42': 15.603409569367155, 'IoU-43': 26.856758553417663, 'IoU-44': 18.454067955646728, 'IoU-45': 10.814879430336918, 'IoU-46': 9.958927040208094, 'IoU-47': 22.075618195100883, 'IoU-48': 31.93135981113555, 'mACC': 38.76223752097705, 'pACC': 61.62402948354399, 'ACC-1': 96.55589588215074, 'ACC-2': 86.8171607469246, 'ACC-3': 36.6718197179286, 'ACC-4': 20.363235555732487, 'ACC-5': 11.311997599950589, 'ACC-6': 32.28512082912615, 'ACC-7': 49.621347210597186, 'ACC-8': 21.867505347702494, 'ACC-9': 8.22993309988753, 'ACC-10': 27.91173833717966, 'ACC-11': 46.383658862635905, 'ACC-12': 36.98849871185825, 'ACC-13': 27.080333933218338, 'ACC-14': 57.27834484066789, 'ACC-15': 52.397568967394115, 'ACC-16': 48.19357647021102, 'ACC-17': 18.441333047816794, 'ACC-18': 52.413721733852995, 'ACC-19': 45.40641610471065, 'ACC-20': 45.067367919051506, 'ACC-21': 21.338871167546653, 'ACC-22': 44.5548571744521, 'ACC-23': 50.5167455725057, 'ACC-24': 49.45086966790994, 'ACC-25': 30.696887647451177, 'ACC-26': 41.17598431727807, 'ACC-27': 47.175015639563114, 'ACC-28': 43.58285985691028, 'ACC-29': 20.1099494964687, 'ACC-30': 45.02070993726509, 'ACC-31': 35.79134395476703, 'ACC-32': 34.95808996812629, 'ACC-33': 21.84101381557958, 'ACC-34': 37.9515125181441, 'ACC-35': 47.13114216135189, 'ACC-36': 48.948482877284974, 'ACC-37': 30.862367505443473, 'ACC-38': 39.00298188444952, 'ACC-39': 51.39138174509487, 'ACC-40': 47.93367234266924, 'ACC-41': 13.914936653948823, 'ACC-42': 21.911456985620045, 'ACC-43': 51.96528746912351, 'ACC-44': 39.1053132177076, 'ACC-45': 15.972135190584996, 'ACC-46': 12.802772982244973, 'ACC-47': 34.807949716109356, 'ACC-48': 59.38623462269983})])
[02/24 16:50:41] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[02/24 16:50:41] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[02/24 16:50:41] d2.evaluation.testing INFO: copypaste: 2.7526,0.3673,0.1333,23.3433,51.6709,38.7622,61.6240
[02/24 16:50:41] d2.utils.events INFO:  eta: 1 day, 3:14:19  iter: 7499  total_loss: 8.104  loss_ce: 0  loss_mask: 0.2174  loss_dice: 0.5479  loss_seg: 0.2785  loss_ce_0: 0  loss_mask_0: 0.2141  loss_dice_0: 0.5519  loss_ce_1: 0  loss_mask_1: 0.2154  loss_dice_1: 0.5508  loss_ce_2: 0  loss_mask_2: 0.2151  loss_dice_2: 0.549  loss_ce_3: 0  loss_mask_3: 0.2152  loss_dice_3: 0.546  loss_ce_4: 0  loss_mask_4: 0.2144  loss_dice_4: 0.5464  loss_ce_5: 0  loss_mask_5: 0.2146  loss_dice_5: 0.5473  loss_ce_6: 0  loss_mask_6: 0.2148  loss_dice_6: 0.5452  loss_ce_7: 0  loss_mask_7: 0.2155  loss_dice_7: 0.5434  loss_ce_8: 0  loss_mask_8: 0.2154  loss_dice_8: 0.5456  time: 1.7543  data_time: 0.1004  lr: 8.8678e-05  max_mem: 5916M
[02/24 16:51:56] d2.utils.events INFO:  eta: 1 day, 3:38:56  iter: 7519  total_loss: 7.575  loss_ce: 0  loss_mask: 0.212  loss_dice: 0.5289  loss_seg: 0.3018  loss_ce_0: 0  loss_mask_0: 0.2073  loss_dice_0: 0.5412  loss_ce_1: 0  loss_mask_1: 0.2087  loss_dice_1: 0.5306  loss_ce_2: 0  loss_mask_2: 0.209  loss_dice_2: 0.5269  loss_ce_3: 0  loss_mask_3: 0.2091  loss_dice_3: 0.5251  loss_ce_4: 0  loss_mask_4: 0.2099  loss_dice_4: 0.5247  loss_ce_5: 0  loss_mask_5: 0.2095  loss_dice_5: 0.5257  loss_ce_6: 0  loss_mask_6: 0.2096  loss_dice_6: 0.5244  loss_ce_7: 0  loss_mask_7: 0.2095  loss_dice_7: 0.5252  loss_ce_8: 0  loss_mask_8: 0.2104  loss_dice_8: 0.5257  time: 1.7595  data_time: 0.1036  lr: 8.8647e-05  max_mem: 5916M
[02/24 16:53:09] d2.utils.events INFO:  eta: 1 day, 3:53:23  iter: 7539  total_loss: 7.497  loss_ce: 0  loss_mask: 0.2079  loss_dice: 0.5251  loss_seg: 0.2724  loss_ce_0: 0  loss_mask_0: 0.2094  loss_dice_0: 0.5345  loss_ce_1: 0  loss_mask_1: 0.2055  loss_dice_1: 0.5261  loss_ce_2: 0  loss_mask_2: 0.2051  loss_dice_2: 0.5245  loss_ce_3: 0  loss_mask_3: 0.2063  loss_dice_3: 0.5211  loss_ce_4: 0  loss_mask_4: 0.2066  loss_dice_4: 0.5209  loss_ce_5: 0  loss_mask_5: 0.2061  loss_dice_5: 0.5215  loss_ce_6: 0  loss_mask_6: 0.2068  loss_dice_6: 0.5219  loss_ce_7: 0  loss_mask_7: 0.2059  loss_dice_7: 0.5215  loss_ce_8: 0  loss_mask_8: 0.2058  loss_dice_8: 0.5223  time: 1.7645  data_time: 0.1221  lr: 8.8617e-05  max_mem: 5916M
[02/24 16:54:18] d2.utils.events INFO:  eta: 1 day, 4:17:42  iter: 7559  total_loss: 7.482  loss_ce: 0  loss_mask: 0.1871  loss_dice: 0.5143  loss_seg: 0.2718  loss_ce_0: 0  loss_mask_0: 0.1852  loss_dice_0: 0.5327  loss_ce_1: 0  loss_mask_1: 0.1843  loss_dice_1: 0.5174  loss_ce_2: 0  loss_mask_2: 0.1845  loss_dice_2: 0.5136  loss_ce_3: 0  loss_mask_3: 0.186  loss_dice_3: 0.5105  loss_ce_4: 0  loss_mask_4: 0.1864  loss_dice_4: 0.5118  loss_ce_5: 0  loss_mask_5: 0.1866  loss_dice_5: 0.5108  loss_ce_6: 0  loss_mask_6: 0.1855  loss_dice_6: 0.5106  loss_ce_7: 0  loss_mask_7: 0.1865  loss_dice_7: 0.5121  loss_ce_8: 0  loss_mask_8: 0.1857  loss_dice_8: 0.5109  time: 1.7690  data_time: 0.1176  lr: 8.8587e-05  max_mem: 5916M
[02/24 16:55:23] d2.utils.events INFO:  eta: 1 day, 4:42:55  iter: 7579  total_loss: 7.876  loss_ce: 0  loss_mask: 0.1997  loss_dice: 0.5451  loss_seg: 0.2867  loss_ce_0: 0  loss_mask_0: 0.2025  loss_dice_0: 0.5549  loss_ce_1: 0  loss_mask_1: 0.2  loss_dice_1: 0.5446  loss_ce_2: 0  loss_mask_2: 0.1992  loss_dice_2: 0.5441  loss_ce_3: 0  loss_mask_3: 0.1988  loss_dice_3: 0.5428  loss_ce_4: 0  loss_mask_4: 0.199  loss_dice_4: 0.5437  loss_ce_5: 0  loss_mask_5: 0.1995  loss_dice_5: 0.5427  loss_ce_6: 0  loss_mask_6: 0.2006  loss_dice_6: 0.5415  loss_ce_7: 0  loss_mask_7: 0.2002  loss_dice_7: 0.5425  loss_ce_8: 0  loss_mask_8: 0.1998  loss_dice_8: 0.5441  time: 1.7728  data_time: 0.1006  lr: 8.8556e-05  max_mem: 5916M
[02/24 16:56:32] d2.utils.events INFO:  eta: 1 day, 5:08:28  iter: 7599  total_loss: 7.271  loss_ce: 0  loss_mask: 0.1994  loss_dice: 0.5083  loss_seg: 0.2716  loss_ce_0: 0  loss_mask_0: 0.1972  loss_dice_0: 0.5268  loss_ce_1: 0  loss_mask_1: 0.1986  loss_dice_1: 0.5059  loss_ce_2: 0  loss_mask_2: 0.1986  loss_dice_2: 0.5046  loss_ce_3: 0  loss_mask_3: 0.1984  loss_dice_3: 0.5028  loss_ce_4: 0  loss_mask_4: 0.1984  loss_dice_4: 0.5027  loss_ce_5: 0  loss_mask_5: 0.1984  loss_dice_5: 0.5044  loss_ce_6: 0  loss_mask_6: 0.199  loss_dice_6: 0.5037  loss_ce_7: 0  loss_mask_7: 0.1991  loss_dice_7: 0.504  loss_ce_8: 0  loss_mask_8: 0.1999  loss_dice_8: 0.5041  time: 1.7772  data_time: 0.1064  lr: 8.8526e-05  max_mem: 5916M
[02/24 16:57:41] d2.utils.events INFO:  eta: 1 day, 5:36:28  iter: 7619  total_loss: 7.721  loss_ce: 0  loss_mask: 0.2057  loss_dice: 0.5333  loss_seg: 0.2925  loss_ce_0: 0  loss_mask_0: 0.2044  loss_dice_0: 0.5501  loss_ce_1: 0  loss_mask_1: 0.2039  loss_dice_1: 0.535  loss_ce_2: 0  loss_mask_2: 0.2042  loss_dice_2: 0.5331  loss_ce_3: 0  loss_mask_3: 0.2052  loss_dice_3: 0.5305  loss_ce_4: 0  loss_mask_4: 0.2051  loss_dice_4: 0.5302  loss_ce_5: 0  loss_mask_5: 0.2048  loss_dice_5: 0.5314  loss_ce_6: 0  loss_mask_6: 0.2059  loss_dice_6: 0.5308  loss_ce_7: 0  loss_mask_7: 0.2051  loss_dice_7: 0.5309  loss_ce_8: 0  loss_mask_8: 0.2049  loss_dice_8: 0.5314  time: 1.7816  data_time: 0.1013  lr: 8.8495e-05  max_mem: 5916M
[02/24 16:58:48] d2.utils.events INFO:  eta: 1 day, 6:12:49  iter: 7639  total_loss: 7.939  loss_ce: 0  loss_mask: 0.2076  loss_dice: 0.5478  loss_seg: 0.306  loss_ce_0: 0  loss_mask_0: 0.2041  loss_dice_0: 0.5564  loss_ce_1: 0  loss_mask_1: 0.2071  loss_dice_1: 0.5488  loss_ce_2: 0  loss_mask_2: 0.2072  loss_dice_2: 0.5462  loss_ce_3: 0  loss_mask_3: 0.2074  loss_dice_3: 0.5452  loss_ce_4: 0  loss_mask_4: 0.2069  loss_dice_4: 0.5454  loss_ce_5: 0  loss_mask_5: 0.207  loss_dice_5: 0.5459  loss_ce_6: 0  loss_mask_6: 0.2086  loss_dice_6: 0.5452  loss_ce_7: 0  loss_mask_7: 0.2077  loss_dice_7: 0.5458  loss_ce_8: 0  loss_mask_8: 0.2073  loss_dice_8: 0.5458  time: 1.7855  data_time: 0.0971  lr: 8.8465e-05  max_mem: 5916M
[02/24 16:59:57] d2.utils.events INFO:  eta: 1 day, 7:04:20  iter: 7659  total_loss: 7.738  loss_ce: 0  loss_mask: 0.2052  loss_dice: 0.5442  loss_seg: 0.2726  loss_ce_0: 0  loss_mask_0: 0.206  loss_dice_0: 0.5533  loss_ce_1: 0  loss_mask_1: 0.2066  loss_dice_1: 0.5393  loss_ce_2: 0  loss_mask_2: 0.2056  loss_dice_2: 0.5362  loss_ce_3: 0  loss_mask_3: 0.2059  loss_dice_3: 0.5368  loss_ce_4: 0  loss_mask_4: 0.2067  loss_dice_4: 0.5373  loss_ce_5: 0  loss_mask_5: 0.206  loss_dice_5: 0.5399  loss_ce_6: 0  loss_mask_6: 0.206  loss_dice_6: 0.5399  loss_ce_7: 0  loss_mask_7: 0.2066  loss_dice_7: 0.5393  loss_ce_8: 0  loss_mask_8: 0.2061  loss_dice_8: 0.5407  time: 1.7899  data_time: 0.0977  lr: 8.8434e-05  max_mem: 5916M
[02/24 17:01:09] d2.utils.events INFO:  eta: 1 day, 7:51:28  iter: 7679  total_loss: 7.41  loss_ce: 0  loss_mask: 0.1962  loss_dice: 0.5115  loss_seg: 0.2586  loss_ce_0: 0  loss_mask_0: 0.1961  loss_dice_0: 0.528  loss_ce_1: 0  loss_mask_1: 0.1956  loss_dice_1: 0.5146  loss_ce_2: 0  loss_mask_2: 0.1957  loss_dice_2: 0.5116  loss_ce_3: 0  loss_mask_3: 0.1956  loss_dice_3: 0.51  loss_ce_4: 0  loss_mask_4: 0.1964  loss_dice_4: 0.5096  loss_ce_5: 0  loss_mask_5: 0.1952  loss_dice_5: 0.5081  loss_ce_6: 0  loss_mask_6: 0.1952  loss_dice_6: 0.5073  loss_ce_7: 0  loss_mask_7: 0.1955  loss_dice_7: 0.509  loss_ce_8: 0  loss_mask_8: 0.1953  loss_dice_8: 0.5088  time: 1.7946  data_time: 0.1015  lr: 8.8404e-05  max_mem: 5916M
[02/24 17:02:20] d2.utils.events INFO:  eta: 1 day, 9:05:37  iter: 7699  total_loss: 7.715  loss_ce: 0  loss_mask: 0.194  loss_dice: 0.5382  loss_seg: 0.2943  loss_ce_0: 0  loss_mask_0: 0.1948  loss_dice_0: 0.5525  loss_ce_1: 0  loss_mask_1: 0.1962  loss_dice_1: 0.5359  loss_ce_2: 0  loss_mask_2: 0.1953  loss_dice_2: 0.5348  loss_ce_3: 0  loss_mask_3: 0.1947  loss_dice_3: 0.5341  loss_ce_4: 0  loss_mask_4: 0.1953  loss_dice_4: 0.5352  loss_ce_5: 0  loss_mask_5: 0.1952  loss_dice_5: 0.5335  loss_ce_6: 0  loss_mask_6: 0.1954  loss_dice_6: 0.5332  loss_ce_7: 0  loss_mask_7: 0.1944  loss_dice_7: 0.5342  loss_ce_8: 0  loss_mask_8: 0.1946  loss_dice_8: 0.5348  time: 1.7991  data_time: 0.1116  lr: 8.8374e-05  max_mem: 5916M
[02/24 17:03:27] d2.utils.events INFO:  eta: 1 day, 10:40:55  iter: 7719  total_loss: 7.522  loss_ce: 0  loss_mask: 0.205  loss_dice: 0.5271  loss_seg: 0.2657  loss_ce_0: 0  loss_mask_0: 0.2068  loss_dice_0: 0.5365  loss_ce_1: 0  loss_mask_1: 0.206  loss_dice_1: 0.5251  loss_ce_2: 0  loss_mask_2: 0.2071  loss_dice_2: 0.5232  loss_ce_3: 0  loss_mask_3: 0.2062  loss_dice_3: 0.5223  loss_ce_4: 0  loss_mask_4: 0.2058  loss_dice_4: 0.5235  loss_ce_5: 0  loss_mask_5: 0.2047  loss_dice_5: 0.5239  loss_ce_6: 0  loss_mask_6: 0.2036  loss_dice_6: 0.5255  loss_ce_7: 0  loss_mask_7: 0.2052  loss_dice_7: 0.5249  loss_ce_8: 0  loss_mask_8: 0.2048  loss_dice_8: 0.5261  time: 1.8031  data_time: 0.0965  lr: 8.8343e-05  max_mem: 5916M
[02/24 17:04:34] d2.utils.events INFO:  eta: 1 day, 13:02:45  iter: 7739  total_loss: 7.64  loss_ce: 0  loss_mask: 0.2091  loss_dice: 0.5392  loss_seg: 0.2798  loss_ce_0: 0  loss_mask_0: 0.206  loss_dice_0: 0.5486  loss_ce_1: 0  loss_mask_1: 0.2063  loss_dice_1: 0.5406  loss_ce_2: 0  loss_mask_2: 0.2083  loss_dice_2: 0.5384  loss_ce_3: 0  loss_mask_3: 0.2092  loss_dice_3: 0.5342  loss_ce_4: 0  loss_mask_4: 0.2087  loss_dice_4: 0.5348  loss_ce_5: 0  loss_mask_5: 0.2102  loss_dice_5: 0.5356  loss_ce_6: 0  loss_mask_6: 0.2092  loss_dice_6: 0.5338  loss_ce_7: 0  loss_mask_7: 0.2088  loss_dice_7: 0.5354  loss_ce_8: 0  loss_mask_8: 0.2087  loss_dice_8: 0.5356  time: 1.8070  data_time: 0.1231  lr: 8.8313e-05  max_mem: 5916M
[02/24 17:05:44] d2.utils.events INFO:  eta: 1 day, 15:02:56  iter: 7759  total_loss: 7.61  loss_ce: 0  loss_mask: 0.1971  loss_dice: 0.537  loss_seg: 0.2753  loss_ce_0: 0  loss_mask_0: 0.1977  loss_dice_0: 0.5463  loss_ce_1: 0  loss_mask_1: 0.1972  loss_dice_1: 0.5372  loss_ce_2: 0  loss_mask_2: 0.199  loss_dice_2: 0.5348  loss_ce_3: 0  loss_mask_3: 0.199  loss_dice_3: 0.533  loss_ce_4: 0  loss_mask_4: 0.1987  loss_dice_4: 0.5331  loss_ce_5: 0  loss_mask_5: 0.1991  loss_dice_5: 0.5341  loss_ce_6: 0  loss_mask_6: 0.1987  loss_dice_6: 0.5325  loss_ce_7: 0  loss_mask_7: 0.1979  loss_dice_7: 0.5328  loss_ce_8: 0  loss_mask_8: 0.1988  loss_dice_8: 0.5336  time: 1.8114  data_time: 0.1235  lr: 8.8282e-05  max_mem: 5916M
[02/24 17:06:53] d2.utils.events INFO:  eta: 1 day, 17:13:50  iter: 7779  total_loss: 7.572  loss_ce: 0  loss_mask: 0.2087  loss_dice: 0.5223  loss_seg: 0.2673  loss_ce_0: 0  loss_mask_0: 0.2092  loss_dice_0: 0.5362  loss_ce_1: 0  loss_mask_1: 0.2087  loss_dice_1: 0.5233  loss_ce_2: 0  loss_mask_2: 0.2086  loss_dice_2: 0.5208  loss_ce_3: 0  loss_mask_3: 0.2089  loss_dice_3: 0.5171  loss_ce_4: 0  loss_mask_4: 0.209  loss_dice_4: 0.5171  loss_ce_5: 0  loss_mask_5: 0.2087  loss_dice_5: 0.517  loss_ce_6: 0  loss_mask_6: 0.2094  loss_dice_6: 0.5166  loss_ce_7: 0  loss_mask_7: 0.2093  loss_dice_7: 0.517  loss_ce_8: 0  loss_mask_8: 0.2078  loss_dice_8: 0.5179  time: 1.8155  data_time: 0.0939  lr: 8.8252e-05  max_mem: 5916M
[02/24 17:08:02] d2.utils.events INFO:  eta: 1 day, 18:02:31  iter: 7799  total_loss: 7.508  loss_ce: 0  loss_mask: 0.2009  loss_dice: 0.5223  loss_seg: 0.2763  loss_ce_0: 0  loss_mask_0: 0.1998  loss_dice_0: 0.5399  loss_ce_1: 0  loss_mask_1: 0.2004  loss_dice_1: 0.5268  loss_ce_2: 0  loss_mask_2: 0.2003  loss_dice_2: 0.5253  loss_ce_3: 0  loss_mask_3: 0.2006  loss_dice_3: 0.5225  loss_ce_4: 0  loss_mask_4: 0.202  loss_dice_4: 0.5227  loss_ce_5: 0  loss_mask_5: 0.2011  loss_dice_5: 0.5243  loss_ce_6: 0  loss_mask_6: 0.2028  loss_dice_6: 0.522  loss_ce_7: 0  loss_mask_7: 0.2018  loss_dice_7: 0.5233  loss_ce_8: 0  loss_mask_8: 0.2018  loss_dice_8: 0.5238  time: 1.8196  data_time: 0.1003  lr: 8.8222e-05  max_mem: 5916M
[02/24 17:09:12] d2.utils.events INFO:  eta: 1 day, 18:58:04  iter: 7819  total_loss: 7.667  loss_ce: 0  loss_mask: 0.195  loss_dice: 0.5331  loss_seg: 0.2782  loss_ce_0: 0  loss_mask_0: 0.1954  loss_dice_0: 0.5444  loss_ce_1: 0  loss_mask_1: 0.1947  loss_dice_1: 0.5339  loss_ce_2: 0  loss_mask_2: 0.196  loss_dice_2: 0.5325  loss_ce_3: 0  loss_mask_3: 0.1955  loss_dice_3: 0.5302  loss_ce_4: 0  loss_mask_4: 0.1957  loss_dice_4: 0.5298  loss_ce_5: 0  loss_mask_5: 0.1965  loss_dice_5: 0.5291  loss_ce_6: 0  loss_mask_6: 0.1952  loss_dice_6: 0.5293  loss_ce_7: 0  loss_mask_7: 0.1961  loss_dice_7: 0.5296  loss_ce_8: 0  loss_mask_8: 0.1964  loss_dice_8: 0.5303  time: 1.8239  data_time: 0.0935  lr: 8.8191e-05  max_mem: 5916M
[02/24 17:10:21] d2.utils.events INFO:  eta: 1 day, 19:34:53  iter: 7839  total_loss: 7.642  loss_ce: 0  loss_mask: 0.2019  loss_dice: 0.5297  loss_seg: 0.279  loss_ce_0: 0  loss_mask_0: 0.2018  loss_dice_0: 0.5428  loss_ce_1: 0  loss_mask_1: 0.2004  loss_dice_1: 0.53  loss_ce_2: 0  loss_mask_2: 0.2014  loss_dice_2: 0.5268  loss_ce_3: 0  loss_mask_3: 0.2012  loss_dice_3: 0.5261  loss_ce_4: 0  loss_mask_4: 0.2011  loss_dice_4: 0.5255  loss_ce_5: 0  loss_mask_5: 0.2009  loss_dice_5: 0.5256  loss_ce_6: 0  loss_mask_6: 0.2022  loss_dice_6: 0.5266  loss_ce_7: 0  loss_mask_7: 0.2013  loss_dice_7: 0.5279  loss_ce_8: 0  loss_mask_8: 0.2023  loss_dice_8: 0.5271  time: 1.8281  data_time: 0.0852  lr: 8.8161e-05  max_mem: 5916M
[02/24 17:11:30] d2.utils.events INFO:  eta: 1 day, 20:16:40  iter: 7859  total_loss: 7.697  loss_ce: 0  loss_mask: 0.2066  loss_dice: 0.5311  loss_seg: 0.2985  loss_ce_0: 0  loss_mask_0: 0.2061  loss_dice_0: 0.5385  loss_ce_1: 0  loss_mask_1: 0.2061  loss_dice_1: 0.5301  loss_ce_2: 0  loss_mask_2: 0.2068  loss_dice_2: 0.5263  loss_ce_3: 0  loss_mask_3: 0.2064  loss_dice_3: 0.5254  loss_ce_4: 0  loss_mask_4: 0.2068  loss_dice_4: 0.5261  loss_ce_5: 0  loss_mask_5: 0.2068  loss_dice_5: 0.5253  loss_ce_6: 0  loss_mask_6: 0.2078  loss_dice_6: 0.5255  loss_ce_7: 0  loss_mask_7: 0.2066  loss_dice_7: 0.5259  loss_ce_8: 0  loss_mask_8: 0.2067  loss_dice_8: 0.527  time: 1.8322  data_time: 0.1157  lr: 8.813e-05  max_mem: 5916M
[02/24 17:12:42] d2.utils.events INFO:  eta: 1 day, 20:53:51  iter: 7879  total_loss: 7.408  loss_ce: 0  loss_mask: 0.2  loss_dice: 0.5245  loss_seg: 0.2679  loss_ce_0: 0  loss_mask_0: 0.1963  loss_dice_0: 0.5378  loss_ce_1: 0  loss_mask_1: 0.199  loss_dice_1: 0.5251  loss_ce_2: 0  loss_mask_2: 0.1998  loss_dice_2: 0.5234  loss_ce_3: 0  loss_mask_3: 0.2002  loss_dice_3: 0.5226  loss_ce_4: 0  loss_mask_4: 0.201  loss_dice_4: 0.5223  loss_ce_5: 0  loss_mask_5: 0.2016  loss_dice_5: 0.5217  loss_ce_6: 0  loss_mask_6: 0.2027  loss_dice_6: 0.5218  loss_ce_7: 0  loss_mask_7: 0.2024  loss_dice_7: 0.5222  loss_ce_8: 0  loss_mask_8: 0.2024  loss_dice_8: 0.5224  time: 1.8365  data_time: 0.1138  lr: 8.81e-05  max_mem: 5916M
[02/24 17:13:49] d2.utils.events INFO:  eta: 1 day, 21:21:04  iter: 7899  total_loss: 7.203  loss_ce: 0  loss_mask: 0.1942  loss_dice: 0.5003  loss_seg: 0.2767  loss_ce_0: 0  loss_mask_0: 0.192  loss_dice_0: 0.5238  loss_ce_1: 0  loss_mask_1: 0.1932  loss_dice_1: 0.4996  loss_ce_2: 0  loss_mask_2: 0.1935  loss_dice_2: 0.4974  loss_ce_3: 0  loss_mask_3: 0.1939  loss_dice_3: 0.4951  loss_ce_4: 0  loss_mask_4: 0.1935  loss_dice_4: 0.4949  loss_ce_5: 0  loss_mask_5: 0.1932  loss_dice_5: 0.4944  loss_ce_6: 0  loss_mask_6: 0.1944  loss_dice_6: 0.4954  loss_ce_7: 0  loss_mask_7: 0.1935  loss_dice_7: 0.4954  loss_ce_8: 0  loss_mask_8: 0.1947  loss_dice_8: 0.4974  time: 1.8404  data_time: 0.1106  lr: 8.8069e-05  max_mem: 5916M
[02/24 17:15:01] d2.utils.events INFO:  eta: 1 day, 21:41:29  iter: 7919  total_loss: 7.549  loss_ce: 0  loss_mask: 0.1943  loss_dice: 0.524  loss_seg: 0.267  loss_ce_0: 0  loss_mask_0: 0.1929  loss_dice_0: 0.5353  loss_ce_1: 0  loss_mask_1: 0.1936  loss_dice_1: 0.5248  loss_ce_2: 0  loss_mask_2: 0.1943  loss_dice_2: 0.5217  loss_ce_3: 0  loss_mask_3: 0.1941  loss_dice_3: 0.5198  loss_ce_4: 0  loss_mask_4: 0.1935  loss_dice_4: 0.5201  loss_ce_5: 0  loss_mask_5: 0.1936  loss_dice_5: 0.5223  loss_ce_6: 0  loss_mask_6: 0.1937  loss_dice_6: 0.5202  loss_ce_7: 0  loss_mask_7: 0.1924  loss_dice_7: 0.5203  loss_ce_8: 0  loss_mask_8: 0.1927  loss_dice_8: 0.5209  time: 1.8447  data_time: 0.1035  lr: 8.8039e-05  max_mem: 5916M
[02/24 17:16:08] d2.utils.events INFO:  eta: 1 day, 22:02:29  iter: 7939  total_loss: 7.325  loss_ce: 0  loss_mask: 0.1924  loss_dice: 0.5139  loss_seg: 0.265  loss_ce_0: 0  loss_mask_0: 0.1952  loss_dice_0: 0.5297  loss_ce_1: 0  loss_mask_1: 0.1926  loss_dice_1: 0.5127  loss_ce_2: 0  loss_mask_2: 0.1922  loss_dice_2: 0.5107  loss_ce_3: 0  loss_mask_3: 0.1931  loss_dice_3: 0.5108  loss_ce_4: 0  loss_mask_4: 0.1926  loss_dice_4: 0.5116  loss_ce_5: 0  loss_mask_5: 0.1932  loss_dice_5: 0.5125  loss_ce_6: 0  loss_mask_6: 0.1933  loss_dice_6: 0.5124  loss_ce_7: 0  loss_mask_7: 0.1938  loss_dice_7: 0.5124  loss_ce_8: 0  loss_mask_8: 0.1933  loss_dice_8: 0.512  time: 1.8485  data_time: 0.0881  lr: 8.8009e-05  max_mem: 5916M
[02/24 17:17:19] d2.utils.events INFO:  eta: 1 day, 22:19:37  iter: 7959  total_loss: 7.52  loss_ce: 0  loss_mask: 0.2028  loss_dice: 0.5244  loss_seg: 0.3073  loss_ce_0: 0  loss_mask_0: 0.206  loss_dice_0: 0.5351  loss_ce_1: 0  loss_mask_1: 0.2032  loss_dice_1: 0.5236  loss_ce_2: 0  loss_mask_2: 0.2036  loss_dice_2: 0.5212  loss_ce_3: 0  loss_mask_3: 0.2033  loss_dice_3: 0.5199  loss_ce_4: 0  loss_mask_4: 0.203  loss_dice_4: 0.5196  loss_ce_5: 0  loss_mask_5: 0.2018  loss_dice_5: 0.5209  loss_ce_6: 0  loss_mask_6: 0.2029  loss_dice_6: 0.5196  loss_ce_7: 0  loss_mask_7: 0.2026  loss_dice_7: 0.5204  loss_ce_8: 0  loss_mask_8: 0.2024  loss_dice_8: 0.5204  time: 1.8527  data_time: 0.0937  lr: 8.7978e-05  max_mem: 5916M
[02/24 17:18:28] d2.utils.events INFO:  eta: 1 day, 22:51:46  iter: 7979  total_loss: 7.64  loss_ce: 0  loss_mask: 0.1984  loss_dice: 0.5321  loss_seg: 0.2816  loss_ce_0: 0  loss_mask_0: 0.2006  loss_dice_0: 0.5388  loss_ce_1: 0  loss_mask_1: 0.1981  loss_dice_1: 0.5328  loss_ce_2: 0  loss_mask_2: 0.198  loss_dice_2: 0.5294  loss_ce_3: 0  loss_mask_3: 0.1984  loss_dice_3: 0.5282  loss_ce_4: 0  loss_mask_4: 0.1992  loss_dice_4: 0.5287  loss_ce_5: 0  loss_mask_5: 0.1986  loss_dice_5: 0.5281  loss_ce_6: 0  loss_mask_6: 0.1984  loss_dice_6: 0.5275  loss_ce_7: 0  loss_mask_7: 0.1997  loss_dice_7: 0.5282  loss_ce_8: 0  loss_mask_8: 0.1993  loss_dice_8: 0.529  time: 1.8567  data_time: 0.1015  lr: 8.7948e-05  max_mem: 5916M
[02/24 17:19:40] d2.utils.events INFO:  eta: 1 day, 23:15:59  iter: 7999  total_loss: 7.474  loss_ce: 0  loss_mask: 0.2047  loss_dice: 0.5292  loss_seg: 0.2702  loss_ce_0: 0  loss_mask_0: 0.2047  loss_dice_0: 0.5441  loss_ce_1: 0  loss_mask_1: 0.2048  loss_dice_1: 0.5294  loss_ce_2: 0  loss_mask_2: 0.2055  loss_dice_2: 0.5257  loss_ce_3: 0  loss_mask_3: 0.2064  loss_dice_3: 0.5236  loss_ce_4: 0  loss_mask_4: 0.2059  loss_dice_4: 0.5241  loss_ce_5: 0  loss_mask_5: 0.2065  loss_dice_5: 0.5251  loss_ce_6: 0  loss_mask_6: 0.2061  loss_dice_6: 0.5252  loss_ce_7: 0  loss_mask_7: 0.2055  loss_dice_7: 0.5263  loss_ce_8: 0  loss_mask_8: 0.2054  loss_dice_8: 0.5274  time: 1.8610  data_time: 0.1054  lr: 8.7917e-05  max_mem: 5916M
[02/24 17:20:52] d2.utils.events INFO:  eta: 1 day, 23:38:52  iter: 8019  total_loss: 7.287  loss_ce: 0  loss_mask: 0.2062  loss_dice: 0.5034  loss_seg: 0.2501  loss_ce_0: 0  loss_mask_0: 0.2056  loss_dice_0: 0.5183  loss_ce_1: 0  loss_mask_1: 0.2026  loss_dice_1: 0.5053  loss_ce_2: 0  loss_mask_2: 0.2018  loss_dice_2: 0.5041  loss_ce_3: 0  loss_mask_3: 0.2034  loss_dice_3: 0.5017  loss_ce_4: 0  loss_mask_4: 0.2033  loss_dice_4: 0.5015  loss_ce_5: 0  loss_mask_5: 0.2023  loss_dice_5: 0.5026  loss_ce_6: 0  loss_mask_6: 0.2029  loss_dice_6: 0.5018  loss_ce_7: 0  loss_mask_7: 0.2037  loss_dice_7: 0.5019  loss_ce_8: 0  loss_mask_8: 0.204  loss_dice_8: 0.5023  time: 1.8653  data_time: 0.1101  lr: 8.7887e-05  max_mem: 5916M
[02/24 17:21:59] d2.utils.events INFO:  eta: 1 day, 23:49:28  iter: 8039  total_loss: 7.596  loss_ce: 0  loss_mask: 0.1923  loss_dice: 0.5321  loss_seg: 0.2865  loss_ce_0: 0  loss_mask_0: 0.1944  loss_dice_0: 0.5447  loss_ce_1: 0  loss_mask_1: 0.1899  loss_dice_1: 0.536  loss_ce_2: 0  loss_mask_2: 0.1905  loss_dice_2: 0.5338  loss_ce_3: 0  loss_mask_3: 0.1904  loss_dice_3: 0.5314  loss_ce_4: 0  loss_mask_4: 0.1903  loss_dice_4: 0.5322  loss_ce_5: 0  loss_mask_5: 0.1903  loss_dice_5: 0.5314  loss_ce_6: 0  loss_mask_6: 0.1906  loss_dice_6: 0.5313  loss_ce_7: 0  loss_mask_7: 0.1917  loss_dice_7: 0.5309  loss_ce_8: 0  loss_mask_8: 0.1927  loss_dice_8: 0.5313  time: 1.8689  data_time: 0.1113  lr: 8.7856e-05  max_mem: 5916M
[02/24 17:23:09] d2.utils.events INFO:  eta: 2 days, 0:11:21  iter: 8059  total_loss: 7.712  loss_ce: 0  loss_mask: 0.2003  loss_dice: 0.5407  loss_seg: 0.3016  loss_ce_0: 0  loss_mask_0: 0.197  loss_dice_0: 0.5516  loss_ce_1: 0  loss_mask_1: 0.1999  loss_dice_1: 0.5377  loss_ce_2: 0  loss_mask_2: 0.2015  loss_dice_2: 0.5358  loss_ce_3: 0  loss_mask_3: 0.2002  loss_dice_3: 0.5337  loss_ce_4: 0  loss_mask_4: 0.2014  loss_dice_4: 0.5337  loss_ce_5: 0  loss_mask_5: 0.2021  loss_dice_5: 0.535  loss_ce_6: 0  loss_mask_6: 0.2009  loss_dice_6: 0.534  loss_ce_7: 0  loss_mask_7: 0.2007  loss_dice_7: 0.535  loss_ce_8: 0  loss_mask_8: 0.2008  loss_dice_8: 0.5365  time: 1.8729  data_time: 0.1013  lr: 8.7826e-05  max_mem: 5916M
[02/24 17:24:16] d2.utils.events INFO:  eta: 2 days, 0:16:09  iter: 8079  total_loss: 7.527  loss_ce: 0  loss_mask: 0.1917  loss_dice: 0.5329  loss_seg: 0.2896  loss_ce_0: 0  loss_mask_0: 0.196  loss_dice_0: 0.5446  loss_ce_1: 0  loss_mask_1: 0.1909  loss_dice_1: 0.5326  loss_ce_2: 0  loss_mask_2: 0.1918  loss_dice_2: 0.5296  loss_ce_3: 0  loss_mask_3: 0.1919  loss_dice_3: 0.5256  loss_ce_4: 0  loss_mask_4: 0.192  loss_dice_4: 0.5279  loss_ce_5: 0  loss_mask_5: 0.1915  loss_dice_5: 0.5275  loss_ce_6: 0  loss_mask_6: 0.1921  loss_dice_6: 0.5259  loss_ce_7: 0  loss_mask_7: 0.1916  loss_dice_7: 0.5276  loss_ce_8: 0  loss_mask_8: 0.1911  loss_dice_8: 0.5288  time: 1.8765  data_time: 0.0923  lr: 8.7796e-05  max_mem: 5916M
[02/24 17:25:27] d2.utils.events INFO:  eta: 2 days, 0:24:09  iter: 8099  total_loss: 7.535  loss_ce: 0  loss_mask: 0.2049  loss_dice: 0.5239  loss_seg: 0.2887  loss_ce_0: 0  loss_mask_0: 0.2019  loss_dice_0: 0.5377  loss_ce_1: 0  loss_mask_1: 0.2051  loss_dice_1: 0.5271  loss_ce_2: 0  loss_mask_2: 0.2046  loss_dice_2: 0.5232  loss_ce_3: 0  loss_mask_3: 0.2046  loss_dice_3: 0.52  loss_ce_4: 0  loss_mask_4: 0.2048  loss_dice_4: 0.5216  loss_ce_5: 0  loss_mask_5: 0.2042  loss_dice_5: 0.5218  loss_ce_6: 0  loss_mask_6: 0.2052  loss_dice_6: 0.5226  loss_ce_7: 0  loss_mask_7: 0.2051  loss_dice_7: 0.523  loss_ce_8: 0  loss_mask_8: 0.2046  loss_dice_8: 0.5221  time: 1.8807  data_time: 0.1029  lr: 8.7765e-05  max_mem: 5916M
[02/24 17:26:39] d2.utils.events INFO:  eta: 2 days, 0:39:51  iter: 8119  total_loss: 7.414  loss_ce: 0  loss_mask: 0.205  loss_dice: 0.521  loss_seg: 0.3054  loss_ce_0: 0  loss_mask_0: 0.2033  loss_dice_0: 0.5375  loss_ce_1: 0  loss_mask_1: 0.2018  loss_dice_1: 0.5227  loss_ce_2: 0  loss_mask_2: 0.2017  loss_dice_2: 0.5212  loss_ce_3: 0  loss_mask_3: 0.2011  loss_dice_3: 0.5206  loss_ce_4: 0  loss_mask_4: 0.2015  loss_dice_4: 0.5213  loss_ce_5: 0  loss_mask_5: 0.2028  loss_dice_5: 0.5211  loss_ce_6: 0  loss_mask_6: 0.2028  loss_dice_6: 0.5201  loss_ce_7: 0  loss_mask_7: 0.2031  loss_dice_7: 0.5191  loss_ce_8: 0  loss_mask_8: 0.2036  loss_dice_8: 0.5194  time: 1.8849  data_time: 0.1052  lr: 8.7735e-05  max_mem: 5916M
[02/24 17:27:51] d2.utils.events INFO:  eta: 2 days, 0:54:11  iter: 8139  total_loss: 7.203  loss_ce: 0  loss_mask: 0.1965  loss_dice: 0.5048  loss_seg: 0.253  loss_ce_0: 0  loss_mask_0: 0.1973  loss_dice_0: 0.5275  loss_ce_1: 0  loss_mask_1: 0.1973  loss_dice_1: 0.5069  loss_ce_2: 0  loss_mask_2: 0.1982  loss_dice_2: 0.5029  loss_ce_3: 0  loss_mask_3: 0.1982  loss_dice_3: 0.5005  loss_ce_4: 0  loss_mask_4: 0.1978  loss_dice_4: 0.5013  loss_ce_5: 0  loss_mask_5: 0.1984  loss_dice_5: 0.502  loss_ce_6: 0  loss_mask_6: 0.1978  loss_dice_6: 0.5021  loss_ce_7: 0  loss_mask_7: 0.1979  loss_dice_7: 0.5015  loss_ce_8: 0  loss_mask_8: 0.1971  loss_dice_8: 0.5026  time: 1.8890  data_time: 0.0952  lr: 8.7704e-05  max_mem: 5916M
[02/24 17:28:58] d2.utils.events INFO:  eta: 2 days, 0:58:56  iter: 8159  total_loss: 7.533  loss_ce: 0  loss_mask: 0.2006  loss_dice: 0.5294  loss_seg: 0.2472  loss_ce_0: 0  loss_mask_0: 0.1984  loss_dice_0: 0.5387  loss_ce_1: 0  loss_mask_1: 0.201  loss_dice_1: 0.5296  loss_ce_2: 0  loss_mask_2: 0.2013  loss_dice_2: 0.5263  loss_ce_3: 0  loss_mask_3: 0.2006  loss_dice_3: 0.5233  loss_ce_4: 0  loss_mask_4: 0.2017  loss_dice_4: 0.526  loss_ce_5: 0  loss_mask_5: 0.201  loss_dice_5: 0.5248  loss_ce_6: 0  loss_mask_6: 0.2007  loss_dice_6: 0.523  loss_ce_7: 0  loss_mask_7: 0.2011  loss_dice_7: 0.5262  loss_ce_8: 0  loss_mask_8: 0.2014  loss_dice_8: 0.5252  time: 1.8926  data_time: 0.1158  lr: 8.7674e-05  max_mem: 5916M
[02/24 17:30:04] d2.utils.events INFO:  eta: 2 days, 1:04:41  iter: 8179  total_loss: 7.556  loss_ce: 0  loss_mask: 0.2017  loss_dice: 0.528  loss_seg: 0.2628  loss_ce_0: 0  loss_mask_0: 0.2026  loss_dice_0: 0.5366  loss_ce_1: 0  loss_mask_1: 0.2011  loss_dice_1: 0.5258  loss_ce_2: 0  loss_mask_2: 0.2012  loss_dice_2: 0.5225  loss_ce_3: 0  loss_mask_3: 0.2012  loss_dice_3: 0.5226  loss_ce_4: 0  loss_mask_4: 0.2015  loss_dice_4: 0.5221  loss_ce_5: 0  loss_mask_5: 0.2021  loss_dice_5: 0.5226  loss_ce_6: 0  loss_mask_6: 0.201  loss_dice_6: 0.523  loss_ce_7: 0  loss_mask_7: 0.2019  loss_dice_7: 0.5233  loss_ce_8: 0  loss_mask_8: 0.2025  loss_dice_8: 0.5233  time: 1.8960  data_time: 0.1099  lr: 8.7643e-05  max_mem: 5916M
[02/24 17:31:16] d2.utils.events INFO:  eta: 2 days, 1:13:55  iter: 8199  total_loss: 7.721  loss_ce: 0  loss_mask: 0.1977  loss_dice: 0.5416  loss_seg: 0.2994  loss_ce_0: 0  loss_mask_0: 0.1975  loss_dice_0: 0.5478  loss_ce_1: 0  loss_mask_1: 0.1975  loss_dice_1: 0.541  loss_ce_2: 0  loss_mask_2: 0.1977  loss_dice_2: 0.5378  loss_ce_3: 0  loss_mask_3: 0.1985  loss_dice_3: 0.5355  loss_ce_4: 0  loss_mask_4: 0.1981  loss_dice_4: 0.5368  loss_ce_5: 0  loss_mask_5: 0.1993  loss_dice_5: 0.5361  loss_ce_6: 0  loss_mask_6: 0.1987  loss_dice_6: 0.5345  loss_ce_7: 0  loss_mask_7: 0.1981  loss_dice_7: 0.5346  loss_ce_8: 0  loss_mask_8: 0.1976  loss_dice_8: 0.5356  time: 1.9001  data_time: 0.1109  lr: 8.7613e-05  max_mem: 5916M
[02/24 17:32:26] d2.utils.events INFO:  eta: 2 days, 1:30:59  iter: 8219  total_loss: 7.782  loss_ce: 0  loss_mask: 0.1961  loss_dice: 0.5472  loss_seg: 0.3369  loss_ce_0: 0  loss_mask_0: 0.1959  loss_dice_0: 0.5599  loss_ce_1: 0  loss_mask_1: 0.1955  loss_dice_1: 0.5475  loss_ce_2: 0  loss_mask_2: 0.1973  loss_dice_2: 0.545  loss_ce_3: 0  loss_mask_3: 0.1982  loss_dice_3: 0.5422  loss_ce_4: 0  loss_mask_4: 0.1979  loss_dice_4: 0.5435  loss_ce_5: 0  loss_mask_5: 0.1982  loss_dice_5: 0.5446  loss_ce_6: 0  loss_mask_6: 0.1989  loss_dice_6: 0.5431  loss_ce_7: 0  loss_mask_7: 0.1966  loss_dice_7: 0.5451  loss_ce_8: 0  loss_mask_8: 0.1956  loss_dice_8: 0.5445  time: 1.9040  data_time: 0.1104  lr: 8.7582e-05  max_mem: 5916M
[02/24 17:33:37] d2.utils.events INFO:  eta: 2 days, 1:39:04  iter: 8239  total_loss: 7.418  loss_ce: 0  loss_mask: 0.2002  loss_dice: 0.5161  loss_seg: 0.2854  loss_ce_0: 0  loss_mask_0: 0.1986  loss_dice_0: 0.5292  loss_ce_1: 0  loss_mask_1: 0.1999  loss_dice_1: 0.5153  loss_ce_2: 0  loss_mask_2: 0.1991  loss_dice_2: 0.5137  loss_ce_3: 0  loss_mask_3: 0.1974  loss_dice_3: 0.5118  loss_ce_4: 0  loss_mask_4: 0.1986  loss_dice_4: 0.5134  loss_ce_5: 0  loss_mask_5: 0.1984  loss_dice_5: 0.5153  loss_ce_6: 0  loss_mask_6: 0.1991  loss_dice_6: 0.5132  loss_ce_7: 0  loss_mask_7: 0.199  loss_dice_7: 0.5142  loss_ce_8: 0  loss_mask_8: 0.1991  loss_dice_8: 0.5141  time: 1.9079  data_time: 0.1024  lr: 8.7552e-05  max_mem: 5916M
[02/24 17:34:45] d2.utils.events INFO:  eta: 2 days, 1:44:41  iter: 8259  total_loss: 7.623  loss_ce: 0  loss_mask: 0.2076  loss_dice: 0.5365  loss_seg: 0.2862  loss_ce_0: 0  loss_mask_0: 0.2075  loss_dice_0: 0.5484  loss_ce_1: 0  loss_mask_1: 0.2052  loss_dice_1: 0.5383  loss_ce_2: 0  loss_mask_2: 0.2075  loss_dice_2: 0.5374  loss_ce_3: 0  loss_mask_3: 0.2073  loss_dice_3: 0.5367  loss_ce_4: 0  loss_mask_4: 0.2074  loss_dice_4: 0.536  loss_ce_5: 0  loss_mask_5: 0.2062  loss_dice_5: 0.5362  loss_ce_6: 0  loss_mask_6: 0.2071  loss_dice_6: 0.5345  loss_ce_7: 0  loss_mask_7: 0.2068  loss_dice_7: 0.5362  loss_ce_8: 0  loss_mask_8: 0.2083  loss_dice_8: 0.5386  time: 1.9114  data_time: 0.1013  lr: 8.7522e-05  max_mem: 5916M
[02/24 17:35:57] d2.utils.events INFO:  eta: 2 days, 1:50:02  iter: 8279  total_loss: 7.795  loss_ce: 0  loss_mask: 0.2026  loss_dice: 0.5502  loss_seg: 0.3195  loss_ce_0: 0  loss_mask_0: 0.2073  loss_dice_0: 0.5617  loss_ce_1: 0  loss_mask_1: 0.2006  loss_dice_1: 0.5506  loss_ce_2: 0  loss_mask_2: 0.2013  loss_dice_2: 0.5495  loss_ce_3: 0  loss_mask_3: 0.2011  loss_dice_3: 0.5463  loss_ce_4: 0  loss_mask_4: 0.2014  loss_dice_4: 0.5448  loss_ce_5: 0  loss_mask_5: 0.2017  loss_dice_5: 0.5467  loss_ce_6: 0  loss_mask_6: 0.2013  loss_dice_6: 0.546  loss_ce_7: 0  loss_mask_7: 0.2013  loss_dice_7: 0.5457  loss_ce_8: 0  loss_mask_8: 0.201  loss_dice_8: 0.5461  time: 1.9154  data_time: 0.1090  lr: 8.7491e-05  max_mem: 5916M
[02/24 17:37:05] d2.utils.events INFO:  eta: 2 days, 1:49:01  iter: 8299  total_loss: 7.565  loss_ce: 0  loss_mask: 0.2076  loss_dice: 0.5366  loss_seg: 0.2825  loss_ce_0: 0  loss_mask_0: 0.2084  loss_dice_0: 0.5523  loss_ce_1: 0  loss_mask_1: 0.2081  loss_dice_1: 0.5379  loss_ce_2: 0  loss_mask_2: 0.2078  loss_dice_2: 0.5364  loss_ce_3: 0  loss_mask_3: 0.2077  loss_dice_3: 0.5342  loss_ce_4: 0  loss_mask_4: 0.2075  loss_dice_4: 0.5346  loss_ce_5: 0  loss_mask_5: 0.2082  loss_dice_5: 0.5344  loss_ce_6: 0  loss_mask_6: 0.2077  loss_dice_6: 0.5352  loss_ce_7: 0  loss_mask_7: 0.2074  loss_dice_7: 0.5345  loss_ce_8: 0  loss_mask_8: 0.2089  loss_dice_8: 0.5347  time: 1.9190  data_time: 0.1005  lr: 8.7461e-05  max_mem: 5916M
[02/24 17:38:18] d2.utils.events INFO:  eta: 2 days, 1:46:55  iter: 8319  total_loss: 7.67  loss_ce: 0  loss_mask: 0.2147  loss_dice: 0.5348  loss_seg: 0.3017  loss_ce_0: 0  loss_mask_0: 0.2164  loss_dice_0: 0.5488  loss_ce_1: 0  loss_mask_1: 0.2152  loss_dice_1: 0.5358  loss_ce_2: 0  loss_mask_2: 0.2147  loss_dice_2: 0.5333  loss_ce_3: 0  loss_mask_3: 0.2141  loss_dice_3: 0.5306  loss_ce_4: 0  loss_mask_4: 0.2142  loss_dice_4: 0.5307  loss_ce_5: 0  loss_mask_5: 0.2127  loss_dice_5: 0.5317  loss_ce_6: 0  loss_mask_6: 0.2128  loss_dice_6: 0.532  loss_ce_7: 0  loss_mask_7: 0.2113  loss_dice_7: 0.5329  loss_ce_8: 0  loss_mask_8: 0.2118  loss_dice_8: 0.5327  time: 1.9231  data_time: 0.0926  lr: 8.743e-05  max_mem: 5916M
[02/24 17:39:29] d2.utils.events INFO:  eta: 2 days, 1:45:33  iter: 8339  total_loss: 7.283  loss_ce: 0  loss_mask: 0.1906  loss_dice: 0.5105  loss_seg: 0.2622  loss_ce_0: 0  loss_mask_0: 0.1935  loss_dice_0: 0.5195  loss_ce_1: 0  loss_mask_1: 0.1898  loss_dice_1: 0.5069  loss_ce_2: 0  loss_mask_2: 0.1902  loss_dice_2: 0.5048  loss_ce_3: 0  loss_mask_3: 0.1913  loss_dice_3: 0.5033  loss_ce_4: 0  loss_mask_4: 0.1913  loss_dice_4: 0.5034  loss_ce_5: 0  loss_mask_5: 0.1906  loss_dice_5: 0.5029  loss_ce_6: 0  loss_mask_6: 0.192  loss_dice_6: 0.5039  loss_ce_7: 0  loss_mask_7: 0.1919  loss_dice_7: 0.5041  loss_ce_8: 0  loss_mask_8: 0.1913  loss_dice_8: 0.5046  time: 1.9269  data_time: 0.1123  lr: 8.74e-05  max_mem: 5916M
[02/24 17:40:38] d2.utils.events INFO:  eta: 2 days, 1:42:17  iter: 8359  total_loss: 7.256  loss_ce: 0  loss_mask: 0.1922  loss_dice: 0.505  loss_seg: 0.2744  loss_ce_0: 0  loss_mask_0: 0.1911  loss_dice_0: 0.518  loss_ce_1: 0  loss_mask_1: 0.1902  loss_dice_1: 0.5002  loss_ce_2: 0  loss_mask_2: 0.1914  loss_dice_2: 0.4992  loss_ce_3: 0  loss_mask_3: 0.1917  loss_dice_3: 0.4971  loss_ce_4: 0  loss_mask_4: 0.1909  loss_dice_4: 0.4971  loss_ce_5: 0  loss_mask_5: 0.1908  loss_dice_5: 0.4986  loss_ce_6: 0  loss_mask_6: 0.191  loss_dice_6: 0.4995  loss_ce_7: 0  loss_mask_7: 0.1916  loss_dice_7: 0.4982  loss_ce_8: 0  loss_mask_8: 0.1928  loss_dice_8: 0.4985  time: 1.9305  data_time: 0.0998  lr: 8.7369e-05  max_mem: 5916M
[02/24 17:41:49] d2.utils.events INFO:  eta: 2 days, 1:41:07  iter: 8379  total_loss: 7.743  loss_ce: 0  loss_mask: 0.1974  loss_dice: 0.5336  loss_seg: 0.2595  loss_ce_0: 0  loss_mask_0: 0.2005  loss_dice_0: 0.5441  loss_ce_1: 0  loss_mask_1: 0.1982  loss_dice_1: 0.5325  loss_ce_2: 0  loss_mask_2: 0.1986  loss_dice_2: 0.5304  loss_ce_3: 0  loss_mask_3: 0.199  loss_dice_3: 0.5286  loss_ce_4: 0  loss_mask_4: 0.1987  loss_dice_4: 0.5293  loss_ce_5: 0  loss_mask_5: 0.1977  loss_dice_5: 0.5293  loss_ce_6: 0  loss_mask_6: 0.1984  loss_dice_6: 0.5297  loss_ce_7: 0  loss_mask_7: 0.1985  loss_dice_7: 0.5298  loss_ce_8: 0  loss_mask_8: 0.1988  loss_dice_8: 0.5295  time: 1.9344  data_time: 0.1048  lr: 8.7339e-05  max_mem: 5936M
[02/24 17:43:00] d2.utils.events INFO:  eta: 2 days, 1:39:58  iter: 8399  total_loss: 7.741  loss_ce: 0  loss_mask: 0.2056  loss_dice: 0.5421  loss_seg: 0.2696  loss_ce_0: 0  loss_mask_0: 0.2089  loss_dice_0: 0.5537  loss_ce_1: 0  loss_mask_1: 0.2051  loss_dice_1: 0.5433  loss_ce_2: 0  loss_mask_2: 0.2054  loss_dice_2: 0.5406  loss_ce_3: 0  loss_mask_3: 0.2057  loss_dice_3: 0.5394  loss_ce_4: 0  loss_mask_4: 0.2052  loss_dice_4: 0.5389  loss_ce_5: 0  loss_mask_5: 0.2058  loss_dice_5: 0.5391  loss_ce_6: 0  loss_mask_6: 0.206  loss_dice_6: 0.5398  loss_ce_7: 0  loss_mask_7: 0.2061  loss_dice_7: 0.5394  loss_ce_8: 0  loss_mask_8: 0.2058  loss_dice_8: 0.5391  time: 1.9381  data_time: 0.1062  lr: 8.7308e-05  max_mem: 5936M
[02/24 17:44:09] d2.utils.events INFO:  eta: 2 days, 1:33:41  iter: 8419  total_loss: 7.415  loss_ce: 0  loss_mask: 0.1945  loss_dice: 0.5077  loss_seg: 0.266  loss_ce_0: 0  loss_mask_0: 0.1909  loss_dice_0: 0.5296  loss_ce_1: 0  loss_mask_1: 0.1929  loss_dice_1: 0.5098  loss_ce_2: 0  loss_mask_2: 0.1918  loss_dice_2: 0.5068  loss_ce_3: 0  loss_mask_3: 0.1934  loss_dice_3: 0.5058  loss_ce_4: 0  loss_mask_4: 0.1933  loss_dice_4: 0.5056  loss_ce_5: 0  loss_mask_5: 0.1933  loss_dice_5: 0.5064  loss_ce_6: 0  loss_mask_6: 0.1942  loss_dice_6: 0.5083  loss_ce_7: 0  loss_mask_7: 0.1929  loss_dice_7: 0.5062  loss_ce_8: 0  loss_mask_8: 0.1936  loss_dice_8: 0.5065  time: 1.9416  data_time: 0.1109  lr: 8.7278e-05  max_mem: 5936M
[02/24 17:45:18] d2.utils.events INFO:  eta: 2 days, 1:29:32  iter: 8439  total_loss: 7.468  loss_ce: 0  loss_mask: 0.1991  loss_dice: 0.5162  loss_seg: 0.2538  loss_ce_0: 0  loss_mask_0: 0.2027  loss_dice_0: 0.5264  loss_ce_1: 0  loss_mask_1: 0.1989  loss_dice_1: 0.5159  loss_ce_2: 0  loss_mask_2: 0.198  loss_dice_2: 0.5148  loss_ce_3: 0  loss_mask_3: 0.1977  loss_dice_3: 0.5138  loss_ce_4: 0  loss_mask_4: 0.1972  loss_dice_4: 0.5137  loss_ce_5: 0  loss_mask_5: 0.1963  loss_dice_5: 0.5141  loss_ce_6: 0  loss_mask_6: 0.197  loss_dice_6: 0.5139  loss_ce_7: 0  loss_mask_7: 0.1976  loss_dice_7: 0.514  loss_ce_8: 0  loss_mask_8: 0.1972  loss_dice_8: 0.514  time: 1.9453  data_time: 0.1085  lr: 8.7248e-05  max_mem: 5936M
[02/24 17:46:29] d2.utils.events INFO:  eta: 2 days, 1:26:43  iter: 8459  total_loss: 7.393  loss_ce: 0  loss_mask: 0.1977  loss_dice: 0.5031  loss_seg: 0.2831  loss_ce_0: 0  loss_mask_0: 0.1986  loss_dice_0: 0.5238  loss_ce_1: 0  loss_mask_1: 0.1985  loss_dice_1: 0.5025  loss_ce_2: 0  loss_mask_2: 0.197  loss_dice_2: 0.4999  loss_ce_3: 0  loss_mask_3: 0.1961  loss_dice_3: 0.5008  loss_ce_4: 0  loss_mask_4: 0.1959  loss_dice_4: 0.5009  loss_ce_5: 0  loss_mask_5: 0.197  loss_dice_5: 0.5017  loss_ce_6: 0  loss_mask_6: 0.1969  loss_dice_6: 0.5009  loss_ce_7: 0  loss_mask_7: 0.1964  loss_dice_7: 0.5012  loss_ce_8: 0  loss_mask_8: 0.1979  loss_dice_8: 0.5009  time: 1.9490  data_time: 0.0775  lr: 8.7217e-05  max_mem: 5936M
[02/24 17:47:39] d2.utils.events INFO:  eta: 2 days, 1:25:50  iter: 8479  total_loss: 7.503  loss_ce: 0  loss_mask: 0.1979  loss_dice: 0.5249  loss_seg: 0.2719  loss_ce_0: 0  loss_mask_0: 0.1961  loss_dice_0: 0.5323  loss_ce_1: 0  loss_mask_1: 0.1956  loss_dice_1: 0.5282  loss_ce_2: 0  loss_mask_2: 0.1969  loss_dice_2: 0.5257  loss_ce_3: 0  loss_mask_3: 0.197  loss_dice_3: 0.5235  loss_ce_4: 0  loss_mask_4: 0.1969  loss_dice_4: 0.5235  loss_ce_5: 0  loss_mask_5: 0.1979  loss_dice_5: 0.5229  loss_ce_6: 0  loss_mask_6: 0.1983  loss_dice_6: 0.523  loss_ce_7: 0  loss_mask_7: 0.1981  loss_dice_7: 0.5228  loss_ce_8: 0  loss_mask_8: 0.1984  loss_dice_8: 0.5239  time: 1.9527  data_time: 0.0888  lr: 8.7187e-05  max_mem: 5936M
[02/24 17:48:49] d2.utils.events INFO:  eta: 2 days, 1:24:06  iter: 8499  total_loss: 7.236  loss_ce: 0  loss_mask: 0.1975  loss_dice: 0.5029  loss_seg: 0.2745  loss_ce_0: 0  loss_mask_0: 0.1949  loss_dice_0: 0.5163  loss_ce_1: 0  loss_mask_1: 0.1955  loss_dice_1: 0.5042  loss_ce_2: 0  loss_mask_2: 0.1951  loss_dice_2: 0.5018  loss_ce_3: 0  loss_mask_3: 0.1955  loss_dice_3: 0.4995  loss_ce_4: 0  loss_mask_4: 0.1958  loss_dice_4: 0.4984  loss_ce_5: 0  loss_mask_5: 0.1953  loss_dice_5: 0.4992  loss_ce_6: 0  loss_mask_6: 0.1954  loss_dice_6: 0.4979  loss_ce_7: 0  loss_mask_7: 0.1967  loss_dice_7: 0.4975  loss_ce_8: 0  loss_mask_8: 0.1963  loss_dice_8: 0.4983  time: 1.9562  data_time: 0.1088  lr: 8.7156e-05  max_mem: 5936M
[02/24 17:50:00] d2.utils.events INFO:  eta: 2 days, 1:20:17  iter: 8519  total_loss: 7.329  loss_ce: 0  loss_mask: 0.1944  loss_dice: 0.4925  loss_seg: 0.2862  loss_ce_0: 0  loss_mask_0: 0.1921  loss_dice_0: 0.5129  loss_ce_1: 0  loss_mask_1: 0.1936  loss_dice_1: 0.4927  loss_ce_2: 0  loss_mask_2: 0.1937  loss_dice_2: 0.491  loss_ce_3: 0  loss_mask_3: 0.1941  loss_dice_3: 0.4873  loss_ce_4: 0  loss_mask_4: 0.194  loss_dice_4: 0.488  loss_ce_5: 0  loss_mask_5: 0.1937  loss_dice_5: 0.488  loss_ce_6: 0  loss_mask_6: 0.1944  loss_dice_6: 0.488  loss_ce_7: 0  loss_mask_7: 0.1945  loss_dice_7: 0.4882  loss_ce_8: 0  loss_mask_8: 0.1946  loss_dice_8: 0.4891  time: 1.9599  data_time: 0.1032  lr: 8.7126e-05  max_mem: 5936M
[02/24 17:51:13] d2.utils.events INFO:  eta: 2 days, 1:17:37  iter: 8539  total_loss: 7.613  loss_ce: 0  loss_mask: 0.2002  loss_dice: 0.5258  loss_seg: 0.2966  loss_ce_0: 0  loss_mask_0: 0.1997  loss_dice_0: 0.537  loss_ce_1: 0  loss_mask_1: 0.201  loss_dice_1: 0.5231  loss_ce_2: 0  loss_mask_2: 0.2019  loss_dice_2: 0.5217  loss_ce_3: 0  loss_mask_3: 0.2018  loss_dice_3: 0.5199  loss_ce_4: 0  loss_mask_4: 0.2018  loss_dice_4: 0.52  loss_ce_5: 0  loss_mask_5: 0.2015  loss_dice_5: 0.5201  loss_ce_6: 0  loss_mask_6: 0.2008  loss_dice_6: 0.5221  loss_ce_7: 0  loss_mask_7: 0.2006  loss_dice_7: 0.5225  loss_ce_8: 0  loss_mask_8: 0.1999  loss_dice_8: 0.5229  time: 1.9638  data_time: 0.1178  lr: 8.7095e-05  max_mem: 5936M
[02/24 17:52:24] d2.utils.events INFO:  eta: 2 days, 1:19:27  iter: 8559  total_loss: 7.545  loss_ce: 0  loss_mask: 0.1937  loss_dice: 0.5262  loss_seg: 0.2757  loss_ce_0: 0  loss_mask_0: 0.1961  loss_dice_0: 0.5424  loss_ce_1: 0  loss_mask_1: 0.1958  loss_dice_1: 0.5254  loss_ce_2: 0  loss_mask_2: 0.1959  loss_dice_2: 0.5241  loss_ce_3: 0  loss_mask_3: 0.1961  loss_dice_3: 0.5234  loss_ce_4: 0  loss_mask_4: 0.1956  loss_dice_4: 0.5237  loss_ce_5: 0  loss_mask_5: 0.1948  loss_dice_5: 0.5245  loss_ce_6: 0  loss_mask_6: 0.1952  loss_dice_6: 0.5231  loss_ce_7: 0  loss_mask_7: 0.194  loss_dice_7: 0.5245  loss_ce_8: 0  loss_mask_8: 0.1941  loss_dice_8: 0.5243  time: 1.9675  data_time: 0.1216  lr: 8.7065e-05  max_mem: 5936M
[02/24 17:53:36] d2.utils.events INFO:  eta: 2 days, 1:20:16  iter: 8579  total_loss: 7.363  loss_ce: 0  loss_mask: 0.195  loss_dice: 0.5134  loss_seg: 0.2712  loss_ce_0: 0  loss_mask_0: 0.1963  loss_dice_0: 0.5337  loss_ce_1: 0  loss_mask_1: 0.1951  loss_dice_1: 0.5125  loss_ce_2: 0  loss_mask_2: 0.1952  loss_dice_2: 0.5109  loss_ce_3: 0  loss_mask_3: 0.1955  loss_dice_3: 0.5105  loss_ce_4: 0  loss_mask_4: 0.1959  loss_dice_4: 0.5103  loss_ce_5: 0  loss_mask_5: 0.195  loss_dice_5: 0.5098  loss_ce_6: 0  loss_mask_6: 0.1961  loss_dice_6: 0.5096  loss_ce_7: 0  loss_mask_7: 0.196  loss_dice_7: 0.5084  loss_ce_8: 0  loss_mask_8: 0.1961  loss_dice_8: 0.5101  time: 1.9713  data_time: 0.0918  lr: 8.7034e-05  max_mem: 5936M
[02/24 17:54:45] d2.utils.events INFO:  eta: 2 days, 1:20:19  iter: 8599  total_loss: 7.713  loss_ce: 0  loss_mask: 0.1998  loss_dice: 0.5417  loss_seg: 0.3103  loss_ce_0: 0  loss_mask_0: 0.2008  loss_dice_0: 0.5467  loss_ce_1: 0  loss_mask_1: 0.198  loss_dice_1: 0.5397  loss_ce_2: 0  loss_mask_2: 0.1988  loss_dice_2: 0.5395  loss_ce_3: 0  loss_mask_3: 0.2003  loss_dice_3: 0.5381  loss_ce_4: 0  loss_mask_4: 0.1996  loss_dice_4: 0.5388  loss_ce_5: 0  loss_mask_5: 0.1995  loss_dice_5: 0.5404  loss_ce_6: 0  loss_mask_6: 0.1998  loss_dice_6: 0.5387  loss_ce_7: 0  loss_mask_7: 0.201  loss_dice_7: 0.5382  loss_ce_8: 0  loss_mask_8: 0.2003  loss_dice_8: 0.5379  time: 1.9747  data_time: 0.0986  lr: 8.7004e-05  max_mem: 5936M
[02/24 17:55:59] d2.utils.events INFO:  eta: 2 days, 1:24:29  iter: 8619  total_loss: 7.38  loss_ce: 0  loss_mask: 0.1937  loss_dice: 0.516  loss_seg: 0.2447  loss_ce_0: 0  loss_mask_0: 0.1939  loss_dice_0: 0.5307  loss_ce_1: 0  loss_mask_1: 0.1929  loss_dice_1: 0.5153  loss_ce_2: 0  loss_mask_2: 0.1935  loss_dice_2: 0.515  loss_ce_3: 0  loss_mask_3: 0.1937  loss_dice_3: 0.5131  loss_ce_4: 0  loss_mask_4: 0.1926  loss_dice_4: 0.5138  loss_ce_5: 0  loss_mask_5: 0.1938  loss_dice_5: 0.5139  loss_ce_6: 0  loss_mask_6: 0.1946  loss_dice_6: 0.5132  loss_ce_7: 0  loss_mask_7: 0.1934  loss_dice_7: 0.5146  loss_ce_8: 0  loss_mask_8: 0.1937  loss_dice_8: 0.5145  time: 1.9785  data_time: 0.1049  lr: 8.6973e-05  max_mem: 5936M
[02/24 17:57:10] d2.utils.events INFO:  eta: 2 days, 1:28:26  iter: 8639  total_loss: 7.098  loss_ce: 0  loss_mask: 0.1976  loss_dice: 0.4982  loss_seg: 0.282  loss_ce_0: 0  loss_mask_0: 0.1939  loss_dice_0: 0.5095  loss_ce_1: 0  loss_mask_1: 0.1948  loss_dice_1: 0.496  loss_ce_2: 0  loss_mask_2: 0.1937  loss_dice_2: 0.4924  loss_ce_3: 0  loss_mask_3: 0.1943  loss_dice_3: 0.4931  loss_ce_4: 0  loss_mask_4: 0.1951  loss_dice_4: 0.4941  loss_ce_5: 0  loss_mask_5: 0.1933  loss_dice_5: 0.4939  loss_ce_6: 0  loss_mask_6: 0.1937  loss_dice_6: 0.495  loss_ce_7: 0  loss_mask_7: 0.1941  loss_dice_7: 0.4967  loss_ce_8: 0  loss_mask_8: 0.194  loss_dice_8: 0.4952  time: 1.9822  data_time: 0.0997  lr: 8.6943e-05  max_mem: 5936M
[02/24 17:58:21] d2.utils.events INFO:  eta: 2 days, 1:28:04  iter: 8659  total_loss: 7.424  loss_ce: 0  loss_mask: 0.2013  loss_dice: 0.5093  loss_seg: 0.2909  loss_ce_0: 0  loss_mask_0: 0.2023  loss_dice_0: 0.5239  loss_ce_1: 0  loss_mask_1: 0.1999  loss_dice_1: 0.5112  loss_ce_2: 0  loss_mask_2: 0.2014  loss_dice_2: 0.5076  loss_ce_3: 0  loss_mask_3: 0.2016  loss_dice_3: 0.5061  loss_ce_4: 0  loss_mask_4: 0.2002  loss_dice_4: 0.5061  loss_ce_5: 0  loss_mask_5: 0.2008  loss_dice_5: 0.5061  loss_ce_6: 0  loss_mask_6: 0.2013  loss_dice_6: 0.507  loss_ce_7: 0  loss_mask_7: 0.2005  loss_dice_7: 0.5076  loss_ce_8: 0  loss_mask_8: 0.2009  loss_dice_8: 0.5068  time: 1.9858  data_time: 0.1085  lr: 8.6912e-05  max_mem: 5936M
[02/24 17:59:32] d2.utils.events INFO:  eta: 2 days, 1:26:19  iter: 8679  total_loss: 7.214  loss_ce: 0  loss_mask: 0.199  loss_dice: 0.5049  loss_seg: 0.2519  loss_ce_0: 0  loss_mask_0: 0.1999  loss_dice_0: 0.513  loss_ce_1: 0  loss_mask_1: 0.1984  loss_dice_1: 0.5061  loss_ce_2: 0  loss_mask_2: 0.1984  loss_dice_2: 0.5022  loss_ce_3: 0  loss_mask_3: 0.1994  loss_dice_3: 0.5  loss_ce_4: 0  loss_mask_4: 0.1991  loss_dice_4: 0.501  loss_ce_5: 0  loss_mask_5: 0.1984  loss_dice_5: 0.5013  loss_ce_6: 0  loss_mask_6: 0.1992  loss_dice_6: 0.4995  loss_ce_7: 0  loss_mask_7: 0.198  loss_dice_7: 0.5014  loss_ce_8: 0  loss_mask_8: 0.1984  loss_dice_8: 0.5021  time: 1.9893  data_time: 0.1243  lr: 8.6882e-05  max_mem: 5936M
[02/24 18:00:45] d2.utils.events INFO:  eta: 2 days, 1:25:32  iter: 8699  total_loss: 7.349  loss_ce: 0  loss_mask: 0.1937  loss_dice: 0.5174  loss_seg: 0.2525  loss_ce_0: 0  loss_mask_0: 0.1959  loss_dice_0: 0.5223  loss_ce_1: 0  loss_mask_1: 0.195  loss_dice_1: 0.5179  loss_ce_2: 0  loss_mask_2: 0.1962  loss_dice_2: 0.5154  loss_ce_3: 0  loss_mask_3: 0.1969  loss_dice_3: 0.5144  loss_ce_4: 0  loss_mask_4: 0.1962  loss_dice_4: 0.5152  loss_ce_5: 0  loss_mask_5: 0.1956  loss_dice_5: 0.5147  loss_ce_6: 0  loss_mask_6: 0.1952  loss_dice_6: 0.5136  loss_ce_7: 0  loss_mask_7: 0.1949  loss_dice_7: 0.5159  loss_ce_8: 0  loss_mask_8: 0.1952  loss_dice_8: 0.516  time: 1.9931  data_time: 0.1050  lr: 8.6851e-05  max_mem: 5936M
[02/24 18:01:58] d2.utils.events INFO:  eta: 2 days, 1:31:22  iter: 8719  total_loss: 7.39  loss_ce: 0  loss_mask: 0.1985  loss_dice: 0.52  loss_seg: 0.256  loss_ce_0: 0  loss_mask_0: 0.1995  loss_dice_0: 0.5354  loss_ce_1: 0  loss_mask_1: 0.1958  loss_dice_1: 0.5201  loss_ce_2: 0  loss_mask_2: 0.1967  loss_dice_2: 0.5169  loss_ce_3: 0  loss_mask_3: 0.1986  loss_dice_3: 0.5156  loss_ce_4: 0  loss_mask_4: 0.1976  loss_dice_4: 0.5161  loss_ce_5: 0  loss_mask_5: 0.1964  loss_dice_5: 0.5165  loss_ce_6: 0  loss_mask_6: 0.1977  loss_dice_6: 0.5153  loss_ce_7: 0  loss_mask_7: 0.1982  loss_dice_7: 0.5158  loss_ce_8: 0  loss_mask_8: 0.198  loss_dice_8: 0.5168  time: 1.9969  data_time: 0.1108  lr: 8.6821e-05  max_mem: 5936M
[02/24 18:03:12] d2.utils.events INFO:  eta: 2 days, 1:40:05  iter: 8739  total_loss: 7.52  loss_ce: 0  loss_mask: 0.1954  loss_dice: 0.5177  loss_seg: 0.2806  loss_ce_0: 0  loss_mask_0: 0.1931  loss_dice_0: 0.5373  loss_ce_1: 0  loss_mask_1: 0.1945  loss_dice_1: 0.5167  loss_ce_2: 0  loss_mask_2: 0.1954  loss_dice_2: 0.5154  loss_ce_3: 0  loss_mask_3: 0.1965  loss_dice_3: 0.514  loss_ce_4: 0  loss_mask_4: 0.1966  loss_dice_4: 0.5131  loss_ce_5: 0  loss_mask_5: 0.1959  loss_dice_5: 0.5138  loss_ce_6: 0  loss_mask_6: 0.1962  loss_dice_6: 0.5144  loss_ce_7: 0  loss_mask_7: 0.1965  loss_dice_7: 0.5129  loss_ce_8: 0  loss_mask_8: 0.1953  loss_dice_8: 0.5141  time: 2.0008  data_time: 0.1041  lr: 8.6791e-05  max_mem: 5936M
[02/24 18:04:23] d2.utils.events INFO:  eta: 2 days, 1:36:29  iter: 8759  total_loss: 7.292  loss_ce: 0  loss_mask: 0.1925  loss_dice: 0.5012  loss_seg: 0.2536  loss_ce_0: 0  loss_mask_0: 0.1917  loss_dice_0: 0.5155  loss_ce_1: 0  loss_mask_1: 0.1926  loss_dice_1: 0.5003  loss_ce_2: 0  loss_mask_2: 0.1929  loss_dice_2: 0.4983  loss_ce_3: 0  loss_mask_3: 0.1926  loss_dice_3: 0.4964  loss_ce_4: 0  loss_mask_4: 0.1936  loss_dice_4: 0.4978  loss_ce_5: 0  loss_mask_5: 0.1932  loss_dice_5: 0.4985  loss_ce_6: 0  loss_mask_6: 0.1931  loss_dice_6: 0.4987  loss_ce_7: 0  loss_mask_7: 0.1942  loss_dice_7: 0.4995  loss_ce_8: 0  loss_mask_8: 0.194  loss_dice_8: 0.4995  time: 2.0043  data_time: 0.1046  lr: 8.676e-05  max_mem: 5936M
[02/24 18:05:33] d2.utils.events INFO:  eta: 2 days, 1:33:41  iter: 8779  total_loss: 7.496  loss_ce: 0  loss_mask: 0.1989  loss_dice: 0.5256  loss_seg: 0.2872  loss_ce_0: 0  loss_mask_0: 0.1986  loss_dice_0: 0.5381  loss_ce_1: 0  loss_mask_1: 0.1958  loss_dice_1: 0.5265  loss_ce_2: 0  loss_mask_2: 0.1955  loss_dice_2: 0.5247  loss_ce_3: 0  loss_mask_3: 0.1954  loss_dice_3: 0.5236  loss_ce_4: 0  loss_mask_4: 0.1952  loss_dice_4: 0.5241  loss_ce_5: 0  loss_mask_5: 0.1956  loss_dice_5: 0.5259  loss_ce_6: 0  loss_mask_6: 0.1969  loss_dice_6: 0.5243  loss_ce_7: 0  loss_mask_7: 0.1981  loss_dice_7: 0.5243  loss_ce_8: 0  loss_mask_8: 0.1969  loss_dice_8: 0.525  time: 2.0076  data_time: 0.1018  lr: 8.673e-05  max_mem: 5936M
[02/24 18:06:45] d2.utils.events INFO:  eta: 2 days, 1:31:06  iter: 8799  total_loss: 7.433  loss_ce: 0  loss_mask: 0.2001  loss_dice: 0.5125  loss_seg: 0.2779  loss_ce_0: 0  loss_mask_0: 0.1996  loss_dice_0: 0.5261  loss_ce_1: 0  loss_mask_1: 0.1996  loss_dice_1: 0.5133  loss_ce_2: 0  loss_mask_2: 0.1994  loss_dice_2: 0.5107  loss_ce_3: 0  loss_mask_3: 0.2004  loss_dice_3: 0.5105  loss_ce_4: 0  loss_mask_4: 0.2009  loss_dice_4: 0.5101  loss_ce_5: 0  loss_mask_5: 0.2011  loss_dice_5: 0.5103  loss_ce_6: 0  loss_mask_6: 0.2012  loss_dice_6: 0.5105  loss_ce_7: 0  loss_mask_7: 0.2007  loss_dice_7: 0.5102  loss_ce_8: 0  loss_mask_8: 0.1998  loss_dice_8: 0.511  time: 2.0112  data_time: 0.1284  lr: 8.6699e-05  max_mem: 5936M
[02/24 18:07:53] d2.utils.events INFO:  eta: 2 days, 1:27:29  iter: 8819  total_loss: 7.205  loss_ce: 0  loss_mask: 0.1877  loss_dice: 0.5076  loss_seg: 0.2595  loss_ce_0: 0  loss_mask_0: 0.1897  loss_dice_0: 0.5236  loss_ce_1: 0  loss_mask_1: 0.1859  loss_dice_1: 0.5101  loss_ce_2: 0  loss_mask_2: 0.1866  loss_dice_2: 0.5093  loss_ce_3: 0  loss_mask_3: 0.1872  loss_dice_3: 0.5065  loss_ce_4: 0  loss_mask_4: 0.1875  loss_dice_4: 0.5061  loss_ce_5: 0  loss_mask_5: 0.1865  loss_dice_5: 0.5058  loss_ce_6: 0  loss_mask_6: 0.1875  loss_dice_6: 0.5044  loss_ce_7: 0  loss_mask_7: 0.1859  loss_dice_7: 0.5035  loss_ce_8: 0  loss_mask_8: 0.1859  loss_dice_8: 0.5055  time: 2.0143  data_time: 0.0924  lr: 8.6669e-05  max_mem: 5936M
[02/24 18:09:01] d2.utils.events INFO:  eta: 2 days, 1:25:34  iter: 8839  total_loss: 7.215  loss_ce: 0  loss_mask: 0.1829  loss_dice: 0.5084  loss_seg: 0.2867  loss_ce_0: 0  loss_mask_0: 0.1831  loss_dice_0: 0.5226  loss_ce_1: 0  loss_mask_1: 0.1831  loss_dice_1: 0.5092  loss_ce_2: 0  loss_mask_2: 0.1842  loss_dice_2: 0.5074  loss_ce_3: 0  loss_mask_3: 0.1845  loss_dice_3: 0.5042  loss_ce_4: 0  loss_mask_4: 0.1846  loss_dice_4: 0.5043  loss_ce_5: 0  loss_mask_5: 0.1849  loss_dice_5: 0.5047  loss_ce_6: 0  loss_mask_6: 0.1846  loss_dice_6: 0.5049  loss_ce_7: 0  loss_mask_7: 0.1843  loss_dice_7: 0.5047  loss_ce_8: 0  loss_mask_8: 0.1839  loss_dice_8: 0.5054  time: 2.0174  data_time: 0.1059  lr: 8.6638e-05  max_mem: 5936M
[02/24 18:10:16] d2.utils.events INFO:  eta: 2 days, 1:30:40  iter: 8859  total_loss: 7.389  loss_ce: 0  loss_mask: 0.1907  loss_dice: 0.5131  loss_seg: 0.2736  loss_ce_0: 0  loss_mask_0: 0.1943  loss_dice_0: 0.5365  loss_ce_1: 0  loss_mask_1: 0.1921  loss_dice_1: 0.5143  loss_ce_2: 0  loss_mask_2: 0.1927  loss_dice_2: 0.5146  loss_ce_3: 0  loss_mask_3: 0.1927  loss_dice_3: 0.5137  loss_ce_4: 0  loss_mask_4: 0.1921  loss_dice_4: 0.5131  loss_ce_5: 0  loss_mask_5: 0.1932  loss_dice_5: 0.5139  loss_ce_6: 0  loss_mask_6: 0.1916  loss_dice_6: 0.5117  loss_ce_7: 0  loss_mask_7: 0.1922  loss_dice_7: 0.5111  loss_ce_8: 0  loss_mask_8: 0.1919  loss_dice_8: 0.5118  time: 2.0212  data_time: 0.1534  lr: 8.6608e-05  max_mem: 5936M
[02/24 18:11:23] d2.utils.events INFO:  eta: 2 days, 1:25:25  iter: 8879  total_loss: 7.316  loss_ce: 0  loss_mask: 0.1957  loss_dice: 0.5082  loss_seg: 0.2553  loss_ce_0: 0  loss_mask_0: 0.196  loss_dice_0: 0.5211  loss_ce_1: 0  loss_mask_1: 0.1958  loss_dice_1: 0.5086  loss_ce_2: 0  loss_mask_2: 0.1967  loss_dice_2: 0.5076  loss_ce_3: 0  loss_mask_3: 0.1954  loss_dice_3: 0.5056  loss_ce_4: 0  loss_mask_4: 0.1951  loss_dice_4: 0.5058  loss_ce_5: 0  loss_mask_5: 0.1953  loss_dice_5: 0.5061  loss_ce_6: 0  loss_mask_6: 0.1957  loss_dice_6: 0.5065  loss_ce_7: 0  loss_mask_7: 0.1964  loss_dice_7: 0.5053  loss_ce_8: 0  loss_mask_8: 0.1964  loss_dice_8: 0.5061  time: 2.0242  data_time: 0.1168  lr: 8.6577e-05  max_mem: 5936M
[02/24 18:12:37] d2.utils.events INFO:  eta: 2 days, 1:30:52  iter: 8899  total_loss: 7.35  loss_ce: 0  loss_mask: 0.1938  loss_dice: 0.5076  loss_seg: 0.2664  loss_ce_0: 0  loss_mask_0: 0.1911  loss_dice_0: 0.5189  loss_ce_1: 0  loss_mask_1: 0.194  loss_dice_1: 0.5053  loss_ce_2: 0  loss_mask_2: 0.1936  loss_dice_2: 0.5044  loss_ce_3: 0  loss_mask_3: 0.1945  loss_dice_3: 0.5039  loss_ce_4: 0  loss_mask_4: 0.1958  loss_dice_4: 0.5052  loss_ce_5: 0  loss_mask_5: 0.1959  loss_dice_5: 0.5041  loss_ce_6: 0  loss_mask_6: 0.1956  loss_dice_6: 0.5053  loss_ce_7: 0  loss_mask_7: 0.1947  loss_dice_7: 0.5058  loss_ce_8: 0  loss_mask_8: 0.1945  loss_dice_8: 0.5055  time: 2.0280  data_time: 0.1048  lr: 8.6547e-05  max_mem: 5936M
[02/24 18:13:46] d2.utils.events INFO:  eta: 2 days, 1:29:43  iter: 8919  total_loss: 7.554  loss_ce: 0  loss_mask: 0.2021  loss_dice: 0.5236  loss_seg: 0.2797  loss_ce_0: 0  loss_mask_0: 0.2018  loss_dice_0: 0.5303  loss_ce_1: 0  loss_mask_1: 0.2013  loss_dice_1: 0.5239  loss_ce_2: 0  loss_mask_2: 0.2008  loss_dice_2: 0.5216  loss_ce_3: 0  loss_mask_3: 0.2026  loss_dice_3: 0.5204  loss_ce_4: 0  loss_mask_4: 0.2025  loss_dice_4: 0.522  loss_ce_5: 0  loss_mask_5: 0.202  loss_dice_5: 0.5204  loss_ce_6: 0  loss_mask_6: 0.2014  loss_dice_6: 0.5214  loss_ce_7: 0  loss_mask_7: 0.2011  loss_dice_7: 0.5207  loss_ce_8: 0  loss_mask_8: 0.201  loss_dice_8: 0.5212  time: 2.0311  data_time: 0.1035  lr: 8.6516e-05  max_mem: 5936M
[02/24 18:14:57] d2.utils.events INFO:  eta: 2 days, 1:32:22  iter: 8939  total_loss: 7.378  loss_ce: 0  loss_mask: 0.1966  loss_dice: 0.5293  loss_seg: 0.265  loss_ce_0: 0  loss_mask_0: 0.1948  loss_dice_0: 0.5446  loss_ce_1: 0  loss_mask_1: 0.1956  loss_dice_1: 0.5295  loss_ce_2: 0  loss_mask_2: 0.1964  loss_dice_2: 0.5257  loss_ce_3: 0  loss_mask_3: 0.1966  loss_dice_3: 0.5256  loss_ce_4: 0  loss_mask_4: 0.1965  loss_dice_4: 0.5253  loss_ce_5: 0  loss_mask_5: 0.1967  loss_dice_5: 0.5245  loss_ce_6: 0  loss_mask_6: 0.1965  loss_dice_6: 0.5234  loss_ce_7: 0  loss_mask_7: 0.1965  loss_dice_7: 0.5246  loss_ce_8: 0  loss_mask_8: 0.197  loss_dice_8: 0.5262  time: 2.0345  data_time: 0.1134  lr: 8.6486e-05  max_mem: 5936M
[02/24 18:16:06] d2.utils.events INFO:  eta: 2 days, 1:30:40  iter: 8959  total_loss: 7.47  loss_ce: 0  loss_mask: 0.1977  loss_dice: 0.5206  loss_seg: 0.2719  loss_ce_0: 0  loss_mask_0: 0.201  loss_dice_0: 0.5324  loss_ce_1: 0  loss_mask_1: 0.1983  loss_dice_1: 0.5188  loss_ce_2: 0  loss_mask_2: 0.1985  loss_dice_2: 0.5173  loss_ce_3: 0  loss_mask_3: 0.1983  loss_dice_3: 0.5153  loss_ce_4: 0  loss_mask_4: 0.1988  loss_dice_4: 0.5163  loss_ce_5: 0  loss_mask_5: 0.1991  loss_dice_5: 0.5163  loss_ce_6: 0  loss_mask_6: 0.1986  loss_dice_6: 0.5156  loss_ce_7: 0  loss_mask_7: 0.1977  loss_dice_7: 0.5167  loss_ce_8: 0  loss_mask_8: 0.1981  loss_dice_8: 0.5171  time: 2.0376  data_time: 0.0902  lr: 8.6455e-05  max_mem: 5936M
[02/24 18:17:19] d2.utils.events INFO:  eta: 2 days, 1:38:10  iter: 8979  total_loss: 7.587  loss_ce: 0  loss_mask: 0.1962  loss_dice: 0.521  loss_seg: 0.2593  loss_ce_0: 0  loss_mask_0: 0.1964  loss_dice_0: 0.5364  loss_ce_1: 0  loss_mask_1: 0.1967  loss_dice_1: 0.5208  loss_ce_2: 0  loss_mask_2: 0.196  loss_dice_2: 0.5184  loss_ce_3: 0  loss_mask_3: 0.1953  loss_dice_3: 0.5182  loss_ce_4: 0  loss_mask_4: 0.1954  loss_dice_4: 0.5187  loss_ce_5: 0  loss_mask_5: 0.195  loss_dice_5: 0.5201  loss_ce_6: 0  loss_mask_6: 0.1954  loss_dice_6: 0.5196  loss_ce_7: 0  loss_mask_7: 0.1965  loss_dice_7: 0.5193  loss_ce_8: 0  loss_mask_8: 0.1963  loss_dice_8: 0.5189  time: 2.0411  data_time: 0.1142  lr: 8.6425e-05  max_mem: 5936M
[02/24 18:18:28] d2.utils.events INFO:  eta: 2 days, 1:29:33  iter: 8999  total_loss: 7.363  loss_ce: 0  loss_mask: 0.1947  loss_dice: 0.5105  loss_seg: 0.2631  loss_ce_0: 0  loss_mask_0: 0.1929  loss_dice_0: 0.5253  loss_ce_1: 0  loss_mask_1: 0.1942  loss_dice_1: 0.5123  loss_ce_2: 0  loss_mask_2: 0.1946  loss_dice_2: 0.5088  loss_ce_3: 0  loss_mask_3: 0.1954  loss_dice_3: 0.5066  loss_ce_4: 0  loss_mask_4: 0.1962  loss_dice_4: 0.5079  loss_ce_5: 0  loss_mask_5: 0.1958  loss_dice_5: 0.5086  loss_ce_6: 0  loss_mask_6: 0.1959  loss_dice_6: 0.507  loss_ce_7: 0  loss_mask_7: 0.1953  loss_dice_7: 0.5076  loss_ce_8: 0  loss_mask_8: 0.1954  loss_dice_8: 0.5089  time: 2.0442  data_time: 0.1065  lr: 8.6394e-05  max_mem: 5936M
[02/24 18:19:39] d2.utils.events INFO:  eta: 2 days, 1:31:19  iter: 9019  total_loss: 7.286  loss_ce: 0  loss_mask: 0.1988  loss_dice: 0.5061  loss_seg: 0.2623  loss_ce_0: 0  loss_mask_0: 0.1967  loss_dice_0: 0.522  loss_ce_1: 0  loss_mask_1: 0.1966  loss_dice_1: 0.5093  loss_ce_2: 0  loss_mask_2: 0.1979  loss_dice_2: 0.5046  loss_ce_3: 0  loss_mask_3: 0.1977  loss_dice_3: 0.5028  loss_ce_4: 0  loss_mask_4: 0.1976  loss_dice_4: 0.5038  loss_ce_5: 0  loss_mask_5: 0.1978  loss_dice_5: 0.5049  loss_ce_6: 0  loss_mask_6: 0.1988  loss_dice_6: 0.5039  loss_ce_7: 0  loss_mask_7: 0.197  loss_dice_7: 0.5038  loss_ce_8: 0  loss_mask_8: 0.1985  loss_dice_8: 0.5041  time: 2.0475  data_time: 0.1192  lr: 8.6364e-05  max_mem: 5936M
[02/24 18:20:52] d2.utils.events INFO:  eta: 2 days, 1:40:25  iter: 9039  total_loss: 7.566  loss_ce: 0  loss_mask: 0.1954  loss_dice: 0.5324  loss_seg: 0.276  loss_ce_0: 0  loss_mask_0: 0.1932  loss_dice_0: 0.5478  loss_ce_1: 0  loss_mask_1: 0.1941  loss_dice_1: 0.5354  loss_ce_2: 0  loss_mask_2: 0.1935  loss_dice_2: 0.5324  loss_ce_3: 0  loss_mask_3: 0.1933  loss_dice_3: 0.53  loss_ce_4: 0  loss_mask_4: 0.1934  loss_dice_4: 0.5316  loss_ce_5: 0  loss_mask_5: 0.1933  loss_dice_5: 0.5311  loss_ce_6: 0  loss_mask_6: 0.1927  loss_dice_6: 0.5314  loss_ce_7: 0  loss_mask_7: 0.193  loss_dice_7: 0.5333  loss_ce_8: 0  loss_mask_8: 0.1935  loss_dice_8: 0.5323  time: 2.0510  data_time: 0.1075  lr: 8.6333e-05  max_mem: 5936M
[02/24 18:22:08] d2.utils.events INFO:  eta: 2 days, 1:44:30  iter: 9059  total_loss: 7.305  loss_ce: 0  loss_mask: 0.1903  loss_dice: 0.5105  loss_seg: 0.2713  loss_ce_0: 0  loss_mask_0: 0.192  loss_dice_0: 0.5289  loss_ce_1: 0  loss_mask_1: 0.1904  loss_dice_1: 0.5117  loss_ce_2: 0  loss_mask_2: 0.1903  loss_dice_2: 0.5098  loss_ce_3: 0  loss_mask_3: 0.1907  loss_dice_3: 0.5069  loss_ce_4: 0  loss_mask_4: 0.1914  loss_dice_4: 0.5072  loss_ce_5: 0  loss_mask_5: 0.1912  loss_dice_5: 0.5073  loss_ce_6: 0  loss_mask_6: 0.1904  loss_dice_6: 0.5057  loss_ce_7: 0  loss_mask_7: 0.1908  loss_dice_7: 0.5064  loss_ce_8: 0  loss_mask_8: 0.1918  loss_dice_8: 0.5061  time: 2.0549  data_time: 0.1093  lr: 8.6303e-05  max_mem: 5936M
[02/24 18:23:22] d2.utils.events INFO:  eta: 2 days, 1:49:51  iter: 9079  total_loss: 7.407  loss_ce: 0  loss_mask: 0.202  loss_dice: 0.51  loss_seg: 0.2562  loss_ce_0: 0  loss_mask_0: 0.2027  loss_dice_0: 0.5216  loss_ce_1: 0  loss_mask_1: 0.1997  loss_dice_1: 0.5105  loss_ce_2: 0  loss_mask_2: 0.202  loss_dice_2: 0.5075  loss_ce_3: 0  loss_mask_3: 0.2024  loss_dice_3: 0.5055  loss_ce_4: 0  loss_mask_4: 0.2019  loss_dice_4: 0.5057  loss_ce_5: 0  loss_mask_5: 0.2032  loss_dice_5: 0.506  loss_ce_6: 0  loss_mask_6: 0.2037  loss_dice_6: 0.505  loss_ce_7: 0  loss_mask_7: 0.2027  loss_dice_7: 0.5058  loss_ce_8: 0  loss_mask_8: 0.2026  loss_dice_8: 0.5075  time: 2.0585  data_time: 0.1075  lr: 8.6272e-05  max_mem: 5936M
[02/24 18:24:35] d2.utils.events INFO:  eta: 2 days, 1:49:13  iter: 9099  total_loss: 7.305  loss_ce: 0  loss_mask: 0.2011  loss_dice: 0.508  loss_seg: 0.2514  loss_ce_0: 0  loss_mask_0: 0.1982  loss_dice_0: 0.5226  loss_ce_1: 0  loss_mask_1: 0.2006  loss_dice_1: 0.5062  loss_ce_2: 0  loss_mask_2: 0.1998  loss_dice_2: 0.5052  loss_ce_3: 0  loss_mask_3: 0.1988  loss_dice_3: 0.5046  loss_ce_4: 0  loss_mask_4: 0.1988  loss_dice_4: 0.5042  loss_ce_5: 0  loss_mask_5: 0.2001  loss_dice_5: 0.5039  loss_ce_6: 0  loss_mask_6: 0.1994  loss_dice_6: 0.5022  loss_ce_7: 0  loss_mask_7: 0.2014  loss_dice_7: 0.5021  loss_ce_8: 0  loss_mask_8: 0.2004  loss_dice_8: 0.5026  time: 2.0619  data_time: 0.0868  lr: 8.6242e-05  max_mem: 5936M
[02/24 18:25:49] d2.utils.events INFO:  eta: 2 days, 1:48:37  iter: 9119  total_loss: 7.522  loss_ce: 0  loss_mask: 0.1944  loss_dice: 0.5188  loss_seg: 0.2835  loss_ce_0: 0  loss_mask_0: 0.1953  loss_dice_0: 0.5261  loss_ce_1: 0  loss_mask_1: 0.1932  loss_dice_1: 0.5203  loss_ce_2: 0  loss_mask_2: 0.1929  loss_dice_2: 0.5173  loss_ce_3: 0  loss_mask_3: 0.1944  loss_dice_3: 0.516  loss_ce_4: 0  loss_mask_4: 0.1946  loss_dice_4: 0.5155  loss_ce_5: 0  loss_mask_5: 0.1938  loss_dice_5: 0.5174  loss_ce_6: 0  loss_mask_6: 0.194  loss_dice_6: 0.5169  loss_ce_7: 0  loss_mask_7: 0.1935  loss_dice_7: 0.5167  loss_ce_8: 0  loss_mask_8: 0.1938  loss_dice_8: 0.5166  time: 2.0654  data_time: 0.1088  lr: 8.6211e-05  max_mem: 5936M
[02/24 18:27:00] d2.utils.events INFO:  eta: 2 days, 1:46:52  iter: 9139  total_loss: 7.248  loss_ce: 0  loss_mask: 0.1913  loss_dice: 0.5039  loss_seg: 0.2497  loss_ce_0: 0  loss_mask_0: 0.1921  loss_dice_0: 0.5135  loss_ce_1: 0  loss_mask_1: 0.1917  loss_dice_1: 0.5023  loss_ce_2: 0  loss_mask_2: 0.1934  loss_dice_2: 0.5011  loss_ce_3: 0  loss_mask_3: 0.1944  loss_dice_3: 0.5004  loss_ce_4: 0  loss_mask_4: 0.1933  loss_dice_4: 0.5006  loss_ce_5: 0  loss_mask_5: 0.1934  loss_dice_5: 0.5005  loss_ce_6: 0  loss_mask_6: 0.1927  loss_dice_6: 0.499  loss_ce_7: 0  loss_mask_7: 0.1928  loss_dice_7: 0.5003  loss_ce_8: 0  loss_mask_8: 0.1924  loss_dice_8: 0.5004  time: 2.0686  data_time: 0.0978  lr: 8.6181e-05  max_mem: 5936M
[02/24 18:28:10] d2.utils.events INFO:  eta: 2 days, 1:48:09  iter: 9159  total_loss: 7.262  loss_ce: 0  loss_mask: 0.1954  loss_dice: 0.5002  loss_seg: 0.2636  loss_ce_0: 0  loss_mask_0: 0.194  loss_dice_0: 0.5153  loss_ce_1: 0  loss_mask_1: 0.1958  loss_dice_1: 0.4991  loss_ce_2: 0  loss_mask_2: 0.1956  loss_dice_2: 0.4982  loss_ce_3: 0  loss_mask_3: 0.195  loss_dice_3: 0.4972  loss_ce_4: 0  loss_mask_4: 0.1949  loss_dice_4: 0.4963  loss_ce_5: 0  loss_mask_5: 0.1946  loss_dice_5: 0.498  loss_ce_6: 0  loss_mask_6: 0.1954  loss_dice_6: 0.4979  loss_ce_7: 0  loss_mask_7: 0.1962  loss_dice_7: 0.4975  loss_ce_8: 0  loss_mask_8: 0.1963  loss_dice_8: 0.4968  time: 2.0717  data_time: 0.0991  lr: 8.615e-05  max_mem: 5936M
[02/24 18:29:22] d2.utils.events INFO:  eta: 2 days, 1:56:07  iter: 9179  total_loss: 7.486  loss_ce: 0  loss_mask: 0.1994  loss_dice: 0.5247  loss_seg: 0.2511  loss_ce_0: 0  loss_mask_0: 0.201  loss_dice_0: 0.5355  loss_ce_1: 0  loss_mask_1: 0.1975  loss_dice_1: 0.5295  loss_ce_2: 0  loss_mask_2: 0.1963  loss_dice_2: 0.5259  loss_ce_3: 0  loss_mask_3: 0.196  loss_dice_3: 0.5222  loss_ce_4: 0  loss_mask_4: 0.1966  loss_dice_4: 0.5244  loss_ce_5: 0  loss_mask_5: 0.1963  loss_dice_5: 0.524  loss_ce_6: 0  loss_mask_6: 0.196  loss_dice_6: 0.5216  loss_ce_7: 0  loss_mask_7: 0.1975  loss_dice_7: 0.5224  loss_ce_8: 0  loss_mask_8: 0.1979  loss_dice_8: 0.5225  time: 2.0750  data_time: 0.1167  lr: 8.612e-05  max_mem: 5936M
[02/24 18:30:31] d2.utils.events INFO:  eta: 2 days, 1:53:00  iter: 9199  total_loss: 7.514  loss_ce: 0  loss_mask: 0.2051  loss_dice: 0.5203  loss_seg: 0.2559  loss_ce_0: 0  loss_mask_0: 0.2032  loss_dice_0: 0.5268  loss_ce_1: 0  loss_mask_1: 0.2029  loss_dice_1: 0.5179  loss_ce_2: 0  loss_mask_2: 0.2021  loss_dice_2: 0.5178  loss_ce_3: 0  loss_mask_3: 0.2035  loss_dice_3: 0.5172  loss_ce_4: 0  loss_mask_4: 0.2039  loss_dice_4: 0.5167  loss_ce_5: 0  loss_mask_5: 0.2033  loss_dice_5: 0.5182  loss_ce_6: 0  loss_mask_6: 0.2026  loss_dice_6: 0.5167  loss_ce_7: 0  loss_mask_7: 0.2032  loss_dice_7: 0.5181  loss_ce_8: 0  loss_mask_8: 0.2027  loss_dice_8: 0.5178  time: 2.0780  data_time: 0.1060  lr: 8.6089e-05  max_mem: 5936M
[02/24 18:31:42] d2.utils.events INFO:  eta: 2 days, 1:52:34  iter: 9219  total_loss: 7.398  loss_ce: 0  loss_mask: 0.1991  loss_dice: 0.5097  loss_seg: 0.2806  loss_ce_0: 0  loss_mask_0: 0.195  loss_dice_0: 0.5292  loss_ce_1: 0  loss_mask_1: 0.1966  loss_dice_1: 0.5118  loss_ce_2: 0  loss_mask_2: 0.198  loss_dice_2: 0.5093  loss_ce_3: 0  loss_mask_3: 0.1991  loss_dice_3: 0.5087  loss_ce_4: 0  loss_mask_4: 0.1985  loss_dice_4: 0.5086  loss_ce_5: 0  loss_mask_5: 0.1977  loss_dice_5: 0.5074  loss_ce_6: 0  loss_mask_6: 0.198  loss_dice_6: 0.5075  loss_ce_7: 0  loss_mask_7: 0.1985  loss_dice_7: 0.5093  loss_ce_8: 0  loss_mask_8: 0.1991  loss_dice_8: 0.509  time: 2.0811  data_time: 0.0982  lr: 8.6059e-05  max_mem: 5936M
[02/24 18:32:52] d2.utils.events INFO:  eta: 2 days, 1:53:42  iter: 9239  total_loss: 7.289  loss_ce: 0  loss_mask: 0.1893  loss_dice: 0.5073  loss_seg: 0.266  loss_ce_0: 0  loss_mask_0: 0.189  loss_dice_0: 0.5246  loss_ce_1: 0  loss_mask_1: 0.1881  loss_dice_1: 0.5073  loss_ce_2: 0  loss_mask_2: 0.1899  loss_dice_2: 0.5047  loss_ce_3: 0  loss_mask_3: 0.189  loss_dice_3: 0.5021  loss_ce_4: 0  loss_mask_4: 0.1899  loss_dice_4: 0.5031  loss_ce_5: 0  loss_mask_5: 0.1917  loss_dice_5: 0.5036  loss_ce_6: 0  loss_mask_6: 0.1903  loss_dice_6: 0.5042  loss_ce_7: 0  loss_mask_7: 0.1892  loss_dice_7: 0.5035  loss_ce_8: 0  loss_mask_8: 0.1895  loss_dice_8: 0.5044  time: 2.0841  data_time: 0.1014  lr: 8.6028e-05  max_mem: 5936M
[02/24 18:34:02] d2.utils.events INFO:  eta: 2 days, 1:54:30  iter: 9259  total_loss: 7.392  loss_ce: 0  loss_mask: 0.1965  loss_dice: 0.5155  loss_seg: 0.2636  loss_ce_0: 0  loss_mask_0: 0.1988  loss_dice_0: 0.5217  loss_ce_1: 0  loss_mask_1: 0.1983  loss_dice_1: 0.5142  loss_ce_2: 0  loss_mask_2: 0.199  loss_dice_2: 0.5114  loss_ce_3: 0  loss_mask_3: 0.1985  loss_dice_3: 0.5109  loss_ce_4: 0  loss_mask_4: 0.199  loss_dice_4: 0.5113  loss_ce_5: 0  loss_mask_5: 0.1978  loss_dice_5: 0.5109  loss_ce_6: 0  loss_mask_6: 0.1977  loss_dice_6: 0.5105  loss_ce_7: 0  loss_mask_7: 0.1977  loss_dice_7: 0.5116  loss_ce_8: 0  loss_mask_8: 0.1972  loss_dice_8: 0.512  time: 2.0872  data_time: 0.1068  lr: 8.5998e-05  max_mem: 5936M
[02/24 18:35:10] d2.utils.events INFO:  eta: 2 days, 1:51:20  iter: 9279  total_loss: 7.146  loss_ce: 0  loss_mask: 0.191  loss_dice: 0.5028  loss_seg: 0.254  loss_ce_0: 0  loss_mask_0: 0.1918  loss_dice_0: 0.5175  loss_ce_1: 0  loss_mask_1: 0.1902  loss_dice_1: 0.504  loss_ce_2: 0  loss_mask_2: 0.1908  loss_dice_2: 0.501  loss_ce_3: 0  loss_mask_3: 0.1912  loss_dice_3: 0.4987  loss_ce_4: 0  loss_mask_4: 0.1914  loss_dice_4: 0.4981  loss_ce_5: 0  loss_mask_5: 0.1914  loss_dice_5: 0.4977  loss_ce_6: 0  loss_mask_6: 0.1915  loss_dice_6: 0.4976  loss_ce_7: 0  loss_mask_7: 0.191  loss_dice_7: 0.4986  loss_ce_8: 0  loss_mask_8: 0.1907  loss_dice_8: 0.4988  time: 2.0900  data_time: 0.1038  lr: 8.5967e-05  max_mem: 5936M
[02/24 18:36:19] d2.utils.events INFO:  eta: 2 days, 1:51:08  iter: 9299  total_loss: 7.38  loss_ce: 0  loss_mask: 0.1974  loss_dice: 0.5114  loss_seg: 0.3009  loss_ce_0: 0  loss_mask_0: 0.1972  loss_dice_0: 0.527  loss_ce_1: 0  loss_mask_1: 0.1973  loss_dice_1: 0.5128  loss_ce_2: 0  loss_mask_2: 0.1983  loss_dice_2: 0.5086  loss_ce_3: 0  loss_mask_3: 0.1977  loss_dice_3: 0.5072  loss_ce_4: 0  loss_mask_4: 0.1982  loss_dice_4: 0.5073  loss_ce_5: 0  loss_mask_5: 0.1989  loss_dice_5: 0.5072  loss_ce_6: 0  loss_mask_6: 0.1982  loss_dice_6: 0.5068  loss_ce_7: 0  loss_mask_7: 0.1981  loss_dice_7: 0.5074  loss_ce_8: 0  loss_mask_8: 0.1969  loss_dice_8: 0.5076  time: 2.0929  data_time: 0.1038  lr: 8.5937e-05  max_mem: 5936M
[02/24 18:37:32] d2.utils.events INFO:  eta: 2 days, 1:50:26  iter: 9319  total_loss: 7.356  loss_ce: 0  loss_mask: 0.1992  loss_dice: 0.5124  loss_seg: 0.265  loss_ce_0: 0  loss_mask_0: 0.1984  loss_dice_0: 0.5225  loss_ce_1: 0  loss_mask_1: 0.1984  loss_dice_1: 0.5136  loss_ce_2: 0  loss_mask_2: 0.1993  loss_dice_2: 0.512  loss_ce_3: 0  loss_mask_3: 0.2003  loss_dice_3: 0.511  loss_ce_4: 0  loss_mask_4: 0.2012  loss_dice_4: 0.51  loss_ce_5: 0  loss_mask_5: 0.2011  loss_dice_5: 0.5108  loss_ce_6: 0  loss_mask_6: 0.1998  loss_dice_6: 0.5099  loss_ce_7: 0  loss_mask_7: 0.2  loss_dice_7: 0.5116  loss_ce_8: 0  loss_mask_8: 0.1996  loss_dice_8: 0.5108  time: 2.0962  data_time: 0.0959  lr: 8.5906e-05  max_mem: 5936M
[02/24 18:38:39] d2.utils.events INFO:  eta: 2 days, 1:45:30  iter: 9339  total_loss: 7.145  loss_ce: 0  loss_mask: 0.1847  loss_dice: 0.5028  loss_seg: 0.2689  loss_ce_0: 0  loss_mask_0: 0.1844  loss_dice_0: 0.5193  loss_ce_1: 0  loss_mask_1: 0.187  loss_dice_1: 0.5033  loss_ce_2: 0  loss_mask_2: 0.186  loss_dice_2: 0.5015  loss_ce_3: 0  loss_mask_3: 0.1865  loss_dice_3: 0.4996  loss_ce_4: 0  loss_mask_4: 0.1872  loss_dice_4: 0.4999  loss_ce_5: 0  loss_mask_5: 0.1865  loss_dice_5: 0.5002  loss_ce_6: 0  loss_mask_6: 0.1862  loss_dice_6: 0.4997  loss_ce_7: 0  loss_mask_7: 0.186  loss_dice_7: 0.4999  loss_ce_8: 0  loss_mask_8: 0.1863  loss_dice_8: 0.4998  time: 2.0989  data_time: 0.1266  lr: 8.5876e-05  max_mem: 5936M
[02/24 18:39:48] d2.utils.events INFO:  eta: 2 days, 1:44:16  iter: 9359  total_loss: 7.223  loss_ce: 0  loss_mask: 0.189  loss_dice: 0.4996  loss_seg: 0.2534  loss_ce_0: 0  loss_mask_0: 0.1895  loss_dice_0: 0.5173  loss_ce_1: 0  loss_mask_1: 0.1899  loss_dice_1: 0.4999  loss_ce_2: 0  loss_mask_2: 0.189  loss_dice_2: 0.4982  loss_ce_3: 0  loss_mask_3: 0.188  loss_dice_3: 0.4963  loss_ce_4: 0  loss_mask_4: 0.1887  loss_dice_4: 0.4966  loss_ce_5: 0  loss_mask_5: 0.1894  loss_dice_5: 0.4957  loss_ce_6: 0  loss_mask_6: 0.19  loss_dice_6: 0.4953  loss_ce_7: 0  loss_mask_7: 0.1907  loss_dice_7: 0.4952  loss_ce_8: 0  loss_mask_8: 0.1903  loss_dice_8: 0.4963  time: 2.1018  data_time: 0.0929  lr: 8.5845e-05  max_mem: 5936M
[02/24 18:40:58] d2.utils.events INFO:  eta: 2 days, 1:43:05  iter: 9379  total_loss: 7.349  loss_ce: 0  loss_mask: 0.2012  loss_dice: 0.5078  loss_seg: 0.2725  loss_ce_0: 0  loss_mask_0: 0.1982  loss_dice_0: 0.5231  loss_ce_1: 0  loss_mask_1: 0.1971  loss_dice_1: 0.5093  loss_ce_2: 0  loss_mask_2: 0.1982  loss_dice_2: 0.5081  loss_ce_3: 0  loss_mask_3: 0.1995  loss_dice_3: 0.5046  loss_ce_4: 0  loss_mask_4: 0.1991  loss_dice_4: 0.5041  loss_ce_5: 0  loss_mask_5: 0.2  loss_dice_5: 0.505  loss_ce_6: 0  loss_mask_6: 0.1987  loss_dice_6: 0.5052  loss_ce_7: 0  loss_mask_7: 0.1986  loss_dice_7: 0.5064  loss_ce_8: 0  loss_mask_8: 0.199  loss_dice_8: 0.5072  time: 2.1047  data_time: 0.0974  lr: 8.5815e-05  max_mem: 5936M
[02/24 18:42:09] d2.utils.events INFO:  eta: 2 days, 1:41:55  iter: 9399  total_loss: 7.456  loss_ce: 0  loss_mask: 0.1949  loss_dice: 0.5135  loss_seg: 0.2605  loss_ce_0: 0  loss_mask_0: 0.1952  loss_dice_0: 0.5255  loss_ce_1: 0  loss_mask_1: 0.1931  loss_dice_1: 0.5153  loss_ce_2: 0  loss_mask_2: 0.1937  loss_dice_2: 0.5133  loss_ce_3: 0  loss_mask_3: 0.1934  loss_dice_3: 0.5122  loss_ce_4: 0  loss_mask_4: 0.1945  loss_dice_4: 0.5122  loss_ce_5: 0  loss_mask_5: 0.1939  loss_dice_5: 0.5126  loss_ce_6: 0  loss_mask_6: 0.1938  loss_dice_6: 0.5113  loss_ce_7: 0  loss_mask_7: 0.1934  loss_dice_7: 0.5107  loss_ce_8: 0  loss_mask_8: 0.1935  loss_dice_8: 0.5104  time: 2.1078  data_time: 0.0986  lr: 8.5784e-05  max_mem: 5936M
[02/24 18:43:18] d2.utils.events INFO:  eta: 2 days, 1:39:29  iter: 9419  total_loss: 7.413  loss_ce: 0  loss_mask: 0.1936  loss_dice: 0.5267  loss_seg: 0.2747  loss_ce_0: 0  loss_mask_0: 0.194  loss_dice_0: 0.5395  loss_ce_1: 0  loss_mask_1: 0.1931  loss_dice_1: 0.5289  loss_ce_2: 0  loss_mask_2: 0.1931  loss_dice_2: 0.5247  loss_ce_3: 0  loss_mask_3: 0.1939  loss_dice_3: 0.5237  loss_ce_4: 0  loss_mask_4: 0.1944  loss_dice_4: 0.5232  loss_ce_5: 0  loss_mask_5: 0.1949  loss_dice_5: 0.5237  loss_ce_6: 0  loss_mask_6: 0.1946  loss_dice_6: 0.5232  loss_ce_7: 0  loss_mask_7: 0.1939  loss_dice_7: 0.5244  loss_ce_8: 0  loss_mask_8: 0.1935  loss_dice_8: 0.5247  time: 2.1105  data_time: 0.1055  lr: 8.5754e-05  max_mem: 5936M
[02/24 18:44:23] d2.utils.events INFO:  eta: 2 days, 1:36:41  iter: 9439  total_loss: 7.216  loss_ce: 0  loss_mask: 0.1925  loss_dice: 0.4941  loss_seg: 0.2818  loss_ce_0: 0  loss_mask_0: 0.1908  loss_dice_0: 0.5128  loss_ce_1: 0  loss_mask_1: 0.1912  loss_dice_1: 0.4962  loss_ce_2: 0  loss_mask_2: 0.1911  loss_dice_2: 0.4937  loss_ce_3: 0  loss_mask_3: 0.1915  loss_dice_3: 0.4915  loss_ce_4: 0  loss_mask_4: 0.1916  loss_dice_4: 0.4918  loss_ce_5: 0  loss_mask_5: 0.1918  loss_dice_5: 0.4908  loss_ce_6: 0  loss_mask_6: 0.1922  loss_dice_6: 0.4909  loss_ce_7: 0  loss_mask_7: 0.1925  loss_dice_7: 0.4914  loss_ce_8: 0  loss_mask_8: 0.1931  loss_dice_8: 0.4916  time: 2.1130  data_time: 0.0819  lr: 8.5723e-05  max_mem: 5936M
[02/24 18:45:34] d2.utils.events INFO:  eta: 2 days, 1:33:45  iter: 9459  total_loss: 7.56  loss_ce: 0  loss_mask: 0.1948  loss_dice: 0.5305  loss_seg: 0.2716  loss_ce_0: 0  loss_mask_0: 0.1962  loss_dice_0: 0.5404  loss_ce_1: 0  loss_mask_1: 0.194  loss_dice_1: 0.534  loss_ce_2: 0  loss_mask_2: 0.194  loss_dice_2: 0.5321  loss_ce_3: 0  loss_mask_3: 0.1944  loss_dice_3: 0.5313  loss_ce_4: 0  loss_mask_4: 0.1948  loss_dice_4: 0.5307  loss_ce_5: 0  loss_mask_5: 0.1945  loss_dice_5: 0.5292  loss_ce_6: 0  loss_mask_6: 0.1952  loss_dice_6: 0.5294  loss_ce_7: 0  loss_mask_7: 0.1937  loss_dice_7: 0.5286  loss_ce_8: 0  loss_mask_8: 0.1949  loss_dice_8: 0.5295  time: 2.1159  data_time: 0.0971  lr: 8.5693e-05  max_mem: 5936M
[02/24 18:46:47] d2.utils.events INFO:  eta: 2 days, 1:33:15  iter: 9479  total_loss: 7.173  loss_ce: 0  loss_mask: 0.2027  loss_dice: 0.5033  loss_seg: 0.2462  loss_ce_0: 0  loss_mask_0: 0.2023  loss_dice_0: 0.507  loss_ce_1: 0  loss_mask_1: 0.2029  loss_dice_1: 0.5039  loss_ce_2: 0  loss_mask_2: 0.202  loss_dice_2: 0.5014  loss_ce_3: 0  loss_mask_3: 0.2018  loss_dice_3: 0.4991  loss_ce_4: 0  loss_mask_4: 0.2014  loss_dice_4: 0.4984  loss_ce_5: 0  loss_mask_5: 0.2012  loss_dice_5: 0.4979  loss_ce_6: 0  loss_mask_6: 0.2021  loss_dice_6: 0.4978  loss_ce_7: 0  loss_mask_7: 0.2027  loss_dice_7: 0.4992  loss_ce_8: 0  loss_mask_8: 0.2029  loss_dice_8: 0.4995  time: 2.1191  data_time: 0.0900  lr: 8.5662e-05  max_mem: 5936M
[02/24 18:47:59] d2.utils.events INFO:  eta: 2 days, 1:32:38  iter: 9499  total_loss: 7.472  loss_ce: 0  loss_mask: 0.197  loss_dice: 0.5313  loss_seg: 0.2771  loss_ce_0: 0  loss_mask_0: 0.1987  loss_dice_0: 0.5413  loss_ce_1: 0  loss_mask_1: 0.1993  loss_dice_1: 0.5302  loss_ce_2: 0  loss_mask_2: 0.1986  loss_dice_2: 0.5284  loss_ce_3: 0  loss_mask_3: 0.1985  loss_dice_3: 0.5252  loss_ce_4: 0  loss_mask_4: 0.1985  loss_dice_4: 0.5265  loss_ce_5: 0  loss_mask_5: 0.1986  loss_dice_5: 0.5264  loss_ce_6: 0  loss_mask_6: 0.1981  loss_dice_6: 0.5259  loss_ce_7: 0  loss_mask_7: 0.1984  loss_dice_7: 0.5268  loss_ce_8: 0  loss_mask_8: 0.1974  loss_dice_8: 0.5274  time: 2.1222  data_time: 0.1025  lr: 8.5632e-05  max_mem: 5936M
[02/24 18:49:11] d2.utils.events INFO:  eta: 2 days, 1:34:42  iter: 9519  total_loss: 7.34  loss_ce: 0  loss_mask: 0.1975  loss_dice: 0.5108  loss_seg: 0.2605  loss_ce_0: 0  loss_mask_0: 0.1981  loss_dice_0: 0.5232  loss_ce_1: 0  loss_mask_1: 0.1965  loss_dice_1: 0.5108  loss_ce_2: 0  loss_mask_2: 0.1963  loss_dice_2: 0.5084  loss_ce_3: 0  loss_mask_3: 0.1971  loss_dice_3: 0.508  loss_ce_4: 0  loss_mask_4: 0.1961  loss_dice_4: 0.5091  loss_ce_5: 0  loss_mask_5: 0.1946  loss_dice_5: 0.509  loss_ce_6: 0  loss_mask_6: 0.1953  loss_dice_6: 0.5117  loss_ce_7: 0  loss_mask_7: 0.1946  loss_dice_7: 0.5115  loss_ce_8: 0  loss_mask_8: 0.1956  loss_dice_8: 0.5094  time: 2.1253  data_time: 0.1155  lr: 8.5601e-05  max_mem: 5936M
[02/24 18:50:21] d2.utils.events INFO:  eta: 2 days, 1:28:24  iter: 9539  total_loss: 7.376  loss_ce: 0  loss_mask: 0.1932  loss_dice: 0.5075  loss_seg: 0.2464  loss_ce_0: 0  loss_mask_0: 0.1922  loss_dice_0: 0.5149  loss_ce_1: 0  loss_mask_1: 0.1906  loss_dice_1: 0.5085  loss_ce_2: 0  loss_mask_2: 0.1906  loss_dice_2: 0.5066  loss_ce_3: 0  loss_mask_3: 0.1918  loss_dice_3: 0.5029  loss_ce_4: 0  loss_mask_4: 0.1903  loss_dice_4: 0.5042  loss_ce_5: 0  loss_mask_5: 0.1903  loss_dice_5: 0.5034  loss_ce_6: 0  loss_mask_6: 0.1908  loss_dice_6: 0.5027  loss_ce_7: 0  loss_mask_7: 0.1923  loss_dice_7: 0.5029  loss_ce_8: 0  loss_mask_8: 0.192  loss_dice_8: 0.5051  time: 2.1281  data_time: 0.0831  lr: 8.5571e-05  max_mem: 5936M
[02/24 18:51:30] d2.utils.events INFO:  eta: 2 days, 1:25:09  iter: 9559  total_loss: 7.196  loss_ce: 0  loss_mask: 0.1924  loss_dice: 0.4979  loss_seg: 0.2691  loss_ce_0: 0  loss_mask_0: 0.1932  loss_dice_0: 0.5075  loss_ce_1: 0  loss_mask_1: 0.1913  loss_dice_1: 0.4985  loss_ce_2: 0  loss_mask_2: 0.1911  loss_dice_2: 0.4943  loss_ce_3: 0  loss_mask_3: 0.1917  loss_dice_3: 0.4926  loss_ce_4: 0  loss_mask_4: 0.1921  loss_dice_4: 0.4944  loss_ce_5: 0  loss_mask_5: 0.1924  loss_dice_5: 0.4952  loss_ce_6: 0  loss_mask_6: 0.1921  loss_dice_6: 0.4931  loss_ce_7: 0  loss_mask_7: 0.1918  loss_dice_7: 0.4935  loss_ce_8: 0  loss_mask_8: 0.1929  loss_dice_8: 0.4949  time: 2.1309  data_time: 0.1046  lr: 8.554e-05  max_mem: 5936M
[02/24 18:52:40] d2.utils.events INFO:  eta: 2 days, 1:23:59  iter: 9579  total_loss: 7.152  loss_ce: 0  loss_mask: 0.1845  loss_dice: 0.4894  loss_seg: 0.2699  loss_ce_0: 0  loss_mask_0: 0.1868  loss_dice_0: 0.5128  loss_ce_1: 0  loss_mask_1: 0.1832  loss_dice_1: 0.4895  loss_ce_2: 0  loss_mask_2: 0.1842  loss_dice_2: 0.4866  loss_ce_3: 0  loss_mask_3: 0.1842  loss_dice_3: 0.4846  loss_ce_4: 0  loss_mask_4: 0.1843  loss_dice_4: 0.4858  loss_ce_5: 0  loss_mask_5: 0.1842  loss_dice_5: 0.4856  loss_ce_6: 0  loss_mask_6: 0.1843  loss_dice_6: 0.486  loss_ce_7: 0  loss_mask_7: 0.1834  loss_dice_7: 0.4865  loss_ce_8: 0  loss_mask_8: 0.1842  loss_dice_8: 0.4863  time: 2.1336  data_time: 0.0960  lr: 8.5509e-05  max_mem: 5936M
[02/24 18:53:49] d2.utils.events INFO:  eta: 2 days, 1:21:19  iter: 9599  total_loss: 7.391  loss_ce: 0  loss_mask: 0.1891  loss_dice: 0.5132  loss_seg: 0.2753  loss_ce_0: 0  loss_mask_0: 0.1918  loss_dice_0: 0.5304  loss_ce_1: 0  loss_mask_1: 0.1895  loss_dice_1: 0.5149  loss_ce_2: 0  loss_mask_2: 0.191  loss_dice_2: 0.5103  loss_ce_3: 0  loss_mask_3: 0.1909  loss_dice_3: 0.5072  loss_ce_4: 0  loss_mask_4: 0.1902  loss_dice_4: 0.5076  loss_ce_5: 0  loss_mask_5: 0.1894  loss_dice_5: 0.5087  loss_ce_6: 0  loss_mask_6: 0.1902  loss_dice_6: 0.509  loss_ce_7: 0  loss_mask_7: 0.1898  loss_dice_7: 0.5095  loss_ce_8: 0  loss_mask_8: 0.1893  loss_dice_8: 0.5098  time: 2.1363  data_time: 0.1055  lr: 8.5479e-05  max_mem: 5936M
[02/24 18:54:57] d2.utils.events INFO:  eta: 2 days, 1:17:05  iter: 9619  total_loss: 7.398  loss_ce: 0  loss_mask: 0.1925  loss_dice: 0.5172  loss_seg: 0.2637  loss_ce_0: 0  loss_mask_0: 0.1918  loss_dice_0: 0.5336  loss_ce_1: 0  loss_mask_1: 0.189  loss_dice_1: 0.5187  loss_ce_2: 0  loss_mask_2: 0.1893  loss_dice_2: 0.516  loss_ce_3: 0  loss_mask_3: 0.1904  loss_dice_3: 0.5135  loss_ce_4: 0  loss_mask_4: 0.1908  loss_dice_4: 0.5137  loss_ce_5: 0  loss_mask_5: 0.1908  loss_dice_5: 0.5134  loss_ce_6: 0  loss_mask_6: 0.1909  loss_dice_6: 0.5133  loss_ce_7: 0  loss_mask_7: 0.1909  loss_dice_7: 0.5135  loss_ce_8: 0  loss_mask_8: 0.191  loss_dice_8: 0.5132  time: 2.1389  data_time: 0.1104  lr: 8.5448e-05  max_mem: 5936M
[02/24 18:56:06] d2.utils.events INFO:  eta: 2 days, 1:14:23  iter: 9639  total_loss: 7.347  loss_ce: 0  loss_mask: 0.1907  loss_dice: 0.5035  loss_seg: 0.2865  loss_ce_0: 0  loss_mask_0: 0.1922  loss_dice_0: 0.5141  loss_ce_1: 0  loss_mask_1: 0.1899  loss_dice_1: 0.5036  loss_ce_2: 0  loss_mask_2: 0.1893  loss_dice_2: 0.5023  loss_ce_3: 0  loss_mask_3: 0.1893  loss_dice_3: 0.5009  loss_ce_4: 0  loss_mask_4: 0.19  loss_dice_4: 0.5013  loss_ce_5: 0  loss_mask_5: 0.1904  loss_dice_5: 0.5023  loss_ce_6: 0  loss_mask_6: 0.1894  loss_dice_6: 0.5012  loss_ce_7: 0  loss_mask_7: 0.1891  loss_dice_7: 0.5011  loss_ce_8: 0  loss_mask_8: 0.1888  loss_dice_8: 0.5029  time: 2.1417  data_time: 0.0961  lr: 8.5418e-05  max_mem: 5936M
[02/24 18:57:16] d2.utils.events INFO:  eta: 2 days, 1:11:44  iter: 9659  total_loss: 7.233  loss_ce: 0  loss_mask: 0.19  loss_dice: 0.5062  loss_seg: 0.249  loss_ce_0: 0  loss_mask_0: 0.1926  loss_dice_0: 0.5216  loss_ce_1: 0  loss_mask_1: 0.1895  loss_dice_1: 0.507  loss_ce_2: 0  loss_mask_2: 0.1898  loss_dice_2: 0.5036  loss_ce_3: 0  loss_mask_3: 0.1887  loss_dice_3: 0.5018  loss_ce_4: 0  loss_mask_4: 0.1892  loss_dice_4: 0.5021  loss_ce_5: 0  loss_mask_5: 0.1887  loss_dice_5: 0.5032  loss_ce_6: 0  loss_mask_6: 0.1907  loss_dice_6: 0.5024  loss_ce_7: 0  loss_mask_7: 0.1907  loss_dice_7: 0.5022  loss_ce_8: 0  loss_mask_8: 0.1896  loss_dice_8: 0.5035  time: 2.1444  data_time: 0.1036  lr: 8.5387e-05  max_mem: 5936M
[02/24 18:58:27] d2.utils.events INFO:  eta: 2 days, 1:10:49  iter: 9679  total_loss: 7.55  loss_ce: 0  loss_mask: 0.1988  loss_dice: 0.5217  loss_seg: 0.265  loss_ce_0: 0  loss_mask_0: 0.1956  loss_dice_0: 0.5297  loss_ce_1: 0  loss_mask_1: 0.1982  loss_dice_1: 0.5244  loss_ce_2: 0  loss_mask_2: 0.1978  loss_dice_2: 0.5214  loss_ce_3: 0  loss_mask_3: 0.1985  loss_dice_3: 0.5209  loss_ce_4: 0  loss_mask_4: 0.1994  loss_dice_4: 0.5212  loss_ce_5: 0  loss_mask_5: 0.1994  loss_dice_5: 0.5204  loss_ce_6: 0  loss_mask_6: 0.1998  loss_dice_6: 0.5208  loss_ce_7: 0  loss_mask_7: 0.2017  loss_dice_7: 0.5193  loss_ce_8: 0  loss_mask_8: 0.2005  loss_dice_8: 0.5212  time: 2.1473  data_time: 0.1298  lr: 8.5357e-05  max_mem: 5936M
[02/24 18:59:40] d2.utils.events INFO:  eta: 2 days, 1:07:02  iter: 9699  total_loss: 7.312  loss_ce: 0  loss_mask: 0.194  loss_dice: 0.5187  loss_seg: 0.2845  loss_ce_0: 0  loss_mask_0: 0.1951  loss_dice_0: 0.5339  loss_ce_1: 0  loss_mask_1: 0.1954  loss_dice_1: 0.5188  loss_ce_2: 0  loss_mask_2: 0.1958  loss_dice_2: 0.5163  loss_ce_3: 0  loss_mask_3: 0.1969  loss_dice_3: 0.5153  loss_ce_4: 0  loss_mask_4: 0.1961  loss_dice_4: 0.5149  loss_ce_5: 0  loss_mask_5: 0.1956  loss_dice_5: 0.5151  loss_ce_6: 0  loss_mask_6: 0.1951  loss_dice_6: 0.5155  loss_ce_7: 0  loss_mask_7: 0.1945  loss_dice_7: 0.5162  loss_ce_8: 0  loss_mask_8: 0.1954  loss_dice_8: 0.5162  time: 2.1504  data_time: 0.1142  lr: 8.5326e-05  max_mem: 5936M
[02/24 19:00:51] d2.utils.events INFO:  eta: 2 days, 1:03:53  iter: 9719  total_loss: 6.826  loss_ce: 0  loss_mask: 0.1763  loss_dice: 0.4788  loss_seg: 0.2634  loss_ce_0: 0  loss_mask_0: 0.1789  loss_dice_0: 0.5002  loss_ce_1: 0  loss_mask_1: 0.1743  loss_dice_1: 0.479  loss_ce_2: 0  loss_mask_2: 0.1755  loss_dice_2: 0.4763  loss_ce_3: 0  loss_mask_3: 0.1752  loss_dice_3: 0.4751  loss_ce_4: 0  loss_mask_4: 0.1745  loss_dice_4: 0.4748  loss_ce_5: 0  loss_mask_5: 0.1755  loss_dice_5: 0.475  loss_ce_6: 0  loss_mask_6: 0.1753  loss_dice_6: 0.4752  loss_ce_7: 0  loss_mask_7: 0.1749  loss_dice_7: 0.4763  loss_ce_8: 0  loss_mask_8: 0.1752  loss_dice_8: 0.4762  time: 2.1533  data_time: 0.1136  lr: 8.5296e-05  max_mem: 5936M
