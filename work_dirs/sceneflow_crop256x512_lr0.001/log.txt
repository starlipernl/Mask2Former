[01/19 15:08:38] detectron2 INFO: Rank of current process: 0. World size: 4
[01/19 15:08:41] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/19 15:08:41] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['OUTPUT_DIR', 'work_dirs/sceneflow_crop256x512_lr0.001'], resume=False)
[01/19 15:08:41] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/19 15:08:42] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mwork_dirs/sceneflow_crop256x512_lr0.001[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/19 15:08:42] detectron2 INFO: Full config saved to work_dirs/sceneflow_crop256x512_lr0.001/config.yaml
[01/19 15:08:42] d2.utils.env INFO: Using a generated random seed 42287732
[01/19 15:08:43] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/19 15:08:43] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/19 15:08:47] d2.data.build INFO: Using training sampler TrainingSampler
[01/19 15:08:48] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/19 15:08:48] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/19 15:08:48] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/19 15:08:48] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/19 15:08:48] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/19 15:08:48] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/19 15:08:48] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/19 15:08:48] d2.engine.train_loop INFO: Starting training from iteration 0
[01/19 15:10:03] d2.utils.events INFO:  eta: 1 day, 6:24:18  iter: 19  total_loss: 149.7  loss_ce: 9.262  loss_mask: 0.8331  loss_dice: 4.887  loss_ce_0: 9.251  loss_mask_0: 0.4345  loss_dice_0: 4.753  loss_ce_1: 9.145  loss_mask_1: 0.7141  loss_dice_1: 4.8  loss_ce_2: 9.317  loss_mask_2: 0.8198  loss_dice_2: 4.863  loss_ce_3: 9.269  loss_mask_3: 0.8198  loss_dice_3: 4.875  loss_ce_4: 9.38  loss_mask_4: 0.7809  loss_dice_4: 4.872  loss_ce_5: 9.287  loss_mask_5: 0.6758  loss_dice_5: 4.879  loss_ce_6: 9.3  loss_mask_6: 0.7513  loss_dice_6: 4.881  loss_ce_7: 9.215  loss_mask_7: 0.7255  loss_dice_7: 4.882  loss_ce_8: 9.229  loss_mask_8: 0.7762  loss_dice_8: 4.885  time: 2.7668  data_time: 0.7730  lr: 9.9957e-05  max_mem: 23450M
[01/19 15:10:47] d2.utils.events INFO:  eta: 1 day, 2:46:54  iter: 39  total_loss: 129  loss_ce: 8.789  loss_mask: 0.3871  loss_dice: 4.933  loss_ce_0: 7.795  loss_mask_0: 0.3815  loss_dice_0: 4.577  loss_ce_1: 3.826  loss_mask_1: 0.3859  loss_dice_1: 4.621  loss_ce_2: 3.952  loss_mask_2: 0.3852  loss_dice_2: 4.653  loss_ce_3: 8.513  loss_mask_3: 0.3769  loss_dice_3: 4.928  loss_ce_4: 8.767  loss_mask_4: 0.3767  loss_dice_4: 4.936  loss_ce_5: 8.778  loss_mask_5: 0.3739  loss_dice_5: 4.935  loss_ce_6: 8.768  loss_mask_6: 0.3765  loss_dice_6: 4.935  loss_ce_7: 8.768  loss_mask_7: 0.3747  loss_dice_7: 4.936  loss_ce_8: 8.768  loss_mask_8: 0.3755  loss_dice_8: 4.935  time: 2.4926  data_time: 0.4132  lr: 9.9912e-05  max_mem: 23887M
[01/19 15:11:32] d2.utils.events INFO:  eta: 1 day, 1:26:28  iter: 59  total_loss: 109.2  loss_ce: 8.691  loss_mask: 0.3771  loss_dice: 4.934  loss_ce_0: 4.94  loss_mask_0: 0.3909  loss_dice_0: 4.701  loss_ce_1: 1.829  loss_mask_1: 0.3825  loss_dice_1: 4.749  loss_ce_2: 1.802  loss_mask_2: 0.3856  loss_dice_2: 4.751  loss_ce_3: 1.965  loss_mask_3: 0.394  loss_dice_3: 4.745  loss_ce_4: 2.836  loss_mask_4: 0.3901  loss_dice_4: 4.741  loss_ce_5: 8.512  loss_mask_5: 0.3727  loss_dice_5: 4.931  loss_ce_6: 8.699  loss_mask_6: 0.3722  loss_dice_6: 4.934  loss_ce_7: 8.697  loss_mask_7: 0.3732  loss_dice_7: 4.933  loss_ce_8: 8.699  loss_mask_8: 0.3738  loss_dice_8: 4.935  time: 2.3962  data_time: 0.4279  lr: 9.9867e-05  max_mem: 23887M
[01/19 15:12:15] d2.utils.events INFO:  eta: 1 day, 0:55:25  iter: 79  total_loss: 94.87  loss_ce: 8.69  loss_mask: 0.3728  loss_dice: 4.932  loss_ce_0: 3.882  loss_mask_0: 0.3908  loss_dice_0: 4.727  loss_ce_1: 1.263  loss_mask_1: 0.3882  loss_dice_1: 4.746  loss_ce_2: 1.293  loss_mask_2: 0.3904  loss_dice_2: 4.742  loss_ce_3: 1.385  loss_mask_3: 0.3853  loss_dice_3: 4.748  loss_ce_4: 1.463  loss_mask_4: 0.3936  loss_dice_4: 4.739  loss_ce_5: 1.8  loss_mask_5: 0.4088  loss_dice_5: 4.732  loss_ce_6: 5.781  loss_mask_6: 0.3888  loss_dice_6: 4.814  loss_ce_7: 8.557  loss_mask_7: 0.3706  loss_dice_7: 4.931  loss_ce_8: 8.665  loss_mask_8: 0.3716  loss_dice_8: 4.932  time: 2.3366  data_time: 0.3954  lr: 9.9822e-05  max_mem: 24135M
[01/19 15:12:58] d2.utils.events INFO:  eta: 1 day, 0:30:51  iter: 99  total_loss: 83.44  loss_ce: 8.699  loss_mask: 0.3767  loss_dice: 4.93  loss_ce_0: 3.536  loss_mask_0: 0.39  loss_dice_0: 4.754  loss_ce_1: 1.159  loss_mask_1: 0.3926  loss_dice_1: 4.755  loss_ce_2: 1.173  loss_mask_2: 0.3921  loss_dice_2: 4.753  loss_ce_3: 1.212  loss_mask_3: 0.3903  loss_dice_3: 4.753  loss_ce_4: 1.268  loss_mask_4: 0.3953  loss_dice_4: 4.754  loss_ce_5: 1.421  loss_mask_5: 0.3946  loss_dice_5: 4.753  loss_ce_6: 1.73  loss_mask_6: 0.3999  loss_dice_6: 4.738  loss_ce_7: 2.75  loss_mask_7: 0.3918  loss_dice_7: 4.73  loss_ce_8: 8.398  loss_mask_8: 0.3736  loss_dice_8: 4.925  time: 2.2967  data_time: 0.3926  lr: 9.9777e-05  max_mem: 24135M
[01/19 15:13:40] d2.utils.events INFO:  eta: 1 day, 0:17:10  iter: 119  total_loss: 73.72  loss_ce: 7.381  loss_mask: 0.3918  loss_dice: 4.809  loss_ce_0: 3.326  loss_mask_0: 0.3865  loss_dice_0: 4.751  loss_ce_1: 1.063  loss_mask_1: 0.3936  loss_dice_1: 4.746  loss_ce_2: 1.055  loss_mask_2: 0.3952  loss_dice_2: 4.745  loss_ce_3: 1.073  loss_mask_3: 0.3949  loss_dice_3: 4.748  loss_ce_4: 1.118  loss_mask_4: 0.3917  loss_dice_4: 4.746  loss_ce_5: 1.222  loss_mask_5: 0.3888  loss_dice_5: 4.746  loss_ce_6: 1.362  loss_mask_6: 0.3884  loss_dice_6: 4.749  loss_ce_7: 1.673  loss_mask_7: 0.3899  loss_dice_7: 4.743  loss_ce_8: 2.724  loss_mask_8: 0.402  loss_dice_8: 4.732  time: 2.2676  data_time: 0.3961  lr: 9.9732e-05  max_mem: 24135M
[01/19 15:14:23] d2.utils.events INFO:  eta: 23:59:24  iter: 139  total_loss: 66.17  loss_ce: 2.279  loss_mask: 0.3958  loss_dice: 4.743  loss_ce_0: 3.102  loss_mask_0: 0.3825  loss_dice_0: 4.752  loss_ce_1: 1.043  loss_mask_1: 0.3941  loss_dice_1: 4.749  loss_ce_2: 1.041  loss_mask_2: 0.3882  loss_dice_2: 4.75  loss_ce_3: 1.071  loss_mask_3: 0.3868  loss_dice_3: 4.75  loss_ce_4: 1.082  loss_mask_4: 0.3841  loss_dice_4: 4.75  loss_ce_5: 1.15  loss_mask_5: 0.3828  loss_dice_5: 4.748  loss_ce_6: 1.212  loss_mask_6: 0.3821  loss_dice_6: 4.744  loss_ce_7: 1.274  loss_mask_7: 0.387  loss_dice_7: 4.748  loss_ce_8: 1.531  loss_mask_8: 0.3885  loss_dice_8: 4.747  time: 2.2481  data_time: 0.4228  lr: 9.9687e-05  max_mem: 24135M
[01/19 15:15:06] d2.utils.events INFO:  eta: 23:53:42  iter: 159  total_loss: 65.15  loss_ce: 1.511  loss_mask: 0.3841  loss_dice: 4.746  loss_ce_0: 2.969  loss_mask_0: 0.3839  loss_dice_0: 4.752  loss_ce_1: 1.012  loss_mask_1: 0.3951  loss_dice_1: 4.75  loss_ce_2: 1.038  loss_mask_2: 0.3904  loss_dice_2: 4.753  loss_ce_3: 1.069  loss_mask_3: 0.3909  loss_dice_3: 4.751  loss_ce_4: 1.087  loss_mask_4: 0.3943  loss_dice_4: 4.751  loss_ce_5: 1.148  loss_mask_5: 0.391  loss_dice_5: 4.749  loss_ce_6: 1.196  loss_mask_6: 0.3934  loss_dice_6: 4.748  loss_ce_7: 1.206  loss_mask_7: 0.3906  loss_dice_7: 4.745  loss_ce_8: 1.285  loss_mask_8: 0.3929  loss_dice_8: 4.744  time: 2.2334  data_time: 0.3967  lr: 9.9642e-05  max_mem: 24135M
[01/19 15:15:48] d2.utils.events INFO:  eta: 23:50:36  iter: 179  total_loss: 64.29  loss_ce: 1.233  loss_mask: 0.4133  loss_dice: 4.709  loss_ce_0: 2.658  loss_mask_0: 0.3928  loss_dice_0: 4.726  loss_ce_1: 1.046  loss_mask_1: 0.4016  loss_dice_1: 4.716  loss_ce_2: 1.041  loss_mask_2: 0.4046  loss_dice_2: 4.711  loss_ce_3: 1.129  loss_mask_3: 0.4031  loss_dice_3: 4.706  loss_ce_4: 1.087  loss_mask_4: 0.4017  loss_dice_4: 4.71  loss_ce_5: 1.079  loss_mask_5: 0.4041  loss_dice_5: 4.704  loss_ce_6: 1.092  loss_mask_6: 0.4035  loss_dice_6: 4.708  loss_ce_7: 1.119  loss_mask_7: 0.4066  loss_dice_7: 4.704  loss_ce_8: 1.14  loss_mask_8: 0.4062  loss_dice_8: 4.711  time: 2.2215  data_time: 0.4010  lr: 9.9597e-05  max_mem: 24135M
[01/19 15:16:31] d2.utils.events INFO:  eta: 23:48:19  iter: 199  total_loss: 62.81  loss_ce: 1.107  loss_mask: 0.4111  loss_dice: 4.713  loss_ce_0: 2.271  loss_mask_0: 0.4003  loss_dice_0: 4.73  loss_ce_1: 0.9809  loss_mask_1: 0.4115  loss_dice_1: 4.716  loss_ce_2: 0.9654  loss_mask_2: 0.4062  loss_dice_2: 4.712  loss_ce_3: 0.9999  loss_mask_3: 0.4077  loss_dice_3: 4.71  loss_ce_4: 1.021  loss_mask_4: 0.4092  loss_dice_4: 4.714  loss_ce_5: 1.014  loss_mask_5: 0.4111  loss_dice_5: 4.714  loss_ce_6: 1.008  loss_mask_6: 0.4119  loss_dice_6: 4.711  loss_ce_7: 1.024  loss_mask_7: 0.4068  loss_dice_7: 4.714  loss_ce_8: 1.039  loss_mask_8: 0.4111  loss_dice_8: 4.712  time: 2.2131  data_time: 0.4047  lr: 9.9552e-05  max_mem: 24135M
[01/19 15:17:14] d2.utils.events INFO:  eta: 23:46:10  iter: 219  total_loss: 62.51  loss_ce: 1.057  loss_mask: 0.431  loss_dice: 4.707  loss_ce_0: 1.983  loss_mask_0: 0.4202  loss_dice_0: 4.715  loss_ce_1: 1.03  loss_mask_1: 0.4243  loss_dice_1: 4.701  loss_ce_2: 0.999  loss_mask_2: 0.429  loss_dice_2: 4.701  loss_ce_3: 1.001  loss_mask_3: 0.431  loss_dice_3: 4.7  loss_ce_4: 0.9911  loss_mask_4: 0.4326  loss_dice_4: 4.697  loss_ce_5: 1.008  loss_mask_5: 0.4327  loss_dice_5: 4.694  loss_ce_6: 1.012  loss_mask_6: 0.4349  loss_dice_6: 4.701  loss_ce_7: 1.028  loss_mask_7: 0.4333  loss_dice_7: 4.703  loss_ce_8: 1.029  loss_mask_8: 0.4342  loss_dice_8: 4.698  time: 2.2051  data_time: 0.4045  lr: 9.9507e-05  max_mem: 24135M
[01/19 15:17:57] d2.utils.events INFO:  eta: 23:41:46  iter: 239  total_loss: 61.82  loss_ce: 1.055  loss_mask: 0.4401  loss_dice: 4.69  loss_ce_0: 1.581  loss_mask_0: 0.4259  loss_dice_0: 4.704  loss_ce_1: 0.9974  loss_mask_1: 0.4363  loss_dice_1: 4.69  loss_ce_2: 0.9739  loss_mask_2: 0.4371  loss_dice_2: 4.685  loss_ce_3: 0.9816  loss_mask_3: 0.4365  loss_dice_3: 4.686  loss_ce_4: 0.9687  loss_mask_4: 0.4386  loss_dice_4: 4.692  loss_ce_5: 0.9805  loss_mask_5: 0.4384  loss_dice_5: 4.688  loss_ce_6: 0.9843  loss_mask_6: 0.439  loss_dice_6: 4.693  loss_ce_7: 1.005  loss_mask_7: 0.4417  loss_dice_7: 4.689  loss_ce_8: 0.9991  loss_mask_8: 0.439  loss_dice_8: 4.686  time: 2.1998  data_time: 0.4029  lr: 9.9462e-05  max_mem: 24135M
[01/19 15:18:39] d2.utils.events INFO:  eta: 23:39:26  iter: 259  total_loss: 61.94  loss_ce: 1.054  loss_mask: 0.4423  loss_dice: 4.704  loss_ce_0: 1.411  loss_mask_0: 0.4425  loss_dice_0: 4.713  loss_ce_1: 0.9952  loss_mask_1: 0.4451  loss_dice_1: 4.705  loss_ce_2: 1.014  loss_mask_2: 0.4465  loss_dice_2: 4.699  loss_ce_3: 1.026  loss_mask_3: 0.4442  loss_dice_3: 4.699  loss_ce_4: 1.026  loss_mask_4: 0.4469  loss_dice_4: 4.695  loss_ce_5: 1.02  loss_mask_5: 0.4469  loss_dice_5: 4.7  loss_ce_6: 1.022  loss_mask_6: 0.4447  loss_dice_6: 4.7  loss_ce_7: 1.013  loss_mask_7: 0.447  loss_dice_7: 4.704  loss_ce_8: 1.015  loss_mask_8: 0.4438  loss_dice_8: 4.703  time: 2.1933  data_time: 0.3919  lr: 9.9417e-05  max_mem: 24135M
[01/19 15:19:22] d2.utils.events INFO:  eta: 23:38:07  iter: 279  total_loss: 61.63  loss_ce: 1.018  loss_mask: 0.4503  loss_dice: 4.676  loss_ce_0: 1.309  loss_mask_0: 0.443  loss_dice_0: 4.69  loss_ce_1: 1.003  loss_mask_1: 0.4496  loss_dice_1: 4.681  loss_ce_2: 1.002  loss_mask_2: 0.4485  loss_dice_2: 4.681  loss_ce_3: 0.9929  loss_mask_3: 0.4502  loss_dice_3: 4.679  loss_ce_4: 1.002  loss_mask_4: 0.4498  loss_dice_4: 4.676  loss_ce_5: 1.004  loss_mask_5: 0.4508  loss_dice_5: 4.677  loss_ce_6: 1.008  loss_mask_6: 0.4494  loss_dice_6: 4.681  loss_ce_7: 1.016  loss_mask_7: 0.4476  loss_dice_7: 4.674  loss_ce_8: 1.019  loss_mask_8: 0.4499  loss_dice_8: 4.674  time: 2.1885  data_time: 0.3808  lr: 9.9372e-05  max_mem: 24135M
[01/19 15:20:04] d2.utils.events INFO:  eta: 23:37:09  iter: 299  total_loss: 61.67  loss_ce: 1.029  loss_mask: 0.45  loss_dice: 4.692  loss_ce_0: 1.215  loss_mask_0: 0.4445  loss_dice_0: 4.703  loss_ce_1: 0.9778  loss_mask_1: 0.449  loss_dice_1: 4.699  loss_ce_2: 0.9981  loss_mask_2: 0.4497  loss_dice_2: 4.695  loss_ce_3: 0.9947  loss_mask_3: 0.4496  loss_dice_3: 4.695  loss_ce_4: 1.004  loss_mask_4: 0.4499  loss_dice_4: 4.696  loss_ce_5: 1.01  loss_mask_5: 0.4489  loss_dice_5: 4.695  loss_ce_6: 1.032  loss_mask_6: 0.4504  loss_dice_6: 4.695  loss_ce_7: 1.007  loss_mask_7: 0.4517  loss_dice_7: 4.688  loss_ce_8: 1.008  loss_mask_8: 0.4498  loss_dice_8: 4.693  time: 2.1850  data_time: 0.4066  lr: 9.9327e-05  max_mem: 24135M
[01/19 15:20:47] d2.utils.events INFO:  eta: 23:35:30  iter: 319  total_loss: 61.85  loss_ce: 1.024  loss_mask: 0.4629  loss_dice: 4.696  loss_ce_0: 1.15  loss_mask_0: 0.4541  loss_dice_0: 4.707  loss_ce_1: 0.9962  loss_mask_1: 0.4617  loss_dice_1: 4.694  loss_ce_2: 0.9983  loss_mask_2: 0.4615  loss_dice_2: 4.7  loss_ce_3: 1.002  loss_mask_3: 0.4606  loss_dice_3: 4.695  loss_ce_4: 1.011  loss_mask_4: 0.4615  loss_dice_4: 4.691  loss_ce_5: 1.021  loss_mask_5: 0.4626  loss_dice_5: 4.688  loss_ce_6: 1.016  loss_mask_6: 0.4628  loss_dice_6: 4.692  loss_ce_7: 1.025  loss_mask_7: 0.4632  loss_dice_7: 4.695  loss_ce_8: 1.02  loss_mask_8: 0.4633  loss_dice_8: 4.692  time: 2.1818  data_time: 0.4224  lr: 9.9282e-05  max_mem: 24135M
[01/19 15:21:29] d2.utils.events INFO:  eta: 23:34:13  iter: 339  total_loss: 62.07  loss_ce: 1.044  loss_mask: 0.4668  loss_dice: 4.687  loss_ce_0: 1.157  loss_mask_0: 0.4589  loss_dice_0: 4.7  loss_ce_1: 1.018  loss_mask_1: 0.467  loss_dice_1: 4.689  loss_ce_2: 1.024  loss_mask_2: 0.4665  loss_dice_2: 4.691  loss_ce_3: 1.035  loss_mask_3: 0.4656  loss_dice_3: 4.69  loss_ce_4: 1.016  loss_mask_4: 0.4677  loss_dice_4: 4.685  loss_ce_5: 1.025  loss_mask_5: 0.4696  loss_dice_5: 4.688  loss_ce_6: 1.062  loss_mask_6: 0.4697  loss_dice_6: 4.687  loss_ce_7: 1.048  loss_mask_7: 0.4681  loss_dice_7: 4.688  loss_ce_8: 1.045  loss_mask_8: 0.4699  loss_dice_8: 4.685  time: 2.1778  data_time: 0.3975  lr: 9.9237e-05  max_mem: 24135M
[01/19 15:22:12] d2.utils.events INFO:  eta: 23:32:40  iter: 359  total_loss: 61.69  loss_ce: 1.032  loss_mask: 0.4705  loss_dice: 4.682  loss_ce_0: 1.13  loss_mask_0: 0.4612  loss_dice_0: 4.694  loss_ce_1: 1.006  loss_mask_1: 0.4741  loss_dice_1: 4.678  loss_ce_2: 1.011  loss_mask_2: 0.4723  loss_dice_2: 4.679  loss_ce_3: 1.004  loss_mask_3: 0.4717  loss_dice_3: 4.684  loss_ce_4: 1.012  loss_mask_4: 0.4728  loss_dice_4: 4.681  loss_ce_5: 1.025  loss_mask_5: 0.4724  loss_dice_5: 4.684  loss_ce_6: 1.035  loss_mask_6: 0.4712  loss_dice_6: 4.68  loss_ce_7: 1.011  loss_mask_7: 0.4686  loss_dice_7: 4.684  loss_ce_8: 1.018  loss_mask_8: 0.4713  loss_dice_8: 4.682  time: 2.1740  data_time: 0.4034  lr: 9.9192e-05  max_mem: 24135M
[01/19 15:22:54] d2.utils.events INFO:  eta: 23:30:36  iter: 379  total_loss: 62.35  loss_ce: 1.047  loss_mask: 0.4851  loss_dice: 4.688  loss_ce_0: 1.106  loss_mask_0: 0.4772  loss_dice_0: 4.699  loss_ce_1: 1.005  loss_mask_1: 0.4847  loss_dice_1: 4.694  loss_ce_2: 1.024  loss_mask_2: 0.4849  loss_dice_2: 4.696  loss_ce_3: 1.02  loss_mask_3: 0.4851  loss_dice_3: 4.693  loss_ce_4: 1.034  loss_mask_4: 0.4866  loss_dice_4: 4.694  loss_ce_5: 1.051  loss_mask_5: 0.4872  loss_dice_5: 4.696  loss_ce_6: 1.063  loss_mask_6: 0.4869  loss_dice_6: 4.69  loss_ce_7: 1.04  loss_mask_7: 0.4858  loss_dice_7: 4.69  loss_ce_8: 1.036  loss_mask_8: 0.4864  loss_dice_8: 4.696  time: 2.1697  data_time: 0.3964  lr: 9.9147e-05  max_mem: 24135M
[01/19 15:23:37] d2.utils.events INFO:  eta: 23:29:47  iter: 399  total_loss: 61.9  loss_ce: 1.027  loss_mask: 0.4693  loss_dice: 4.697  loss_ce_0: 1.08  loss_mask_0: 0.4666  loss_dice_0: 4.702  loss_ce_1: 0.9949  loss_mask_1: 0.4729  loss_dice_1: 4.705  loss_ce_2: 1.01  loss_mask_2: 0.4715  loss_dice_2: 4.698  loss_ce_3: 1.015  loss_mask_3: 0.4716  loss_dice_3: 4.696  loss_ce_4: 1.003  loss_mask_4: 0.4708  loss_dice_4: 4.689  loss_ce_5: 1.014  loss_mask_5: 0.4696  loss_dice_5: 4.69  loss_ce_6: 1.006  loss_mask_6: 0.4701  loss_dice_6: 4.696  loss_ce_7: 1.01  loss_mask_7: 0.4703  loss_dice_7: 4.693  loss_ce_8: 1.024  loss_mask_8: 0.472  loss_dice_8: 4.696  time: 2.1686  data_time: 0.4210  lr: 9.9102e-05  max_mem: 24135M
[01/19 15:24:19] d2.utils.events INFO:  eta: 23:29:10  iter: 419  total_loss: 61.67  loss_ce: 0.9986  loss_mask: 0.4645  loss_dice: 4.701  loss_ce_0: 1.067  loss_mask_0: 0.4597  loss_dice_0: 4.705  loss_ce_1: 0.9733  loss_mask_1: 0.4666  loss_dice_1: 4.706  loss_ce_2: 0.9955  loss_mask_2: 0.4661  loss_dice_2: 4.699  loss_ce_3: 0.9877  loss_mask_3: 0.4656  loss_dice_3: 4.696  loss_ce_4: 0.9873  loss_mask_4: 0.4662  loss_dice_4: 4.699  loss_ce_5: 0.9957  loss_mask_5: 0.4653  loss_dice_5: 4.699  loss_ce_6: 0.9918  loss_mask_6: 0.4654  loss_dice_6: 4.697  loss_ce_7: 0.9981  loss_mask_7: 0.4652  loss_dice_7: 4.695  loss_ce_8: 0.9946  loss_mask_8: 0.466  loss_dice_8: 4.7  time: 2.1673  data_time: 0.3884  lr: 9.9057e-05  max_mem: 24135M
[01/19 15:25:02] d2.utils.events INFO:  eta: 23:28:22  iter: 439  total_loss: 61.82  loss_ce: 1.033  loss_mask: 0.4737  loss_dice: 4.683  loss_ce_0: 1.079  loss_mask_0: 0.4692  loss_dice_0: 4.696  loss_ce_1: 1.031  loss_mask_1: 0.4763  loss_dice_1: 4.688  loss_ce_2: 1.011  loss_mask_2: 0.4762  loss_dice_2: 4.683  loss_ce_3: 1.017  loss_mask_3: 0.4744  loss_dice_3: 4.685  loss_ce_4: 1.016  loss_mask_4: 0.4741  loss_dice_4: 4.69  loss_ce_5: 1.01  loss_mask_5: 0.4755  loss_dice_5: 4.685  loss_ce_6: 1.014  loss_mask_6: 0.4749  loss_dice_6: 4.685  loss_ce_7: 1.022  loss_mask_7: 0.4738  loss_dice_7: 4.685  loss_ce_8: 1.008  loss_mask_8: 0.4739  loss_dice_8: 4.69  time: 2.1653  data_time: 0.3997  lr: 9.9012e-05  max_mem: 24135M
[01/19 15:25:45] d2.utils.events INFO:  eta: 23:27:39  iter: 459  total_loss: 61.85  loss_ce: 1.009  loss_mask: 0.4773  loss_dice: 4.696  loss_ce_0: 1.088  loss_mask_0: 0.4766  loss_dice_0: 4.694  loss_ce_1: 1.029  loss_mask_1: 0.4789  loss_dice_1: 4.698  loss_ce_2: 1.026  loss_mask_2: 0.4797  loss_dice_2: 4.693  loss_ce_3: 1.014  loss_mask_3: 0.4799  loss_dice_3: 4.691  loss_ce_4: 0.9943  loss_mask_4: 0.4785  loss_dice_4: 4.693  loss_ce_5: 0.9929  loss_mask_5: 0.4771  loss_dice_5: 4.698  loss_ce_6: 1.008  loss_mask_6: 0.4773  loss_dice_6: 4.694  loss_ce_7: 0.998  loss_mask_7: 0.4773  loss_dice_7: 4.695  loss_ce_8: 1.008  loss_mask_8: 0.4793  loss_dice_8: 4.696  time: 2.1643  data_time: 0.4202  lr: 9.8967e-05  max_mem: 24135M
[01/19 15:26:28] d2.utils.events INFO:  eta: 23:26:56  iter: 479  total_loss: 61.84  loss_ce: 1.013  loss_mask: 0.4858  loss_dice: 4.685  loss_ce_0: 1.074  loss_mask_0: 0.4815  loss_dice_0: 4.685  loss_ce_1: 1.027  loss_mask_1: 0.4887  loss_dice_1: 4.687  loss_ce_2: 1.022  loss_mask_2: 0.4882  loss_dice_2: 4.684  loss_ce_3: 1.004  loss_mask_3: 0.4889  loss_dice_3: 4.687  loss_ce_4: 0.9992  loss_mask_4: 0.4872  loss_dice_4: 4.684  loss_ce_5: 1.006  loss_mask_5: 0.4873  loss_dice_5: 4.685  loss_ce_6: 0.9937  loss_mask_6: 0.4855  loss_dice_6: 4.685  loss_ce_7: 0.9905  loss_mask_7: 0.4864  loss_dice_7: 4.684  loss_ce_8: 0.9993  loss_mask_8: 0.4866  loss_dice_8: 4.684  time: 2.1635  data_time: 0.4000  lr: 9.8922e-05  max_mem: 24135M
[01/19 15:27:11] d2.utils.events INFO:  eta: 23:25:58  iter: 499  total_loss: 61.48  loss_ce: 0.9866  loss_mask: 0.4864  loss_dice: 4.677  loss_ce_0: 1.066  loss_mask_0: 0.4805  loss_dice_0: 4.682  loss_ce_1: 0.9799  loss_mask_1: 0.4858  loss_dice_1: 4.679  loss_ce_2: 0.9955  loss_mask_2: 0.4853  loss_dice_2: 4.675  loss_ce_3: 0.9872  loss_mask_3: 0.4842  loss_dice_3: 4.67  loss_ce_4: 0.992  loss_mask_4: 0.4853  loss_dice_4: 4.673  loss_ce_5: 0.9933  loss_mask_5: 0.4859  loss_dice_5: 4.678  loss_ce_6: 0.9933  loss_mask_6: 0.4854  loss_dice_6: 4.677  loss_ce_7: 0.9893  loss_mask_7: 0.4857  loss_dice_7: 4.676  loss_ce_8: 0.9891  loss_mask_8: 0.4873  loss_dice_8: 4.679  time: 2.1623  data_time: 0.4009  lr: 9.8877e-05  max_mem: 24135M
[01/19 15:27:53] d2.utils.events INFO:  eta: 23:23:35  iter: 519  total_loss: 62.24  loss_ce: 1.029  loss_mask: 0.4863  loss_dice: 4.672  loss_ce_0: 1.088  loss_mask_0: 0.4821  loss_dice_0: 4.678  loss_ce_1: 1.025  loss_mask_1: 0.4882  loss_dice_1: 4.674  loss_ce_2: 1.034  loss_mask_2: 0.4865  loss_dice_2: 4.674  loss_ce_3: 1.039  loss_mask_3: 0.4879  loss_dice_3: 4.671  loss_ce_4: 1.047  loss_mask_4: 0.4884  loss_dice_4: 4.673  loss_ce_5: 1.06  loss_mask_5: 0.4881  loss_dice_5: 4.668  loss_ce_6: 1.035  loss_mask_6: 0.4864  loss_dice_6: 4.672  loss_ce_7: 1.04  loss_mask_7: 0.4859  loss_dice_7: 4.673  loss_ce_8: 1.023  loss_mask_8: 0.4867  loss_dice_8: 4.669  time: 2.1606  data_time: 0.4101  lr: 9.8831e-05  max_mem: 24135M
[01/19 15:28:35] d2.utils.events INFO:  eta: 23:22:52  iter: 539  total_loss: 61.65  loss_ce: 1.005  loss_mask: 0.4784  loss_dice: 4.688  loss_ce_0: 1.057  loss_mask_0: 0.4767  loss_dice_0: 4.692  loss_ce_1: 0.9978  loss_mask_1: 0.4768  loss_dice_1: 4.691  loss_ce_2: 0.9989  loss_mask_2: 0.4793  loss_dice_2: 4.686  loss_ce_3: 1.003  loss_mask_3: 0.4792  loss_dice_3: 4.683  loss_ce_4: 0.992  loss_mask_4: 0.4789  loss_dice_4: 4.688  loss_ce_5: 0.9948  loss_mask_5: 0.4785  loss_dice_5: 4.687  loss_ce_6: 0.9893  loss_mask_6: 0.4791  loss_dice_6: 4.685  loss_ce_7: 0.9947  loss_mask_7: 0.4795  loss_dice_7: 4.688  loss_ce_8: 1  loss_mask_8: 0.48  loss_dice_8: 4.685  time: 2.1594  data_time: 0.4014  lr: 9.8786e-05  max_mem: 24135M
[01/19 15:29:18] d2.utils.events INFO:  eta: 23:23:15  iter: 559  total_loss: 61.47  loss_ce: 0.9662  loss_mask: 0.4764  loss_dice: 4.673  loss_ce_0: 1.058  loss_mask_0: 0.4763  loss_dice_0: 4.674  loss_ce_1: 1.009  loss_mask_1: 0.4796  loss_dice_1: 4.68  loss_ce_2: 0.9927  loss_mask_2: 0.4757  loss_dice_2: 4.673  loss_ce_3: 0.9754  loss_mask_3: 0.4783  loss_dice_3: 4.671  loss_ce_4: 0.9596  loss_mask_4: 0.4776  loss_dice_4: 4.674  loss_ce_5: 0.9578  loss_mask_5: 0.4774  loss_dice_5: 4.672  loss_ce_6: 0.9734  loss_mask_6: 0.4785  loss_dice_6: 4.673  loss_ce_7: 0.9619  loss_mask_7: 0.4772  loss_dice_7: 4.673  loss_ce_8: 0.9601  loss_mask_8: 0.4769  loss_dice_8: 4.677  time: 2.1585  data_time: 0.4257  lr: 9.8741e-05  max_mem: 24135M
[01/19 15:30:01] d2.utils.events INFO:  eta: 23:22:51  iter: 579  total_loss: 61.56  loss_ce: 0.9998  loss_mask: 0.4811  loss_dice: 4.675  loss_ce_0: 1.03  loss_mask_0: 0.474  loss_dice_0: 4.679  loss_ce_1: 0.9725  loss_mask_1: 0.4799  loss_dice_1: 4.682  loss_ce_2: 0.9856  loss_mask_2: 0.4809  loss_dice_2: 4.681  loss_ce_3: 0.9927  loss_mask_3: 0.4791  loss_dice_3: 4.676  loss_ce_4: 1.006  loss_mask_4: 0.4803  loss_dice_4: 4.677  loss_ce_5: 1.008  loss_mask_5: 0.4806  loss_dice_5: 4.678  loss_ce_6: 0.9917  loss_mask_6: 0.4807  loss_dice_6: 4.674  loss_ce_7: 0.9925  loss_mask_7: 0.4815  loss_dice_7: 4.677  loss_ce_8: 1.006  loss_mask_8: 0.4825  loss_dice_8: 4.674  time: 2.1580  data_time: 0.4168  lr: 9.8696e-05  max_mem: 24135M
[01/19 15:30:43] d2.utils.events INFO:  eta: 23:21:36  iter: 599  total_loss: 61.63  loss_ce: 0.9957  loss_mask: 0.4809  loss_dice: 4.68  loss_ce_0: 1.056  loss_mask_0: 0.4793  loss_dice_0: 4.68  loss_ce_1: 1.013  loss_mask_1: 0.4807  loss_dice_1: 4.685  loss_ce_2: 0.9971  loss_mask_2: 0.4827  loss_dice_2: 4.682  loss_ce_3: 0.9818  loss_mask_3: 0.4826  loss_dice_3: 4.682  loss_ce_4: 0.9885  loss_mask_4: 0.484  loss_dice_4: 4.678  loss_ce_5: 0.9925  loss_mask_5: 0.4838  loss_dice_5: 4.683  loss_ce_6: 0.9905  loss_mask_6: 0.4815  loss_dice_6: 4.676  loss_ce_7: 0.9919  loss_mask_7: 0.481  loss_dice_7: 4.679  loss_ce_8: 0.9945  loss_mask_8: 0.4824  loss_dice_8: 4.682  time: 2.1565  data_time: 0.4095  lr: 9.8651e-05  max_mem: 24135M
[01/19 15:31:27] d2.utils.events INFO:  eta: 23:20:53  iter: 619  total_loss: 61.41  loss_ce: 0.9876  loss_mask: 0.485  loss_dice: 4.673  loss_ce_0: 1.046  loss_mask_0: 0.4781  loss_dice_0: 4.672  loss_ce_1: 1.006  loss_mask_1: 0.4837  loss_dice_1: 4.674  loss_ce_2: 0.981  loss_mask_2: 0.4824  loss_dice_2: 4.674  loss_ce_3: 0.987  loss_mask_3: 0.4821  loss_dice_3: 4.672  loss_ce_4: 0.9817  loss_mask_4: 0.4832  loss_dice_4: 4.67  loss_ce_5: 0.9814  loss_mask_5: 0.4843  loss_dice_5: 4.674  loss_ce_6: 0.9787  loss_mask_6: 0.4844  loss_dice_6: 4.668  loss_ce_7: 0.9764  loss_mask_7: 0.4848  loss_dice_7: 4.665  loss_ce_8: 0.9851  loss_mask_8: 0.4845  loss_dice_8: 4.666  time: 2.1564  data_time: 0.4163  lr: 9.8606e-05  max_mem: 24139M
[01/19 15:32:09] d2.utils.events INFO:  eta: 23:18:28  iter: 639  total_loss: 61.68  loss_ce: 0.9701  loss_mask: 0.4771  loss_dice: 4.679  loss_ce_0: 1.035  loss_mask_0: 0.4771  loss_dice_0: 4.68  loss_ce_1: 0.9951  loss_mask_1: 0.4777  loss_dice_1: 4.685  loss_ce_2: 0.996  loss_mask_2: 0.4759  loss_dice_2: 4.683  loss_ce_3: 0.9793  loss_mask_3: 0.4779  loss_dice_3: 4.681  loss_ce_4: 0.9743  loss_mask_4: 0.4798  loss_dice_4: 4.678  loss_ce_5: 0.9789  loss_mask_5: 0.4799  loss_dice_5: 4.676  loss_ce_6: 0.9699  loss_mask_6: 0.4777  loss_dice_6: 4.678  loss_ce_7: 0.9638  loss_mask_7: 0.4778  loss_dice_7: 4.674  loss_ce_8: 0.9749  loss_mask_8: 0.476  loss_dice_8: 4.673  time: 2.1549  data_time: 0.3887  lr: 9.8561e-05  max_mem: 24139M
[01/19 15:32:51] d2.utils.events INFO:  eta: 23:17:00  iter: 659  total_loss: 62.08  loss_ce: 1.002  loss_mask: 0.4905  loss_dice: 4.672  loss_ce_0: 1.053  loss_mask_0: 0.4882  loss_dice_0: 4.678  loss_ce_1: 0.9969  loss_mask_1: 0.4902  loss_dice_1: 4.68  loss_ce_2: 1.016  loss_mask_2: 0.4889  loss_dice_2: 4.68  loss_ce_3: 1.03  loss_mask_3: 0.4882  loss_dice_3: 4.674  loss_ce_4: 1.027  loss_mask_4: 0.4901  loss_dice_4: 4.673  loss_ce_5: 1.032  loss_mask_5: 0.4908  loss_dice_5: 4.673  loss_ce_6: 1.037  loss_mask_6: 0.4902  loss_dice_6: 4.674  loss_ce_7: 1.02  loss_mask_7: 0.489  loss_dice_7: 4.673  loss_ce_8: 1.016  loss_mask_8: 0.4895  loss_dice_8: 4.671  time: 2.1539  data_time: 0.4005  lr: 9.8516e-05  max_mem: 24139M
[01/19 15:33:34] d2.utils.events INFO:  eta: 23:16:17  iter: 679  total_loss: 61.68  loss_ce: 0.9969  loss_mask: 0.4826  loss_dice: 4.682  loss_ce_0: 1.053  loss_mask_0: 0.4812  loss_dice_0: 4.688  loss_ce_1: 0.9866  loss_mask_1: 0.4846  loss_dice_1: 4.694  loss_ce_2: 0.986  loss_mask_2: 0.485  loss_dice_2: 4.686  loss_ce_3: 0.9742  loss_mask_3: 0.4864  loss_dice_3: 4.683  loss_ce_4: 0.9882  loss_mask_4: 0.4856  loss_dice_4: 4.681  loss_ce_5: 1.001  loss_mask_5: 0.484  loss_dice_5: 4.682  loss_ce_6: 0.9925  loss_mask_6: 0.485  loss_dice_6: 4.682  loss_ce_7: 0.9876  loss_mask_7: 0.4849  loss_dice_7: 4.682  loss_ce_8: 0.9844  loss_mask_8: 0.4849  loss_dice_8: 4.682  time: 2.1528  data_time: 0.4116  lr: 9.8471e-05  max_mem: 24139M
[01/19 15:34:17] d2.utils.events INFO:  eta: 23:16:02  iter: 699  total_loss: 61.68  loss_ce: 0.9815  loss_mask: 0.4848  loss_dice: 4.671  loss_ce_0: 1.04  loss_mask_0: 0.4815  loss_dice_0: 4.679  loss_ce_1: 0.9632  loss_mask_1: 0.4844  loss_dice_1: 4.684  loss_ce_2: 0.9851  loss_mask_2: 0.4829  loss_dice_2: 4.676  loss_ce_3: 1.009  loss_mask_3: 0.4818  loss_dice_3: 4.674  loss_ce_4: 1.006  loss_mask_4: 0.4842  loss_dice_4: 4.675  loss_ce_5: 0.9848  loss_mask_5: 0.4815  loss_dice_5: 4.675  loss_ce_6: 0.9848  loss_mask_6: 0.4835  loss_dice_6: 4.674  loss_ce_7: 0.9711  loss_mask_7: 0.482  loss_dice_7: 4.674  loss_ce_8: 0.9881  loss_mask_8: 0.4841  loss_dice_8: 4.671  time: 2.1526  data_time: 0.4256  lr: 9.8426e-05  max_mem: 24139M
[01/19 15:34:59] d2.utils.events INFO:  eta: 23:14:45  iter: 719  total_loss: 61.55  loss_ce: 0.9819  loss_mask: 0.4988  loss_dice: 4.68  loss_ce_0: 1.043  loss_mask_0: 0.4946  loss_dice_0: 4.672  loss_ce_1: 0.9914  loss_mask_1: 0.4991  loss_dice_1: 4.682  loss_ce_2: 0.9778  loss_mask_2: 0.498  loss_dice_2: 4.678  loss_ce_3: 0.9653  loss_mask_3: 0.4979  loss_dice_3: 4.678  loss_ce_4: 0.9552  loss_mask_4: 0.4981  loss_dice_4: 4.675  loss_ce_5: 0.9672  loss_mask_5: 0.4991  loss_dice_5: 4.677  loss_ce_6: 0.9551  loss_mask_6: 0.4999  loss_dice_6: 4.677  loss_ce_7: 0.956  loss_mask_7: 0.5002  loss_dice_7: 4.68  loss_ce_8: 0.9619  loss_mask_8: 0.4995  loss_dice_8: 4.676  time: 2.1512  data_time: 0.3814  lr: 9.8381e-05  max_mem: 24139M
[01/19 15:35:41] d2.utils.events INFO:  eta: 23:13:17  iter: 739  total_loss: 61.38  loss_ce: 0.9496  loss_mask: 0.4869  loss_dice: 4.671  loss_ce_0: 1.024  loss_mask_0: 0.4848  loss_dice_0: 4.677  loss_ce_1: 0.9791  loss_mask_1: 0.488  loss_dice_1: 4.681  loss_ce_2: 0.9704  loss_mask_2: 0.4888  loss_dice_2: 4.674  loss_ce_3: 0.9621  loss_mask_3: 0.4892  loss_dice_3: 4.669  loss_ce_4: 0.9761  loss_mask_4: 0.4876  loss_dice_4: 4.672  loss_ce_5: 0.9679  loss_mask_5: 0.4852  loss_dice_5: 4.672  loss_ce_6: 0.9628  loss_mask_6: 0.4861  loss_dice_6: 4.673  loss_ce_7: 0.9507  loss_mask_7: 0.4866  loss_dice_7: 4.672  loss_ce_8: 0.9572  loss_mask_8: 0.4863  loss_dice_8: 4.671  time: 2.1498  data_time: 0.3848  lr: 9.8336e-05  max_mem: 24139M
[01/19 15:36:23] d2.utils.events INFO:  eta: 23:12:08  iter: 759  total_loss: 61.85  loss_ce: 1.02  loss_mask: 0.5051  loss_dice: 4.655  loss_ce_0: 1.067  loss_mask_0: 0.5032  loss_dice_0: 4.663  loss_ce_1: 1.012  loss_mask_1: 0.505  loss_dice_1: 4.666  loss_ce_2: 1.018  loss_mask_2: 0.5061  loss_dice_2: 4.66  loss_ce_3: 1.018  loss_mask_3: 0.5069  loss_dice_3: 4.662  loss_ce_4: 1.014  loss_mask_4: 0.5057  loss_dice_4: 4.659  loss_ce_5: 1.013  loss_mask_5: 0.5044  loss_dice_5: 4.658  loss_ce_6: 1.013  loss_mask_6: 0.5051  loss_dice_6: 4.656  loss_ce_7: 1.024  loss_mask_7: 0.5067  loss_dice_7: 4.656  loss_ce_8: 1.035  loss_mask_8: 0.5067  loss_dice_8: 4.657  time: 2.1482  data_time: 0.4019  lr: 9.8291e-05  max_mem: 24139M
[01/19 15:37:05] d2.utils.events INFO:  eta: 23:11:16  iter: 779  total_loss: 61.84  loss_ce: 1.011  loss_mask: 0.4955  loss_dice: 4.657  loss_ce_0: 1.086  loss_mask_0: 0.4891  loss_dice_0: 4.654  loss_ce_1: 1.03  loss_mask_1: 0.4925  loss_dice_1: 4.664  loss_ce_2: 1.028  loss_mask_2: 0.4934  loss_dice_2: 4.659  loss_ce_3: 1.026  loss_mask_3: 0.493  loss_dice_3: 4.659  loss_ce_4: 1.026  loss_mask_4: 0.493  loss_dice_4: 4.653  loss_ce_5: 1.021  loss_mask_5: 0.4937  loss_dice_5: 4.655  loss_ce_6: 1.023  loss_mask_6: 0.4947  loss_dice_6: 4.655  loss_ce_7: 1.014  loss_mask_7: 0.4932  loss_dice_7: 4.657  loss_ce_8: 1.01  loss_mask_8: 0.4943  loss_dice_8: 4.653  time: 2.1477  data_time: 0.3993  lr: 9.8246e-05  max_mem: 24139M
[01/19 15:37:47] d2.utils.events INFO:  eta: 23:10:34  iter: 799  total_loss: 61.61  loss_ce: 1.004  loss_mask: 0.4908  loss_dice: 4.639  loss_ce_0: 1.082  loss_mask_0: 0.4914  loss_dice_0: 4.638  loss_ce_1: 1.014  loss_mask_1: 0.4943  loss_dice_1: 4.647  loss_ce_2: 1.019  loss_mask_2: 0.494  loss_dice_2: 4.65  loss_ce_3: 1.021  loss_mask_3: 0.4944  loss_dice_3: 4.644  loss_ce_4: 0.9997  loss_mask_4: 0.4954  loss_dice_4: 4.64  loss_ce_5: 1.013  loss_mask_5: 0.4932  loss_dice_5: 4.642  loss_ce_6: 0.9893  loss_mask_6: 0.4926  loss_dice_6: 4.644  loss_ce_7: 0.9932  loss_mask_7: 0.4932  loss_dice_7: 4.642  loss_ce_8: 0.9892  loss_mask_8: 0.4928  loss_dice_8: 4.642  time: 2.1468  data_time: 0.4038  lr: 9.82e-05  max_mem: 24139M
[01/19 15:38:29] d2.utils.events INFO:  eta: 23:08:57  iter: 819  total_loss: 61.36  loss_ce: 0.9951  loss_mask: 0.4904  loss_dice: 4.652  loss_ce_0: 1.058  loss_mask_0: 0.4866  loss_dice_0: 4.656  loss_ce_1: 0.9834  loss_mask_1: 0.4923  loss_dice_1: 4.66  loss_ce_2: 0.9878  loss_mask_2: 0.4914  loss_dice_2: 4.656  loss_ce_3: 0.9896  loss_mask_3: 0.4905  loss_dice_3: 4.656  loss_ce_4: 0.9908  loss_mask_4: 0.4901  loss_dice_4: 4.654  loss_ce_5: 0.9836  loss_mask_5: 0.4893  loss_dice_5: 4.654  loss_ce_6: 0.9787  loss_mask_6: 0.4901  loss_dice_6: 4.653  loss_ce_7: 0.9918  loss_mask_7: 0.4902  loss_dice_7: 4.653  loss_ce_8: 0.9916  loss_mask_8: 0.4907  loss_dice_8: 4.652  time: 2.1455  data_time: 0.3970  lr: 9.8155e-05  max_mem: 24139M
[01/19 15:39:12] d2.utils.events INFO:  eta: 23:08:36  iter: 839  total_loss: 61.15  loss_ce: 0.9672  loss_mask: 0.4878  loss_dice: 4.66  loss_ce_0: 1.052  loss_mask_0: 0.4824  loss_dice_0: 4.66  loss_ce_1: 0.976  loss_mask_1: 0.4864  loss_dice_1: 4.668  loss_ce_2: 0.9759  loss_mask_2: 0.486  loss_dice_2: 4.663  loss_ce_3: 0.9848  loss_mask_3: 0.4849  loss_dice_3: 4.664  loss_ce_4: 0.9695  loss_mask_4: 0.4845  loss_dice_4: 4.656  loss_ce_5: 0.9716  loss_mask_5: 0.4847  loss_dice_5: 4.662  loss_ce_6: 0.9593  loss_mask_6: 0.4866  loss_dice_6: 4.659  loss_ce_7: 0.9556  loss_mask_7: 0.4877  loss_dice_7: 4.66  loss_ce_8: 0.962  loss_mask_8: 0.487  loss_dice_8: 4.661  time: 2.1454  data_time: 0.4116  lr: 9.811e-05  max_mem: 24139M
[01/19 15:39:54] d2.utils.events INFO:  eta: 23:07:23  iter: 859  total_loss: 61.7  loss_ce: 1  loss_mask: 0.5096  loss_dice: 4.648  loss_ce_0: 1.08  loss_mask_0: 0.5106  loss_dice_0: 4.649  loss_ce_1: 1.021  loss_mask_1: 0.5116  loss_dice_1: 4.66  loss_ce_2: 1.013  loss_mask_2: 0.5092  loss_dice_2: 4.654  loss_ce_3: 0.9993  loss_mask_3: 0.5106  loss_dice_3: 4.652  loss_ce_4: 1.024  loss_mask_4: 0.5124  loss_dice_4: 4.646  loss_ce_5: 1.001  loss_mask_5: 0.5108  loss_dice_5: 4.649  loss_ce_6: 1.005  loss_mask_6: 0.5106  loss_dice_6: 4.646  loss_ce_7: 0.986  loss_mask_7: 0.5108  loss_dice_7: 4.646  loss_ce_8: 1.001  loss_mask_8: 0.5095  loss_dice_8: 4.649  time: 2.1441  data_time: 0.4031  lr: 9.8065e-05  max_mem: 24139M
[01/19 15:40:36] d2.utils.events INFO:  eta: 23:06:26  iter: 879  total_loss: 61.55  loss_ce: 0.9811  loss_mask: 0.5071  loss_dice: 4.651  loss_ce_0: 1.073  loss_mask_0: 0.5034  loss_dice_0: 4.655  loss_ce_1: 0.9827  loss_mask_1: 0.5072  loss_dice_1: 4.66  loss_ce_2: 0.9918  loss_mask_2: 0.5061  loss_dice_2: 4.659  loss_ce_3: 1.006  loss_mask_3: 0.506  loss_dice_3: 4.654  loss_ce_4: 0.9937  loss_mask_4: 0.5071  loss_dice_4: 4.652  loss_ce_5: 0.9902  loss_mask_5: 0.5067  loss_dice_5: 4.65  loss_ce_6: 0.9873  loss_mask_6: 0.5076  loss_dice_6: 4.649  loss_ce_7: 0.9854  loss_mask_7: 0.5076  loss_dice_7: 4.648  loss_ce_8: 0.9829  loss_mask_8: 0.5072  loss_dice_8: 4.649  time: 2.1431  data_time: 0.3970  lr: 9.802e-05  max_mem: 24139M
[01/19 15:41:19] d2.utils.events INFO:  eta: 23:05:24  iter: 899  total_loss: 61.71  loss_ce: 1.024  loss_mask: 0.4947  loss_dice: 4.643  loss_ce_0: 1.098  loss_mask_0: 0.495  loss_dice_0: 4.647  loss_ce_1: 1.006  loss_mask_1: 0.4983  loss_dice_1: 4.655  loss_ce_2: 1.019  loss_mask_2: 0.4985  loss_dice_2: 4.646  loss_ce_3: 1.021  loss_mask_3: 0.4981  loss_dice_3: 4.645  loss_ce_4: 1.036  loss_mask_4: 0.4959  loss_dice_4: 4.639  loss_ce_5: 1.039  loss_mask_5: 0.4948  loss_dice_5: 4.639  loss_ce_6: 1.037  loss_mask_6: 0.4949  loss_dice_6: 4.638  loss_ce_7: 1.018  loss_mask_7: 0.4944  loss_dice_7: 4.64  loss_ce_8: 1.024  loss_mask_8: 0.4944  loss_dice_8: 4.64  time: 2.1427  data_time: 0.4075  lr: 9.7975e-05  max_mem: 24284M
[01/19 15:42:01] d2.utils.events INFO:  eta: 23:04:34  iter: 919  total_loss: 61.29  loss_ce: 0.9637  loss_mask: 0.5005  loss_dice: 4.662  loss_ce_0: 1.047  loss_mask_0: 0.4957  loss_dice_0: 4.666  loss_ce_1: 0.9922  loss_mask_1: 0.4993  loss_dice_1: 4.677  loss_ce_2: 0.9804  loss_mask_2: 0.4987  loss_dice_2: 4.669  loss_ce_3: 0.9883  loss_mask_3: 0.4982  loss_dice_3: 4.667  loss_ce_4: 0.9854  loss_mask_4: 0.4982  loss_dice_4: 4.661  loss_ce_5: 0.9753  loss_mask_5: 0.5017  loss_dice_5: 4.664  loss_ce_6: 0.9672  loss_mask_6: 0.5001  loss_dice_6: 4.662  loss_ce_7: 0.9701  loss_mask_7: 0.5009  loss_dice_7: 4.665  loss_ce_8: 0.9684  loss_mask_8: 0.5003  loss_dice_8: 4.663  time: 2.1427  data_time: 0.4120  lr: 9.793e-05  max_mem: 24284M
[01/19 15:42:44] d2.utils.events INFO:  eta: 23:03:51  iter: 939  total_loss: 61.74  loss_ce: 0.9819  loss_mask: 0.4905  loss_dice: 4.658  loss_ce_0: 1.066  loss_mask_0: 0.4926  loss_dice_0: 4.664  loss_ce_1: 1.003  loss_mask_1: 0.494  loss_dice_1: 4.675  loss_ce_2: 0.9823  loss_mask_2: 0.4926  loss_dice_2: 4.667  loss_ce_3: 0.9832  loss_mask_3: 0.4917  loss_dice_3: 4.665  loss_ce_4: 0.9933  loss_mask_4: 0.4915  loss_dice_4: 4.662  loss_ce_5: 0.9895  loss_mask_5: 0.4919  loss_dice_5: 4.656  loss_ce_6: 0.993  loss_mask_6: 0.4913  loss_dice_6: 4.657  loss_ce_7: 0.9957  loss_mask_7: 0.49  loss_dice_7: 4.661  loss_ce_8: 0.9833  loss_mask_8: 0.4918  loss_dice_8: 4.662  time: 2.1424  data_time: 0.3867  lr: 9.7885e-05  max_mem: 24284M
[01/19 15:43:27] d2.utils.events INFO:  eta: 23:03:09  iter: 959  total_loss: 61.55  loss_ce: 0.9822  loss_mask: 0.5039  loss_dice: 4.651  loss_ce_0: 1.07  loss_mask_0: 0.5011  loss_dice_0: 4.656  loss_ce_1: 0.995  loss_mask_1: 0.5039  loss_dice_1: 4.664  loss_ce_2: 0.9818  loss_mask_2: 0.5021  loss_dice_2: 4.657  loss_ce_3: 1.005  loss_mask_3: 0.5019  loss_dice_3: 4.656  loss_ce_4: 1.001  loss_mask_4: 0.5031  loss_dice_4: 4.652  loss_ce_5: 0.9864  loss_mask_5: 0.5037  loss_dice_5: 4.647  loss_ce_6: 0.9891  loss_mask_6: 0.5039  loss_dice_6: 4.65  loss_ce_7: 0.9841  loss_mask_7: 0.5035  loss_dice_7: 4.649  loss_ce_8: 0.9764  loss_mask_8: 0.5038  loss_dice_8: 4.647  time: 2.1421  data_time: 0.4225  lr: 9.784e-05  max_mem: 24284M
[01/19 15:44:10] d2.utils.events INFO:  eta: 23:03:08  iter: 979  total_loss: 61.44  loss_ce: 0.9683  loss_mask: 0.4949  loss_dice: 4.667  loss_ce_0: 1.044  loss_mask_0: 0.4938  loss_dice_0: 4.668  loss_ce_1: 0.9903  loss_mask_1: 0.4952  loss_dice_1: 4.675  loss_ce_2: 0.9877  loss_mask_2: 0.4968  loss_dice_2: 4.677  loss_ce_3: 0.9878  loss_mask_3: 0.4965  loss_dice_3: 4.67  loss_ce_4: 0.9709  loss_mask_4: 0.4945  loss_dice_4: 4.668  loss_ce_5: 0.9701  loss_mask_5: 0.4932  loss_dice_5: 4.668  loss_ce_6: 0.9583  loss_mask_6: 0.4944  loss_dice_6: 4.665  loss_ce_7: 0.9609  loss_mask_7: 0.4938  loss_dice_7: 4.665  loss_ce_8: 0.963  loss_mask_8: 0.4946  loss_dice_8: 4.666  time: 2.1424  data_time: 0.4039  lr: 9.7795e-05  max_mem: 24284M
[01/19 15:44:52] d2.utils.events INFO:  eta: 23:02:04  iter: 999  total_loss: 61.98  loss_ce: 1.016  loss_mask: 0.5045  loss_dice: 4.642  loss_ce_0: 1.085  loss_mask_0: 0.5055  loss_dice_0: 4.644  loss_ce_1: 1.019  loss_mask_1: 0.5054  loss_dice_1: 4.65  loss_ce_2: 1.017  loss_mask_2: 0.5057  loss_dice_2: 4.646  loss_ce_3: 1.038  loss_mask_3: 0.5053  loss_dice_3: 4.643  loss_ce_4: 1.045  loss_mask_4: 0.5049  loss_dice_4: 4.644  loss_ce_5: 1.039  loss_mask_5: 0.5041  loss_dice_5: 4.637  loss_ce_6: 1.032  loss_mask_6: 0.504  loss_dice_6: 4.639  loss_ce_7: 1.03  loss_mask_7: 0.5043  loss_dice_7: 4.637  loss_ce_8: 1.032  loss_mask_8: 0.5046  loss_dice_8: 4.639  time: 2.1419  data_time: 0.4042  lr: 9.7749e-05  max_mem: 24284M
[01/19 15:45:35] d2.utils.events INFO:  eta: 23:00:26  iter: 1019  total_loss: 62.12  loss_ce: 1.051  loss_mask: 0.506  loss_dice: 4.643  loss_ce_0: 1.069  loss_mask_0: 0.5011  loss_dice_0: 4.653  loss_ce_1: 0.9956  loss_mask_1: 0.5095  loss_dice_1: 4.66  loss_ce_2: 1.005  loss_mask_2: 0.508  loss_dice_2: 4.653  loss_ce_3: 1.015  loss_mask_3: 0.5083  loss_dice_3: 4.65  loss_ce_4: 1.024  loss_mask_4: 0.5086  loss_dice_4: 4.648  loss_ce_5: 1.047  loss_mask_5: 0.5081  loss_dice_5: 4.643  loss_ce_6: 1.065  loss_mask_6: 0.5074  loss_dice_6: 4.645  loss_ce_7: 1.063  loss_mask_7: 0.5054  loss_dice_7: 4.645  loss_ce_8: 1.044  loss_mask_8: 0.5058  loss_dice_8: 4.642  time: 2.1416  data_time: 0.4086  lr: 9.7704e-05  max_mem: 24284M
[01/19 15:46:17] d2.utils.events INFO:  eta: 22:59:15  iter: 1039  total_loss: 61.83  loss_ce: 0.992  loss_mask: 0.5001  loss_dice: 4.652  loss_ce_0: 1.07  loss_mask_0: 0.5024  loss_dice_0: 4.659  loss_ce_1: 0.9964  loss_mask_1: 0.4991  loss_dice_1: 4.667  loss_ce_2: 1.022  loss_mask_2: 0.4989  loss_dice_2: 4.66  loss_ce_3: 1.018  loss_mask_3: 0.4985  loss_dice_3: 4.659  loss_ce_4: 0.9971  loss_mask_4: 0.5015  loss_dice_4: 4.654  loss_ce_5: 0.9854  loss_mask_5: 0.5014  loss_dice_5: 4.653  loss_ce_6: 0.9845  loss_mask_6: 0.5014  loss_dice_6: 4.649  loss_ce_7: 1.004  loss_mask_7: 0.5012  loss_dice_7: 4.648  loss_ce_8: 0.9987  loss_mask_8: 0.5009  loss_dice_8: 4.648  time: 2.1413  data_time: 0.4118  lr: 9.7659e-05  max_mem: 24284M
[01/19 15:47:00] d2.utils.events INFO:  eta: 22:57:34  iter: 1059  total_loss: 62.07  loss_ce: 1.063  loss_mask: 0.5006  loss_dice: 4.625  loss_ce_0: 1.072  loss_mask_0: 0.501  loss_dice_0: 4.642  loss_ce_1: 1.081  loss_mask_1: 0.5016  loss_dice_1: 4.648  loss_ce_2: 1.02  loss_mask_2: 0.4997  loss_dice_2: 4.64  loss_ce_3: 1.065  loss_mask_3: 0.5025  loss_dice_3: 4.632  loss_ce_4: 1.068  loss_mask_4: 0.5009  loss_dice_4: 4.631  loss_ce_5: 1.049  loss_mask_5: 0.5004  loss_dice_5: 4.631  loss_ce_6: 1.05  loss_mask_6: 0.5017  loss_dice_6: 4.637  loss_ce_7: 1.036  loss_mask_7: 0.5012  loss_dice_7: 4.632  loss_ce_8: 1.079  loss_mask_8: 0.5017  loss_dice_8: 4.632  time: 2.1411  data_time: 0.4142  lr: 9.7614e-05  max_mem: 24284M
[01/19 15:47:42] d2.utils.events INFO:  eta: 22:56:19  iter: 1079  total_loss: 61.87  loss_ce: 1.049  loss_mask: 0.5018  loss_dice: 4.642  loss_ce_0: 1.065  loss_mask_0: 0.5031  loss_dice_0: 4.654  loss_ce_1: 1.012  loss_mask_1: 0.5027  loss_dice_1: 4.663  loss_ce_2: 1.02  loss_mask_2: 0.5011  loss_dice_2: 4.656  loss_ce_3: 1.052  loss_mask_3: 0.5008  loss_dice_3: 4.652  loss_ce_4: 1.029  loss_mask_4: 0.5023  loss_dice_4: 4.651  loss_ce_5: 1.015  loss_mask_5: 0.5025  loss_dice_5: 4.646  loss_ce_6: 1.029  loss_mask_6: 0.5026  loss_dice_6: 4.644  loss_ce_7: 1.028  loss_mask_7: 0.5036  loss_dice_7: 4.641  loss_ce_8: 1.041  loss_mask_8: 0.5022  loss_dice_8: 4.641  time: 2.1404  data_time: 0.4027  lr: 9.7569e-05  max_mem: 24284M
[01/19 15:48:24] d2.utils.events INFO:  eta: 22:55:23  iter: 1099  total_loss: 61.46  loss_ce: 0.9851  loss_mask: 0.5077  loss_dice: 4.636  loss_ce_0: 1.09  loss_mask_0: 0.5072  loss_dice_0: 4.642  loss_ce_1: 1.008  loss_mask_1: 0.5102  loss_dice_1: 4.655  loss_ce_2: 1.014  loss_mask_2: 0.509  loss_dice_2: 4.643  loss_ce_3: 1.017  loss_mask_3: 0.5066  loss_dice_3: 4.643  loss_ce_4: 0.9919  loss_mask_4: 0.5091  loss_dice_4: 4.64  loss_ce_5: 0.9904  loss_mask_5: 0.5099  loss_dice_5: 4.634  loss_ce_6: 0.9961  loss_mask_6: 0.5077  loss_dice_6: 4.639  loss_ce_7: 1.002  loss_mask_7: 0.5077  loss_dice_7: 4.634  loss_ce_8: 0.9872  loss_mask_8: 0.5091  loss_dice_8: 4.633  time: 2.1397  data_time: 0.3988  lr: 9.7524e-05  max_mem: 24284M
[01/19 15:49:07] d2.utils.events INFO:  eta: 22:54:34  iter: 1119  total_loss: 61.6  loss_ce: 1.01  loss_mask: 0.5011  loss_dice: 4.642  loss_ce_0: 1.071  loss_mask_0: 0.4986  loss_dice_0: 4.646  loss_ce_1: 1.003  loss_mask_1: 0.5017  loss_dice_1: 4.657  loss_ce_2: 1.018  loss_mask_2: 0.5012  loss_dice_2: 4.644  loss_ce_3: 1.01  loss_mask_3: 0.5012  loss_dice_3: 4.644  loss_ce_4: 1.006  loss_mask_4: 0.5004  loss_dice_4: 4.641  loss_ce_5: 1.008  loss_mask_5: 0.5008  loss_dice_5: 4.639  loss_ce_6: 0.994  loss_mask_6: 0.5017  loss_dice_6: 4.641  loss_ce_7: 1.009  loss_mask_7: 0.5008  loss_dice_7: 4.638  loss_ce_8: 1.002  loss_mask_8: 0.5016  loss_dice_8: 4.64  time: 2.1396  data_time: 0.4182  lr: 9.7479e-05  max_mem: 24284M
[01/19 15:49:49] d2.utils.events INFO:  eta: 22:53:10  iter: 1139  total_loss: 61.98  loss_ce: 1.003  loss_mask: 0.5091  loss_dice: 4.639  loss_ce_0: 1.068  loss_mask_0: 0.5102  loss_dice_0: 4.653  loss_ce_1: 0.9919  loss_mask_1: 0.5111  loss_dice_1: 4.654  loss_ce_2: 1.038  loss_mask_2: 0.509  loss_dice_2: 4.646  loss_ce_3: 1.059  loss_mask_3: 0.5087  loss_dice_3: 4.642  loss_ce_4: 1.052  loss_mask_4: 0.509  loss_dice_4: 4.639  loss_ce_5: 1.033  loss_mask_5: 0.5097  loss_dice_5: 4.64  loss_ce_6: 1.022  loss_mask_6: 0.5087  loss_dice_6: 4.634  loss_ce_7: 1.018  loss_mask_7: 0.5092  loss_dice_7: 4.638  loss_ce_8: 1.008  loss_mask_8: 0.5083  loss_dice_8: 4.635  time: 2.1390  data_time: 0.4057  lr: 9.7434e-05  max_mem: 24284M
[01/19 15:50:31] d2.utils.events INFO:  eta: 22:52:15  iter: 1159  total_loss: 62.07  loss_ce: 1.061  loss_mask: 0.5171  loss_dice: 4.629  loss_ce_0: 1.095  loss_mask_0: 0.517  loss_dice_0: 4.645  loss_ce_1: 1.038  loss_mask_1: 0.5217  loss_dice_1: 4.644  loss_ce_2: 1.064  loss_mask_2: 0.52  loss_dice_2: 4.634  loss_ce_3: 1.073  loss_mask_3: 0.5172  loss_dice_3: 4.63  loss_ce_4: 1.08  loss_mask_4: 0.517  loss_dice_4: 4.63  loss_ce_5: 1.077  loss_mask_5: 0.5139  loss_dice_5: 4.626  loss_ce_6: 1.06  loss_mask_6: 0.5162  loss_dice_6: 4.628  loss_ce_7: 1.057  loss_mask_7: 0.516  loss_dice_7: 4.624  loss_ce_8: 1.048  loss_mask_8: 0.517  loss_dice_8: 4.628  time: 2.1382  data_time: 0.3840  lr: 9.7388e-05  max_mem: 24284M
[01/19 15:51:13] d2.utils.events INFO:  eta: 22:51:20  iter: 1179  total_loss: 62.63  loss_ce: 1.118  loss_mask: 0.5003  loss_dice: 4.638  loss_ce_0: 1.102  loss_mask_0: 0.5005  loss_dice_0: 4.66  loss_ce_1: 1.07  loss_mask_1: 0.4996  loss_dice_1: 4.654  loss_ce_2: 1.126  loss_mask_2: 0.4996  loss_dice_2: 4.642  loss_ce_3: 1.141  loss_mask_3: 0.5011  loss_dice_3: 4.644  loss_ce_4: 1.101  loss_mask_4: 0.502  loss_dice_4: 4.64  loss_ce_5: 1.113  loss_mask_5: 0.5028  loss_dice_5: 4.64  loss_ce_6: 1.147  loss_mask_6: 0.5019  loss_dice_6: 4.637  loss_ce_7: 1.176  loss_mask_7: 0.5003  loss_dice_7: 4.638  loss_ce_8: 1.149  loss_mask_8: 0.5003  loss_dice_8: 4.637  time: 2.1378  data_time: 0.4066  lr: 9.7343e-05  max_mem: 24284M
[01/19 15:51:56] d2.utils.events INFO:  eta: 22:50:51  iter: 1199  total_loss: 62.49  loss_ce: 1.111  loss_mask: 0.5116  loss_dice: 4.628  loss_ce_0: 1.12  loss_mask_0: 0.5118  loss_dice_0: 4.638  loss_ce_1: 1.109  loss_mask_1: 0.5108  loss_dice_1: 4.644  loss_ce_2: 1.099  loss_mask_2: 0.5107  loss_dice_2: 4.633  loss_ce_3: 1.098  loss_mask_3: 0.5132  loss_dice_3: 4.628  loss_ce_4: 1.095  loss_mask_4: 0.5123  loss_dice_4: 4.626  loss_ce_5: 1.101  loss_mask_5: 0.512  loss_dice_5: 4.622  loss_ce_6: 1.147  loss_mask_6: 0.51  loss_dice_6: 4.622  loss_ce_7: 1.144  loss_mask_7: 0.512  loss_dice_7: 4.624  loss_ce_8: 1.132  loss_mask_8: 0.5122  loss_dice_8: 4.621  time: 2.1376  data_time: 0.4002  lr: 9.7298e-05  max_mem: 24284M
[01/19 15:52:39] d2.utils.events INFO:  eta: 22:50:22  iter: 1219  total_loss: 62.99  loss_ce: 1.194  loss_mask: 0.4944  loss_dice: 4.609  loss_ce_0: 1.126  loss_mask_0: 0.4907  loss_dice_0: 4.638  loss_ce_1: 1.15  loss_mask_1: 0.4965  loss_dice_1: 4.631  loss_ce_2: 1.165  loss_mask_2: 0.4944  loss_dice_2: 4.625  loss_ce_3: 1.169  loss_mask_3: 0.494  loss_dice_3: 4.618  loss_ce_4: 1.187  loss_mask_4: 0.4934  loss_dice_4: 4.609  loss_ce_5: 1.185  loss_mask_5: 0.4948  loss_dice_5: 4.612  loss_ce_6: 1.191  loss_mask_6: 0.494  loss_dice_6: 4.609  loss_ce_7: 1.209  loss_mask_7: 0.4941  loss_dice_7: 4.609  loss_ce_8: 1.19  loss_mask_8: 0.495  loss_dice_8: 4.605  time: 2.1378  data_time: 0.4170  lr: 9.7253e-05  max_mem: 24284M
[01/19 15:53:21] d2.utils.events INFO:  eta: 22:49:26  iter: 1239  total_loss: 63.35  loss_ce: 1.2  loss_mask: 0.5204  loss_dice: 4.595  loss_ce_0: 1.119  loss_mask_0: 0.5186  loss_dice_0: 4.633  loss_ce_1: 1.153  loss_mask_1: 0.5214  loss_dice_1: 4.614  loss_ce_2: 1.178  loss_mask_2: 0.5181  loss_dice_2: 4.604  loss_ce_3: 1.204  loss_mask_3: 0.5218  loss_dice_3: 4.598  loss_ce_4: 1.234  loss_mask_4: 0.5214  loss_dice_4: 4.593  loss_ce_5: 1.233  loss_mask_5: 0.5232  loss_dice_5: 4.598  loss_ce_6: 1.239  loss_mask_6: 0.5219  loss_dice_6: 4.595  loss_ce_7: 1.253  loss_mask_7: 0.5232  loss_dice_7: 4.591  loss_ce_8: 1.224  loss_mask_8: 0.5228  loss_dice_8: 4.589  time: 2.1373  data_time: 0.4052  lr: 9.7208e-05  max_mem: 24284M
[01/19 15:54:03] d2.utils.events INFO:  eta: 22:48:16  iter: 1259  total_loss: 64.4  loss_ce: 1.387  loss_mask: 0.5158  loss_dice: 4.601  loss_ce_0: 1.107  loss_mask_0: 0.5204  loss_dice_0: 4.636  loss_ce_1: 1.184  loss_mask_1: 0.52  loss_dice_1: 4.623  loss_ce_2: 1.283  loss_mask_2: 0.5162  loss_dice_2: 4.617  loss_ce_3: 1.302  loss_mask_3: 0.5173  loss_dice_3: 4.601  loss_ce_4: 1.373  loss_mask_4: 0.5162  loss_dice_4: 4.6  loss_ce_5: 1.36  loss_mask_5: 0.5184  loss_dice_5: 4.601  loss_ce_6: 1.388  loss_mask_6: 0.5184  loss_dice_6: 4.602  loss_ce_7: 1.454  loss_mask_7: 0.5162  loss_dice_7: 4.602  loss_ce_8: 1.46  loss_mask_8: 0.517  loss_dice_8: 4.592  time: 2.1367  data_time: 0.3981  lr: 9.7163e-05  max_mem: 24284M
[01/19 15:54:45] d2.utils.events INFO:  eta: 22:47:08  iter: 1279  total_loss: 63.47  loss_ce: 1.242  loss_mask: 0.5179  loss_dice: 4.597  loss_ce_0: 1.115  loss_mask_0: 0.5129  loss_dice_0: 4.636  loss_ce_1: 1.157  loss_mask_1: 0.5167  loss_dice_1: 4.617  loss_ce_2: 1.222  loss_mask_2: 0.519  loss_dice_2: 4.605  loss_ce_3: 1.241  loss_mask_3: 0.5185  loss_dice_3: 4.602  loss_ce_4: 1.253  loss_mask_4: 0.5197  loss_dice_4: 4.6  loss_ce_5: 1.223  loss_mask_5: 0.5198  loss_dice_5: 4.593  loss_ce_6: 1.23  loss_mask_6: 0.5166  loss_dice_6: 4.598  loss_ce_7: 1.25  loss_mask_7: 0.5162  loss_dice_7: 4.598  loss_ce_8: 1.242  loss_mask_8: 0.5169  loss_dice_8: 4.597  time: 2.1361  data_time: 0.3897  lr: 9.7118e-05  max_mem: 24284M
[01/19 15:55:27] d2.utils.events INFO:  eta: 22:46:19  iter: 1299  total_loss: 63.83  loss_ce: 1.327  loss_mask: 0.509  loss_dice: 4.589  loss_ce_0: 1.132  loss_mask_0: 0.5064  loss_dice_0: 4.64  loss_ce_1: 1.278  loss_mask_1: 0.51  loss_dice_1: 4.617  loss_ce_2: 1.294  loss_mask_2: 0.5101  loss_dice_2: 4.601  loss_ce_3: 1.303  loss_mask_3: 0.5094  loss_dice_3: 4.596  loss_ce_4: 1.319  loss_mask_4: 0.5073  loss_dice_4: 4.598  loss_ce_5: 1.301  loss_mask_5: 0.5076  loss_dice_5: 4.588  loss_ce_6: 1.309  loss_mask_6: 0.5089  loss_dice_6: 4.593  loss_ce_7: 1.34  loss_mask_7: 0.5104  loss_dice_7: 4.582  loss_ce_8: 1.359  loss_mask_8: 0.5102  loss_dice_8: 4.584  time: 2.1356  data_time: 0.3996  lr: 9.7072e-05  max_mem: 24284M
[01/19 15:56:09] d2.utils.events INFO:  eta: 22:45:31  iter: 1319  total_loss: 64.42  loss_ce: 1.378  loss_mask: 0.521  loss_dice: 4.586  loss_ce_0: 1.134  loss_mask_0: 0.5154  loss_dice_0: 4.637  loss_ce_1: 1.283  loss_mask_1: 0.5175  loss_dice_1: 4.607  loss_ce_2: 1.321  loss_mask_2: 0.5172  loss_dice_2: 4.596  loss_ce_3: 1.332  loss_mask_3: 0.5179  loss_dice_3: 4.591  loss_ce_4: 1.343  loss_mask_4: 0.5193  loss_dice_4: 4.594  loss_ce_5: 1.329  loss_mask_5: 0.5209  loss_dice_5: 4.592  loss_ce_6: 1.332  loss_mask_6: 0.5212  loss_dice_6: 4.591  loss_ce_7: 1.408  loss_mask_7: 0.5212  loss_dice_7: 4.584  loss_ce_8: 1.399  loss_mask_8: 0.5216  loss_dice_8: 4.581  time: 2.1352  data_time: 0.4037  lr: 9.7027e-05  max_mem: 24284M
[01/19 15:56:52] d2.utils.events INFO:  eta: 22:45:00  iter: 1339  total_loss: 64.66  loss_ce: 1.373  loss_mask: 0.5044  loss_dice: 4.586  loss_ce_0: 1.126  loss_mask_0: 0.5038  loss_dice_0: 4.65  loss_ce_1: 1.322  loss_mask_1: 0.5048  loss_dice_1: 4.601  loss_ce_2: 1.365  loss_mask_2: 0.508  loss_dice_2: 4.586  loss_ce_3: 1.392  loss_mask_3: 0.5091  loss_dice_3: 4.586  loss_ce_4: 1.405  loss_mask_4: 0.5062  loss_dice_4: 4.591  loss_ce_5: 1.399  loss_mask_5: 0.5051  loss_dice_5: 4.584  loss_ce_6: 1.401  loss_mask_6: 0.5046  loss_dice_6: 4.58  loss_ce_7: 1.394  loss_mask_7: 0.5045  loss_dice_7: 4.575  loss_ce_8: 1.398  loss_mask_8: 0.503  loss_dice_8: 4.573  time: 2.1352  data_time: 0.4151  lr: 9.6982e-05  max_mem: 24284M
[01/19 15:57:35] d2.utils.events INFO:  eta: 22:44:17  iter: 1359  total_loss: 64.71  loss_ce: 1.408  loss_mask: 0.5066  loss_dice: 4.579  loss_ce_0: 1.135  loss_mask_0: 0.5039  loss_dice_0: 4.647  loss_ce_1: 1.319  loss_mask_1: 0.5082  loss_dice_1: 4.597  loss_ce_2: 1.344  loss_mask_2: 0.5054  loss_dice_2: 4.589  loss_ce_3: 1.341  loss_mask_3: 0.5093  loss_dice_3: 4.587  loss_ce_4: 1.4  loss_mask_4: 0.5086  loss_dice_4: 4.58  loss_ce_5: 1.409  loss_mask_5: 0.5063  loss_dice_5: 4.578  loss_ce_6: 1.409  loss_mask_6: 0.5066  loss_dice_6: 4.58  loss_ce_7: 1.424  loss_mask_7: 0.5075  loss_dice_7: 4.575  loss_ce_8: 1.422  loss_mask_8: 0.5079  loss_dice_8: 4.579  time: 2.1350  data_time: 0.4022  lr: 9.6937e-05  max_mem: 24284M
[01/19 15:58:17] d2.utils.events INFO:  eta: 22:43:40  iter: 1379  total_loss: 65.04  loss_ce: 1.449  loss_mask: 0.5207  loss_dice: 4.545  loss_ce_0: 1.168  loss_mask_0: 0.5207  loss_dice_0: 4.622  loss_ce_1: 1.374  loss_mask_1: 0.5255  loss_dice_1: 4.567  loss_ce_2: 1.419  loss_mask_2: 0.523  loss_dice_2: 4.55  loss_ce_3: 1.404  loss_mask_3: 0.5222  loss_dice_3: 4.552  loss_ce_4: 1.421  loss_mask_4: 0.5197  loss_dice_4: 4.545  loss_ce_5: 1.458  loss_mask_5: 0.5209  loss_dice_5: 4.543  loss_ce_6: 1.471  loss_mask_6: 0.5229  loss_dice_6: 4.542  loss_ce_7: 1.461  loss_mask_7: 0.522  loss_dice_7: 4.538  loss_ce_8: 1.471  loss_mask_8: 0.521  loss_dice_8: 4.537  time: 2.1350  data_time: 0.4125  lr: 9.6892e-05  max_mem: 24284M
[01/19 15:59:00] d2.utils.events INFO:  eta: 22:43:05  iter: 1399  total_loss: 65.31  loss_ce: 1.5  loss_mask: 0.5057  loss_dice: 4.543  loss_ce_0: 1.139  loss_mask_0: 0.5075  loss_dice_0: 4.634  loss_ce_1: 1.4  loss_mask_1: 0.5078  loss_dice_1: 4.566  loss_ce_2: 1.506  loss_mask_2: 0.5055  loss_dice_2: 4.561  loss_ce_3: 1.487  loss_mask_3: 0.5083  loss_dice_3: 4.552  loss_ce_4: 1.478  loss_mask_4: 0.5068  loss_dice_4: 4.557  loss_ce_5: 1.495  loss_mask_5: 0.5074  loss_dice_5: 4.552  loss_ce_6: 1.483  loss_mask_6: 0.5064  loss_dice_6: 4.553  loss_ce_7: 1.485  loss_mask_7: 0.5065  loss_dice_7: 4.548  loss_ce_8: 1.516  loss_mask_8: 0.506  loss_dice_8: 4.548  time: 2.1351  data_time: 0.4016  lr: 9.6847e-05  max_mem: 24284M
[01/19 15:59:43] d2.utils.events INFO:  eta: 22:42:11  iter: 1419  total_loss: 64.56  loss_ce: 1.404  loss_mask: 0.5061  loss_dice: 4.553  loss_ce_0: 1.086  loss_mask_0: 0.504  loss_dice_0: 4.641  loss_ce_1: 1.375  loss_mask_1: 0.506  loss_dice_1: 4.579  loss_ce_2: 1.43  loss_mask_2: 0.5068  loss_dice_2: 4.559  loss_ce_3: 1.408  loss_mask_3: 0.5076  loss_dice_3: 4.558  loss_ce_4: 1.397  loss_mask_4: 0.5067  loss_dice_4: 4.561  loss_ce_5: 1.403  loss_mask_5: 0.5065  loss_dice_5: 4.555  loss_ce_6: 1.407  loss_mask_6: 0.5067  loss_dice_6: 4.563  loss_ce_7: 1.413  loss_mask_7: 0.5068  loss_dice_7: 4.563  loss_ce_8: 1.435  loss_mask_8: 0.5055  loss_dice_8: 4.555  time: 2.1352  data_time: 0.4153  lr: 9.6802e-05  max_mem: 24284M
[01/19 16:00:26] d2.utils.events INFO:  eta: 22:41:28  iter: 1439  total_loss: 65.14  loss_ce: 1.513  loss_mask: 0.5005  loss_dice: 4.528  loss_ce_0: 1.141  loss_mask_0: 0.4981  loss_dice_0: 4.631  loss_ce_1: 1.483  loss_mask_1: 0.4989  loss_dice_1: 4.558  loss_ce_2: 1.511  loss_mask_2: 0.5025  loss_dice_2: 4.538  loss_ce_3: 1.487  loss_mask_3: 0.5028  loss_dice_3: 4.529  loss_ce_4: 1.468  loss_mask_4: 0.4996  loss_dice_4: 4.536  loss_ce_5: 1.524  loss_mask_5: 0.4986  loss_dice_5: 4.532  loss_ce_6: 1.492  loss_mask_6: 0.5021  loss_dice_6: 4.538  loss_ce_7: 1.517  loss_mask_7: 0.5023  loss_dice_7: 4.533  loss_ce_8: 1.524  loss_mask_8: 0.503  loss_dice_8: 4.53  time: 2.1350  data_time: 0.4055  lr: 9.6756e-05  max_mem: 24284M
[01/19 16:01:09] d2.utils.events INFO:  eta: 22:40:40  iter: 1459  total_loss: 65.36  loss_ce: 1.543  loss_mask: 0.5134  loss_dice: 4.521  loss_ce_0: 1.154  loss_mask_0: 0.5144  loss_dice_0: 4.629  loss_ce_1: 1.44  loss_mask_1: 0.5174  loss_dice_1: 4.542  loss_ce_2: 1.512  loss_mask_2: 0.5143  loss_dice_2: 4.527  loss_ce_3: 1.483  loss_mask_3: 0.5124  loss_dice_3: 4.53  loss_ce_4: 1.485  loss_mask_4: 0.5131  loss_dice_4: 4.534  loss_ce_5: 1.513  loss_mask_5: 0.5173  loss_dice_5: 4.522  loss_ce_6: 1.5  loss_mask_6: 0.5141  loss_dice_6: 4.527  loss_ce_7: 1.537  loss_mask_7: 0.5128  loss_dice_7: 4.52  loss_ce_8: 1.563  loss_mask_8: 0.5121  loss_dice_8: 4.513  time: 2.1352  data_time: 0.4167  lr: 9.6711e-05  max_mem: 24284M
[01/19 16:01:51] d2.utils.events INFO:  eta: 22:39:26  iter: 1479  total_loss: 66.24  loss_ce: 1.656  loss_mask: 0.521  loss_dice: 4.515  loss_ce_0: 1.184  loss_mask_0: 0.5211  loss_dice_0: 4.616  loss_ce_1: 1.519  loss_mask_1: 0.5222  loss_dice_1: 4.536  loss_ce_2: 1.602  loss_mask_2: 0.5242  loss_dice_2: 4.52  loss_ce_3: 1.602  loss_mask_3: 0.5218  loss_dice_3: 4.512  loss_ce_4: 1.621  loss_mask_4: 0.5227  loss_dice_4: 4.509  loss_ce_5: 1.605  loss_mask_5: 0.523  loss_dice_5: 4.514  loss_ce_6: 1.632  loss_mask_6: 0.5188  loss_dice_6: 4.52  loss_ce_7: 1.648  loss_mask_7: 0.5224  loss_dice_7: 4.512  loss_ce_8: 1.65  loss_mask_8: 0.5201  loss_dice_8: 4.513  time: 2.1347  data_time: 0.3850  lr: 9.6666e-05  max_mem: 24284M
[01/19 16:02:33] d2.utils.events INFO:  eta: 22:39:09  iter: 1499  total_loss: 65.95  loss_ce: 1.617  loss_mask: 0.5073  loss_dice: 4.507  loss_ce_0: 1.168  loss_mask_0: 0.5086  loss_dice_0: 4.611  loss_ce_1: 1.544  loss_mask_1: 0.5139  loss_dice_1: 4.519  loss_ce_2: 1.57  loss_mask_2: 0.511  loss_dice_2: 4.509  loss_ce_3: 1.585  loss_mask_3: 0.514  loss_dice_3: 4.504  loss_ce_4: 1.604  loss_mask_4: 0.512  loss_dice_4: 4.505  loss_ce_5: 1.621  loss_mask_5: 0.5111  loss_dice_5: 4.506  loss_ce_6: 1.624  loss_mask_6: 0.5077  loss_dice_6: 4.509  loss_ce_7: 1.604  loss_mask_7: 0.5106  loss_dice_7: 4.509  loss_ce_8: 1.625  loss_mask_8: 0.5093  loss_dice_8: 4.506  time: 2.1348  data_time: 0.4075  lr: 9.6621e-05  max_mem: 24284M
[01/19 16:03:16] d2.utils.events INFO:  eta: 22:38:48  iter: 1519  total_loss: 65.8  loss_ce: 1.592  loss_mask: 0.501  loss_dice: 4.511  loss_ce_0: 1.138  loss_mask_0: 0.5051  loss_dice_0: 4.625  loss_ce_1: 1.497  loss_mask_1: 0.5054  loss_dice_1: 4.531  loss_ce_2: 1.541  loss_mask_2: 0.5082  loss_dice_2: 4.515  loss_ce_3: 1.524  loss_mask_3: 0.505  loss_dice_3: 4.512  loss_ce_4: 1.573  loss_mask_4: 0.5043  loss_dice_4: 4.507  loss_ce_5: 1.595  loss_mask_5: 0.505  loss_dice_5: 4.503  loss_ce_6: 1.616  loss_mask_6: 0.5045  loss_dice_6: 4.505  loss_ce_7: 1.625  loss_mask_7: 0.5024  loss_dice_7: 4.501  loss_ce_8: 1.63  loss_mask_8: 0.5028  loss_dice_8: 4.503  time: 2.1349  data_time: 0.4193  lr: 9.6576e-05  max_mem: 24284M
[01/19 16:03:59] d2.utils.events INFO:  eta: 22:37:57  iter: 1539  total_loss: 66.61  loss_ce: 1.726  loss_mask: 0.5264  loss_dice: 4.482  loss_ce_0: 1.187  loss_mask_0: 0.5222  loss_dice_0: 4.609  loss_ce_1: 1.591  loss_mask_1: 0.524  loss_dice_1: 4.498  loss_ce_2: 1.662  loss_mask_2: 0.5247  loss_dice_2: 4.494  loss_ce_3: 1.652  loss_mask_3: 0.5256  loss_dice_3: 4.486  loss_ce_4: 1.666  loss_mask_4: 0.5243  loss_dice_4: 4.484  loss_ce_5: 1.686  loss_mask_5: 0.5239  loss_dice_5: 4.482  loss_ce_6: 1.682  loss_mask_6: 0.526  loss_dice_6: 4.486  loss_ce_7: 1.717  loss_mask_7: 0.5292  loss_dice_7: 4.48  loss_ce_8: 1.702  loss_mask_8: 0.5269  loss_dice_8: 4.481  time: 2.1348  data_time: 0.4119  lr: 9.653e-05  max_mem: 24284M
[01/19 16:04:41] d2.utils.events INFO:  eta: 22:37:03  iter: 1559  total_loss: 66.73  loss_ce: 1.697  loss_mask: 0.5153  loss_dice: 4.477  loss_ce_0: 1.201  loss_mask_0: 0.5148  loss_dice_0: 4.599  loss_ce_1: 1.618  loss_mask_1: 0.5118  loss_dice_1: 4.492  loss_ce_2: 1.672  loss_mask_2: 0.5109  loss_dice_2: 4.47  loss_ce_3: 1.664  loss_mask_3: 0.5146  loss_dice_3: 4.468  loss_ce_4: 1.697  loss_mask_4: 0.5138  loss_dice_4: 4.473  loss_ce_5: 1.704  loss_mask_5: 0.514  loss_dice_5: 4.471  loss_ce_6: 1.694  loss_mask_6: 0.513  loss_dice_6: 4.48  loss_ce_7: 1.695  loss_mask_7: 0.5109  loss_dice_7: 4.478  loss_ce_8: 1.687  loss_mask_8: 0.5127  loss_dice_8: 4.475  time: 2.1344  data_time: 0.4007  lr: 9.6485e-05  max_mem: 24284M
[01/19 16:05:24] d2.utils.events INFO:  eta: 22:36:02  iter: 1579  total_loss: 67.51  loss_ce: 1.872  loss_mask: 0.528  loss_dice: 4.453  loss_ce_0: 1.183  loss_mask_0: 0.5247  loss_dice_0: 4.605  loss_ce_1: 1.654  loss_mask_1: 0.5267  loss_dice_1: 4.476  loss_ce_2: 1.671  loss_mask_2: 0.5233  loss_dice_2: 4.468  loss_ce_3: 1.7  loss_mask_3: 0.5245  loss_dice_3: 4.468  loss_ce_4: 1.792  loss_mask_4: 0.5224  loss_dice_4: 4.457  loss_ce_5: 1.798  loss_mask_5: 0.5232  loss_dice_5: 4.455  loss_ce_6: 1.854  loss_mask_6: 0.5247  loss_dice_6: 4.45  loss_ce_7: 1.927  loss_mask_7: 0.5263  loss_dice_7: 4.451  loss_ce_8: 1.894  loss_mask_8: 0.5282  loss_dice_8: 4.45  time: 2.1343  data_time: 0.4049  lr: 9.644e-05  max_mem: 24284M
[01/19 16:06:07] d2.utils.events INFO:  eta: 22:35:39  iter: 1599  total_loss: 67.34  loss_ce: 1.867  loss_mask: 0.5047  loss_dice: 4.471  loss_ce_0: 1.191  loss_mask_0: 0.5022  loss_dice_0: 4.615  loss_ce_1: 1.671  loss_mask_1: 0.5048  loss_dice_1: 4.49  loss_ce_2: 1.729  loss_mask_2: 0.5026  loss_dice_2: 4.481  loss_ce_3: 1.705  loss_mask_3: 0.505  loss_dice_3: 4.483  loss_ce_4: 1.761  loss_mask_4: 0.5042  loss_dice_4: 4.477  loss_ce_5: 1.81  loss_mask_5: 0.5065  loss_dice_5: 4.484  loss_ce_6: 1.827  loss_mask_6: 0.5069  loss_dice_6: 4.478  loss_ce_7: 1.873  loss_mask_7: 0.5049  loss_dice_7: 4.471  loss_ce_8: 1.891  loss_mask_8: 0.5042  loss_dice_8: 4.467  time: 2.1345  data_time: 0.4083  lr: 9.6395e-05  max_mem: 24284M
[01/19 16:06:49] d2.utils.events INFO:  eta: 22:34:28  iter: 1619  total_loss: 67.28  loss_ce: 1.83  loss_mask: 0.5246  loss_dice: 4.462  loss_ce_0: 1.205  loss_mask_0: 0.5235  loss_dice_0: 4.61  loss_ce_1: 1.693  loss_mask_1: 0.5244  loss_dice_1: 4.486  loss_ce_2: 1.757  loss_mask_2: 0.525  loss_dice_2: 4.475  loss_ce_3: 1.78  loss_mask_3: 0.5215  loss_dice_3: 4.455  loss_ce_4: 1.792  loss_mask_4: 0.5269  loss_dice_4: 4.462  loss_ce_5: 1.795  loss_mask_5: 0.5247  loss_dice_5: 4.46  loss_ce_6: 1.782  loss_mask_6: 0.5225  loss_dice_6: 4.459  loss_ce_7: 1.813  loss_mask_7: 0.5247  loss_dice_7: 4.455  loss_ce_8: 1.817  loss_mask_8: 0.5247  loss_dice_8: 4.458  time: 2.1341  data_time: 0.4013  lr: 9.635e-05  max_mem: 24284M
[01/19 16:07:31] d2.utils.events INFO:  eta: 22:34:13  iter: 1639  total_loss: 67.46  loss_ce: 1.914  loss_mask: 0.5148  loss_dice: 4.448  loss_ce_0: 1.223  loss_mask_0: 0.5184  loss_dice_0: 4.6  loss_ce_1: 1.755  loss_mask_1: 0.52  loss_dice_1: 4.48  loss_ce_2: 1.782  loss_mask_2: 0.5174  loss_dice_2: 4.457  loss_ce_3: 1.792  loss_mask_3: 0.5188  loss_dice_3: 4.456  loss_ce_4: 1.836  loss_mask_4: 0.5184  loss_dice_4: 4.451  loss_ce_5: 1.871  loss_mask_5: 0.519  loss_dice_5: 4.453  loss_ce_6: 1.894  loss_mask_6: 0.5199  loss_dice_6: 4.447  loss_ce_7: 1.909  loss_mask_7: 0.5186  loss_dice_7: 4.449  loss_ce_8: 1.91  loss_mask_8: 0.5165  loss_dice_8: 4.449  time: 2.1340  data_time: 0.3925  lr: 9.6305e-05  max_mem: 24284M
[01/19 16:08:14] d2.utils.events INFO:  eta: 22:33:42  iter: 1659  total_loss: 68.01  loss_ce: 1.956  loss_mask: 0.5188  loss_dice: 4.437  loss_ce_0: 1.191  loss_mask_0: 0.5124  loss_dice_0: 4.604  loss_ce_1: 1.743  loss_mask_1: 0.5171  loss_dice_1: 4.466  loss_ce_2: 1.815  loss_mask_2: 0.5162  loss_dice_2: 4.452  loss_ce_3: 1.846  loss_mask_3: 0.5148  loss_dice_3: 4.446  loss_ce_4: 1.896  loss_mask_4: 0.5172  loss_dice_4: 4.445  loss_ce_5: 1.919  loss_mask_5: 0.518  loss_dice_5: 4.446  loss_ce_6: 1.92  loss_mask_6: 0.5159  loss_dice_6: 4.434  loss_ce_7: 1.986  loss_mask_7: 0.5162  loss_dice_7: 4.437  loss_ce_8: 1.967  loss_mask_8: 0.5168  loss_dice_8: 4.439  time: 2.1339  data_time: 0.4120  lr: 9.6259e-05  max_mem: 24284M
[01/19 16:08:57] d2.utils.events INFO:  eta: 22:33:01  iter: 1679  total_loss: 67.33  loss_ce: 1.861  loss_mask: 0.5077  loss_dice: 4.444  loss_ce_0: 1.181  loss_mask_0: 0.5076  loss_dice_0: 4.6  loss_ce_1: 1.719  loss_mask_1: 0.5094  loss_dice_1: 4.465  loss_ce_2: 1.779  loss_mask_2: 0.5091  loss_dice_2: 4.464  loss_ce_3: 1.79  loss_mask_3: 0.5112  loss_dice_3: 4.453  loss_ce_4: 1.804  loss_mask_4: 0.5125  loss_dice_4: 4.451  loss_ce_5: 1.813  loss_mask_5: 0.5107  loss_dice_5: 4.449  loss_ce_6: 1.849  loss_mask_6: 0.5104  loss_dice_6: 4.453  loss_ce_7: 1.873  loss_mask_7: 0.5123  loss_dice_7: 4.444  loss_ce_8: 1.864  loss_mask_8: 0.5096  loss_dice_8: 4.447  time: 2.1341  data_time: 0.4226  lr: 9.6214e-05  max_mem: 24284M
[01/19 16:09:39] d2.utils.events INFO:  eta: 22:31:55  iter: 1699  total_loss: 68.59  loss_ce: 2.011  loss_mask: 0.5286  loss_dice: 4.424  loss_ce_0: 1.194  loss_mask_0: 0.5232  loss_dice_0: 4.6  loss_ce_1: 1.831  loss_mask_1: 0.53  loss_dice_1: 4.449  loss_ce_2: 1.905  loss_mask_2: 0.5277  loss_dice_2: 4.435  loss_ce_3: 1.918  loss_mask_3: 0.5286  loss_dice_3: 4.431  loss_ce_4: 1.974  loss_mask_4: 0.5259  loss_dice_4: 4.424  loss_ce_5: 2.004  loss_mask_5: 0.5276  loss_dice_5: 4.426  loss_ce_6: 1.995  loss_mask_6: 0.5268  loss_dice_6: 4.436  loss_ce_7: 2.013  loss_mask_7: 0.5294  loss_dice_7: 4.424  loss_ce_8: 2.01  loss_mask_8: 0.5285  loss_dice_8: 4.424  time: 2.1337  data_time: 0.3906  lr: 9.6169e-05  max_mem: 24284M
[01/19 16:10:21] d2.utils.events INFO:  eta: 22:31:13  iter: 1719  total_loss: 68.02  loss_ce: 1.903  loss_mask: 0.5188  loss_dice: 4.437  loss_ce_0: 1.224  loss_mask_0: 0.5165  loss_dice_0: 4.599  loss_ce_1: 1.799  loss_mask_1: 0.5199  loss_dice_1: 4.474  loss_ce_2: 1.898  loss_mask_2: 0.5189  loss_dice_2: 4.446  loss_ce_3: 1.905  loss_mask_3: 0.5175  loss_dice_3: 4.449  loss_ce_4: 1.885  loss_mask_4: 0.5178  loss_dice_4: 4.449  loss_ce_5: 1.922  loss_mask_5: 0.5213  loss_dice_5: 4.439  loss_ce_6: 1.925  loss_mask_6: 0.5154  loss_dice_6: 4.451  loss_ce_7: 1.895  loss_mask_7: 0.517  loss_dice_7: 4.445  loss_ce_8: 1.921  loss_mask_8: 0.5177  loss_dice_8: 4.437  time: 2.1335  data_time: 0.3966  lr: 9.6124e-05  max_mem: 24420M
[01/19 16:11:04] d2.utils.events INFO:  eta: 22:30:54  iter: 1739  total_loss: 68.37  loss_ce: 1.997  loss_mask: 0.5226  loss_dice: 4.435  loss_ce_0: 1.201  loss_mask_0: 0.5209  loss_dice_0: 4.609  loss_ce_1: 1.759  loss_mask_1: 0.5224  loss_dice_1: 4.485  loss_ce_2: 1.876  loss_mask_2: 0.5256  loss_dice_2: 4.455  loss_ce_3: 1.911  loss_mask_3: 0.5276  loss_dice_3: 4.445  loss_ce_4: 1.946  loss_mask_4: 0.5268  loss_dice_4: 4.442  loss_ce_5: 1.969  loss_mask_5: 0.5254  loss_dice_5: 4.445  loss_ce_6: 1.954  loss_mask_6: 0.5238  loss_dice_6: 4.445  loss_ce_7: 1.988  loss_mask_7: 0.5247  loss_dice_7: 4.436  loss_ce_8: 1.986  loss_mask_8: 0.5244  loss_dice_8: 4.433  time: 2.1334  data_time: 0.4140  lr: 9.6079e-05  max_mem: 24420M
[01/19 16:11:46] d2.utils.events INFO:  eta: 22:30:15  iter: 1759  total_loss: 69.06  loss_ce: 2.095  loss_mask: 0.5212  loss_dice: 4.423  loss_ce_0: 1.189  loss_mask_0: 0.5133  loss_dice_0: 4.598  loss_ce_1: 1.765  loss_mask_1: 0.5193  loss_dice_1: 4.459  loss_ce_2: 1.918  loss_mask_2: 0.5194  loss_dice_2: 4.434  loss_ce_3: 1.976  loss_mask_3: 0.5192  loss_dice_3: 4.437  loss_ce_4: 2.078  loss_mask_4: 0.5202  loss_dice_4: 4.42  loss_ce_5: 2.078  loss_mask_5: 0.5214  loss_dice_5: 4.437  loss_ce_6: 2.076  loss_mask_6: 0.5185  loss_dice_6: 4.431  loss_ce_7: 2.079  loss_mask_7: 0.5198  loss_dice_7: 4.423  loss_ce_8: 2.091  loss_mask_8: 0.5228  loss_dice_8: 4.423  time: 2.1332  data_time: 0.3992  lr: 9.6033e-05  max_mem: 24420M
[01/19 16:12:28] d2.utils.events INFO:  eta: 22:29:28  iter: 1779  total_loss: 69.1  loss_ce: 2.102  loss_mask: 0.5255  loss_dice: 4.383  loss_ce_0: 1.215  loss_mask_0: 0.5195  loss_dice_0: 4.586  loss_ce_1: 1.889  loss_mask_1: 0.5221  loss_dice_1: 4.431  loss_ce_2: 2.007  loss_mask_2: 0.5229  loss_dice_2: 4.415  loss_ce_3: 2.017  loss_mask_3: 0.5243  loss_dice_3: 4.403  loss_ce_4: 2.069  loss_mask_4: 0.523  loss_dice_4: 4.399  loss_ce_5: 2.098  loss_mask_5: 0.5257  loss_dice_5: 4.389  loss_ce_6: 2.081  loss_mask_6: 0.5245  loss_dice_6: 4.399  loss_ce_7: 2.108  loss_mask_7: 0.5258  loss_dice_7: 4.393  loss_ce_8: 2.083  loss_mask_8: 0.5275  loss_dice_8: 4.389  time: 2.1327  data_time: 0.3940  lr: 9.5988e-05  max_mem: 24420M
[01/19 16:13:11] d2.utils.events INFO:  eta: 22:28:47  iter: 1799  total_loss: 68.38  loss_ce: 1.998  loss_mask: 0.5161  loss_dice: 4.415  loss_ce_0: 1.203  loss_mask_0: 0.5081  loss_dice_0: 4.6  loss_ce_1: 1.82  loss_mask_1: 0.515  loss_dice_1: 4.447  loss_ce_2: 1.895  loss_mask_2: 0.5165  loss_dice_2: 4.424  loss_ce_3: 1.908  loss_mask_3: 0.519  loss_dice_3: 4.424  loss_ce_4: 1.987  loss_mask_4: 0.5182  loss_dice_4: 4.418  loss_ce_5: 2.032  loss_mask_5: 0.515  loss_dice_5: 4.413  loss_ce_6: 1.988  loss_mask_6: 0.5153  loss_dice_6: 4.424  loss_ce_7: 2.037  loss_mask_7: 0.5168  loss_dice_7: 4.422  loss_ce_8: 1.99  loss_mask_8: 0.5155  loss_dice_8: 4.411  time: 2.1327  data_time: 0.4129  lr: 9.5943e-05  max_mem: 24420M
[01/19 16:13:53] d2.utils.events INFO:  eta: 22:28:13  iter: 1819  total_loss: 67.97  loss_ce: 1.978  loss_mask: 0.5233  loss_dice: 4.413  loss_ce_0: 1.21  loss_mask_0: 0.5276  loss_dice_0: 4.601  loss_ce_1: 1.818  loss_mask_1: 0.5281  loss_dice_1: 4.441  loss_ce_2: 1.856  loss_mask_2: 0.5265  loss_dice_2: 4.418  loss_ce_3: 1.865  loss_mask_3: 0.5257  loss_dice_3: 4.423  loss_ce_4: 1.95  loss_mask_4: 0.5257  loss_dice_4: 4.423  loss_ce_5: 1.942  loss_mask_5: 0.5274  loss_dice_5: 4.418  loss_ce_6: 1.946  loss_mask_6: 0.5269  loss_dice_6: 4.421  loss_ce_7: 1.994  loss_mask_7: 0.5263  loss_dice_7: 4.417  loss_ce_8: 1.963  loss_mask_8: 0.5247  loss_dice_8: 4.419  time: 2.1326  data_time: 0.4007  lr: 9.5898e-05  max_mem: 24420M
[01/19 16:14:35] d2.utils.events INFO:  eta: 22:27:20  iter: 1839  total_loss: 68.57  loss_ce: 2.019  loss_mask: 0.5271  loss_dice: 4.388  loss_ce_0: 1.243  loss_mask_0: 0.5258  loss_dice_0: 4.585  loss_ce_1: 1.829  loss_mask_1: 0.5253  loss_dice_1: 4.434  loss_ce_2: 1.918  loss_mask_2: 0.5245  loss_dice_2: 4.408  loss_ce_3: 1.916  loss_mask_3: 0.5273  loss_dice_3: 4.407  loss_ce_4: 1.993  loss_mask_4: 0.5276  loss_dice_4: 4.394  loss_ce_5: 2.034  loss_mask_5: 0.5261  loss_dice_5: 4.394  loss_ce_6: 2  loss_mask_6: 0.5267  loss_dice_6: 4.403  loss_ce_7: 1.991  loss_mask_7: 0.5258  loss_dice_7: 4.401  loss_ce_8: 2.055  loss_mask_8: 0.5253  loss_dice_8: 4.393  time: 2.1322  data_time: 0.4047  lr: 9.5853e-05  max_mem: 24420M
[01/19 16:15:18] d2.utils.events INFO:  eta: 22:26:38  iter: 1859  total_loss: 68.75  loss_ce: 2.056  loss_mask: 0.5214  loss_dice: 4.4  loss_ce_0: 1.23  loss_mask_0: 0.5177  loss_dice_0: 4.59  loss_ce_1: 1.863  loss_mask_1: 0.5206  loss_dice_1: 4.422  loss_ce_2: 1.944  loss_mask_2: 0.5195  loss_dice_2: 4.407  loss_ce_3: 1.964  loss_mask_3: 0.5197  loss_dice_3: 4.398  loss_ce_4: 2.049  loss_mask_4: 0.5194  loss_dice_4: 4.391  loss_ce_5: 2.059  loss_mask_5: 0.5203  loss_dice_5: 4.394  loss_ce_6: 2.023  loss_mask_6: 0.5189  loss_dice_6: 4.403  loss_ce_7: 2.048  loss_mask_7: 0.5197  loss_dice_7: 4.397  loss_ce_8: 2.041  loss_mask_8: 0.5213  loss_dice_8: 4.4  time: 2.1321  data_time: 0.4191  lr: 9.5807e-05  max_mem: 24420M
[01/19 16:16:00] d2.utils.events INFO:  eta: 22:25:59  iter: 1879  total_loss: 68.39  loss_ce: 1.975  loss_mask: 0.5239  loss_dice: 4.404  loss_ce_0: 1.176  loss_mask_0: 0.5198  loss_dice_0: 4.59  loss_ce_1: 1.812  loss_mask_1: 0.5204  loss_dice_1: 4.432  loss_ce_2: 1.906  loss_mask_2: 0.5252  loss_dice_2: 4.407  loss_ce_3: 1.932  loss_mask_3: 0.5229  loss_dice_3: 4.407  loss_ce_4: 1.973  loss_mask_4: 0.5262  loss_dice_4: 4.397  loss_ce_5: 2.01  loss_mask_5: 0.5231  loss_dice_5: 4.4  loss_ce_6: 1.975  loss_mask_6: 0.5255  loss_dice_6: 4.412  loss_ce_7: 2.007  loss_mask_7: 0.524  loss_dice_7: 4.401  loss_ce_8: 1.993  loss_mask_8: 0.5244  loss_dice_8: 4.407  time: 2.1320  data_time: 0.4049  lr: 9.5762e-05  max_mem: 24420M
[01/19 16:16:42] d2.utils.events INFO:  eta: 22:25:12  iter: 1899  total_loss: 69.04  loss_ce: 2.151  loss_mask: 0.5398  loss_dice: 4.375  loss_ce_0: 1.202  loss_mask_0: 0.5403  loss_dice_0: 4.588  loss_ce_1: 1.94  loss_mask_1: 0.5364  loss_dice_1: 4.41  loss_ce_2: 1.989  loss_mask_2: 0.5369  loss_dice_2: 4.39  loss_ce_3: 2.08  loss_mask_3: 0.5381  loss_dice_3: 4.376  loss_ce_4: 2.108  loss_mask_4: 0.5416  loss_dice_4: 4.375  loss_ce_5: 2.13  loss_mask_5: 0.5404  loss_dice_5: 4.377  loss_ce_6: 2.121  loss_mask_6: 0.5381  loss_dice_6: 4.379  loss_ce_7: 2.092  loss_mask_7: 0.541  loss_dice_7: 4.386  loss_ce_8: 2.125  loss_mask_8: 0.5395  loss_dice_8: 4.381  time: 2.1316  data_time: 0.4114  lr: 9.5717e-05  max_mem: 24420M
[01/19 16:17:25] d2.utils.events INFO:  eta: 22:24:23  iter: 1919  total_loss: 68.99  loss_ce: 2.045  loss_mask: 0.5186  loss_dice: 4.388  loss_ce_0: 1.228  loss_mask_0: 0.5158  loss_dice_0: 4.592  loss_ce_1: 1.903  loss_mask_1: 0.5175  loss_dice_1: 4.42  loss_ce_2: 1.987  loss_mask_2: 0.5193  loss_dice_2: 4.397  loss_ce_3: 2.033  loss_mask_3: 0.5176  loss_dice_3: 4.392  loss_ce_4: 2.032  loss_mask_4: 0.5173  loss_dice_4: 4.399  loss_ce_5: 2.03  loss_mask_5: 0.5173  loss_dice_5: 4.392  loss_ce_6: 2.035  loss_mask_6: 0.5186  loss_dice_6: 4.391  loss_ce_7: 2.062  loss_mask_7: 0.5168  loss_dice_7: 4.389  loss_ce_8: 2.056  loss_mask_8: 0.5198  loss_dice_8: 4.394  time: 2.1315  data_time: 0.3840  lr: 9.5672e-05  max_mem: 24420M
[01/19 16:18:07] d2.utils.events INFO:  eta: 22:23:27  iter: 1939  total_loss: 68.92  loss_ce: 2.118  loss_mask: 0.5128  loss_dice: 4.399  loss_ce_0: 1.185  loss_mask_0: 0.5086  loss_dice_0: 4.611  loss_ce_1: 1.911  loss_mask_1: 0.5131  loss_dice_1: 4.441  loss_ce_2: 2.028  loss_mask_2: 0.5146  loss_dice_2: 4.417  loss_ce_3: 2.03  loss_mask_3: 0.5107  loss_dice_3: 4.415  loss_ce_4: 2.054  loss_mask_4: 0.5073  loss_dice_4: 4.418  loss_ce_5: 2.064  loss_mask_5: 0.5073  loss_dice_5: 4.414  loss_ce_6: 2.076  loss_mask_6: 0.512  loss_dice_6: 4.413  loss_ce_7: 2.116  loss_mask_7: 0.511  loss_dice_7: 4.41  loss_ce_8: 2.087  loss_mask_8: 0.515  loss_dice_8: 4.407  time: 2.1314  data_time: 0.4003  lr: 9.5626e-05  max_mem: 24420M
[01/19 16:18:50] d2.utils.events INFO:  eta: 22:22:26  iter: 1959  total_loss: 69.06  loss_ce: 2.148  loss_mask: 0.5067  loss_dice: 4.404  loss_ce_0: 1.175  loss_mask_0: 0.5047  loss_dice_0: 4.608  loss_ce_1: 1.873  loss_mask_1: 0.5011  loss_dice_1: 4.437  loss_ce_2: 1.963  loss_mask_2: 0.5011  loss_dice_2: 4.408  loss_ce_3: 2.039  loss_mask_3: 0.5029  loss_dice_3: 4.399  loss_ce_4: 2.08  loss_mask_4: 0.5043  loss_dice_4: 4.405  loss_ce_5: 2.099  loss_mask_5: 0.5045  loss_dice_5: 4.405  loss_ce_6: 2.093  loss_mask_6: 0.5078  loss_dice_6: 4.398  loss_ce_7: 2.132  loss_mask_7: 0.5032  loss_dice_7: 4.403  loss_ce_8: 2.131  loss_mask_8: 0.5059  loss_dice_8: 4.394  time: 2.1313  data_time: 0.4042  lr: 9.5581e-05  max_mem: 24420M
[01/19 16:19:32] d2.utils.events INFO:  eta: 22:21:26  iter: 1979  total_loss: 69.15  loss_ce: 2.14  loss_mask: 0.5127  loss_dice: 4.395  loss_ce_0: 1.24  loss_mask_0: 0.513  loss_dice_0: 4.604  loss_ce_1: 1.895  loss_mask_1: 0.5094  loss_dice_1: 4.438  loss_ce_2: 1.986  loss_mask_2: 0.5132  loss_dice_2: 4.412  loss_ce_3: 2.035  loss_mask_3: 0.5132  loss_dice_3: 4.406  loss_ce_4: 2.097  loss_mask_4: 0.514  loss_dice_4: 4.401  loss_ce_5: 2.129  loss_mask_5: 0.5157  loss_dice_5: 4.395  loss_ce_6: 2.129  loss_mask_6: 0.514  loss_dice_6: 4.406  loss_ce_7: 2.117  loss_mask_7: 0.5133  loss_dice_7: 4.399  loss_ce_8: 2.159  loss_mask_8: 0.5121  loss_dice_8: 4.397  time: 2.1314  data_time: 0.4096  lr: 9.5536e-05  max_mem: 24420M
[01/19 16:20:15] d2.utils.events INFO:  eta: 22:20:40  iter: 1999  total_loss: 68.97  loss_ce: 2.115  loss_mask: 0.5257  loss_dice: 4.383  loss_ce_0: 1.225  loss_mask_0: 0.5201  loss_dice_0: 4.59  loss_ce_1: 1.925  loss_mask_1: 0.523  loss_dice_1: 4.434  loss_ce_2: 1.969  loss_mask_2: 0.5253  loss_dice_2: 4.405  loss_ce_3: 2.011  loss_mask_3: 0.5241  loss_dice_3: 4.392  loss_ce_4: 2.068  loss_mask_4: 0.5268  loss_dice_4: 4.391  loss_ce_5: 2.085  loss_mask_5: 0.5247  loss_dice_5: 4.389  loss_ce_6: 2.102  loss_mask_6: 0.5258  loss_dice_6: 4.391  loss_ce_7: 2.071  loss_mask_7: 0.523  loss_dice_7: 4.398  loss_ce_8: 2.107  loss_mask_8: 0.5261  loss_dice_8: 4.385  time: 2.1313  data_time: 0.3988  lr: 9.5491e-05  max_mem: 24420M
[01/19 16:20:57] d2.utils.events INFO:  eta: 22:19:11  iter: 2019  total_loss: 68.74  loss_ce: 2.11  loss_mask: 0.5141  loss_dice: 4.4  loss_ce_0: 1.199  loss_mask_0: 0.5171  loss_dice_0: 4.597  loss_ce_1: 1.841  loss_mask_1: 0.5204  loss_dice_1: 4.443  loss_ce_2: 1.938  loss_mask_2: 0.5216  loss_dice_2: 4.425  loss_ce_3: 1.949  loss_mask_3: 0.5206  loss_dice_3: 4.422  loss_ce_4: 2.058  loss_mask_4: 0.5186  loss_dice_4: 4.411  loss_ce_5: 2.065  loss_mask_5: 0.5196  loss_dice_5: 4.41  loss_ce_6: 2.079  loss_mask_6: 0.5182  loss_dice_6: 4.411  loss_ce_7: 2.069  loss_mask_7: 0.5178  loss_dice_7: 4.409  loss_ce_8: 2.097  loss_mask_8: 0.5172  loss_dice_8: 4.397  time: 2.1310  data_time: 0.3962  lr: 9.5446e-05  max_mem: 24420M
[01/19 16:21:40] d2.utils.events INFO:  eta: 22:19:16  iter: 2039  total_loss: 68.88  loss_ce: 2.12  loss_mask: 0.5099  loss_dice: 4.39  loss_ce_0: 1.192  loss_mask_0: 0.5105  loss_dice_0: 4.603  loss_ce_1: 1.902  loss_mask_1: 0.5079  loss_dice_1: 4.435  loss_ce_2: 1.991  loss_mask_2: 0.5089  loss_dice_2: 4.416  loss_ce_3: 2.023  loss_mask_3: 0.5095  loss_dice_3: 4.411  loss_ce_4: 2.055  loss_mask_4: 0.5085  loss_dice_4: 4.401  loss_ce_5: 2.074  loss_mask_5: 0.5107  loss_dice_5: 4.403  loss_ce_6: 2.076  loss_mask_6: 0.5133  loss_dice_6: 4.396  loss_ce_7: 2.092  loss_mask_7: 0.5111  loss_dice_7: 4.398  loss_ce_8: 2.095  loss_mask_8: 0.5101  loss_dice_8: 4.397  time: 2.1313  data_time: 0.4279  lr: 9.54e-05  max_mem: 24420M
[01/19 16:22:23] d2.utils.events INFO:  eta: 22:18:47  iter: 2059  total_loss: 69.1  loss_ce: 2.069  loss_mask: 0.5234  loss_dice: 4.365  loss_ce_0: 1.235  loss_mask_0: 0.5218  loss_dice_0: 4.579  loss_ce_1: 1.929  loss_mask_1: 0.5249  loss_dice_1: 4.409  loss_ce_2: 2.048  loss_mask_2: 0.5258  loss_dice_2: 4.391  loss_ce_3: 2.07  loss_mask_3: 0.5248  loss_dice_3: 4.374  loss_ce_4: 2.072  loss_mask_4: 0.5249  loss_dice_4: 4.378  loss_ce_5: 2.124  loss_mask_5: 0.5252  loss_dice_5: 4.367  loss_ce_6: 2.091  loss_mask_6: 0.5257  loss_dice_6: 4.372  loss_ce_7: 2.07  loss_mask_7: 0.5254  loss_dice_7: 4.369  loss_ce_8: 2.057  loss_mask_8: 0.5248  loss_dice_8: 4.363  time: 2.1314  data_time: 0.4015  lr: 9.5355e-05  max_mem: 24420M
[01/19 16:23:06] d2.utils.events INFO:  eta: 22:18:40  iter: 2079  total_loss: 69.31  loss_ce: 2.162  loss_mask: 0.5152  loss_dice: 4.369  loss_ce_0: 1.243  loss_mask_0: 0.5182  loss_dice_0: 4.582  loss_ce_1: 1.913  loss_mask_1: 0.5179  loss_dice_1: 4.414  loss_ce_2: 2.002  loss_mask_2: 0.5234  loss_dice_2: 4.396  loss_ce_3: 2.091  loss_mask_3: 0.5203  loss_dice_3: 4.378  loss_ce_4: 2.137  loss_mask_4: 0.516  loss_dice_4: 4.377  loss_ce_5: 2.142  loss_mask_5: 0.5176  loss_dice_5: 4.377  loss_ce_6: 2.131  loss_mask_6: 0.5194  loss_dice_6: 4.379  loss_ce_7: 2.109  loss_mask_7: 0.5172  loss_dice_7: 4.379  loss_ce_8: 2.141  loss_mask_8: 0.5194  loss_dice_8: 4.376  time: 2.1313  data_time: 0.4007  lr: 9.531e-05  max_mem: 24420M
[01/19 16:23:48] d2.utils.events INFO:  eta: 22:17:22  iter: 2099  total_loss: 69.88  loss_ce: 2.244  loss_mask: 0.5332  loss_dice: 4.355  loss_ce_0: 1.236  loss_mask_0: 0.5319  loss_dice_0: 4.587  loss_ce_1: 1.994  loss_mask_1: 0.53  loss_dice_1: 4.4  loss_ce_2: 2.044  loss_mask_2: 0.5302  loss_dice_2: 4.372  loss_ce_3: 2.092  loss_mask_3: 0.5274  loss_dice_3: 4.371  loss_ce_4: 2.173  loss_mask_4: 0.5247  loss_dice_4: 4.383  loss_ce_5: 2.247  loss_mask_5: 0.5335  loss_dice_5: 4.365  loss_ce_6: 2.246  loss_mask_6: 0.5314  loss_dice_6: 4.361  loss_ce_7: 2.228  loss_mask_7: 0.5344  loss_dice_7: 4.366  loss_ce_8: 2.218  loss_mask_8: 0.5337  loss_dice_8: 4.361  time: 2.1310  data_time: 0.3906  lr: 9.5265e-05  max_mem: 24420M
[01/19 16:24:29] d2.utils.events INFO:  eta: 22:16:15  iter: 2119  total_loss: 69.35  loss_ce: 2.156  loss_mask: 0.521  loss_dice: 4.361  loss_ce_0: 1.234  loss_mask_0: 0.5267  loss_dice_0: 4.576  loss_ce_1: 1.97  loss_mask_1: 0.5247  loss_dice_1: 4.394  loss_ce_2: 2.046  loss_mask_2: 0.5215  loss_dice_2: 4.377  loss_ce_3: 2.091  loss_mask_3: 0.525  loss_dice_3: 4.368  loss_ce_4: 2.127  loss_mask_4: 0.5251  loss_dice_4: 4.376  loss_ce_5: 2.16  loss_mask_5: 0.5263  loss_dice_5: 4.372  loss_ce_6: 2.099  loss_mask_6: 0.5235  loss_dice_6: 4.371  loss_ce_7: 2.146  loss_mask_7: 0.5286  loss_dice_7: 4.37  loss_ce_8: 2.158  loss_mask_8: 0.523  loss_dice_8: 4.363  time: 2.1306  data_time: 0.3874  lr: 9.5219e-05  max_mem: 24420M
[01/19 16:25:11] d2.utils.events INFO:  eta: 22:15:15  iter: 2139  total_loss: 69.04  loss_ce: 2.136  loss_mask: 0.535  loss_dice: 4.342  loss_ce_0: 1.232  loss_mask_0: 0.5314  loss_dice_0: 4.584  loss_ce_1: 1.934  loss_mask_1: 0.5316  loss_dice_1: 4.4  loss_ce_2: 2.035  loss_mask_2: 0.534  loss_dice_2: 4.371  loss_ce_3: 2.079  loss_mask_3: 0.5337  loss_dice_3: 4.359  loss_ce_4: 2.08  loss_mask_4: 0.535  loss_dice_4: 4.344  loss_ce_5: 2.09  loss_mask_5: 0.5342  loss_dice_5: 4.351  loss_ce_6: 2.079  loss_mask_6: 0.5336  loss_dice_6: 4.349  loss_ce_7: 2.12  loss_mask_7: 0.5359  loss_dice_7: 4.348  loss_ce_8: 2.106  loss_mask_8: 0.539  loss_dice_8: 4.342  time: 2.1303  data_time: 0.3923  lr: 9.5174e-05  max_mem: 24420M
[01/19 16:25:54] d2.utils.events INFO:  eta: 22:15:05  iter: 2159  total_loss: 69.87  loss_ce: 2.286  loss_mask: 0.5221  loss_dice: 4.351  loss_ce_0: 1.242  loss_mask_0: 0.516  loss_dice_0: 4.591  loss_ce_1: 1.938  loss_mask_1: 0.517  loss_dice_1: 4.414  loss_ce_2: 2.058  loss_mask_2: 0.5177  loss_dice_2: 4.385  loss_ce_3: 2.135  loss_mask_3: 0.5195  loss_dice_3: 4.377  loss_ce_4: 2.206  loss_mask_4: 0.5176  loss_dice_4: 4.379  loss_ce_5: 2.248  loss_mask_5: 0.5225  loss_dice_5: 4.374  loss_ce_6: 2.235  loss_mask_6: 0.5197  loss_dice_6: 4.372  loss_ce_7: 2.246  loss_mask_7: 0.5183  loss_dice_7: 4.376  loss_ce_8: 2.229  loss_mask_8: 0.522  loss_dice_8: 4.364  time: 2.1303  data_time: 0.4026  lr: 9.5129e-05  max_mem: 24420M
[01/19 16:26:37] d2.utils.events INFO:  eta: 22:14:48  iter: 2179  total_loss: 69.79  loss_ce: 2.229  loss_mask: 0.5157  loss_dice: 4.366  loss_ce_0: 1.244  loss_mask_0: 0.5191  loss_dice_0: 4.579  loss_ce_1: 1.967  loss_mask_1: 0.5211  loss_dice_1: 4.399  loss_ce_2: 2.057  loss_mask_2: 0.5225  loss_dice_2: 4.381  loss_ce_3: 2.117  loss_mask_3: 0.5214  loss_dice_3: 4.374  loss_ce_4: 2.159  loss_mask_4: 0.5195  loss_dice_4: 4.372  loss_ce_5: 2.203  loss_mask_5: 0.5175  loss_dice_5: 4.378  loss_ce_6: 2.209  loss_mask_6: 0.5187  loss_dice_6: 4.375  loss_ce_7: 2.211  loss_mask_7: 0.5199  loss_dice_7: 4.364  loss_ce_8: 2.198  loss_mask_8: 0.5184  loss_dice_8: 4.368  time: 2.1303  data_time: 0.4028  lr: 9.5084e-05  max_mem: 24420M
[01/19 16:27:19] d2.utils.events INFO:  eta: 22:13:50  iter: 2199  total_loss: 69.2  loss_ce: 2.181  loss_mask: 0.5173  loss_dice: 4.356  loss_ce_0: 1.22  loss_mask_0: 0.5195  loss_dice_0: 4.597  loss_ce_1: 1.899  loss_mask_1: 0.5155  loss_dice_1: 4.412  loss_ce_2: 2.022  loss_mask_2: 0.5165  loss_dice_2: 4.392  loss_ce_3: 2.027  loss_mask_3: 0.5152  loss_dice_3: 4.387  loss_ce_4: 2.09  loss_mask_4: 0.5135  loss_dice_4: 4.376  loss_ce_5: 2.126  loss_mask_5: 0.5133  loss_dice_5: 4.373  loss_ce_6: 2.146  loss_mask_6: 0.5145  loss_dice_6: 4.371  loss_ce_7: 2.121  loss_mask_7: 0.5152  loss_dice_7: 4.38  loss_ce_8: 2.134  loss_mask_8: 0.5153  loss_dice_8: 4.371  time: 2.1302  data_time: 0.3809  lr: 9.5038e-05  max_mem: 24420M
[01/19 16:28:01] d2.utils.events INFO:  eta: 22:12:25  iter: 2219  total_loss: 68.72  loss_ce: 2.065  loss_mask: 0.5243  loss_dice: 4.376  loss_ce_0: 1.216  loss_mask_0: 0.528  loss_dice_0: 4.59  loss_ce_1: 1.887  loss_mask_1: 0.5262  loss_dice_1: 4.412  loss_ce_2: 2.012  loss_mask_2: 0.5252  loss_dice_2: 4.382  loss_ce_3: 2.024  loss_mask_3: 0.5283  loss_dice_3: 4.371  loss_ce_4: 2.095  loss_mask_4: 0.5297  loss_dice_4: 4.37  loss_ce_5: 2.115  loss_mask_5: 0.5271  loss_dice_5: 4.379  loss_ce_6: 2.082  loss_mask_6: 0.5278  loss_dice_6: 4.376  loss_ce_7: 2.058  loss_mask_7: 0.5278  loss_dice_7: 4.375  loss_ce_8: 2.088  loss_mask_8: 0.526  loss_dice_8: 4.37  time: 2.1300  data_time: 0.4093  lr: 9.4993e-05  max_mem: 24420M
[01/19 16:28:44] d2.utils.events INFO:  eta: 22:11:23  iter: 2239  total_loss: 69.69  loss_ce: 2.218  loss_mask: 0.533  loss_dice: 4.332  loss_ce_0: 1.233  loss_mask_0: 0.5291  loss_dice_0: 4.58  loss_ce_1: 1.992  loss_mask_1: 0.531  loss_dice_1: 4.382  loss_ce_2: 2.121  loss_mask_2: 0.5344  loss_dice_2: 4.354  loss_ce_3: 2.079  loss_mask_3: 0.5329  loss_dice_3: 4.35  loss_ce_4: 2.155  loss_mask_4: 0.531  loss_dice_4: 4.343  loss_ce_5: 2.177  loss_mask_5: 0.5322  loss_dice_5: 4.343  loss_ce_6: 2.198  loss_mask_6: 0.533  loss_dice_6: 4.343  loss_ce_7: 2.204  loss_mask_7: 0.5319  loss_dice_7: 4.344  loss_ce_8: 2.199  loss_mask_8: 0.5296  loss_dice_8: 4.353  time: 2.1298  data_time: 0.3953  lr: 9.4948e-05  max_mem: 24420M
[01/19 16:29:26] d2.utils.events INFO:  eta: 22:11:23  iter: 2259  total_loss: 69.05  loss_ce: 2.1  loss_mask: 0.5291  loss_dice: 4.355  loss_ce_0: 1.245  loss_mask_0: 0.5265  loss_dice_0: 4.587  loss_ce_1: 1.953  loss_mask_1: 0.5297  loss_dice_1: 4.398  loss_ce_2: 2.04  loss_mask_2: 0.5281  loss_dice_2: 4.377  loss_ce_3: 2.046  loss_mask_3: 0.5291  loss_dice_3: 4.363  loss_ce_4: 2.072  loss_mask_4: 0.5295  loss_dice_4: 4.364  loss_ce_5: 2.09  loss_mask_5: 0.5288  loss_dice_5: 4.369  loss_ce_6: 2.05  loss_mask_6: 0.5296  loss_dice_6: 4.362  loss_ce_7: 2.048  loss_mask_7: 0.5291  loss_dice_7: 4.367  loss_ce_8: 2.075  loss_mask_8: 0.5298  loss_dice_8: 4.365  time: 2.1297  data_time: 0.4148  lr: 9.4903e-05  max_mem: 24420M
[01/19 16:30:09] d2.utils.events INFO:  eta: 22:10:47  iter: 2279  total_loss: 69.64  loss_ce: 2.2  loss_mask: 0.5181  loss_dice: 4.365  loss_ce_0: 1.218  loss_mask_0: 0.5179  loss_dice_0: 4.599  loss_ce_1: 1.993  loss_mask_1: 0.5135  loss_dice_1: 4.415  loss_ce_2: 2.068  loss_mask_2: 0.5196  loss_dice_2: 4.389  loss_ce_3: 2.073  loss_mask_3: 0.5173  loss_dice_3: 4.384  loss_ce_4: 2.121  loss_mask_4: 0.5185  loss_dice_4: 4.375  loss_ce_5: 2.139  loss_mask_5: 0.5186  loss_dice_5: 4.372  loss_ce_6: 2.174  loss_mask_6: 0.5211  loss_dice_6: 4.372  loss_ce_7: 2.168  loss_mask_7: 0.5213  loss_dice_7: 4.372  loss_ce_8: 2.169  loss_mask_8: 0.5213  loss_dice_8: 4.373  time: 2.1297  data_time: 0.4082  lr: 9.4857e-05  max_mem: 24420M
[01/19 16:30:51] d2.utils.events INFO:  eta: 22:10:02  iter: 2299  total_loss: 69.28  loss_ce: 2.157  loss_mask: 0.5264  loss_dice: 4.363  loss_ce_0: 1.249  loss_mask_0: 0.5279  loss_dice_0: 4.588  loss_ce_1: 1.973  loss_mask_1: 0.5241  loss_dice_1: 4.417  loss_ce_2: 2.065  loss_mask_2: 0.5277  loss_dice_2: 4.387  loss_ce_3: 2.063  loss_mask_3: 0.5286  loss_dice_3: 4.382  loss_ce_4: 2.097  loss_mask_4: 0.5251  loss_dice_4: 4.38  loss_ce_5: 2.129  loss_mask_5: 0.5257  loss_dice_5: 4.373  loss_ce_6: 2.132  loss_mask_6: 0.5274  loss_dice_6: 4.371  loss_ce_7: 2.133  loss_mask_7: 0.5284  loss_dice_7: 4.385  loss_ce_8: 2.146  loss_mask_8: 0.5247  loss_dice_8: 4.374  time: 2.1295  data_time: 0.4040  lr: 9.4812e-05  max_mem: 24420M
[01/19 16:31:33] d2.utils.events INFO:  eta: 22:09:23  iter: 2319  total_loss: 68.83  loss_ce: 2.074  loss_mask: 0.5202  loss_dice: 4.368  loss_ce_0: 1.202  loss_mask_0: 0.5208  loss_dice_0: 4.591  loss_ce_1: 1.962  loss_mask_1: 0.5193  loss_dice_1: 4.409  loss_ce_2: 2.057  loss_mask_2: 0.5211  loss_dice_2: 4.39  loss_ce_3: 2.074  loss_mask_3: 0.5206  loss_dice_3: 4.381  loss_ce_4: 2.039  loss_mask_4: 0.5199  loss_dice_4: 4.378  loss_ce_5: 2.054  loss_mask_5: 0.5202  loss_dice_5: 4.385  loss_ce_6: 2.051  loss_mask_6: 0.5201  loss_dice_6: 4.372  loss_ce_7: 2.041  loss_mask_7: 0.5217  loss_dice_7: 4.382  loss_ce_8: 2.031  loss_mask_8: 0.5229  loss_dice_8: 4.382  time: 2.1295  data_time: 0.3988  lr: 9.4767e-05  max_mem: 24420M
[01/19 16:32:17] d2.utils.events INFO:  eta: 22:09:18  iter: 2339  total_loss: 68.56  loss_ce: 2.085  loss_mask: 0.5066  loss_dice: 4.357  loss_ce_0: 1.216  loss_mask_0: 0.5086  loss_dice_0: 4.593  loss_ce_1: 1.901  loss_mask_1: 0.5095  loss_dice_1: 4.406  loss_ce_2: 2.022  loss_mask_2: 0.5089  loss_dice_2: 4.381  loss_ce_3: 2.034  loss_mask_3: 0.5102  loss_dice_3: 4.365  loss_ce_4: 2.048  loss_mask_4: 0.5099  loss_dice_4: 4.367  loss_ce_5: 2.055  loss_mask_5: 0.5078  loss_dice_5: 4.373  loss_ce_6: 2.089  loss_mask_6: 0.5114  loss_dice_6: 4.364  loss_ce_7: 2.067  loss_mask_7: 0.5098  loss_dice_7: 4.366  loss_ce_8: 2.048  loss_mask_8: 0.5104  loss_dice_8: 4.37  time: 2.1297  data_time: 0.4204  lr: 9.4722e-05  max_mem: 24463M
[01/19 16:32:59] d2.utils.events INFO:  eta: 22:08:59  iter: 2359  total_loss: 69.85  loss_ce: 2.213  loss_mask: 0.5186  loss_dice: 4.336  loss_ce_0: 1.257  loss_mask_0: 0.5159  loss_dice_0: 4.585  loss_ce_1: 2.019  loss_mask_1: 0.5185  loss_dice_1: 4.392  loss_ce_2: 2.117  loss_mask_2: 0.5212  loss_dice_2: 4.361  loss_ce_3: 2.154  loss_mask_3: 0.5203  loss_dice_3: 4.349  loss_ce_4: 2.17  loss_mask_4: 0.5169  loss_dice_4: 4.346  loss_ce_5: 2.2  loss_mask_5: 0.5205  loss_dice_5: 4.345  loss_ce_6: 2.183  loss_mask_6: 0.5196  loss_dice_6: 4.343  loss_ce_7: 2.181  loss_mask_7: 0.5182  loss_dice_7: 4.347  loss_ce_8: 2.165  loss_mask_8: 0.5179  loss_dice_8: 4.343  time: 2.1297  data_time: 0.4031  lr: 9.4676e-05  max_mem: 24463M
[01/19 16:33:42] d2.utils.events INFO:  eta: 22:08:30  iter: 2379  total_loss: 69.69  loss_ce: 2.299  loss_mask: 0.5182  loss_dice: 4.307  loss_ce_0: 1.222  loss_mask_0: 0.5183  loss_dice_0: 4.573  loss_ce_1: 1.97  loss_mask_1: 0.5178  loss_dice_1: 4.368  loss_ce_2: 2.075  loss_mask_2: 0.5154  loss_dice_2: 4.337  loss_ce_3: 2.148  loss_mask_3: 0.5163  loss_dice_3: 4.335  loss_ce_4: 2.205  loss_mask_4: 0.5188  loss_dice_4: 4.333  loss_ce_5: 2.187  loss_mask_5: 0.5188  loss_dice_5: 4.337  loss_ce_6: 2.214  loss_mask_6: 0.5179  loss_dice_6: 4.325  loss_ce_7: 2.233  loss_mask_7: 0.5174  loss_dice_7: 4.334  loss_ce_8: 2.253  loss_mask_8: 0.5213  loss_dice_8: 4.321  time: 2.1298  data_time: 0.4140  lr: 9.4631e-05  max_mem: 24463M
[01/19 16:34:25] d2.utils.events INFO:  eta: 22:07:22  iter: 2399  total_loss: 68.9  loss_ce: 2.154  loss_mask: 0.514  loss_dice: 4.337  loss_ce_0: 1.229  loss_mask_0: 0.5144  loss_dice_0: 4.571  loss_ce_1: 1.968  loss_mask_1: 0.5168  loss_dice_1: 4.383  loss_ce_2: 2.05  loss_mask_2: 0.5188  loss_dice_2: 4.366  loss_ce_3: 2.112  loss_mask_3: 0.5224  loss_dice_3: 4.356  loss_ce_4: 2.117  loss_mask_4: 0.5182  loss_dice_4: 4.356  loss_ce_5: 2.098  loss_mask_5: 0.5158  loss_dice_5: 4.353  loss_ce_6: 2.152  loss_mask_6: 0.5138  loss_dice_6: 4.353  loss_ce_7: 2.13  loss_mask_7: 0.5162  loss_dice_7: 4.358  loss_ce_8: 2.104  loss_mask_8: 0.5175  loss_dice_8: 4.353  time: 2.1298  data_time: 0.4195  lr: 9.4586e-05  max_mem: 24463M
[01/19 16:35:07] d2.utils.events INFO:  eta: 22:06:52  iter: 2419  total_loss: 69.3  loss_ce: 2.189  loss_mask: 0.5184  loss_dice: 4.321  loss_ce_0: 1.245  loss_mask_0: 0.5193  loss_dice_0: 4.577  loss_ce_1: 1.97  loss_mask_1: 0.5161  loss_dice_1: 4.377  loss_ce_2: 2.062  loss_mask_2: 0.5182  loss_dice_2: 4.346  loss_ce_3: 2.118  loss_mask_3: 0.5197  loss_dice_3: 4.341  loss_ce_4: 2.163  loss_mask_4: 0.5165  loss_dice_4: 4.334  loss_ce_5: 2.152  loss_mask_5: 0.5136  loss_dice_5: 4.337  loss_ce_6: 2.173  loss_mask_6: 0.5172  loss_dice_6: 4.333  loss_ce_7: 2.168  loss_mask_7: 0.5191  loss_dice_7: 4.335  loss_ce_8: 2.199  loss_mask_8: 0.5196  loss_dice_8: 4.339  time: 2.1297  data_time: 0.4129  lr: 9.454e-05  max_mem: 24463M
[01/19 16:35:50] d2.utils.events INFO:  eta: 22:06:27  iter: 2439  total_loss: 69.09  loss_ce: 2.15  loss_mask: 0.5142  loss_dice: 4.329  loss_ce_0: 1.231  loss_mask_0: 0.5164  loss_dice_0: 4.572  loss_ce_1: 1.955  loss_mask_1: 0.5191  loss_dice_1: 4.375  loss_ce_2: 2.033  loss_mask_2: 0.5182  loss_dice_2: 4.347  loss_ce_3: 2.065  loss_mask_3: 0.5161  loss_dice_3: 4.345  loss_ce_4: 2.115  loss_mask_4: 0.5181  loss_dice_4: 4.34  loss_ce_5: 2.12  loss_mask_5: 0.5148  loss_dice_5: 4.341  loss_ce_6: 2.13  loss_mask_6: 0.5135  loss_dice_6: 4.338  loss_ce_7: 2.103  loss_mask_7: 0.5136  loss_dice_7: 4.349  loss_ce_8: 2.122  loss_mask_8: 0.515  loss_dice_8: 4.337  time: 2.1298  data_time: 0.4092  lr: 9.4495e-05  max_mem: 24463M
[01/19 16:36:33] d2.utils.events INFO:  eta: 22:05:34  iter: 2459  total_loss: 70.33  loss_ce: 2.306  loss_mask: 0.5167  loss_dice: 4.325  loss_ce_0: 1.222  loss_mask_0: 0.5154  loss_dice_0: 4.58  loss_ce_1: 2.028  loss_mask_1: 0.5176  loss_dice_1: 4.394  loss_ce_2: 2.176  loss_mask_2: 0.5192  loss_dice_2: 4.359  loss_ce_3: 2.219  loss_mask_3: 0.5195  loss_dice_3: 4.346  loss_ce_4: 2.255  loss_mask_4: 0.5152  loss_dice_4: 4.341  loss_ce_5: 2.3  loss_mask_5: 0.5146  loss_dice_5: 4.342  loss_ce_6: 2.247  loss_mask_6: 0.5142  loss_dice_6: 4.344  loss_ce_7: 2.263  loss_mask_7: 0.5169  loss_dice_7: 4.349  loss_ce_8: 2.238  loss_mask_8: 0.5149  loss_dice_8: 4.341  time: 2.1298  data_time: 0.4096  lr: 9.445e-05  max_mem: 24463M
[01/19 16:37:15] d2.utils.events INFO:  eta: 22:05:46  iter: 2479  total_loss: 71.26  loss_ce: 2.488  loss_mask: 0.5336  loss_dice: 4.282  loss_ce_0: 1.259  loss_mask_0: 0.5309  loss_dice_0: 4.569  loss_ce_1: 2.12  loss_mask_1: 0.5361  loss_dice_1: 4.345  loss_ce_2: 2.254  loss_mask_2: 0.5361  loss_dice_2: 4.313  loss_ce_3: 2.277  loss_mask_3: 0.536  loss_dice_3: 4.303  loss_ce_4: 2.381  loss_mask_4: 0.5386  loss_dice_4: 4.296  loss_ce_5: 2.451  loss_mask_5: 0.5371  loss_dice_5: 4.303  loss_ce_6: 2.437  loss_mask_6: 0.5348  loss_dice_6: 4.297  loss_ce_7: 2.46  loss_mask_7: 0.5385  loss_dice_7: 4.3  loss_ce_8: 2.486  loss_mask_8: 0.5362  loss_dice_8: 4.289  time: 2.1297  data_time: 0.4208  lr: 9.4405e-05  max_mem: 24463M
[01/19 16:37:57] d2.utils.events INFO:  eta: 22:04:09  iter: 2499  total_loss: 70.09  loss_ce: 2.304  loss_mask: 0.5309  loss_dice: 4.315  loss_ce_0: 1.245  loss_mask_0: 0.526  loss_dice_0: 4.576  loss_ce_1: 2.094  loss_mask_1: 0.5229  loss_dice_1: 4.362  loss_ce_2: 2.172  loss_mask_2: 0.5266  loss_dice_2: 4.34  loss_ce_3: 2.222  loss_mask_3: 0.5283  loss_dice_3: 4.324  loss_ce_4: 2.256  loss_mask_4: 0.5283  loss_dice_4: 4.33  loss_ce_5: 2.261  loss_mask_5: 0.5271  loss_dice_5: 4.331  loss_ce_6: 2.289  loss_mask_6: 0.5298  loss_dice_6: 4.324  loss_ce_7: 2.285  loss_mask_7: 0.5328  loss_dice_7: 4.329  loss_ce_8: 2.288  loss_mask_8: 0.5316  loss_dice_8: 4.324  time: 2.1296  data_time: 0.3932  lr: 9.4359e-05  max_mem: 24463M
[01/19 16:38:40] d2.utils.events INFO:  eta: 22:02:57  iter: 2519  total_loss: 69.85  loss_ce: 2.263  loss_mask: 0.5265  loss_dice: 4.308  loss_ce_0: 1.263  loss_mask_0: 0.5269  loss_dice_0: 4.574  loss_ce_1: 2.041  loss_mask_1: 0.5266  loss_dice_1: 4.369  loss_ce_2: 2.166  loss_mask_2: 0.5293  loss_dice_2: 4.331  loss_ce_3: 2.208  loss_mask_3: 0.5294  loss_dice_3: 4.315  loss_ce_4: 2.233  loss_mask_4: 0.5297  loss_dice_4: 4.315  loss_ce_5: 2.245  loss_mask_5: 0.5275  loss_dice_5: 4.318  loss_ce_6: 2.259  loss_mask_6: 0.5265  loss_dice_6: 4.316  loss_ce_7: 2.227  loss_mask_7: 0.528  loss_dice_7: 4.325  loss_ce_8: 2.242  loss_mask_8: 0.5292  loss_dice_8: 4.317  time: 2.1296  data_time: 0.4249  lr: 9.4314e-05  max_mem: 24463M
[01/19 16:39:22] d2.utils.events INFO:  eta: 22:02:15  iter: 2539  total_loss: 70.86  loss_ce: 2.451  loss_mask: 0.5306  loss_dice: 4.276  loss_ce_0: 1.297  loss_mask_0: 0.5315  loss_dice_0: 4.546  loss_ce_1: 2.171  loss_mask_1: 0.531  loss_dice_1: 4.331  loss_ce_2: 2.29  loss_mask_2: 0.5323  loss_dice_2: 4.308  loss_ce_3: 2.291  loss_mask_3: 0.5292  loss_dice_3: 4.303  loss_ce_4: 2.361  loss_mask_4: 0.5309  loss_dice_4: 4.291  loss_ce_5: 2.394  loss_mask_5: 0.5302  loss_dice_5: 4.289  loss_ce_6: 2.428  loss_mask_6: 0.5331  loss_dice_6: 4.286  loss_ce_7: 2.41  loss_mask_7: 0.5373  loss_dice_7: 4.286  loss_ce_8: 2.428  loss_mask_8: 0.5348  loss_dice_8: 4.284  time: 2.1293  data_time: 0.3956  lr: 9.4269e-05  max_mem: 24463M
[01/19 16:40:04] d2.utils.events INFO:  eta: 22:00:57  iter: 2559  total_loss: 70.46  loss_ce: 2.345  loss_mask: 0.5373  loss_dice: 4.305  loss_ce_0: 1.294  loss_mask_0: 0.5352  loss_dice_0: 4.554  loss_ce_1: 2.19  loss_mask_1: 0.5332  loss_dice_1: 4.358  loss_ce_2: 2.254  loss_mask_2: 0.5353  loss_dice_2: 4.331  loss_ce_3: 2.272  loss_mask_3: 0.5374  loss_dice_3: 4.32  loss_ce_4: 2.316  loss_mask_4: 0.5378  loss_dice_4: 4.321  loss_ce_5: 2.288  loss_mask_5: 0.5359  loss_dice_5: 4.32  loss_ce_6: 2.32  loss_mask_6: 0.5382  loss_dice_6: 4.323  loss_ce_7: 2.341  loss_mask_7: 0.5387  loss_dice_7: 4.321  loss_ce_8: 2.351  loss_mask_8: 0.5373  loss_dice_8: 4.315  time: 2.1291  data_time: 0.3836  lr: 9.4223e-05  max_mem: 24483M
[01/19 16:40:47] d2.utils.events INFO:  eta: 22:00:09  iter: 2579  total_loss: 70.57  loss_ce: 2.281  loss_mask: 0.5328  loss_dice: 4.313  loss_ce_0: 1.268  loss_mask_0: 0.5329  loss_dice_0: 4.568  loss_ce_1: 2.069  loss_mask_1: 0.5385  loss_dice_1: 4.368  loss_ce_2: 2.227  loss_mask_2: 0.5437  loss_dice_2: 4.333  loss_ce_3: 2.244  loss_mask_3: 0.5429  loss_dice_3: 4.314  loss_ce_4: 2.284  loss_mask_4: 0.5348  loss_dice_4: 4.316  loss_ce_5: 2.319  loss_mask_5: 0.5365  loss_dice_5: 4.315  loss_ce_6: 2.3  loss_mask_6: 0.5377  loss_dice_6: 4.321  loss_ce_7: 2.274  loss_mask_7: 0.5388  loss_dice_7: 4.321  loss_ce_8: 2.269  loss_mask_8: 0.5361  loss_dice_8: 4.319  time: 2.1291  data_time: 0.4119  lr: 9.4178e-05  max_mem: 24483M
[01/19 16:41:29] d2.utils.events INFO:  eta: 21:58:55  iter: 2599  total_loss: 70.92  loss_ce: 2.366  loss_mask: 0.5363  loss_dice: 4.275  loss_ce_0: 1.291  loss_mask_0: 0.5386  loss_dice_0: 4.557  loss_ce_1: 2.104  loss_mask_1: 0.5403  loss_dice_1: 4.35  loss_ce_2: 2.246  loss_mask_2: 0.5413  loss_dice_2: 4.309  loss_ce_3: 2.29  loss_mask_3: 0.5433  loss_dice_3: 4.298  loss_ce_4: 2.342  loss_mask_4: 0.5457  loss_dice_4: 4.295  loss_ce_5: 2.371  loss_mask_5: 0.5461  loss_dice_5: 4.292  loss_ce_6: 2.353  loss_mask_6: 0.5476  loss_dice_6: 4.29  loss_ce_7: 2.32  loss_mask_7: 0.5454  loss_dice_7: 4.295  loss_ce_8: 2.343  loss_mask_8: 0.541  loss_dice_8: 4.286  time: 2.1288  data_time: 0.3949  lr: 9.4133e-05  max_mem: 24483M
[01/19 16:42:11] d2.utils.events INFO:  eta: 21:58:30  iter: 2619  total_loss: 70.22  loss_ce: 2.313  loss_mask: 0.5275  loss_dice: 4.285  loss_ce_0: 1.29  loss_mask_0: 0.5264  loss_dice_0: 4.56  loss_ce_1: 2.158  loss_mask_1: 0.5292  loss_dice_1: 4.34  loss_ce_2: 2.225  loss_mask_2: 0.5307  loss_dice_2: 4.316  loss_ce_3: 2.197  loss_mask_3: 0.5298  loss_dice_3: 4.298  loss_ce_4: 2.27  loss_mask_4: 0.5307  loss_dice_4: 4.295  loss_ce_5: 2.266  loss_mask_5: 0.5313  loss_dice_5: 4.293  loss_ce_6: 2.309  loss_mask_6: 0.5338  loss_dice_6: 4.288  loss_ce_7: 2.291  loss_mask_7: 0.5303  loss_dice_7: 4.3  loss_ce_8: 2.305  loss_mask_8: 0.53  loss_dice_8: 4.289  time: 2.1287  data_time: 0.3981  lr: 9.4087e-05  max_mem: 24483M
[01/19 16:42:53] d2.utils.events INFO:  eta: 21:57:47  iter: 2639  total_loss: 70.11  loss_ce: 2.324  loss_mask: 0.5233  loss_dice: 4.293  loss_ce_0: 1.268  loss_mask_0: 0.5224  loss_dice_0: 4.569  loss_ce_1: 2.121  loss_mask_1: 0.5226  loss_dice_1: 4.353  loss_ce_2: 2.195  loss_mask_2: 0.5227  loss_dice_2: 4.322  loss_ce_3: 2.232  loss_mask_3: 0.5244  loss_dice_3: 4.314  loss_ce_4: 2.258  loss_mask_4: 0.5276  loss_dice_4: 4.31  loss_ce_5: 2.258  loss_mask_5: 0.5236  loss_dice_5: 4.311  loss_ce_6: 2.284  loss_mask_6: 0.5221  loss_dice_6: 4.302  loss_ce_7: 2.278  loss_mask_7: 0.5242  loss_dice_7: 4.306  loss_ce_8: 2.283  loss_mask_8: 0.5227  loss_dice_8: 4.302  time: 2.1287  data_time: 0.4223  lr: 9.4042e-05  max_mem: 24483M
[01/19 16:43:36] d2.utils.events INFO:  eta: 21:56:42  iter: 2659  total_loss: 69.84  loss_ce: 2.302  loss_mask: 0.525  loss_dice: 4.289  loss_ce_0: 1.288  loss_mask_0: 0.5285  loss_dice_0: 4.547  loss_ce_1: 2.092  loss_mask_1: 0.5273  loss_dice_1: 4.342  loss_ce_2: 2.181  loss_mask_2: 0.532  loss_dice_2: 4.316  loss_ce_3: 2.166  loss_mask_3: 0.5264  loss_dice_3: 4.319  loss_ce_4: 2.225  loss_mask_4: 0.5261  loss_dice_4: 4.301  loss_ce_5: 2.213  loss_mask_5: 0.5274  loss_dice_5: 4.305  loss_ce_6: 2.228  loss_mask_6: 0.5256  loss_dice_6: 4.303  loss_ce_7: 2.224  loss_mask_7: 0.5256  loss_dice_7: 4.307  loss_ce_8: 2.261  loss_mask_8: 0.5258  loss_dice_8: 4.298  time: 2.1286  data_time: 0.4009  lr: 9.3997e-05  max_mem: 24483M
[01/19 16:44:18] d2.utils.events INFO:  eta: 21:55:17  iter: 2679  total_loss: 70  loss_ce: 2.309  loss_mask: 0.5298  loss_dice: 4.274  loss_ce_0: 1.286  loss_mask_0: 0.5279  loss_dice_0: 4.549  loss_ce_1: 2.141  loss_mask_1: 0.5301  loss_dice_1: 4.339  loss_ce_2: 2.177  loss_mask_2: 0.5323  loss_dice_2: 4.307  loss_ce_3: 2.185  loss_mask_3: 0.5321  loss_dice_3: 4.308  loss_ce_4: 2.233  loss_mask_4: 0.5292  loss_dice_4: 4.296  loss_ce_5: 2.236  loss_mask_5: 0.5339  loss_dice_5: 4.295  loss_ce_6: 2.232  loss_mask_6: 0.5314  loss_dice_6: 4.29  loss_ce_7: 2.187  loss_mask_7: 0.5295  loss_dice_7: 4.299  loss_ce_8: 2.282  loss_mask_8: 0.5335  loss_dice_8: 4.29  time: 2.1286  data_time: 0.4041  lr: 9.3952e-05  max_mem: 24483M
[01/19 16:45:01] d2.utils.events INFO:  eta: 21:54:48  iter: 2699  total_loss: 70.16  loss_ce: 2.33  loss_mask: 0.5187  loss_dice: 4.301  loss_ce_0: 1.256  loss_mask_0: 0.5196  loss_dice_0: 4.556  loss_ce_1: 2.077  loss_mask_1: 0.5212  loss_dice_1: 4.366  loss_ce_2: 2.155  loss_mask_2: 0.5234  loss_dice_2: 4.334  loss_ce_3: 2.182  loss_mask_3: 0.5208  loss_dice_3: 4.332  loss_ce_4: 2.255  loss_mask_4: 0.5204  loss_dice_4: 4.328  loss_ce_5: 2.282  loss_mask_5: 0.5225  loss_dice_5: 4.322  loss_ce_6: 2.295  loss_mask_6: 0.5182  loss_dice_6: 4.323  loss_ce_7: 2.25  loss_mask_7: 0.5225  loss_dice_7: 4.325  loss_ce_8: 2.316  loss_mask_8: 0.5227  loss_dice_8: 4.316  time: 2.1285  data_time: 0.4086  lr: 9.3906e-05  max_mem: 24483M
[01/19 16:45:43] d2.utils.events INFO:  eta: 21:54:45  iter: 2719  total_loss: 70.63  loss_ce: 2.372  loss_mask: 0.5243  loss_dice: 4.288  loss_ce_0: 1.283  loss_mask_0: 0.5249  loss_dice_0: 4.562  loss_ce_1: 2.129  loss_mask_1: 0.5237  loss_dice_1: 4.347  loss_ce_2: 2.249  loss_mask_2: 0.5246  loss_dice_2: 4.321  loss_ce_3: 2.261  loss_mask_3: 0.5227  loss_dice_3: 4.303  loss_ce_4: 2.292  loss_mask_4: 0.5258  loss_dice_4: 4.301  loss_ce_5: 2.293  loss_mask_5: 0.5255  loss_dice_5: 4.306  loss_ce_6: 2.319  loss_mask_6: 0.5266  loss_dice_6: 4.304  loss_ce_7: 2.308  loss_mask_7: 0.5282  loss_dice_7: 4.305  loss_ce_8: 2.352  loss_mask_8: 0.5246  loss_dice_8: 4.3  time: 2.1285  data_time: 0.4036  lr: 9.3861e-05  max_mem: 24483M
[01/19 16:46:25] d2.utils.events INFO:  eta: 21:53:04  iter: 2739  total_loss: 69.45  loss_ce: 2.243  loss_mask: 0.5221  loss_dice: 4.306  loss_ce_0: 1.269  loss_mask_0: 0.5242  loss_dice_0: 4.559  loss_ce_1: 2.13  loss_mask_1: 0.5208  loss_dice_1: 4.343  loss_ce_2: 2.139  loss_mask_2: 0.5192  loss_dice_2: 4.334  loss_ce_3: 2.129  loss_mask_3: 0.5209  loss_dice_3: 4.326  loss_ce_4: 2.194  loss_mask_4: 0.5251  loss_dice_4: 4.317  loss_ce_5: 2.189  loss_mask_5: 0.5222  loss_dice_5: 4.329  loss_ce_6: 2.206  loss_mask_6: 0.5217  loss_dice_6: 4.326  loss_ce_7: 2.213  loss_mask_7: 0.5216  loss_dice_7: 4.332  loss_ce_8: 2.217  loss_mask_8: 0.5237  loss_dice_8: 4.317  time: 2.1283  data_time: 0.3968  lr: 9.3816e-05  max_mem: 24483M
[01/19 16:47:08] d2.utils.events INFO:  eta: 21:52:09  iter: 2759  total_loss: 71.02  loss_ce: 2.447  loss_mask: 0.5313  loss_dice: 4.248  loss_ce_0: 1.321  loss_mask_0: 0.5366  loss_dice_0: 4.537  loss_ce_1: 2.251  loss_mask_1: 0.534  loss_dice_1: 4.302  loss_ce_2: 2.358  loss_mask_2: 0.5318  loss_dice_2: 4.275  loss_ce_3: 2.311  loss_mask_3: 0.5334  loss_dice_3: 4.261  loss_ce_4: 2.364  loss_mask_4: 0.5369  loss_dice_4: 4.261  loss_ce_5: 2.36  loss_mask_5: 0.5363  loss_dice_5: 4.275  loss_ce_6: 2.384  loss_mask_6: 0.5359  loss_dice_6: 4.27  loss_ce_7: 2.406  loss_mask_7: 0.5345  loss_dice_7: 4.279  loss_ce_8: 2.424  loss_mask_8: 0.5323  loss_dice_8: 4.267  time: 2.1282  data_time: 0.4223  lr: 9.377e-05  max_mem: 24483M
[01/19 16:47:50] d2.utils.events INFO:  eta: 21:52:20  iter: 2779  total_loss: 69.81  loss_ce: 2.282  loss_mask: 0.5177  loss_dice: 4.293  loss_ce_0: 1.269  loss_mask_0: 0.5192  loss_dice_0: 4.569  loss_ce_1: 2.074  loss_mask_1: 0.5213  loss_dice_1: 4.355  loss_ce_2: 2.149  loss_mask_2: 0.5213  loss_dice_2: 4.33  loss_ce_3: 2.167  loss_mask_3: 0.52  loss_dice_3: 4.311  loss_ce_4: 2.236  loss_mask_4: 0.5201  loss_dice_4: 4.31  loss_ce_5: 2.225  loss_mask_5: 0.518  loss_dice_5: 4.317  loss_ce_6: 2.225  loss_mask_6: 0.5198  loss_dice_6: 4.309  loss_ce_7: 2.211  loss_mask_7: 0.5205  loss_dice_7: 4.311  loss_ce_8: 2.242  loss_mask_8: 0.5198  loss_dice_8: 4.309  time: 2.1282  data_time: 0.4083  lr: 9.3725e-05  max_mem: 24483M
[01/19 16:48:34] d2.utils.events INFO:  eta: 21:52:09  iter: 2799  total_loss: 70.45  loss_ce: 2.364  loss_mask: 0.521  loss_dice: 4.296  loss_ce_0: 1.286  loss_mask_0: 0.5184  loss_dice_0: 4.563  loss_ce_1: 2.221  loss_mask_1: 0.517  loss_dice_1: 4.346  loss_ce_2: 2.258  loss_mask_2: 0.5179  loss_dice_2: 4.331  loss_ce_3: 2.304  loss_mask_3: 0.5221  loss_dice_3: 4.31  loss_ce_4: 2.336  loss_mask_4: 0.5199  loss_dice_4: 4.303  loss_ce_5: 2.318  loss_mask_5: 0.5186  loss_dice_5: 4.306  loss_ce_6: 2.314  loss_mask_6: 0.5183  loss_dice_6: 4.312  loss_ce_7: 2.299  loss_mask_7: 0.5217  loss_dice_7: 4.315  loss_ce_8: 2.296  loss_mask_8: 0.5191  loss_dice_8: 4.304  time: 2.1284  data_time: 0.4183  lr: 9.368e-05  max_mem: 24483M
[01/19 16:49:17] d2.utils.events INFO:  eta: 21:51:39  iter: 2819  total_loss: 69.66  loss_ce: 2.25  loss_mask: 0.5198  loss_dice: 4.295  loss_ce_0: 1.26  loss_mask_0: 0.5206  loss_dice_0: 4.564  loss_ce_1: 2.104  loss_mask_1: 0.5203  loss_dice_1: 4.343  loss_ce_2: 2.171  loss_mask_2: 0.5215  loss_dice_2: 4.323  loss_ce_3: 2.163  loss_mask_3: 0.5198  loss_dice_3: 4.304  loss_ce_4: 2.179  loss_mask_4: 0.5177  loss_dice_4: 4.307  loss_ce_5: 2.19  loss_mask_5: 0.5213  loss_dice_5: 4.31  loss_ce_6: 2.186  loss_mask_6: 0.5205  loss_dice_6: 4.298  loss_ce_7: 2.163  loss_mask_7: 0.5229  loss_dice_7: 4.318  loss_ce_8: 2.217  loss_mask_8: 0.5237  loss_dice_8: 4.303  time: 2.1286  data_time: 0.4164  lr: 9.3634e-05  max_mem: 24483M
[01/19 16:49:59] d2.utils.events INFO:  eta: 21:51:09  iter: 2839  total_loss: 69.51  loss_ce: 2.27  loss_mask: 0.526  loss_dice: 4.265  loss_ce_0: 1.288  loss_mask_0: 0.5331  loss_dice_0: 4.556  loss_ce_1: 2.137  loss_mask_1: 0.5288  loss_dice_1: 4.319  loss_ce_2: 2.192  loss_mask_2: 0.531  loss_dice_2: 4.288  loss_ce_3: 2.182  loss_mask_3: 0.5315  loss_dice_3: 4.271  loss_ce_4: 2.214  loss_mask_4: 0.5303  loss_dice_4: 4.266  loss_ce_5: 2.232  loss_mask_5: 0.5305  loss_dice_5: 4.276  loss_ce_6: 2.213  loss_mask_6: 0.5279  loss_dice_6: 4.276  loss_ce_7: 2.185  loss_mask_7: 0.5271  loss_dice_7: 4.286  loss_ce_8: 2.247  loss_mask_8: 0.5253  loss_dice_8: 4.27  time: 2.1287  data_time: 0.4106  lr: 9.3589e-05  max_mem: 24483M
[01/19 16:50:43] d2.utils.events INFO:  eta: 21:51:13  iter: 2859  total_loss: 69.82  loss_ce: 2.254  loss_mask: 0.5239  loss_dice: 4.277  loss_ce_0: 1.274  loss_mask_0: 0.5238  loss_dice_0: 4.552  loss_ce_1: 2.087  loss_mask_1: 0.5228  loss_dice_1: 4.339  loss_ce_2: 2.171  loss_mask_2: 0.5236  loss_dice_2: 4.308  loss_ce_3: 2.185  loss_mask_3: 0.524  loss_dice_3: 4.287  loss_ce_4: 2.225  loss_mask_4: 0.5217  loss_dice_4: 4.293  loss_ce_5: 2.207  loss_mask_5: 0.5242  loss_dice_5: 4.302  loss_ce_6: 2.225  loss_mask_6: 0.523  loss_dice_6: 4.292  loss_ce_7: 2.219  loss_mask_7: 0.5267  loss_dice_7: 4.307  loss_ce_8: 2.231  loss_mask_8: 0.5257  loss_dice_8: 4.293  time: 2.1288  data_time: 0.3994  lr: 9.3544e-05  max_mem: 24483M
[01/19 16:51:26] d2.utils.events INFO:  eta: 21:50:55  iter: 2879  total_loss: 70.71  loss_ce: 2.429  loss_mask: 0.5282  loss_dice: 4.282  loss_ce_0: 1.238  loss_mask_0: 0.5289  loss_dice_0: 4.565  loss_ce_1: 2.173  loss_mask_1: 0.5296  loss_dice_1: 4.333  loss_ce_2: 2.225  loss_mask_2: 0.5275  loss_dice_2: 4.305  loss_ce_3: 2.294  loss_mask_3: 0.531  loss_dice_3: 4.295  loss_ce_4: 2.34  loss_mask_4: 0.5281  loss_dice_4: 4.29  loss_ce_5: 2.39  loss_mask_5: 0.5283  loss_dice_5: 4.296  loss_ce_6: 2.388  loss_mask_6: 0.5259  loss_dice_6: 4.291  loss_ce_7: 2.356  loss_mask_7: 0.528  loss_dice_7: 4.307  loss_ce_8: 2.391  loss_mask_8: 0.5265  loss_dice_8: 4.297  time: 2.1290  data_time: 0.4219  lr: 9.3498e-05  max_mem: 24483M
[01/19 16:52:08] d2.utils.events INFO:  eta: 21:50:27  iter: 2899  total_loss: 70.46  loss_ce: 2.338  loss_mask: 0.5257  loss_dice: 4.269  loss_ce_0: 1.272  loss_mask_0: 0.5286  loss_dice_0: 4.56  loss_ce_1: 2.208  loss_mask_1: 0.5288  loss_dice_1: 4.322  loss_ce_2: 2.289  loss_mask_2: 0.5325  loss_dice_2: 4.296  loss_ce_3: 2.334  loss_mask_3: 0.5306  loss_dice_3: 4.276  loss_ce_4: 2.343  loss_mask_4: 0.5278  loss_dice_4: 4.275  loss_ce_5: 2.327  loss_mask_5: 0.5252  loss_dice_5: 4.286  loss_ce_6: 2.3  loss_mask_6: 0.5252  loss_dice_6: 4.289  loss_ce_7: 2.313  loss_mask_7: 0.5271  loss_dice_7: 4.292  loss_ce_8: 2.331  loss_mask_8: 0.527  loss_dice_8: 4.278  time: 2.1290  data_time: 0.3978  lr: 9.3453e-05  max_mem: 24483M
[01/19 16:52:51] d2.utils.events INFO:  eta: 21:50:07  iter: 2919  total_loss: 71.14  loss_ce: 2.465  loss_mask: 0.5263  loss_dice: 4.257  loss_ce_0: 1.299  loss_mask_0: 0.5278  loss_dice_0: 4.548  loss_ce_1: 2.257  loss_mask_1: 0.525  loss_dice_1: 4.311  loss_ce_2: 2.372  loss_mask_2: 0.527  loss_dice_2: 4.273  loss_ce_3: 2.407  loss_mask_3: 0.5282  loss_dice_3: 4.26  loss_ce_4: 2.437  loss_mask_4: 0.5299  loss_dice_4: 4.259  loss_ce_5: 2.454  loss_mask_5: 0.5274  loss_dice_5: 4.265  loss_ce_6: 2.431  loss_mask_6: 0.5267  loss_dice_6: 4.269  loss_ce_7: 2.402  loss_mask_7: 0.5278  loss_dice_7: 4.275  loss_ce_8: 2.425  loss_mask_8: 0.5263  loss_dice_8: 4.266  time: 2.1290  data_time: 0.4051  lr: 9.3408e-05  max_mem: 24483M
[01/19 16:53:33] d2.utils.events INFO:  eta: 21:49:41  iter: 2939  total_loss: 70.16  loss_ce: 2.319  loss_mask: 0.5182  loss_dice: 4.299  loss_ce_0: 1.277  loss_mask_0: 0.5124  loss_dice_0: 4.562  loss_ce_1: 2.189  loss_mask_1: 0.5164  loss_dice_1: 4.338  loss_ce_2: 2.262  loss_mask_2: 0.5161  loss_dice_2: 4.31  loss_ce_3: 2.271  loss_mask_3: 0.5135  loss_dice_3: 4.302  loss_ce_4: 2.29  loss_mask_4: 0.5144  loss_dice_4: 4.3  loss_ce_5: 2.27  loss_mask_5: 0.5158  loss_dice_5: 4.297  loss_ce_6: 2.294  loss_mask_6: 0.515  loss_dice_6: 4.301  loss_ce_7: 2.25  loss_mask_7: 0.5191  loss_dice_7: 4.318  loss_ce_8: 2.272  loss_mask_8: 0.5186  loss_dice_8: 4.312  time: 2.1290  data_time: 0.4181  lr: 9.3362e-05  max_mem: 24483M
[01/19 16:54:16] d2.utils.events INFO:  eta: 21:49:10  iter: 2959  total_loss: 70.11  loss_ce: 2.317  loss_mask: 0.5223  loss_dice: 4.292  loss_ce_0: 1.281  loss_mask_0: 0.5289  loss_dice_0: 4.571  loss_ce_1: 2.131  loss_mask_1: 0.5261  loss_dice_1: 4.35  loss_ce_2: 2.228  loss_mask_2: 0.5287  loss_dice_2: 4.318  loss_ce_3: 2.231  loss_mask_3: 0.5243  loss_dice_3: 4.311  loss_ce_4: 2.27  loss_mask_4: 0.5265  loss_dice_4: 4.303  loss_ce_5: 2.27  loss_mask_5: 0.5252  loss_dice_5: 4.307  loss_ce_6: 2.275  loss_mask_6: 0.5261  loss_dice_6: 4.304  loss_ce_7: 2.262  loss_mask_7: 0.5259  loss_dice_7: 4.312  loss_ce_8: 2.254  loss_mask_8: 0.5259  loss_dice_8: 4.307  time: 2.1290  data_time: 0.3895  lr: 9.3317e-05  max_mem: 24483M
[01/19 16:54:59] d2.utils.events INFO:  eta: 21:48:13  iter: 2979  total_loss: 71.49  loss_ce: 2.451  loss_mask: 0.5173  loss_dice: 4.262  loss_ce_0: 1.282  loss_mask_0: 0.5195  loss_dice_0: 4.562  loss_ce_1: 2.272  loss_mask_1: 0.519  loss_dice_1: 4.327  loss_ce_2: 2.336  loss_mask_2: 0.523  loss_dice_2: 4.305  loss_ce_3: 2.377  loss_mask_3: 0.5228  loss_dice_3: 4.297  loss_ce_4: 2.417  loss_mask_4: 0.5212  loss_dice_4: 4.282  loss_ce_5: 2.439  loss_mask_5: 0.5186  loss_dice_5: 4.292  loss_ce_6: 2.444  loss_mask_6: 0.5204  loss_dice_6: 4.28  loss_ce_7: 2.366  loss_mask_7: 0.5182  loss_dice_7: 4.294  loss_ce_8: 2.379  loss_mask_8: 0.517  loss_dice_8: 4.285  time: 2.1289  data_time: 0.4045  lr: 9.3272e-05  max_mem: 24483M
[01/19 16:55:41] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/19 16:55:41] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 16:55:41] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 17:00:41] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 18.41470343742859, 'error_1pix': 0.81186338139422, 'error_3pix': 0.7131714223345902, 'mIoU': 1.1984276018561675, 'fwIoU': 10.4068962349541, 'IoU-0': nan, 'IoU-1': 91.80804602995116, 'IoU-2': 10.193396070058522, 'IoU-3': 20.262409346221737, 'IoU-4': 10.36608834083388, 'IoU-5': 12.634230802930688, 'IoU-6': 8.762734410591746, 'IoU-7': 3.286030181393879, 'IoU-8': 2.26573399937415, 'IoU-9': 1.074785405698293, 'IoU-10': 1.9394328276592019, 'IoU-11': 3.3320711361015674, 'IoU-12': 6.886679272432247, 'IoU-13': 3.2673855239522624, 'IoU-14': 4.100008365751522, 'IoU-15': 2.0671919349616794, 'IoU-16': 0.8694016779117094, 'IoU-17': 0.5501234868622872, 'IoU-18': 0.43592846536038754, 'IoU-19': 0.7006202178436957, 'IoU-20': 0.9354858592245543, 'IoU-21': 0.6731687481800595, 'IoU-22': 0.4817844474425779, 'IoU-23': 0.6223241234854276, 'IoU-24': 0.5788706075223408, 'IoU-25': 0.3579869355601529, 'IoU-26': 1.2636478859410347, 'IoU-27': 0.9749378532004277, 'IoU-28': 0.9323181113985864, 'IoU-29': 1.8419633905223454, 'IoU-30': 1.7276273941119868, 'IoU-31': 0.5784400318523631, 'IoU-32': 0.07294150762969696, 'IoU-33': 0.7024768604223592, 'IoU-34': 2.101239039302618, 'IoU-35': 0.10019687015432804, 'IoU-36': 0.3474779802601785, 'IoU-37': 0.056365862543736885, 'IoU-38': 0.5421089139948916, 'IoU-39': 1.5159468873105901, 'IoU-40': 1.5562957036772216, 'IoU-41': 2.0002391339233276, 'IoU-42': 2.1774021435552555, 'IoU-43': 0.18195656670840438, 'IoU-44': 0.22760594016078387, 'IoU-45': 0.5354946207213548, 'IoU-46': 0.058617266090709524, 'IoU-47': 0.4360425948070689, 'IoU-48': 0.9711968159788688, 'IoU-49': 1.7982392404675671, 'IoU-50': 0.1997051688007774, 'IoU-51': 0.1866295820073426, 'IoU-52': 0.8969147654677931, 'IoU-53': 0.7760344222569704, 'IoU-54': 0.04105128206229104, 'IoU-55': 0.0028481720437732133, 'IoU-56': 0.06930755232451472, 'IoU-57': 0.19424610365417436, 'IoU-58': 0.03881310810326372, 'IoU-59': 1.2711145804825916, 'IoU-60': 0.37508813187584245, 'IoU-61': 0.010709965432177362, 'IoU-62': 0.5437640271379685, 'IoU-63': 0.8177828856590688, 'IoU-64': 0.9263311698959898, 'IoU-65': 0.6155718132828514, 'IoU-66': 0.03416703342722734, 'IoU-67': 0.379739743484285, 'IoU-68': 0.1594136450822578, 'IoU-69': 0.02947310330204568, 'IoU-70': 0.0, 'IoU-71': 4.4064495880685686e-05, 'IoU-72': 0.0008125458865810608, 'IoU-73': 0.0716753997147013, 'IoU-74': 0.6561520091151101, 'IoU-75': 0.4284602373265321, 'IoU-76': 0.060319694380215144, 'IoU-77': 0.360748542208919, 'IoU-78': 0.27953118193554866, 'IoU-79': 0.10404249247778793, 'IoU-80': 1.7073256203722527, 'IoU-81': 0.0734339768278531, 'IoU-82': 0.013086054383238456, 'IoU-83': 0.2861696972324107, 'IoU-84': 1.4165820278151444, 'IoU-85': 0.19414908890138094, 'IoU-86': 1.6676173477662748, 'IoU-87': 0.5119617034877616, 'IoU-88': 0.2336099224206088, 'IoU-89': 0.026701019558340353, 'IoU-90': 0.010714258480904258, 'IoU-91': 0.29787134695007916, 'IoU-92': 0.0005062777740822626, 'IoU-93': 0.14101920538420062, 'IoU-94': 0.0030578484372880696, 'IoU-95': 0.0002790345095929739, 'IoU-96': 0.4690284933764056, 'IoU-97': 0.0005980785615492901, 'IoU-98': 0.0017144518570429948, 'IoU-99': 0.0709888821570499, 'IoU-100': 0.4248632099357788, 'IoU-101': 0.0, 'IoU-102': 0.012962862629925274, 'IoU-103': 0.0, 'IoU-104': 0.015937606198753965, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.022135102696581116, 'IoU-108': 0.2546393817219656, 'IoU-109': 0.054444392294643394, 'IoU-110': 0.018169565678646724, 'IoU-111': 0.13945070323864328, 'IoU-112': 0.29289629159742936, 'IoU-113': 0.46117459914737413, 'IoU-114': 0.02366589897632181, 'IoU-115': 0.0, 'IoU-116': 0.008559263871896873, 'IoU-117': 0.005964481703856172, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0465514757105155, 'IoU-121': 9.013292352897435e-05, 'IoU-122': 0.0, 'IoU-123': 0.06268650366365273, 'IoU-124': 0.0, 'IoU-125': 0.333945201931317, 'IoU-126': 0.013272665514202022, 'IoU-127': 0.0, 'IoU-128': 0.08513515330053058, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.00013592192101169405, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0004212357582822849, 'IoU-153': 0.011394314349954367, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.489094086916999, 'pACC': 12.911440149791872, 'ACC-0': nan, 'ACC-1': 95.04449618415816, 'ACC-2': 12.167686552593276, 'ACC-3': 56.830717895510354, 'ACC-4': 31.276844249380144, 'ACC-5': 25.714637422018395, 'ACC-6': 23.187378521894946, 'ACC-7': 18.550342569398108, 'ACC-8': 3.8310308949806067, 'ACC-9': 1.2124744486183259, 'ACC-10': 2.264557105648036, 'ACC-11': 32.63459418648792, 'ACC-12': 15.450142206271892, 'ACC-13': 7.876195216757287, 'ACC-14': 34.48445411875986, 'ACC-15': 5.648783611250009, 'ACC-16': 1.2545658983354575, 'ACC-17': 1.0683562145813361, 'ACC-18': 0.5179807457402908, 'ACC-19': 1.041999824996446, 'ACC-20': 1.5333556593659965, 'ACC-21': 0.8533682352536933, 'ACC-22': 0.5673927481625891, 'ACC-23': 0.748421867683037, 'ACC-24': 0.7172265614074593, 'ACC-25': 0.4047433011351127, 'ACC-26': 3.469476718771025, 'ACC-27': 1.374769612831138, 'ACC-28': 1.6317723227309682, 'ACC-29': 5.408370818543873, 'ACC-30': 3.6081667151985872, 'ACC-31': 0.7263561209249842, 'ACC-32': 0.07505256277961322, 'ACC-33': 1.0130553043334989, 'ACC-34': 6.399758175319093, 'ACC-35': 0.10540544834078118, 'ACC-36': 0.40166801012714176, 'ACC-37': 0.05761264711191692, 'ACC-38': 0.6802021062940253, 'ACC-39': 3.0796574238390857, 'ACC-40': 3.145346469439663, 'ACC-41': 7.715709092980136, 'ACC-42': 13.303248750980067, 'ACC-43': 0.19608544867866862, 'ACC-44': 0.24669481788515382, 'ACC-45': 0.7053568073612636, 'ACC-46': 0.060308517883708064, 'ACC-47': 0.5893659297945335, 'ACC-48': 2.090563262466092, 'ACC-49': 5.4897214515247414, 'ACC-50': 0.21340691817993357, 'ACC-51': 0.20328121788536854, 'ACC-52': 1.5294062926581473, 'ACC-53': 1.2291884505848905, 'ACC-54': 0.04284704707719168, 'ACC-55': 0.002852196232520978, 'ACC-56': 0.0721438982142923, 'ACC-57': 0.20821587432072464, 'ACC-58': 0.039447067784123484, 'ACC-59': 3.407987472733226, 'ACC-60': 0.5232522709497462, 'ACC-61': 0.010784381811188513, 'ACC-62': 0.8887781690165528, 'ACC-63': 2.0008167728397575, 'ACC-64': 2.648260872914117, 'ACC-65': 0.9856337174134856, 'ACC-66': 0.0351896603109282, 'ACC-67': 0.5636573973658745, 'ACC-68': 0.18291786408632058, 'ACC-69': 0.030388604474571073, 'ACC-70': 0.0, 'ACC-71': 4.410369440109112e-05, 'ACC-72': 0.0008129559792132724, 'ACC-73': 0.07451706445195705, 'ACC-74': 1.0096416375653614, 'ACC-75': 0.5255099979360932, 'ACC-76': 0.06430680190581976, 'ACC-77': 0.44684465494802894, 'ACC-78': 0.35317883132092054, 'ACC-79': 0.10981124917619288, 'ACC-80': 6.7666633750702605, 'ACC-81': 0.07695145908608923, 'ACC-82': 0.013231355883194131, 'ACC-83': 0.3850049621155251, 'ACC-84': 2.837548271733296, 'ACC-85': 0.22418462851685875, 'ACC-86': 8.359201155943927, 'ACC-87': 0.6782518946567889, 'ACC-88': 0.2815704398672473, 'ACC-89': 0.02732994158465228, 'ACC-90': 0.010799197967405963, 'ACC-91': 0.4027867399339375, 'ACC-92': 0.0005119163460435052, 'ACC-93': 0.15643988260894995, 'ACC-94': 0.0030713950337062797, 'ACC-95': 0.0002833137636974335, 'ACC-96': 0.7282923241123161, 'ACC-97': 0.0005992300065624246, 'ACC-98': 0.0017511557176407636, 'ACC-99': 0.07790763240247854, 'ACC-100': 0.6060510223030993, 'ACC-101': 0.0, 'ACC-102': 0.013117353874037153, 'ACC-103': 0.0, 'ACC-104': 0.017289294409876785, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.022219538834423368, 'ACC-108': 0.30184386751480685, 'ACC-109': 0.05754922514079007, 'ACC-110': 0.018306807030897855, 'ACC-111': 0.15845153736538592, 'ACC-112': 0.4794336350271831, 'ACC-113': 0.49543902722365846, 'ACC-114': 0.02525512965210968, 'ACC-115': 0.0, 'ACC-116': 0.00856795647163692, 'ACC-117': 0.00622826636406668, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.04981077177705858, 'ACC-121': 9.084190918806864e-05, 'ACC-122': 0.0, 'ACC-123': 0.06833850107269242, 'ACC-124': 0.0, 'ACC-125': 0.5567441804814856, 'ACC-126': 0.013945937576844963, 'ACC-127': 0.0, 'ACC-128': 0.10428215457908428, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.00013787160706591985, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0004214714410951514, 'ACC-153': 0.01156580369739277, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/19 17:00:41] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 17:00:41] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 17:00:41] d2.evaluation.testing INFO: copypaste: 18.4147,0.8119,0.7132,1.1984,10.4069,2.4891,12.9114
[01/19 17:00:41] d2.utils.events INFO:  eta: 21:47:17  iter: 2999  total_loss: 70.2  loss_ce: 2.336  loss_mask: 0.5217  loss_dice: 4.271  loss_ce_0: 1.285  loss_mask_0: 0.5282  loss_dice_0: 4.559  loss_ce_1: 2.215  loss_mask_1: 0.5227  loss_dice_1: 4.315  loss_ce_2: 2.252  loss_mask_2: 0.5219  loss_dice_2: 4.306  loss_ce_3: 2.247  loss_mask_3: 0.525  loss_dice_3: 4.291  loss_ce_4: 2.302  loss_mask_4: 0.5234  loss_dice_4: 4.28  loss_ce_5: 2.28  loss_mask_5: 0.5269  loss_dice_5: 4.28  loss_ce_6: 2.297  loss_mask_6: 0.5268  loss_dice_6: 4.276  loss_ce_7: 2.284  loss_mask_7: 0.5267  loss_dice_7: 4.292  loss_ce_8: 2.28  loss_mask_8: 0.5233  loss_dice_8: 4.286  time: 2.1288  data_time: 0.4050  lr: 9.3226e-05  max_mem: 24483M
[01/19 17:01:24] d2.utils.events INFO:  eta: 21:47:27  iter: 3019  total_loss: 71.22  loss_ce: 2.473  loss_mask: 0.5219  loss_dice: 4.272  loss_ce_0: 1.297  loss_mask_0: 0.5168  loss_dice_0: 4.558  loss_ce_1: 2.218  loss_mask_1: 0.5165  loss_dice_1: 4.332  loss_ce_2: 2.33  loss_mask_2: 0.5187  loss_dice_2: 4.298  loss_ce_3: 2.4  loss_mask_3: 0.5205  loss_dice_3: 4.285  loss_ce_4: 2.436  loss_mask_4: 0.5207  loss_dice_4: 4.284  loss_ce_5: 2.426  loss_mask_5: 0.5221  loss_dice_5: 4.293  loss_ce_6: 2.442  loss_mask_6: 0.5204  loss_dice_6: 4.284  loss_ce_7: 2.421  loss_mask_7: 0.5217  loss_dice_7: 4.297  loss_ce_8: 2.444  loss_mask_8: 0.5188  loss_dice_8: 4.278  time: 2.1289  data_time: 0.4115  lr: 9.3181e-05  max_mem: 24483M
[01/19 17:02:06] d2.utils.events INFO:  eta: 21:45:52  iter: 3039  total_loss: 70.18  loss_ce: 2.29  loss_mask: 0.5194  loss_dice: 4.287  loss_ce_0: 1.268  loss_mask_0: 0.5268  loss_dice_0: 4.57  loss_ce_1: 2.193  loss_mask_1: 0.5195  loss_dice_1: 4.34  loss_ce_2: 2.222  loss_mask_2: 0.5209  loss_dice_2: 4.306  loss_ce_3: 2.25  loss_mask_3: 0.5204  loss_dice_3: 4.303  loss_ce_4: 2.264  loss_mask_4: 0.5207  loss_dice_4: 4.292  loss_ce_5: 2.271  loss_mask_5: 0.5211  loss_dice_5: 4.305  loss_ce_6: 2.263  loss_mask_6: 0.5199  loss_dice_6: 4.295  loss_ce_7: 2.254  loss_mask_7: 0.5227  loss_dice_7: 4.304  loss_ce_8: 2.282  loss_mask_8: 0.5236  loss_dice_8: 4.301  time: 2.1289  data_time: 0.3944  lr: 9.3136e-05  max_mem: 24483M
[01/19 17:02:49] d2.utils.events INFO:  eta: 21:45:10  iter: 3059  total_loss: 71.25  loss_ce: 2.422  loss_mask: 0.5234  loss_dice: 4.29  loss_ce_0: 1.289  loss_mask_0: 0.527  loss_dice_0: 4.553  loss_ce_1: 2.2  loss_mask_1: 0.5243  loss_dice_1: 4.335  loss_ce_2: 2.327  loss_mask_2: 0.5247  loss_dice_2: 4.31  loss_ce_3: 2.35  loss_mask_3: 0.5208  loss_dice_3: 4.297  loss_ce_4: 2.352  loss_mask_4: 0.5227  loss_dice_4: 4.304  loss_ce_5: 2.41  loss_mask_5: 0.5271  loss_dice_5: 4.306  loss_ce_6: 2.406  loss_mask_6: 0.5237  loss_dice_6: 4.302  loss_ce_7: 2.367  loss_mask_7: 0.5244  loss_dice_7: 4.319  loss_ce_8: 2.385  loss_mask_8: 0.5228  loss_dice_8: 4.304  time: 2.1291  data_time: 0.4242  lr: 9.309e-05  max_mem: 24483M
[01/19 17:03:32] d2.utils.events INFO:  eta: 21:44:27  iter: 3079  total_loss: 70.85  loss_ce: 2.432  loss_mask: 0.5235  loss_dice: 4.256  loss_ce_0: 1.328  loss_mask_0: 0.5262  loss_dice_0: 4.548  loss_ce_1: 2.317  loss_mask_1: 0.5212  loss_dice_1: 4.308  loss_ce_2: 2.334  loss_mask_2: 0.5251  loss_dice_2: 4.281  loss_ce_3: 2.377  loss_mask_3: 0.5231  loss_dice_3: 4.266  loss_ce_4: 2.385  loss_mask_4: 0.5233  loss_dice_4: 4.27  loss_ce_5: 2.395  loss_mask_5: 0.5231  loss_dice_5: 4.266  loss_ce_6: 2.389  loss_mask_6: 0.5252  loss_dice_6: 4.268  loss_ce_7: 2.4  loss_mask_7: 0.5238  loss_dice_7: 4.285  loss_ce_8: 2.404  loss_mask_8: 0.5208  loss_dice_8: 4.271  time: 2.1291  data_time: 0.4018  lr: 9.3045e-05  max_mem: 24483M
