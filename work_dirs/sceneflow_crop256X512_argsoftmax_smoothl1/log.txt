[01/23 18:29:57] detectron2 INFO: Rank of current process: 0. World size: 4
[01/23 18:30:00] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/23 18:30:00] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/23 18:30:00] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/23 18:30:00] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/23 18:30:00] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/config.yaml
[01/23 18:30:00] d2.utils.env INFO: Using a generated random seed 943713
[01/23 18:31:00] detectron2 INFO: Rank of current process: 0. World size: 4
[01/23 18:31:03] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/23 18:31:03] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/23 18:31:03] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/23 18:31:03] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/23 18:31:03] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/config.yaml
[01/23 18:31:03] d2.utils.env INFO: Using a generated random seed 3949761
[01/23 18:31:04] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 0.5, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 0.5, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 0.5, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 0.5, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 0.5, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 0.5, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 0.5, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 0.5, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 0.5, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 0.5}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/23 18:31:04] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/23 18:31:09] d2.data.build INFO: Using training sampler TrainingSampler
[01/23 18:31:09] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/23 18:31:10] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/23 18:31:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/23 18:31:10] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/23 18:31:10] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/23 18:31:10] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/23 18:31:10] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/23 18:31:10] d2.engine.train_loop INFO: Starting training from iteration 0
[01/23 18:32:22] d2.utils.events INFO:  eta: 1 day, 19:32:35  iter: 19  total_loss: 121.6  loss_ce: 10.73  loss_mask: 1.941  loss_ce_0: 9.359  loss_mask_0: 1.829  loss_ce_1: 9.726  loss_mask_1: 1.862  loss_ce_2: 9.959  loss_mask_2: 1.876  loss_ce_3: 10.01  loss_mask_3: 1.905  loss_ce_4: 10.61  loss_mask_4: 1.922  loss_ce_5: 9.912  loss_mask_5: 1.933  loss_ce_6: 10.52  loss_mask_6: 1.954  loss_ce_7: 10.91  loss_mask_7: 1.953  loss_ce_8: 11.03  loss_mask_8: 1.951  time: 2.6181  data_time: 1.0120  lr: 1.9975e-06  max_mem: 18085M
[01/23 18:32:36] d2.engine.hooks INFO: Overall training speed: 23 iterations in 0:01:00 (2.6460 s / it)
[01/23 18:32:36] d2.engine.hooks INFO: Total training time: 0:01:00 (0:00:00 on hooks)
[01/23 18:32:36] d2.utils.events INFO:  eta: 1 day, 19:26:02  iter: 25  total_loss: 121.1  loss_ce: 10.61  loss_mask: 1.952  loss_ce_0: 9.354  loss_mask_0: 1.846  loss_ce_1: 9.659  loss_mask_1: 1.872  loss_ce_2: 9.896  loss_mask_2: 1.884  loss_ce_3: 9.905  loss_mask_3: 1.907  loss_ce_4: 10.51  loss_mask_4: 1.94  loss_ce_5: 9.838  loss_mask_5: 1.946  loss_ce_6: 10.41  loss_mask_6: 1.979  loss_ce_7: 10.8  loss_mask_7: 1.961  loss_ce_8: 10.92  loss_mask_8: 1.967  time: 2.5910  data_time: 0.6098  lr: 2.4967e-06  max_mem: 18085M
[01/23 18:33:02] detectron2 INFO: Rank of current process: 0. World size: 4
[01/23 18:33:05] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/23 18:33:05] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/23 18:33:05] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/23 18:33:05] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/23 18:33:05] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/config.yaml
[01/23 18:33:05] d2.utils.env INFO: Using a generated random seed 6009717
[01/23 18:33:07] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 0.5, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 0.5, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 0.5, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 0.5, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 0.5, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 0.5, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 0.5, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 0.5, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 0.5, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 0.5}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/23 18:33:08] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/23 18:33:12] d2.data.build INFO: Using training sampler TrainingSampler
[01/23 18:33:12] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/23 18:33:12] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/23 18:33:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/23 18:33:12] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/23 18:33:13] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/23 18:33:13] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/23 18:33:13] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/23 18:33:13] d2.engine.train_loop INFO: Starting training from iteration 0
[01/23 18:33:24] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 395, in run_step
    loss_dict = self.model(data)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 799, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 332, in forward
    outputs = self.sem_seg_head(features)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/modeling/meta_arch/mask_former_head.py", line 116, in forward
    return self.layers(features, mask)
  File "/home/nstarli/Mask2Former/mask2former/modeling/meta_arch/mask_former_head.py", line 121, in layers
    predictions = self.predictor(multi_scale_features, mask_features, mask)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py", line 400, in forward
    output = self.transformer_cross_attention_layers[i](
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py", line 134, in forward
    return self.forward_post(tgt, memory, memory_mask,
  File "/home/nstarli/Mask2Former/mask2former/modeling/transformer_decoder/mask2former_transformer_decoder.py", line 103, in forward_post
    tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt, query_pos),
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 1031, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/functional.py", line 5082, in multi_head_attention_forward
    attn_output, attn_output_weights = _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/functional.py", line 4828, in _scaled_dot_product_attention
    attn = softmax(attn, dim=-1)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/functional.py", line 1679, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 600.00 MiB (GPU 0; 31.75 GiB total capacity; 29.25 GiB already allocated; 495.75 MiB free; 29.83 GiB reserved in total by PyTorch)
[01/23 18:33:24] d2.engine.hooks INFO: Total training time: 0:00:11 (0:00:00 on hooks)
[01/23 18:33:24] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 30032M
[01/23 18:33:48] detectron2 INFO: Rank of current process: 0. World size: 4
[01/23 18:33:50] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/23 18:33:50] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/23 18:33:50] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/23 18:33:50] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/23 18:33:50] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/config.yaml
[01/23 18:33:50] d2.utils.env INFO: Using a generated random seed 50846071
[01/23 18:33:51] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 0.5, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 0.5, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 0.5, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 0.5, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 0.5, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 0.5, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 0.5, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 0.5, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 0.5, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 0.5}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/23 18:33:51] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/23 18:33:56] d2.data.build INFO: Using training sampler TrainingSampler
[01/23 18:33:57] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/23 18:33:57] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/23 18:33:57] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/23 18:33:57] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/23 18:33:57] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/23 18:33:57] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/23 18:33:57] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/23 18:33:57] d2.engine.train_loop INFO: Starting training from iteration 0
[01/23 18:35:07] d2.utils.events INFO:  eta: 1 day, 17:25:21  iter: 19  total_loss: 124.8  loss_ce: 10.72  loss_mask: 1.949  loss_ce_0: 9.484  loss_mask_0: 1.841  loss_ce_1: 9.721  loss_mask_1: 1.862  loss_ce_2: 10.51  loss_mask_2: 1.884  loss_ce_3: 10.75  loss_mask_3: 1.926  loss_ce_4: 11.05  loss_mask_4: 1.927  loss_ce_5: 10.88  loss_mask_5: 1.948  loss_ce_6: 11.05  loss_mask_6: 1.953  loss_ce_7: 10.77  loss_mask_7: 1.941  loss_ce_8: 10.71  loss_mask_8: 1.968  time: 2.5157  data_time: 0.9621  lr: 1.9975e-06  max_mem: 17983M
[01/23 18:35:57] d2.utils.events INFO:  eta: 1 day, 16:51:26  iter: 39  total_loss: 120.3  loss_ce: 10.21  loss_mask: 2.041  loss_ce_0: 9.511  loss_mask_0: 1.91  loss_ce_1: 9.421  loss_mask_1: 1.934  loss_ce_2: 10.04  loss_mask_2: 1.949  loss_ce_3: 10.15  loss_mask_3: 2.022  loss_ce_4: 10.41  loss_mask_4: 2.04  loss_ce_5: 10.15  loss_mask_5: 2.027  loss_ce_6: 10.33  loss_mask_6: 2.038  loss_ce_7: 9.904  loss_mask_7: 2.026  loss_ce_8: 10.02  loss_mask_8: 2.048  time: 2.4912  data_time: 0.5404  lr: 3.9938e-06  max_mem: 18004M
[01/23 18:36:48] d2.utils.events INFO:  eta: 1 day, 17:26:40  iter: 59  total_loss: 112.2  loss_ce: 9.436  loss_mask: 1.965  loss_ce_0: 9.499  loss_mask_0: 1.805  loss_ce_1: 8.893  loss_mask_1: 1.851  loss_ce_2: 9.172  loss_mask_2: 1.87  loss_ce_3: 9.173  loss_mask_3: 1.913  loss_ce_4: 9.323  loss_mask_4: 1.933  loss_ce_5: 9.279  loss_mask_5: 1.967  loss_ce_6: 9.368  loss_mask_6: 1.957  loss_ce_7: 9.209  loss_mask_7: 1.963  loss_ce_8: 9.241  loss_mask_8: 1.962  time: 2.5230  data_time: 0.6025  lr: 5.9888e-06  max_mem: 18166M
[01/23 18:37:40] d2.utils.events INFO:  eta: 1 day, 17:35:37  iter: 79  total_loss: 108.9  loss_ce: 9.042  loss_mask: 2.036  loss_ce_0: 9.511  loss_mask_0: 1.829  loss_ce_1: 8.523  loss_mask_1: 1.886  loss_ce_2: 8.625  loss_mask_2: 1.902  loss_ce_3: 8.819  loss_mask_3: 1.94  loss_ce_4: 8.83  loss_mask_4: 1.986  loss_ce_5: 8.924  loss_mask_5: 2.004  loss_ce_6: 8.985  loss_mask_6: 2.032  loss_ce_7: 8.984  loss_mask_7: 2.018  loss_ce_8: 8.999  loss_mask_8: 2.041  time: 2.5382  data_time: 0.5786  lr: 7.9826e-06  max_mem: 18166M
[01/23 18:38:32] d2.utils.events INFO:  eta: 1 day, 18:11:01  iter: 99  total_loss: 104.5  loss_ce: 8.801  loss_mask: 1.926  loss_ce_0: 9.544  loss_mask_0: 1.685  loss_ce_1: 8.355  loss_mask_1: 1.659  loss_ce_2: 8.393  loss_mask_2: 1.666  loss_ce_3: 8.515  loss_mask_3: 1.683  loss_ce_4: 8.436  loss_mask_4: 1.729  loss_ce_5: 8.503  loss_mask_5: 1.74  loss_ce_6: 8.608  loss_mask_6: 1.822  loss_ce_7: 8.648  loss_mask_7: 1.888  loss_ce_8: 8.727  loss_mask_8: 1.927  time: 2.5468  data_time: 0.6185  lr: 9.9753e-06  max_mem: 18244M
[01/23 18:39:21] d2.utils.events INFO:  eta: 1 day, 18:00:32  iter: 119  total_loss: 98.68  loss_ce: 8.45  loss_mask: 1.57  loss_ce_0: 9.662  loss_mask_0: 1.554  loss_ce_1: 8.263  loss_mask_1: 1.44  loss_ce_2: 8.26  loss_mask_2: 1.375  loss_ce_3: 8.311  loss_mask_3: 1.353  loss_ce_4: 8.196  loss_mask_4: 1.346  loss_ce_5: 8.208  loss_mask_5: 1.338  loss_ce_6: 8.273  loss_mask_6: 1.356  loss_ce_7: 8.302  loss_mask_7: 1.412  loss_ce_8: 8.366  loss_mask_8: 1.473  time: 2.5347  data_time: 0.5620  lr: 1.1967e-05  max_mem: 18244M
[01/23 18:40:09] d2.utils.events INFO:  eta: 1 day, 17:28:13  iter: 139  total_loss: 94.77  loss_ce: 8.017  loss_mask: 1.38  loss_ce_0: 9.678  loss_mask_0: 1.475  loss_ce_1: 8.181  loss_mask_1: 1.305  loss_ce_2: 8.032  loss_mask_2: 1.265  loss_ce_3: 8.023  loss_mask_3: 1.295  loss_ce_4: 7.906  loss_mask_4: 1.295  loss_ce_5: 7.833  loss_mask_5: 1.286  loss_ce_6: 7.87  loss_mask_6: 1.255  loss_ce_7: 7.862  loss_mask_7: 1.291  loss_ce_8: 7.913  loss_mask_8: 1.322  time: 2.5175  data_time: 0.5097  lr: 1.3957e-05  max_mem: 18244M
[01/23 18:41:00] d2.utils.events INFO:  eta: 1 day, 17:35:07  iter: 159  total_loss: 92.75  loss_ce: 8.126  loss_mask: 1.294  loss_ce_0: 9.681  loss_mask_0: 1.387  loss_ce_1: 8.048  loss_mask_1: 1.266  loss_ce_2: 7.844  loss_mask_2: 1.212  loss_ce_3: 7.82  loss_mask_3: 1.222  loss_ce_4: 7.713  loss_mask_4: 1.234  loss_ce_5: 7.682  loss_mask_5: 1.255  loss_ce_6: 7.734  loss_mask_6: 1.229  loss_ce_7: 7.816  loss_mask_7: 1.244  loss_ce_8: 7.937  loss_mask_8: 1.254  time: 2.5197  data_time: 0.5898  lr: 1.5946e-05  max_mem: 18244M
[01/23 18:41:52] d2.utils.events INFO:  eta: 1 day, 17:59:48  iter: 179  total_loss: 92.18  loss_ce: 8.053  loss_mask: 1.239  loss_ce_0: 9.653  loss_mask_0: 1.286  loss_ce_1: 7.987  loss_mask_1: 1.213  loss_ce_2: 7.748  loss_mask_2: 1.209  loss_ce_3: 7.691  loss_mask_3: 1.204  loss_ce_4: 7.594  loss_mask_4: 1.207  loss_ce_5: 7.566  loss_mask_5: 1.193  loss_ce_6: 7.655  loss_mask_6: 1.224  loss_ce_7: 7.799  loss_mask_7: 1.208  loss_ce_8: 7.945  loss_mask_8: 1.233  time: 2.5257  data_time: 0.5890  lr: 1.7934e-05  max_mem: 18244M
[01/23 18:42:44] d2.utils.events INFO:  eta: 1 day, 18:04:19  iter: 199  total_loss: 90.23  loss_ce: 7.833  loss_mask: 1.194  loss_ce_0: 9.67  loss_mask_0: 1.246  loss_ce_1: 7.91  loss_mask_1: 1.176  loss_ce_2: 7.684  loss_mask_2: 1.164  loss_ce_3: 7.615  loss_mask_3: 1.157  loss_ce_4: 7.513  loss_mask_4: 1.149  loss_ce_5: 7.489  loss_mask_5: 1.159  loss_ce_6: 7.533  loss_mask_6: 1.174  loss_ce_7: 7.598  loss_mask_7: 1.162  loss_ce_8: 7.684  loss_mask_8: 1.153  time: 2.5334  data_time: 0.5550  lr: 1.992e-05  max_mem: 18244M
[01/23 18:43:35] d2.utils.events INFO:  eta: 1 day, 18:02:07  iter: 219  total_loss: 88.66  loss_ce: 7.601  loss_mask: 1.144  loss_ce_0: 9.675  loss_mask_0: 1.169  loss_ce_1: 7.856  loss_mask_1: 1.155  loss_ce_2: 7.606  loss_mask_2: 1.125  loss_ce_3: 7.526  loss_mask_3: 1.132  loss_ce_4: 7.411  loss_mask_4: 1.128  loss_ce_5: 7.34  loss_mask_5: 1.151  loss_ce_6: 7.347  loss_mask_6: 1.151  loss_ce_7: 7.367  loss_mask_7: 1.164  loss_ce_8: 7.472  loss_mask_8: 1.134  time: 2.5345  data_time: 0.5786  lr: 2.1906e-05  max_mem: 18244M
[01/23 18:44:26] d2.utils.events INFO:  eta: 1 day, 18:01:17  iter: 239  total_loss: 88.56  loss_ce: 7.604  loss_mask: 1.172  loss_ce_0: 9.687  loss_mask_0: 1.213  loss_ce_1: 7.721  loss_mask_1: 1.192  loss_ce_2: 7.476  loss_mask_2: 1.158  loss_ce_3: 7.385  loss_mask_3: 1.16  loss_ce_4: 7.263  loss_mask_4: 1.169  loss_ce_5: 7.248  loss_mask_5: 1.176  loss_ce_6: 7.275  loss_mask_6: 1.185  loss_ce_7: 7.294  loss_mask_7: 1.171  loss_ce_8: 7.385  loss_mask_8: 1.174  time: 2.5363  data_time: 0.5661  lr: 2.389e-05  max_mem: 18244M
[01/23 18:45:17] d2.utils.events INFO:  eta: 1 day, 18:03:00  iter: 259  total_loss: 87.47  loss_ce: 7.585  loss_mask: 1.089  loss_ce_0: 9.653  loss_mask_0: 1.135  loss_ce_1: 7.73  loss_mask_1: 1.083  loss_ce_2: 7.48  loss_mask_2: 1.083  loss_ce_3: 7.422  loss_mask_3: 1.076  loss_ce_4: 7.369  loss_mask_4: 1.104  loss_ce_5: 7.315  loss_mask_5: 1.072  loss_ce_6: 7.326  loss_mask_6: 1.068  loss_ce_7: 7.314  loss_mask_7: 1.071  loss_ce_8: 7.405  loss_mask_8: 1.058  time: 2.5384  data_time: 0.5444  lr: 2.5873e-05  max_mem: 18244M
[01/23 18:46:07] d2.utils.events INFO:  eta: 1 day, 18:00:52  iter: 279  total_loss: 90.77  loss_ce: 8.26  loss_mask: 1.155  loss_ce_0: 9.691  loss_mask_0: 1.161  loss_ce_1: 7.645  loss_mask_1: 1.187  loss_ce_2: 7.593  loss_mask_2: 1.148  loss_ce_3: 7.993  loss_mask_3: 1.147  loss_ce_4: 7.846  loss_mask_4: 1.117  loss_ce_5: 7.624  loss_mask_5: 1.116  loss_ce_6: 7.569  loss_mask_6: 1.164  loss_ce_7: 7.614  loss_mask_7: 1.118  loss_ce_8: 7.687  loss_mask_8: 1.124  time: 2.5340  data_time: 0.5255  lr: 2.7855e-05  max_mem: 18244M
[01/23 18:46:58] d2.utils.events INFO:  eta: 1 day, 18:01:10  iter: 299  total_loss: 95.4  loss_ce: 8.495  loss_mask: 1.118  loss_ce_0: 9.627  loss_mask_0: 1.134  loss_ce_1: 8.435  loss_mask_1: 1.168  loss_ce_2: 8.135  loss_mask_2: 1.101  loss_ce_3: 8.01  loss_mask_3: 1.129  loss_ce_4: 8.17  loss_mask_4: 1.142  loss_ce_5: 8.311  loss_mask_5: 1.166  loss_ce_6: 8.417  loss_mask_6: 1.134  loss_ce_7: 8.356  loss_mask_7: 1.135  loss_ce_8: 8.31  loss_mask_8: 1.121  time: 2.5353  data_time: 0.5414  lr: 2.9836e-05  max_mem: 18244M
[01/23 18:47:50] d2.utils.events INFO:  eta: 1 day, 18:01:24  iter: 319  total_loss: 93.07  loss_ce: 8.137  loss_mask: 1.104  loss_ce_0: 9.626  loss_mask_0: 1.061  loss_ce_1: 8.198  loss_mask_1: 1.066  loss_ce_2: 7.875  loss_mask_2: 1.092  loss_ce_3: 7.834  loss_mask_3: 1.09  loss_ce_4: 7.855  loss_mask_4: 1.12  loss_ce_5: 8.065  loss_mask_5: 1.081  loss_ce_6: 8.217  loss_mask_6: 1.099  loss_ce_7: 8.281  loss_mask_7: 1.104  loss_ce_8: 8.263  loss_mask_8: 1.113  time: 2.5413  data_time: 0.6004  lr: 3.1815e-05  max_mem: 18244M
[01/23 18:48:32] d2.engine.hooks INFO: Overall training speed: 333 iterations in 0:14:09 (2.5513 s / it)
[01/23 18:48:32] d2.engine.hooks INFO: Total training time: 0:14:10 (0:00:00 on hooks)
[01/23 18:48:32] d2.utils.events INFO:  eta: 1 day, 18:01:59  iter: 335  total_loss: 91.73  loss_ce: 7.997  loss_mask: 1.027  loss_ce_0: 9.655  loss_mask_0: 0.9816  loss_ce_1: 8.035  loss_mask_1: 0.9752  loss_ce_2: 7.72  loss_mask_2: 1.022  loss_ce_3: 7.687  loss_mask_3: 0.9855  loss_ce_4: 7.796  loss_mask_4: 1.005  loss_ce_5: 8.043  loss_mask_5: 1.003  loss_ce_6: 8.231  loss_mask_6: 1.02  loss_ce_7: 8.142  loss_mask_7: 1.037  loss_ce_8: 8.009  loss_mask_8: 1.028  time: 2.5460  data_time: 0.6049  lr: 3.3299e-05  max_mem: 18244M
[01/23 18:52:37] detectron2 INFO: Rank of current process: 0. World size: 1
[01/23 18:52:40] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/23 18:52:40] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/23 18:52:40] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/23 18:52:41] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/23 18:52:41] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/config.yaml
[01/23 18:52:41] d2.utils.env INFO: Using a generated random seed 41579394
[01/23 18:52:46] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/23 18:52:47] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/23 18:52:59] d2.data.build INFO: Using training sampler TrainingSampler
[01/23 18:52:59] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/23 18:52:59] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/23 18:52:59] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/23 18:52:59] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/23 18:53:00] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/23 18:53:00] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/23 18:53:00] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/23 18:53:00] d2.engine.train_loop INFO: Starting training from iteration 0
[01/23 19:04:41] detectron2 INFO: Rank of current process: 0. World size: 1
[01/23 19:04:43] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/23 19:04:43] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/23 19:04:43] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/23 19:04:44] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/23 19:04:44] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/config.yaml
[01/23 19:04:44] d2.utils.env INFO: Using a generated random seed 44506903
[01/23 19:04:50] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/23 19:04:50] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/23 19:05:02] d2.data.build INFO: Using training sampler TrainingSampler
[01/23 19:05:02] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/23 19:05:03] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/23 19:05:03] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/23 19:05:03] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/23 19:05:03] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/23 19:05:03] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/23 19:05:03] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/23 19:05:03] d2.engine.train_loop INFO: Starting training from iteration 0
[01/23 19:11:05] detectron2 INFO: Rank of current process: 0. World size: 4
[01/23 19:11:08] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/23 19:11:08] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/23 19:11:08] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/23 19:11:08] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/23 19:11:08] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/config.yaml
[01/23 19:11:08] d2.utils.env INFO: Using a generated random seed 8911953
[01/23 19:11:09] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 5.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 1.0, 'loss_mask': 5.0, 'loss_ce_0': 1.0, 'loss_mask_0': 5.0, 'loss_ce_1': 1.0, 'loss_mask_1': 5.0, 'loss_ce_2': 1.0, 'loss_mask_2': 5.0, 'loss_ce_3': 1.0, 'loss_mask_3': 5.0, 'loss_ce_4': 1.0, 'loss_mask_4': 5.0, 'loss_ce_5': 1.0, 'loss_mask_5': 5.0, 'loss_ce_6': 1.0, 'loss_mask_6': 5.0, 'loss_ce_7': 1.0, 'loss_mask_7': 5.0, 'loss_ce_8': 1.0, 'loss_mask_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/23 19:11:09] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/23 19:11:14] d2.data.build INFO: Using training sampler TrainingSampler
[01/23 19:11:14] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/23 19:11:14] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/23 19:11:14] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/23 19:11:14] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/23 19:11:14] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/23 19:11:14] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/23 19:11:14] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/23 19:11:14] d2.engine.train_loop INFO: Starting training from iteration 0
[01/23 19:11:31] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 395, in run_step
    loss_dict = self.model(data)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 799, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 343, in forward
    losses = self.criterion(outputs, targets)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/modeling/criterion.py", line 259, in forward
    losses.update(self.get_loss(loss, outputs, targets, indices, num_masks))
  File "/home/nstarli/Mask2Former/mask2former/modeling/criterion.py", line 233, in get_loss
    return loss_map[loss](outputs, targets, indices, num_masks)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 124, in loss_masks
    "loss_mask": smooth_l1_loss(src_masks, target_masks, num_masks),
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 46, in smooth_l1_loss
    loss = F.smooth_l1_loss(inputs, targets, beta=1.0, reduction="mean")
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/functional.py", line 2997, in smooth_l1_loss
    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/functional.py", line 73, in broadcast_tensors
    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
RuntimeError: The size of tensor a (128) must match the size of tensor b (512) at non-singleton dimension 3
[01/23 19:11:31] d2.engine.hooks INFO: Total training time: 0:00:17 (0:00:00 on hooks)
[01/23 19:11:31] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 16740M
[01/23 19:26:52] detectron2 INFO: Rank of current process: 0. World size: 4
[01/23 19:26:56] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/23 19:26:56] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/23 19:26:56] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/23 19:26:56] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/23 19:26:56] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/config.yaml
[01/23 19:26:56] d2.utils.env INFO: Using a generated random seed 56673516
[01/23 19:26:57] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 5.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 1.0, 'loss_mask': 5.0, 'loss_ce_0': 1.0, 'loss_mask_0': 5.0, 'loss_ce_1': 1.0, 'loss_mask_1': 5.0, 'loss_ce_2': 1.0, 'loss_mask_2': 5.0, 'loss_ce_3': 1.0, 'loss_mask_3': 5.0, 'loss_ce_4': 1.0, 'loss_mask_4': 5.0, 'loss_ce_5': 1.0, 'loss_mask_5': 5.0, 'loss_ce_6': 1.0, 'loss_mask_6': 5.0, 'loss_ce_7': 1.0, 'loss_mask_7': 5.0, 'loss_ce_8': 1.0, 'loss_mask_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/23 19:26:57] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/23 19:27:02] d2.data.build INFO: Using training sampler TrainingSampler
[01/23 19:27:02] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/23 19:27:04] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/23 19:27:05] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/23 19:27:05] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/23 19:27:05] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/23 19:27:05] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/23 19:27:05] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/23 19:27:05] d2.engine.train_loop INFO: Starting training from iteration 0
[01/23 19:28:13] d2.utils.events INFO:  eta: 1 day, 15:29:29  iter: 19  total_loss: 1377  loss_ce: 5.318  loss_mask: 135.1  loss_ce_0: 4.867  loss_mask_0: 126.7  loss_ce_1: 4.935  loss_mask_1: 129.4  loss_ce_2: 5.022  loss_mask_2: 130.3  loss_ce_3: 5.404  loss_mask_3: 132.3  loss_ce_4: 5.434  loss_mask_4: 133.3  loss_ce_5: 5.617  loss_mask_5: 133.4  loss_ce_6: 5.531  loss_mask_6: 134.3  loss_ce_7: 5.565  loss_mask_7: 134.6  loss_ce_8: 5.517  loss_mask_8: 135  time: 2.3868  data_time: 0.8478  lr: 1.9975e-06  max_mem: 18196M
[01/23 19:29:00] d2.utils.events INFO:  eta: 1 day, 15:27:25  iter: 39  total_loss: 1342  loss_ce: 5.244  loss_mask: 133.7  loss_ce_0: 4.871  loss_mask_0: 122.2  loss_ce_1: 4.934  loss_mask_1: 125.2  loss_ce_2: 4.992  loss_mask_2: 124.8  loss_ce_3: 5.316  loss_mask_3: 128.5  loss_ce_4: 5.342  loss_mask_4: 129.5  loss_ce_5: 5.544  loss_mask_5: 129.1  loss_ce_6: 5.474  loss_mask_6: 132  loss_ce_7: 5.424  loss_mask_7: 132.1  loss_ce_8: 5.408  loss_mask_8: 133.9  time: 2.3686  data_time: 0.4288  lr: 3.9938e-06  max_mem: 18208M
[01/23 19:29:48] d2.utils.events INFO:  eta: 1 day, 15:31:06  iter: 59  total_loss: 1238  loss_ce: 5.072  loss_mask: 129.2  loss_ce_0: 4.901  loss_mask_0: 116.6  loss_ce_1: 4.965  loss_mask_1: 119.9  loss_ce_2: 4.977  loss_mask_2: 116.9  loss_ce_3: 5.205  loss_mask_3: 120.8  loss_ce_4: 5.19  loss_mask_4: 114.8  loss_ce_5: 5.406  loss_mask_5: 108.8  loss_ce_6: 5.332  loss_mask_6: 118.6  loss_ce_7: 5.192  loss_mask_7: 119.3  loss_ce_8: 5.21  loss_mask_8: 132.2  time: 2.3773  data_time: 0.4795  lr: 5.9888e-06  max_mem: 18315M
[01/23 19:30:33] d2.utils.events INFO:  eta: 1 day, 14:56:01  iter: 79  total_loss: 1110  loss_ce: 4.916  loss_mask: 107.2  loss_ce_0: 4.903  loss_mask_0: 109.7  loss_ce_1: 5.006  loss_mask_1: 112.8  loss_ce_2: 4.961  loss_mask_2: 106.3  loss_ce_3: 5.084  loss_mask_3: 109.4  loss_ce_4: 5.024  loss_mask_4: 101.3  loss_ce_5: 5.225  loss_mask_5: 97.18  loss_ce_6: 5.172  loss_mask_6: 99.48  loss_ce_7: 5.035  loss_mask_7: 100.1  loss_ce_8: 5.091  loss_mask_8: 110.8  time: 2.3428  data_time: 0.4308  lr: 7.9826e-06  max_mem: 18315M
[01/23 19:31:15] d2.utils.events INFO:  eta: 1 day, 14:12:59  iter: 99  total_loss: 969.6  loss_ce: 4.946  loss_mask: 91.76  loss_ce_0: 4.925  loss_mask_0: 100.4  loss_ce_1: 5.03  loss_mask_1: 97.24  loss_ce_2: 4.977  loss_mask_2: 88.85  loss_ce_3: 5.052  loss_mask_3: 88.68  loss_ce_4: 4.963  loss_mask_4: 88.37  loss_ce_5: 5.15  loss_mask_5: 88.75  loss_ce_6: 5.151  loss_mask_6: 90.09  loss_ce_7: 4.973  loss_mask_7: 91.75  loss_ce_8: 5.036  loss_mask_8: 90.55  time: 2.3028  data_time: 0.4509  lr: 9.9753e-06  max_mem: 18315M
[01/23 19:32:00] d2.utils.events INFO:  eta: 1 day, 14:01:17  iter: 119  total_loss: 936.9  loss_ce: 4.87  loss_mask: 90.41  loss_ce_0: 4.957  loss_mask_0: 96.55  loss_ce_1: 5.015  loss_mask_1: 92.11  loss_ce_2: 4.962  loss_mask_2: 86.24  loss_ce_3: 5.078  loss_mask_3: 85.75  loss_ce_4: 4.955  loss_mask_4: 86.64  loss_ce_5: 5.099  loss_mask_5: 87.05  loss_ce_6: 5.076  loss_mask_6: 85.81  loss_ce_7: 4.878  loss_mask_7: 86.76  loss_ce_8: 4.979  loss_mask_8: 88.42  time: 2.2858  data_time: 0.4466  lr: 1.1967e-05  max_mem: 18315M
[01/23 19:32:46] d2.utils.events INFO:  eta: 1 day, 14:01:13  iter: 139  total_loss: 920.7  loss_ce: 4.845  loss_mask: 84.85  loss_ce_0: 4.952  loss_mask_0: 96.81  loss_ce_1: 5.023  loss_mask_1: 93.22  loss_ce_2: 4.979  loss_mask_2: 86.97  loss_ce_3: 5.007  loss_mask_3: 88.23  loss_ce_4: 4.912  loss_mask_4: 85.34  loss_ce_5: 5.077  loss_mask_5: 84.12  loss_ce_6: 5.063  loss_mask_6: 84.28  loss_ce_7: 4.907  loss_mask_7: 83.9  loss_ce_8: 4.953  loss_mask_8: 85.14  time: 2.2891  data_time: 0.4600  lr: 1.3957e-05  max_mem: 18315M
[01/23 19:33:34] d2.utils.events INFO:  eta: 1 day, 14:13:36  iter: 159  total_loss: 974.4  loss_ce: 4.793  loss_mask: 90.94  loss_ce_0: 4.965  loss_mask_0: 94.48  loss_ce_1: 5.059  loss_mask_1: 89.85  loss_ce_2: 4.994  loss_mask_2: 88.12  loss_ce_3: 5.049  loss_mask_3: 91.34  loss_ce_4: 5.025  loss_mask_4: 94.77  loss_ce_5: 5.168  loss_mask_5: 94.22  loss_ce_6: 5.117  loss_mask_6: 94.66  loss_ce_7: 4.979  loss_mask_7: 92.97  loss_ce_8: 5.027  loss_mask_8: 92.7  time: 2.3055  data_time: 0.4469  lr: 1.5946e-05  max_mem: 18315M
[01/23 19:34:22] d2.utils.events INFO:  eta: 1 day, 14:18:36  iter: 179  total_loss: 861.1  loss_ce: 4.778  loss_mask: 79.4  loss_ce_0: 4.95  loss_mask_0: 85.49  loss_ce_1: 5.062  loss_mask_1: 81.96  loss_ce_2: 5.006  loss_mask_2: 80.44  loss_ce_3: 5.049  loss_mask_3: 82.45  loss_ce_4: 5.018  loss_mask_4: 82.17  loss_ce_5: 5.165  loss_mask_5: 80.47  loss_ce_6: 5.048  loss_mask_6: 80.05  loss_ce_7: 4.897  loss_mask_7: 80.6  loss_ce_8: 4.928  loss_mask_8: 81.17  time: 2.3131  data_time: 0.4293  lr: 1.7934e-05  max_mem: 18315M
[01/23 19:35:10] d2.utils.events INFO:  eta: 1 day, 14:31:06  iter: 199  total_loss: 930  loss_ce: 4.986  loss_mask: 94.42  loss_ce_0: 4.954  loss_mask_0: 82.07  loss_ce_1: 5.077  loss_mask_1: 78.58  loss_ce_2: 5.056  loss_mask_2: 76.93  loss_ce_3: 5.107  loss_mask_3: 82.14  loss_ce_4: 5.147  loss_mask_4: 89.57  loss_ce_5: 5.304  loss_mask_5: 91.62  loss_ce_6: 5.341  loss_mask_6: 95.02  loss_ce_7: 5.208  loss_mask_7: 94.2  loss_ce_8: 5.264  loss_mask_8: 94.69  time: 2.3244  data_time: 0.4327  lr: 1.992e-05  max_mem: 18315M
[01/23 19:35:59] d2.utils.events INFO:  eta: 1 day, 14:40:17  iter: 219  total_loss: 795.8  loss_ce: 4.76  loss_mask: 74.59  loss_ce_0: 4.96  loss_mask_0: 81.89  loss_ce_1: 5.045  loss_mask_1: 74.49  loss_ce_2: 4.99  loss_mask_2: 74.18  loss_ce_3: 4.938  loss_mask_3: 74.01  loss_ce_4: 4.929  loss_mask_4: 73.59  loss_ce_5: 5.052  loss_mask_5: 72.87  loss_ce_6: 4.995  loss_mask_6: 73.69  loss_ce_7: 4.818  loss_mask_7: 74.84  loss_ce_8: 4.799  loss_mask_8: 75.02  time: 2.3341  data_time: 0.4390  lr: 2.1906e-05  max_mem: 18322M
[01/23 19:36:47] d2.utils.events INFO:  eta: 1 day, 14:49:47  iter: 239  total_loss: 735.7  loss_ce: 4.717  loss_mask: 68.52  loss_ce_0: 4.989  loss_mask_0: 75.41  loss_ce_1: 4.996  loss_mask_1: 67.4  loss_ce_2: 4.94  loss_mask_2: 66.49  loss_ce_3: 4.944  loss_mask_3: 67.76  loss_ce_4: 4.905  loss_mask_4: 68.64  loss_ce_5: 4.988  loss_mask_5: 67.42  loss_ce_6: 4.915  loss_mask_6: 68.28  loss_ce_7: 4.804  loss_mask_7: 68.98  loss_ce_8: 4.777  loss_mask_8: 68.72  time: 2.3414  data_time: 0.4662  lr: 2.389e-05  max_mem: 18322M
[01/23 19:37:35] d2.utils.events INFO:  eta: 1 day, 14:54:13  iter: 259  total_loss: 744.2  loss_ce: 4.61  loss_mask: 70.21  loss_ce_0: 4.997  loss_mask_0: 73.56  loss_ce_1: 4.975  loss_mask_1: 67.1  loss_ce_2: 4.923  loss_mask_2: 66.94  loss_ce_3: 4.913  loss_mask_3: 68.98  loss_ce_4: 4.842  loss_mask_4: 68.96  loss_ce_5: 4.927  loss_mask_5: 68.45  loss_ce_6: 4.802  loss_mask_6: 69.15  loss_ce_7: 4.667  loss_mask_7: 69.36  loss_ce_8: 4.627  loss_mask_8: 69.6  time: 2.3463  data_time: 0.4293  lr: 2.5873e-05  max_mem: 18322M
[01/23 19:38:25] d2.utils.events INFO:  eta: 1 day, 15:03:03  iter: 279  total_loss: 713.3  loss_ce: 4.608  loss_mask: 66.71  loss_ce_0: 5.006  loss_mask_0: 68.17  loss_ce_1: 4.95  loss_mask_1: 66.4  loss_ce_2: 4.906  loss_mask_2: 72  loss_ce_3: 4.9  loss_mask_3: 65.85  loss_ce_4: 4.801  loss_mask_4: 66.6  loss_ce_5: 4.976  loss_mask_5: 65.67  loss_ce_6: 4.879  loss_mask_6: 65.52  loss_ce_7: 4.717  loss_mask_7: 64.92  loss_ce_8: 4.639  loss_mask_8: 65.49  time: 2.3574  data_time: 0.4590  lr: 2.7855e-05  max_mem: 18322M
[01/23 19:39:16] d2.utils.events INFO:  eta: 1 day, 15:16:36  iter: 299  total_loss: 729.6  loss_ce: 4.643  loss_mask: 67.87  loss_ce_0: 4.997  loss_mask_0: 69.62  loss_ce_1: 4.935  loss_mask_1: 69.54  loss_ce_2: 4.961  loss_mask_2: 68.79  loss_ce_3: 4.985  loss_mask_3: 65.34  loss_ce_4: 4.819  loss_mask_4: 66.56  loss_ce_5: 4.893  loss_mask_5: 66.6  loss_ce_6: 4.787  loss_mask_6: 66.74  loss_ce_7: 4.677  loss_mask_7: 66.36  loss_ce_8: 4.656  loss_mask_8: 66.71  time: 2.3681  data_time: 0.4634  lr: 2.9836e-05  max_mem: 18322M
[01/23 19:40:06] d2.utils.events INFO:  eta: 1 day, 15:20:47  iter: 319  total_loss: 706.8  loss_ce: 4.695  loss_mask: 67.2  loss_ce_0: 4.995  loss_mask_0: 67.28  loss_ce_1: 4.961  loss_mask_1: 64.62  loss_ce_2: 4.959  loss_mask_2: 65.57  loss_ce_3: 4.982  loss_mask_3: 64.21  loss_ce_4: 4.839  loss_mask_4: 63.84  loss_ce_5: 4.806  loss_mask_5: 63.72  loss_ce_6: 4.784  loss_mask_6: 66.36  loss_ce_7: 4.724  loss_mask_7: 66.77  loss_ce_8: 4.738  loss_mask_8: 67.46  time: 2.3754  data_time: 0.4544  lr: 3.1815e-05  max_mem: 18322M
[01/23 19:40:54] d2.utils.events INFO:  eta: 1 day, 15:21:45  iter: 339  total_loss: 639.9  loss_ce: 4.75  loss_mask: 60  loss_ce_0: 5.024  loss_mask_0: 61.78  loss_ce_1: 4.944  loss_mask_1: 57.94  loss_ce_2: 4.893  loss_mask_2: 58.41  loss_ce_3: 4.825  loss_mask_3: 57.95  loss_ce_4: 4.756  loss_mask_4: 58.45  loss_ce_5: 4.751  loss_mask_5: 57.76  loss_ce_6: 4.77  loss_mask_6: 59.96  loss_ce_7: 4.728  loss_mask_7: 58.56  loss_ce_8: 4.797  loss_mask_8: 58.99  time: 2.3790  data_time: 0.4310  lr: 3.3793e-05  max_mem: 18322M
[01/23 19:41:44] d2.utils.events INFO:  eta: 1 day, 15:27:33  iter: 359  total_loss: 643.1  loss_ce: 4.651  loss_mask: 61.16  loss_ce_0: 5.006  loss_mask_0: 61.44  loss_ce_1: 4.932  loss_mask_1: 57.57  loss_ce_2: 4.905  loss_mask_2: 57.97  loss_ce_3: 4.942  loss_mask_3: 58.41  loss_ce_4: 4.813  loss_mask_4: 58.88  loss_ce_5: 4.844  loss_mask_5: 59.81  loss_ce_6: 4.833  loss_mask_6: 61  loss_ce_7: 4.753  loss_mask_7: 60.66  loss_ce_8: 4.678  loss_mask_8: 60.65  time: 2.3847  data_time: 0.4425  lr: 3.577e-05  max_mem: 18322M
[01/23 19:42:32] d2.utils.events INFO:  eta: 1 day, 15:27:50  iter: 379  total_loss: 616  loss_ce: 4.612  loss_mask: 57.48  loss_ce_0: 5.027  loss_mask_0: 58.01  loss_ce_1: 4.882  loss_mask_1: 54.94  loss_ce_2: 4.814  loss_mask_2: 55.69  loss_ce_3: 4.819  loss_mask_3: 56.92  loss_ce_4: 4.704  loss_mask_4: 55.72  loss_ce_5: 4.767  loss_mask_5: 55.93  loss_ce_6: 4.817  loss_mask_6: 57.3  loss_ce_7: 4.728  loss_mask_7: 56.87  loss_ce_8: 4.668  loss_mask_8: 57.7  time: 2.3863  data_time: 0.4534  lr: 3.7746e-05  max_mem: 18322M
[01/23 19:43:21] d2.utils.events INFO:  eta: 1 day, 15:29:34  iter: 399  total_loss: 575.6  loss_ce: 4.559  loss_mask: 53.62  loss_ce_0: 5.046  loss_mask_0: 53.38  loss_ce_1: 4.849  loss_mask_1: 50.94  loss_ce_2: 4.759  loss_mask_2: 51.89  loss_ce_3: 4.726  loss_mask_3: 51.57  loss_ce_4: 4.639  loss_mask_4: 51.59  loss_ce_5: 4.699  loss_mask_5: 52.73  loss_ce_6: 4.727  loss_mask_6: 53.59  loss_ce_7: 4.659  loss_mask_7: 53.14  loss_ce_8: 4.636  loss_mask_8: 53.5  time: 2.3896  data_time: 0.4525  lr: 3.9721e-05  max_mem: 18322M
[01/23 19:44:11] d2.utils.events INFO:  eta: 1 day, 15:34:26  iter: 419  total_loss: 583.3  loss_ce: 4.631  loss_mask: 53.29  loss_ce_0: 5.034  loss_mask_0: 56.42  loss_ce_1: 4.824  loss_mask_1: 53.03  loss_ce_2: 4.741  loss_mask_2: 51.5  loss_ce_3: 4.708  loss_mask_3: 53.36  loss_ce_4: 4.659  loss_mask_4: 52.51  loss_ce_5: 4.716  loss_mask_5: 52.36  loss_ce_6: 4.753  loss_mask_6: 53.38  loss_ce_7: 4.672  loss_mask_7: 53.69  loss_ce_8: 4.676  loss_mask_8: 54.17  time: 2.3935  data_time: 0.4144  lr: 4.1694e-05  max_mem: 18322M
[01/23 19:45:00] d2.utils.events INFO:  eta: 1 day, 15:38:21  iter: 439  total_loss: 587.7  loss_ce: 4.578  loss_mask: 54.4  loss_ce_0: 5.056  loss_mask_0: 56.26  loss_ce_1: 4.819  loss_mask_1: 52.36  loss_ce_2: 4.814  loss_mask_2: 54.65  loss_ce_3: 4.835  loss_mask_3: 53.95  loss_ce_4: 4.788  loss_mask_4: 52.63  loss_ce_5: 4.776  loss_mask_5: 53.87  loss_ce_6: 4.778  loss_mask_6: 54.53  loss_ce_7: 4.712  loss_mask_7: 53.18  loss_ce_8: 4.644  loss_mask_8: 54.12  time: 2.3962  data_time: 0.4461  lr: 4.3667e-05  max_mem: 18322M
[01/23 19:45:50] d2.utils.events INFO:  eta: 1 day, 15:39:49  iter: 459  total_loss: 563.1  loss_ce: 4.604  loss_mask: 52.88  loss_ce_0: 5.052  loss_mask_0: 53.64  loss_ce_1: 4.783  loss_mask_1: 49.73  loss_ce_2: 4.735  loss_mask_2: 50.95  loss_ce_3: 4.726  loss_mask_3: 50.38  loss_ce_4: 4.707  loss_mask_4: 50.39  loss_ce_5: 4.716  loss_mask_5: 51.77  loss_ce_6: 4.661  loss_mask_6: 52.35  loss_ce_7: 4.591  loss_mask_7: 52.28  loss_ce_8: 4.578  loss_mask_8: 52.15  time: 2.4002  data_time: 0.4588  lr: 4.5638e-05  max_mem: 18322M
[01/23 19:46:39] d2.utils.events INFO:  eta: 1 day, 15:40:05  iter: 479  total_loss: 600.4  loss_ce: 4.571  loss_mask: 58.62  loss_ce_0: 5.057  loss_mask_0: 56.47  loss_ce_1: 4.769  loss_mask_1: 52  loss_ce_2: 4.666  loss_mask_2: 53.17  loss_ce_3: 4.663  loss_mask_3: 53  loss_ce_4: 4.655  loss_mask_4: 54.21  loss_ce_5: 4.627  loss_mask_5: 56.68  loss_ce_6: 4.709  loss_mask_6: 57.82  loss_ce_7: 4.622  loss_mask_7: 56.96  loss_ce_8: 4.601  loss_mask_8: 57.87  time: 2.4018  data_time: 0.4486  lr: 4.7607e-05  max_mem: 18322M
[01/23 19:47:28] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/23 19:47:28] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/23 19:47:28] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/23 19:50:12] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 25.059804468364383, 'error_1pix': 0.9509921303738704, 'error_3pix': 0.8890922038960248, 'mIoU': 0.03366917498488865, 'fwIoU': 0.09400127626363997, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0004046750928059989, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.7252147945079372, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.003518909470159485, 'IoU-22': 0.0, 'IoU-23': 0.6908179525366714, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 1.7432097119309158, 'IoU-29': 1.6837605277590162, 'IoU-30': 0.0, 'IoU-31': 0.45714486034532803, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.4030489781304883, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.00215573304760622, 'IoU-42': 1.7675596177532132e-05, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.04434483743702706, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0032134006855150292, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.07729880080692784, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.47680691830340677, 'IoU-61': 0.0, 'IoU-62': 0.005073276817375886, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0005664682173396933, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.012869465771938439, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.00118039086161252, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 4.953204599545791e-05, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.13378468773437657, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5400466935346204, 'pACC': 1.6736316230508343, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.00048404336383148775, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 3.7000360108889288, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.003564780044989859, 'ACC-22': 0.0, 'ACC-23': 1.0800286847806195, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 25.4460110917635, 'ACC-29': 71.39529180773299, 'ACC-30': 0.0, 'ACC-31': 0.5622161024118886, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.4810987281142752, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0021704718378908784, 'ACC-42': 1.7675602426068346e-05, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.04715628157143709, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0032140594982513425, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.08250658105817427, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.6978775630575546, 'ACC-61': 0.0, 'ACC-62': 0.005134862879883464, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0005924994228420801, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.01341395555229476, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0011855732357396037, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 5.0273702605409506e-05, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.16691411212700943, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/23 19:50:12] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/23 19:50:12] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/23 19:50:12] d2.evaluation.testing INFO: copypaste: 25.0598,0.9510,0.8891,0.0337,0.0940,0.5400,1.6736
[01/23 19:50:12] d2.utils.events INFO:  eta: 1 day, 15:41:38  iter: 499  total_loss: 534.8  loss_ce: 4.516  loss_mask: 50.11  loss_ce_0: 5.062  loss_mask_0: 51.25  loss_ce_1: 4.746  loss_mask_1: 48.41  loss_ce_2: 4.627  loss_mask_2: 48.99  loss_ce_3: 4.642  loss_mask_3: 49.56  loss_ce_4: 4.646  loss_mask_4: 48.77  loss_ce_5: 4.627  loss_mask_5: 50.04  loss_ce_6: 4.605  loss_mask_6: 49.86  loss_ce_7: 4.54  loss_mask_7: 49.25  loss_ce_8: 4.505  loss_mask_8: 49.91  time: 2.4038  data_time: 0.4492  lr: 4.9576e-05  max_mem: 18322M
[01/23 19:51:01] d2.utils.events INFO:  eta: 1 day, 15:42:42  iter: 519  total_loss: 555.6  loss_ce: 4.575  loss_mask: 51.72  loss_ce_0: 5.083  loss_mask_0: 51.9  loss_ce_1: 4.73  loss_mask_1: 49.86  loss_ce_2: 4.581  loss_mask_2: 50.08  loss_ce_3: 4.578  loss_mask_3: 51.25  loss_ce_4: 4.554  loss_mask_4: 51.37  loss_ce_5: 4.632  loss_mask_5: 49.68  loss_ce_6: 4.666  loss_mask_6: 49.59  loss_ce_7: 4.617  loss_mask_7: 52.8  loss_ce_8: 4.615  loss_mask_8: 51.34  time: 2.4056  data_time: 0.4477  lr: 5.1544e-05  max_mem: 18322M
[01/23 19:51:51] d2.utils.events INFO:  eta: 1 day, 15:45:01  iter: 539  total_loss: 579.5  loss_ce: 4.572  loss_mask: 55.89  loss_ce_0: 5.05  loss_mask_0: 54.65  loss_ce_1: 4.73  loss_mask_1: 52.4  loss_ce_2: 4.555  loss_mask_2: 52.18  loss_ce_3: 4.575  loss_mask_3: 51.49  loss_ce_4: 4.553  loss_mask_4: 52.15  loss_ce_5: 4.526  loss_mask_5: 52.27  loss_ce_6: 4.578  loss_mask_6: 54.2  loss_ce_7: 4.662  loss_mask_7: 54.29  loss_ce_8: 4.616  loss_mask_8: 53.46  time: 2.4093  data_time: 0.4581  lr: 5.351e-05  max_mem: 18322M
[01/23 19:52:40] d2.utils.events INFO:  eta: 1 day, 15:43:22  iter: 559  total_loss: 530.1  loss_ce: 4.468  loss_mask: 50.81  loss_ce_0: 5.083  loss_mask_0: 49.02  loss_ce_1: 4.707  loss_mask_1: 45.68  loss_ce_2: 4.505  loss_mask_2: 46.1  loss_ce_3: 4.526  loss_mask_3: 46.76  loss_ce_4: 4.458  loss_mask_4: 48.11  loss_ce_5: 4.546  loss_mask_5: 49.06  loss_ce_6: 4.533  loss_mask_6: 47.8  loss_ce_7: 4.516  loss_mask_7: 49.77  loss_ce_8: 4.495  loss_mask_8: 49.91  time: 2.4095  data_time: 0.4142  lr: 5.5475e-05  max_mem: 18322M
[01/23 19:53:31] d2.utils.events INFO:  eta: 1 day, 15:47:27  iter: 579  total_loss: 555.2  loss_ce: 4.556  loss_mask: 52.05  loss_ce_0: 5.043  loss_mask_0: 49.65  loss_ce_1: 4.707  loss_mask_1: 49.47  loss_ce_2: 4.538  loss_mask_2: 49.53  loss_ce_3: 4.492  loss_mask_3: 48.87  loss_ce_4: 4.47  loss_mask_4: 49.23  loss_ce_5: 4.565  loss_mask_5: 48.41  loss_ce_6: 4.57  loss_mask_6: 50.81  loss_ce_7: 4.534  loss_mask_7: 49.8  loss_ce_8: 4.562  loss_mask_8: 51.16  time: 2.4154  data_time: 0.4334  lr: 5.7439e-05  max_mem: 18322M
[01/23 19:54:24] d2.utils.events INFO:  eta: 1 day, 15:57:25  iter: 599  total_loss: 528.5  loss_ce: 4.47  loss_mask: 50.22  loss_ce_0: 5.08  loss_mask_0: 48.29  loss_ce_1: 4.709  loss_mask_1: 47.45  loss_ce_2: 4.496  loss_mask_2: 47.99  loss_ce_3: 4.537  loss_mask_3: 48.31  loss_ce_4: 4.549  loss_mask_4: 48.9  loss_ce_5: 4.601  loss_mask_5: 49.68  loss_ce_6: 4.567  loss_mask_6: 48.69  loss_ce_7: 4.562  loss_mask_7: 48.66  loss_ce_8: 4.49  loss_mask_8: 49.87  time: 2.4233  data_time: 0.4485  lr: 5.9401e-05  max_mem: 18322M
[01/23 19:55:17] d2.utils.events INFO:  eta: 1 day, 15:59:48  iter: 619  total_loss: 563.7  loss_ce: 4.488  loss_mask: 52.47  loss_ce_0: 5.069  loss_mask_0: 51.49  loss_ce_1: 4.721  loss_mask_1: 50.26  loss_ce_2: 4.505  loss_mask_2: 48.25  loss_ce_3: 4.564  loss_mask_3: 50.24  loss_ce_4: 4.516  loss_mask_4: 51.15  loss_ce_5: 4.555  loss_mask_5: 52.67  loss_ce_6: 4.532  loss_mask_6: 53.25  loss_ce_7: 4.553  loss_mask_7: 53  loss_ce_8: 4.546  loss_mask_8: 52.27  time: 2.4301  data_time: 0.4660  lr: 6.1363e-05  max_mem: 18322M
[01/23 19:56:09] d2.utils.events INFO:  eta: 1 day, 16:01:47  iter: 639  total_loss: 513.1  loss_ce: 4.434  loss_mask: 47.2  loss_ce_0: 5.089  loss_mask_0: 47.18  loss_ce_1: 4.761  loss_mask_1: 45.65  loss_ce_2: 4.572  loss_mask_2: 46.25  loss_ce_3: 4.632  loss_mask_3: 45.72  loss_ce_4: 4.543  loss_mask_4: 47.18  loss_ce_5: 4.558  loss_mask_5: 46.85  loss_ce_6: 4.5  loss_mask_6: 48.68  loss_ce_7: 4.449  loss_mask_7: 46.91  loss_ce_8: 4.463  loss_mask_8: 46.74  time: 2.4349  data_time: 0.4294  lr: 6.3323e-05  max_mem: 18322M
[01/23 19:56:57] d2.utils.events INFO:  eta: 1 day, 15:59:49  iter: 659  total_loss: 513.5  loss_ce: 4.466  loss_mask: 46.58  loss_ce_0: 5.108  loss_mask_0: 46.41  loss_ce_1: 4.643  loss_mask_1: 43.55  loss_ce_2: 4.452  loss_mask_2: 44.66  loss_ce_3: 4.492  loss_mask_3: 46.07  loss_ce_4: 4.484  loss_mask_4: 48.2  loss_ce_5: 4.463  loss_mask_5: 48.08  loss_ce_6: 4.405  loss_mask_6: 49.01  loss_ce_7: 4.431  loss_mask_7: 46.31  loss_ce_8: 4.465  loss_mask_8: 45.92  time: 2.4342  data_time: 0.4038  lr: 6.5282e-05  max_mem: 18322M
[01/23 19:57:47] d2.utils.events INFO:  eta: 1 day, 16:00:16  iter: 679  total_loss: 540.2  loss_ce: 4.437  loss_mask: 51.35  loss_ce_0: 5.105  loss_mask_0: 47.23  loss_ce_1: 4.657  loss_mask_1: 46.93  loss_ce_2: 4.488  loss_mask_2: 46.44  loss_ce_3: 4.555  loss_mask_3: 48.03  loss_ce_4: 4.509  loss_mask_4: 49.75  loss_ce_5: 4.449  loss_mask_5: 52.05  loss_ce_6: 4.391  loss_mask_6: 52.83  loss_ce_7: 4.437  loss_mask_7: 48.81  loss_ce_8: 4.466  loss_mask_8: 49.08  time: 2.4355  data_time: 0.4212  lr: 6.724e-05  max_mem: 18322M
[01/23 19:58:35] d2.utils.events INFO:  eta: 1 day, 15:59:58  iter: 699  total_loss: 508.1  loss_ce: 4.325  loss_mask: 47.33  loss_ce_0: 5.121  loss_mask_0: 45.76  loss_ce_1: 4.683  loss_mask_1: 44.49  loss_ce_2: 4.463  loss_mask_2: 43.84  loss_ce_3: 4.533  loss_mask_3: 44.55  loss_ce_4: 4.545  loss_mask_4: 46.16  loss_ce_5: 4.613  loss_mask_5: 46.03  loss_ce_6: 4.431  loss_mask_6: 47.95  loss_ce_7: 4.39  loss_mask_7: 47.46  loss_ce_8: 4.387  loss_mask_8: 47.61  time: 2.4346  data_time: 0.3959  lr: 6.9196e-05  max_mem: 18322M
[01/23 19:59:23] d2.utils.events INFO:  eta: 1 day, 15:58:10  iter: 719  total_loss: 476.8  loss_ce: 4.273  loss_mask: 46.03  loss_ce_0: 5.122  loss_mask_0: 43.18  loss_ce_1: 4.615  loss_mask_1: 41.46  loss_ce_2: 4.367  loss_mask_2: 41.39  loss_ce_3: 4.397  loss_mask_3: 41.6  loss_ce_4: 4.428  loss_mask_4: 42.76  loss_ce_5: 4.48  loss_mask_5: 42.94  loss_ce_6: 4.399  loss_mask_6: 44.92  loss_ce_7: 4.359  loss_mask_7: 44.68  loss_ce_8: 4.41  loss_mask_8: 45.5  time: 2.4337  data_time: 0.4099  lr: 7.1152e-05  max_mem: 18322M
[01/23 20:00:13] d2.utils.events INFO:  eta: 1 day, 15:57:39  iter: 739  total_loss: 477.4  loss_ce: 4.285  loss_mask: 45.38  loss_ce_0: 5.112  loss_mask_0: 41.83  loss_ce_1: 4.572  loss_mask_1: 40.53  loss_ce_2: 4.301  loss_mask_2: 41.15  loss_ce_3: 4.328  loss_mask_3: 42.2  loss_ce_4: 4.328  loss_mask_4: 44.57  loss_ce_5: 4.389  loss_mask_5: 42.78  loss_ce_6: 4.399  loss_mask_6: 45.14  loss_ce_7: 4.391  loss_mask_7: 44.16  loss_ce_8: 4.43  loss_mask_8: 45.12  time: 2.4350  data_time: 0.4309  lr: 7.3106e-05  max_mem: 18347M
[01/23 20:01:01] d2.utils.events INFO:  eta: 1 day, 15:56:33  iter: 759  total_loss: 482.3  loss_ce: 4.285  loss_mask: 44.17  loss_ce_0: 5.11  loss_mask_0: 43.28  loss_ce_1: 4.525  loss_mask_1: 43.97  loss_ce_2: 4.27  loss_mask_2: 43.12  loss_ce_3: 4.305  loss_mask_3: 44.26  loss_ce_4: 4.279  loss_mask_4: 44.11  loss_ce_5: 4.368  loss_mask_5: 42.94  loss_ce_6: 4.351  loss_mask_6: 44.73  loss_ce_7: 4.367  loss_mask_7: 43.5  loss_ce_8: 4.376  loss_mask_8: 43.9  time: 2.4343  data_time: 0.3892  lr: 7.5059e-05  max_mem: 18347M
[01/23 20:01:50] d2.utils.events INFO:  eta: 1 day, 15:54:58  iter: 779  total_loss: 469.7  loss_ce: 4.234  loss_mask: 42.39  loss_ce_0: 5.114  loss_mask_0: 41.61  loss_ce_1: 4.485  loss_mask_1: 42.28  loss_ce_2: 4.258  loss_mask_2: 41.81  loss_ce_3: 4.284  loss_mask_3: 41.91  loss_ce_4: 4.277  loss_mask_4: 41.82  loss_ce_5: 4.332  loss_mask_5: 42.71  loss_ce_6: 4.363  loss_mask_6: 44.43  loss_ce_7: 4.409  loss_mask_7: 44.54  loss_ce_8: 4.391  loss_mask_8: 43.24  time: 2.4345  data_time: 0.4329  lr: 7.7011e-05  max_mem: 18347M
[01/23 20:02:40] d2.utils.events INFO:  eta: 1 day, 15:55:55  iter: 799  total_loss: 507.5  loss_ce: 4.232  loss_mask: 48.28  loss_ce_0: 5.111  loss_mask_0: 44.1  loss_ce_1: 4.473  loss_mask_1: 45.54  loss_ce_2: 4.289  loss_mask_2: 46.45  loss_ce_3: 4.346  loss_mask_3: 47.35  loss_ce_4: 4.369  loss_mask_4: 46.88  loss_ce_5: 4.393  loss_mask_5: 46.63  loss_ce_6: 4.36  loss_mask_6: 47.54  loss_ce_7: 4.364  loss_mask_7: 46.53  loss_ce_8: 4.327  loss_mask_8: 47.21  time: 2.4365  data_time: 0.4241  lr: 7.8962e-05  max_mem: 18347M
[01/23 20:03:34] d2.utils.events INFO:  eta: 1 day, 15:59:23  iter: 819  total_loss: 450.6  loss_ce: 4.169  loss_mask: 40.45  loss_ce_0: 5.115  loss_mask_0: 40.24  loss_ce_1: 4.382  loss_mask_1: 39.34  loss_ce_2: 4.193  loss_mask_2: 40.29  loss_ce_3: 4.22  loss_mask_3: 40.26  loss_ce_4: 4.202  loss_mask_4: 41.33  loss_ce_5: 4.24  loss_mask_5: 41.1  loss_ce_6: 4.267  loss_mask_6: 41.17  loss_ce_7: 4.243  loss_mask_7: 41.4  loss_ce_8: 4.228  loss_mask_8: 40.97  time: 2.4434  data_time: 0.4606  lr: 8.0911e-05  max_mem: 18347M
[01/23 20:04:25] d2.utils.events INFO:  eta: 1 day, 15:58:57  iter: 839  total_loss: 446.8  loss_ce: 4.204  loss_mask: 41.48  loss_ce_0: 5.11  loss_mask_0: 38.19  loss_ce_1: 4.369  loss_mask_1: 39.07  loss_ce_2: 4.155  loss_mask_2: 39.16  loss_ce_3: 4.173  loss_mask_3: 39.1  loss_ce_4: 4.16  loss_mask_4: 39.8  loss_ce_5: 4.174  loss_mask_5: 39.22  loss_ce_6: 4.204  loss_mask_6: 40.24  loss_ce_7: 4.222  loss_mask_7: 40.98  loss_ce_8: 4.267  loss_mask_8: 42.38  time: 2.4461  data_time: 0.4629  lr: 8.2859e-05  max_mem: 18347M
[01/23 20:05:14] d2.utils.events INFO:  eta: 1 day, 15:57:55  iter: 859  total_loss: 452.5  loss_ce: 4.322  loss_mask: 42.57  loss_ce_0: 5.106  loss_mask_0: 39.69  loss_ce_1: 4.36  loss_mask_1: 39.78  loss_ce_2: 4.216  loss_mask_2: 38.64  loss_ce_3: 4.19  loss_mask_3: 40  loss_ce_4: 4.176  loss_mask_4: 39.83  loss_ce_5: 4.234  loss_mask_5: 40.44  loss_ce_6: 4.242  loss_mask_6: 40.74  loss_ce_7: 4.238  loss_mask_7: 41.58  loss_ce_8: 4.35  loss_mask_8: 43.22  time: 2.4457  data_time: 0.3895  lr: 8.4806e-05  max_mem: 18347M
[01/23 20:06:09] d2.utils.events INFO:  eta: 1 day, 15:58:52  iter: 879  total_loss: 419  loss_ce: 4.286  loss_mask: 40.02  loss_ce_0: 5.109  loss_mask_0: 36.16  loss_ce_1: 4.264  loss_mask_1: 36.47  loss_ce_2: 4.134  loss_mask_2: 35.5  loss_ce_3: 4.128  loss_mask_3: 36.18  loss_ce_4: 4.069  loss_mask_4: 36.87  loss_ce_5: 4.124  loss_mask_5: 37.79  loss_ce_6: 4.152  loss_mask_6: 38.02  loss_ce_7: 4.227  loss_mask_7: 39.05  loss_ce_8: 4.333  loss_mask_8: 39.72  time: 2.4525  data_time: 0.4902  lr: 8.6752e-05  max_mem: 18347M
[01/23 20:07:00] d2.utils.events INFO:  eta: 1 day, 15:59:39  iter: 899  total_loss: 444.2  loss_ce: 4.285  loss_mask: 40.69  loss_ce_0: 5.089  loss_mask_0: 39.06  loss_ce_1: 4.295  loss_mask_1: 39.91  loss_ce_2: 4.205  loss_mask_2: 39.32  loss_ce_3: 4.203  loss_mask_3: 39.18  loss_ce_4: 4.155  loss_mask_4: 39.77  loss_ce_5: 4.204  loss_mask_5: 40.08  loss_ce_6: 4.25  loss_mask_6: 41.16  loss_ce_7: 4.307  loss_mask_7: 40.33  loss_ce_8: 4.342  loss_mask_8: 41.62  time: 2.4550  data_time: 0.4405  lr: 8.8697e-05  max_mem: 18347M
[01/23 20:07:53] d2.utils.events INFO:  eta: 1 day, 16:00:48  iter: 919  total_loss: 428.3  loss_ce: 4.236  loss_mask: 38.46  loss_ce_0: 5.104  loss_mask_0: 35.92  loss_ce_1: 4.295  loss_mask_1: 37.87  loss_ce_2: 4.202  loss_mask_2: 37.76  loss_ce_3: 4.183  loss_mask_3: 38.59  loss_ce_4: 4.102  loss_mask_4: 38.55  loss_ce_5: 4.158  loss_mask_5: 38.28  loss_ce_6: 4.245  loss_mask_6: 39.74  loss_ce_7: 4.285  loss_mask_7: 38.22  loss_ce_8: 4.42  loss_mask_8: 38.62  time: 2.4587  data_time: 0.4921  lr: 9.064e-05  max_mem: 18347M
[01/23 20:08:46] d2.utils.events INFO:  eta: 1 day, 16:03:03  iter: 939  total_loss: 441.3  loss_ce: 4.356  loss_mask: 40.89  loss_ce_0: 5.104  loss_mask_0: 36.99  loss_ce_1: 4.327  loss_mask_1: 38.35  loss_ce_2: 4.211  loss_mask_2: 38.27  loss_ce_3: 4.205  loss_mask_3: 38.98  loss_ce_4: 4.145  loss_mask_4: 38.87  loss_ce_5: 4.215  loss_mask_5: 40.9  loss_ce_6: 4.211  loss_mask_6: 41.32  loss_ce_7: 4.316  loss_mask_7: 40.62  loss_ce_8: 4.374  loss_mask_8: 41.42  time: 2.4626  data_time: 0.4504  lr: 9.2582e-05  max_mem: 18347M
[01/23 20:09:35] d2.utils.events INFO:  eta: 1 day, 16:02:29  iter: 959  total_loss: 440  loss_ce: 4.321  loss_mask: 43.15  loss_ce_0: 5.108  loss_mask_0: 37.58  loss_ce_1: 4.599  loss_mask_1: 36.93  loss_ce_2: 4.59  loss_mask_2: 38.26  loss_ce_3: 4.664  loss_mask_3: 38.35  loss_ce_4: 4.579  loss_mask_4: 38.78  loss_ce_5: 4.5  loss_mask_5: 39.53  loss_ce_6: 4.382  loss_mask_6: 39.37  loss_ce_7: 4.647  loss_mask_7: 39  loss_ce_8: 4.494  loss_mask_8: 40.64  time: 2.4628  data_time: 0.4290  lr: 9.4523e-05  max_mem: 18347M
[01/23 20:10:28] d2.utils.events INFO:  eta: 1 day, 16:03:53  iter: 979  total_loss: 460.7  loss_ce: 4.457  loss_mask: 43.9  loss_ce_0: 5.111  loss_mask_0: 38.87  loss_ce_1: 4.652  loss_mask_1: 40.06  loss_ce_2: 4.689  loss_mask_2: 40.6  loss_ce_3: 4.656  loss_mask_3: 41.68  loss_ce_4: 4.644  loss_mask_4: 42.07  loss_ce_5: 4.421  loss_mask_5: 40.93  loss_ce_6: 4.395  loss_mask_6: 43.92  loss_ce_7: 4.66  loss_mask_7: 42.76  loss_ce_8: 4.385  loss_mask_8: 42.47  time: 2.4667  data_time: 0.4805  lr: 9.6463e-05  max_mem: 18347M
[01/23 20:11:22] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/23 20:11:23] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/23 20:11:23] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/23 20:15:38] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 37.40014697776855, 'error_1pix': 0.9809031206244032, 'error_3pix': 0.9581229242217963, 'mIoU': 0.013082309348659034, 'fwIoU': 0.03805057993680832, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.4454897000165119, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 1.5031878823263496, 'IoU-21': 0.0, 'IoU-22': 0.2987833943375843, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.2154803896245663, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.031486911652321994, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.002635756938955544, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.005169900683892981, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.00956945936235164, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.19219951957657394, 'pACC': 0.5887969680549596, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 10.932588270214277, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 21.16363483412883, 'ACC-21': 0.0, 'ACC-22': 1.994998358339453, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 1.80260746171584, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.9909847229943015, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0026469760694845376, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.00518619948998317, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.009660935750036485, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/23 20:15:38] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/23 20:15:38] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/23 20:15:38] d2.evaluation.testing INFO: copypaste: 37.4001,0.9809,0.9581,0.0131,0.0381,0.1922,0.5888
[01/23 20:15:38] d2.utils.events INFO:  eta: 1 day, 16:06:23  iter: 999  total_loss: 461  loss_ce: 4.568  loss_mask: 44.86  loss_ce_0: 5.115  loss_mask_0: 39.6  loss_ce_1: 4.784  loss_mask_1: 40.49  loss_ce_2: 4.713  loss_mask_2: 41.08  loss_ce_3: 4.664  loss_mask_3: 41.57  loss_ce_4: 4.566  loss_mask_4: 42.55  loss_ce_5: 4.494  loss_mask_5: 42.83  loss_ce_6: 4.478  loss_mask_6: 44.69  loss_ce_7: 4.552  loss_mask_7: 42.02  loss_ce_8: 4.532  loss_mask_8: 43.09  time: 2.4711  data_time: 0.4696  lr: 9.8402e-05  max_mem: 18347M
[01/23 20:16:29] d2.utils.events INFO:  eta: 1 day, 16:11:34  iter: 1019  total_loss: 453.5  loss_ce: 4.496  loss_mask: 42.75  loss_ce_0: 5.135  loss_mask_0: 38.89  loss_ce_1: 4.553  loss_mask_1: 42.07  loss_ce_2: 4.459  loss_mask_2: 40.98  loss_ce_3: 4.491  loss_mask_3: 40.65  loss_ce_4: 4.495  loss_mask_4: 41.77  loss_ce_5: 4.427  loss_mask_5: 42.02  loss_ce_6: 4.479  loss_mask_6: 42.38  loss_ce_7: 4.447  loss_mask_7: 42.76  loss_ce_8: 4.522  loss_mask_8: 41.19  time: 2.4729  data_time: 0.4469  lr: 9.847e-05  max_mem: 18347M
[01/23 20:17:21] d2.utils.events INFO:  eta: 1 day, 16:17:27  iter: 1039  total_loss: 443  loss_ce: 4.546  loss_mask: 40.36  loss_ce_0: 5.12  loss_mask_0: 38.39  loss_ce_1: 4.476  loss_mask_1: 38.38  loss_ce_2: 4.503  loss_mask_2: 39.04  loss_ce_3: 4.537  loss_mask_3: 38.97  loss_ce_4: 4.508  loss_mask_4: 40.23  loss_ce_5: 4.433  loss_mask_5: 39.14  loss_ce_6: 4.552  loss_mask_6: 41.36  loss_ce_7: 4.533  loss_mask_7: 40.05  loss_ce_8: 4.447  loss_mask_8: 41.3  time: 2.4754  data_time: 0.4506  lr: 9.844e-05  max_mem: 18347M
[01/23 20:18:17] d2.utils.events INFO:  eta: 1 day, 16:19:18  iter: 1059  total_loss: 438  loss_ce: 4.44  loss_mask: 40.28  loss_ce_0: 5.125  loss_mask_0: 40.14  loss_ce_1: 4.401  loss_mask_1: 38.59  loss_ce_2: 4.403  loss_mask_2: 39.42  loss_ce_3: 4.396  loss_mask_3: 39.46  loss_ce_4: 4.353  loss_mask_4: 40.87  loss_ce_5: 4.307  loss_mask_5: 39.63  loss_ce_6: 4.399  loss_mask_6: 38.34  loss_ce_7: 4.531  loss_mask_7: 41.05  loss_ce_8: 4.459  loss_mask_8: 38.67  time: 2.4812  data_time: 0.4799  lr: 9.841e-05  max_mem: 18347M
[01/23 20:19:08] d2.utils.events INFO:  eta: 1 day, 16:25:47  iter: 1079  total_loss: 478.1  loss_ce: 4.43  loss_mask: 43.59  loss_ce_0: 5.107  loss_mask_0: 41.48  loss_ce_1: 4.385  loss_mask_1: 42.39  loss_ce_2: 4.328  loss_mask_2: 42.16  loss_ce_3: 4.379  loss_mask_3: 43.8  loss_ce_4: 4.337  loss_mask_4: 43.19  loss_ce_5: 4.307  loss_mask_5: 43.34  loss_ce_6: 4.362  loss_mask_6: 43.64  loss_ce_7: 4.468  loss_mask_7: 43.52  loss_ce_8: 4.469  loss_mask_8: 43.56  time: 2.4825  data_time: 0.4354  lr: 9.838e-05  max_mem: 18347M
[01/23 20:20:02] d2.utils.events INFO:  eta: 1 day, 16:32:42  iter: 1099  total_loss: 464.1  loss_ce: 4.397  loss_mask: 42.62  loss_ce_0: 5.099  loss_mask_0: 39.3  loss_ce_1: 4.336  loss_mask_1: 42.22  loss_ce_2: 4.302  loss_mask_2: 42.29  loss_ce_3: 4.308  loss_mask_3: 41.57  loss_ce_4: 4.329  loss_mask_4: 40.99  loss_ce_5: 4.418  loss_mask_5: 42.32  loss_ce_6: 4.457  loss_mask_6: 42.23  loss_ce_7: 4.505  loss_mask_7: 42.52  loss_ce_8: 4.438  loss_mask_8: 40.7  time: 2.4865  data_time: 0.4356  lr: 9.835e-05  max_mem: 18347M
[01/23 20:20:56] d2.utils.events INFO:  eta: 1 day, 16:38:13  iter: 1119  total_loss: 460.5  loss_ce: 4.334  loss_mask: 47.07  loss_ce_0: 5.108  loss_mask_0: 37.03  loss_ce_1: 4.268  loss_mask_1: 37.8  loss_ce_2: 4.28  loss_mask_2: 39.92  loss_ce_3: 4.282  loss_mask_3: 40.98  loss_ce_4: 4.36  loss_mask_4: 40.32  loss_ce_5: 4.363  loss_mask_5: 42.35  loss_ce_6: 4.388  loss_mask_6: 42.13  loss_ce_7: 4.446  loss_mask_7: 40.76  loss_ce_8: 4.386  loss_mask_8: 47.38  time: 2.4905  data_time: 0.4584  lr: 9.832e-05  max_mem: 18347M
[01/23 20:21:47] d2.utils.events INFO:  eta: 1 day, 16:41:02  iter: 1139  total_loss: 462.1  loss_ce: 4.437  loss_mask: 41.99  loss_ce_0: 5.102  loss_mask_0: 35.94  loss_ce_1: 4.262  loss_mask_1: 38.26  loss_ce_2: 4.29  loss_mask_2: 40.38  loss_ce_3: 4.304  loss_mask_3: 42.32  loss_ce_4: 4.373  loss_mask_4: 39.53  loss_ce_5: 4.383  loss_mask_5: 41.94  loss_ce_6: 4.526  loss_mask_6: 42.98  loss_ce_7: 4.536  loss_mask_7: 52.22  loss_ce_8: 4.542  loss_mask_8: 43.3  time: 2.4919  data_time: 0.4441  lr: 9.829e-05  max_mem: 18347M
[01/23 20:22:42] d2.utils.events INFO:  eta: 1 day, 16:44:53  iter: 1159  total_loss: 480.6  loss_ce: 4.299  loss_mask: 43.48  loss_ce_0: 5.113  loss_mask_0: 38.78  loss_ce_1: 4.231  loss_mask_1: 42.51  loss_ce_2: 4.287  loss_mask_2: 41.73  loss_ce_3: 4.265  loss_mask_3: 43.8  loss_ce_4: 4.262  loss_mask_4: 42.51  loss_ce_5: 4.388  loss_mask_5: 42.71  loss_ce_6: 4.353  loss_mask_6: 42.96  loss_ce_7: 4.495  loss_mask_7: 46.98  loss_ce_8: 4.362  loss_mask_8: 44.15  time: 2.4958  data_time: 0.4722  lr: 9.826e-05  max_mem: 18347M
[01/23 20:23:34] d2.utils.events INFO:  eta: 1 day, 16:51:39  iter: 1179  total_loss: 474.8  loss_ce: 4.291  loss_mask: 45.77  loss_ce_0: 5.107  loss_mask_0: 37.07  loss_ce_1: 4.24  loss_mask_1: 39.6  loss_ce_2: 4.343  loss_mask_2: 45.72  loss_ce_3: 4.379  loss_mask_3: 46.65  loss_ce_4: 4.246  loss_mask_4: 45.88  loss_ce_5: 4.296  loss_mask_5: 41.94  loss_ce_6: 4.333  loss_mask_6: 43.62  loss_ce_7: 4.471  loss_mask_7: 42.39  loss_ce_8: 4.33  loss_mask_8: 44.15  time: 2.4975  data_time: 0.4453  lr: 9.823e-05  max_mem: 18347M
[01/23 20:24:25] d2.utils.events INFO:  eta: 1 day, 16:52:00  iter: 1199  total_loss: 463.4  loss_ce: 4.223  loss_mask: 42.92  loss_ce_0: 5.105  loss_mask_0: 37.92  loss_ce_1: 4.241  loss_mask_1: 39.36  loss_ce_2: 4.396  loss_mask_2: 41.64  loss_ce_3: 4.287  loss_mask_3: 43.75  loss_ce_4: 4.246  loss_mask_4: 42.38  loss_ce_5: 4.269  loss_mask_5: 42.78  loss_ce_6: 4.293  loss_mask_6: 40.67  loss_ce_7: 4.378  loss_mask_7: 40.74  loss_ce_8: 4.263  loss_mask_8: 42.5  time: 2.4982  data_time: 0.4295  lr: 9.82e-05  max_mem: 18347M
[01/23 20:25:20] d2.utils.events INFO:  eta: 1 day, 16:54:42  iter: 1219  total_loss: 471.2  loss_ce: 4.191  loss_mask: 43.14  loss_ce_0: 5.095  loss_mask_0: 38.54  loss_ce_1: 4.287  loss_mask_1: 41.37  loss_ce_2: 4.292  loss_mask_2: 41.98  loss_ce_3: 4.237  loss_mask_3: 44.2  loss_ce_4: 4.257  loss_mask_4: 47.97  loss_ce_5: 4.278  loss_mask_5: 43.78  loss_ce_6: 4.287  loss_mask_6: 42.91  loss_ce_7: 4.219  loss_mask_7: 41.85  loss_ce_8: 4.206  loss_mask_8: 42.79  time: 2.5028  data_time: 0.5279  lr: 9.817e-05  max_mem: 18347M
[01/23 20:26:10] d2.utils.events INFO:  eta: 1 day, 16:57:14  iter: 1239  total_loss: 459.4  loss_ce: 4.33  loss_mask: 43.53  loss_ce_0: 5.095  loss_mask_0: 36.81  loss_ce_1: 4.354  loss_mask_1: 38.85  loss_ce_2: 4.349  loss_mask_2: 38.98  loss_ce_3: 4.376  loss_mask_3: 41.31  loss_ce_4: 4.341  loss_mask_4: 46.5  loss_ce_5: 4.389  loss_mask_5: 41.1  loss_ce_6: 4.375  loss_mask_6: 42.99  loss_ce_7: 4.291  loss_mask_7: 40.77  loss_ce_8: 4.345  loss_mask_8: 45.59  time: 2.5024  data_time: 0.3863  lr: 9.814e-05  max_mem: 18347M
[01/23 20:27:04] d2.utils.events INFO:  eta: 1 day, 17:01:17  iter: 1259  total_loss: 474.3  loss_ce: 4.343  loss_mask: 47.74  loss_ce_0: 5.108  loss_mask_0: 39.94  loss_ce_1: 4.472  loss_mask_1: 40.37  loss_ce_2: 4.482  loss_mask_2: 41.16  loss_ce_3: 4.397  loss_mask_3: 42.51  loss_ce_4: 4.473  loss_mask_4: 45.64  loss_ce_5: 4.394  loss_mask_5: 43.2  loss_ce_6: 4.355  loss_mask_6: 44.6  loss_ce_7: 4.36  loss_mask_7: 42.83  loss_ce_8: 4.258  loss_mask_8: 45.54  time: 2.5053  data_time: 0.4686  lr: 9.811e-05  max_mem: 18347M
[01/23 20:27:58] d2.utils.events INFO:  eta: 1 day, 17:02:10  iter: 1279  total_loss: 480  loss_ce: 4.486  loss_mask: 44.33  loss_ce_0: 5.091  loss_mask_0: 39.49  loss_ce_1: 4.43  loss_mask_1: 40.35  loss_ce_2: 4.482  loss_mask_2: 41.49  loss_ce_3: 4.409  loss_mask_3: 41.83  loss_ce_4: 4.451  loss_mask_4: 43.58  loss_ce_5: 4.614  loss_mask_5: 47.46  loss_ce_6: 4.484  loss_mask_6: 44.56  loss_ce_7: 4.515  loss_mask_7: 43.98  loss_ce_8: 4.456  loss_mask_8: 46.01  time: 2.5089  data_time: 0.4673  lr: 9.8079e-05  max_mem: 18347M
[01/23 20:28:52] d2.utils.events INFO:  eta: 1 day, 17:04:31  iter: 1299  total_loss: 497.7  loss_ce: 4.612  loss_mask: 50.43  loss_ce_0: 5.104  loss_mask_0: 39.85  loss_ce_1: 4.382  loss_mask_1: 41.89  loss_ce_2: 4.418  loss_mask_2: 43.78  loss_ce_3: 4.371  loss_mask_3: 43.52  loss_ce_4: 4.38  loss_mask_4: 44.77  loss_ce_5: 4.696  loss_mask_5: 46.06  loss_ce_6: 4.631  loss_mask_6: 44.71  loss_ce_7: 4.604  loss_mask_7: 49.31  loss_ce_8: 4.641  loss_mask_8: 45.99  time: 2.5112  data_time: 0.4424  lr: 9.8049e-05  max_mem: 18347M
[01/23 20:29:48] d2.utils.events INFO:  eta: 1 day, 17:07:34  iter: 1319  total_loss: 496.4  loss_ce: 4.421  loss_mask: 45.85  loss_ce_0: 5.139  loss_mask_0: 42.38  loss_ce_1: 4.451  loss_mask_1: 42.67  loss_ce_2: 4.392  loss_mask_2: 43.56  loss_ce_3: 4.518  loss_mask_3: 45.03  loss_ce_4: 4.546  loss_mask_4: 44.8  loss_ce_5: 4.616  loss_mask_5: 46.79  loss_ce_6: 4.558  loss_mask_6: 44.6  loss_ce_7: 4.677  loss_mask_7: 50.3  loss_ce_8: 4.719  loss_mask_8: 46.95  time: 2.5157  data_time: 0.5111  lr: 9.8019e-05  max_mem: 18347M
[01/23 20:30:38] d2.utils.events INFO:  eta: 1 day, 17:07:19  iter: 1339  total_loss: 491.6  loss_ce: 4.388  loss_mask: 46.08  loss_ce_0: 5.139  loss_mask_0: 41.57  loss_ce_1: 4.443  loss_mask_1: 41.87  loss_ce_2: 4.449  loss_mask_2: 42.98  loss_ce_3: 4.507  loss_mask_3: 43.35  loss_ce_4: 4.55  loss_mask_4: 42.88  loss_ce_5: 4.542  loss_mask_5: 43.09  loss_ce_6: 4.43  loss_mask_6: 45.11  loss_ce_7: 4.41  loss_mask_7: 47.37  loss_ce_8: 4.475  loss_mask_8: 47.11  time: 2.5155  data_time: 0.4245  lr: 9.7989e-05  max_mem: 18347M
[01/23 20:31:31] d2.utils.events INFO:  eta: 1 day, 17:15:05  iter: 1359  total_loss: 475.2  loss_ce: 4.424  loss_mask: 43.47  loss_ce_0: 5.131  loss_mask_0: 40.22  loss_ce_1: 4.462  loss_mask_1: 41.68  loss_ce_2: 4.436  loss_mask_2: 41.6  loss_ce_3: 4.404  loss_mask_3: 41.16  loss_ce_4: 4.386  loss_mask_4: 41.2  loss_ce_5: 4.363  loss_mask_5: 43.3  loss_ce_6: 4.44  loss_mask_6: 45.88  loss_ce_7: 4.489  loss_mask_7: 44.25  loss_ce_8: 4.4  loss_mask_8: 45.88  time: 2.5180  data_time: 0.4441  lr: 9.7959e-05  max_mem: 18347M
[01/23 20:32:27] d2.utils.events INFO:  eta: 1 day, 17:21:32  iter: 1379  total_loss: 417.3  loss_ce: 4.295  loss_mask: 37.43  loss_ce_0: 5.137  loss_mask_0: 35.77  loss_ce_1: 4.365  loss_mask_1: 36.94  loss_ce_2: 4.334  loss_mask_2: 37.05  loss_ce_3: 4.262  loss_mask_3: 37.18  loss_ce_4: 4.33  loss_mask_4: 37.63  loss_ce_5: 4.271  loss_mask_5: 37.7  loss_ce_6: 4.29  loss_mask_6: 38.18  loss_ce_7: 4.363  loss_mask_7: 38.25  loss_ce_8: 4.332  loss_mask_8: 38.2  time: 2.5218  data_time: 0.4888  lr: 9.7929e-05  max_mem: 18417M
[01/23 20:33:19] d2.utils.events INFO:  eta: 1 day, 17:26:45  iter: 1399  total_loss: 422.9  loss_ce: 4.272  loss_mask: 39.28  loss_ce_0: 5.121  loss_mask_0: 35.42  loss_ce_1: 4.276  loss_mask_1: 37.5  loss_ce_2: 4.251  loss_mask_2: 37.41  loss_ce_3: 4.23  loss_mask_3: 39.05  loss_ce_4: 4.279  loss_mask_4: 38  loss_ce_5: 4.282  loss_mask_5: 37.68  loss_ce_6: 4.254  loss_mask_6: 38.41  loss_ce_7: 4.285  loss_mask_7: 39.65  loss_ce_8: 4.29  loss_mask_8: 39.12  time: 2.5229  data_time: 0.4641  lr: 9.7899e-05  max_mem: 18417M
[01/23 20:34:16] d2.utils.events INFO:  eta: 1 day, 17:35:21  iter: 1419  total_loss: 463.6  loss_ce: 4.27  loss_mask: 42.21  loss_ce_0: 5.126  loss_mask_0: 37.17  loss_ce_1: 4.249  loss_mask_1: 39.48  loss_ce_2: 4.215  loss_mask_2: 41.68  loss_ce_3: 4.242  loss_mask_3: 41.95  loss_ce_4: 4.295  loss_mask_4: 44.02  loss_ce_5: 4.305  loss_mask_5: 42.12  loss_ce_6: 4.287  loss_mask_6: 41.87  loss_ce_7: 4.249  loss_mask_7: 43.16  loss_ce_8: 4.239  loss_mask_8: 41.41  time: 2.5274  data_time: 0.4921  lr: 9.7869e-05  max_mem: 18417M
[01/23 20:35:10] d2.utils.events INFO:  eta: 1 day, 17:39:01  iter: 1439  total_loss: 427.5  loss_ce: 4.248  loss_mask: 40.07  loss_ce_0: 5.126  loss_mask_0: 35.46  loss_ce_1: 4.195  loss_mask_1: 36.11  loss_ce_2: 4.188  loss_mask_2: 38.04  loss_ce_3: 4.202  loss_mask_3: 38.74  loss_ce_4: 4.238  loss_mask_4: 38.04  loss_ce_5: 4.234  loss_mask_5: 38.98  loss_ce_6: 4.218  loss_mask_6: 39.68  loss_ce_7: 4.163  loss_mask_7: 39.85  loss_ce_8: 4.204  loss_mask_8: 38.87  time: 2.5295  data_time: 0.4318  lr: 9.7839e-05  max_mem: 18417M
[01/23 20:36:04] d2.utils.events INFO:  eta: 1 day, 17:43:23  iter: 1459  total_loss: 447.5  loss_ce: 4.172  loss_mask: 40.19  loss_ce_0: 5.111  loss_mask_0: 37.1  loss_ce_1: 4.241  loss_mask_1: 38.15  loss_ce_2: 4.333  loss_mask_2: 37.38  loss_ce_3: 4.539  loss_mask_3: 42.92  loss_ce_4: 4.896  loss_mask_4: 43.23  loss_ce_5: 4.454  loss_mask_5: 43.36  loss_ce_6: 4.339  loss_mask_6: 41.71  loss_ce_7: 4.176  loss_mask_7: 41.61  loss_ce_8: 4.263  loss_mask_8: 41.91  time: 2.5318  data_time: 0.4327  lr: 9.7809e-05  max_mem: 18417M
[01/23 20:36:59] d2.utils.events INFO:  eta: 1 day, 17:47:24  iter: 1479  total_loss: 488.9  loss_ce: 4.251  loss_mask: 43.84  loss_ce_0: 5.115  loss_mask_0: 40.44  loss_ce_1: 4.308  loss_mask_1: 40.45  loss_ce_2: 4.418  loss_mask_2: 41.44  loss_ce_3: 4.707  loss_mask_3: 52.73  loss_ce_4: 4.444  loss_mask_4: 43.97  loss_ce_5: 4.463  loss_mask_5: 47.49  loss_ce_6: 4.38  loss_mask_6: 43.92  loss_ce_7: 4.268  loss_mask_7: 45.65  loss_ce_8: 4.334  loss_mask_8: 46.18  time: 2.5352  data_time: 0.4903  lr: 9.7779e-05  max_mem: 18417M
[01/23 20:37:51] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/23 20:37:51] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/23 20:37:51] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/23 20:42:12] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 18.821688536223654, 'error_1pix': 0.9431785219996769, 'error_3pix': 0.8701592506205511, 'mIoU': 0.03762054577545498, 'fwIoU': 0.09520629914321475, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0014000488155748877, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0017654209520158585, 'IoU-25': 0.000186408097095504, 'IoU-26': 0.0, 'IoU-27': 1.9847229472598562, 'IoU-28': 0.10050727095993672, 'IoU-29': 5.376527639518876e-06, 'IoU-30': 0.07465252926883147, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 7.133138343765738e-05, 'IoU-34': 0.8786242734059315, 'IoU-35': 0.00024116644057543867, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 1.0474130384407865, 'IoU-39': 1.6204381407126938, 'IoU-40': 0.0, 'IoU-41': 0.011244602329340296, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 7.946479176175639e-05, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.039880964651652515, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 1.4554911931645087, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0002762655614865474, 'IoU-81': 0.00613016957544689, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 1.417654878441056e-05, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.8500720648357993, 'pACC': 1.9006286738430012, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0014015119194639403, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.001767942598427242, 'ACC-25': 0.0001864431875756746, 'ACC-26': 0.0, 'ACC-27': 95.49416408895249, 'ACC-28': 0.1166053936702243, 'ACC-29': 5.376600486270501e-06, 'ACC-30': 0.08661929429948918, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 7.141273208459507e-05, 'ACC-34': 1.320803465209222, 'ACC-35': 0.000241202398949156, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 2.6505258263693943, 'ACC-39': 5.105501807235844, 'ACC-40': 0.0, 'ACC-41': 0.011282390271220603, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 7.946488497817383e-05, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.04136274881108588, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 58.37602449250369, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.00027644986620379376, 'ACC-81': 0.0069029170641661045, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 1.4219898501208479e-05, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/23 20:42:12] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/23 20:42:12] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/23 20:42:12] d2.evaluation.testing INFO: copypaste: 18.8217,0.9432,0.8702,0.0376,0.0952,0.8501,1.9006
[01/23 20:42:12] d2.utils.events INFO:  eta: 1 day, 17:50:56  iter: 1499  total_loss: 459.4  loss_ce: 4.302  loss_mask: 42.03  loss_ce_0: 5.126  loss_mask_0: 38.08  loss_ce_1: 4.297  loss_mask_1: 36.5  loss_ce_2: 4.425  loss_mask_2: 38.51  loss_ce_3: 4.672  loss_mask_3: 43.48  loss_ce_4: 4.526  loss_mask_4: 39.44  loss_ce_5: 4.376  loss_mask_5: 44.3  loss_ce_6: 4.366  loss_mask_6: 40.69  loss_ce_7: 4.318  loss_mask_7: 42.35  loss_ce_8: 4.273  loss_mask_8: 42.97  time: 2.5357  data_time: 0.4325  lr: 9.7749e-05  max_mem: 18417M
[01/23 20:43:03] d2.utils.events INFO:  eta: 1 day, 17:54:10  iter: 1519  total_loss: 468.3  loss_ce: 4.285  loss_mask: 42.65  loss_ce_0: 5.116  loss_mask_0: 38.21  loss_ce_1: 4.286  loss_mask_1: 38.84  loss_ce_2: 4.502  loss_mask_2: 40.27  loss_ce_3: 4.605  loss_mask_3: 42.04  loss_ce_4: 4.457  loss_mask_4: 41.79  loss_ce_5: 4.298  loss_mask_5: 44.02  loss_ce_6: 4.339  loss_mask_6: 41.38  loss_ce_7: 4.333  loss_mask_7: 44.01  loss_ce_8: 4.25  loss_mask_8: 43.08  time: 2.5355  data_time: 0.4289  lr: 9.7719e-05  max_mem: 18417M
[01/23 20:43:59] d2.utils.events INFO:  eta: 1 day, 17:56:45  iter: 1539  total_loss: 487.2  loss_ce: 4.319  loss_mask: 45.81  loss_ce_0: 5.128  loss_mask_0: 41.51  loss_ce_1: 4.264  loss_mask_1: 40.26  loss_ce_2: 4.361  loss_mask_2: 40.96  loss_ce_3: 4.43  loss_mask_3: 42.85  loss_ce_4: 4.553  loss_mask_4: 44.48  loss_ce_5: 4.526  loss_mask_5: 46.32  loss_ce_6: 4.302  loss_mask_6: 45.64  loss_ce_7: 4.309  loss_mask_7: 45.24  loss_ce_8: 4.265  loss_mask_8: 45.83  time: 2.5393  data_time: 0.4875  lr: 9.7689e-05  max_mem: 18417M
[01/23 20:44:50] detectron2 INFO: Rank of current process: 0. World size: 1
[01/23 20:44:54] d2.utils.events INFO:  eta: 1 day, 18:02:16  iter: 1559  total_loss: 469.7  loss_ce: 4.271  loss_mask: 42.67  loss_ce_0: 5.125  loss_mask_0: 40.62  loss_ce_1: 4.309  loss_mask_1: 39.62  loss_ce_2: 4.405  loss_mask_2: 40.29  loss_ce_3: 4.332  loss_mask_3: 42.82  loss_ce_4: 4.519  loss_mask_4: 43.83  loss_ce_5: 4.385  loss_mask_5: 47.56  loss_ce_6: 4.267  loss_mask_6: 44.74  loss_ce_7: 4.282  loss_mask_7: 42.46  loss_ce_8: 4.286  loss_mask_8: 41.91  time: 2.5418  data_time: 0.4627  lr: 9.7658e-05  max_mem: 18417M
[01/23 20:44:54] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/23 20:44:54] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/23 20:44:54] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/23 20:44:55] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0e-05[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/23 20:44:55] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/config.yaml
[01/23 20:44:55] d2.utils.env INFO: Using a generated random seed 55457375
[01/23 20:45:02] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 5.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 1.0, 'loss_mask': 5.0, 'loss_ce_0': 1.0, 'loss_mask_0': 5.0, 'loss_ce_1': 1.0, 'loss_mask_1': 5.0, 'loss_ce_2': 1.0, 'loss_mask_2': 5.0, 'loss_ce_3': 1.0, 'loss_mask_3': 5.0, 'loss_ce_4': 1.0, 'loss_mask_4': 5.0, 'loss_ce_5': 1.0, 'loss_mask_5': 5.0, 'loss_ce_6': 1.0, 'loss_mask_6': 5.0, 'loss_ce_7': 1.0, 'loss_mask_7': 5.0, 'loss_ce_8': 1.0, 'loss_mask_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/23 20:45:02] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/23 20:45:17] d2.data.build INFO: Using training sampler TrainingSampler
[01/23 20:45:17] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/23 20:45:17] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/23 20:45:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/23 20:45:17] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/23 20:45:17] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/23 20:45:17] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/23 20:45:17] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/23 20:45:17] d2.engine.train_loop INFO: Starting training from iteration 0
[01/23 20:45:20] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 395, in run_step
    loss_dict = self.model(data)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 331, in forward
    features_left = self.backbone(images_left.tensor)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/detectron2/detectron2/modeling/backbone/resnet.py", line 445, in forward
    x = self.stem(x)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/detectron2/detectron2/modeling/backbone/resnet.py", line 356, in forward
    x = self.conv1(x)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/detectron2/detectron2/layers/wrappers.py", line 110, in forward
    x = self.norm(x)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py", line 731, in forward
    world_size = torch.distributed.get_world_size(process_group)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 748, in get_world_size
    return _get_group_size(group)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 274, in _get_group_size
    default_pg = _get_default_group()
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 358, in _get_default_group
    raise RuntimeError("Default process group has not been initialized, "
RuntimeError: Default process group has not been initialized, please make sure to call init_process_group.
[01/23 20:45:20] d2.engine.hooks INFO: Total training time: 0:00:02 (0:00:00 on hooks)
[01/23 20:45:20] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 238M
[01/23 20:45:47] d2.utils.events INFO:  eta: 1 day, 18:05:48  iter: 1579  total_loss: 437.1  loss_ce: 4.353  loss_mask: 40.84  loss_ce_0: 5.105  loss_mask_0: 37.08  loss_ce_1: 4.262  loss_mask_1: 36.35  loss_ce_2: 4.543  loss_mask_2: 39.29  loss_ce_3: 4.403  loss_mask_3: 39.57  loss_ce_4: 4.452  loss_mask_4: 42.39  loss_ce_5: 4.31  loss_mask_5: 43.45  loss_ce_6: 4.243  loss_mask_6: 38.68  loss_ce_7: 4.255  loss_mask_7: 38.98  loss_ce_8: 4.301  loss_mask_8: 40.27  time: 2.5433  data_time: 0.4421  lr: 9.7628e-05  max_mem: 18472M
[01/23 20:46:43] d2.utils.events INFO:  eta: 1 day, 18:08:14  iter: 1599  total_loss: 449.4  loss_ce: 4.269  loss_mask: 41.69  loss_ce_0: 5.112  loss_mask_0: 36.73  loss_ce_1: 4.251  loss_mask_1: 37.71  loss_ce_2: 4.539  loss_mask_2: 39.34  loss_ce_3: 4.375  loss_mask_3: 38.97  loss_ce_4: 4.68  loss_mask_4: 41.16  loss_ce_5: 4.39  loss_mask_5: 43.64  loss_ce_6: 4.201  loss_mask_6: 42.73  loss_ce_7: 4.261  loss_mask_7: 39.57  loss_ce_8: 4.28  loss_mask_8: 42.11  time: 2.5462  data_time: 0.4760  lr: 9.7598e-05  max_mem: 18472M
[01/23 20:47:10] detectron2 INFO: Rank of current process: 0. World size: 1
[01/23 20:47:13] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/23 20:47:13] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8', 'MODEL.RESNETS.NORM', 'BN'], resume=False)
[01/23 20:47:13] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/23 20:47:14] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0e-05[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/23 20:47:14] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/config.yaml
[01/23 20:47:14] d2.utils.env INFO: Using a generated random seed 14534468
[01/23 20:47:21] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 5.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 1.0, 'loss_mask': 5.0, 'loss_ce_0': 1.0, 'loss_mask_0': 5.0, 'loss_ce_1': 1.0, 'loss_mask_1': 5.0, 'loss_ce_2': 1.0, 'loss_mask_2': 5.0, 'loss_ce_3': 1.0, 'loss_mask_3': 5.0, 'loss_ce_4': 1.0, 'loss_mask_4': 5.0, 'loss_ce_5': 1.0, 'loss_mask_5': 5.0, 'loss_ce_6': 1.0, 'loss_mask_6': 5.0, 'loss_ce_7': 1.0, 'loss_mask_7': 5.0, 'loss_ce_8': 1.0, 'loss_mask_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/23 20:47:21] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/23 20:47:36] d2.data.build INFO: Using training sampler TrainingSampler
[01/23 20:47:36] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/23 20:47:36] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/23 20:47:36] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/23 20:47:36] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/23 20:47:36] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/23 20:47:36] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/23 20:47:36] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/23 20:47:36] d2.engine.train_loop INFO: Starting training from iteration 0
[01/23 20:47:36] d2.utils.events INFO:  eta: 1 day, 18:07:22  iter: 1619  total_loss: 470  loss_ce: 4.264  loss_mask: 43.32  loss_ce_0: 5.103  loss_mask_0: 38.46  loss_ce_1: 4.271  loss_mask_1: 39.93  loss_ce_2: 4.443  loss_mask_2: 39.28  loss_ce_3: 4.356  loss_mask_3: 41.09  loss_ce_4: 4.557  loss_mask_4: 42.48  loss_ce_5: 4.387  loss_mask_5: 43.97  loss_ce_6: 4.353  loss_mask_6: 46.09  loss_ce_7: 4.359  loss_mask_7: 43.01  loss_ce_8: 4.375  loss_mask_8: 43.26  time: 2.5479  data_time: 0.4356  lr: 9.7568e-05  max_mem: 18472M
[01/23 20:48:12] d2.utils.events INFO:  eta: 17:51:28  iter: 19  total_loss: 1332  loss_ce: 5.249  loss_mask: 130.4  loss_ce_0: 4.871  loss_mask_0: 120.1  loss_ce_1: 5.279  loss_mask_1: 123.2  loss_ce_2: 5.264  loss_mask_2: 126.6  loss_ce_3: 5.341  loss_mask_3: 128.4  loss_ce_4: 5.45  loss_mask_4: 129.1  loss_ce_5: 5.497  loss_mask_5: 129.6  loss_ce_6: 5.357  loss_mask_6: 130  loss_ce_7: 5.395  loss_mask_7: 130.5  loss_ce_8: 5.382  loss_mask_8: 130.6  time: 1.2687  data_time: 0.1099  lr: 1.9975e-07  max_mem: 9489M
[01/23 20:48:31] d2.utils.events INFO:  eta: 1 day, 18:06:28  iter: 1639  total_loss: 458.6  loss_ce: 4.277  loss_mask: 42.5  loss_ce_0: 5.114  loss_mask_0: 37.28  loss_ce_1: 4.253  loss_mask_1: 38.44  loss_ce_2: 4.461  loss_mask_2: 41.87  loss_ce_3: 4.523  loss_mask_3: 39.09  loss_ce_4: 4.405  loss_mask_4: 40.51  loss_ce_5: 4.351  loss_mask_5: 43.45  loss_ce_6: 4.376  loss_mask_6: 46.58  loss_ce_7: 4.324  loss_mask_7: 44.44  loss_ce_8: 4.266  loss_mask_8: 43.12  time: 2.5498  data_time: 0.4547  lr: 9.7538e-05  max_mem: 18472M
[01/23 20:49:24] d2.utils.events INFO:  eta: 1 day, 18:10:50  iter: 1659  total_loss: 461.7  loss_ce: 4.337  loss_mask: 40.98  loss_ce_0: 5.12  loss_mask_0: 37.26  loss_ce_1: 4.227  loss_mask_1: 37.46  loss_ce_2: 4.442  loss_mask_2: 39.61  loss_ce_3: 4.536  loss_mask_3: 40.14  loss_ce_4: 4.364  loss_mask_4: 42.97  loss_ce_5: 4.397  loss_mask_5: 43.43  loss_ce_6: 4.363  loss_mask_6: 47.17  loss_ce_7: 4.289  loss_mask_7: 42.81  loss_ce_8: 4.252  loss_mask_8: 43.6  time: 2.5512  data_time: 0.4780  lr: 9.7508e-05  max_mem: 18472M
[01/23 20:50:16] d2.utils.events INFO:  eta: 1 day, 18:14:12  iter: 1679  total_loss: 479.1  loss_ce: 4.228  loss_mask: 42.62  loss_ce_0: 5.114  loss_mask_0: 37.75  loss_ce_1: 4.244  loss_mask_1: 39.42  loss_ce_2: 4.414  loss_mask_2: 42.71  loss_ce_3: 4.374  loss_mask_3: 43.07  loss_ce_4: 4.291  loss_mask_4: 44.06  loss_ce_5: 4.392  loss_mask_5: 47.47  loss_ce_6: 4.268  loss_mask_6: 46.76  loss_ce_7: 4.299  loss_mask_7: 45.64  loss_ce_8: 4.22  loss_mask_8: 41.78  time: 2.5515  data_time: 0.4279  lr: 9.7478e-05  max_mem: 18472M
[01/23 20:51:13] d2.utils.events INFO:  eta: 1 day, 18:21:26  iter: 1699  total_loss: 449.3  loss_ce: 4.208  loss_mask: 39.96  loss_ce_0: 5.109  loss_mask_0: 36.65  loss_ce_1: 4.259  loss_mask_1: 38.49  loss_ce_2: 4.372  loss_mask_2: 39.21  loss_ce_3: 4.416  loss_mask_3: 40.26  loss_ce_4: 4.234  loss_mask_4: 39.89  loss_ce_5: 4.33  loss_mask_5: 42.73  loss_ce_6: 4.256  loss_mask_6: 43.62  loss_ce_7: 4.305  loss_mask_7: 44.93  loss_ce_8: 4.24  loss_mask_8: 41.31  time: 2.5551  data_time: 0.4922  lr: 9.7448e-05  max_mem: 18472M
[01/23 20:52:05] d2.utils.events INFO:  eta: 1 day, 18:27:18  iter: 1719  total_loss: 444  loss_ce: 4.258  loss_mask: 41  loss_ce_0: 5.11  loss_mask_0: 36.68  loss_ce_1: 4.279  loss_mask_1: 38.05  loss_ce_2: 4.404  loss_mask_2: 39.96  loss_ce_3: 4.454  loss_mask_3: 38.89  loss_ce_4: 4.317  loss_mask_4: 38.71  loss_ce_5: 4.364  loss_mask_5: 40.84  loss_ce_6: 4.338  loss_mask_6: 42.84  loss_ce_7: 4.306  loss_mask_7: 40.98  loss_ce_8: 4.281  loss_mask_8: 39.81  time: 2.5557  data_time: 0.4402  lr: 9.7418e-05  max_mem: 18472M
[01/23 20:52:56] d2.utils.events INFO:  eta: 1 day, 18:29:01  iter: 1739  total_loss: 425.1  loss_ce: 4.27  loss_mask: 38.05  loss_ce_0: 5.13  loss_mask_0: 34.35  loss_ce_1: 4.334  loss_mask_1: 36.37  loss_ce_2: 4.469  loss_mask_2: 37.55  loss_ce_3: 4.569  loss_mask_3: 38.08  loss_ce_4: 4.323  loss_mask_4: 38.78  loss_ce_5: 4.332  loss_mask_5: 38.1  loss_ce_6: 4.278  loss_mask_6: 41.17  loss_ce_7: 4.38  loss_mask_7: 40.12  loss_ce_8: 4.281  loss_mask_8: 38.27  time: 2.5559  data_time: 0.4192  lr: 9.7388e-05  max_mem: 18472M
[01/23 20:53:51] d2.utils.events INFO:  eta: 1 day, 18:34:43  iter: 1759  total_loss: 427.7  loss_ce: 4.214  loss_mask: 40.48  loss_ce_0: 5.114  loss_mask_0: 35.3  loss_ce_1: 4.343  loss_mask_1: 36.88  loss_ce_2: 4.458  loss_mask_2: 37.79  loss_ce_3: 4.483  loss_mask_3: 39.43  loss_ce_4: 4.243  loss_mask_4: 39.88  loss_ce_5: 4.272  loss_mask_5: 40.59  loss_ce_6: 4.272  loss_mask_6: 40.85  loss_ce_7: 4.266  loss_mask_7: 39.53  loss_ce_8: 4.32  loss_mask_8: 39.76  time: 2.5581  data_time: 0.5223  lr: 9.7358e-05  max_mem: 18472M
[01/23 20:54:42] d2.utils.events INFO:  eta: 1 day, 18:34:53  iter: 1779  total_loss: 419  loss_ce: 4.169  loss_mask: 38.16  loss_ce_0: 5.115  loss_mask_0: 34.32  loss_ce_1: 4.272  loss_mask_1: 36.22  loss_ce_2: 4.405  loss_mask_2: 37.28  loss_ce_3: 4.448  loss_mask_3: 38.42  loss_ce_4: 4.334  loss_mask_4: 38.03  loss_ce_5: 4.312  loss_mask_5: 38.46  loss_ce_6: 4.276  loss_mask_6: 39.36  loss_ce_7: 4.247  loss_mask_7: 39.68  loss_ce_8: 4.237  loss_mask_8: 36.96  time: 2.5575  data_time: 0.4045  lr: 9.7328e-05  max_mem: 18472M
[01/23 20:55:37] d2.utils.events INFO:  eta: 1 day, 18:35:50  iter: 1799  total_loss: 416.5  loss_ce: 4.185  loss_mask: 38.21  loss_ce_0: 5.099  loss_mask_0: 33.17  loss_ce_1: 4.362  loss_mask_1: 35.54  loss_ce_2: 4.404  loss_mask_2: 37.61  loss_ce_3: 4.434  loss_mask_3: 36.76  loss_ce_4: 4.275  loss_mask_4: 37.12  loss_ce_5: 4.281  loss_mask_5: 39.98  loss_ce_6: 4.234  loss_mask_6: 40.42  loss_ce_7: 4.188  loss_mask_7: 38.51  loss_ce_8: 4.174  loss_mask_8: 37.18  time: 2.5597  data_time: 0.4865  lr: 9.7297e-05  max_mem: 18472M
[01/23 20:56:28] d2.utils.events INFO:  eta: 1 day, 18:33:07  iter: 1819  total_loss: 425.4  loss_ce: 4.314  loss_mask: 38.84  loss_ce_0: 5.12  loss_mask_0: 32.86  loss_ce_1: 4.4  loss_mask_1: 34.27  loss_ce_2: 4.394  loss_mask_2: 36.1  loss_ce_3: 4.462  loss_mask_3: 37.91  loss_ce_4: 4.399  loss_mask_4: 38.81  loss_ce_5: 4.337  loss_mask_5: 39.23  loss_ce_6: 4.489  loss_mask_6: 40.09  loss_ce_7: 4.369  loss_mask_7: 41.83  loss_ce_8: 4.342  loss_mask_8: 39.6  time: 2.5597  data_time: 0.4578  lr: 9.7267e-05  max_mem: 18472M
[01/23 20:57:18] d2.utils.events INFO:  eta: 1 day, 18:31:43  iter: 1839  total_loss: 426.7  loss_ce: 4.42  loss_mask: 38.85  loss_ce_0: 5.1  loss_mask_0: 32.82  loss_ce_1: 4.393  loss_mask_1: 36.5  loss_ce_2: 4.384  loss_mask_2: 38.02  loss_ce_3: 4.479  loss_mask_3: 39.48  loss_ce_4: 4.516  loss_mask_4: 40.6  loss_ce_5: 4.489  loss_mask_5: 39.19  loss_ce_6: 4.564  loss_mask_6: 40.47  loss_ce_7: 4.461  loss_mask_7: 39.34  loss_ce_8: 4.511  loss_mask_8: 38.69  time: 2.5591  data_time: 0.4206  lr: 9.7237e-05  max_mem: 18472M
[01/23 20:58:13] d2.utils.events INFO:  eta: 1 day, 18:34:34  iter: 1859  total_loss: 463.5  loss_ce: 4.427  loss_mask: 42.38  loss_ce_0: 5.11  loss_mask_0: 36.59  loss_ce_1: 4.504  loss_mask_1: 39.32  loss_ce_2: 4.538  loss_mask_2: 40.59  loss_ce_3: 4.706  loss_mask_3: 40.4  loss_ce_4: 4.74  loss_mask_4: 42.53  loss_ce_5: 4.547  loss_mask_5: 42.52  loss_ce_6: 4.669  loss_mask_6: 47.8  loss_ce_7: 4.793  loss_mask_7: 43.22  loss_ce_8: 4.49  loss_mask_8: 42.88  time: 2.5613  data_time: 0.4937  lr: 9.7207e-05  max_mem: 18472M
[01/23 20:59:03] d2.utils.events INFO:  eta: 1 day, 18:29:57  iter: 1879  total_loss: 440.7  loss_ce: 4.381  loss_mask: 38.99  loss_ce_0: 5.117  loss_mask_0: 31.82  loss_ce_1: 4.551  loss_mask_1: 36.88  loss_ce_2: 4.645  loss_mask_2: 38.28  loss_ce_3: 4.722  loss_mask_3: 40.14  loss_ce_4: 4.85  loss_mask_4: 40.15  loss_ce_5: 4.883  loss_mask_5: 47.15  loss_ce_6: 4.616  loss_mask_6: 44.07  loss_ce_7: 4.54  loss_mask_7: 41.55  loss_ce_8: 4.432  loss_mask_8: 38.34  time: 2.5603  data_time: 0.4158  lr: 9.7177e-05  max_mem: 18472M
[01/23 20:59:53] d2.utils.events INFO:  eta: 1 day, 18:27:46  iter: 1899  total_loss: 475  loss_ce: 4.502  loss_mask: 43.39  loss_ce_0: 5.111  loss_mask_0: 35.29  loss_ce_1: 4.511  loss_mask_1: 40.28  loss_ce_2: 4.586  loss_mask_2: 40.61  loss_ce_3: 4.646  loss_mask_3: 43.83  loss_ce_4: 4.807  loss_mask_4: 42.98  loss_ce_5: 4.708  loss_mask_5: 46.57  loss_ce_6: 4.482  loss_mask_6: 45.17  loss_ce_7: 4.477  loss_mask_7: 43.99  loss_ce_8: 4.475  loss_mask_8: 40.83  time: 2.5597  data_time: 0.4243  lr: 9.7147e-05  max_mem: 18472M
[01/23 21:00:43] d2.utils.events INFO:  eta: 1 day, 18:24:31  iter: 1919  total_loss: 448.3  loss_ce: 4.445  loss_mask: 40.48  loss_ce_0: 5.123  loss_mask_0: 34.47  loss_ce_1: 4.428  loss_mask_1: 38.79  loss_ce_2: 4.437  loss_mask_2: 39.41  loss_ce_3: 4.358  loss_mask_3: 39.11  loss_ce_4: 4.359  loss_mask_4: 39.07  loss_ce_5: 4.386  loss_mask_5: 42.34  loss_ce_6: 4.533  loss_mask_6: 42.33  loss_ce_7: 4.446  loss_mask_7: 42.63  loss_ce_8: 4.452  loss_mask_8: 43.85  time: 2.5589  data_time: 0.4159  lr: 9.7117e-05  max_mem: 18472M
[01/23 21:01:32] d2.utils.events INFO:  eta: 1 day, 18:17:12  iter: 1939  total_loss: 447.3  loss_ce: 4.555  loss_mask: 39.19  loss_ce_0: 5.118  loss_mask_0: 34.92  loss_ce_1: 4.497  loss_mask_1: 41.77  loss_ce_2: 4.571  loss_mask_2: 42.32  loss_ce_3: 4.393  loss_mask_3: 41.55  loss_ce_4: 4.39  loss_mask_4: 40.94  loss_ce_5: 4.465  loss_mask_5: 43.82  loss_ce_6: 4.498  loss_mask_6: 40.25  loss_ce_7: 4.561  loss_mask_7: 39.21  loss_ce_8: 4.468  loss_mask_8: 40.31  time: 2.5581  data_time: 0.4218  lr: 9.7087e-05  max_mem: 18472M
[01/23 21:02:21] d2.utils.events INFO:  eta: 1 day, 18:16:20  iter: 1959  total_loss: 464.1  loss_ce: 4.356  loss_mask: 39.58  loss_ce_0: 5.12  loss_mask_0: 36.97  loss_ce_1: 4.581  loss_mask_1: 41.89  loss_ce_2: 4.637  loss_mask_2: 42.13  loss_ce_3: 4.644  loss_mask_3: 48.41  loss_ce_4: 4.572  loss_mask_4: 45.02  loss_ce_5: 4.621  loss_mask_5: 41.57  loss_ce_6: 4.41  loss_mask_6: 40.83  loss_ce_7: 4.41  loss_mask_7: 41.26  loss_ce_8: 4.449  loss_mask_8: 38.96  time: 2.5570  data_time: 0.3956  lr: 9.7057e-05  max_mem: 18472M
[01/23 21:03:10] d2.utils.events INFO:  eta: 1 day, 18:11:31  iter: 1979  total_loss: 452  loss_ce: 4.329  loss_mask: 39.63  loss_ce_0: 5.121  loss_mask_0: 36.2  loss_ce_1: 4.867  loss_mask_1: 40.21  loss_ce_2: 4.956  loss_mask_2: 39.75  loss_ce_3: 5.356  loss_mask_3: 42.8  loss_ce_4: 5.251  loss_mask_4: 43.64  loss_ce_5: 4.47  loss_mask_5: 40.09  loss_ce_6: 4.357  loss_mask_6: 41.05  loss_ce_7: 4.319  loss_mask_7: 40.55  loss_ce_8: 4.35  loss_mask_8: 39.13  time: 2.5557  data_time: 0.4070  lr: 9.7027e-05  max_mem: 18472M
[01/23 21:03:59] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/23 21:04:00] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/23 21:04:00] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/23 21:07:27] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 25.974576498965995, 'error_1pix': 0.9540038120961499, 'error_3pix': 0.8952458627717053, 'mIoU': 0.020848768626002, 'fwIoU': 0.07110856641718656, 'IoU-0': nan, 'IoU-1': 0.1231488500296574, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0002630779328914501, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0002561625562306597, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.02690642334162509, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 2.6147806332402523e-06, 'IoU-17': 0.0, 'IoU-18': 0.01938031899381606, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.014909544912530121, 'IoU-22': 1.7999194013937612, 'IoU-23': 1.5713294844554482, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0006651282145488245, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.00016188903431777713, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.20961414002598389, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.14307735743658878, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0023731177023664255, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.019293474054952974, 'IoU-74': 0.0714637052877385, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.00019888603929391478, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.507979670828843, 'pACC': 1.4879848245721081, 'ACC-0': nan, 'ACC-1': 0.156286914090993, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.00031563514471082295, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0002680694387124687, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.05803109975202352, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 2.6482216966208347e-06, 'ACC-17': 0.0, 'ACC-18': 0.03265902583158216, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.016234565041162885, 'ACC-22': 32.726669380537196, 'ACC-23': 63.17139583131915, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.000665723682998982, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.000165014859195178, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 1.0815329416651407, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.18568027568392986, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0023773051420444575, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.019833649272132693, 'ACC-74': 0.07977964087615126, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0001990785790169187, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/23 21:07:27] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/23 21:07:27] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/23 21:07:27] d2.evaluation.testing INFO: copypaste: 25.9746,0.9540,0.8952,0.0208,0.0711,0.5080,1.4880
[01/23 21:07:27] d2.utils.events INFO:  eta: 1 day, 18:07:35  iter: 1999  total_loss: 458.3  loss_ce: 4.338  loss_mask: 41.42  loss_ce_0: 5.122  loss_mask_0: 38.22  loss_ce_1: 4.658  loss_mask_1: 41.78  loss_ce_2: 4.486  loss_mask_2: 40.97  loss_ce_3: 4.475  loss_mask_3: 43.12  loss_ce_4: 4.399  loss_mask_4: 42.71  loss_ce_5: 4.349  loss_mask_5: 41.51  loss_ce_6: 4.403  loss_mask_6: 43.17  loss_ce_7: 4.353  loss_mask_7: 43.5  loss_ce_8: 4.362  loss_mask_8: 39.87  time: 2.5550  data_time: 0.4123  lr: 9.6996e-05  max_mem: 18472M
[01/23 21:08:23] d2.utils.events INFO:  eta: 1 day, 18:10:38  iter: 2019  total_loss: 443.8  loss_ce: 4.251  loss_mask: 42.88  loss_ce_0: 5.122  loss_mask_0: 35.32  loss_ce_1: 4.39  loss_mask_1: 39.26  loss_ce_2: 4.253  loss_mask_2: 39.69  loss_ce_3: 4.586  loss_mask_3: 43.48  loss_ce_4: 4.437  loss_mask_4: 40.45  loss_ce_5: 4.265  loss_mask_5: 44.75  loss_ce_6: 4.649  loss_mask_6: 40.18  loss_ce_7: 4.376  loss_mask_7: 42.05  loss_ce_8: 4.222  loss_mask_8: 38.52  time: 2.5577  data_time: 0.5019  lr: 9.6966e-05  max_mem: 18472M
[01/23 21:09:15] d2.utils.events INFO:  eta: 1 day, 18:10:10  iter: 2039  total_loss: 457.3  loss_ce: 4.495  loss_mask: 40.94  loss_ce_0: 5.11  loss_mask_0: 37.36  loss_ce_1: 4.335  loss_mask_1: 38.32  loss_ce_2: 4.38  loss_mask_2: 38.52  loss_ce_3: 4.831  loss_mask_3: 45.68  loss_ce_4: 4.646  loss_mask_4: 41.09  loss_ce_5: 4.353  loss_mask_5: 41.18  loss_ce_6: 4.704  loss_mask_6: 42.72  loss_ce_7: 4.329  loss_mask_7: 42.65  loss_ce_8: 4.408  loss_mask_8: 41.87  time: 2.5580  data_time: 0.4233  lr: 9.6936e-05  max_mem: 18472M
[01/23 21:10:09] d2.utils.events INFO:  eta: 1 day, 18:06:22  iter: 2059  total_loss: 458.2  loss_ce: 4.637  loss_mask: 44.22  loss_ce_0: 5.108  loss_mask_0: 36.83  loss_ce_1: 4.491  loss_mask_1: 40.61  loss_ce_2: 4.535  loss_mask_2: 39.78  loss_ce_3: 4.654  loss_mask_3: 43.25  loss_ce_4: 4.433  loss_mask_4: 44.46  loss_ce_5: 4.461  loss_mask_5: 43.79  loss_ce_6: 4.426  loss_mask_6: 43.56  loss_ce_7: 4.325  loss_mask_7: 45.05  loss_ce_8: 4.497  loss_mask_8: 39.94  time: 2.5594  data_time: 0.4400  lr: 9.6906e-05  max_mem: 18472M
[01/23 21:11:04] d2.utils.events INFO:  eta: 1 day, 18:10:36  iter: 2079  total_loss: 479.5  loss_ce: 4.46  loss_mask: 47.47  loss_ce_0: 5.117  loss_mask_0: 37.84  loss_ce_1: 4.498  loss_mask_1: 43.23  loss_ce_2: 4.504  loss_mask_2: 42.73  loss_ce_3: 4.542  loss_mask_3: 40.26  loss_ce_4: 4.417  loss_mask_4: 42.86  loss_ce_5: 4.406  loss_mask_5: 47.3  loss_ce_6: 4.388  loss_mask_6: 46.03  loss_ce_7: 4.507  loss_mask_7: 45.22  loss_ce_8: 4.491  loss_mask_8: 42.48  time: 2.5610  data_time: 0.4212  lr: 9.6876e-05  max_mem: 18472M
[01/23 21:15:47] detectron2 INFO: Rank of current process: 0. World size: 4
[01/23 21:15:51] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/23 21:15:51] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/23 21:15:51] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/23 21:15:51] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0e-05[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/23 21:15:51] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/config.yaml
[01/23 21:15:52] d2.utils.env INFO: Using a generated random seed 52109262
[01/23 21:15:54] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 5.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 1.0, 'loss_mask': 5.0, 'loss_ce_0': 1.0, 'loss_mask_0': 5.0, 'loss_ce_1': 1.0, 'loss_mask_1': 5.0, 'loss_ce_2': 1.0, 'loss_mask_2': 5.0, 'loss_ce_3': 1.0, 'loss_mask_3': 5.0, 'loss_ce_4': 1.0, 'loss_mask_4': 5.0, 'loss_ce_5': 1.0, 'loss_mask_5': 5.0, 'loss_ce_6': 1.0, 'loss_mask_6': 5.0, 'loss_ce_7': 1.0, 'loss_mask_7': 5.0, 'loss_ce_8': 1.0, 'loss_mask_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/23 21:15:54] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/23 21:15:58] d2.data.build INFO: Using training sampler TrainingSampler
[01/23 21:15:58] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/23 21:15:59] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/23 21:15:59] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/23 21:15:59] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/23 21:15:59] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/23 21:15:59] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/23 21:15:59] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/23 21:15:59] d2.engine.train_loop INFO: Starting training from iteration 0
[01/23 21:17:16] d2.utils.events INFO:  eta: 1 day, 22:54:11  iter: 19  total_loss: 1369  loss_ce: 5.296  loss_mask: 134.2  loss_ce_0: 4.851  loss_mask_0: 127.4  loss_ce_1: 4.995  loss_mask_1: 128.2  loss_ce_2: 5.167  loss_mask_2: 129.4  loss_ce_3: 5.28  loss_mask_3: 131.4  loss_ce_4: 5.467  loss_mask_4: 132.1  loss_ce_5: 5.294  loss_mask_5: 133.3  loss_ce_6: 5.23  loss_mask_6: 133.8  loss_ce_7: 5.319  loss_mask_7: 133.9  loss_ce_8: 5.107  loss_mask_8: 134.1  time: 2.7893  data_time: 0.9117  lr: 1.9975e-07  max_mem: 18333M
[01/23 21:18:06] d2.utils.events INFO:  eta: 1 day, 19:34:11  iter: 39  total_loss: 1420  loss_ce: 5.283  loss_mask: 140.1  loss_ce_0: 4.829  loss_mask_0: 130.7  loss_ce_1: 4.981  loss_mask_1: 132.5  loss_ce_2: 5.156  loss_mask_2: 133.8  loss_ce_3: 5.269  loss_mask_3: 136.2  loss_ce_4: 5.456  loss_mask_4: 137.5  loss_ce_5: 5.285  loss_mask_5: 138.9  loss_ce_6: 5.224  loss_mask_6: 139.5  loss_ce_7: 5.305  loss_mask_7: 139.7  loss_ce_8: 5.1  loss_mask_8: 140  time: 2.6466  data_time: 0.4095  lr: 3.9938e-07  max_mem: 18333M
[01/23 21:18:56] d2.utils.events INFO:  eta: 1 day, 18:24:17  iter: 59  total_loss: 1369  loss_ce: 5.23  loss_mask: 134.5  loss_ce_0: 4.867  loss_mask_0: 126.2  loss_ce_1: 4.995  loss_mask_1: 127.9  loss_ce_2: 5.15  loss_mask_2: 129.1  loss_ce_3: 5.256  loss_mask_3: 131.2  loss_ce_4: 5.449  loss_mask_4: 132.3  loss_ce_5: 5.27  loss_mask_5: 133.4  loss_ce_6: 5.195  loss_mask_6: 134  loss_ce_7: 5.276  loss_mask_7: 134.2  loss_ce_8: 5.044  loss_mask_8: 134.4  time: 2.5805  data_time: 0.4328  lr: 5.9888e-07  max_mem: 18435M
[01/23 21:19:49] d2.utils.events INFO:  eta: 1 day, 18:32:33  iter: 79  total_loss: 1395  loss_ce: 5.179  loss_mask: 137.5  loss_ce_0: 4.855  loss_mask_0: 129  loss_ce_1: 4.987  loss_mask_1: 130.2  loss_ce_2: 5.135  loss_mask_2: 131.1  loss_ce_3: 5.23  loss_mask_3: 133.4  loss_ce_4: 5.416  loss_mask_4: 134.7  loss_ce_5: 5.249  loss_mask_5: 136.2  loss_ce_6: 5.167  loss_mask_6: 136.8  loss_ce_7: 5.244  loss_mask_7: 137.1  loss_ce_8: 4.995  loss_mask_8: 137.3  time: 2.6068  data_time: 0.5060  lr: 7.9826e-07  max_mem: 18435M
[01/23 21:20:38] d2.utils.events INFO:  eta: 1 day, 18:17:45  iter: 99  total_loss: 1389  loss_ce: 5.106  loss_mask: 138.1  loss_ce_0: 4.875  loss_mask_0: 127.7  loss_ce_1: 4.999  loss_mask_1: 128.5  loss_ce_2: 5.116  loss_mask_2: 129.6  loss_ce_3: 5.213  loss_mask_3: 132.4  loss_ce_4: 5.389  loss_mask_4: 133.6  loss_ce_5: 5.231  loss_mask_5: 135.6  loss_ce_6: 5.137  loss_mask_6: 137  loss_ce_7: 5.2  loss_mask_7: 137.5  loss_ce_8: 4.928  loss_mask_8: 137.9  time: 2.5690  data_time: 0.3724  lr: 9.9753e-07  max_mem: 18435M
[01/23 21:21:28] d2.utils.events INFO:  eta: 1 day, 18:06:47  iter: 119  total_loss: 1401  loss_ce: 5.038  loss_mask: 140.5  loss_ce_0: 4.871  loss_mask_0: 128.9  loss_ce_1: 4.991  loss_mask_1: 129.2  loss_ce_2: 5.098  loss_mask_2: 129.1  loss_ce_3: 5.194  loss_mask_3: 132  loss_ce_4: 5.362  loss_mask_4: 133.2  loss_ce_5: 5.223  loss_mask_5: 136.5  loss_ce_6: 5.114  loss_mask_6: 139  loss_ce_7: 5.16  loss_mask_7: 139.4  loss_ce_8: 4.869  loss_mask_8: 140.2  time: 2.5563  data_time: 0.4170  lr: 1.1967e-06  max_mem: 18435M
[01/23 21:22:20] d2.utils.events INFO:  eta: 1 day, 18:05:57  iter: 139  total_loss: 1365  loss_ce: 4.965  loss_mask: 137.8  loss_ce_0: 4.867  loss_mask_0: 126.9  loss_ce_1: 4.987  loss_mask_1: 127.5  loss_ce_2: 5.082  loss_mask_2: 127.1  loss_ce_3: 5.174  loss_mask_3: 128.8  loss_ce_4: 5.333  loss_mask_4: 128.6  loss_ce_5: 5.21  loss_mask_5: 130.3  loss_ce_6: 5.084  loss_mask_6: 134.1  loss_ce_7: 5.121  loss_mask_7: 135.1  loss_ce_8: 4.81  loss_mask_8: 137.5  time: 2.5651  data_time: 0.4825  lr: 1.3957e-06  max_mem: 18435M
[01/23 21:23:08] d2.utils.events INFO:  eta: 1 day, 17:37:25  iter: 159  total_loss: 1315  loss_ce: 4.907  loss_mask: 134.3  loss_ce_0: 4.876  loss_mask_0: 122.9  loss_ce_1: 4.995  loss_mask_1: 123.5  loss_ce_2: 5.065  loss_mask_2: 121.7  loss_ce_3: 5.151  loss_mask_3: 123.6  loss_ce_4: 5.288  loss_mask_4: 121.3  loss_ce_5: 5.185  loss_mask_5: 124.3  loss_ce_6: 5.052  loss_mask_6: 128.2  loss_ce_7: 5.083  loss_mask_7: 128.9  loss_ce_8: 4.746  loss_mask_8: 132.6  time: 2.5436  data_time: 0.4336  lr: 1.5946e-06  max_mem: 18435M
[01/23 21:23:59] d2.utils.events INFO:  eta: 1 day, 17:48:51  iter: 179  total_loss: 1207  loss_ce: 4.856  loss_mask: 125.4  loss_ce_0: 4.905  loss_mask_0: 118.1  loss_ce_1: 5.003  loss_mask_1: 117.5  loss_ce_2: 5.05  loss_mask_2: 114.6  loss_ce_3: 5.128  loss_mask_3: 112.4  loss_ce_4: 5.242  loss_mask_4: 108.4  loss_ce_5: 5.156  loss_mask_5: 110.8  loss_ce_6: 5.021  loss_mask_6: 115  loss_ce_7: 5.057  loss_mask_7: 115.2  loss_ce_8: 4.703  loss_mask_8: 120.4  time: 2.5457  data_time: 0.4601  lr: 1.7934e-06  max_mem: 18435M
[01/23 21:24:48] d2.utils.events INFO:  eta: 1 day, 17:30:37  iter: 199  total_loss: 1160  loss_ce: 4.835  loss_mask: 118.1  loss_ce_0: 4.896  loss_mask_0: 116.3  loss_ce_1: 5.004  loss_mask_1: 114.3  loss_ce_2: 5.036  loss_mask_2: 109.4  loss_ce_3: 5.103  loss_mask_3: 107.6  loss_ce_4: 5.202  loss_mask_4: 103.7  loss_ce_5: 5.131  loss_mask_5: 107  loss_ce_6: 5.01  loss_mask_6: 110  loss_ce_7: 5.031  loss_mask_7: 107.3  loss_ce_8: 4.695  loss_mask_8: 112.7  time: 2.5367  data_time: 0.4274  lr: 1.992e-06  max_mem: 18476M
[01/23 21:25:38] d2.utils.events INFO:  eta: 1 day, 17:23:00  iter: 219  total_loss: 1165  loss_ce: 4.804  loss_mask: 117.4  loss_ce_0: 4.894  loss_mask_0: 119  loss_ce_1: 5.013  loss_mask_1: 116.9  loss_ce_2: 5.04  loss_mask_2: 108.9  loss_ce_3: 5.08  loss_mask_3: 106.6  loss_ce_4: 5.181  loss_mask_4: 105.5  loss_ce_5: 5.122  loss_mask_5: 107.7  loss_ce_6: 5.004  loss_mask_6: 109.8  loss_ce_7: 5.019  loss_mask_7: 107.9  loss_ce_8: 4.691  loss_mask_8: 114  time: 2.5291  data_time: 0.4102  lr: 2.1906e-06  max_mem: 18476M
[01/23 21:26:30] d2.utils.events INFO:  eta: 1 day, 17:28:57  iter: 239  total_loss: 1072  loss_ce: 4.774  loss_mask: 104.6  loss_ce_0: 4.906  loss_mask_0: 112.9  loss_ce_1: 5.02  loss_mask_1: 106.9  loss_ce_2: 5.026  loss_mask_2: 99.8  loss_ce_3: 5.058  loss_mask_3: 96.24  loss_ce_4: 5.157  loss_mask_4: 97.3  loss_ce_5: 5.106  loss_mask_5: 98.08  loss_ce_6: 4.989  loss_mask_6: 98.81  loss_ce_7: 5.01  loss_mask_7: 101.6  loss_ce_8: 4.701  loss_mask_8: 103.8  time: 2.5359  data_time: 0.4793  lr: 2.389e-06  max_mem: 18476M
[01/23 21:27:17] d2.utils.events INFO:  eta: 1 day, 17:09:49  iter: 259  total_loss: 1088  loss_ce: 4.768  loss_mask: 105.7  loss_ce_0: 4.902  loss_mask_0: 117.7  loss_ce_1: 5.017  loss_mask_1: 106  loss_ce_2: 5.015  loss_mask_2: 98.97  loss_ce_3: 5.034  loss_mask_3: 99.42  loss_ce_4: 5.126  loss_mask_4: 101.2  loss_ce_5: 5.098  loss_mask_5: 101.4  loss_ce_6: 4.977  loss_mask_6: 101.9  loss_ce_7: 4.993  loss_mask_7: 102.5  loss_ce_8: 4.709  loss_mask_8: 103.2  time: 2.5241  data_time: 0.4022  lr: 2.5873e-06  max_mem: 18476M
[01/23 21:28:05] d2.utils.events INFO:  eta: 1 day, 17:00:59  iter: 279  total_loss: 1038  loss_ce: 4.783  loss_mask: 100.7  loss_ce_0: 4.923  loss_mask_0: 113.1  loss_ce_1: 4.968  loss_mask_1: 99.22  loss_ce_2: 5.002  loss_mask_2: 94.63  loss_ce_3: 5.02  loss_mask_3: 94.8  loss_ce_4: 5.136  loss_mask_4: 95.69  loss_ce_5: 5.105  loss_mask_5: 96.96  loss_ce_6: 4.964  loss_mask_6: 97.29  loss_ce_7: 4.965  loss_mask_7: 98.6  loss_ce_8: 4.719  loss_mask_8: 99.9  time: 2.5129  data_time: 0.3852  lr: 2.7855e-06  max_mem: 18476M
[01/23 21:28:59] d2.utils.events INFO:  eta: 1 day, 17:05:52  iter: 299  total_loss: 1048  loss_ce: 4.802  loss_mask: 105.5  loss_ce_0: 4.911  loss_mask_0: 111.8  loss_ce_1: 4.946  loss_mask_1: 96.86  loss_ce_2: 4.98  loss_mask_2: 95.49  loss_ce_3: 5.002  loss_mask_3: 94.83  loss_ce_4: 5.107  loss_mask_4: 96.07  loss_ce_5: 5.111  loss_mask_5: 97.04  loss_ce_6: 4.968  loss_mask_6: 98.85  loss_ce_7: 4.927  loss_mask_7: 99.71  loss_ce_8: 4.739  loss_mask_8: 102.4  time: 2.5242  data_time: 0.5118  lr: 2.9836e-06  max_mem: 18476M
[01/23 21:29:47] d2.utils.events INFO:  eta: 1 day, 16:55:13  iter: 319  total_loss: 997.2  loss_ce: 4.81  loss_mask: 95.25  loss_ce_0: 4.908  loss_mask_0: 113.5  loss_ce_1: 4.929  loss_mask_1: 93.97  loss_ce_2: 4.941  loss_mask_2: 91.24  loss_ce_3: 4.933  loss_mask_3: 90.58  loss_ce_4: 5.05  loss_mask_4: 91.24  loss_ce_5: 5.062  loss_mask_5: 92.41  loss_ce_6: 4.917  loss_mask_6: 94.7  loss_ce_7: 4.964  loss_mask_7: 93.73  loss_ce_8: 4.79  loss_mask_8: 94.57  time: 2.5181  data_time: 0.4031  lr: 3.1815e-06  max_mem: 18476M
[01/23 21:30:37] d2.utils.events INFO:  eta: 1 day, 16:58:31  iter: 339  total_loss: 1006  loss_ce: 4.893  loss_mask: 94.41  loss_ce_0: 4.925  loss_mask_0: 111.1  loss_ce_1: 4.925  loss_mask_1: 96.18  loss_ce_2: 4.946  loss_mask_2: 92.51  loss_ce_3: 4.902  loss_mask_3: 92.48  loss_ce_4: 4.983  loss_mask_4: 92.54  loss_ce_5: 4.993  loss_mask_5: 93.83  loss_ce_6: 4.885  loss_mask_6: 94.12  loss_ce_7: 5.076  loss_mask_7: 94.48  loss_ce_8: 4.914  loss_mask_8: 95.52  time: 2.5171  data_time: 0.4093  lr: 3.3793e-06  max_mem: 18476M
[01/23 21:31:29] d2.utils.events INFO:  eta: 1 day, 16:52:51  iter: 359  total_loss: 933  loss_ce: 4.847  loss_mask: 87.07  loss_ce_0: 4.923  loss_mask_0: 106.2  loss_ce_1: 4.927  loss_mask_1: 88.9  loss_ce_2: 4.934  loss_mask_2: 85.39  loss_ce_3: 4.873  loss_mask_3: 84.39  loss_ce_4: 4.921  loss_mask_4: 84.51  loss_ce_5: 4.925  loss_mask_5: 85.45  loss_ce_6: 4.855  loss_mask_6: 85.36  loss_ce_7: 5.059  loss_mask_7: 87.85  loss_ce_8: 4.891  loss_mask_8: 87.12  time: 2.5201  data_time: 0.4306  lr: 3.577e-06  max_mem: 18476M
[01/23 21:32:18] d2.utils.events INFO:  eta: 1 day, 16:48:36  iter: 379  total_loss: 913.9  loss_ce: 4.791  loss_mask: 84.94  loss_ce_0: 4.925  loss_mask_0: 103.8  loss_ce_1: 4.929  loss_mask_1: 86.13  loss_ce_2: 4.929  loss_mask_2: 84.01  loss_ce_3: 4.856  loss_mask_3: 83.89  loss_ce_4: 4.925  loss_mask_4: 83.92  loss_ce_5: 4.915  loss_mask_5: 84.84  loss_ce_6: 4.833  loss_mask_6: 84.63  loss_ce_7: 4.989  loss_mask_7: 85.6  loss_ce_8: 4.825  loss_mask_8: 85.51  time: 2.5159  data_time: 0.4087  lr: 3.7746e-06  max_mem: 18476M
[01/23 21:33:10] d2.utils.events INFO:  eta: 1 day, 16:54:01  iter: 399  total_loss: 892.8  loss_ce: 4.725  loss_mask: 83.6  loss_ce_0: 4.918  loss_mask_0: 100.3  loss_ce_1: 4.922  loss_mask_1: 82.77  loss_ce_2: 4.941  loss_mask_2: 82.2  loss_ce_3: 4.86  loss_mask_3: 81.32  loss_ce_4: 4.952  loss_mask_4: 82.09  loss_ce_5: 4.944  loss_mask_5: 82.19  loss_ce_6: 4.83  loss_mask_6: 82.26  loss_ce_7: 4.912  loss_mask_7: 82.15  loss_ce_8: 4.766  loss_mask_8: 82.96  time: 2.5207  data_time: 0.4399  lr: 3.9721e-06  max_mem: 18476M
[01/23 21:34:00] d2.utils.events INFO:  eta: 1 day, 16:54:27  iter: 419  total_loss: 841.3  loss_ce: 4.655  loss_mask: 79.54  loss_ce_0: 4.946  loss_mask_0: 95.63  loss_ce_1: 4.933  loss_mask_1: 78.92  loss_ce_2: 4.942  loss_mask_2: 77.66  loss_ce_3: 4.847  loss_mask_3: 77.56  loss_ce_4: 4.926  loss_mask_4: 77.2  loss_ce_5: 4.929  loss_mask_5: 77.51  loss_ce_6: 4.802  loss_mask_6: 77.78  loss_ce_7: 4.854  loss_mask_7: 77.26  loss_ce_8: 4.672  loss_mask_8: 78.86  time: 2.5204  data_time: 0.4423  lr: 4.1694e-06  max_mem: 18476M
[01/23 21:34:50] d2.utils.events INFO:  eta: 1 day, 16:52:23  iter: 439  total_loss: 885.7  loss_ce: 4.726  loss_mask: 84.12  loss_ce_0: 4.946  loss_mask_0: 96.41  loss_ce_1: 4.94  loss_mask_1: 81.93  loss_ce_2: 4.957  loss_mask_2: 81.66  loss_ce_3: 4.871  loss_mask_3: 82.15  loss_ce_4: 4.973  loss_mask_4: 80.38  loss_ce_5: 5.002  loss_mask_5: 80.4  loss_ce_6: 4.843  loss_mask_6: 81.98  loss_ce_7: 4.91  loss_mask_7: 81.97  loss_ce_8: 4.746  loss_mask_8: 83.17  time: 2.5190  data_time: 0.4344  lr: 4.3667e-06  max_mem: 18476M
[01/23 21:35:45] d2.utils.events INFO:  eta: 1 day, 17:03:08  iter: 459  total_loss: 855.4  loss_ce: 4.721  loss_mask: 81.39  loss_ce_0: 4.948  loss_mask_0: 94.87  loss_ce_1: 4.948  loss_mask_1: 79.07  loss_ce_2: 4.972  loss_mask_2: 78.11  loss_ce_3: 4.886  loss_mask_3: 78.53  loss_ce_4: 4.976  loss_mask_4: 78.15  loss_ce_5: 5.013  loss_mask_5: 78.15  loss_ce_6: 4.866  loss_mask_6: 77.92  loss_ce_7: 4.923  loss_mask_7: 78.54  loss_ce_8: 4.757  loss_mask_8: 79.87  time: 2.5287  data_time: 0.5233  lr: 4.5638e-06  max_mem: 18476M
[01/23 21:36:35] d2.utils.events INFO:  eta: 1 day, 16:58:48  iter: 479  total_loss: 846.4  loss_ce: 4.832  loss_mask: 78.95  loss_ce_0: 4.929  loss_mask_0: 91.56  loss_ce_1: 4.944  loss_mask_1: 78.95  loss_ce_2: 4.98  loss_mask_2: 79.43  loss_ce_3: 4.902  loss_mask_3: 78.51  loss_ce_4: 5.01  loss_mask_4: 77.9  loss_ce_5: 5.055  loss_mask_5: 77.18  loss_ce_6: 4.91  loss_mask_6: 77.4  loss_ce_7: 4.972  loss_mask_7: 77.18  loss_ce_8: 4.827  loss_mask_8: 78.87  time: 2.5269  data_time: 0.4154  lr: 4.7607e-06  max_mem: 18476M
[01/23 21:37:23] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/23 21:37:24] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/23 21:37:24] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/23 21:41:08] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 53.156373736214434, 'error_1pix': 0.9725334965669997, 'error_3pix': 0.9341333153753095, 'mIoU': 0.02388490615820861, 'fwIoU': 0.055470673280917336, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0003467135645302593, 'IoU-3': 0.042068839806295846, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.004632342844420796, 'IoU-7': 0.005001509200569633, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.23437780804083114, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.22780704394597856, 'IoU-15': 0.0, 'IoU-16': 0.8492914159744309, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.007720829995073584, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 1.6734164145000947, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.52843416707917, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.03932950859358441, 'IoU-45': 0.0, 'IoU-46': 0.00017569990978422539, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.06478755642290929, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.012128017967434025, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.07860137657159107, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.22945688162202157, 'IoU-111': 0.0, 'IoU-112': 0.03446689423489799, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.031126463351954146, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0376044340532675, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.027863854507812, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.018841151512256512, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.019900956016039587, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.3901991996624876, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.028322902998617856, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.4479273638676682, 'pACC': 0.8685325164369827, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0004622398144532406, 'ACC-3': 2.4161700377353257, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.10140780943610014, 'ACC-7': 0.8964415808875812, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.32196386423966156, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.35113354558878407, 'ACC-15': 0.0, 'ACC-16': 4.811879731859079, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.007901779444813793, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 47.41832225690135, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.740987572812812, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.04061926562088609, 'ACC-45': 0.0, 'ACC-46': 0.00017695436840664937, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.06689298757297568, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.013439613244151067, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.09609940074244613, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 14.39505186276278, 'ACC-111': 0.0, 'ACC-112': 0.7160307472811852, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 5.98739532709952, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.047384451387075144, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.06335740072202166, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 1.696050678832518, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.48836345040291973, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 1.0720193870443464, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 4.25250191679109, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/23 21:41:08] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/23 21:41:08] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/23 21:41:08] d2.evaluation.testing INFO: copypaste: 53.1564,0.9725,0.9341,0.0239,0.0555,0.4479,0.8685
[01/23 21:41:08] d2.utils.events INFO:  eta: 1 day, 16:51:09  iter: 499  total_loss: 824.4  loss_ce: 4.814  loss_mask: 76.39  loss_ce_0: 4.943  loss_mask_0: 93.71  loss_ce_1: 4.951  loss_mask_1: 77.48  loss_ce_2: 4.983  loss_mask_2: 78.21  loss_ce_3: 4.908  loss_mask_3: 76.42  loss_ce_4: 5.018  loss_mask_4: 74.9  loss_ce_5: 5.052  loss_mask_5: 75.03  loss_ce_6: 4.921  loss_mask_6: 75.32  loss_ce_7: 4.978  loss_mask_7: 75.04  loss_ce_8: 4.83  loss_mask_8: 76.37  time: 2.5231  data_time: 0.3841  lr: 4.9576e-06  max_mem: 18476M
[01/23 21:41:59] d2.utils.events INFO:  eta: 1 day, 16:57:09  iter: 519  total_loss: 783  loss_ce: 4.783  loss_mask: 73.3  loss_ce_0: 4.922  loss_mask_0: 88.64  loss_ce_1: 4.943  loss_mask_1: 72.29  loss_ce_2: 4.979  loss_mask_2: 71.88  loss_ce_3: 4.9  loss_mask_3: 72.09  loss_ce_4: 4.983  loss_mask_4: 70.37  loss_ce_5: 5.003  loss_mask_5: 71.32  loss_ce_6: 4.886  loss_mask_6: 71.79  loss_ce_7: 4.932  loss_mask_7: 71.21  loss_ce_8: 4.789  loss_mask_8: 72.35  time: 2.5236  data_time: 0.4239  lr: 5.1544e-06  max_mem: 18476M
[01/23 21:42:52] d2.utils.events INFO:  eta: 1 day, 17:02:14  iter: 539  total_loss: 784.5  loss_ce: 4.772  loss_mask: 73.82  loss_ce_0: 4.942  loss_mask_0: 86.34  loss_ce_1: 4.948  loss_mask_1: 74.19  loss_ce_2: 4.975  loss_mask_2: 73.13  loss_ce_3: 4.89  loss_mask_3: 72.04  loss_ce_4: 4.977  loss_mask_4: 71.63  loss_ce_5: 5.005  loss_mask_5: 71.44  loss_ce_6: 4.878  loss_mask_6: 72.01  loss_ce_7: 4.925  loss_mask_7: 72.03  loss_ce_8: 4.764  loss_mask_8: 73.46  time: 2.5286  data_time: 0.4470  lr: 5.351e-06  max_mem: 18476M
[01/23 21:43:44] d2.utils.events INFO:  eta: 1 day, 17:02:54  iter: 559  total_loss: 755.9  loss_ce: 4.756  loss_mask: 69.68  loss_ce_0: 4.955  loss_mask_0: 84.44  loss_ce_1: 4.951  loss_mask_1: 71.43  loss_ce_2: 4.973  loss_mask_2: 70.14  loss_ce_3: 4.884  loss_mask_3: 68.76  loss_ce_4: 4.969  loss_mask_4: 69.49  loss_ce_5: 4.995  loss_mask_5: 68.29  loss_ce_6: 4.865  loss_mask_6: 68.33  loss_ce_7: 4.918  loss_mask_7: 68.23  loss_ce_8: 4.745  loss_mask_8: 68.75  time: 2.5304  data_time: 0.4185  lr: 5.5475e-06  max_mem: 18476M
[01/23 21:44:35] d2.utils.events INFO:  eta: 1 day, 17:07:22  iter: 579  total_loss: 789.9  loss_ce: 4.703  loss_mask: 73.83  loss_ce_0: 4.939  loss_mask_0: 86.57  loss_ce_1: 4.929  loss_mask_1: 76.14  loss_ce_2: 4.955  loss_mask_2: 73.79  loss_ce_3: 4.869  loss_mask_3: 72.59  loss_ce_4: 4.923  loss_mask_4: 72.46  loss_ce_5: 4.938  loss_mask_5: 71.54  loss_ce_6: 4.822  loss_mask_6: 71.57  loss_ce_7: 4.875  loss_mask_7: 71.73  loss_ce_8: 4.714  loss_mask_8: 72.03  time: 2.5307  data_time: 0.4174  lr: 5.7439e-06  max_mem: 18476M
[01/23 21:45:30] d2.utils.events INFO:  eta: 1 day, 17:13:57  iter: 599  total_loss: 747.7  loss_ce: 4.72  loss_mask: 68.95  loss_ce_0: 4.952  loss_mask_0: 83.11  loss_ce_1: 4.929  loss_mask_1: 70.76  loss_ce_2: 4.959  loss_mask_2: 68.97  loss_ce_3: 4.88  loss_mask_3: 67.47  loss_ce_4: 4.946  loss_mask_4: 67.59  loss_ce_5: 4.963  loss_mask_5: 68.42  loss_ce_6: 4.817  loss_mask_6: 67.76  loss_ce_7: 4.883  loss_mask_7: 68.26  loss_ce_8: 4.726  loss_mask_8: 67.79  time: 2.5384  data_time: 0.4678  lr: 5.9401e-06  max_mem: 18476M
[01/23 21:46:19] d2.utils.events INFO:  eta: 1 day, 17:11:27  iter: 619  total_loss: 715.5  loss_ce: 4.659  loss_mask: 65.64  loss_ce_0: 4.96  loss_mask_0: 79.79  loss_ce_1: 4.924  loss_mask_1: 69.42  loss_ce_2: 4.948  loss_mask_2: 66.92  loss_ce_3: 4.853  loss_mask_3: 64.88  loss_ce_4: 4.895  loss_mask_4: 65.14  loss_ce_5: 4.922  loss_mask_5: 63.27  loss_ce_6: 4.762  loss_mask_6: 64.69  loss_ce_7: 4.809  loss_mask_7: 64.08  loss_ce_8: 4.644  loss_mask_8: 65.06  time: 2.5357  data_time: 0.3981  lr: 6.1363e-06  max_mem: 18476M
[01/23 21:47:09] d2.utils.events INFO:  eta: 1 day, 17:05:34  iter: 639  total_loss: 705.1  loss_ce: 4.717  loss_mask: 65.39  loss_ce_0: 4.957  loss_mask_0: 77.93  loss_ce_1: 4.931  loss_mask_1: 67.24  loss_ce_2: 4.944  loss_mask_2: 65.92  loss_ce_3: 4.836  loss_mask_3: 64.11  loss_ce_4: 4.888  loss_mask_4: 65.03  loss_ce_5: 4.918  loss_mask_5: 64.12  loss_ce_6: 4.783  loss_mask_6: 64.23  loss_ce_7: 4.839  loss_mask_7: 64.06  loss_ce_8: 4.703  loss_mask_8: 64.27  time: 2.5344  data_time: 0.3832  lr: 6.3323e-06  max_mem: 18476M
[01/23 21:48:03] d2.utils.events INFO:  eta: 1 day, 17:09:48  iter: 659  total_loss: 710.6  loss_ce: 4.711  loss_mask: 65.91  loss_ce_0: 4.951  loss_mask_0: 76.4  loss_ce_1: 4.928  loss_mask_1: 67.74  loss_ce_2: 4.928  loss_mask_2: 65.32  loss_ce_3: 4.814  loss_mask_3: 63.53  loss_ce_4: 4.851  loss_mask_4: 63.76  loss_ce_5: 4.88  loss_mask_5: 64.55  loss_ce_6: 4.726  loss_mask_6: 64.86  loss_ce_7: 4.791  loss_mask_7: 65.01  loss_ce_8: 4.676  loss_mask_8: 65.44  time: 2.5393  data_time: 0.4632  lr: 6.5282e-06  max_mem: 18476M
[01/23 21:48:53] d2.utils.events INFO:  eta: 1 day, 17:09:10  iter: 679  total_loss: 710  loss_ce: 4.732  loss_mask: 66.44  loss_ce_0: 4.961  loss_mask_0: 77.76  loss_ce_1: 4.923  loss_mask_1: 67.82  loss_ce_2: 4.918  loss_mask_2: 65.15  loss_ce_3: 4.818  loss_mask_3: 64.61  loss_ce_4: 4.85  loss_mask_4: 63.59  loss_ce_5: 4.875  loss_mask_5: 63.76  loss_ce_6: 4.728  loss_mask_6: 63.24  loss_ce_7: 4.796  loss_mask_7: 64.5  loss_ce_8: 4.691  loss_mask_8: 64.67  time: 2.5384  data_time: 0.4209  lr: 6.724e-06  max_mem: 18476M
[01/23 21:49:46] d2.utils.events INFO:  eta: 1 day, 17:10:50  iter: 699  total_loss: 711.8  loss_ce: 4.731  loss_mask: 66.47  loss_ce_0: 4.953  loss_mask_0: 75.51  loss_ce_1: 4.91  loss_mask_1: 68.97  loss_ce_2: 4.888  loss_mask_2: 64.4  loss_ce_3: 4.78  loss_mask_3: 64.93  loss_ce_4: 4.789  loss_mask_4: 64.63  loss_ce_5: 4.816  loss_mask_5: 63.86  loss_ce_6: 4.676  loss_mask_6: 65.09  loss_ce_7: 4.725  loss_mask_7: 64.84  loss_ce_8: 4.636  loss_mask_8: 65.66  time: 2.5417  data_time: 0.4689  lr: 6.9196e-06  max_mem: 18476M
[01/23 21:50:39] d2.utils.events INFO:  eta: 1 day, 17:15:34  iter: 719  total_loss: 666.4  loss_ce: 4.762  loss_mask: 61.45  loss_ce_0: 4.969  loss_mask_0: 74.5  loss_ce_1: 4.906  loss_mask_1: 63.44  loss_ce_2: 4.867  loss_mask_2: 60  loss_ce_3: 4.744  loss_mask_3: 59.46  loss_ce_4: 4.777  loss_mask_4: 60.76  loss_ce_5: 4.789  loss_mask_5: 60.39  loss_ce_6: 4.681  loss_mask_6: 59.83  loss_ce_7: 4.747  loss_mask_7: 59.76  loss_ce_8: 4.662  loss_mask_8: 60.82  time: 2.5440  data_time: 0.4406  lr: 7.1152e-06  max_mem: 18476M
[01/23 21:51:29] d2.utils.events INFO:  eta: 1 day, 17:14:44  iter: 739  total_loss: 673.7  loss_ce: 4.791  loss_mask: 63.39  loss_ce_0: 4.991  loss_mask_0: 73.26  loss_ce_1: 4.909  loss_mask_1: 63.47  loss_ce_2: 4.858  loss_mask_2: 60.61  loss_ce_3: 4.728  loss_mask_3: 59.32  loss_ce_4: 4.762  loss_mask_4: 59.96  loss_ce_5: 4.779  loss_mask_5: 61.26  loss_ce_6: 4.678  loss_mask_6: 60.55  loss_ce_7: 4.743  loss_mask_7: 61.74  loss_ce_8: 4.661  loss_mask_8: 62.55  time: 2.5427  data_time: 0.4419  lr: 7.3106e-06  max_mem: 18476M
[01/23 21:52:23] d2.utils.events INFO:  eta: 1 day, 17:18:08  iter: 759  total_loss: 651.1  loss_ce: 4.881  loss_mask: 61.05  loss_ce_0: 4.977  loss_mask_0: 70.45  loss_ce_1: 4.909  loss_mask_1: 61.61  loss_ce_2: 4.873  loss_mask_2: 58.24  loss_ce_3: 4.747  loss_mask_3: 57.9  loss_ce_4: 4.775  loss_mask_4: 58.33  loss_ce_5: 4.785  loss_mask_5: 58.29  loss_ce_6: 4.724  loss_mask_6: 58.06  loss_ce_7: 4.779  loss_mask_7: 59.25  loss_ce_8: 4.73  loss_mask_8: 59.99  time: 2.5464  data_time: 0.4897  lr: 7.5059e-06  max_mem: 18476M
[01/23 21:53:13] d2.utils.events INFO:  eta: 1 day, 17:17:18  iter: 779  total_loss: 656.9  loss_ce: 4.853  loss_mask: 61.65  loss_ce_0: 4.974  loss_mask_0: 71.87  loss_ce_1: 4.908  loss_mask_1: 61.94  loss_ce_2: 4.87  loss_mask_2: 59.21  loss_ce_3: 4.728  loss_mask_3: 59  loss_ce_4: 4.735  loss_mask_4: 58.23  loss_ce_5: 4.754  loss_mask_5: 59.11  loss_ce_6: 4.689  loss_mask_6: 58.64  loss_ce_7: 4.746  loss_mask_7: 58.54  loss_ce_8: 4.711  loss_mask_8: 59.36  time: 2.5458  data_time: 0.4489  lr: 7.7011e-06  max_mem: 18476M
[01/23 21:54:03] d2.utils.events INFO:  eta: 1 day, 17:16:02  iter: 799  total_loss: 701.8  loss_ce: 4.843  loss_mask: 65.55  loss_ce_0: 4.966  loss_mask_0: 75.37  loss_ce_1: 4.895  loss_mask_1: 65.42  loss_ce_2: 4.874  loss_mask_2: 61.42  loss_ce_3: 4.735  loss_mask_3: 62.16  loss_ce_4: 4.741  loss_mask_4: 62.53  loss_ce_5: 4.753  loss_mask_5: 63.5  loss_ce_6: 4.709  loss_mask_6: 63.94  loss_ce_7: 4.778  loss_mask_7: 64.28  loss_ce_8: 4.739  loss_mask_8: 64.42  time: 2.5447  data_time: 0.4013  lr: 7.8962e-06  max_mem: 18476M
[01/23 21:54:58] d2.utils.events INFO:  eta: 1 day, 17:22:57  iter: 819  total_loss: 642.6  loss_ce: 4.855  loss_mask: 59.57  loss_ce_0: 4.97  loss_mask_0: 68.9  loss_ce_1: 4.897  loss_mask_1: 59.31  loss_ce_2: 4.867  loss_mask_2: 57.56  loss_ce_3: 4.727  loss_mask_3: 57.14  loss_ce_4: 4.75  loss_mask_4: 57.69  loss_ce_5: 4.762  loss_mask_5: 57.73  loss_ce_6: 4.736  loss_mask_6: 57.85  loss_ce_7: 4.824  loss_mask_7: 58.78  loss_ce_8: 4.776  loss_mask_8: 58.69  time: 2.5494  data_time: 0.4708  lr: 8.0911e-06  max_mem: 18476M
[01/23 21:55:47] d2.utils.events INFO:  eta: 1 day, 17:20:26  iter: 839  total_loss: 656.9  loss_ce: 4.81  loss_mask: 62.02  loss_ce_0: 4.97  loss_mask_0: 72.17  loss_ce_1: 4.897  loss_mask_1: 60.88  loss_ce_2: 4.848  loss_mask_2: 57.6  loss_ce_3: 4.705  loss_mask_3: 57.29  loss_ce_4: 4.716  loss_mask_4: 57.69  loss_ce_5: 4.741  loss_mask_5: 57.29  loss_ce_6: 4.713  loss_mask_6: 58.87  loss_ce_7: 4.81  loss_mask_7: 59.11  loss_ce_8: 4.754  loss_mask_8: 60.89  time: 2.5476  data_time: 0.4025  lr: 8.2859e-06  max_mem: 18476M
[01/23 21:56:41] d2.utils.events INFO:  eta: 1 day, 17:22:41  iter: 859  total_loss: 649.4  loss_ce: 4.768  loss_mask: 60.51  loss_ce_0: 4.975  loss_mask_0: 70.7  loss_ce_1: 4.899  loss_mask_1: 60.48  loss_ce_2: 4.855  loss_mask_2: 57.81  loss_ce_3: 4.72  loss_mask_3: 57.29  loss_ce_4: 4.716  loss_mask_4: 58.21  loss_ce_5: 4.745  loss_mask_5: 58.25  loss_ce_6: 4.715  loss_mask_6: 59.32  loss_ce_7: 4.78  loss_mask_7: 59.07  loss_ce_8: 4.707  loss_mask_8: 60.19  time: 2.5505  data_time: 0.4603  lr: 8.4806e-06  max_mem: 18476M
[01/23 21:57:34] d2.utils.events INFO:  eta: 1 day, 17:22:24  iter: 879  total_loss: 633.3  loss_ce: 4.778  loss_mask: 58.98  loss_ce_0: 4.969  loss_mask_0: 68.06  loss_ce_1: 4.881  loss_mask_1: 57.53  loss_ce_2: 4.837  loss_mask_2: 56.05  loss_ce_3: 4.697  loss_mask_3: 55.51  loss_ce_4: 4.691  loss_mask_4: 56.38  loss_ce_5: 4.737  loss_mask_5: 57.54  loss_ce_6: 4.731  loss_mask_6: 57.09  loss_ce_7: 4.83  loss_mask_7: 58.16  loss_ce_8: 4.73  loss_mask_8: 59.01  time: 2.5528  data_time: 0.4318  lr: 8.6752e-06  max_mem: 18476M
[01/23 21:58:25] d2.utils.events INFO:  eta: 1 day, 17:23:47  iter: 899  total_loss: 641.4  loss_ce: 4.727  loss_mask: 59.93  loss_ce_0: 4.975  loss_mask_0: 68.98  loss_ce_1: 4.87  loss_mask_1: 58.3  loss_ce_2: 4.834  loss_mask_2: 55.59  loss_ce_3: 4.683  loss_mask_3: 55.65  loss_ce_4: 4.669  loss_mask_4: 57.9  loss_ce_5: 4.7  loss_mask_5: 58.53  loss_ce_6: 4.688  loss_mask_6: 57.88  loss_ce_7: 4.785  loss_mask_7: 59.99  loss_ce_8: 4.685  loss_mask_8: 60.06  time: 2.5529  data_time: 0.4402  lr: 8.8697e-06  max_mem: 18476M
[01/23 21:59:19] d2.utils.events INFO:  eta: 1 day, 17:25:13  iter: 919  total_loss: 614  loss_ce: 4.689  loss_mask: 56.11  loss_ce_0: 4.996  loss_mask_0: 65.29  loss_ce_1: 4.857  loss_mask_1: 55.99  loss_ce_2: 4.793  loss_mask_2: 54.44  loss_ce_3: 4.648  loss_mask_3: 54.69  loss_ce_4: 4.637  loss_mask_4: 55.41  loss_ce_5: 4.676  loss_mask_5: 56.68  loss_ce_6: 4.635  loss_mask_6: 55.01  loss_ce_7: 4.721  loss_mask_7: 55.26  loss_ce_8: 4.642  loss_mask_8: 56.71  time: 2.5561  data_time: 0.4590  lr: 9.064e-06  max_mem: 18476M
[01/23 22:00:10] d2.utils.events INFO:  eta: 1 day, 17:26:02  iter: 939  total_loss: 614.8  loss_ce: 4.682  loss_mask: 56.5  loss_ce_0: 4.986  loss_mask_0: 68.71  loss_ce_1: 4.847  loss_mask_1: 55.48  loss_ce_2: 4.803  loss_mask_2: 54.53  loss_ce_3: 4.687  loss_mask_3: 54.29  loss_ce_4: 4.653  loss_mask_4: 55.53  loss_ce_5: 4.692  loss_mask_5: 54.85  loss_ce_6: 4.671  loss_mask_6: 55.3  loss_ce_7: 4.773  loss_mask_7: 55.58  loss_ce_8: 4.647  loss_mask_8: 56.7  time: 2.5560  data_time: 0.4402  lr: 9.2582e-06  max_mem: 18476M
[01/23 22:01:02] d2.utils.events INFO:  eta: 1 day, 17:26:25  iter: 959  total_loss: 625.9  loss_ce: 4.697  loss_mask: 58.38  loss_ce_0: 4.967  loss_mask_0: 67.12  loss_ce_1: 4.838  loss_mask_1: 56.81  loss_ce_2: 4.81  loss_mask_2: 56  loss_ce_3: 4.71  loss_mask_3: 55.86  loss_ce_4: 4.669  loss_mask_4: 55.82  loss_ce_5: 4.707  loss_mask_5: 55.74  loss_ce_6: 4.69  loss_mask_6: 58.58  loss_ce_7: 4.765  loss_mask_7: 58.1  loss_ce_8: 4.674  loss_mask_8: 59.57  time: 2.5565  data_time: 0.4244  lr: 9.4523e-06  max_mem: 18476M
[01/23 22:01:56] d2.utils.events INFO:  eta: 1 day, 17:28:06  iter: 979  total_loss: 622.3  loss_ce: 4.648  loss_mask: 58.7  loss_ce_0: 5  loss_mask_0: 64.73  loss_ce_1: 4.834  loss_mask_1: 55.54  loss_ce_2: 4.767  loss_mask_2: 53.32  loss_ce_3: 4.678  loss_mask_3: 53.67  loss_ce_4: 4.621  loss_mask_4: 54.49  loss_ce_5: 4.679  loss_mask_5: 55.65  loss_ce_6: 4.661  loss_mask_6: 56.87  loss_ce_7: 4.76  loss_mask_7: 57.66  loss_ce_8: 4.653  loss_mask_8: 57.2  time: 2.5600  data_time: 0.4677  lr: 9.6463e-06  max_mem: 18476M
[01/23 22:02:47] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/23 22:02:48] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/23 22:02:48] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/23 22:05:46] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 40.3377873773628, 'error_1pix': 0.9750337227204595, 'error_3pix': 0.9447206141965804, 'mIoU': 0.04824938403695214, 'fwIoU': 0.11424303105079733, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.4972360400367808, 'IoU-3': 0.0, 'IoU-4': 0.018403692396501557, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.4717766925339324, 'IoU-15': 0.0, 'IoU-16': 0.8453477608144321, 'IoU-17': 0.6786757205897902, 'IoU-18': 0.0, 'IoU-19': 0.017186787187621424, 'IoU-20': 0.0, 'IoU-21': 0.011084062013170479, 'IoU-22': 0.12130792680185985, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.5891088529760361, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.9148623913328294, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.9318604634828868, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.00017343327980499958, 'IoU-38': 0.003789807339848262, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 1.038655183800121, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.14339961924732794, 'IoU-45': 0.0, 'IoU-46': 0.7340432035274989, 'IoU-47': 0.0, 'IoU-48': 0.1766219508527714, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 1.1629328776446712, 'IoU-52': 0.0, 'IoU-53': 0.12915784893387447, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0007306827301279066, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.002837710632553555, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.007900903227661953, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.29363344602392066, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 4.5825282404030976e-05, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.016075402568827005, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.00016115381836514286, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.005898661965118051, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.06371406320513669, 'IoU-139': 0.33769196899774445, 'IoU-140': 0.01919415032949283, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.03037345152170046, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.4870892516764372, 'pACC': 0.7469041386991642, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 1.2092008650170991, 'ACC-3': 0.0, 'ACC-4': 0.1049968018215537, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.55981572270369, 'ACC-15': 0.0, 'ACC-16': 2.4592472445716687, 'ACC-17': 0.9727245522783973, 'ACC-18': 0.0, 'ACC-19': 0.017285682780236837, 'ACC-20': 0.0, 'ACC-21': 0.012538088672092794, 'ACC-22': 0.1311351371912231, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 1.2763865028996992, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 1.8733667637204834, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 2.7546893991542474, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.0001734378657566467, 'ACC-38': 0.003876491364389901, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 7.431018358636374, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.1538477092311637, 'ACC-45': 0.0, 'ACC-46': 2.531472157464697, 'ACC-47': 0.0, 'ACC-48': 0.3736337126120755, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 34.79798677586094, 'ACC-52': 0.0, 'ACC-53': 0.1486516893981258, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0007501744791405086, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0028565960731092312, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.010559777403823578, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 34.85499176528115, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 5.443064053161318e-05, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.02349777423860684, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.00020019498992018226, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.024631379833568078, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.3086370789654035, 'ACC-139': 0.5841346567706741, 'ACC-140': 0.7848438015064099, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.11393159844967843, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/23 22:05:46] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/23 22:05:46] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/23 22:05:46] d2.evaluation.testing INFO: copypaste: 40.3378,0.9750,0.9447,0.0482,0.1142,0.4871,0.7469
[01/23 22:05:46] d2.utils.events INFO:  eta: 1 day, 17:27:15  iter: 999  total_loss: 636.1  loss_ce: 4.605  loss_mask: 58.92  loss_ce_0: 4.992  loss_mask_0: 66.39  loss_ce_1: 4.837  loss_mask_1: 57.21  loss_ce_2: 4.769  loss_mask_2: 57.13  loss_ce_3: 4.681  loss_mask_3: 56.18  loss_ce_4: 4.627  loss_mask_4: 57.11  loss_ce_5: 4.667  loss_mask_5: 58.04  loss_ce_6: 4.649  loss_mask_6: 58.5  loss_ce_7: 4.724  loss_mask_7: 58.12  loss_ce_8: 4.616  loss_mask_8: 58.45  time: 2.5593  data_time: 0.4118  lr: 9.8402e-06  max_mem: 18476M
[01/23 22:06:35] d2.utils.events INFO:  eta: 1 day, 17:20:16  iter: 1019  total_loss: 578.9  loss_ce: 4.642  loss_mask: 53.98  loss_ce_0: 5.011  loss_mask_0: 59.64  loss_ce_1: 4.822  loss_mask_1: 52.12  loss_ce_2: 4.744  loss_mask_2: 50.82  loss_ce_3: 4.638  loss_mask_3: 50.32  loss_ce_4: 4.589  loss_mask_4: 51  loss_ce_5: 4.623  loss_mask_5: 51.68  loss_ce_6: 4.614  loss_mask_6: 52.81  loss_ce_7: 4.717  loss_mask_7: 53.64  loss_ce_8: 4.624  loss_mask_8: 53.27  time: 2.5566  data_time: 0.3919  lr: 9.847e-06  max_mem: 18476M
[01/23 22:07:25] d2.utils.events INFO:  eta: 1 day, 17:19:26  iter: 1039  total_loss: 586.8  loss_ce: 4.618  loss_mask: 54.64  loss_ce_0: 4.999  loss_mask_0: 61.37  loss_ce_1: 4.82  loss_mask_1: 53.42  loss_ce_2: 4.72  loss_mask_2: 52.77  loss_ce_3: 4.603  loss_mask_3: 52.61  loss_ce_4: 4.588  loss_mask_4: 52.4  loss_ce_5: 4.631  loss_mask_5: 52.49  loss_ce_6: 4.595  loss_mask_6: 54.07  loss_ce_7: 4.708  loss_mask_7: 53.57  loss_ce_8: 4.627  loss_mask_8: 53.78  time: 2.5553  data_time: 0.4253  lr: 9.844e-06  max_mem: 18476M
[01/23 22:08:12] d2.utils.events INFO:  eta: 1 day, 17:16:11  iter: 1059  total_loss: 603  loss_ce: 4.581  loss_mask: 57.05  loss_ce_0: 4.999  loss_mask_0: 61.64  loss_ce_1: 4.81  loss_mask_1: 54.23  loss_ce_2: 4.721  loss_mask_2: 54.33  loss_ce_3: 4.613  loss_mask_3: 52.86  loss_ce_4: 4.554  loss_mask_4: 53.63  loss_ce_5: 4.594  loss_mask_5: 55.24  loss_ce_6: 4.542  loss_mask_6: 55.75  loss_ce_7: 4.662  loss_mask_7: 55.59  loss_ce_8: 4.587  loss_mask_8: 55.82  time: 2.5521  data_time: 0.4064  lr: 9.841e-06  max_mem: 18476M
[01/23 22:09:03] d2.utils.events INFO:  eta: 1 day, 17:12:38  iter: 1079  total_loss: 614.8  loss_ce: 4.612  loss_mask: 58.13  loss_ce_0: 4.989  loss_mask_0: 61.51  loss_ce_1: 4.815  loss_mask_1: 55.63  loss_ce_2: 4.729  loss_mask_2: 55.87  loss_ce_3: 4.64  loss_mask_3: 54.58  loss_ce_4: 4.614  loss_mask_4: 54.7  loss_ce_5: 4.663  loss_mask_5: 56.14  loss_ce_6: 4.62  loss_mask_6: 56.04  loss_ce_7: 4.724  loss_mask_7: 58.97  loss_ce_8: 4.626  loss_mask_8: 57.44  time: 2.5516  data_time: 0.4152  lr: 9.838e-06  max_mem: 18476M
[01/23 22:09:53] d2.utils.events INFO:  eta: 1 day, 17:14:30  iter: 1099  total_loss: 572  loss_ce: 4.57  loss_mask: 54.14  loss_ce_0: 5.009  loss_mask_0: 57.73  loss_ce_1: 4.789  loss_mask_1: 52.79  loss_ce_2: 4.686  loss_mask_2: 51.7  loss_ce_3: 4.603  loss_mask_3: 50.95  loss_ce_4: 4.575  loss_mask_4: 51.16  loss_ce_5: 4.626  loss_mask_5: 52.12  loss_ce_6: 4.573  loss_mask_6: 52.32  loss_ce_7: 4.663  loss_mask_7: 52.72  loss_ce_8: 4.564  loss_mask_8: 52.99  time: 2.5509  data_time: 0.4275  lr: 9.835e-06  max_mem: 18476M
[01/23 22:10:42] d2.utils.events INFO:  eta: 1 day, 17:12:20  iter: 1119  total_loss: 575.8  loss_ce: 4.51  loss_mask: 52.88  loss_ce_0: 5.006  loss_mask_0: 60.66  loss_ce_1: 4.778  loss_mask_1: 53.12  loss_ce_2: 4.667  loss_mask_2: 51.3  loss_ce_3: 4.562  loss_mask_3: 51.74  loss_ce_4: 4.529  loss_mask_4: 51.59  loss_ce_5: 4.595  loss_mask_5: 51.64  loss_ce_6: 4.521  loss_mask_6: 52.28  loss_ce_7: 4.623  loss_mask_7: 52.23  loss_ce_8: 4.53  loss_mask_8: 52.73  time: 2.5492  data_time: 0.3721  lr: 9.832e-06  max_mem: 18476M
[01/23 22:11:38] d2.utils.events INFO:  eta: 1 day, 17:14:37  iter: 1139  total_loss: 572.6  loss_ce: 4.543  loss_mask: 53.71  loss_ce_0: 5.007  loss_mask_0: 58.17  loss_ce_1: 4.776  loss_mask_1: 52.78  loss_ce_2: 4.672  loss_mask_2: 50.6  loss_ce_3: 4.593  loss_mask_3: 50.36  loss_ce_4: 4.554  loss_mask_4: 51.16  loss_ce_5: 4.608  loss_mask_5: 52.11  loss_ce_6: 4.554  loss_mask_6: 53.38  loss_ce_7: 4.641  loss_mask_7: 53.55  loss_ce_8: 4.569  loss_mask_8: 53.59  time: 2.5536  data_time: 0.4723  lr: 9.829e-06  max_mem: 18476M
[01/23 22:12:29] d2.utils.events INFO:  eta: 1 day, 17:16:29  iter: 1159  total_loss: 590.3  loss_ce: 4.519  loss_mask: 55.43  loss_ce_0: 5.017  loss_mask_0: 59.44  loss_ce_1: 4.76  loss_mask_1: 52.42  loss_ce_2: 4.65  loss_mask_2: 51.86  loss_ce_3: 4.539  loss_mask_3: 52.65  loss_ce_4: 4.513  loss_mask_4: 52.86  loss_ce_5: 4.575  loss_mask_5: 53.81  loss_ce_6: 4.523  loss_mask_6: 53.87  loss_ce_7: 4.614  loss_mask_7: 55.26  loss_ce_8: 4.544  loss_mask_8: 55.01  time: 2.5531  data_time: 0.4216  lr: 9.826e-06  max_mem: 18476M
[01/23 22:13:21] d2.utils.events INFO:  eta: 1 day, 17:14:40  iter: 1179  total_loss: 590.6  loss_ce: 4.536  loss_mask: 57.35  loss_ce_0: 4.995  loss_mask_0: 60.74  loss_ce_1: 4.747  loss_mask_1: 53.71  loss_ce_2: 4.666  loss_mask_2: 52.15  loss_ce_3: 4.556  loss_mask_3: 51.96  loss_ce_4: 4.532  loss_mask_4: 53.26  loss_ce_5: 4.586  loss_mask_5: 53.01  loss_ce_6: 4.536  loss_mask_6: 52.99  loss_ce_7: 4.609  loss_mask_7: 55.53  loss_ce_8: 4.53  loss_mask_8: 54.85  time: 2.5542  data_time: 0.4283  lr: 9.823e-06  max_mem: 18476M
[01/23 22:14:15] d2.utils.events INFO:  eta: 1 day, 17:18:30  iter: 1199  total_loss: 559.1  loss_ce: 4.555  loss_mask: 51.69  loss_ce_0: 5.014  loss_mask_0: 57.23  loss_ce_1: 4.723  loss_mask_1: 50.33  loss_ce_2: 4.632  loss_mask_2: 48.9  loss_ce_3: 4.529  loss_mask_3: 49.87  loss_ce_4: 4.516  loss_mask_4: 50.42  loss_ce_5: 4.578  loss_mask_5: 50.54  loss_ce_6: 4.539  loss_mask_6: 51.68  loss_ce_7: 4.636  loss_mask_7: 52.02  loss_ce_8: 4.559  loss_mask_8: 51.91  time: 2.5560  data_time: 0.4597  lr: 9.82e-06  max_mem: 18476M
[01/23 22:15:06] d2.utils.events INFO:  eta: 1 day, 17:20:13  iter: 1219  total_loss: 553.5  loss_ce: 4.519  loss_mask: 51.32  loss_ce_0: 5.026  loss_mask_0: 55.76  loss_ce_1: 4.721  loss_mask_1: 49.53  loss_ce_2: 4.636  loss_mask_2: 48.75  loss_ce_3: 4.54  loss_mask_3: 49.1  loss_ce_4: 4.52  loss_mask_4: 51.15  loss_ce_5: 4.583  loss_mask_5: 49.42  loss_ce_6: 4.53  loss_mask_6: 50.57  loss_ce_7: 4.641  loss_mask_7: 50.19  loss_ce_8: 4.518  loss_mask_8: 50.48  time: 2.5565  data_time: 0.4319  lr: 9.817e-06  max_mem: 18476M
[01/23 22:16:01] d2.utils.events INFO:  eta: 1 day, 17:20:57  iter: 1239  total_loss: 542.5  loss_ce: 4.48  loss_mask: 50.05  loss_ce_0: 5.025  loss_mask_0: 53.17  loss_ce_1: 4.708  loss_mask_1: 48.17  loss_ce_2: 4.637  loss_mask_2: 48.78  loss_ce_3: 4.546  loss_mask_3: 49.62  loss_ce_4: 4.523  loss_mask_4: 49.32  loss_ce_5: 4.568  loss_mask_5: 49.65  loss_ce_6: 4.488  loss_mask_6: 49.39  loss_ce_7: 4.579  loss_mask_7: 49.48  loss_ce_8: 4.481  loss_mask_8: 49.96  time: 2.5595  data_time: 0.4794  lr: 9.814e-06  max_mem: 18476M
[01/23 22:16:52] d2.utils.events INFO:  eta: 1 day, 17:21:36  iter: 1259  total_loss: 571.1  loss_ce: 4.521  loss_mask: 53.33  loss_ce_0: 5.028  loss_mask_0: 57.46  loss_ce_1: 4.708  loss_mask_1: 50.64  loss_ce_2: 4.625  loss_mask_2: 50.25  loss_ce_3: 4.533  loss_mask_3: 51.44  loss_ce_4: 4.52  loss_mask_4: 51.11  loss_ce_5: 4.574  loss_mask_5: 50.81  loss_ce_6: 4.504  loss_mask_6: 51.96  loss_ce_7: 4.598  loss_mask_7: 54.91  loss_ce_8: 4.508  loss_mask_8: 52.73  time: 2.5594  data_time: 0.4278  lr: 9.811e-06  max_mem: 18476M
[01/23 22:17:43] d2.utils.events INFO:  eta: 1 day, 17:26:08  iter: 1279  total_loss: 542.6  loss_ce: 4.505  loss_mask: 50.64  loss_ce_0: 5.017  loss_mask_0: 52.77  loss_ce_1: 4.693  loss_mask_1: 47.91  loss_ce_2: 4.619  loss_mask_2: 48.29  loss_ce_3: 4.523  loss_mask_3: 48.06  loss_ce_4: 4.527  loss_mask_4: 48.02  loss_ce_5: 4.573  loss_mask_5: 48.39  loss_ce_6: 4.512  loss_mask_6: 49.1  loss_ce_7: 4.62  loss_mask_7: 49.77  loss_ce_8: 4.508  loss_mask_8: 49.95  time: 2.5592  data_time: 0.4395  lr: 9.8079e-06  max_mem: 18476M
[01/23 22:18:38] d2.utils.events INFO:  eta: 1 day, 17:28:01  iter: 1299  total_loss: 568.2  loss_ce: 4.516  loss_mask: 51.92  loss_ce_0: 5.016  loss_mask_0: 57.46  loss_ce_1: 4.695  loss_mask_1: 51.18  loss_ce_2: 4.611  loss_mask_2: 49.93  loss_ce_3: 4.527  loss_mask_3: 51.98  loss_ce_4: 4.543  loss_mask_4: 50.38  loss_ce_5: 4.588  loss_mask_5: 51.76  loss_ce_6: 4.513  loss_mask_6: 51.98  loss_ce_7: 4.609  loss_mask_7: 51.86  loss_ce_8: 4.505  loss_mask_8: 51.65  time: 2.5622  data_time: 0.4702  lr: 9.8049e-06  max_mem: 18476M
[01/23 22:19:29] d2.utils.events INFO:  eta: 1 day, 17:29:51  iter: 1319  total_loss: 573.9  loss_ce: 4.508  loss_mask: 52.81  loss_ce_0: 5.018  loss_mask_0: 56.89  loss_ce_1: 4.673  loss_mask_1: 51.81  loss_ce_2: 4.601  loss_mask_2: 52.18  loss_ce_3: 4.513  loss_mask_3: 53.75  loss_ce_4: 4.512  loss_mask_4: 50.2  loss_ce_5: 4.558  loss_mask_5: 52.02  loss_ce_6: 4.487  loss_mask_6: 51.85  loss_ce_7: 4.565  loss_mask_7: 52.8  loss_ce_8: 4.458  loss_mask_8: 52.93  time: 2.5619  data_time: 0.4063  lr: 9.8019e-06  max_mem: 18476M
[01/23 22:20:22] d2.utils.events INFO:  eta: 1 day, 17:30:07  iter: 1339  total_loss: 552.5  loss_ce: 4.506  loss_mask: 52.22  loss_ce_0: 5.027  loss_mask_0: 55.03  loss_ce_1: 4.659  loss_mask_1: 50.02  loss_ce_2: 4.579  loss_mask_2: 49.98  loss_ce_3: 4.479  loss_mask_3: 50.16  loss_ce_4: 4.494  loss_mask_4: 49.55  loss_ce_5: 4.528  loss_mask_5: 50.38  loss_ce_6: 4.483  loss_mask_6: 49.66  loss_ce_7: 4.573  loss_mask_7: 50.45  loss_ce_8: 4.458  loss_mask_8: 50.89  time: 2.5628  data_time: 0.4306  lr: 9.7989e-06  max_mem: 18476M
[01/23 22:21:15] d2.utils.events INFO:  eta: 1 day, 17:33:07  iter: 1359  total_loss: 568.9  loss_ce: 4.504  loss_mask: 53.32  loss_ce_0: 5.013  loss_mask_0: 57.83  loss_ce_1: 4.648  loss_mask_1: 52  loss_ce_2: 4.595  loss_mask_2: 50.16  loss_ce_3: 4.505  loss_mask_3: 51.33  loss_ce_4: 4.519  loss_mask_4: 49.89  loss_ce_5: 4.554  loss_mask_5: 51.31  loss_ce_6: 4.492  loss_mask_6: 50.66  loss_ce_7: 4.567  loss_mask_7: 51.78  loss_ce_8: 4.481  loss_mask_8: 52.23  time: 2.5644  data_time: 0.4354  lr: 9.7959e-06  max_mem: 18476M
[01/23 22:22:05] d2.utils.events INFO:  eta: 1 day, 17:34:14  iter: 1379  total_loss: 576.3  loss_ce: 4.459  loss_mask: 52.95  loss_ce_0: 5.019  loss_mask_0: 56.69  loss_ce_1: 4.648  loss_mask_1: 51.62  loss_ce_2: 4.587  loss_mask_2: 51.46  loss_ce_3: 4.464  loss_mask_3: 51.71  loss_ce_4: 4.477  loss_mask_4: 51.26  loss_ce_5: 4.519  loss_mask_5: 51.66  loss_ce_6: 4.462  loss_mask_6: 50.79  loss_ce_7: 4.553  loss_mask_7: 52.56  loss_ce_8: 4.464  loss_mask_8: 52.28  time: 2.5635  data_time: 0.4126  lr: 9.7929e-06  max_mem: 18476M
[01/23 22:23:01] d2.utils.events INFO:  eta: 1 day, 17:36:47  iter: 1399  total_loss: 546.2  loss_ce: 4.442  loss_mask: 49.45  loss_ce_0: 5.021  loss_mask_0: 54.83  loss_ce_1: 4.638  loss_mask_1: 50.12  loss_ce_2: 4.561  loss_mask_2: 49.12  loss_ce_3: 4.452  loss_mask_3: 50.38  loss_ce_4: 4.474  loss_mask_4: 48.61  loss_ce_5: 4.486  loss_mask_5: 48.27  loss_ce_6: 4.44  loss_mask_6: 49.03  loss_ce_7: 4.504  loss_mask_7: 50.3  loss_ce_8: 4.438  loss_mask_8: 49.38  time: 2.5667  data_time: 0.4951  lr: 9.7899e-06  max_mem: 18476M
[01/23 22:23:52] d2.utils.events INFO:  eta: 1 day, 17:35:56  iter: 1419  total_loss: 502.9  loss_ce: 4.366  loss_mask: 46.05  loss_ce_0: 5.039  loss_mask_0: 50.26  loss_ce_1: 4.632  loss_mask_1: 44.58  loss_ce_2: 4.546  loss_mask_2: 45.27  loss_ce_3: 4.417  loss_mask_3: 45.76  loss_ce_4: 4.426  loss_mask_4: 45.75  loss_ce_5: 4.452  loss_mask_5: 45.02  loss_ce_6: 4.399  loss_mask_6: 45.24  loss_ce_7: 4.455  loss_mask_7: 45.43  loss_ce_8: 4.372  loss_mask_8: 46.22  time: 2.5661  data_time: 0.4036  lr: 9.7869e-06  max_mem: 18476M
[01/23 22:24:41] d2.utils.events INFO:  eta: 1 day, 17:34:38  iter: 1439  total_loss: 537.5  loss_ce: 4.408  loss_mask: 48.71  loss_ce_0: 5.033  loss_mask_0: 52.55  loss_ce_1: 4.628  loss_mask_1: 49  loss_ce_2: 4.561  loss_mask_2: 48.75  loss_ce_3: 4.431  loss_mask_3: 49.33  loss_ce_4: 4.45  loss_mask_4: 49.46  loss_ce_5: 4.473  loss_mask_5: 48.98  loss_ce_6: 4.41  loss_mask_6: 47.72  loss_ce_7: 4.489  loss_mask_7: 47.5  loss_ce_8: 4.404  loss_mask_8: 48  time: 2.5647  data_time: 0.4006  lr: 9.7839e-06  max_mem: 18476M
[01/23 22:25:37] d2.utils.events INFO:  eta: 1 day, 17:33:47  iter: 1459  total_loss: 542.2  loss_ce: 4.431  loss_mask: 49.25  loss_ce_0: 5.008  loss_mask_0: 55.41  loss_ce_1: 4.616  loss_mask_1: 48.98  loss_ce_2: 4.564  loss_mask_2: 49.84  loss_ce_3: 4.46  loss_mask_3: 49.68  loss_ce_4: 4.47  loss_mask_4: 48.87  loss_ce_5: 4.47  loss_mask_5: 49.38  loss_ce_6: 4.437  loss_mask_6: 48.13  loss_ce_7: 4.491  loss_mask_7: 49.07  loss_ce_8: 4.426  loss_mask_8: 49.53  time: 2.5681  data_time: 0.4898  lr: 9.7809e-06  max_mem: 18476M
[01/23 22:26:27] d2.utils.events INFO:  eta: 1 day, 17:34:58  iter: 1479  total_loss: 526.1  loss_ce: 4.429  loss_mask: 49.16  loss_ce_0: 5.029  loss_mask_0: 51.99  loss_ce_1: 4.605  loss_mask_1: 48.06  loss_ce_2: 4.555  loss_mask_2: 48.66  loss_ce_3: 4.452  loss_mask_3: 47.67  loss_ce_4: 4.481  loss_mask_4: 47.98  loss_ce_5: 4.485  loss_mask_5: 48.72  loss_ce_6: 4.447  loss_mask_6: 48.28  loss_ce_7: 4.5  loss_mask_7: 48.3  loss_ce_8: 4.438  loss_mask_8: 48.16  time: 2.5672  data_time: 0.3859  lr: 9.7779e-06  max_mem: 18476M
[01/23 22:27:21] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/23 22:27:22] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/23 22:27:22] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/23 22:31:01] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 32.225055578703675, 'error_1pix': 0.9662402350210404, 'error_3pix': 0.9165563434954656, 'mIoU': 0.03060536795723664, 'fwIoU': 0.0759104621298209, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.08811800000940062, 'IoU-15': 0.0, 'IoU-16': 0.3228121809566576, 'IoU-17': 1.3988453143836066, 'IoU-18': 0.0, 'IoU-19': 0.00022660746954418273, 'IoU-20': 1.6500546632950233, 'IoU-21': 0.00027202705443575234, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.09503435814365489, 'IoU-30': 0.0, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.001919443784785077, 'IoU-35': 0.3360171586928217, 'IoU-36': 0.03779754210997407, 'IoU-37': 0.02662942493780984, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.15324190410086164, 'IoU-42': 0.0, 'IoU-43': 0.05354971640692984, 'IoU-44': 0.3974969926276845, 'IoU-45': 0.0, 'IoU-46': 0.00545254924083068, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.029671104608924626, 'IoU-51': 0.05719286280982386, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.94930046566077, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.012337220870377807, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0004993577704230392, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.2545458247790015, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.005042317567796926, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0001736105082968462, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5419481760296603, 'pACC': 1.0877680145787043, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.08830203560984477, 'ACC-15': 0.0, 'ACC-16': 0.38889665259216283, 'ACC-17': 16.121803090785072, 'ACC-18': 0.0, 'ACC-19': 0.000226766872226301, 'ACC-20': 35.9264488601653, 'ACC-21': 0.0002723719429841118, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.09781111604623297, 'ACC-30': 0.0, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0019265112833087754, 'ACC-35': 0.46306701936187106, 'ACC-36': 0.040254489485384855, 'ACC-37': 0.029800037229433023, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.23079124804805679, 'ACC-42': 0.0, 'ACC-43': 0.05572119408134246, 'ACC-44': 0.45022494397194324, 'ACC-45': 0.0, 'ACC-46': 0.0055431984707850395, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.032141723856957884, 'ACC-51': 0.062419279779552105, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 31.506862608997388, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.013502350646543818, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.000500830321024445, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 18.532254784366298, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.005104972242964648, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.00017371153809407175, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/23 22:31:01] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/23 22:31:01] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/23 22:31:01] d2.evaluation.testing INFO: copypaste: 32.2251,0.9662,0.9166,0.0306,0.0759,0.5419,1.0878
[01/23 22:31:01] d2.utils.events INFO:  eta: 1 day, 17:39:27  iter: 1499  total_loss: 519.9  loss_ce: 4.439  loss_mask: 48.24  loss_ce_0: 5.016  loss_mask_0: 51.97  loss_ce_1: 4.596  loss_mask_1: 47.81  loss_ce_2: 4.554  loss_mask_2: 47.42  loss_ce_3: 4.445  loss_mask_3: 47.33  loss_ce_4: 4.456  loss_mask_4: 47.71  loss_ce_5: 4.474  loss_mask_5: 46.9  loss_ce_6: 4.45  loss_mask_6: 46.19  loss_ce_7: 4.492  loss_mask_7: 46.98  loss_ce_8: 4.441  loss_mask_8: 49.35  time: 2.5685  data_time: 0.4633  lr: 9.7749e-06  max_mem: 18476M
[01/23 22:31:52] d2.utils.events INFO:  eta: 1 day, 17:37:34  iter: 1519  total_loss: 515.6  loss_ce: 4.409  loss_mask: 47.76  loss_ce_0: 5.042  loss_mask_0: 51.17  loss_ce_1: 4.584  loss_mask_1: 47.51  loss_ce_2: 4.539  loss_mask_2: 45.58  loss_ce_3: 4.43  loss_mask_3: 46.07  loss_ce_4: 4.449  loss_mask_4: 46.88  loss_ce_5: 4.436  loss_mask_5: 46.54  loss_ce_6: 4.412  loss_mask_6: 46.09  loss_ce_7: 4.434  loss_mask_7: 46.75  loss_ce_8: 4.401  loss_mask_8: 47.16  time: 2.5683  data_time: 0.4256  lr: 9.7719e-06  max_mem: 18476M
[01/23 22:32:46] d2.utils.events INFO:  eta: 1 day, 17:36:49  iter: 1539  total_loss: 512.8  loss_ce: 4.441  loss_mask: 47.07  loss_ce_0: 5.018  loss_mask_0: 51.81  loss_ce_1: 4.573  loss_mask_1: 46.59  loss_ce_2: 4.547  loss_mask_2: 46.89  loss_ce_3: 4.438  loss_mask_3: 46.96  loss_ce_4: 4.474  loss_mask_4: 47.85  loss_ce_5: 4.465  loss_mask_5: 46.14  loss_ce_6: 4.425  loss_mask_6: 47.46  loss_ce_7: 4.442  loss_mask_7: 46.74  loss_ce_8: 4.422  loss_mask_8: 47.5  time: 2.5700  data_time: 0.4423  lr: 9.7689e-06  max_mem: 18476M
[01/23 22:33:39] d2.utils.events INFO:  eta: 1 day, 17:37:36  iter: 1559  total_loss: 530.6  loss_ce: 4.421  loss_mask: 48.89  loss_ce_0: 5.026  loss_mask_0: 53.57  loss_ce_1: 4.568  loss_mask_1: 47.15  loss_ce_2: 4.53  loss_mask_2: 48.39  loss_ce_3: 4.433  loss_mask_3: 47.68  loss_ce_4: 4.471  loss_mask_4: 48.4  loss_ce_5: 4.485  loss_mask_5: 48.02  loss_ce_6: 4.441  loss_mask_6: 48.21  loss_ce_7: 4.448  loss_mask_7: 48.58  loss_ce_8: 4.434  loss_mask_8: 49.17  time: 2.5712  data_time: 0.4462  lr: 9.7658e-06  max_mem: 18476M
[01/23 22:34:31] d2.utils.events INFO:  eta: 1 day, 17:37:19  iter: 1579  total_loss: 547.6  loss_ce: 4.434  loss_mask: 49.87  loss_ce_0: 5.02  loss_mask_0: 53.46  loss_ce_1: 4.557  loss_mask_1: 50.09  loss_ce_2: 4.543  loss_mask_2: 49.59  loss_ce_3: 4.431  loss_mask_3: 49.4  loss_ce_4: 4.466  loss_mask_4: 49.46  loss_ce_5: 4.469  loss_mask_5: 49.53  loss_ce_6: 4.44  loss_mask_6: 49.75  loss_ce_7: 4.463  loss_mask_7: 49.75  loss_ce_8: 4.444  loss_mask_8: 49.87  time: 2.5713  data_time: 0.3977  lr: 9.7628e-06  max_mem: 18476M
[01/23 22:35:27] d2.utils.events INFO:  eta: 1 day, 17:36:28  iter: 1599  total_loss: 516.6  loss_ce: 4.408  loss_mask: 46.9  loss_ce_0: 5.046  loss_mask_0: 52.12  loss_ce_1: 4.552  loss_mask_1: 46.63  loss_ce_2: 4.535  loss_mask_2: 46.96  loss_ce_3: 4.419  loss_mask_3: 46.36  loss_ce_4: 4.444  loss_mask_4: 47.37  loss_ce_5: 4.462  loss_mask_5: 46.25  loss_ce_6: 4.437  loss_mask_6: 46.83  loss_ce_7: 4.453  loss_mask_7: 47.42  loss_ce_8: 4.419  loss_mask_8: 47.31  time: 2.5742  data_time: 0.5103  lr: 9.7598e-06  max_mem: 18476M
[01/23 22:36:18] d2.utils.events INFO:  eta: 1 day, 17:36:44  iter: 1619  total_loss: 524.2  loss_ce: 4.44  loss_mask: 50.16  loss_ce_0: 5.03  loss_mask_0: 52.14  loss_ce_1: 4.544  loss_mask_1: 46.35  loss_ce_2: 4.539  loss_mask_2: 47.13  loss_ce_3: 4.429  loss_mask_3: 46.25  loss_ce_4: 4.458  loss_mask_4: 46.78  loss_ce_5: 4.469  loss_mask_5: 46.45  loss_ce_6: 4.444  loss_mask_6: 47.3  loss_ce_7: 4.449  loss_mask_7: 48.59  loss_ce_8: 4.446  loss_mask_8: 48.74  time: 2.5738  data_time: 0.4178  lr: 9.7568e-06  max_mem: 18476M
[01/23 22:37:10] d2.utils.events INFO:  eta: 1 day, 17:38:02  iter: 1639  total_loss: 522.2  loss_ce: 4.358  loss_mask: 48.19  loss_ce_0: 5.048  loss_mask_0: 51.89  loss_ce_1: 4.517  loss_mask_1: 46.54  loss_ce_2: 4.503  loss_mask_2: 46.98  loss_ce_3: 4.394  loss_mask_3: 47.22  loss_ce_4: 4.426  loss_mask_4: 46.55  loss_ce_5: 4.424  loss_mask_5: 46.85  loss_ce_6: 4.384  loss_mask_6: 47.11  loss_ce_7: 4.394  loss_mask_7: 46.8  loss_ce_8: 4.363  loss_mask_8: 48.35  time: 2.5742  data_time: 0.4388  lr: 9.7538e-06  max_mem: 18476M
[01/23 22:38:03] d2.utils.events INFO:  eta: 1 day, 17:36:54  iter: 1659  total_loss: 495.1  loss_ce: 4.377  loss_mask: 45.17  loss_ce_0: 5.034  loss_mask_0: 49.14  loss_ce_1: 4.525  loss_mask_1: 44.78  loss_ce_2: 4.525  loss_mask_2: 43.9  loss_ce_3: 4.437  loss_mask_3: 44.47  loss_ce_4: 4.474  loss_mask_4: 44.82  loss_ce_5: 4.465  loss_mask_5: 45.25  loss_ce_6: 4.421  loss_mask_6: 45.67  loss_ce_7: 4.435  loss_mask_7: 45.64  loss_ce_8: 4.386  loss_mask_8: 44.56  time: 2.5750  data_time: 0.4530  lr: 9.7508e-06  max_mem: 18476M
[01/23 22:38:54] d2.utils.events INFO:  eta: 1 day, 17:36:03  iter: 1679  total_loss: 536.9  loss_ce: 4.38  loss_mask: 49.9  loss_ce_0: 5.04  loss_mask_0: 52.72  loss_ce_1: 4.516  loss_mask_1: 47.93  loss_ce_2: 4.522  loss_mask_2: 48.67  loss_ce_3: 4.439  loss_mask_3: 47.4  loss_ce_4: 4.454  loss_mask_4: 47.79  loss_ce_5: 4.438  loss_mask_5: 48.35  loss_ce_6: 4.415  loss_mask_6: 49.21  loss_ce_7: 4.441  loss_mask_7: 48.65  loss_ce_8: 4.393  loss_mask_8: 49.98  time: 2.5746  data_time: 0.4394  lr: 9.7478e-06  max_mem: 18476M
[01/23 22:39:48] d2.utils.events INFO:  eta: 1 day, 17:36:13  iter: 1699  total_loss: 546  loss_ce: 4.358  loss_mask: 50.9  loss_ce_0: 5.034  loss_mask_0: 53.53  loss_ce_1: 4.516  loss_mask_1: 50.23  loss_ce_2: 4.518  loss_mask_2: 50.25  loss_ce_3: 4.42  loss_mask_3: 49.71  loss_ce_4: 4.458  loss_mask_4: 49.57  loss_ce_5: 4.415  loss_mask_5: 49.11  loss_ce_6: 4.394  loss_mask_6: 49.48  loss_ce_7: 4.42  loss_mask_7: 49.62  loss_ce_8: 4.358  loss_mask_8: 50.51  time: 2.5764  data_time: 0.4656  lr: 9.7448e-06  max_mem: 18476M
[01/23 22:40:40] d2.utils.events INFO:  eta: 1 day, 17:35:21  iter: 1719  total_loss: 526.8  loss_ce: 4.392  loss_mask: 48.48  loss_ce_0: 5.026  loss_mask_0: 52.46  loss_ce_1: 4.518  loss_mask_1: 48.29  loss_ce_2: 4.524  loss_mask_2: 47.36  loss_ce_3: 4.433  loss_mask_3: 47.49  loss_ce_4: 4.463  loss_mask_4: 48.03  loss_ce_5: 4.431  loss_mask_5: 47.94  loss_ce_6: 4.417  loss_mask_6: 48.48  loss_ce_7: 4.445  loss_mask_7: 48.07  loss_ce_8: 4.396  loss_mask_8: 48.33  time: 2.5765  data_time: 0.4253  lr: 9.7418e-06  max_mem: 18476M
[01/23 22:41:32] d2.utils.events INFO:  eta: 1 day, 17:36:41  iter: 1739  total_loss: 499.4  loss_ce: 4.349  loss_mask: 45.3  loss_ce_0: 5.036  loss_mask_0: 49.44  loss_ce_1: 4.488  loss_mask_1: 44.56  loss_ce_2: 4.496  loss_mask_2: 45.34  loss_ce_3: 4.42  loss_mask_3: 45.41  loss_ce_4: 4.433  loss_mask_4: 45.12  loss_ce_5: 4.406  loss_mask_5: 44.77  loss_ce_6: 4.378  loss_mask_6: 45.65  loss_ce_7: 4.407  loss_mask_7: 45.96  loss_ce_8: 4.354  loss_mask_8: 46.04  time: 2.5764  data_time: 0.4419  lr: 9.7388e-06  max_mem: 18476M
[01/23 22:42:26] d2.utils.events INFO:  eta: 1 day, 17:37:04  iter: 1759  total_loss: 532.4  loss_ce: 4.35  loss_mask: 49.17  loss_ce_0: 5.033  loss_mask_0: 52.58  loss_ce_1: 4.496  loss_mask_1: 47.47  loss_ce_2: 4.488  loss_mask_2: 48.13  loss_ce_3: 4.417  loss_mask_3: 47.97  loss_ce_4: 4.433  loss_mask_4: 48.39  loss_ce_5: 4.414  loss_mask_5: 46.61  loss_ce_6: 4.401  loss_mask_6: 48.69  loss_ce_7: 4.444  loss_mask_7: 48.33  loss_ce_8: 4.363  loss_mask_8: 48.66  time: 2.5777  data_time: 0.4569  lr: 9.7358e-06  max_mem: 18476M
[01/23 22:43:15] d2.utils.events INFO:  eta: 1 day, 17:36:21  iter: 1779  total_loss: 525.1  loss_ce: 4.365  loss_mask: 47.89  loss_ce_0: 5.04  loss_mask_0: 50.69  loss_ce_1: 4.496  loss_mask_1: 46.53  loss_ce_2: 4.495  loss_mask_2: 46.99  loss_ce_3: 4.433  loss_mask_3: 46.11  loss_ce_4: 4.447  loss_mask_4: 48.37  loss_ce_5: 4.419  loss_mask_5: 46.42  loss_ce_6: 4.417  loss_mask_6: 46.46  loss_ce_7: 4.455  loss_mask_7: 47.9  loss_ce_8: 4.38  loss_mask_8: 47.34  time: 2.5763  data_time: 0.4009  lr: 9.7328e-06  max_mem: 18476M
[01/23 22:44:09] d2.utils.events INFO:  eta: 1 day, 17:38:51  iter: 1799  total_loss: 521.5  loss_ce: 4.308  loss_mask: 48.65  loss_ce_0: 5.062  loss_mask_0: 50.6  loss_ce_1: 4.48  loss_mask_1: 46.53  loss_ce_2: 4.495  loss_mask_2: 47.38  loss_ce_3: 4.425  loss_mask_3: 47.73  loss_ce_4: 4.433  loss_mask_4: 48.57  loss_ce_5: 4.396  loss_mask_5: 46.87  loss_ce_6: 4.411  loss_mask_6: 46.99  loss_ce_7: 4.429  loss_mask_7: 47.34  loss_ce_8: 4.343  loss_mask_8: 47.57  time: 2.5776  data_time: 0.4874  lr: 9.7297e-06  max_mem: 18476M
[01/23 22:45:01] d2.utils.events INFO:  eta: 1 day, 17:33:15  iter: 1819  total_loss: 527.6  loss_ce: 4.316  loss_mask: 49.06  loss_ce_0: 5.042  loss_mask_0: 51.49  loss_ce_1: 4.475  loss_mask_1: 46.76  loss_ce_2: 4.494  loss_mask_2: 46.23  loss_ce_3: 4.423  loss_mask_3: 46.66  loss_ce_4: 4.425  loss_mask_4: 48.28  loss_ce_5: 4.391  loss_mask_5: 45.93  loss_ce_6: 4.382  loss_mask_6: 47.96  loss_ce_7: 4.398  loss_mask_7: 48.07  loss_ce_8: 4.337  loss_mask_8: 49.07  time: 2.5782  data_time: 0.4797  lr: 9.7267e-06  max_mem: 18476M
[01/23 22:45:52] d2.utils.events INFO:  eta: 1 day, 17:33:01  iter: 1839  total_loss: 511.4  loss_ce: 4.369  loss_mask: 47.16  loss_ce_0: 5.044  loss_mask_0: 50.14  loss_ce_1: 4.469  loss_mask_1: 45.47  loss_ce_2: 4.481  loss_mask_2: 46.06  loss_ce_3: 4.42  loss_mask_3: 47.16  loss_ce_4: 4.447  loss_mask_4: 46.76  loss_ce_5: 4.396  loss_mask_5: 46.21  loss_ce_6: 4.38  loss_mask_6: 46.96  loss_ce_7: 4.422  loss_mask_7: 47.61  loss_ce_8: 4.383  loss_mask_8: 46.76  time: 2.5777  data_time: 0.4257  lr: 9.7237e-06  max_mem: 18476M
[01/23 22:46:48] d2.utils.events INFO:  eta: 1 day, 17:32:56  iter: 1859  total_loss: 530.9  loss_ce: 4.385  loss_mask: 48.12  loss_ce_0: 5.038  loss_mask_0: 51.83  loss_ce_1: 4.476  loss_mask_1: 47.87  loss_ce_2: 4.504  loss_mask_2: 48.4  loss_ce_3: 4.443  loss_mask_3: 47.93  loss_ce_4: 4.466  loss_mask_4: 48.79  loss_ce_5: 4.423  loss_mask_5: 47.74  loss_ce_6: 4.415  loss_mask_6: 47.24  loss_ce_7: 4.441  loss_mask_7: 47.69  loss_ce_8: 4.401  loss_mask_8: 49.16  time: 2.5801  data_time: 0.4798  lr: 9.7207e-06  max_mem: 18476M
[01/23 22:47:38] d2.utils.events INFO:  eta: 1 day, 17:29:37  iter: 1879  total_loss: 502.5  loss_ce: 4.353  loss_mask: 46.24  loss_ce_0: 5.049  loss_mask_0: 48.38  loss_ce_1: 4.483  loss_mask_1: 45.15  loss_ce_2: 4.503  loss_mask_2: 45.65  loss_ce_3: 4.437  loss_mask_3: 45.45  loss_ce_4: 4.462  loss_mask_4: 45.38  loss_ce_5: 4.406  loss_mask_5: 46.13  loss_ce_6: 4.4  loss_mask_6: 46.68  loss_ce_7: 4.402  loss_mask_7: 46.07  loss_ce_8: 4.37  loss_mask_8: 45.48  time: 2.5794  data_time: 0.4197  lr: 9.7177e-06  max_mem: 18476M
[01/23 22:48:28] d2.utils.events INFO:  eta: 1 day, 17:27:13  iter: 1899  total_loss: 517.9  loss_ce: 4.348  loss_mask: 46.61  loss_ce_0: 5.054  loss_mask_0: 50.79  loss_ce_1: 4.475  loss_mask_1: 45.55  loss_ce_2: 4.496  loss_mask_2: 47.39  loss_ce_3: 4.463  loss_mask_3: 47.22  loss_ce_4: 4.485  loss_mask_4: 47.51  loss_ce_5: 4.439  loss_mask_5: 46.65  loss_ce_6: 4.421  loss_mask_6: 46.66  loss_ce_7: 4.422  loss_mask_7: 46.62  loss_ce_8: 4.369  loss_mask_8: 45.37  time: 2.5785  data_time: 0.3916  lr: 9.7147e-06  max_mem: 18476M
[01/23 22:49:23] d2.utils.events INFO:  eta: 1 day, 17:26:03  iter: 1919  total_loss: 524  loss_ce: 4.381  loss_mask: 47.9  loss_ce_0: 5.038  loss_mask_0: 51.29  loss_ce_1: 4.474  loss_mask_1: 47.09  loss_ce_2: 4.502  loss_mask_2: 48.17  loss_ce_3: 4.482  loss_mask_3: 47.81  loss_ce_4: 4.508  loss_mask_4: 47.96  loss_ce_5: 4.469  loss_mask_5: 46.91  loss_ce_6: 4.438  loss_mask_6: 48.69  loss_ce_7: 4.448  loss_mask_7: 48.33  loss_ce_8: 4.408  loss_mask_8: 47.64  time: 2.5803  data_time: 0.4615  lr: 9.7117e-06  max_mem: 18476M
[01/23 22:50:15] d2.utils.events INFO:  eta: 1 day, 17:25:42  iter: 1939  total_loss: 532.5  loss_ce: 4.395  loss_mask: 48.99  loss_ce_0: 5.05  loss_mask_0: 52.3  loss_ce_1: 4.497  loss_mask_1: 47.23  loss_ce_2: 4.529  loss_mask_2: 47.97  loss_ce_3: 4.492  loss_mask_3: 47.9  loss_ce_4: 4.5  loss_mask_4: 48.29  loss_ce_5: 4.46  loss_mask_5: 47.29  loss_ce_6: 4.437  loss_mask_6: 48.49  loss_ce_7: 4.454  loss_mask_7: 49.23  loss_ce_8: 4.406  loss_mask_8: 48.39  time: 2.5803  data_time: 0.4368  lr: 9.7087e-06  max_mem: 18476M
[01/23 22:51:09] d2.utils.events INFO:  eta: 1 day, 17:25:14  iter: 1959  total_loss: 512.6  loss_ce: 4.35  loss_mask: 46.2  loss_ce_0: 5.058  loss_mask_0: 49.02  loss_ce_1: 4.461  loss_mask_1: 44.66  loss_ce_2: 4.492  loss_mask_2: 45.8  loss_ce_3: 4.456  loss_mask_3: 45.12  loss_ce_4: 4.471  loss_mask_4: 46.68  loss_ce_5: 4.419  loss_mask_5: 45.94  loss_ce_6: 4.404  loss_mask_6: 46.72  loss_ce_7: 4.429  loss_mask_7: 46.5  loss_ce_8: 4.36  loss_mask_8: 46.63  time: 2.5813  data_time: 0.4681  lr: 9.7057e-06  max_mem: 18476M
[01/23 22:52:01] d2.utils.events INFO:  eta: 1 day, 17:23:48  iter: 1979  total_loss: 544.1  loss_ce: 4.353  loss_mask: 49.24  loss_ce_0: 5.048  loss_mask_0: 52.86  loss_ce_1: 4.479  loss_mask_1: 48.04  loss_ce_2: 4.51  loss_mask_2: 48.43  loss_ce_3: 4.489  loss_mask_3: 48.49  loss_ce_4: 4.509  loss_mask_4: 48.86  loss_ce_5: 4.43  loss_mask_5: 50.13  loss_ce_6: 4.411  loss_mask_6: 49.89  loss_ce_7: 4.42  loss_mask_7: 50.49  loss_ce_8: 4.369  loss_mask_8: 49.21  time: 2.5817  data_time: 0.4293  lr: 9.7027e-06  max_mem: 18476M
[01/23 22:52:52] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/23 22:52:53] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/23 22:52:53] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/23 22:56:38] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 28.228141186588374, 'error_1pix': 0.9532010586500462, 'error_3pix': 0.8855738786172953, 'mIoU': 0.02007022116889009, 'fwIoU': 0.056089087974393666, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.23277786054270028, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 1.4408643082037287, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.09528778029493616, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.017520830010514944, 'IoU-31': 0.0002762781938964674, 'IoU-32': 1.0806051154159377, 'IoU-33': 0.020348589741125297, 'IoU-34': 2.8556469061136116e-06, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.09912592808664066, 'IoU-38': 0.47381431704079285, 'IoU-39': 0.001701203775354171, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.002883678634545416, 'IoU-47': 0.0, 'IoU-48': 0.022989501673061196, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.011252425746145473, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0993989316337924, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.007893361421836826, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.03557727468179616, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.006190775186083309, 'IoU-75': 0.12714942754151723, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.010972644893288863, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.06684937606229653, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5263175863320338, 'pACC': 1.446227850807742, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.24654731633020305, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 96.86088185587744, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.09777489347751638, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.017620217522337146, 'ACC-31': 0.0002776440488045852, 'ACC-32': 2.4648921451336343, 'ACC-33': 0.021166733789873975, 'ACC-34': 2.879688016903999e-06, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.1163313160234951, 'ACC-38': 0.6510062929046989, 'ACC-39': 0.0017027947914449331, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0029711873020837405, 'ACC-47': 0.0, 'ACC-48': 0.02396925564710885, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.011402893801049066, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.10543765878428249, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.00807159226890038, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.039638195342980645, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.006274313646185571, 'ACC-75': 0.2790969916100548, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.011212806573225874, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.08669759118714623, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/23 22:56:38] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/23 22:56:38] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/23 22:56:38] d2.evaluation.testing INFO: copypaste: 28.2281,0.9532,0.8856,0.0201,0.0561,0.5263,1.4462
[01/23 22:56:38] d2.utils.events INFO:  eta: 1 day, 17:21:55  iter: 1999  total_loss: 528.6  loss_ce: 4.36  loss_mask: 47.2  loss_ce_0: 5.042  loss_mask_0: 51.49  loss_ce_1: 4.479  loss_mask_1: 46.26  loss_ce_2: 4.481  loss_mask_2: 47.25  loss_ce_3: 4.483  loss_mask_3: 48.48  loss_ce_4: 4.498  loss_mask_4: 47.73  loss_ce_5: 4.435  loss_mask_5: 47.43  loss_ce_6: 4.406  loss_mask_6: 48.09  loss_ce_7: 4.423  loss_mask_7: 48.19  loss_ce_8: 4.375  loss_mask_8: 47.3  time: 2.5815  data_time: 0.4124  lr: 9.6996e-06  max_mem: 18476M
[01/23 22:57:29] d2.utils.events INFO:  eta: 1 day, 17:22:05  iter: 2019  total_loss: 539.7  loss_ce: 4.359  loss_mask: 48.82  loss_ce_0: 5.051  loss_mask_0: 51.42  loss_ce_1: 4.456  loss_mask_1: 47.73  loss_ce_2: 4.478  loss_mask_2: 48.82  loss_ce_3: 4.469  loss_mask_3: 50.75  loss_ce_4: 4.466  loss_mask_4: 49.69  loss_ce_5: 4.424  loss_mask_5: 49.98  loss_ce_6: 4.402  loss_mask_6: 49.09  loss_ce_7: 4.411  loss_mask_7: 48.75  loss_ce_8: 4.374  loss_mask_8: 48.8  time: 2.5811  data_time: 0.4305  lr: 9.6966e-06  max_mem: 18476M
[01/23 22:58:20] d2.utils.events INFO:  eta: 1 day, 17:21:14  iter: 2039  total_loss: 489.9  loss_ce: 4.375  loss_mask: 44.55  loss_ce_0: 5.041  loss_mask_0: 48.22  loss_ce_1: 4.439  loss_mask_1: 42.77  loss_ce_2: 4.48  loss_mask_2: 44.38  loss_ce_3: 4.463  loss_mask_3: 44.28  loss_ce_4: 4.484  loss_mask_4: 44.09  loss_ce_5: 4.44  loss_mask_5: 43.65  loss_ce_6: 4.45  loss_mask_6: 44.64  loss_ce_7: 4.448  loss_mask_7: 44.43  loss_ce_8: 4.394  loss_mask_8: 43.86  time: 2.5804  data_time: 0.4355  lr: 9.6936e-06  max_mem: 18476M
[01/23 22:59:15] d2.utils.events INFO:  eta: 1 day, 17:29:29  iter: 2059  total_loss: 518.5  loss_ce: 4.322  loss_mask: 47.92  loss_ce_0: 5.059  loss_mask_0: 50.58  loss_ce_1: 4.429  loss_mask_1: 45.44  loss_ce_2: 4.468  loss_mask_2: 47.07  loss_ce_3: 4.44  loss_mask_3: 46.8  loss_ce_4: 4.459  loss_mask_4: 46.4  loss_ce_5: 4.401  loss_mask_5: 46.64  loss_ce_6: 4.396  loss_mask_6: 47.54  loss_ce_7: 4.407  loss_mask_7: 46.93  loss_ce_8: 4.339  loss_mask_8: 46.74  time: 2.5822  data_time: 0.4791  lr: 9.6906e-06  max_mem: 18476M
[01/23 23:00:06] d2.utils.events INFO:  eta: 1 day, 17:30:22  iter: 2079  total_loss: 503.4  loss_ce: 4.332  loss_mask: 45.42  loss_ce_0: 5.056  loss_mask_0: 48.99  loss_ce_1: 4.425  loss_mask_1: 45.43  loss_ce_2: 4.46  loss_mask_2: 45.58  loss_ce_3: 4.457  loss_mask_3: 45.78  loss_ce_4: 4.494  loss_mask_4: 45.22  loss_ce_5: 4.418  loss_mask_5: 46.03  loss_ce_6: 4.407  loss_mask_6: 45.98  loss_ce_7: 4.416  loss_mask_7: 45.79  loss_ce_8: 4.346  loss_mask_8: 45.21  time: 2.5817  data_time: 0.4077  lr: 9.6876e-06  max_mem: 18476M
[01/23 23:00:59] d2.utils.events INFO:  eta: 1 day, 17:30:06  iter: 2099  total_loss: 520.4  loss_ce: 4.342  loss_mask: 45.68  loss_ce_0: 5.05  loss_mask_0: 50.37  loss_ce_1: 4.425  loss_mask_1: 46.77  loss_ce_2: 4.463  loss_mask_2: 47.56  loss_ce_3: 4.451  loss_mask_3: 47.66  loss_ce_4: 4.505  loss_mask_4: 48.14  loss_ce_5: 4.46  loss_mask_5: 47.93  loss_ce_6: 4.438  loss_mask_6: 47.43  loss_ce_7: 4.447  loss_mask_7: 46.69  loss_ce_8: 4.368  loss_mask_8: 46.05  time: 2.5825  data_time: 0.4518  lr: 9.6846e-06  max_mem: 18476M
[01/23 23:01:52] d2.utils.events INFO:  eta: 1 day, 17:32:32  iter: 2119  total_loss: 562.4  loss_ce: 4.367  loss_mask: 51.3  loss_ce_0: 5.041  loss_mask_0: 53.7  loss_ce_1: 4.426  loss_mask_1: 50.22  loss_ce_2: 4.469  loss_mask_2: 51.26  loss_ce_3: 4.458  loss_mask_3: 50.87  loss_ce_4: 4.503  loss_mask_4: 50.96  loss_ce_5: 4.479  loss_mask_5: 51.84  loss_ce_6: 4.446  loss_mask_6: 50.85  loss_ce_7: 4.483  loss_mask_7: 51.46  loss_ce_8: 4.397  loss_mask_8: 50.89  time: 2.5830  data_time: 0.4553  lr: 9.6816e-06  max_mem: 18476M
[01/23 23:02:42] d2.utils.events INFO:  eta: 1 day, 17:28:49  iter: 2139  total_loss: 509.4  loss_ce: 4.346  loss_mask: 45.82  loss_ce_0: 5.044  loss_mask_0: 50.46  loss_ce_1: 4.434  loss_mask_1: 45.48  loss_ce_2: 4.462  loss_mask_2: 45.7  loss_ce_3: 4.454  loss_mask_3: 46.4  loss_ce_4: 4.481  loss_mask_4: 46.16  loss_ce_5: 4.441  loss_mask_5: 47.02  loss_ce_6: 4.417  loss_mask_6: 45.9  loss_ce_7: 4.435  loss_mask_7: 46.9  loss_ce_8: 4.366  loss_mask_8: 46.3  time: 2.5825  data_time: 0.4087  lr: 9.6786e-06  max_mem: 18476M
[01/23 23:03:37] d2.utils.events INFO:  eta: 1 day, 17:32:58  iter: 2159  total_loss: 501.2  loss_ce: 4.328  loss_mask: 45.58  loss_ce_0: 5.035  loss_mask_0: 48.95  loss_ce_1: 4.413  loss_mask_1: 44.79  loss_ce_2: 4.44  loss_mask_2: 45.9  loss_ce_3: 4.429  loss_mask_3: 45.08  loss_ce_4: 4.465  loss_mask_4: 45.49  loss_ce_5: 4.416  loss_mask_5: 46.46  loss_ce_6: 4.414  loss_mask_6: 45.46  loss_ce_7: 4.421  loss_mask_7: 45.94  loss_ce_8: 4.355  loss_mask_8: 46.01  time: 2.5841  data_time: 0.4682  lr: 9.6756e-06  max_mem: 18476M
[01/23 23:04:29] d2.utils.events INFO:  eta: 1 day, 17:32:19  iter: 2179  total_loss: 506.7  loss_ce: 4.348  loss_mask: 46.51  loss_ce_0: 5.051  loss_mask_0: 48.27  loss_ce_1: 4.409  loss_mask_1: 45.57  loss_ce_2: 4.448  loss_mask_2: 45.35  loss_ce_3: 4.445  loss_mask_3: 46.54  loss_ce_4: 4.488  loss_mask_4: 46.85  loss_ce_5: 4.462  loss_mask_5: 46.14  loss_ce_6: 4.449  loss_mask_6: 47.21  loss_ce_7: 4.436  loss_mask_7: 46.29  loss_ce_8: 4.376  loss_mask_8: 46.76  time: 2.5839  data_time: 0.4403  lr: 9.6725e-06  max_mem: 18476M
[01/23 23:05:20] d2.utils.events INFO:  eta: 1 day, 17:30:50  iter: 2199  total_loss: 506.6  loss_ce: 4.32  loss_mask: 45.89  loss_ce_0: 5.058  loss_mask_0: 48.44  loss_ce_1: 4.397  loss_mask_1: 45.79  loss_ce_2: 4.441  loss_mask_2: 46.55  loss_ce_3: 4.436  loss_mask_3: 46.12  loss_ce_4: 4.476  loss_mask_4: 46  loss_ce_5: 4.463  loss_mask_5: 46.58  loss_ce_6: 4.433  loss_mask_6: 46.22  loss_ce_7: 4.409  loss_mask_7: 46.79  loss_ce_8: 4.352  loss_mask_8: 46.52  time: 2.5837  data_time: 0.4270  lr: 9.6695e-06  max_mem: 18476M
[01/23 23:06:15] d2.utils.events INFO:  eta: 1 day, 17:31:13  iter: 2219  total_loss: 520.8  loss_ce: 4.332  loss_mask: 48.37  loss_ce_0: 5.053  loss_mask_0: 50.18  loss_ce_1: 4.382  loss_mask_1: 47.64  loss_ce_2: 4.434  loss_mask_2: 47.14  loss_ce_3: 4.451  loss_mask_3: 47.41  loss_ce_4: 4.497  loss_mask_4: 49.45  loss_ce_5: 4.491  loss_mask_5: 47.33  loss_ce_6: 4.456  loss_mask_6: 46.46  loss_ce_7: 4.45  loss_mask_7: 47.44  loss_ce_8: 4.361  loss_mask_8: 46.76  time: 2.5850  data_time: 0.4796  lr: 9.6665e-06  max_mem: 18476M
[01/23 23:07:06] d2.utils.events INFO:  eta: 1 day, 17:29:20  iter: 2239  total_loss: 523.9  loss_ce: 4.334  loss_mask: 48.55  loss_ce_0: 5.051  loss_mask_0: 49.92  loss_ce_1: 4.389  loss_mask_1: 46.7  loss_ce_2: 4.432  loss_mask_2: 48.34  loss_ce_3: 4.453  loss_mask_3: 48.79  loss_ce_4: 4.478  loss_mask_4: 47.46  loss_ce_5: 4.455  loss_mask_5: 49.04  loss_ce_6: 4.422  loss_mask_6: 48.13  loss_ce_7: 4.428  loss_mask_7: 48.29  loss_ce_8: 4.357  loss_mask_8: 47.12  time: 2.5848  data_time: 0.4269  lr: 9.6635e-06  max_mem: 18476M
[01/23 23:07:56] d2.utils.events INFO:  eta: 1 day, 17:28:21  iter: 2259  total_loss: 489  loss_ce: 4.321  loss_mask: 44.36  loss_ce_0: 5.053  loss_mask_0: 47.37  loss_ce_1: 4.384  loss_mask_1: 43.81  loss_ce_2: 4.397  loss_mask_2: 43.57  loss_ce_3: 4.419  loss_mask_3: 44.07  loss_ce_4: 4.444  loss_mask_4: 43.69  loss_ce_5: 4.429  loss_mask_5: 44.56  loss_ce_6: 4.405  loss_mask_6: 43.93  loss_ce_7: 4.398  loss_mask_7: 44.41  loss_ce_8: 4.339  loss_mask_8: 43.26  time: 2.5843  data_time: 0.4213  lr: 9.6605e-06  max_mem: 18476M
[01/23 23:08:46] d2.utils.events INFO:  eta: 1 day, 17:26:51  iter: 2279  total_loss: 508.9  loss_ce: 4.307  loss_mask: 46.5  loss_ce_0: 5.056  loss_mask_0: 49.1  loss_ce_1: 4.357  loss_mask_1: 45.8  loss_ce_2: 4.375  loss_mask_2: 46.32  loss_ce_3: 4.389  loss_mask_3: 46.31  loss_ce_4: 4.425  loss_mask_4: 46.54  loss_ce_5: 4.423  loss_mask_5: 46.83  loss_ce_6: 4.402  loss_mask_6: 46.14  loss_ce_7: 4.395  loss_mask_7: 47.1  loss_ce_8: 4.327  loss_mask_8: 46.59  time: 2.5833  data_time: 0.4212  lr: 9.6575e-06  max_mem: 18476M
[01/23 23:09:37] d2.utils.events INFO:  eta: 1 day, 17:21:30  iter: 2299  total_loss: 514.6  loss_ce: 4.337  loss_mask: 47.33  loss_ce_0: 5.061  loss_mask_0: 49.81  loss_ce_1: 4.379  loss_mask_1: 47.03  loss_ce_2: 4.404  loss_mask_2: 48.48  loss_ce_3: 4.416  loss_mask_3: 47.41  loss_ce_4: 4.453  loss_mask_4: 46.77  loss_ce_5: 4.465  loss_mask_5: 46.5  loss_ce_6: 4.435  loss_mask_6: 46.35  loss_ce_7: 4.413  loss_mask_7: 47.24  loss_ce_8: 4.347  loss_mask_8: 46.7  time: 2.5828  data_time: 0.4105  lr: 9.6545e-06  max_mem: 18476M
[01/23 23:10:25] d2.utils.events INFO:  eta: 1 day, 17:18:48  iter: 2319  total_loss: 475.2  loss_ce: 4.264  loss_mask: 42.99  loss_ce_0: 5.071  loss_mask_0: 45.78  loss_ce_1: 4.346  loss_mask_1: 41.66  loss_ce_2: 4.363  loss_mask_2: 43.45  loss_ce_3: 4.355  loss_mask_3: 42.91  loss_ce_4: 4.39  loss_mask_4: 43.51  loss_ce_5: 4.38  loss_mask_5: 42.81  loss_ce_6: 4.343  loss_mask_6: 42.94  loss_ce_7: 4.344  loss_mask_7: 43.5  loss_ce_8: 4.29  loss_mask_8: 43.39  time: 2.5814  data_time: 0.3992  lr: 9.6515e-06  max_mem: 18476M
[01/23 23:11:16] d2.utils.events INFO:  eta: 1 day, 17:17:18  iter: 2339  total_loss: 482.6  loss_ce: 4.352  loss_mask: 43.12  loss_ce_0: 5.057  loss_mask_0: 48.39  loss_ce_1: 4.389  loss_mask_1: 43.81  loss_ce_2: 4.406  loss_mask_2: 42.44  loss_ce_3: 4.41  loss_mask_3: 43.98  loss_ce_4: 4.438  loss_mask_4: 43.7  loss_ce_5: 4.43  loss_mask_5: 42.96  loss_ce_6: 4.403  loss_mask_6: 42.91  loss_ce_7: 4.395  loss_mask_7: 43.68  loss_ce_8: 4.359  loss_mask_8: 44.02  time: 2.5811  data_time: 0.4002  lr: 9.6485e-06  max_mem: 18476M
[01/23 23:12:05] d2.utils.events INFO:  eta: 1 day, 17:10:44  iter: 2359  total_loss: 493  loss_ce: 4.277  loss_mask: 44.25  loss_ce_0: 5.062  loss_mask_0: 48.18  loss_ce_1: 4.364  loss_mask_1: 43.05  loss_ce_2: 4.381  loss_mask_2: 43.81  loss_ce_3: 4.383  loss_mask_3: 44.86  loss_ce_4: 4.407  loss_mask_4: 44.93  loss_ce_5: 4.409  loss_mask_5: 44.41  loss_ce_6: 4.363  loss_mask_6: 44.67  loss_ce_7: 4.339  loss_mask_7: 45.51  loss_ce_8: 4.295  loss_mask_8: 44.35  time: 2.5801  data_time: 0.4007  lr: 9.6454e-06  max_mem: 18476M
[01/23 23:12:54] d2.utils.events INFO:  eta: 1 day, 17:07:15  iter: 2379  total_loss: 522.4  loss_ce: 4.283  loss_mask: 47.33  loss_ce_0: 5.074  loss_mask_0: 50.34  loss_ce_1: 4.367  loss_mask_1: 46.73  loss_ce_2: 4.373  loss_mask_2: 47.17  loss_ce_3: 4.368  loss_mask_3: 48.21  loss_ce_4: 4.398  loss_mask_4: 48.41  loss_ce_5: 4.382  loss_mask_5: 46.93  loss_ce_6: 4.349  loss_mask_6: 47.74  loss_ce_7: 4.326  loss_mask_7: 48.13  loss_ce_8: 4.304  loss_mask_8: 47.39  time: 2.5790  data_time: 0.4141  lr: 9.6424e-06  max_mem: 18476M
[01/23 23:13:46] d2.utils.events INFO:  eta: 1 day, 17:04:51  iter: 2399  total_loss: 492.2  loss_ce: 4.348  loss_mask: 45.4  loss_ce_0: 5.061  loss_mask_0: 48.2  loss_ce_1: 4.384  loss_mask_1: 43.77  loss_ce_2: 4.396  loss_mask_2: 43.19  loss_ce_3: 4.4  loss_mask_3: 44.43  loss_ce_4: 4.43  loss_mask_4: 44.93  loss_ce_5: 4.415  loss_mask_5: 45.14  loss_ce_6: 4.384  loss_mask_6: 44.11  loss_ce_7: 4.369  loss_mask_7: 46.26  loss_ce_8: 4.356  loss_mask_8: 44.7  time: 2.5790  data_time: 0.4604  lr: 9.6394e-06  max_mem: 18476M
[01/23 23:14:39] d2.utils.events INFO:  eta: 1 day, 17:05:19  iter: 2419  total_loss: 485.6  loss_ce: 4.334  loss_mask: 43.31  loss_ce_0: 5.052  loss_mask_0: 46.46  loss_ce_1: 4.371  loss_mask_1: 42.44  loss_ce_2: 4.378  loss_mask_2: 42.9  loss_ce_3: 4.382  loss_mask_3: 43.62  loss_ce_4: 4.397  loss_mask_4: 43.11  loss_ce_5: 4.386  loss_mask_5: 42.62  loss_ce_6: 4.361  loss_mask_6: 43.6  loss_ce_7: 4.363  loss_mask_7: 45.05  loss_ce_8: 4.351  loss_mask_8: 43.27  time: 2.5794  data_time: 0.4322  lr: 9.6364e-06  max_mem: 18476M
[01/23 23:15:32] d2.utils.events INFO:  eta: 1 day, 17:12:00  iter: 2439  total_loss: 497.2  loss_ce: 4.325  loss_mask: 45.35  loss_ce_0: 5.084  loss_mask_0: 47  loss_ce_1: 4.35  loss_mask_1: 43.98  loss_ce_2: 4.352  loss_mask_2: 44.04  loss_ce_3: 4.346  loss_mask_3: 44.09  loss_ce_4: 4.373  loss_mask_4: 44.35  loss_ce_5: 4.352  loss_mask_5: 44.98  loss_ce_6: 4.342  loss_mask_6: 45.78  loss_ce_7: 4.37  loss_mask_7: 46.51  loss_ce_8: 4.344  loss_mask_8: 45.95  time: 2.5803  data_time: 0.4654  lr: 9.6334e-06  max_mem: 18476M
[01/23 23:16:26] d2.utils.events INFO:  eta: 1 day, 17:08:07  iter: 2459  total_loss: 473.2  loss_ce: 4.338  loss_mask: 43.14  loss_ce_0: 5.065  loss_mask_0: 45.4  loss_ce_1: 4.361  loss_mask_1: 40.98  loss_ce_2: 4.358  loss_mask_2: 41.81  loss_ce_3: 4.365  loss_mask_3: 42.33  loss_ce_4: 4.392  loss_mask_4: 42.23  loss_ce_5: 4.36  loss_mask_5: 41.87  loss_ce_6: 4.373  loss_mask_6: 44.79  loss_ce_7: 4.403  loss_mask_7: 43.04  loss_ce_8: 4.367  loss_mask_8: 42.04  time: 2.5810  data_time: 0.4469  lr: 9.6304e-06  max_mem: 18476M
[01/23 23:17:17] d2.utils.events INFO:  eta: 1 day, 17:08:27  iter: 2479  total_loss: 511.8  loss_ce: 4.351  loss_mask: 46.26  loss_ce_0: 5.063  loss_mask_0: 48.52  loss_ce_1: 4.384  loss_mask_1: 45.02  loss_ce_2: 4.392  loss_mask_2: 45.92  loss_ce_3: 4.373  loss_mask_3: 44.85  loss_ce_4: 4.388  loss_mask_4: 45.91  loss_ce_5: 4.384  loss_mask_5: 45.54  loss_ce_6: 4.395  loss_mask_6: 46.95  loss_ce_7: 4.452  loss_mask_7: 48.69  loss_ce_8: 4.396  loss_mask_8: 47.04  time: 2.5807  data_time: 0.4189  lr: 9.6274e-06  max_mem: 18476M
[01/23 23:18:12] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/23 23:18:13] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/23 23:18:13] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/23 23:21:48] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 26.074823779207666, 'error_1pix': 0.9548245035090358, 'error_3pix': 0.8906686812696718, 'mIoU': 0.06012488735334826, 'fwIoU': 0.14046087752887765, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.06553449830950323, 'IoU-13': 0.0, 'IoU-14': 0.0003200864899302711, 'IoU-15': 0.0, 'IoU-16': 0.025268571626885533, 'IoU-17': 1.4117695003393753, 'IoU-18': 0.10101301060035704, 'IoU-19': 0.03428786661939045, 'IoU-20': 0.0, 'IoU-21': 0.1650561069406693, 'IoU-22': 0.33513903450590843, 'IoU-23': 0.5162342407983798, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 1.5961040821988322, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.16191151712780302, 'IoU-30': 0.4717686355235229, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.007970921493370423, 'IoU-34': 0.03244201556984168, 'IoU-35': 0.8063791216433875, 'IoU-36': 0.6874306879266089, 'IoU-37': 0.0, 'IoU-38': 0.057618449046594106, 'IoU-39': 0.0, 'IoU-40': 0.00017431338721309164, 'IoU-41': 0.7085271172817568, 'IoU-42': 1.1467157769937464, 'IoU-43': 0.33970867054493326, 'IoU-44': 0.0017781882977922062, 'IoU-45': 0.0, 'IoU-46': 0.028369832946692052, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.00048504246758715485, 'IoU-51': 0.0, 'IoU-52': 0.14796649182040028, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.26389592616038465, 'IoU-58': 0.1829521795261134, 'IoU-59': 0.0, 'IoU-60': 0.0514635814687926, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0023111061141249186, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.6639422207959736, 'IoU-72': 0.0, 'IoU-73': 0.6534015792991372, 'IoU-74': 0.004626290278167849, 'IoU-75': 0.0, 'IoU-76': 0.3400200898719691, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.36721250283186824, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.001700670091226665, 'IoU-92': 0.1624784449046252, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5527716124610373, 'pACC': 1.3941772835499098, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.06893970259490816, 'ACC-13': 0.0, 'ACC-14': 0.00032114502331191723, 'ACC-15': 0.0, 'ACC-16': 0.02552885715542485, 'ACC-17': 62.86253671274169, 'ACC-18': 0.10937878455713397, 'ACC-19': 0.03590777832746068, 'ACC-20': 0.0, 'ACC-21': 0.18441077089161645, 'ACC-22': 0.45505922578280583, 'ACC-23': 0.6765697108564848, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 14.245410237248294, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.20413339066223213, 'ACC-30': 0.7174996318071691, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.008095347309109695, 'ACC-34': 0.03293787153734794, 'ACC-35': 1.8382201170397214, 'ACC-36': 0.953036684691763, 'ACC-37': 0.0, 'ACC-38': 0.05896060030730317, 'ACC-39': 0.0, 'ACC-40': 0.00017439421187446518, 'ACC-41': 2.098179211153015, 'ACC-42': 9.422004619059129, 'ACC-43': 0.36581573734722045, 'ACC-44': 0.00180689407528037, 'ACC-45': 0.0, 'ACC-46': 0.029337388194674494, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.00048506923915995055, 'ACC-51': 0.0, 'ACC-52': 0.17455740048958227, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.48713716098429605, 'ACC-58': 0.24607489553973147, 'ACC-59': 0.0, 'ACC-60': 0.06209215024500586, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0023947494148235634, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 3.156755004528898, 'ACC-72': 0.0, 'ACC-73': 5.238470075387756, 'ACC-74': 0.004771092668453611, 'ACC-75': 0.0, 'ACC-76': 0.7432667431739686, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 1.1987870085711014, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.001700957516612912, 'ACC-92': 0.421392472184812, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/23 23:21:48] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/23 23:21:48] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/23 23:21:48] d2.evaluation.testing INFO: copypaste: 26.0748,0.9548,0.8907,0.0601,0.1405,0.5528,1.3942
[01/23 23:21:48] d2.utils.events INFO:  eta: 1 day, 17:09:48  iter: 2499  total_loss: 478.5  loss_ce: 4.312  loss_mask: 42.3  loss_ce_0: 5.075  loss_mask_0: 45.32  loss_ce_1: 4.369  loss_mask_1: 42.23  loss_ce_2: 4.363  loss_mask_2: 42.47  loss_ce_3: 4.345  loss_mask_3: 42.64  loss_ce_4: 4.376  loss_mask_4: 42.43  loss_ce_5: 4.353  loss_mask_5: 41.97  loss_ce_6: 4.352  loss_mask_6: 43.79  loss_ce_7: 4.404  loss_mask_7: 44.84  loss_ce_8: 4.35  loss_mask_8: 44.02  time: 2.5822  data_time: 0.4854  lr: 9.6244e-06  max_mem: 18476M
[01/23 23:22:41] d2.utils.events INFO:  eta: 1 day, 17:09:16  iter: 2519  total_loss: 488.8  loss_ce: 4.332  loss_mask: 45.23  loss_ce_0: 5.079  loss_mask_0: 45.78  loss_ce_1: 4.373  loss_mask_1: 42.56  loss_ce_2: 4.377  loss_mask_2: 42.2  loss_ce_3: 4.353  loss_mask_3: 44.86  loss_ce_4: 4.367  loss_mask_4: 43.95  loss_ce_5: 4.367  loss_mask_5: 43.97  loss_ce_6: 4.386  loss_mask_6: 46.96  loss_ce_7: 4.428  loss_mask_7: 45.59  loss_ce_8: 4.379  loss_mask_8: 44.24  time: 2.5826  data_time: 0.4195  lr: 9.6213e-06  max_mem: 18476M
[01/23 23:23:37] d2.utils.events INFO:  eta: 1 day, 17:09:34  iter: 2539  total_loss: 480.2  loss_ce: 4.344  loss_mask: 42.8  loss_ce_0: 5.061  loss_mask_0: 47.2  loss_ce_1: 4.374  loss_mask_1: 42.94  loss_ce_2: 4.371  loss_mask_2: 42.78  loss_ce_3: 4.375  loss_mask_3: 43.07  loss_ce_4: 4.371  loss_mask_4: 42.86  loss_ce_5: 4.381  loss_mask_5: 43.27  loss_ce_6: 4.419  loss_mask_6: 46.09  loss_ce_7: 4.459  loss_mask_7: 44.31  loss_ce_8: 4.397  loss_mask_8: 43.44  time: 2.5843  data_time: 0.4901  lr: 9.6183e-06  max_mem: 18476M
[01/23 23:24:26] d2.utils.events INFO:  eta: 1 day, 17:05:01  iter: 2559  total_loss: 481.5  loss_ce: 4.296  loss_mask: 43.17  loss_ce_0: 5.075  loss_mask_0: 45.6  loss_ce_1: 4.355  loss_mask_1: 42.68  loss_ce_2: 4.357  loss_mask_2: 42.34  loss_ce_3: 4.339  loss_mask_3: 43.66  loss_ce_4: 4.351  loss_mask_4: 43.83  loss_ce_5: 4.346  loss_mask_5: 42.82  loss_ce_6: 4.397  loss_mask_6: 45.31  loss_ce_7: 4.416  loss_mask_7: 44.41  loss_ce_8: 4.357  loss_mask_8: 43.42  time: 2.5834  data_time: 0.3742  lr: 9.6153e-06  max_mem: 18476M
[01/23 23:25:19] d2.utils.events INFO:  eta: 1 day, 17:05:59  iter: 2579  total_loss: 500.9  loss_ce: 4.348  loss_mask: 43.85  loss_ce_0: 5.066  loss_mask_0: 46.47  loss_ce_1: 4.38  loss_mask_1: 44.36  loss_ce_2: 4.392  loss_mask_2: 43.89  loss_ce_3: 4.374  loss_mask_3: 45.85  loss_ce_4: 4.396  loss_mask_4: 45.09  loss_ce_5: 4.405  loss_mask_5: 44.89  loss_ce_6: 4.417  loss_mask_6: 47.35  loss_ce_7: 4.455  loss_mask_7: 46.46  loss_ce_8: 4.39  loss_mask_8: 45.1  time: 2.5838  data_time: 0.4489  lr: 9.6123e-06  max_mem: 18476M
[01/23 23:26:13] d2.utils.events INFO:  eta: 1 day, 17:03:08  iter: 2599  total_loss: 497.3  loss_ce: 4.317  loss_mask: 44.48  loss_ce_0: 5.079  loss_mask_0: 47.42  loss_ce_1: 4.373  loss_mask_1: 44.24  loss_ce_2: 4.376  loss_mask_2: 43.73  loss_ce_3: 4.363  loss_mask_3: 45.3  loss_ce_4: 4.38  loss_mask_4: 44.96  loss_ce_5: 4.383  loss_mask_5: 44.45  loss_ce_6: 4.403  loss_mask_6: 46.82  loss_ce_7: 4.417  loss_mask_7: 44.3  loss_ce_8: 4.354  loss_mask_8: 45.48  time: 2.5846  data_time: 0.4506  lr: 9.6093e-06  max_mem: 18476M
[01/23 23:27:03] d2.utils.events INFO:  eta: 1 day, 17:00:05  iter: 2619  total_loss: 502.3  loss_ce: 4.319  loss_mask: 45.58  loss_ce_0: 5.09  loss_mask_0: 48.16  loss_ce_1: 4.361  loss_mask_1: 44.71  loss_ce_2: 4.374  loss_mask_2: 44.13  loss_ce_3: 4.359  loss_mask_3: 44.9  loss_ce_4: 4.382  loss_mask_4: 44.7  loss_ce_5: 4.377  loss_mask_5: 45.61  loss_ce_6: 4.39  loss_mask_6: 45.99  loss_ce_7: 4.398  loss_mask_7: 45.46  loss_ce_8: 4.352  loss_mask_8: 46.07  time: 2.5838  data_time: 0.4015  lr: 9.6063e-06  max_mem: 18476M
[01/23 23:27:59] d2.utils.events INFO:  eta: 1 day, 17:01:51  iter: 2639  total_loss: 470.1  loss_ce: 4.318  loss_mask: 41.94  loss_ce_0: 5.071  loss_mask_0: 44.98  loss_ce_1: 4.355  loss_mask_1: 43.32  loss_ce_2: 4.353  loss_mask_2: 42.51  loss_ce_3: 4.342  loss_mask_3: 42.92  loss_ce_4: 4.371  loss_mask_4: 41.8  loss_ce_5: 4.373  loss_mask_5: 43.5  loss_ce_6: 4.384  loss_mask_6: 44.14  loss_ce_7: 4.369  loss_mask_7: 42.34  loss_ce_8: 4.35  loss_mask_8: 42.4  time: 2.5854  data_time: 0.4880  lr: 9.6033e-06  max_mem: 18476M
[01/23 23:28:49] d2.utils.events INFO:  eta: 1 day, 16:58:50  iter: 2659  total_loss: 474.9  loss_ce: 4.255  loss_mask: 42.26  loss_ce_0: 5.097  loss_mask_0: 45.2  loss_ce_1: 4.32  loss_mask_1: 42.67  loss_ce_2: 4.31  loss_mask_2: 42.47  loss_ce_3: 4.294  loss_mask_3: 42.61  loss_ce_4: 4.319  loss_mask_4: 43.03  loss_ce_5: 4.321  loss_mask_5: 42.76  loss_ce_6: 4.324  loss_mask_6: 43.49  loss_ce_7: 4.33  loss_mask_7: 44.22  loss_ce_8: 4.288  loss_mask_8: 43.89  time: 2.5849  data_time: 0.4214  lr: 9.6003e-06  max_mem: 18476M
[01/23 23:29:40] d2.utils.events INFO:  eta: 1 day, 16:59:00  iter: 2679  total_loss: 482.2  loss_ce: 4.296  loss_mask: 44.28  loss_ce_0: 5.078  loss_mask_0: 46.06  loss_ce_1: 4.314  loss_mask_1: 43.14  loss_ce_2: 4.318  loss_mask_2: 43.07  loss_ce_3: 4.298  loss_mask_3: 42.78  loss_ce_4: 4.33  loss_mask_4: 42.75  loss_ce_5: 4.331  loss_mask_5: 43.02  loss_ce_6: 4.329  loss_mask_6: 43.65  loss_ce_7: 4.335  loss_mask_7: 43.72  loss_ce_8: 4.329  loss_mask_8: 43.75  time: 2.5846  data_time: 0.4015  lr: 9.5972e-06  max_mem: 18476M
[01/23 23:30:35] d2.utils.events INFO:  eta: 1 day, 16:58:08  iter: 2699  total_loss: 489.7  loss_ce: 4.352  loss_mask: 44.89  loss_ce_0: 5.069  loss_mask_0: 46.14  loss_ce_1: 4.337  loss_mask_1: 43.14  loss_ce_2: 4.339  loss_mask_2: 43.26  loss_ce_3: 4.342  loss_mask_3: 44.34  loss_ce_4: 4.371  loss_mask_4: 44.81  loss_ce_5: 4.375  loss_mask_5: 44.63  loss_ce_6: 4.365  loss_mask_6: 45.46  loss_ce_7: 4.376  loss_mask_7: 46.33  loss_ce_8: 4.374  loss_mask_8: 44.69  time: 2.5860  data_time: 0.4747  lr: 9.5942e-06  max_mem: 18476M
[01/23 23:31:28] d2.utils.events INFO:  eta: 1 day, 16:57:17  iter: 2719  total_loss: 496.7  loss_ce: 4.322  loss_mask: 45.06  loss_ce_0: 5.068  loss_mask_0: 47.87  loss_ce_1: 4.308  loss_mask_1: 43.55  loss_ce_2: 4.315  loss_mask_2: 44.7  loss_ce_3: 4.328  loss_mask_3: 45.31  loss_ce_4: 4.373  loss_mask_4: 44.42  loss_ce_5: 4.368  loss_mask_5: 42.96  loss_ce_6: 4.326  loss_mask_6: 44.44  loss_ce_7: 4.341  loss_mask_7: 46.14  loss_ce_8: 4.338  loss_mask_8: 45.41  time: 2.5861  data_time: 0.4417  lr: 9.5912e-06  max_mem: 18476M
[01/23 23:32:21] d2.utils.events INFO:  eta: 1 day, 16:57:34  iter: 2739  total_loss: 475.1  loss_ce: 4.356  loss_mask: 43.64  loss_ce_0: 5.073  loss_mask_0: 45.26  loss_ce_1: 4.321  loss_mask_1: 42.25  loss_ce_2: 4.343  loss_mask_2: 42.44  loss_ce_3: 4.344  loss_mask_3: 42.79  loss_ce_4: 4.384  loss_mask_4: 42.35  loss_ce_5: 4.374  loss_mask_5: 42.46  loss_ce_6: 4.357  loss_mask_6: 42.74  loss_ce_7: 4.339  loss_mask_7: 43.4  loss_ce_8: 4.359  loss_mask_8: 43.78  time: 2.5866  data_time: 0.4302  lr: 9.5882e-06  max_mem: 18476M
[01/23 23:33:14] d2.utils.events INFO:  eta: 1 day, 16:55:34  iter: 2759  total_loss: 483.9  loss_ce: 4.318  loss_mask: 43.51  loss_ce_0: 5.078  loss_mask_0: 45.57  loss_ce_1: 4.307  loss_mask_1: 43.09  loss_ce_2: 4.318  loss_mask_2: 43.07  loss_ce_3: 4.328  loss_mask_3: 43.96  loss_ce_4: 4.369  loss_mask_4: 42.45  loss_ce_5: 4.346  loss_mask_5: 43.82  loss_ce_6: 4.349  loss_mask_6: 44.49  loss_ce_7: 4.348  loss_mask_7: 44.3  loss_ce_8: 4.335  loss_mask_8: 43.82  time: 2.5871  data_time: 0.4481  lr: 9.5852e-06  max_mem: 18476M
[01/23 23:34:05] d2.utils.events INFO:  eta: 1 day, 16:55:41  iter: 2779  total_loss: 469.2  loss_ce: 4.298  loss_mask: 42.16  loss_ce_0: 5.081  loss_mask_0: 43.41  loss_ce_1: 4.294  loss_mask_1: 41.04  loss_ce_2: 4.298  loss_mask_2: 42.24  loss_ce_3: 4.309  loss_mask_3: 42  loss_ce_4: 4.353  loss_mask_4: 41.59  loss_ce_5: 4.336  loss_mask_5: 42.16  loss_ce_6: 4.318  loss_mask_6: 41.97  loss_ce_7: 4.329  loss_mask_7: 42.65  loss_ce_8: 4.315  loss_mask_8: 42.25  time: 2.5869  data_time: 0.4212  lr: 9.5822e-06  max_mem: 18476M
[01/23 23:35:00] d2.utils.events INFO:  eta: 1 day, 16:55:59  iter: 2799  total_loss: 460.8  loss_ce: 4.288  loss_mask: 41.03  loss_ce_0: 5.076  loss_mask_0: 43.17  loss_ce_1: 4.283  loss_mask_1: 39.67  loss_ce_2: 4.3  loss_mask_2: 40.7  loss_ce_3: 4.306  loss_mask_3: 41.01  loss_ce_4: 4.331  loss_mask_4: 39.93  loss_ce_5: 4.338  loss_mask_5: 40.28  loss_ce_6: 4.327  loss_mask_6: 41.99  loss_ce_7: 4.331  loss_mask_7: 41.72  loss_ce_8: 4.315  loss_mask_8: 41.5  time: 2.5881  data_time: 0.4657  lr: 9.5792e-06  max_mem: 18476M
[01/23 23:35:52] d2.utils.events INFO:  eta: 1 day, 16:54:34  iter: 2819  total_loss: 494.2  loss_ce: 4.322  loss_mask: 45.75  loss_ce_0: 5.075  loss_mask_0: 47.17  loss_ce_1: 4.328  loss_mask_1: 43.46  loss_ce_2: 4.336  loss_mask_2: 44.46  loss_ce_3: 4.338  loss_mask_3: 45.01  loss_ce_4: 4.367  loss_mask_4: 44.23  loss_ce_5: 4.354  loss_mask_5: 44.08  loss_ce_6: 4.344  loss_mask_6: 45.54  loss_ce_7: 4.339  loss_mask_7: 45.41  loss_ce_8: 4.343  loss_mask_8: 46.43  time: 2.5882  data_time: 0.4429  lr: 9.5761e-06  max_mem: 18476M
[01/23 23:36:42] d2.utils.events INFO:  eta: 1 day, 16:54:16  iter: 2839  total_loss: 447.6  loss_ce: 4.301  loss_mask: 41.03  loss_ce_0: 5.086  loss_mask_0: 42.65  loss_ce_1: 4.302  loss_mask_1: 38.78  loss_ce_2: 4.3  loss_mask_2: 39.43  loss_ce_3: 4.309  loss_mask_3: 40.73  loss_ce_4: 4.332  loss_mask_4: 39.53  loss_ce_5: 4.315  loss_mask_5: 39.53  loss_ce_6: 4.308  loss_mask_6: 40.41  loss_ce_7: 4.328  loss_mask_7: 40.73  loss_ce_8: 4.325  loss_mask_8: 40.96  time: 2.5876  data_time: 0.4518  lr: 9.5731e-06  max_mem: 18476M
[01/23 23:37:37] d2.utils.events INFO:  eta: 1 day, 16:53:25  iter: 2859  total_loss: 456.8  loss_ce: 4.311  loss_mask: 41.38  loss_ce_0: 5.082  loss_mask_0: 43.74  loss_ce_1: 4.29  loss_mask_1: 40.52  loss_ce_2: 4.289  loss_mask_2: 40.73  loss_ce_3: 4.288  loss_mask_3: 41.56  loss_ce_4: 4.32  loss_mask_4: 40.93  loss_ce_5: 4.293  loss_mask_5: 40.13  loss_ce_6: 4.302  loss_mask_6: 42.01  loss_ce_7: 4.325  loss_mask_7: 42.21  loss_ce_8: 4.322  loss_mask_8: 41.81  time: 2.5888  data_time: 0.4931  lr: 9.5701e-06  max_mem: 18476M
[01/23 23:38:28] d2.utils.events INFO:  eta: 1 day, 16:53:48  iter: 2879  total_loss: 513.1  loss_ce: 4.344  loss_mask: 47.47  loss_ce_0: 5.064  loss_mask_0: 48.42  loss_ce_1: 4.34  loss_mask_1: 45.57  loss_ce_2: 4.345  loss_mask_2: 46.03  loss_ce_3: 4.339  loss_mask_3: 47.05  loss_ce_4: 4.377  loss_mask_4: 45.85  loss_ce_5: 4.357  loss_mask_5: 45.87  loss_ce_6: 4.347  loss_mask_6: 47.6  loss_ce_7: 4.389  loss_mask_7: 47.2  loss_ce_8: 4.381  loss_mask_8: 47.8  time: 2.5884  data_time: 0.4117  lr: 9.5671e-06  max_mem: 18476M
[01/23 23:39:22] d2.utils.events INFO:  eta: 1 day, 16:55:57  iter: 2899  total_loss: 481.8  loss_ce: 4.303  loss_mask: 43.67  loss_ce_0: 5.068  loss_mask_0: 45.24  loss_ce_1: 4.298  loss_mask_1: 41.92  loss_ce_2: 4.299  loss_mask_2: 42.95  loss_ce_3: 4.294  loss_mask_3: 44.31  loss_ce_4: 4.336  loss_mask_4: 43.33  loss_ce_5: 4.314  loss_mask_5: 44.02  loss_ce_6: 4.316  loss_mask_6: 43.94  loss_ce_7: 4.34  loss_mask_7: 45.68  loss_ce_8: 4.332  loss_mask_8: 43.67  time: 2.5891  data_time: 0.4587  lr: 9.5641e-06  max_mem: 18476M
[01/23 23:40:16] d2.utils.events INFO:  eta: 1 day, 16:54:33  iter: 2919  total_loss: 449.4  loss_ce: 4.323  loss_mask: 40.78  loss_ce_0: 5.07  loss_mask_0: 42.23  loss_ce_1: 4.296  loss_mask_1: 40.24  loss_ce_2: 4.308  loss_mask_2: 39.77  loss_ce_3: 4.309  loss_mask_3: 40.4  loss_ce_4: 4.347  loss_mask_4: 40.01  loss_ce_5: 4.326  loss_mask_5: 39.83  loss_ce_6: 4.333  loss_mask_6: 40.41  loss_ce_7: 4.364  loss_mask_7: 41.44  loss_ce_8: 4.351  loss_mask_8: 40.58  time: 2.5898  data_time: 0.4403  lr: 9.5611e-06  max_mem: 18476M
[01/23 23:41:06] d2.utils.events INFO:  eta: 1 day, 16:51:59  iter: 2939  total_loss: 453.3  loss_ce: 4.34  loss_mask: 41.52  loss_ce_0: 5.068  loss_mask_0: 42.3  loss_ce_1: 4.305  loss_mask_1: 39.85  loss_ce_2: 4.316  loss_mask_2: 40.3  loss_ce_3: 4.331  loss_mask_3: 40.63  loss_ce_4: 4.372  loss_mask_4: 40.49  loss_ce_5: 4.346  loss_mask_5: 40.63  loss_ce_6: 4.356  loss_mask_6: 41.02  loss_ce_7: 4.375  loss_mask_7: 41.6  loss_ce_8: 4.348  loss_mask_8: 41.84  time: 2.5893  data_time: 0.4316  lr: 9.5581e-06  max_mem: 18476M
[01/23 23:42:02] d2.utils.events INFO:  eta: 1 day, 16:52:50  iter: 2959  total_loss: 464.2  loss_ce: 4.334  loss_mask: 42.7  loss_ce_0: 5.067  loss_mask_0: 44.02  loss_ce_1: 4.306  loss_mask_1: 40.87  loss_ce_2: 4.306  loss_mask_2: 40.81  loss_ce_3: 4.325  loss_mask_3: 42.2  loss_ce_4: 4.351  loss_mask_4: 41.13  loss_ce_5: 4.335  loss_mask_5: 40.91  loss_ce_6: 4.335  loss_mask_6: 42.74  loss_ce_7: 4.36  loss_mask_7: 42.7  loss_ce_8: 4.331  loss_mask_8: 42.41  time: 2.5907  data_time: 0.4966  lr: 9.555e-06  max_mem: 18476M
[01/23 23:42:51] d2.utils.events INFO:  eta: 1 day, 16:49:46  iter: 2979  total_loss: 468.6  loss_ce: 4.259  loss_mask: 43.06  loss_ce_0: 5.091  loss_mask_0: 44.48  loss_ce_1: 4.261  loss_mask_1: 41.37  loss_ce_2: 4.261  loss_mask_2: 42.49  loss_ce_3: 4.268  loss_mask_3: 42.28  loss_ce_4: 4.325  loss_mask_4: 41.94  loss_ce_5: 4.295  loss_mask_5: 41.64  loss_ce_6: 4.303  loss_mask_6: 42.76  loss_ce_7: 4.327  loss_mask_7: 43.24  loss_ce_8: 4.277  loss_mask_8: 43.8  time: 2.5898  data_time: 0.3892  lr: 9.552e-06  max_mem: 18476M
[01/23 23:43:42] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/23 23:43:43] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/23 23:43:43] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/23 23:47:26] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 25.617051408340192, 'error_1pix': 0.9633212936006703, 'error_3pix': 0.9135640801371847, 'mIoU': 0.015074778233844666, 'fwIoU': 0.03581462506454093, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.5904387931833182, 'IoU-17': 0.0, 'IoU-18': 0.017092957791200483, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.013595255719228615, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.00016738016076430493, 'IoU-26': 0.010003201683629618, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0011152155111608063, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 0.02828048601860541, 'IoU-37': 0.0, 'IoU-38': 0.006764297460150768, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 1.368583279050242, 'IoU-43': 0.02589006542319051, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.7306324346804177, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.042347687915264685, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0005915235147330995, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.049206666895192014, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.009635368561596963, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 1.2807329480974006e-05, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5250073790795322, 'pACC': 1.191614685865823, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.9525229727273684, 'ACC-17': 0.0, 'ACC-18': 0.017609966405258158, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.01372250559697508, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.00016779886881810712, 'ACC-26': 0.010153773872506126, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0011154458881479528, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 0.04308792325855626, 'ACC-37': 0.0, 'ACC-38': 0.006862165587963739, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 76.93314793747462, 'ACC-43': 0.026453459405098616, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 22.671798572204853, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.060227496378835094, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0005999241569565784, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.054128883802702824, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.009805144729389691, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 1.2812912135326903e-05, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/23 23:47:26] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/23 23:47:26] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/23 23:47:26] d2.evaluation.testing INFO: copypaste: 25.6171,0.9633,0.9136,0.0151,0.0358,0.5250,1.1916
[01/23 23:47:26] d2.utils.events INFO:  eta: 1 day, 16:49:04  iter: 2999  total_loss: 455  loss_ce: 4.308  loss_mask: 41.76  loss_ce_0: 5.074  loss_mask_0: 42.48  loss_ce_1: 4.281  loss_mask_1: 40.71  loss_ce_2: 4.288  loss_mask_2: 40.12  loss_ce_3: 4.302  loss_mask_3: 40.93  loss_ce_4: 4.351  loss_mask_4: 40.69  loss_ce_5: 4.306  loss_mask_5: 41.54  loss_ce_6: 4.316  loss_mask_6: 41.93  loss_ce_7: 4.351  loss_mask_7: 42.45  loss_ce_8: 4.316  loss_mask_8: 41.89  time: 2.5894  data_time: 0.4124  lr: 9.549e-06  max_mem: 18476M
[01/23 23:48:16] d2.utils.events INFO:  eta: 1 day, 16:47:14  iter: 3019  total_loss: 497.7  loss_ce: 4.308  loss_mask: 45.67  loss_ce_0: 5.081  loss_mask_0: 45.63  loss_ce_1: 4.299  loss_mask_1: 44  loss_ce_2: 4.3  loss_mask_2: 44.62  loss_ce_3: 4.305  loss_mask_3: 43.87  loss_ce_4: 4.333  loss_mask_4: 45.08  loss_ce_5: 4.305  loss_mask_5: 44.33  loss_ce_6: 4.317  loss_mask_6: 45.41  loss_ce_7: 4.358  loss_mask_7: 46.95  loss_ce_8: 4.322  loss_mask_8: 45.97  time: 2.5888  data_time: 0.4138  lr: 9.546e-06  max_mem: 18476M
[01/23 23:49:10] d2.utils.events INFO:  eta: 1 day, 16:47:21  iter: 3039  total_loss: 466.5  loss_ce: 4.293  loss_mask: 42.47  loss_ce_0: 5.071  loss_mask_0: 43.62  loss_ce_1: 4.283  loss_mask_1: 40.21  loss_ce_2: 4.276  loss_mask_2: 42.11  loss_ce_3: 4.275  loss_mask_3: 42.67  loss_ce_4: 4.305  loss_mask_4: 41.38  loss_ce_5: 4.273  loss_mask_5: 41.88  loss_ce_6: 4.306  loss_mask_6: 41.77  loss_ce_7: 4.347  loss_mask_7: 42.65  loss_ce_8: 4.304  loss_mask_8: 43.37  time: 2.5894  data_time: 0.4537  lr: 9.543e-06  max_mem: 18476M
[01/23 23:50:04] d2.utils.events INFO:  eta: 1 day, 16:44:15  iter: 3059  total_loss: 467.2  loss_ce: 4.311  loss_mask: 42.71  loss_ce_0: 5.066  loss_mask_0: 43.35  loss_ce_1: 4.282  loss_mask_1: 41.93  loss_ce_2: 4.295  loss_mask_2: 40.71  loss_ce_3: 4.3  loss_mask_3: 41.16  loss_ce_4: 4.341  loss_mask_4: 40.75  loss_ce_5: 4.293  loss_mask_5: 40.89  loss_ce_6: 4.318  loss_mask_6: 41.7  loss_ce_7: 4.368  loss_mask_7: 42.21  loss_ce_8: 4.325  loss_mask_8: 42.44  time: 2.5899  data_time: 0.4572  lr: 9.54e-06  max_mem: 18476M
[01/23 23:50:53] d2.utils.events INFO:  eta: 1 day, 16:42:39  iter: 3079  total_loss: 475.8  loss_ce: 4.297  loss_mask: 43.88  loss_ce_0: 5.078  loss_mask_0: 44.3  loss_ce_1: 4.287  loss_mask_1: 41.97  loss_ce_2: 4.292  loss_mask_2: 42.3  loss_ce_3: 4.284  loss_mask_3: 42.51  loss_ce_4: 4.312  loss_mask_4: 42.33  loss_ce_5: 4.266  loss_mask_5: 42.52  loss_ce_6: 4.306  loss_mask_6: 43.2  loss_ce_7: 4.341  loss_mask_7: 43.37  loss_ce_8: 4.309  loss_mask_8: 43.49  time: 2.5893  data_time: 0.3895  lr: 9.5369e-06  max_mem: 18476M
[01/23 23:51:47] d2.utils.events INFO:  eta: 1 day, 16:43:06  iter: 3099  total_loss: 444.4  loss_ce: 4.239  loss_mask: 40.65  loss_ce_0: 5.097  loss_mask_0: 42.26  loss_ce_1: 4.248  loss_mask_1: 39.4  loss_ce_2: 4.246  loss_mask_2: 38.9  loss_ce_3: 4.232  loss_mask_3: 39.12  loss_ce_4: 4.267  loss_mask_4: 38.5  loss_ce_5: 4.218  loss_mask_5: 39.02  loss_ce_6: 4.258  loss_mask_6: 40.09  loss_ce_7: 4.305  loss_mask_7: 40.76  loss_ce_8: 4.262  loss_mask_8: 42  time: 2.5899  data_time: 0.4631  lr: 9.5339e-06  max_mem: 18476M
[01/23 23:52:38] d2.utils.events INFO:  eta: 1 day, 16:41:40  iter: 3119  total_loss: 451.4  loss_ce: 4.326  loss_mask: 41.94  loss_ce_0: 5.08  loss_mask_0: 42.25  loss_ce_1: 4.298  loss_mask_1: 39.47  loss_ce_2: 4.305  loss_mask_2: 40.1  loss_ce_3: 4.297  loss_mask_3: 40.18  loss_ce_4: 4.315  loss_mask_4: 40  loss_ce_5: 4.286  loss_mask_5: 40.05  loss_ce_6: 4.321  loss_mask_6: 41.22  loss_ce_7: 4.357  loss_mask_7: 42.34  loss_ce_8: 4.316  loss_mask_8: 42.79  time: 2.5896  data_time: 0.4227  lr: 9.5309e-06  max_mem: 18476M
[01/23 23:53:29] d2.utils.events INFO:  eta: 1 day, 16:39:16  iter: 3139  total_loss: 457.8  loss_ce: 4.266  loss_mask: 42.51  loss_ce_0: 5.081  loss_mask_0: 43.36  loss_ce_1: 4.268  loss_mask_1: 39.92  loss_ce_2: 4.267  loss_mask_2: 41.38  loss_ce_3: 4.277  loss_mask_3: 40.18  loss_ce_4: 4.305  loss_mask_4: 39.73  loss_ce_5: 4.263  loss_mask_5: 40.41  loss_ce_6: 4.286  loss_mask_6: 40.22  loss_ce_7: 4.317  loss_mask_7: 42.11  loss_ce_8: 4.282  loss_mask_8: 43.65  time: 2.5892  data_time: 0.4187  lr: 9.5279e-06  max_mem: 18476M
[01/23 23:54:24] d2.utils.events INFO:  eta: 1 day, 16:36:32  iter: 3159  total_loss: 469.3  loss_ce: 4.296  loss_mask: 43.64  loss_ce_0: 5.078  loss_mask_0: 44.62  loss_ce_1: 4.266  loss_mask_1: 41.79  loss_ce_2: 4.29  loss_mask_2: 41.5  loss_ce_3: 4.286  loss_mask_3: 42.39  loss_ce_4: 4.316  loss_mask_4: 41.84  loss_ce_5: 4.28  loss_mask_5: 41.06  loss_ce_6: 4.31  loss_mask_6: 41.86  loss_ce_7: 4.342  loss_mask_7: 42.61  loss_ce_8: 4.302  loss_mask_8: 43.12  time: 2.5903  data_time: 0.4622  lr: 9.5249e-06  max_mem: 18476M
[01/23 23:55:16] d2.utils.events INFO:  eta: 1 day, 16:34:31  iter: 3179  total_loss: 461.1  loss_ce: 4.313  loss_mask: 42.2  loss_ce_0: 5.067  loss_mask_0: 42.21  loss_ce_1: 4.285  loss_mask_1: 41.64  loss_ce_2: 4.301  loss_mask_2: 40.74  loss_ce_3: 4.295  loss_mask_3: 40.51  loss_ce_4: 4.317  loss_mask_4: 41.85  loss_ce_5: 4.29  loss_mask_5: 40.44  loss_ce_6: 4.32  loss_mask_6: 41.56  loss_ce_7: 4.328  loss_mask_7: 41.83  loss_ce_8: 4.312  loss_mask_8: 42.6  time: 2.5902  data_time: 0.4112  lr: 9.5219e-06  max_mem: 18476M
[01/23 23:56:09] d2.utils.events INFO:  eta: 1 day, 16:35:59  iter: 3199  total_loss: 469.4  loss_ce: 4.29  loss_mask: 43.48  loss_ce_0: 5.088  loss_mask_0: 43.72  loss_ce_1: 4.268  loss_mask_1: 42.33  loss_ce_2: 4.283  loss_mask_2: 41.54  loss_ce_3: 4.284  loss_mask_3: 41.86  loss_ce_4: 4.316  loss_mask_4: 41.39  loss_ce_5: 4.29  loss_mask_5: 41.86  loss_ce_6: 4.312  loss_mask_6: 42.41  loss_ce_7: 4.326  loss_mask_7: 42.81  loss_ce_8: 4.298  loss_mask_8: 44.46  time: 2.5906  data_time: 0.4635  lr: 9.5188e-06  max_mem: 18476M
[01/23 23:57:00] d2.utils.events INFO:  eta: 1 day, 16:31:43  iter: 3219  total_loss: 458.1  loss_ce: 4.283  loss_mask: 41.9  loss_ce_0: 5.077  loss_mask_0: 42.55  loss_ce_1: 4.292  loss_mask_1: 40.08  loss_ce_2: 4.297  loss_mask_2: 40.72  loss_ce_3: 4.285  loss_mask_3: 40.5  loss_ce_4: 4.307  loss_mask_4: 41.11  loss_ce_5: 4.28  loss_mask_5: 40.68  loss_ce_6: 4.314  loss_mask_6: 42.02  loss_ce_7: 4.332  loss_mask_7: 41.46  loss_ce_8: 4.298  loss_mask_8: 42.45  time: 2.5906  data_time: 0.4519  lr: 9.5158e-06  max_mem: 18476M
[01/23 23:57:50] d2.utils.events INFO:  eta: 1 day, 16:28:32  iter: 3239  total_loss: 448  loss_ce: 4.25  loss_mask: 41.07  loss_ce_0: 5.07  loss_mask_0: 41.76  loss_ce_1: 4.261  loss_mask_1: 39.59  loss_ce_2: 4.255  loss_mask_2: 40.01  loss_ce_3: 4.248  loss_mask_3: 40  loss_ce_4: 4.272  loss_mask_4: 39.85  loss_ce_5: 4.234  loss_mask_5: 39.46  loss_ce_6: 4.268  loss_mask_6: 39.65  loss_ce_7: 4.289  loss_mask_7: 40.52  loss_ce_8: 4.267  loss_mask_8: 40.61  time: 2.5899  data_time: 0.4041  lr: 9.5128e-06  max_mem: 18476M
[01/23 23:58:46] d2.utils.events INFO:  eta: 1 day, 16:32:58  iter: 3259  total_loss: 469.7  loss_ce: 4.321  loss_mask: 42.92  loss_ce_0: 5.079  loss_mask_0: 44.06  loss_ce_1: 4.291  loss_mask_1: 40.82  loss_ce_2: 4.306  loss_mask_2: 41.6  loss_ce_3: 4.292  loss_mask_3: 41.84  loss_ce_4: 4.315  loss_mask_4: 42.04  loss_ce_5: 4.274  loss_mask_5: 41.2  loss_ce_6: 4.288  loss_mask_6: 42.53  loss_ce_7: 4.345  loss_mask_7: 44.04  loss_ce_8: 4.326  loss_mask_8: 43.83  time: 2.5910  data_time: 0.4833  lr: 9.5098e-06  max_mem: 18476M
[01/23 23:59:36] d2.utils.events INFO:  eta: 1 day, 16:33:15  iter: 3279  total_loss: 465.1  loss_ce: 4.266  loss_mask: 42.83  loss_ce_0: 5.08  loss_mask_0: 43.72  loss_ce_1: 4.251  loss_mask_1: 40.85  loss_ce_2: 4.259  loss_mask_2: 40.71  loss_ce_3: 4.242  loss_mask_3: 40.15  loss_ce_4: 4.27  loss_mask_4: 41.11  loss_ce_5: 4.228  loss_mask_5: 41.92  loss_ce_6: 4.244  loss_mask_6: 42.39  loss_ce_7: 4.292  loss_mask_7: 42.79  loss_ce_8: 4.273  loss_mask_8: 43.26  time: 2.5907  data_time: 0.4090  lr: 9.5068e-06  max_mem: 18476M
[01/24 00:00:27] d2.utils.events INFO:  eta: 1 day, 16:31:41  iter: 3299  total_loss: 446  loss_ce: 4.225  loss_mask: 40.83  loss_ce_0: 5.091  loss_mask_0: 41.38  loss_ce_1: 4.244  loss_mask_1: 39.48  loss_ce_2: 4.251  loss_mask_2: 39.66  loss_ce_3: 4.231  loss_mask_3: 39.15  loss_ce_4: 4.265  loss_mask_4: 39.26  loss_ce_5: 4.218  loss_mask_5: 39.46  loss_ce_6: 4.243  loss_mask_6: 39.84  loss_ce_7: 4.278  loss_mask_7: 40.85  loss_ce_8: 4.248  loss_mask_8: 42.2  time: 2.5903  data_time: 0.4363  lr: 9.5038e-06  max_mem: 18476M
[01/24 00:01:22] d2.utils.events INFO:  eta: 1 day, 16:35:32  iter: 3319  total_loss: 447.2  loss_ce: 4.27  loss_mask: 41.14  loss_ce_0: 5.068  loss_mask_0: 41.67  loss_ce_1: 4.247  loss_mask_1: 39.99  loss_ce_2: 4.253  loss_mask_2: 39.96  loss_ce_3: 4.252  loss_mask_3: 39.54  loss_ce_4: 4.269  loss_mask_4: 39.5  loss_ce_5: 4.241  loss_mask_5: 39.96  loss_ce_6: 4.269  loss_mask_6: 40.45  loss_ce_7: 4.297  loss_mask_7: 40.81  loss_ce_8: 4.28  loss_mask_8: 42.01  time: 2.5914  data_time: 0.4736  lr: 9.5007e-06  max_mem: 18476M
[01/24 00:02:13] d2.utils.events INFO:  eta: 1 day, 16:34:28  iter: 3339  total_loss: 439.3  loss_ce: 4.226  loss_mask: 40.61  loss_ce_0: 5.07  loss_mask_0: 40.23  loss_ce_1: 4.228  loss_mask_1: 38.36  loss_ce_2: 4.233  loss_mask_2: 39.28  loss_ce_3: 4.232  loss_mask_3: 38.41  loss_ce_4: 4.267  loss_mask_4: 38.97  loss_ce_5: 4.247  loss_mask_5: 38.44  loss_ce_6: 4.277  loss_mask_6: 38.51  loss_ce_7: 4.282  loss_mask_7: 40.04  loss_ce_8: 4.251  loss_mask_8: 41.5  time: 2.5911  data_time: 0.4251  lr: 9.4977e-06  max_mem: 18476M
[01/24 00:03:08] d2.utils.events INFO:  eta: 1 day, 16:38:03  iter: 3359  total_loss: 449.5  loss_ce: 4.28  loss_mask: 41.35  loss_ce_0: 5.061  loss_mask_0: 41.73  loss_ce_1: 4.27  loss_mask_1: 39.27  loss_ce_2: 4.283  loss_mask_2: 40.11  loss_ce_3: 4.28  loss_mask_3: 39.98  loss_ce_4: 4.319  loss_mask_4: 40.08  loss_ce_5: 4.286  loss_mask_5: 39.94  loss_ce_6: 4.309  loss_mask_6: 40.37  loss_ce_7: 4.315  loss_mask_7: 41.75  loss_ce_8: 4.297  loss_mask_8: 41.43  time: 2.5920  data_time: 0.4613  lr: 9.4947e-06  max_mem: 18476M
[01/24 00:03:59] d2.utils.events INFO:  eta: 1 day, 16:39:29  iter: 3379  total_loss: 450.4  loss_ce: 4.217  loss_mask: 42.02  loss_ce_0: 5.077  loss_mask_0: 41.31  loss_ce_1: 4.236  loss_mask_1: 40.59  loss_ce_2: 4.241  loss_mask_2: 39.72  loss_ce_3: 4.224  loss_mask_3: 40.11  loss_ce_4: 4.254  loss_mask_4: 39.91  loss_ce_5: 4.226  loss_mask_5: 40.69  loss_ce_6: 4.268  loss_mask_6: 41.83  loss_ce_7: 4.26  loss_mask_7: 41.5  loss_ce_8: 4.251  loss_mask_8: 41.44  time: 2.5919  data_time: 0.4172  lr: 9.4917e-06  max_mem: 18476M
[01/24 00:04:49] d2.utils.events INFO:  eta: 1 day, 16:36:12  iter: 3399  total_loss: 452.3  loss_ce: 4.239  loss_mask: 42.16  loss_ce_0: 5.087  loss_mask_0: 42.3  loss_ce_1: 4.246  loss_mask_1: 40.01  loss_ce_2: 4.257  loss_mask_2: 39.6  loss_ce_3: 4.245  loss_mask_3: 39.84  loss_ce_4: 4.293  loss_mask_4: 40.68  loss_ce_5: 4.256  loss_mask_5: 40.25  loss_ce_6: 4.314  loss_mask_6: 40.73  loss_ce_7: 4.308  loss_mask_7: 41.22  loss_ce_8: 4.267  loss_mask_8: 41.56  time: 2.5912  data_time: 0.4177  lr: 9.4887e-06  max_mem: 18476M
[01/24 00:05:45] d2.utils.events INFO:  eta: 1 day, 16:37:46  iter: 3419  total_loss: 450.4  loss_ce: 4.253  loss_mask: 41.49  loss_ce_0: 5.07  loss_mask_0: 41.9  loss_ce_1: 4.272  loss_mask_1: 39.55  loss_ce_2: 4.272  loss_mask_2: 39.71  loss_ce_3: 4.256  loss_mask_3: 39.07  loss_ce_4: 4.266  loss_mask_4: 40.06  loss_ce_5: 4.251  loss_mask_5: 39.91  loss_ce_6: 4.295  loss_mask_6: 40.63  loss_ce_7: 4.286  loss_mask_7: 41.27  loss_ce_8: 4.286  loss_mask_8: 41.85  time: 2.5925  data_time: 0.4765  lr: 9.4857e-06  max_mem: 18476M
[01/24 00:06:36] d2.utils.events INFO:  eta: 1 day, 16:30:53  iter: 3439  total_loss: 433.1  loss_ce: 4.224  loss_mask: 39.32  loss_ce_0: 5.075  loss_mask_0: 39.93  loss_ce_1: 4.244  loss_mask_1: 38.77  loss_ce_2: 4.258  loss_mask_2: 38.19  loss_ce_3: 4.24  loss_mask_3: 38.46  loss_ce_4: 4.261  loss_mask_4: 38.16  loss_ce_5: 4.247  loss_mask_5: 38.67  loss_ce_6: 4.282  loss_mask_6: 38.87  loss_ce_7: 4.293  loss_mask_7: 39.72  loss_ce_8: 4.257  loss_mask_8: 40.4  time: 2.5922  data_time: 0.3969  lr: 9.4826e-06  max_mem: 18476M
[01/24 00:07:29] d2.utils.events INFO:  eta: 1 day, 16:29:19  iter: 3459  total_loss: 445  loss_ce: 4.272  loss_mask: 41.18  loss_ce_0: 5.076  loss_mask_0: 41.41  loss_ce_1: 4.253  loss_mask_1: 39.14  loss_ce_2: 4.27  loss_mask_2: 38.97  loss_ce_3: 4.266  loss_mask_3: 39  loss_ce_4: 4.276  loss_mask_4: 39.92  loss_ce_5: 4.263  loss_mask_5: 39.37  loss_ce_6: 4.315  loss_mask_6: 40.66  loss_ce_7: 4.308  loss_mask_7: 40.91  loss_ce_8: 4.292  loss_mask_8: 42.44  time: 2.5923  data_time: 0.4376  lr: 9.4796e-06  max_mem: 18476M
[01/24 00:08:23] d2.utils.events INFO:  eta: 1 day, 16:33:01  iter: 3479  total_loss: 471.3  loss_ce: 4.257  loss_mask: 43.28  loss_ce_0: 5.081  loss_mask_0: 43.93  loss_ce_1: 4.247  loss_mask_1: 42.6  loss_ce_2: 4.255  loss_mask_2: 41.69  loss_ce_3: 4.257  loss_mask_3: 42.05  loss_ce_4: 4.275  loss_mask_4: 42.1  loss_ce_5: 4.26  loss_mask_5: 42.26  loss_ce_6: 4.296  loss_mask_6: 42.35  loss_ce_7: 4.304  loss_mask_7: 43.31  loss_ce_8: 4.278  loss_mask_8: 43.24  time: 2.5930  data_time: 0.4378  lr: 9.4766e-06  max_mem: 18476M
[01/24 00:09:13] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 00:09:14] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 00:09:14] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 00:12:50] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 22.908049824019425, 'error_1pix': 0.9517923595417821, 'error_3pix': 0.8865898421722967, 'mIoU': 0.06390594938626534, 'fwIoU': 0.15269729093751644, 'IoU-0': nan, 'IoU-1': 5.638116764218519e-06, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0024252335441664148, 'IoU-13': 0.0, 'IoU-14': 0.08312325545827232, 'IoU-15': 0.20450291455831665, 'IoU-16': 0.9893604223568107, 'IoU-17': 0.0, 'IoU-18': 0.006126208947344421, 'IoU-19': 0.03940204009226519, 'IoU-20': 0.0, 'IoU-21': 0.108189465654097, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.3631299339993748, 'IoU-28': 0.006378907325415121, 'IoU-29': 1.7775224996144854, 'IoU-30': 0.17521215558103082, 'IoU-31': 1.0009309503606405, 'IoU-32': 0.0, 'IoU-33': 0.01806856099436994, 'IoU-34': 1.5635954887415704, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0031514819115993653, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.008133379915909079, 'IoU-42': 1.8731474233238807, 'IoU-43': 0.041868601879685406, 'IoU-44': 0.44764037227127657, 'IoU-45': 0.0, 'IoU-46': 0.0013855848765507604, 'IoU-47': 0.025761637823983937, 'IoU-48': 0.0, 'IoU-49': 0.022073276763407843, 'IoU-50': 0.7133886205531237, 'IoU-51': 0.11711345923596879, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.014944169633597496, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0043459553227938675, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.001729479171071391, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.8596851672563663, 'IoU-72': 0.1120688678833168, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.04099664244481266, 'IoU-80': 0.02916851345789388, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.05637666777564317, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 1.3246125746104853, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.18889932042429552, 'IoU-91': 0.022585420354836253, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.02289198992752443, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.6374935443337914, 'pACC': 1.5875183017173957, 'ACC-0': nan, 'ACC-1': 5.638118647068202e-06, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.002487734997080432, 'ACC-13': 0.0, 'ACC-14': 0.11362539118140047, 'ACC-15': 0.23734748539228023, 'ACC-16': 7.201624398002934, 'ACC-17': 0.0, 'ACC-18': 0.006187366162389858, 'ACC-19': 0.0457948139565274, 'ACC-20': 0.0, 'ACC-21': 0.11251355723863457, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.423715026755503, 'ACC-28': 0.00638633628366123, 'ACC-29': 28.004983355926704, 'ACC-30': 0.21181715950009541, 'ACC-31': 4.459699442459319, 'ACC-32': 0.0, 'ACC-33': 0.01883296570534941, 'ACC-34': 18.744522833391848, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.003201492407245643, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.008502425561535094, 'ACC-42': 39.188408453052844, 'ACC-43': 0.04342648827195379, 'ACC-44': 0.8326268281896125, 'ACC-45': 0.0, 'ACC-46': 0.0013868284221637405, 'ACC-47': 0.02678703679524118, 'ACC-48': 0.0, 'ACC-49': 0.022764891923743695, 'ACC-50': 3.32475404399399, 'ACC-51': 0.1246877276305189, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.020018630403772757, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.004599271818903949, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.001831376010060826, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 12.964898420922353, 'ACC-72': 0.1619898311457022, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.04512073946777131, 'ACC-80': 0.03139364680610282, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.06131276085608151, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 5.235472829794585, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.6436269881466753, 'ACC-91': 0.023568467350188506, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.038837828044515355, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 00:12:50] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 00:12:50] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 00:12:50] d2.evaluation.testing INFO: copypaste: 22.9080,0.9518,0.8866,0.0639,0.1527,0.6375,1.5875
[01/24 00:12:50] d2.utils.events INFO:  eta: 1 day, 16:26:08  iter: 3499  total_loss: 429.4  loss_ce: 4.228  loss_mask: 39.86  loss_ce_0: 5.086  loss_mask_0: 40.27  loss_ce_1: 4.219  loss_mask_1: 38.02  loss_ce_2: 4.244  loss_mask_2: 37.68  loss_ce_3: 4.24  loss_mask_3: 37.5  loss_ce_4: 4.258  loss_mask_4: 37.52  loss_ce_5: 4.247  loss_mask_5: 38.31  loss_ce_6: 4.293  loss_mask_6: 38  loss_ce_7: 4.273  loss_mask_7: 38.9  loss_ce_8: 4.255  loss_mask_8: 40.75  time: 2.5926  data_time: 0.4072  lr: 9.4736e-06  max_mem: 18476M
[01/24 00:13:40] d2.utils.events INFO:  eta: 1 day, 16:23:46  iter: 3519  total_loss: 436.9  loss_ce: 4.286  loss_mask: 39.43  loss_ce_0: 5.065  loss_mask_0: 39.33  loss_ce_1: 4.28  loss_mask_1: 38.64  loss_ce_2: 4.291  loss_mask_2: 38.19  loss_ce_3: 4.284  loss_mask_3: 38.13  loss_ce_4: 4.304  loss_mask_4: 38.13  loss_ce_5: 4.282  loss_mask_5: 39.21  loss_ce_6: 4.327  loss_mask_6: 39.07  loss_ce_7: 4.32  loss_mask_7: 39.57  loss_ce_8: 4.313  loss_mask_8: 40.26  time: 2.5920  data_time: 0.4029  lr: 9.4706e-06  max_mem: 18476M
[01/24 00:14:30] d2.utils.events INFO:  eta: 1 day, 16:18:10  iter: 3539  total_loss: 464  loss_ce: 4.282  loss_mask: 42.27  loss_ce_0: 5.068  loss_mask_0: 41.84  loss_ce_1: 4.287  loss_mask_1: 41.75  loss_ce_2: 4.298  loss_mask_2: 41.52  loss_ce_3: 4.291  loss_mask_3: 40.84  loss_ce_4: 4.315  loss_mask_4: 41.47  loss_ce_5: 4.303  loss_mask_5: 41.56  loss_ce_6: 4.332  loss_mask_6: 41.35  loss_ce_7: 4.331  loss_mask_7: 42.14  loss_ce_8: 4.323  loss_mask_8: 43.28  time: 2.5914  data_time: 0.4128  lr: 9.4675e-06  max_mem: 18476M
[01/24 00:15:18] d2.utils.events INFO:  eta: 1 day, 16:16:49  iter: 3559  total_loss: 432.6  loss_ce: 4.207  loss_mask: 39.32  loss_ce_0: 5.103  loss_mask_0: 39.3  loss_ce_1: 4.236  loss_mask_1: 37.77  loss_ce_2: 4.236  loss_mask_2: 38.02  loss_ce_3: 4.224  loss_mask_3: 38.61  loss_ce_4: 4.237  loss_mask_4: 38.53  loss_ce_5: 4.234  loss_mask_5: 38.63  loss_ce_6: 4.261  loss_mask_6: 39.49  loss_ce_7: 4.261  loss_mask_7: 40.05  loss_ce_8: 4.246  loss_mask_8: 40.12  time: 2.5903  data_time: 0.4029  lr: 9.4645e-06  max_mem: 18476M
[01/24 00:16:08] d2.utils.events INFO:  eta: 1 day, 16:13:52  iter: 3579  total_loss: 457.3  loss_ce: 4.27  loss_mask: 42.1  loss_ce_0: 5.082  loss_mask_0: 41.69  loss_ce_1: 4.265  loss_mask_1: 39.59  loss_ce_2: 4.271  loss_mask_2: 40.84  loss_ce_3: 4.274  loss_mask_3: 40.7  loss_ce_4: 4.299  loss_mask_4: 40.81  loss_ce_5: 4.296  loss_mask_5: 41.26  loss_ce_6: 4.324  loss_mask_6: 41.43  loss_ce_7: 4.316  loss_mask_7: 41.31  loss_ce_8: 4.308  loss_mask_8: 42.92  time: 2.5897  data_time: 0.4053  lr: 9.4615e-06  max_mem: 18476M
[01/24 00:16:56] d2.utils.events INFO:  eta: 1 day, 16:06:40  iter: 3599  total_loss: 457.2  loss_ce: 4.27  loss_mask: 41.94  loss_ce_0: 5.065  loss_mask_0: 42.02  loss_ce_1: 4.278  loss_mask_1: 40.4  loss_ce_2: 4.286  loss_mask_2: 40.13  loss_ce_3: 4.271  loss_mask_3: 40.16  loss_ce_4: 4.295  loss_mask_4: 41.42  loss_ce_5: 4.292  loss_mask_5: 40.89  loss_ce_6: 4.318  loss_mask_6: 40.33  loss_ce_7: 4.298  loss_mask_7: 41.82  loss_ce_8: 4.307  loss_mask_8: 42.39  time: 2.5888  data_time: 0.4042  lr: 9.4585e-06  max_mem: 18476M
[01/24 00:17:45] d2.utils.events INFO:  eta: 1 day, 16:05:13  iter: 3619  total_loss: 430.3  loss_ce: 4.231  loss_mask: 39.73  loss_ce_0: 5.076  loss_mask_0: 38.5  loss_ce_1: 4.265  loss_mask_1: 38.66  loss_ce_2: 4.26  loss_mask_2: 38.85  loss_ce_3: 4.244  loss_mask_3: 37.97  loss_ce_4: 4.259  loss_mask_4: 38.15  loss_ce_5: 4.248  loss_mask_5: 38.2  loss_ce_6: 4.295  loss_mask_6: 38.78  loss_ce_7: 4.289  loss_mask_7: 39.7  loss_ce_8: 4.269  loss_mask_8: 39.58  time: 2.5881  data_time: 0.4159  lr: 9.4555e-06  max_mem: 18476M
[01/24 00:18:36] d2.utils.events INFO:  eta: 1 day, 16:01:00  iter: 3639  total_loss: 426.1  loss_ce: 4.223  loss_mask: 38.76  loss_ce_0: 5.091  loss_mask_0: 38.32  loss_ce_1: 4.245  loss_mask_1: 37.07  loss_ce_2: 4.251  loss_mask_2: 37.33  loss_ce_3: 4.232  loss_mask_3: 37.68  loss_ce_4: 4.249  loss_mask_4: 38  loss_ce_5: 4.243  loss_mask_5: 38.1  loss_ce_6: 4.271  loss_mask_6: 38.21  loss_ce_7: 4.268  loss_mask_7: 38.23  loss_ce_8: 4.262  loss_mask_8: 40.27  time: 2.5877  data_time: 0.4276  lr: 9.4525e-06  max_mem: 18476M
[01/24 00:19:25] d2.utils.events INFO:  eta: 1 day, 15:59:06  iter: 3659  total_loss: 427.7  loss_ce: 4.204  loss_mask: 39.94  loss_ce_0: 5.096  loss_mask_0: 38.87  loss_ce_1: 4.232  loss_mask_1: 38.3  loss_ce_2: 4.215  loss_mask_2: 37.75  loss_ce_3: 4.194  loss_mask_3: 37.94  loss_ce_4: 4.212  loss_mask_4: 38.4  loss_ce_5: 4.223  loss_mask_5: 37.4  loss_ce_6: 4.252  loss_mask_6: 38.37  loss_ce_7: 4.247  loss_mask_7: 39.07  loss_ce_8: 4.247  loss_mask_8: 39.96  time: 2.5871  data_time: 0.3881  lr: 9.4494e-06  max_mem: 18476M
[01/24 00:20:21] d2.utils.events INFO:  eta: 1 day, 16:01:03  iter: 3679  total_loss: 456.3  loss_ce: 4.282  loss_mask: 40.85  loss_ce_0: 5.094  loss_mask_0: 42.52  loss_ce_1: 4.263  loss_mask_1: 40.66  loss_ce_2: 4.281  loss_mask_2: 40.86  loss_ce_3: 4.278  loss_mask_3: 42.3  loss_ce_4: 4.304  loss_mask_4: 40.84  loss_ce_5: 4.293  loss_mask_5: 40.43  loss_ce_6: 4.319  loss_mask_6: 41.28  loss_ce_7: 4.311  loss_mask_7: 42.62  loss_ce_8: 4.307  loss_mask_8: 41.54  time: 2.5880  data_time: 0.4849  lr: 9.4464e-06  max_mem: 18476M
[01/24 00:21:11] d2.utils.events INFO:  eta: 1 day, 15:56:28  iter: 3699  total_loss: 441.3  loss_ce: 4.234  loss_mask: 40.76  loss_ce_0: 5.066  loss_mask_0: 40.85  loss_ce_1: 4.239  loss_mask_1: 39.61  loss_ce_2: 4.239  loss_mask_2: 39.04  loss_ce_3: 4.231  loss_mask_3: 38.14  loss_ce_4: 4.244  loss_mask_4: 38.59  loss_ce_5: 4.244  loss_mask_5: 40.16  loss_ce_6: 4.26  loss_mask_6: 40.23  loss_ce_7: 4.255  loss_mask_7: 40.62  loss_ce_8: 4.268  loss_mask_8: 42.13  time: 2.5877  data_time: 0.4063  lr: 9.4434e-06  max_mem: 18476M
[01/24 00:22:03] d2.utils.events INFO:  eta: 1 day, 15:56:24  iter: 3719  total_loss: 435.1  loss_ce: 4.259  loss_mask: 39.4  loss_ce_0: 5.082  loss_mask_0: 39.8  loss_ce_1: 4.253  loss_mask_1: 38.63  loss_ce_2: 4.266  loss_mask_2: 38.71  loss_ce_3: 4.252  loss_mask_3: 37.55  loss_ce_4: 4.28  loss_mask_4: 38.17  loss_ce_5: 4.283  loss_mask_5: 39.75  loss_ce_6: 4.301  loss_mask_6: 39.42  loss_ce_7: 4.287  loss_mask_7: 40.28  loss_ce_8: 4.286  loss_mask_8: 40.34  time: 2.5876  data_time: 0.4448  lr: 9.4404e-06  max_mem: 18476M
[01/24 00:22:59] d2.utils.events INFO:  eta: 1 day, 15:56:45  iter: 3739  total_loss: 457.2  loss_ce: 4.267  loss_mask: 41.62  loss_ce_0: 5.066  loss_mask_0: 40.86  loss_ce_1: 4.27  loss_mask_1: 40.49  loss_ce_2: 4.271  loss_mask_2: 40.28  loss_ce_3: 4.259  loss_mask_3: 39.98  loss_ce_4: 4.28  loss_mask_4: 40.55  loss_ce_5: 4.29  loss_mask_5: 41.24  loss_ce_6: 4.296  loss_mask_6: 41.32  loss_ce_7: 4.277  loss_mask_7: 42.47  loss_ce_8: 4.291  loss_mask_8: 42.8  time: 2.5888  data_time: 0.4863  lr: 9.4374e-06  max_mem: 18476M
[01/24 00:23:51] d2.utils.events INFO:  eta: 1 day, 15:56:14  iter: 3759  total_loss: 434.4  loss_ce: 4.252  loss_mask: 39.56  loss_ce_0: 5.081  loss_mask_0: 38.28  loss_ce_1: 4.272  loss_mask_1: 38.06  loss_ce_2: 4.274  loss_mask_2: 38.43  loss_ce_3: 4.246  loss_mask_3: 38.25  loss_ce_4: 4.254  loss_mask_4: 37.87  loss_ce_5: 4.27  loss_mask_5: 38.82  loss_ce_6: 4.303  loss_mask_6: 39.46  loss_ce_7: 4.264  loss_mask_7: 40.3  loss_ce_8: 4.278  loss_mask_8: 39.74  time: 2.5889  data_time: 0.4541  lr: 9.4343e-06  max_mem: 18476M
[01/24 00:24:42] d2.utils.events INFO:  eta: 1 day, 15:55:23  iter: 3779  total_loss: 420.2  loss_ce: 4.25  loss_mask: 38.19  loss_ce_0: 5.075  loss_mask_0: 36.95  loss_ce_1: 4.246  loss_mask_1: 36.75  loss_ce_2: 4.256  loss_mask_2: 36.61  loss_ce_3: 4.253  loss_mask_3: 36.76  loss_ce_4: 4.273  loss_mask_4: 36.75  loss_ce_5: 4.273  loss_mask_5: 36.68  loss_ce_6: 4.283  loss_mask_6: 38.61  loss_ce_7: 4.27  loss_mask_7: 37.76  loss_ce_8: 4.272  loss_mask_8: 38.55  time: 2.5887  data_time: 0.4090  lr: 9.4313e-06  max_mem: 18476M
[01/24 00:25:35] d2.utils.events INFO:  eta: 1 day, 15:54:11  iter: 3799  total_loss: 437  loss_ce: 4.255  loss_mask: 39.61  loss_ce_0: 5.079  loss_mask_0: 39.27  loss_ce_1: 4.249  loss_mask_1: 38.32  loss_ce_2: 4.247  loss_mask_2: 37.94  loss_ce_3: 4.247  loss_mask_3: 37.69  loss_ce_4: 4.269  loss_mask_4: 38.56  loss_ce_5: 4.283  loss_mask_5: 40.03  loss_ce_6: 4.281  loss_mask_6: 39.15  loss_ce_7: 4.271  loss_mask_7: 41.25  loss_ce_8: 4.28  loss_mask_8: 40.72  time: 2.5889  data_time: 0.4423  lr: 9.4283e-06  max_mem: 18476M
[01/24 00:26:26] d2.utils.events INFO:  eta: 1 day, 15:53:06  iter: 3819  total_loss: 424  loss_ce: 4.273  loss_mask: 39.57  loss_ce_0: 5.079  loss_mask_0: 37.85  loss_ce_1: 4.262  loss_mask_1: 36.72  loss_ce_2: 4.266  loss_mask_2: 37.24  loss_ce_3: 4.267  loss_mask_3: 37.72  loss_ce_4: 4.288  loss_mask_4: 38.1  loss_ce_5: 4.305  loss_mask_5: 38.61  loss_ce_6: 4.301  loss_mask_6: 37.95  loss_ce_7: 4.296  loss_mask_7: 39.01  loss_ce_8: 4.301  loss_mask_8: 39.89  time: 2.5889  data_time: 0.4570  lr: 9.4253e-06  max_mem: 18476M
[01/24 00:27:23] d2.utils.events INFO:  eta: 1 day, 15:55:50  iter: 3839  total_loss: 464.6  loss_ce: 4.238  loss_mask: 42.08  loss_ce_0: 5.069  loss_mask_0: 42.56  loss_ce_1: 4.267  loss_mask_1: 40.98  loss_ce_2: 4.28  loss_mask_2: 42.03  loss_ce_3: 4.271  loss_mask_3: 41.75  loss_ce_4: 4.291  loss_mask_4: 42.08  loss_ce_5: 4.288  loss_mask_5: 42.53  loss_ce_6: 4.315  loss_mask_6: 43.05  loss_ce_7: 4.28  loss_mask_7: 43.63  loss_ce_8: 4.277  loss_mask_8: 42.71  time: 2.5901  data_time: 0.4878  lr: 9.4223e-06  max_mem: 18476M
[01/24 00:28:12] d2.utils.events INFO:  eta: 1 day, 15:51:03  iter: 3859  total_loss: 468.1  loss_ce: 4.205  loss_mask: 42.89  loss_ce_0: 5.093  loss_mask_0: 42.11  loss_ce_1: 4.253  loss_mask_1: 40.59  loss_ce_2: 4.25  loss_mask_2: 42.21  loss_ce_3: 4.229  loss_mask_3: 41.88  loss_ce_4: 4.255  loss_mask_4: 41.41  loss_ce_5: 4.269  loss_mask_5: 43.74  loss_ce_6: 4.272  loss_mask_6: 42.29  loss_ce_7: 4.244  loss_mask_7: 42.53  loss_ce_8: 4.25  loss_mask_8: 43.33  time: 2.5893  data_time: 0.3911  lr: 9.4192e-06  max_mem: 18476M
[01/24 00:29:01] d2.utils.events INFO:  eta: 1 day, 15:48:39  iter: 3879  total_loss: 436.7  loss_ce: 4.218  loss_mask: 39.17  loss_ce_0: 5.087  loss_mask_0: 39.83  loss_ce_1: 4.242  loss_mask_1: 39.05  loss_ce_2: 4.241  loss_mask_2: 38.43  loss_ce_3: 4.233  loss_mask_3: 39.14  loss_ce_4: 4.269  loss_mask_4: 39.46  loss_ce_5: 4.261  loss_mask_5: 40.5  loss_ce_6: 4.282  loss_mask_6: 39.92  loss_ce_7: 4.248  loss_mask_7: 40.03  loss_ce_8: 4.265  loss_mask_8: 40.74  time: 2.5888  data_time: 0.4106  lr: 9.4162e-06  max_mem: 18476M
[01/24 00:29:57] d2.utils.events INFO:  eta: 1 day, 15:49:21  iter: 3899  total_loss: 434.5  loss_ce: 4.234  loss_mask: 38.71  loss_ce_0: 5.071  loss_mask_0: 38.26  loss_ce_1: 4.259  loss_mask_1: 37.72  loss_ce_2: 4.255  loss_mask_2: 37.89  loss_ce_3: 4.252  loss_mask_3: 38.5  loss_ce_4: 4.276  loss_mask_4: 38.98  loss_ce_5: 4.272  loss_mask_5: 39.62  loss_ce_6: 4.299  loss_mask_6: 39.92  loss_ce_7: 4.277  loss_mask_7: 39.39  loss_ce_8: 4.292  loss_mask_8: 40.14  time: 2.5896  data_time: 0.4888  lr: 9.4132e-06  max_mem: 18476M
[01/24 00:30:47] d2.utils.events INFO:  eta: 1 day, 15:46:07  iter: 3919  total_loss: 427.7  loss_ce: 4.217  loss_mask: 39.31  loss_ce_0: 5.086  loss_mask_0: 37.36  loss_ce_1: 4.239  loss_mask_1: 37.82  loss_ce_2: 4.234  loss_mask_2: 38.4  loss_ce_3: 4.222  loss_mask_3: 37.84  loss_ce_4: 4.248  loss_mask_4: 38.56  loss_ce_5: 4.259  loss_mask_5: 38.11  loss_ce_6: 4.252  loss_mask_6: 38.73  loss_ce_7: 4.24  loss_mask_7: 38.62  loss_ce_8: 4.258  loss_mask_8: 38.51  time: 2.5893  data_time: 0.4262  lr: 9.4102e-06  max_mem: 18476M
[01/24 00:31:39] d2.utils.events INFO:  eta: 1 day, 15:45:16  iter: 3939  total_loss: 430.9  loss_ce: 4.226  loss_mask: 39.41  loss_ce_0: 5.075  loss_mask_0: 37.12  loss_ce_1: 4.219  loss_mask_1: 37.99  loss_ce_2: 4.214  loss_mask_2: 37.41  loss_ce_3: 4.215  loss_mask_3: 37.82  loss_ce_4: 4.254  loss_mask_4: 38.62  loss_ce_5: 4.244  loss_mask_5: 38.85  loss_ce_6: 4.252  loss_mask_6: 38.36  loss_ce_7: 4.238  loss_mask_7: 39.31  loss_ce_8: 4.261  loss_mask_8: 40.34  time: 2.5894  data_time: 0.4338  lr: 9.4072e-06  max_mem: 18476M
[01/24 00:32:32] d2.utils.events INFO:  eta: 1 day, 15:42:37  iter: 3959  total_loss: 448.8  loss_ce: 4.272  loss_mask: 41.51  loss_ce_0: 5.069  loss_mask_0: 40.37  loss_ce_1: 4.271  loss_mask_1: 40.12  loss_ce_2: 4.277  loss_mask_2: 40.47  loss_ce_3: 4.276  loss_mask_3: 40.32  loss_ce_4: 4.292  loss_mask_4: 40.52  loss_ce_5: 4.31  loss_mask_5: 40.43  loss_ce_6: 4.304  loss_mask_6: 40.01  loss_ce_7: 4.299  loss_mask_7: 41.82  loss_ce_8: 4.317  loss_mask_8: 41.16  time: 2.5896  data_time: 0.4257  lr: 9.4041e-06  max_mem: 18476M
[01/24 00:33:23] d2.utils.events INFO:  eta: 1 day, 15:44:52  iter: 3979  total_loss: 418.1  loss_ce: 4.221  loss_mask: 38.73  loss_ce_0: 5.082  loss_mask_0: 36.81  loss_ce_1: 4.227  loss_mask_1: 36.85  loss_ce_2: 4.218  loss_mask_2: 36.51  loss_ce_3: 4.217  loss_mask_3: 36.71  loss_ce_4: 4.23  loss_mask_4: 37.66  loss_ce_5: 4.25  loss_mask_5: 38.57  loss_ce_6: 4.243  loss_mask_6: 38.26  loss_ce_7: 4.25  loss_mask_7: 38.5  loss_ce_8: 4.26  loss_mask_8: 38.8  time: 2.5893  data_time: 0.4025  lr: 9.4011e-06  max_mem: 18476M
[01/24 00:34:18] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 00:34:19] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 00:34:19] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 00:37:56] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 23.559717061633485, 'error_1pix': 0.9579834984402746, 'error_3pix': 0.9012282925738002, 'mIoU': 0.04957266890946773, 'fwIoU': 0.11781718949223528, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 1.103364024511474, 'IoU-16': 0.12214768790134091, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.000594066724958063, 'IoU-20': 0.0, 'IoU-21': 0.7307633704253343, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.006381306503970995, 'IoU-29': 0.0, 'IoU-30': 0.05320719047959996, 'IoU-31': 1.4227698939874596, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.6620727139573992, 'IoU-35': 0.01999512394398136, 'IoU-36': 0.010503451528658388, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0035176333717767015, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 1.5053222384545515, 'IoU-43': 0.02433673971316299, 'IoU-44': 0.019539158046007053, 'IoU-45': 0.0, 'IoU-46': 2.8776840004510564e-05, 'IoU-47': 0.5925854297441712, 'IoU-48': 0.0006146096426239481, 'IoU-49': 0.0, 'IoU-50': 0.9917928070822056, 'IoU-51': 0.8499231120273549, 'IoU-52': 0.009033578186933093, 'IoU-53': 0.0, 'IoU-54': 0.05561600961278586, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.20577110046419017, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.1394092661976234, 'IoU-71': 0.0, 'IoU-72': 0.009797324121817786, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0005567553694415755, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.30218991063827566, 'IoU-79': 0.0, 'IoU-80': 0.002384075130990812, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.06807711936262856, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.6056579566470827, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5793533507539806, 'pACC': 1.354177753666148, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 2.147382599071331, 'ACC-16': 0.12862942424826718, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0006409943588263442, 'ACC-20': 0.0, 'ACC-21': 1.7244586053910012, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.00638633628366123, 'ACC-29': 0.0, 'ACC-30': 0.06044185709601701, 'ACC-31': 9.057793966113806, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 1.8821352909682847, 'ACC-35': 0.020529928324350577, 'ACC-36': 0.0115145925675689, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.00376813925925336, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 66.60309105986059, 'ACC-43': 0.024749603225414307, 'ACC-44': 0.02070399461258757, 'ACC-45': 0.0, 'ACC-46': 2.880652508945455e-05, 'ACC-47': 1.3303717071977508, 'ACC-48': 0.0006149366066718586, 'ACC-49': 0.0, 'ACC-50': 10.257575533522004, 'ACC-51': 15.566523718220216, 'ACC-52': 0.009521977895632432, 'ACC-53': 0.0, 'ACC-54': 0.05625180373240409, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.5620462548212698, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.14948156425811607, 'ACC-71': 0.0, 'ACC-72': 0.01110297412706346, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0005569272467373346, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.6096913043314293, 'ACC-79': 0.0, 'ACC-80': 0.002521222779778599, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.07071623556679185, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.916611986552366, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 00:37:56] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 00:37:56] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 00:37:56] d2.evaluation.testing INFO: copypaste: 23.5597,0.9580,0.9012,0.0496,0.1178,0.5794,1.3542
[01/24 00:37:56] d2.utils.events INFO:  eta: 1 day, 15:47:57  iter: 3999  total_loss: 444.8  loss_ce: 4.233  loss_mask: 40.43  loss_ce_0: 5.074  loss_mask_0: 39.97  loss_ce_1: 4.22  loss_mask_1: 38.29  loss_ce_2: 4.221  loss_mask_2: 38.99  loss_ce_3: 4.218  loss_mask_3: 39.24  loss_ce_4: 4.236  loss_mask_4: 40  loss_ce_5: 4.249  loss_mask_5: 41.17  loss_ce_6: 4.249  loss_mask_6: 41.02  loss_ce_7: 4.245  loss_mask_7: 40.96  loss_ce_8: 4.261  loss_mask_8: 40.62  time: 2.5902  data_time: 0.4886  lr: 9.3981e-06  max_mem: 18476M
[01/24 00:38:47] d2.utils.events INFO:  eta: 1 day, 15:48:14  iter: 4019  total_loss: 414  loss_ce: 4.248  loss_mask: 38.56  loss_ce_0: 5.07  loss_mask_0: 36.72  loss_ce_1: 4.221  loss_mask_1: 36.41  loss_ce_2: 4.223  loss_mask_2: 36.31  loss_ce_3: 4.235  loss_mask_3: 36.41  loss_ce_4: 4.267  loss_mask_4: 37.01  loss_ce_5: 4.266  loss_mask_5: 37.53  loss_ce_6: 4.26  loss_mask_6: 38.18  loss_ce_7: 4.281  loss_mask_7: 37.81  loss_ce_8: 4.284  loss_mask_8: 38.31  time: 2.5900  data_time: 0.4049  lr: 9.3951e-06  max_mem: 18476M
[01/24 00:39:42] d2.utils.events INFO:  eta: 1 day, 15:49:02  iter: 4039  total_loss: 421.8  loss_ce: 4.255  loss_mask: 38.44  loss_ce_0: 5.073  loss_mask_0: 36.76  loss_ce_1: 4.235  loss_mask_1: 37.68  loss_ce_2: 4.242  loss_mask_2: 36.34  loss_ce_3: 4.236  loss_mask_3: 37.04  loss_ce_4: 4.257  loss_mask_4: 37.35  loss_ce_5: 4.264  loss_mask_5: 37.42  loss_ce_6: 4.266  loss_mask_6: 37.51  loss_ce_7: 4.284  loss_mask_7: 38.19  loss_ce_8: 4.289  loss_mask_8: 38.6  time: 2.5907  data_time: 0.4648  lr: 9.3921e-06  max_mem: 18476M
[01/24 00:40:34] d2.utils.events INFO:  eta: 1 day, 15:47:52  iter: 4059  total_loss: 427.4  loss_ce: 4.298  loss_mask: 39.99  loss_ce_0: 5.058  loss_mask_0: 37.62  loss_ce_1: 4.28  loss_mask_1: 37.96  loss_ce_2: 4.277  loss_mask_2: 37.67  loss_ce_3: 4.271  loss_mask_3: 37.75  loss_ce_4: 4.289  loss_mask_4: 37.73  loss_ce_5: 4.303  loss_mask_5: 39.33  loss_ce_6: 4.298  loss_mask_6: 38.94  loss_ce_7: 4.301  loss_mask_7: 38.61  loss_ce_8: 4.306  loss_mask_8: 38.62  time: 2.5908  data_time: 0.4343  lr: 9.389e-06  max_mem: 18476M
[01/24 00:41:27] d2.utils.events INFO:  eta: 1 day, 15:49:09  iter: 4079  total_loss: 442.4  loss_ce: 4.211  loss_mask: 41.43  loss_ce_0: 5.088  loss_mask_0: 38.34  loss_ce_1: 4.213  loss_mask_1: 39.58  loss_ce_2: 4.215  loss_mask_2: 38.72  loss_ce_3: 4.212  loss_mask_3: 39.62  loss_ce_4: 4.225  loss_mask_4: 39.62  loss_ce_5: 4.24  loss_mask_5: 39.19  loss_ce_6: 4.238  loss_mask_6: 40.33  loss_ce_7: 4.225  loss_mask_7: 40.55  loss_ce_8: 4.231  loss_mask_8: 40.99  time: 2.5910  data_time: 0.4471  lr: 9.386e-06  max_mem: 18476M
[01/24 00:42:20] d2.utils.events INFO:  eta: 1 day, 15:46:29  iter: 4099  total_loss: 431.8  loss_ce: 4.255  loss_mask: 39.93  loss_ce_0: 5.075  loss_mask_0: 38.34  loss_ce_1: 4.241  loss_mask_1: 37.94  loss_ce_2: 4.256  loss_mask_2: 37.73  loss_ce_3: 4.265  loss_mask_3: 38.11  loss_ce_4: 4.281  loss_mask_4: 38.83  loss_ce_5: 4.282  loss_mask_5: 38.49  loss_ce_6: 4.313  loss_mask_6: 38.84  loss_ce_7: 4.287  loss_mask_7: 39.05  loss_ce_8: 4.282  loss_mask_8: 39.46  time: 2.5913  data_time: 0.4592  lr: 9.383e-06  max_mem: 18476M
[01/24 00:43:10] d2.utils.events INFO:  eta: 1 day, 15:43:58  iter: 4119  total_loss: 437.9  loss_ce: 4.266  loss_mask: 40.6  loss_ce_0: 5.078  loss_mask_0: 38.84  loss_ce_1: 4.237  loss_mask_1: 39.16  loss_ce_2: 4.257  loss_mask_2: 38.56  loss_ce_3: 4.255  loss_mask_3: 39.86  loss_ce_4: 4.28  loss_mask_4: 39.54  loss_ce_5: 4.258  loss_mask_5: 39.68  loss_ce_6: 4.275  loss_mask_6: 39.98  loss_ce_7: 4.27  loss_mask_7: 40.13  loss_ce_8: 4.279  loss_mask_8: 40.4  time: 2.5908  data_time: 0.4040  lr: 9.38e-06  max_mem: 18476M
[01/24 00:44:04] d2.utils.events INFO:  eta: 1 day, 15:47:39  iter: 4139  total_loss: 421.4  loss_ce: 4.256  loss_mask: 39.73  loss_ce_0: 5.08  loss_mask_0: 36.34  loss_ce_1: 4.242  loss_mask_1: 36.32  loss_ce_2: 4.243  loss_mask_2: 36.85  loss_ce_3: 4.248  loss_mask_3: 37.65  loss_ce_4: 4.265  loss_mask_4: 37.12  loss_ce_5: 4.267  loss_mask_5: 37.9  loss_ce_6: 4.283  loss_mask_6: 38.74  loss_ce_7: 4.27  loss_mask_7: 37.88  loss_ce_8: 4.278  loss_mask_8: 39.1  time: 2.5914  data_time: 0.4782  lr: 9.377e-06  max_mem: 18476M
[01/24 00:44:56] d2.utils.events INFO:  eta: 1 day, 15:44:54  iter: 4159  total_loss: 422.9  loss_ce: 4.282  loss_mask: 39.41  loss_ce_0: 5.058  loss_mask_0: 37.36  loss_ce_1: 4.253  loss_mask_1: 37.4  loss_ce_2: 4.27  loss_mask_2: 37.89  loss_ce_3: 4.272  loss_mask_3: 37.09  loss_ce_4: 4.297  loss_mask_4: 37.68  loss_ce_5: 4.287  loss_mask_5: 38.14  loss_ce_6: 4.288  loss_mask_6: 37.87  loss_ce_7: 4.291  loss_mask_7: 38.77  loss_ce_8: 4.307  loss_mask_8: 39.31  time: 2.5914  data_time: 0.4089  lr: 9.3739e-06  max_mem: 18476M
[01/24 00:45:46] d2.utils.events INFO:  eta: 1 day, 15:42:45  iter: 4179  total_loss: 447.7  loss_ce: 4.242  loss_mask: 41.55  loss_ce_0: 5.067  loss_mask_0: 39.51  loss_ce_1: 4.216  loss_mask_1: 40.42  loss_ce_2: 4.224  loss_mask_2: 39.6  loss_ce_3: 4.234  loss_mask_3: 40.38  loss_ce_4: 4.258  loss_mask_4: 39.78  loss_ce_5: 4.258  loss_mask_5: 40.31  loss_ce_6: 4.265  loss_mask_6: 40.95  loss_ce_7: 4.267  loss_mask_7: 40.47  loss_ce_8: 4.282  loss_mask_8: 41.25  time: 2.5910  data_time: 0.4325  lr: 9.3709e-06  max_mem: 18476M
[01/24 00:46:42] d2.utils.events INFO:  eta: 1 day, 15:45:05  iter: 4199  total_loss: 441.2  loss_ce: 4.229  loss_mask: 41.51  loss_ce_0: 5.075  loss_mask_0: 38.42  loss_ce_1: 4.211  loss_mask_1: 38.88  loss_ce_2: 4.223  loss_mask_2: 38.94  loss_ce_3: 4.219  loss_mask_3: 38.73  loss_ce_4: 4.24  loss_mask_4: 38.26  loss_ce_5: 4.248  loss_mask_5: 38.92  loss_ce_6: 4.242  loss_mask_6: 40.4  loss_ce_7: 4.245  loss_mask_7: 41.63  loss_ce_8: 4.264  loss_mask_8: 41.45  time: 2.5919  data_time: 0.5075  lr: 9.3679e-06  max_mem: 18476M
[01/24 00:47:33] d2.utils.events INFO:  eta: 1 day, 15:44:13  iter: 4219  total_loss: 420.4  loss_ce: 4.222  loss_mask: 39.02  loss_ce_0: 5.086  loss_mask_0: 37.47  loss_ce_1: 4.181  loss_mask_1: 37.33  loss_ce_2: 4.192  loss_mask_2: 36.81  loss_ce_3: 4.196  loss_mask_3: 36.57  loss_ce_4: 4.217  loss_mask_4: 37.15  loss_ce_5: 4.227  loss_mask_5: 37.98  loss_ce_6: 4.242  loss_mask_6: 37.43  loss_ce_7: 4.254  loss_mask_7: 38.85  loss_ce_8: 4.243  loss_mask_8: 38.79  time: 2.5917  data_time: 0.4502  lr: 9.3649e-06  max_mem: 18476M
[01/24 00:48:27] d2.utils.events INFO:  eta: 1 day, 15:46:26  iter: 4239  total_loss: 414  loss_ce: 4.259  loss_mask: 37.88  loss_ce_0: 5.073  loss_mask_0: 35.71  loss_ce_1: 4.226  loss_mask_1: 36.38  loss_ce_2: 4.244  loss_mask_2: 36.27  loss_ce_3: 4.25  loss_mask_3: 36.97  loss_ce_4: 4.273  loss_mask_4: 37.04  loss_ce_5: 4.282  loss_mask_5: 36.82  loss_ce_6: 4.288  loss_mask_6: 36.87  loss_ce_7: 4.27  loss_mask_7: 36.97  loss_ce_8: 4.276  loss_mask_8: 37.22  time: 2.5922  data_time: 0.4550  lr: 9.3618e-06  max_mem: 18476M
[01/24 00:49:20] d2.utils.events INFO:  eta: 1 day, 15:43:07  iter: 4259  total_loss: 444  loss_ce: 4.248  loss_mask: 40.79  loss_ce_0: 5.071  loss_mask_0: 38.21  loss_ce_1: 4.22  loss_mask_1: 39.59  loss_ce_2: 4.24  loss_mask_2: 39.31  loss_ce_3: 4.243  loss_mask_3: 39.01  loss_ce_4: 4.253  loss_mask_4: 39.48  loss_ce_5: 4.247  loss_mask_5: 39.34  loss_ce_6: 4.265  loss_mask_6: 40.38  loss_ce_7: 4.258  loss_mask_7: 40.43  loss_ce_8: 4.277  loss_mask_8: 40.18  time: 2.5924  data_time: 0.4625  lr: 9.3588e-06  max_mem: 18476M
[01/24 00:49:44] d2.engine.hooks INFO: Overall training speed: 4267 iterations in 3:04:22 (2.5926 s / it)
[01/24 00:49:44] d2.engine.hooks INFO: Total training time: 3:33:18 (0:28:55 on hooks)
[01/24 00:49:44] d2.utils.events INFO:  eta: 1 day, 15:41:02  iter: 4269  total_loss: 429  loss_ce: 4.243  loss_mask: 40.26  loss_ce_0: 5.073  loss_mask_0: 36.73  loss_ce_1: 4.22  loss_mask_1: 38.41  loss_ce_2: 4.238  loss_mask_2: 37.46  loss_ce_3: 4.236  loss_mask_3: 38.12  loss_ce_4: 4.247  loss_mask_4: 37.89  loss_ce_5: 4.246  loss_mask_5: 38.53  loss_ce_6: 4.259  loss_mask_6: 39.36  loss_ce_7: 4.248  loss_mask_7: 39.41  loss_ce_8: 4.257  loss_mask_8: 39.3  time: 2.5923  data_time: 0.4137  lr: 9.3575e-06  max_mem: 18476M
[01/24 00:50:07] detectron2 INFO: Rank of current process: 0. World size: 4
[01/24 00:50:10] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/24 00:50:10] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/24 00:50:10] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/24 00:50:10] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/24 00:50:10] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/config.yaml
[01/24 00:50:11] d2.utils.env INFO: Using a generated random seed 11167945
[01/24 00:50:12] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 0.5
          cost_mask: 1.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 0.5, 'loss_mask': 1.0, 'loss_ce_0': 0.5, 'loss_mask_0': 1.0, 'loss_ce_1': 0.5, 'loss_mask_1': 1.0, 'loss_ce_2': 0.5, 'loss_mask_2': 1.0, 'loss_ce_3': 0.5, 'loss_mask_3': 1.0, 'loss_ce_4': 0.5, 'loss_mask_4': 1.0, 'loss_ce_5': 0.5, 'loss_mask_5': 1.0, 'loss_ce_6': 0.5, 'loss_mask_6': 1.0, 'loss_ce_7': 0.5, 'loss_mask_7': 1.0, 'loss_ce_8': 0.5, 'loss_mask_8': 1.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/24 00:50:12] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/24 00:50:16] d2.data.build INFO: Using training sampler TrainingSampler
[01/24 00:50:17] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/24 00:50:17] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/24 00:50:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/24 00:50:18] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/24 00:50:18] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/24 00:50:18] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/24 00:50:18] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/24 00:50:18] d2.engine.train_loop INFO: Starting training from iteration 0
[01/24 00:51:34] d2.utils.events INFO:  eta: 1 day, 18:19:06  iter: 19  total_loss: 284.3  loss_ce: 2.762  loss_mask: 26.25  loss_ce_0: 2.375  loss_mask_0: 24.64  loss_ce_1: 2.533  loss_mask_1: 25.23  loss_ce_2: 2.635  loss_mask_2: 25.41  loss_ce_3: 2.739  loss_mask_3: 25.7  loss_ce_4: 2.717  loss_mask_4: 25.92  loss_ce_5: 2.793  loss_mask_5: 26.1  loss_ce_6: 2.724  loss_mask_6: 26.18  loss_ce_7: 2.781  loss_mask_7: 26.2  loss_ce_8: 2.756  loss_mask_8: 26.24  time: 2.5812  data_time: 0.7671  lr: 2.8802e-06  max_mem: 18229M
[01/24 00:52:22] d2.utils.events INFO:  eta: 1 day, 16:48:32  iter: 39  total_loss: 283.4  loss_ce: 2.578  loss_mask: 26.52  loss_ce_0: 2.399  loss_mask_0: 24.09  loss_ce_1: 2.511  loss_mask_1: 24.74  loss_ce_2: 2.573  loss_mask_2: 24.83  loss_ce_3: 2.645  loss_mask_3: 25.42  loss_ce_4: 2.601  loss_mask_4: 25.9  loss_ce_5: 2.659  loss_mask_5: 26.24  loss_ce_6: 2.575  loss_mask_6: 26.42  loss_ce_7: 2.617  loss_mask_7: 26.44  loss_ce_8: 2.581  loss_mask_8: 26.5  time: 2.4999  data_time: 0.3655  lr: 4.8582e-06  max_mem: 18229M
[01/24 00:53:11] d2.utils.events INFO:  eta: 1 day, 16:51:50  iter: 59  total_loss: 256.3  loss_ce: 2.438  loss_mask: 25.42  loss_ce_0: 2.424  loss_mask_0: 21.31  loss_ce_1: 2.488  loss_mask_1: 21.87  loss_ce_2: 2.522  loss_mask_2: 20.54  loss_ce_3: 2.58  loss_mask_3: 21.09  loss_ce_4: 2.525  loss_mask_4: 22.52  loss_ce_5: 2.54  loss_mask_5: 23.34  loss_ce_6: 2.463  loss_mask_6: 24.65  loss_ce_7: 2.513  loss_mask_7: 24.58  loss_ce_8: 2.459  loss_mask_8: 24.94  time: 2.4881  data_time: 0.4407  lr: 6.8349e-06  max_mem: 18229M
[01/24 00:53:56] d2.utils.events INFO:  eta: 1 day, 16:04:08  iter: 79  total_loss: 209.1  loss_ce: 2.418  loss_mask: 20.6  loss_ce_0: 2.428  loss_mask_0: 18.3  loss_ce_1: 2.463  loss_mask_1: 17.77  loss_ce_2: 2.506  loss_mask_2: 17.13  loss_ce_3: 2.516  loss_mask_3: 17.38  loss_ce_4: 2.455  loss_mask_4: 17.6  loss_ce_5: 2.45  loss_mask_5: 18.29  loss_ce_6: 2.419  loss_mask_6: 18.55  loss_ce_7: 2.482  loss_mask_7: 18.79  loss_ce_8: 2.461  loss_mask_8: 19.43  time: 2.4187  data_time: 0.4011  lr: 8.8105e-06  max_mem: 18229M
[01/24 00:54:42] d2.utils.events INFO:  eta: 1 day, 15:40:41  iter: 99  total_loss: 204.2  loss_ce: 2.378  loss_mask: 19.71  loss_ce_0: 2.438  loss_mask_0: 17.96  loss_ce_1: 2.455  loss_mask_1: 17.25  loss_ce_2: 2.469  loss_mask_2: 16.99  loss_ce_3: 2.482  loss_mask_3: 17.41  loss_ce_4: 2.408  loss_mask_4: 17.58  loss_ce_5: 2.375  loss_mask_5: 18.07  loss_ce_6: 2.333  loss_mask_6: 17.98  loss_ce_7: 2.352  loss_mask_7: 18.6  loss_ce_8: 2.351  loss_mask_8: 19.08  time: 2.3932  data_time: 0.3825  lr: 1.0785e-05  max_mem: 18229M
[01/24 00:55:34] d2.utils.events INFO:  eta: 1 day, 15:55:15  iter: 119  total_loss: 193.2  loss_ce: 2.317  loss_mask: 17.56  loss_ce_0: 2.432  loss_mask_0: 17.39  loss_ce_1: 2.421  loss_mask_1: 16.82  loss_ce_2: 2.425  loss_mask_2: 16.28  loss_ce_3: 2.402  loss_mask_3: 16.58  loss_ce_4: 2.331  loss_mask_4: 16.61  loss_ce_5: 2.32  loss_mask_5: 16.77  loss_ce_6: 2.302  loss_mask_6: 16.86  loss_ce_7: 2.332  loss_mask_7: 16.96  loss_ce_8: 2.3  loss_mask_8: 17.19  time: 2.4271  data_time: 0.4357  lr: 1.2758e-05  max_mem: 18229M
[01/24 00:56:23] d2.utils.events INFO:  eta: 1 day, 15:55:08  iter: 139  total_loss: 175.4  loss_ce: 2.297  loss_mask: 15.61  loss_ce_0: 2.436  loss_mask_0: 16.13  loss_ce_1: 2.412  loss_mask_1: 15.25  loss_ce_2: 2.41  loss_mask_2: 14.51  loss_ce_3: 2.395  loss_mask_3: 14.98  loss_ce_4: 2.329  loss_mask_4: 14.84  loss_ce_5: 2.312  loss_mask_5: 15.19  loss_ce_6: 2.287  loss_mask_6: 14.99  loss_ce_7: 2.325  loss_mask_7: 15.09  loss_ce_8: 2.296  loss_mask_8: 15.23  time: 2.4300  data_time: 0.3839  lr: 1.473e-05  max_mem: 18229M
[01/24 00:57:11] d2.utils.events INFO:  eta: 1 day, 15:54:20  iter: 159  total_loss: 159.2  loss_ce: 2.29  loss_mask: 13.83  loss_ce_0: 2.425  loss_mask_0: 14.58  loss_ce_1: 2.393  loss_mask_1: 13.79  loss_ce_2: 2.375  loss_mask_2: 13.29  loss_ce_3: 2.371  loss_mask_3: 13.46  loss_ce_4: 2.324  loss_mask_4: 13.23  loss_ce_5: 2.299  loss_mask_5: 13.29  loss_ce_6: 2.283  loss_mask_6: 13.35  loss_ce_7: 2.32  loss_mask_7: 13.27  loss_ce_8: 2.29  loss_mask_8: 13.23  time: 2.4293  data_time: 0.4027  lr: 1.6701e-05  max_mem: 18229M
[01/24 00:58:04] d2.utils.events INFO:  eta: 1 day, 16:07:24  iter: 179  total_loss: 147.5  loss_ce: 2.282  loss_mask: 12.47  loss_ce_0: 2.422  loss_mask_0: 13.33  loss_ce_1: 2.379  loss_mask_1: 12.66  loss_ce_2: 2.358  loss_mask_2: 12.27  loss_ce_3: 2.346  loss_mask_3: 12.28  loss_ce_4: 2.287  loss_mask_4: 12.2  loss_ce_5: 2.275  loss_mask_5: 12.16  loss_ce_6: 2.273  loss_mask_6: 12.21  loss_ce_7: 2.308  loss_mask_7: 12.31  loss_ce_8: 2.276  loss_mask_8: 12.29  time: 2.4511  data_time: 0.4375  lr: 1.8671e-05  max_mem: 18229M
[01/24 00:58:54] d2.utils.events INFO:  eta: 1 day, 16:24:14  iter: 199  total_loss: 143.8  loss_ce: 2.263  loss_mask: 12.15  loss_ce_0: 2.425  loss_mask_0: 13.08  loss_ce_1: 2.361  loss_mask_1: 12.32  loss_ce_2: 2.337  loss_mask_2: 11.93  loss_ce_3: 2.31  loss_mask_3: 11.89  loss_ce_4: 2.257  loss_mask_4: 11.69  loss_ce_5: 2.25  loss_mask_5: 11.87  loss_ce_6: 2.253  loss_mask_6: 11.93  loss_ce_7: 2.288  loss_mask_7: 12  loss_ce_8: 2.254  loss_mask_8: 12.04  time: 2.4556  data_time: 0.3695  lr: 2.0639e-05  max_mem: 18229M
[01/24 00:59:43] d2.utils.events INFO:  eta: 1 day, 16:31:07  iter: 219  total_loss: 141.1  loss_ce: 2.227  loss_mask: 11.88  loss_ce_0: 2.425  loss_mask_0: 13.03  loss_ce_1: 2.347  loss_mask_1: 12.03  loss_ce_2: 2.324  loss_mask_2: 11.68  loss_ce_3: 2.291  loss_mask_3: 11.69  loss_ce_4: 2.23  loss_mask_4: 11.5  loss_ce_5: 2.222  loss_mask_5: 11.62  loss_ce_6: 2.23  loss_mask_6: 11.69  loss_ce_7: 2.252  loss_mask_7: 11.73  loss_ce_8: 2.224  loss_mask_8: 11.6  time: 2.4557  data_time: 0.3788  lr: 2.2606e-05  max_mem: 18229M
[01/24 01:00:36] d2.utils.events INFO:  eta: 1 day, 16:39:32  iter: 239  total_loss: 135.1  loss_ce: 2.221  loss_mask: 11.21  loss_ce_0: 2.426  loss_mask_0: 12.38  loss_ce_1: 2.336  loss_mask_1: 11.18  loss_ce_2: 2.301  loss_mask_2: 11.28  loss_ce_3: 2.272  loss_mask_3: 11.2  loss_ce_4: 2.216  loss_mask_4: 11.06  loss_ce_5: 2.207  loss_mask_5: 11.03  loss_ce_6: 2.219  loss_mask_6: 10.9  loss_ce_7: 2.238  loss_mask_7: 11  loss_ce_8: 2.212  loss_mask_8: 10.98  time: 2.4713  data_time: 0.4365  lr: 2.4573e-05  max_mem: 18229M
[01/24 01:01:24] d2.utils.events INFO:  eta: 1 day, 16:35:56  iter: 259  total_loss: 133.6  loss_ce: 2.194  loss_mask: 11.19  loss_ce_0: 2.428  loss_mask_0: 12.09  loss_ce_1: 2.312  loss_mask_1: 11.14  loss_ce_2: 2.265  loss_mask_2: 10.94  loss_ce_3: 2.243  loss_mask_3: 11.04  loss_ce_4: 2.182  loss_mask_4: 10.97  loss_ce_5: 2.192  loss_mask_5: 10.8  loss_ce_6: 2.207  loss_mask_6: 10.97  loss_ce_7: 2.209  loss_mask_7: 11.05  loss_ce_8: 2.186  loss_mask_8: 11.1  time: 2.4668  data_time: 0.3864  lr: 2.6537e-05  max_mem: 18246M
[01/24 01:02:15] d2.utils.events INFO:  eta: 1 day, 16:39:07  iter: 279  total_loss: 130.1  loss_ce: 2.192  loss_mask: 10.85  loss_ce_0: 2.423  loss_mask_0: 11.61  loss_ce_1: 2.29  loss_mask_1: 10.7  loss_ce_2: 2.246  loss_mask_2: 10.47  loss_ce_3: 2.222  loss_mask_3: 10.58  loss_ce_4: 2.178  loss_mask_4: 10.55  loss_ce_5: 2.189  loss_mask_5: 10.55  loss_ce_6: 2.199  loss_mask_6: 10.57  loss_ce_7: 2.211  loss_mask_7: 10.53  loss_ce_8: 2.188  loss_mask_8: 10.66  time: 2.4741  data_time: 0.3930  lr: 2.8501e-05  max_mem: 18246M
[01/24 01:03:06] d2.utils.events INFO:  eta: 1 day, 16:44:00  iter: 299  total_loss: 128.3  loss_ce: 2.226  loss_mask: 10.69  loss_ce_0: 2.426  loss_mask_0: 10.77  loss_ce_1: 2.263  loss_mask_1: 10.24  loss_ce_2: 2.23  loss_mask_2: 10.08  loss_ce_3: 2.219  loss_mask_3: 10.51  loss_ce_4: 2.201  loss_mask_4: 10.6  loss_ce_5: 2.215  loss_mask_5: 10.56  loss_ce_6: 2.227  loss_mask_6: 10.45  loss_ce_7: 2.233  loss_mask_7: 10.57  loss_ce_8: 2.216  loss_mask_8: 10.5  time: 2.4789  data_time: 0.3819  lr: 3.0464e-05  max_mem: 18246M
[01/24 01:03:56] d2.utils.events INFO:  eta: 1 day, 16:41:13  iter: 319  total_loss: 127  loss_ce: 2.22  loss_mask: 10.55  loss_ce_0: 2.425  loss_mask_0: 10.88  loss_ce_1: 2.256  loss_mask_1: 10.27  loss_ce_2: 2.223  loss_mask_2: 10.26  loss_ce_3: 2.207  loss_mask_3: 10.46  loss_ce_4: 2.186  loss_mask_4: 10.43  loss_ce_5: 2.204  loss_mask_5: 10.32  loss_ce_6: 2.21  loss_mask_6: 10.44  loss_ce_7: 2.227  loss_mask_7: 10.39  loss_ce_8: 2.218  loss_mask_8: 10.44  time: 2.4785  data_time: 0.3838  lr: 3.2425e-05  max_mem: 18268M
[01/24 01:04:52] d2.utils.events INFO:  eta: 1 day, 16:52:03  iter: 339  total_loss: 121.4  loss_ce: 2.236  loss_mask: 10.04  loss_ce_0: 2.414  loss_mask_0: 10.61  loss_ce_1: 2.228  loss_mask_1: 10.04  loss_ce_2: 2.211  loss_mask_2: 9.784  loss_ce_3: 2.213  loss_mask_3: 10.2  loss_ce_4: 2.209  loss_mask_4: 10.15  loss_ce_5: 2.215  loss_mask_5: 9.884  loss_ce_6: 2.236  loss_mask_6: 9.996  loss_ce_7: 2.246  loss_mask_7: 9.988  loss_ce_8: 2.235  loss_mask_8: 10.2  time: 2.4964  data_time: 0.4470  lr: 3.4385e-05  max_mem: 18268M
[01/24 01:05:41] d2.utils.events INFO:  eta: 1 day, 16:49:58  iter: 359  total_loss: 120.1  loss_ce: 2.168  loss_mask: 10.07  loss_ce_0: 2.428  loss_mask_0: 10.22  loss_ce_1: 2.22  loss_mask_1: 9.67  loss_ce_2: 2.198  loss_mask_2: 9.69  loss_ce_3: 2.191  loss_mask_3: 9.831  loss_ce_4: 2.167  loss_mask_4: 9.811  loss_ce_5: 2.179  loss_mask_5: 9.631  loss_ce_6: 2.177  loss_mask_6: 9.799  loss_ce_7: 2.172  loss_mask_7: 9.783  loss_ce_8: 2.167  loss_mask_8: 10.01  time: 2.4953  data_time: 0.3665  lr: 3.6344e-05  max_mem: 18341M
[01/24 01:06:32] d2.utils.events INFO:  eta: 1 day, 16:50:50  iter: 379  total_loss: 117.3  loss_ce: 2.15  loss_mask: 9.525  loss_ce_0: 2.424  loss_mask_0: 9.976  loss_ce_1: 2.206  loss_mask_1: 9.519  loss_ce_2: 2.175  loss_mask_2: 9.313  loss_ce_3: 2.18  loss_mask_3: 9.646  loss_ce_4: 2.168  loss_mask_4: 9.647  loss_ce_5: 2.189  loss_mask_5: 9.578  loss_ce_6: 2.181  loss_mask_6: 9.677  loss_ce_7: 2.166  loss_mask_7: 9.521  loss_ce_8: 2.153  loss_mask_8: 9.63  time: 2.4975  data_time: 0.3787  lr: 3.8302e-05  max_mem: 18341M
[01/24 01:07:26] d2.utils.events INFO:  eta: 1 day, 16:55:39  iter: 399  total_loss: 113.3  loss_ce: 2.159  loss_mask: 9.069  loss_ce_0: 2.424  loss_mask_0: 9.409  loss_ce_1: 2.185  loss_mask_1: 9.046  loss_ce_2: 2.157  loss_mask_2: 9.031  loss_ce_3: 2.161  loss_mask_3: 9.135  loss_ce_4: 2.147  loss_mask_4: 9.106  loss_ce_5: 2.157  loss_mask_5: 9.051  loss_ce_6: 2.158  loss_mask_6: 9.169  loss_ce_7: 2.158  loss_mask_7: 9.128  loss_ce_8: 2.163  loss_mask_8: 9.266  time: 2.5067  data_time: 0.4267  lr: 4.0259e-05  max_mem: 18341M
[01/24 01:08:14] d2.utils.events INFO:  eta: 1 day, 16:53:39  iter: 419  total_loss: 114.9  loss_ce: 2.141  loss_mask: 9.353  loss_ce_0: 2.427  loss_mask_0: 9.577  loss_ce_1: 2.157  loss_mask_1: 9.144  loss_ce_2: 2.145  loss_mask_2: 9.078  loss_ce_3: 2.14  loss_mask_3: 9.214  loss_ce_4: 2.127  loss_mask_4: 9.179  loss_ce_5: 2.138  loss_mask_5: 9.148  loss_ce_6: 2.141  loss_mask_6: 9.237  loss_ce_7: 2.145  loss_mask_7: 9.23  loss_ce_8: 2.132  loss_mask_8: 9.282  time: 2.5035  data_time: 0.3658  lr: 4.2214e-05  max_mem: 18341M
[01/24 01:09:06] d2.utils.events INFO:  eta: 1 day, 17:00:20  iter: 439  total_loss: 110.3  loss_ce: 2.098  loss_mask: 9.087  loss_ce_0: 2.436  loss_mask_0: 8.975  loss_ce_1: 2.143  loss_mask_1: 8.515  loss_ce_2: 2.123  loss_mask_2: 8.683  loss_ce_3: 2.106  loss_mask_3: 8.791  loss_ce_4: 2.094  loss_mask_4: 8.808  loss_ce_5: 2.096  loss_mask_5: 8.941  loss_ce_6: 2.104  loss_mask_6: 8.888  loss_ce_7: 2.104  loss_mask_7: 9.045  loss_ce_8: 2.098  loss_mask_8: 9.021  time: 2.5077  data_time: 0.3879  lr: 4.4168e-05  max_mem: 18341M
[01/24 01:09:58] d2.utils.events INFO:  eta: 1 day, 17:03:07  iter: 459  total_loss: 101.2  loss_ce: 2.085  loss_mask: 8.061  loss_ce_0: 2.443  loss_mask_0: 8.199  loss_ce_1: 2.117  loss_mask_1: 7.773  loss_ce_2: 2.102  loss_mask_2: 7.883  loss_ce_3: 2.097  loss_mask_3: 8.063  loss_ce_4: 2.084  loss_mask_4: 7.85  loss_ce_5: 2.092  loss_mask_5: 7.96  loss_ce_6: 2.094  loss_mask_6: 7.964  loss_ce_7: 2.099  loss_mask_7: 8.054  loss_ce_8: 2.085  loss_mask_8: 8.055  time: 2.5100  data_time: 0.3862  lr: 4.6121e-05  max_mem: 18341M
[01/24 01:10:48] d2.utils.events INFO:  eta: 1 day, 17:02:18  iter: 479  total_loss: 105.3  loss_ce: 2.109  loss_mask: 8.461  loss_ce_0: 2.439  loss_mask_0: 8.563  loss_ce_1: 2.109  loss_mask_1: 8.174  loss_ce_2: 2.098  loss_mask_2: 8.216  loss_ce_3: 2.088  loss_mask_3: 8.382  loss_ce_4: 2.082  loss_mask_4: 8.285  loss_ce_5: 2.089  loss_mask_5: 8.34  loss_ce_6: 2.101  loss_mask_6: 8.372  loss_ce_7: 2.106  loss_mask_7: 8.416  loss_ce_8: 2.105  loss_mask_8: 8.588  time: 2.5097  data_time: 0.3885  lr: 4.8073e-05  max_mem: 18341M
[01/24 01:11:41] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 01:11:41] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 01:11:41] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 01:15:19] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 25.357614089980913, 'error_1pix': 0.9588941418080591, 'error_3pix': 0.9054776471863254, 'mIoU': 0.03268563902148607, 'fwIoU': 0.0662564347769098, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.5012158527721341, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 2.0375028537558664, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.04947469316236638, 'IoU-31': 0.0, 'IoU-32': 0.026529021893100333, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.006175309614929571, 'IoU-41': 0.0, 'IoU-42': 1.1742698030222236, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.5321726471455387, 'IoU-76': 0.000423977117349295, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.8805693085058905, 'IoU-86': 0.6092114332901587, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.23825686997537363, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.21984092187039417, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.8086858246741095, 'pACC': 1.3148918728053456, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.563641630414746, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 60.93812499633346, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.053511329335097745, 'ACC-31': 0.0, 'ACC-32': 0.02799143620672919, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.006183345652601651, 'ACC-41': 0.0, 'ACC-42': 2.5884611758397567, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 42.12617350576966, 'ACC-76': 0.00044480989460547266, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 44.75693581320509, 'ACC-86': 3.155354571095354, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.5200359080876953, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.5308198155942192, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 01:15:19] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 01:15:19] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 01:15:19] d2.evaluation.testing INFO: copypaste: 25.3576,0.9589,0.9055,0.0327,0.0663,0.8087,1.3149
[01/24 01:15:19] d2.utils.events INFO:  eta: 1 day, 17:09:22  iter: 499  total_loss: 99.02  loss_ce: 2.103  loss_mask: 7.809  loss_ce_0: 2.438  loss_mask_0: 7.988  loss_ce_1: 2.089  loss_mask_1: 7.933  loss_ce_2: 2.081  loss_mask_2: 7.825  loss_ce_3: 2.075  loss_mask_3: 7.874  loss_ce_4: 2.078  loss_mask_4: 7.724  loss_ce_5: 2.077  loss_mask_5: 7.542  loss_ce_6: 2.086  loss_mask_6: 7.632  loss_ce_7: 2.098  loss_mask_7: 7.67  loss_ce_8: 2.099  loss_mask_8: 7.75  time: 2.5154  data_time: 0.4118  lr: 5.0024e-05  max_mem: 18341M
[01/24 01:16:09] d2.utils.events INFO:  eta: 1 day, 17:03:44  iter: 519  total_loss: 101.1  loss_ce: 2.115  loss_mask: 7.986  loss_ce_0: 2.432  loss_mask_0: 8.09  loss_ce_1: 2.095  loss_mask_1: 7.948  loss_ce_2: 2.089  loss_mask_2: 7.906  loss_ce_3: 2.095  loss_mask_3: 8.057  loss_ce_4: 2.096  loss_mask_4: 7.933  loss_ce_5: 2.099  loss_mask_5: 7.972  loss_ce_6: 2.092  loss_mask_6: 7.868  loss_ce_7: 2.096  loss_mask_7: 7.964  loss_ce_8: 2.105  loss_mask_8: 7.809  time: 2.5141  data_time: 0.3599  lr: 5.1973e-05  max_mem: 18341M
[01/24 01:16:58] d2.utils.events INFO:  eta: 1 day, 17:00:37  iter: 539  total_loss: 99.14  loss_ce: 2.11  loss_mask: 7.936  loss_ce_0: 2.442  loss_mask_0: 8.018  loss_ce_1: 2.085  loss_mask_1: 7.705  loss_ce_2: 2.096  loss_mask_2: 7.617  loss_ce_3: 2.099  loss_mask_3: 7.946  loss_ce_4: 2.084  loss_mask_4: 7.74  loss_ce_5: 2.088  loss_mask_5: 8.012  loss_ce_6: 2.092  loss_mask_6: 7.637  loss_ce_7: 2.1  loss_mask_7: 7.894  loss_ce_8: 2.097  loss_mask_8: 7.817  time: 2.5104  data_time: 0.3714  lr: 5.3921e-05  max_mem: 18341M
[01/24 01:17:47] d2.utils.events INFO:  eta: 1 day, 16:58:47  iter: 559  total_loss: 97.86  loss_ce: 2.087  loss_mask: 7.974  loss_ce_0: 2.442  loss_mask_0: 7.78  loss_ce_1: 2.068  loss_mask_1: 7.414  loss_ce_2: 2.073  loss_mask_2: 7.695  loss_ce_3: 2.084  loss_mask_3: 7.741  loss_ce_4: 2.062  loss_mask_4: 7.711  loss_ce_5: 2.063  loss_mask_5: 7.733  loss_ce_6: 2.073  loss_mask_6: 7.445  loss_ce_7: 2.074  loss_mask_7: 7.723  loss_ce_8: 2.07  loss_mask_8: 7.72  time: 2.5085  data_time: 0.4133  lr: 5.5868e-05  max_mem: 18341M
[01/24 01:18:36] d2.utils.events INFO:  eta: 1 day, 16:55:42  iter: 579  total_loss: 95.39  loss_ce: 2.055  loss_mask: 7.641  loss_ce_0: 2.445  loss_mask_0: 7.696  loss_ce_1: 2.056  loss_mask_1: 7.233  loss_ce_2: 2.055  loss_mask_2: 7.192  loss_ce_3: 2.073  loss_mask_3: 7.29  loss_ce_4: 2.057  loss_mask_4: 7.481  loss_ce_5: 2.068  loss_mask_5: 7.512  loss_ce_6: 2.079  loss_mask_6: 7.481  loss_ce_7: 2.108  loss_mask_7: 7.388  loss_ce_8: 2.07  loss_mask_8: 7.681  time: 2.5063  data_time: 0.3968  lr: 5.7814e-05  max_mem: 18341M
[01/24 01:19:25] d2.utils.events INFO:  eta: 1 day, 16:54:52  iter: 599  total_loss: 94.78  loss_ce: 2.062  loss_mask: 7.407  loss_ce_0: 2.43  loss_mask_0: 7.526  loss_ce_1: 2.062  loss_mask_1: 7.285  loss_ce_2: 2.065  loss_mask_2: 7.312  loss_ce_3: 2.086  loss_mask_3: 7.476  loss_ce_4: 2.086  loss_mask_4: 7.36  loss_ce_5: 2.073  loss_mask_5: 7.352  loss_ce_6: 2.084  loss_mask_6: 7.564  loss_ce_7: 2.08  loss_mask_7: 7.531  loss_ce_8: 2.06  loss_mask_8: 7.321  time: 2.5045  data_time: 0.3912  lr: 5.9759e-05  max_mem: 18341M
[01/24 01:20:14] d2.utils.events INFO:  eta: 1 day, 16:52:53  iter: 619  total_loss: 95.4  loss_ce: 2.087  loss_mask: 7.565  loss_ce_0: 2.435  loss_mask_0: 7.41  loss_ce_1: 2.061  loss_mask_1: 7.333  loss_ce_2: 2.059  loss_mask_2: 7.265  loss_ce_3: 2.078  loss_mask_3: 7.582  loss_ce_4: 2.091  loss_mask_4: 7.392  loss_ce_5: 2.082  loss_mask_5: 7.498  loss_ce_6: 2.073  loss_mask_6: 7.406  loss_ce_7: 2.085  loss_mask_7: 7.649  loss_ce_8: 2.084  loss_mask_8: 7.662  time: 2.5030  data_time: 0.3961  lr: 6.1702e-05  max_mem: 18341M
[01/24 01:21:04] d2.utils.events INFO:  eta: 1 day, 16:52:03  iter: 639  total_loss: 96.89  loss_ce: 2.11  loss_mask: 7.755  loss_ce_0: 2.445  loss_mask_0: 7.494  loss_ce_1: 2.044  loss_mask_1: 7.36  loss_ce_2: 2.046  loss_mask_2: 7.242  loss_ce_3: 2.078  loss_mask_3: 7.421  loss_ce_4: 2.092  loss_mask_4: 7.486  loss_ce_5: 2.103  loss_mask_5: 7.639  loss_ce_6: 2.107  loss_mask_6: 7.719  loss_ce_7: 2.125  loss_mask_7: 7.607  loss_ce_8: 2.144  loss_mask_8: 8.072  time: 2.5031  data_time: 0.4108  lr: 6.3645e-05  max_mem: 18341M
[01/24 01:21:53] d2.utils.events INFO:  eta: 1 day, 16:49:42  iter: 659  total_loss: 93.2  loss_ce: 2.078  loss_mask: 7.117  loss_ce_0: 2.442  loss_mask_0: 7.371  loss_ce_1: 2.027  loss_mask_1: 6.906  loss_ce_2: 2.023  loss_mask_2: 6.886  loss_ce_3: 2.041  loss_mask_3: 7.082  loss_ce_4: 2.058  loss_mask_4: 7.118  loss_ce_5: 2.059  loss_mask_5: 7.364  loss_ce_6: 2.064  loss_mask_6: 7.195  loss_ce_7: 2.068  loss_mask_7: 7.405  loss_ce_8: 2.078  loss_mask_8: 7.351  time: 2.5012  data_time: 0.3997  lr: 6.5586e-05  max_mem: 18341M
[01/24 01:22:43] d2.utils.events INFO:  eta: 1 day, 16:50:24  iter: 679  total_loss: 92.07  loss_ce: 2.067  loss_mask: 7.319  loss_ce_0: 2.441  loss_mask_0: 7.069  loss_ce_1: 2.039  loss_mask_1: 6.924  loss_ce_2: 2.034  loss_mask_2: 6.894  loss_ce_3: 2.049  loss_mask_3: 6.971  loss_ce_4: 2.056  loss_mask_4: 7.118  loss_ce_5: 2.06  loss_mask_5: 7.219  loss_ce_6: 2.067  loss_mask_6: 7.122  loss_ce_7: 2.078  loss_mask_7: 7.205  loss_ce_8: 2.081  loss_mask_8: 7.361  time: 2.5012  data_time: 0.3744  lr: 6.7526e-05  max_mem: 18341M
[01/24 01:23:35] d2.utils.events INFO:  eta: 1 day, 16:49:34  iter: 699  total_loss: 89.31  loss_ce: 2.062  loss_mask: 6.992  loss_ce_0: 2.444  loss_mask_0: 6.904  loss_ce_1: 2.029  loss_mask_1: 6.871  loss_ce_2: 2.035  loss_mask_2: 6.841  loss_ce_3: 2.054  loss_mask_3: 6.674  loss_ce_4: 2.074  loss_mask_4: 6.9  loss_ce_5: 2.066  loss_mask_5: 6.789  loss_ce_6: 2.071  loss_mask_6: 6.833  loss_ce_7: 2.056  loss_mask_7: 7.034  loss_ce_8: 2.049  loss_mask_8: 6.976  time: 2.5034  data_time: 0.3819  lr: 6.9465e-05  max_mem: 18341M
[01/24 01:24:26] d2.utils.events INFO:  eta: 1 day, 16:50:05  iter: 719  total_loss: 89.29  loss_ce: 2.033  loss_mask: 6.898  loss_ce_0: 2.434  loss_mask_0: 6.852  loss_ce_1: 2.011  loss_mask_1: 6.656  loss_ce_2: 2.017  loss_mask_2: 6.673  loss_ce_3: 2.026  loss_mask_3: 6.709  loss_ce_4: 2.055  loss_mask_4: 6.86  loss_ce_5: 2.037  loss_mask_5: 6.772  loss_ce_6: 2.031  loss_mask_6: 6.834  loss_ce_7: 2.03  loss_mask_7: 6.751  loss_ce_8: 2.046  loss_mask_8: 6.968  time: 2.5057  data_time: 0.4043  lr: 7.1402e-05  max_mem: 18341M
[01/24 01:25:16] d2.utils.events INFO:  eta: 1 day, 16:49:51  iter: 739  total_loss: 89.4  loss_ce: 2.056  loss_mask: 6.975  loss_ce_0: 2.43  loss_mask_0: 6.802  loss_ce_1: 2.018  loss_mask_1: 6.741  loss_ce_2: 2.022  loss_mask_2: 6.658  loss_ce_3: 2.027  loss_mask_3: 6.753  loss_ce_4: 2.061  loss_mask_4: 6.841  loss_ce_5: 2.061  loss_mask_5: 6.726  loss_ce_6: 2.064  loss_mask_6: 6.939  loss_ce_7: 2.059  loss_mask_7: 6.953  loss_ce_8: 2.063  loss_mask_8: 7.139  time: 2.5047  data_time: 0.3559  lr: 7.3338e-05  max_mem: 18341M
[01/24 01:26:09] d2.utils.events INFO:  eta: 1 day, 16:51:42  iter: 759  total_loss: 88.99  loss_ce: 2.054  loss_mask: 7.055  loss_ce_0: 2.416  loss_mask_0: 6.819  loss_ce_1: 2.025  loss_mask_1: 6.674  loss_ce_2: 2.033  loss_mask_2: 6.674  loss_ce_3: 2.042  loss_mask_3: 6.636  loss_ce_4: 2.067  loss_mask_4: 6.835  loss_ce_5: 2.061  loss_mask_5: 6.773  loss_ce_6: 2.056  loss_mask_6: 6.845  loss_ce_7: 2.056  loss_mask_7: 6.836  loss_ce_8: 2.039  loss_mask_8: 6.821  time: 2.5083  data_time: 0.4306  lr: 7.5274e-05  max_mem: 18341M
[01/24 01:26:58] d2.utils.events INFO:  eta: 1 day, 16:50:36  iter: 779  total_loss: 85.16  loss_ce: 2.036  loss_mask: 6.59  loss_ce_0: 2.43  loss_mask_0: 6.464  loss_ce_1: 1.996  loss_mask_1: 6.247  loss_ce_2: 1.999  loss_mask_2: 6.319  loss_ce_3: 2.011  loss_mask_3: 6.536  loss_ce_4: 2.037  loss_mask_4: 6.521  loss_ce_5: 2.017  loss_mask_5: 6.347  loss_ce_6: 2.006  loss_mask_6: 6.448  loss_ce_7: 2.004  loss_mask_7: 6.429  loss_ce_8: 2  loss_mask_8: 6.378  time: 2.5076  data_time: 0.3844  lr: 7.7208e-05  max_mem: 18341M
[01/24 01:27:49] d2.utils.events INFO:  eta: 1 day, 16:49:34  iter: 799  total_loss: 84.52  loss_ce: 2.059  loss_mask: 6.447  loss_ce_0: 2.401  loss_mask_0: 6.503  loss_ce_1: 1.995  loss_mask_1: 6.441  loss_ce_2: 2.003  loss_mask_2: 6.494  loss_ce_3: 2.015  loss_mask_3: 6.403  loss_ce_4: 2.031  loss_mask_4: 6.359  loss_ce_5: 2.034  loss_mask_5: 6.338  loss_ce_6: 2.035  loss_mask_6: 6.418  loss_ce_7: 2.033  loss_mask_7: 6.563  loss_ce_8: 2.037  loss_mask_8: 6.59  time: 2.5077  data_time: 0.3707  lr: 7.914e-05  max_mem: 18341M
[01/24 01:28:43] d2.utils.events INFO:  eta: 1 day, 16:51:33  iter: 819  total_loss: 87.34  loss_ce: 2.103  loss_mask: 6.901  loss_ce_0: 2.399  loss_mask_0: 6.669  loss_ce_1: 2.005  loss_mask_1: 6.59  loss_ce_2: 2.017  loss_mask_2: 6.485  loss_ce_3: 2.021  loss_mask_3: 6.509  loss_ce_4: 2.047  loss_mask_4: 6.709  loss_ce_5: 2.059  loss_mask_5: 6.776  loss_ce_6: 2.055  loss_mask_6: 6.79  loss_ce_7: 2.042  loss_mask_7: 6.55  loss_ce_8: 2.049  loss_mask_8: 7.034  time: 2.5130  data_time: 0.4160  lr: 8.1072e-05  max_mem: 18341M
[01/24 01:29:33] d2.utils.events INFO:  eta: 1 day, 16:51:08  iter: 839  total_loss: 88.01  loss_ce: 2.108  loss_mask: 6.934  loss_ce_0: 2.391  loss_mask_0: 6.673  loss_ce_1: 1.999  loss_mask_1: 6.585  loss_ce_2: 2.014  loss_mask_2: 6.461  loss_ce_3: 2.023  loss_mask_3: 6.378  loss_ce_4: 2.042  loss_mask_4: 6.648  loss_ce_5: 2.033  loss_mask_5: 6.565  loss_ce_6: 2.05  loss_mask_6: 6.566  loss_ce_7: 2.042  loss_mask_7: 6.739  loss_ce_8: 2.064  loss_mask_8: 6.612  time: 2.5125  data_time: 0.3723  lr: 8.3002e-05  max_mem: 18341M
[01/24 01:30:22] d2.utils.events INFO:  eta: 1 day, 16:47:47  iter: 859  total_loss: 84.54  loss_ce: 2.013  loss_mask: 6.396  loss_ce_0: 2.401  loss_mask_0: 6.383  loss_ce_1: 1.968  loss_mask_1: 6.239  loss_ce_2: 1.979  loss_mask_2: 6.192  loss_ce_3: 1.991  loss_mask_3: 6.239  loss_ce_4: 2.005  loss_mask_4: 6.354  loss_ce_5: 2.013  loss_mask_5: 6.403  loss_ce_6: 2.006  loss_mask_6: 6.445  loss_ce_7: 2.013  loss_mask_7: 6.456  loss_ce_8: 2.013  loss_mask_8: 6.413  time: 2.5108  data_time: 0.3753  lr: 8.4932e-05  max_mem: 18341M
[01/24 01:31:14] d2.utils.events INFO:  eta: 1 day, 16:49:57  iter: 879  total_loss: 83.03  loss_ce: 2.059  loss_mask: 6.218  loss_ce_0: 2.393  loss_mask_0: 6.116  loss_ce_1: 1.974  loss_mask_1: 6.201  loss_ce_2: 1.997  loss_mask_2: 6.072  loss_ce_3: 2.029  loss_mask_3: 6.167  loss_ce_4: 2.053  loss_mask_4: 6.239  loss_ce_5: 2.042  loss_mask_5: 6.337  loss_ce_6: 2.063  loss_mask_6: 6.227  loss_ce_7: 2.051  loss_mask_7: 6.277  loss_ce_8: 2.056  loss_mask_8: 6.399  time: 2.5125  data_time: 0.3893  lr: 8.686e-05  max_mem: 18341M
[01/24 01:32:03] d2.utils.events INFO:  eta: 1 day, 16:47:04  iter: 899  total_loss: 82.63  loss_ce: 2.037  loss_mask: 6.261  loss_ce_0: 2.366  loss_mask_0: 6.162  loss_ce_1: 1.973  loss_mask_1: 6.077  loss_ce_2: 1.99  loss_mask_2: 5.984  loss_ce_3: 2.011  loss_mask_3: 6.197  loss_ce_4: 2.026  loss_mask_4: 6.209  loss_ce_5: 2.028  loss_mask_5: 6.25  loss_ce_6: 2.025  loss_mask_6: 6.272  loss_ce_7: 2.037  loss_mask_7: 6.247  loss_ce_8: 2.058  loss_mask_8: 6.327  time: 2.5111  data_time: 0.3776  lr: 8.8786e-05  max_mem: 18341M
[01/24 01:32:55] d2.utils.events INFO:  eta: 1 day, 16:48:18  iter: 919  total_loss: 81.59  loss_ce: 2.065  loss_mask: 6.303  loss_ce_0: 2.363  loss_mask_0: 6.07  loss_ce_1: 1.977  loss_mask_1: 5.878  loss_ce_2: 2.006  loss_mask_2: 6.008  loss_ce_3: 2.027  loss_mask_3: 6.018  loss_ce_4: 2.046  loss_mask_4: 6.079  loss_ce_5: 2.044  loss_mask_5: 6.133  loss_ce_6: 2.04  loss_mask_6: 6.103  loss_ce_7: 2.036  loss_mask_7: 6.147  loss_ce_8: 2.054  loss_mask_8: 6.207  time: 2.5130  data_time: 0.4055  lr: 9.0712e-05  max_mem: 18341M
[01/24 01:33:47] d2.utils.events INFO:  eta: 1 day, 16:47:28  iter: 939  total_loss: 83.7  loss_ce: 2.088  loss_mask: 6.478  loss_ce_0: 2.347  loss_mask_0: 6.261  loss_ce_1: 1.99  loss_mask_1: 6.216  loss_ce_2: 2.024  loss_mask_2: 6.114  loss_ce_3: 2.057  loss_mask_3: 6.229  loss_ce_4: 2.072  loss_mask_4: 6.244  loss_ce_5: 2.072  loss_mask_5: 6.258  loss_ce_6: 2.069  loss_mask_6: 6.15  loss_ce_7: 2.073  loss_mask_7: 6.233  loss_ce_8: 2.072  loss_mask_8: 6.391  time: 2.5149  data_time: 0.3900  lr: 9.2637e-05  max_mem: 18427M
[01/24 01:34:37] d2.utils.events INFO:  eta: 1 day, 16:46:38  iter: 959  total_loss: 79.06  loss_ce: 2.055  loss_mask: 6.183  loss_ce_0: 2.348  loss_mask_0: 5.7  loss_ce_1: 1.969  loss_mask_1: 5.63  loss_ce_2: 2.019  loss_mask_2: 5.633  loss_ce_3: 2.038  loss_mask_3: 5.68  loss_ce_4: 2.05  loss_mask_4: 5.896  loss_ce_5: 2.071  loss_mask_5: 5.835  loss_ce_6: 2.079  loss_mask_6: 5.707  loss_ce_7: 2.071  loss_mask_7: 5.884  loss_ce_8: 2.073  loss_mask_8: 5.912  time: 2.5149  data_time: 0.3753  lr: 9.456e-05  max_mem: 18427M
[01/24 01:35:30] d2.utils.events INFO:  eta: 1 day, 16:49:01  iter: 979  total_loss: 80  loss_ce: 2.042  loss_mask: 6.096  loss_ce_0: 2.329  loss_mask_0: 6.001  loss_ce_1: 1.976  loss_mask_1: 5.707  loss_ce_2: 2.011  loss_mask_2: 5.8  loss_ce_3: 2.035  loss_mask_3: 5.767  loss_ce_4: 2.042  loss_mask_4: 5.735  loss_ce_5: 2.048  loss_mask_5: 5.9  loss_ce_6: 2.081  loss_mask_6: 5.842  loss_ce_7: 2.065  loss_mask_7: 5.898  loss_ce_8: 2.06  loss_mask_8: 5.927  time: 2.5173  data_time: 0.4137  lr: 9.6482e-05  max_mem: 18427M
[01/24 01:36:19] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 01:36:20] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 01:36:20] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 01:40:08] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 18.2689422219513, 'error_1pix': 0.9326238334984605, 'error_3pix': 0.85944201704814, 'mIoU': 0.09504098578212647, 'fwIoU': 0.31101257643268526, 'IoU-0': nan, 'IoU-1': 0.5829405702422672, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 5.174022524760172, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 2.1185467807172202e-05, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 2.9928882988243336e-06, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.4910900504915297, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 2.5604439543539628, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.009305392021856207, 'IoU-36': 0.0, 'IoU-37': 2.0342133697732168, 'IoU-38': 0.1158618757042853, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 1.4327529558856953, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 2.8806416028350782e-05, 'IoU-47': 2.2647835073479543, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.39487106793554616, 'IoU-55': 0.0, 'IoU-56': 0.032120369853987994, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.5615972846088089, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.07727788128977853, 'IoU-69': 0.004823240200792321, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.007895767314459921, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 1.0590617560091165e-05, 'IoU-77': 0.00021816565012381991, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.006159274081548142, 'IoU-83': 1.0828922693625012, 'IoU-84': 0.0, 'IoU-85': 1.397364528675206, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0013392539627289524, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0158323912621658, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.0990159994836288, 'pACC': 2.3358755464544254, 'ACC-0': nan, 'ACC-1': 0.5963099805885214, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 40.85500507532077, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 2.1185773572966678e-05, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 2.993098274550679e-06, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.7116774892598767, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 9.100401850471393, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.009429073089954937, 'ACC-36': 0.0, 'ACC-37': 4.18641761444063, 'ACC-38': 0.1182401706230921, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 55.81571076997661, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 2.880652508945455e-05, 'ACC-47': 17.016695165523483, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.48450941167402495, 'ACC-55': 0.0, 'ACC-56': 0.0327343084160549, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.9062128595712817, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.08192847660173408, 'ACC-69': 0.00491471330644858, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.009042743220838043, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 1.0590711776320779e-05, 'ACC-77': 0.00021832445153077096, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.006424408341244769, 'ACC-83': 6.900863086457003, 'ACC-84': 0.0, 'ACC-85': 74.15646078065133, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.00134175801042559, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0164702647518015, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 01:40:08] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 01:40:08] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 01:40:08] d2.evaluation.testing INFO: copypaste: 18.2689,0.9326,0.8594,0.0950,0.3110,1.0990,2.3359
[01/24 01:40:08] d2.utils.events INFO:  eta: 1 day, 16:47:37  iter: 999  total_loss: 79.52  loss_ce: 2.033  loss_mask: 6.148  loss_ce_0: 2.318  loss_mask_0: 5.907  loss_ce_1: 1.966  loss_mask_1: 5.71  loss_ce_2: 1.995  loss_mask_2: 5.78  loss_ce_3: 2.022  loss_mask_3: 6.002  loss_ce_4: 2.021  loss_mask_4: 5.916  loss_ce_5: 2.022  loss_mask_5: 5.773  loss_ce_6: 2.029  loss_mask_6: 5.845  loss_ce_7: 2.042  loss_mask_7: 6.106  loss_ce_8: 2.038  loss_mask_8: 6  time: 2.5163  data_time: 0.3696  lr: 9.8403e-05  max_mem: 18427M
[01/24 01:40:59] d2.utils.events INFO:  eta: 1 day, 16:47:21  iter: 1019  total_loss: 79.27  loss_ce: 2.024  loss_mask: 5.906  loss_ce_0: 2.305  loss_mask_0: 5.783  loss_ce_1: 1.958  loss_mask_1: 5.737  loss_ce_2: 2.003  loss_mask_2: 5.736  loss_ce_3: 2.035  loss_mask_3: 5.788  loss_ce_4: 2.042  loss_mask_4: 5.827  loss_ce_5: 2.035  loss_mask_5: 5.775  loss_ce_6: 2.05  loss_mask_6: 5.937  loss_ce_7: 2.047  loss_mask_7: 5.953  loss_ce_8: 2.041  loss_mask_8: 5.799  time: 2.5174  data_time: 0.3982  lr: 9.847e-05  max_mem: 18427M
[01/24 01:41:47] d2.utils.events INFO:  eta: 1 day, 16:46:32  iter: 1039  total_loss: 72.12  loss_ce: 1.976  loss_mask: 5.301  loss_ce_0: 2.297  loss_mask_0: 5.101  loss_ce_1: 1.929  loss_mask_1: 5.183  loss_ce_2: 1.966  loss_mask_2: 5.146  loss_ce_3: 1.979  loss_mask_3: 5.147  loss_ce_4: 2.004  loss_mask_4: 5.355  loss_ce_5: 2.002  loss_mask_5: 5.24  loss_ce_6: 2.016  loss_mask_6: 5.216  loss_ce_7: 1.977  loss_mask_7: 5.401  loss_ce_8: 1.987  loss_mask_8: 5.454  time: 2.5145  data_time: 0.3460  lr: 9.844e-05  max_mem: 18427M
[01/24 01:42:38] d2.utils.events INFO:  eta: 1 day, 16:46:09  iter: 1059  total_loss: 76.8  loss_ce: 2.018  loss_mask: 5.701  loss_ce_0: 2.284  loss_mask_0: 5.497  loss_ce_1: 1.955  loss_mask_1: 5.557  loss_ce_2: 1.995  loss_mask_2: 5.511  loss_ce_3: 2.004  loss_mask_3: 5.493  loss_ce_4: 2.029  loss_mask_4: 5.471  loss_ce_5: 2.015  loss_mask_5: 5.641  loss_ce_6: 2  loss_mask_6: 5.617  loss_ce_7: 2.015  loss_mask_7: 5.706  loss_ce_8: 2.018  loss_mask_8: 5.681  time: 2.5153  data_time: 0.4114  lr: 9.841e-05  max_mem: 18427M
[01/24 01:43:28] d2.utils.events INFO:  eta: 1 day, 16:49:06  iter: 1079  total_loss: 74.09  loss_ce: 2.009  loss_mask: 5.426  loss_ce_0: 2.285  loss_mask_0: 5.302  loss_ce_1: 1.922  loss_mask_1: 5.237  loss_ce_2: 1.969  loss_mask_2: 5.296  loss_ce_3: 1.992  loss_mask_3: 5.328  loss_ce_4: 2.004  loss_mask_4: 5.481  loss_ce_5: 1.988  loss_mask_5: 5.275  loss_ce_6: 1.998  loss_mask_6: 5.382  loss_ce_7: 1.995  loss_mask_7: 5.502  loss_ce_8: 2.011  loss_mask_8: 5.581  time: 2.5149  data_time: 0.3820  lr: 9.838e-05  max_mem: 18427M
[01/24 01:44:17] d2.utils.events INFO:  eta: 1 day, 16:54:19  iter: 1099  total_loss: 76.67  loss_ce: 2.009  loss_mask: 5.703  loss_ce_0: 2.269  loss_mask_0: 5.689  loss_ce_1: 1.945  loss_mask_1: 5.467  loss_ce_2: 1.995  loss_mask_2: 5.437  loss_ce_3: 2.011  loss_mask_3: 5.715  loss_ce_4: 2.012  loss_mask_4: 5.593  loss_ce_5: 2.002  loss_mask_5: 5.629  loss_ce_6: 1.996  loss_mask_6: 5.703  loss_ce_7: 2  loss_mask_7: 5.579  loss_ce_8: 2.025  loss_mask_8: 5.545  time: 2.5140  data_time: 0.4069  lr: 9.835e-05  max_mem: 18427M
[01/24 01:45:09] d2.utils.events INFO:  eta: 1 day, 16:54:54  iter: 1119  total_loss: 72.61  loss_ce: 1.967  loss_mask: 5.344  loss_ce_0: 2.273  loss_mask_0: 5.29  loss_ce_1: 1.92  loss_mask_1: 5.121  loss_ce_2: 1.967  loss_mask_2: 5.161  loss_ce_3: 1.985  loss_mask_3: 5.272  loss_ce_4: 1.978  loss_mask_4: 5.186  loss_ce_5: 1.964  loss_mask_5: 5.274  loss_ce_6: 1.964  loss_mask_6: 5.238  loss_ce_7: 1.962  loss_mask_7: 5.29  loss_ce_8: 1.966  loss_mask_8: 5.336  time: 2.5154  data_time: 0.4252  lr: 9.832e-05  max_mem: 18427M
[01/24 01:45:58] d2.utils.events INFO:  eta: 1 day, 16:54:03  iter: 1139  total_loss: 74.63  loss_ce: 2.003  loss_mask: 5.415  loss_ce_0: 2.243  loss_mask_0: 5.608  loss_ce_1: 1.925  loss_mask_1: 5.4  loss_ce_2: 1.983  loss_mask_2: 5.463  loss_ce_3: 2  loss_mask_3: 5.467  loss_ce_4: 2.007  loss_mask_4: 5.347  loss_ce_5: 1.99  loss_mask_5: 5.399  loss_ce_6: 2.007  loss_mask_6: 5.574  loss_ce_7: 1.999  loss_mask_7: 5.51  loss_ce_8: 2.005  loss_mask_8: 5.437  time: 2.5139  data_time: 0.3689  lr: 9.829e-05  max_mem: 18427M
[01/24 01:46:45] d2.utils.events INFO:  eta: 1 day, 16:51:22  iter: 1159  total_loss: 74.74  loss_ce: 1.987  loss_mask: 5.598  loss_ce_0: 2.231  loss_mask_0: 5.443  loss_ce_1: 1.908  loss_mask_1: 5.383  loss_ce_2: 1.966  loss_mask_2: 5.419  loss_ce_3: 1.974  loss_mask_3: 5.412  loss_ce_4: 1.997  loss_mask_4: 5.372  loss_ce_5: 1.976  loss_mask_5: 5.506  loss_ce_6: 1.99  loss_mask_6: 5.445  loss_ce_7: 1.993  loss_mask_7: 5.594  loss_ce_8: 2  loss_mask_8: 5.543  time: 2.5115  data_time: 0.3463  lr: 9.826e-05  max_mem: 18427M
[01/24 01:47:38] d2.utils.events INFO:  eta: 1 day, 16:50:59  iter: 1179  total_loss: 74.25  loss_ce: 1.983  loss_mask: 5.374  loss_ce_0: 2.225  loss_mask_0: 5.319  loss_ce_1: 1.919  loss_mask_1: 5.307  loss_ce_2: 2.003  loss_mask_2: 5.459  loss_ce_3: 2.013  loss_mask_3: 5.361  loss_ce_4: 2.008  loss_mask_4: 5.312  loss_ce_5: 2.005  loss_mask_5: 5.488  loss_ce_6: 2.013  loss_mask_6: 5.525  loss_ce_7: 2.013  loss_mask_7: 5.479  loss_ce_8: 2.011  loss_mask_8: 5.413  time: 2.5136  data_time: 0.3943  lr: 9.823e-05  max_mem: 18427M
[01/24 01:48:27] d2.utils.events INFO:  eta: 1 day, 16:48:21  iter: 1199  total_loss: 73.36  loss_ce: 1.984  loss_mask: 5.324  loss_ce_0: 2.209  loss_mask_0: 5.296  loss_ce_1: 1.92  loss_mask_1: 5.285  loss_ce_2: 1.995  loss_mask_2: 5.185  loss_ce_3: 2.005  loss_mask_3: 5.253  loss_ce_4: 1.997  loss_mask_4: 5.42  loss_ce_5: 1.996  loss_mask_5: 5.283  loss_ce_6: 2.002  loss_mask_6: 5.392  loss_ce_7: 2.001  loss_mask_7: 5.443  loss_ce_8: 1.986  loss_mask_8: 5.427  time: 2.5121  data_time: 0.3658  lr: 9.82e-05  max_mem: 18427M
[01/24 01:49:15] d2.utils.events INFO:  eta: 1 day, 16:45:28  iter: 1219  total_loss: 72.83  loss_ce: 1.972  loss_mask: 5.279  loss_ce_0: 2.212  loss_mask_0: 5.297  loss_ce_1: 1.9  loss_mask_1: 5.14  loss_ce_2: 1.961  loss_mask_2: 5.215  loss_ce_3: 1.975  loss_mask_3: 5.203  loss_ce_4: 1.976  loss_mask_4: 5.255  loss_ce_5: 1.957  loss_mask_5: 5.333  loss_ce_6: 1.96  loss_mask_6: 5.302  loss_ce_7: 1.968  loss_mask_7: 5.331  loss_ce_8: 1.973  loss_mask_8: 5.219  time: 2.5106  data_time: 0.3597  lr: 9.817e-05  max_mem: 18427M
[01/24 01:50:07] d2.utils.events INFO:  eta: 1 day, 16:43:52  iter: 1239  total_loss: 71.82  loss_ce: 1.993  loss_mask: 5.25  loss_ce_0: 2.191  loss_mask_0: 5.37  loss_ce_1: 1.895  loss_mask_1: 5.037  loss_ce_2: 1.976  loss_mask_2: 5.109  loss_ce_3: 1.995  loss_mask_3: 5.176  loss_ce_4: 1.972  loss_mask_4: 5.161  loss_ce_5: 1.976  loss_mask_5: 5.222  loss_ce_6: 1.957  loss_mask_6: 5.268  loss_ce_7: 1.977  loss_mask_7: 5.243  loss_ce_8: 1.984  loss_mask_8: 5.188  time: 2.5117  data_time: 0.3963  lr: 9.814e-05  max_mem: 18427M
[01/24 01:50:55] d2.utils.events INFO:  eta: 1 day, 16:43:48  iter: 1259  total_loss: 74.16  loss_ce: 1.972  loss_mask: 5.489  loss_ce_0: 2.178  loss_mask_0: 5.544  loss_ce_1: 1.907  loss_mask_1: 5.203  loss_ce_2: 1.985  loss_mask_2: 5.225  loss_ce_3: 1.979  loss_mask_3: 5.239  loss_ce_4: 1.988  loss_mask_4: 5.45  loss_ce_5: 1.988  loss_mask_5: 5.323  loss_ce_6: 1.986  loss_mask_6: 5.466  loss_ce_7: 1.984  loss_mask_7: 5.347  loss_ce_8: 1.975  loss_mask_8: 5.377  time: 2.5102  data_time: 0.3893  lr: 9.811e-05  max_mem: 18427M
[01/24 01:51:45] d2.utils.events INFO:  eta: 1 day, 16:42:12  iter: 1279  total_loss: 68.44  loss_ce: 2.054  loss_mask: 4.947  loss_ce_0: 2.19  loss_mask_0: 4.889  loss_ce_1: 1.898  loss_mask_1: 4.799  loss_ce_2: 1.99  loss_mask_2: 4.892  loss_ce_3: 1.98  loss_mask_3: 4.819  loss_ce_4: 1.986  loss_mask_4: 5.011  loss_ce_5: 2.039  loss_mask_5: 4.912  loss_ce_6: 1.978  loss_mask_6: 4.982  loss_ce_7: 1.944  loss_mask_7: 4.877  loss_ce_8: 1.969  loss_mask_8: 4.987  time: 2.5103  data_time: 0.3925  lr: 9.8079e-05  max_mem: 18427M
[01/24 01:52:35] d2.utils.events INFO:  eta: 1 day, 16:39:41  iter: 1299  total_loss: 74.39  loss_ce: 2.062  loss_mask: 5.539  loss_ce_0: 2.163  loss_mask_0: 5.447  loss_ce_1: 1.952  loss_mask_1: 5.328  loss_ce_2: 2.076  loss_mask_2: 5.541  loss_ce_3: 2.019  loss_mask_3: 5.421  loss_ce_4: 2.023  loss_mask_4: 5.488  loss_ce_5: 2.017  loss_mask_5: 5.46  loss_ce_6: 2.03  loss_mask_6: 5.532  loss_ce_7: 2.027  loss_mask_7: 5.384  loss_ce_8: 2.027  loss_mask_8: 5.558  time: 2.5101  data_time: 0.3842  lr: 9.8049e-05  max_mem: 18427M
[01/24 01:53:23] d2.utils.events INFO:  eta: 1 day, 16:38:02  iter: 1319  total_loss: 72.12  loss_ce: 2.008  loss_mask: 5.27  loss_ce_0: 2.152  loss_mask_0: 5.249  loss_ce_1: 1.894  loss_mask_1: 5.099  loss_ce_2: 1.973  loss_mask_2: 5.208  loss_ce_3: 1.988  loss_mask_3: 5.133  loss_ce_4: 1.991  loss_mask_4: 5.142  loss_ce_5: 1.998  loss_mask_5: 5.165  loss_ce_6: 2.002  loss_mask_6: 5.264  loss_ce_7: 1.984  loss_mask_7: 5.285  loss_ce_8: 1.981  loss_mask_8: 5.319  time: 2.5081  data_time: 0.3434  lr: 9.8019e-05  max_mem: 18427M
[01/24 01:54:15] d2.utils.events INFO:  eta: 1 day, 16:36:36  iter: 1339  total_loss: 69.55  loss_ce: 2.017  loss_mask: 5.024  loss_ce_0: 2.136  loss_mask_0: 5.071  loss_ce_1: 1.914  loss_mask_1: 5.025  loss_ce_2: 1.991  loss_mask_2: 4.918  loss_ce_3: 1.99  loss_mask_3: 4.897  loss_ce_4: 1.976  loss_mask_4: 4.945  loss_ce_5: 1.981  loss_mask_5: 4.958  loss_ce_6: 1.962  loss_mask_6: 5.038  loss_ce_7: 1.985  loss_mask_7: 5.056  loss_ce_8: 1.988  loss_mask_8: 4.986  time: 2.5095  data_time: 0.4186  lr: 9.7989e-05  max_mem: 18427M
[01/24 01:55:04] d2.utils.events INFO:  eta: 1 day, 16:34:03  iter: 1359  total_loss: 70.34  loss_ce: 1.992  loss_mask: 5.213  loss_ce_0: 2.127  loss_mask_0: 5.105  loss_ce_1: 1.88  loss_mask_1: 5.033  loss_ce_2: 1.991  loss_mask_2: 4.985  loss_ce_3: 1.991  loss_mask_3: 5.053  loss_ce_4: 1.972  loss_mask_4: 5.07  loss_ce_5: 1.984  loss_mask_5: 5.147  loss_ce_6: 1.977  loss_mask_6: 5.137  loss_ce_7: 1.98  loss_mask_7: 5.03  loss_ce_8: 1.975  loss_mask_8: 5.102  time: 2.5089  data_time: 0.3999  lr: 9.7959e-05  max_mem: 18427M
[01/24 01:55:51] d2.utils.events INFO:  eta: 1 day, 16:30:06  iter: 1379  total_loss: 72.91  loss_ce: 2.004  loss_mask: 5.212  loss_ce_0: 2.154  loss_mask_0: 5.291  loss_ce_1: 1.897  loss_mask_1: 5.166  loss_ce_2: 2.006  loss_mask_2: 5.315  loss_ce_3: 1.989  loss_mask_3: 5.242  loss_ce_4: 1.967  loss_mask_4: 5.313  loss_ce_5: 1.985  loss_mask_5: 5.377  loss_ce_6: 1.956  loss_mask_6: 5.515  loss_ce_7: 1.964  loss_mask_7: 5.387  loss_ce_8: 1.965  loss_mask_8: 5.219  time: 2.5065  data_time: 0.3527  lr: 9.7929e-05  max_mem: 18427M
[01/24 01:56:44] d2.utils.events INFO:  eta: 1 day, 16:27:17  iter: 1399  total_loss: 72.31  loss_ce: 2.064  loss_mask: 5.239  loss_ce_0: 2.109  loss_mask_0: 5.361  loss_ce_1: 1.888  loss_mask_1: 5.15  loss_ce_2: 2.002  loss_mask_2: 5.143  loss_ce_3: 2.002  loss_mask_3: 5.197  loss_ce_4: 1.994  loss_mask_4: 5.14  loss_ce_5: 1.99  loss_mask_5: 5.201  loss_ce_6: 1.98  loss_mask_6: 5.252  loss_ce_7: 1.969  loss_mask_7: 5.171  loss_ce_8: 1.996  loss_mask_8: 5.161  time: 2.5080  data_time: 0.3935  lr: 9.7899e-05  max_mem: 18427M
[01/24 01:57:31] d2.utils.events INFO:  eta: 1 day, 16:26:08  iter: 1419  total_loss: 71.33  loss_ce: 2.011  loss_mask: 5.168  loss_ce_0: 2.107  loss_mask_0: 5.166  loss_ce_1: 1.885  loss_mask_1: 5.082  loss_ce_2: 1.956  loss_mask_2: 4.943  loss_ce_3: 1.964  loss_mask_3: 5.196  loss_ce_4: 1.982  loss_mask_4: 5.107  loss_ce_5: 1.983  loss_mask_5: 5.212  loss_ce_6: 1.962  loss_mask_6: 5.16  loss_ce_7: 1.961  loss_mask_7: 5.152  loss_ce_8: 1.98  loss_mask_8: 5.064  time: 2.5062  data_time: 0.3633  lr: 9.7869e-05  max_mem: 18427M
[01/24 01:58:20] d2.utils.events INFO:  eta: 1 day, 16:21:32  iter: 1439  total_loss: 72.62  loss_ce: 2.048  loss_mask: 5.612  loss_ce_0: 2.1  loss_mask_0: 5.217  loss_ce_1: 1.935  loss_mask_1: 5.184  loss_ce_2: 2.055  loss_mask_2: 5.365  loss_ce_3: 2.022  loss_mask_3: 5.171  loss_ce_4: 1.98  loss_mask_4: 5.24  loss_ce_5: 1.997  loss_mask_5: 5.324  loss_ce_6: 1.972  loss_mask_6: 5.213  loss_ce_7: 1.981  loss_mask_7: 5.199  loss_ce_8: 1.981  loss_mask_8: 5.272  time: 2.5051  data_time: 0.3800  lr: 9.7839e-05  max_mem: 18427M
[01/24 01:59:13] d2.utils.events INFO:  eta: 1 day, 16:22:14  iter: 1459  total_loss: 72.34  loss_ce: 2.051  loss_mask: 5.639  loss_ce_0: 2.083  loss_mask_0: 5.378  loss_ce_1: 1.878  loss_mask_1: 5.156  loss_ce_2: 1.989  loss_mask_2: 5.228  loss_ce_3: 1.995  loss_mask_3: 5.123  loss_ce_4: 1.977  loss_mask_4: 5.209  loss_ce_5: 1.986  loss_mask_5: 5.192  loss_ce_6: 1.963  loss_mask_6: 5.252  loss_ce_7: 1.984  loss_mask_7: 5.335  loss_ce_8: 1.986  loss_mask_8: 5.297  time: 2.5071  data_time: 0.3964  lr: 9.7809e-05  max_mem: 18427M
[01/24 02:00:01] d2.utils.events INFO:  eta: 1 day, 16:19:11  iter: 1479  total_loss: 70.21  loss_ce: 1.988  loss_mask: 5.396  loss_ce_0: 2.084  loss_mask_0: 5.251  loss_ce_1: 1.845  loss_mask_1: 5.026  loss_ce_2: 2.008  loss_mask_2: 5.046  loss_ce_3: 2.003  loss_mask_3: 5.104  loss_ce_4: 1.962  loss_mask_4: 4.891  loss_ce_5: 1.963  loss_mask_5: 4.945  loss_ce_6: 1.945  loss_mask_6: 5.025  loss_ce_7: 1.939  loss_mask_7: 4.917  loss_ce_8: 1.942  loss_mask_8: 4.902  time: 2.5057  data_time: 0.3584  lr: 9.7779e-05  max_mem: 18427M
[01/24 02:00:52] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 02:00:53] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 02:00:53] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 02:04:30] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 18.298278948139284, 'error_1pix': 0.9386494505001883, 'error_3pix': 0.8600629436055193, 'mIoU': 0.08535646132274544, 'fwIoU': 0.20966366157704003, 'IoU-0': nan, 'IoU-1': 0.14253163587760484, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.008768911350975716, 'IoU-14': 3.853418033174333e-05, 'IoU-15': 0.0032264536987276784, 'IoU-16': 0.0010012457605146614, 'IoU-17': 0.0, 'IoU-18': 0.021717713064396398, 'IoU-19': 0.0, 'IoU-20': 0.9664618259502825, 'IoU-21': 1.751219751649205, 'IoU-22': 1.9311396126132845, 'IoU-23': 0.007526966094718781, 'IoU-24': 0.0, 'IoU-25': 0.8101316590267761, 'IoU-26': 0.0007962559921682449, 'IoU-27': 0.2845711368677432, 'IoU-28': 0.6981629912432952, 'IoU-29': 0.16693836013303626, 'IoU-30': 0.007943490098255113, 'IoU-31': 0.03350171111787939, 'IoU-32': 0.5618452696294867, 'IoU-33': 0.013116923452931037, 'IoU-34': 0.3142185112412745, 'IoU-35': 1.0256878220726926, 'IoU-36': 0.0020518905613499273, 'IoU-37': 0.1098737518014678, 'IoU-38': 0.5451040280041062, 'IoU-39': 0.00019612842489261968, 'IoU-40': 2.1626866970875276, 'IoU-41': 0.00044587364211208996, 'IoU-42': 0.0, 'IoU-43': 1.8198109791452938e-05, 'IoU-44': 4.6604399842520147e-05, 'IoU-45': 7.945502028600175e-05, 'IoU-46': 0.0008347763038013328, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0018628420059926272, 'IoU-52': 0.0, 'IoU-53': 0.08732303502368344, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 8.26371051281282e-05, 'IoU-57': 0.0016956596420190672, 'IoU-58': 0.04044731278200819, 'IoU-59': 0.04214804041063361, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.02490445706345184, 'IoU-63': 0.0, 'IoU-64': 8.556072458525627e-05, 'IoU-65': 0.0, 'IoU-66': 0.0005919425595269685, 'IoU-67': 0.2441948871051041, 'IoU-68': 0.03372994122557742, 'IoU-69': 0.0, 'IoU-70': 0.00014816058109426536, 'IoU-71': 0.6265485782967928, 'IoU-72': 0.02388436849817461, 'IoU-73': 0.0014220586205634525, 'IoU-74': 0.0031434049623596293, 'IoU-75': 0.8088767807067107, 'IoU-76': 0.7091031367517509, 'IoU-77': 0.0, 'IoU-78': 0.8404151606803094, 'IoU-79': 0.2647917067031559, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.35572927812043986, 'IoU-83': 0.15567283818000943, 'IoU-84': 0.09263551879772498, 'IoU-85': 0.40844158229959204, 'IoU-86': 2.3716394609974997e-05, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0003525328356133747, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.04830125141975613, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.7764104208280869, 'pACC': 2.0765082189823403, 'ACC-0': nan, 'ACC-1': 0.14256156479685703, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.008785778477795627, 'ACC-14': 3.853740279743007e-05, 'ACC-15': 0.003251402393413529, 'ACC-16': 0.001006324244715917, 'ACC-17': 0.0, 'ACC-18': 0.021779648281215046, 'ACC-19': 0.0, 'ACC-20': 1.6833543291647122, 'ACC-21': 8.164316066867732, 'ACC-22': 24.442767558715854, 'ACC-23': 0.007531461759498206, 'ACC-24': 0.0, 'ACC-25': 1.0811156822492256, 'ACC-26': 0.0007967321816701422, 'ACC-27': 0.35665921476778584, 'ACC-28': 0.8987874923834438, 'ACC-29': 0.18215384787435832, 'ACC-30': 0.008004964609061778, 'ACC-31': 0.034155456569922554, 'ACC-32': 0.8458226496599855, 'ACC-33': 0.013162794777832562, 'ACC-34': 0.3403964017261541, 'ACC-35': 2.0352131659470007, 'ACC-36': 0.0020551985782191044, 'ACC-37': 0.11603277543489757, 'ACC-38': 0.763142929311361, 'ACC-39': 0.0001961334314753326, 'ACC-40': 92.98918440752978, 'ACC-41': 0.0004469614393160623, 'ACC-42': 0.0, 'ACC-43': 1.8203591663293844e-05, 'ACC-44': 4.660639479889842e-05, 'ACC-45': 7.946488497817383e-05, 'ACC-46': 0.000835389227594182, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.00186528818350494, 'ACC-52': 0.0, 'ACC-53': 0.10678847431082553, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 8.264634092225943e-05, 'ACC-57': 0.001697500048916509, 'ACC-58': 0.049864695518508334, 'ACC-59': 0.04315331293999292, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.025893378515453307, 'ACC-63': 0.0, 'ACC-64': 8.558298511360048e-05, 'ACC-65': 0.0, 'ACC-66': 0.0005927970659407015, 'ACC-67': 0.3833577069256623, 'ACC-68': 0.03495039686499255, 'ACC-69': 0.0, 'ACC-70': 0.00014826368399671448, 'ACC-71': 2.28536523647574, 'ACC-72': 0.02424390639379855, 'ACC-73': 0.0014253708947660822, 'ACC-74': 0.0031480497287285246, 'ACC-75': 4.219684866539483, 'ACC-76': 1.194176887762602, 'ACC-77': 0.0, 'ACC-78': 4.279230564626923, 'ACC-79': 0.32658237519983274, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.46552770495156487, 'ACC-83': 0.27500036449317805, 'ACC-84': 0.0987862896425354, 'ACC-85': 1.0497747275460092, 'ACC-86': 2.3716535227652056e-05, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0003683018236391137, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.05528324831971626, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 02:04:30] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 02:04:30] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 02:04:30] d2.evaluation.testing INFO: copypaste: 18.2983,0.9386,0.8601,0.0854,0.2097,0.7764,2.0765
[01/24 02:04:30] d2.utils.events INFO:  eta: 1 day, 16:15:30  iter: 1499  total_loss: 72.09  loss_ce: 2.025  loss_mask: 5.28  loss_ce_0: 2.072  loss_mask_0: 5.222  loss_ce_1: 1.902  loss_mask_1: 5.185  loss_ce_2: 2.033  loss_mask_2: 5.132  loss_ce_3: 2.044  loss_mask_3: 5.296  loss_ce_4: 2.017  loss_mask_4: 5.121  loss_ce_5: 2.016  loss_mask_5: 5.105  loss_ce_6: 2.015  loss_mask_6: 5.202  loss_ce_7: 2.032  loss_mask_7: 5.339  loss_ce_8: 1.985  loss_mask_8: 5.342  time: 2.5061  data_time: 0.4003  lr: 9.7749e-05  max_mem: 18427M
[01/24 02:05:18] d2.utils.events INFO:  eta: 1 day, 16:14:12  iter: 1519  total_loss: 73.14  loss_ce: 2.114  loss_mask: 5.379  loss_ce_0: 2.064  loss_mask_0: 5.318  loss_ce_1: 1.872  loss_mask_1: 5.107  loss_ce_2: 2.023  loss_mask_2: 5.258  loss_ce_3: 2.019  loss_mask_3: 5.223  loss_ce_4: 2.01  loss_mask_4: 5.226  loss_ce_5: 2.048  loss_mask_5: 5.377  loss_ce_6: 2.033  loss_mask_6: 5.33  loss_ce_7: 2.134  loss_mask_7: 5.402  loss_ce_8: 2.034  loss_mask_8: 5.281  time: 2.5042  data_time: 0.3724  lr: 9.7719e-05  max_mem: 18427M
[01/24 02:06:11] d2.utils.events INFO:  eta: 1 day, 16:17:24  iter: 1539  total_loss: 72.52  loss_ce: 2.064  loss_mask: 5.363  loss_ce_0: 2.055  loss_mask_0: 5.178  loss_ce_1: 1.89  loss_mask_1: 5.058  loss_ce_2: 2.031  loss_mask_2: 5.256  loss_ce_3: 2.022  loss_mask_3: 5.233  loss_ce_4: 2.019  loss_mask_4: 5.149  loss_ce_5: 2.023  loss_mask_5: 5.182  loss_ce_6: 2.037  loss_mask_6: 5.394  loss_ce_7: 2.065  loss_mask_7: 5.345  loss_ce_8: 2.03  loss_mask_8: 5.35  time: 2.5061  data_time: 0.4161  lr: 9.7689e-05  max_mem: 18427M
[01/24 02:06:59] d2.utils.events INFO:  eta: 1 day, 16:15:52  iter: 1559  total_loss: 70.37  loss_ce: 1.964  loss_mask: 5.086  loss_ce_0: 2.053  loss_mask_0: 5.114  loss_ce_1: 1.902  loss_mask_1: 5.102  loss_ce_2: 2.062  loss_mask_2: 5.107  loss_ce_3: 2.044  loss_mask_3: 5.129  loss_ce_4: 2.004  loss_mask_4: 5.052  loss_ce_5: 1.996  loss_mask_5: 5.125  loss_ce_6: 1.993  loss_mask_6: 5.086  loss_ce_7: 1.989  loss_mask_7: 5.124  loss_ce_8: 1.967  loss_mask_8: 5.132  time: 2.5048  data_time: 0.3727  lr: 9.7658e-05  max_mem: 18427M
[01/24 02:07:47] d2.utils.events INFO:  eta: 1 day, 16:15:03  iter: 1579  total_loss: 74.04  loss_ce: 1.989  loss_mask: 5.2  loss_ce_0: 2.055  loss_mask_0: 5.447  loss_ce_1: 1.984  loss_mask_1: 5.344  loss_ce_2: 2.176  loss_mask_2: 5.676  loss_ce_3: 2.141  loss_mask_3: 5.415  loss_ce_4: 2.11  loss_mask_4: 5.459  loss_ce_5: 2.074  loss_mask_5: 5.488  loss_ce_6: 2.018  loss_mask_6: 5.13  loss_ce_7: 2.039  loss_mask_7: 5.066  loss_ce_8: 1.96  loss_mask_8: 5.098  time: 2.5034  data_time: 0.3537  lr: 9.7628e-05  max_mem: 18427M
[01/24 02:08:38] d2.utils.events INFO:  eta: 1 day, 16:16:35  iter: 1599  total_loss: 74.49  loss_ce: 1.996  loss_mask: 5.3  loss_ce_0: 2.067  loss_mask_0: 5.294  loss_ce_1: 1.99  loss_mask_1: 5.17  loss_ce_2: 2.128  loss_mask_2: 5.279  loss_ce_3: 2.16  loss_mask_3: 5.119  loss_ce_4: 2.177  loss_mask_4: 5.289  loss_ce_5: 2.204  loss_mask_5: 5.485  loss_ce_6: 2.149  loss_mask_6: 5.376  loss_ce_7: 2.206  loss_mask_7: 5.64  loss_ce_8: 1.989  loss_mask_8: 5.162  time: 2.5040  data_time: 0.3981  lr: 9.7598e-05  max_mem: 18427M
[01/24 02:09:27] d2.utils.events INFO:  eta: 1 day, 16:16:44  iter: 1619  total_loss: 76.28  loss_ce: 2.161  loss_mask: 5.371  loss_ce_0: 2.057  loss_mask_0: 5.534  loss_ce_1: 2.057  loss_mask_1: 5.204  loss_ce_2: 2.264  loss_mask_2: 5.274  loss_ce_3: 2.328  loss_mask_3: 5.229  loss_ce_4: 2.441  loss_mask_4: 5.456  loss_ce_5: 2.382  loss_mask_5: 5.758  loss_ce_6: 2.241  loss_mask_6: 5.591  loss_ce_7: 2.292  loss_mask_7: 5.494  loss_ce_8: 2.044  loss_mask_8: 5.295  time: 2.5033  data_time: 0.3935  lr: 9.7568e-05  max_mem: 18427M
[01/24 02:10:17] d2.utils.events INFO:  eta: 1 day, 16:13:17  iter: 1639  total_loss: 79.62  loss_ce: 2.356  loss_mask: 5.813  loss_ce_0: 2.036  loss_mask_0: 5.539  loss_ce_1: 2.09  loss_mask_1: 5.354  loss_ce_2: 2.269  loss_mask_2: 5.419  loss_ce_3: 2.416  loss_mask_3: 5.767  loss_ce_4: 2.45  loss_mask_4: 5.839  loss_ce_5: 2.449  loss_mask_5: 6.366  loss_ce_6: 2.293  loss_mask_6: 5.942  loss_ce_7: 2.375  loss_mask_7: 5.758  loss_ce_8: 2.155  loss_mask_8: 5.343  time: 2.5031  data_time: 0.3917  lr: 9.7538e-05  max_mem: 18427M
[01/24 02:11:09] d2.utils.events INFO:  eta: 1 day, 16:17:02  iter: 1659  total_loss: 83.35  loss_ce: 2.326  loss_mask: 5.978  loss_ce_0: 2.023  loss_mask_0: 6.04  loss_ce_1: 2.064  loss_mask_1: 5.781  loss_ce_2: 2.263  loss_mask_2: 5.855  loss_ce_3: 2.387  loss_mask_3: 6.107  loss_ce_4: 2.3  loss_mask_4: 6.178  loss_ce_5: 2.336  loss_mask_5: 6.052  loss_ce_6: 2.341  loss_mask_6: 6.612  loss_ce_7: 2.407  loss_mask_7: 6.078  loss_ce_8: 2.277  loss_mask_8: 5.808  time: 2.5044  data_time: 0.4109  lr: 9.7508e-05  max_mem: 18427M
[01/24 02:11:58] d2.utils.events INFO:  eta: 1 day, 16:11:38  iter: 1679  total_loss: 78.74  loss_ce: 2.273  loss_mask: 5.638  loss_ce_0: 2.028  loss_mask_0: 5.411  loss_ce_1: 2.075  loss_mask_1: 5.452  loss_ce_2: 2.269  loss_mask_2: 5.248  loss_ce_3: 2.37  loss_mask_3: 5.5  loss_ce_4: 2.251  loss_mask_4: 5.462  loss_ce_5: 2.26  loss_mask_5: 5.977  loss_ce_6: 2.306  loss_mask_6: 5.924  loss_ce_7: 2.347  loss_mask_7: 5.503  loss_ce_8: 2.241  loss_mask_8: 5.721  time: 2.5039  data_time: 0.3641  lr: 9.7478e-05  max_mem: 18427M
[01/24 02:12:50] d2.utils.events INFO:  eta: 1 day, 16:14:33  iter: 1699  total_loss: 77.27  loss_ce: 2.184  loss_mask: 5.632  loss_ce_0: 2.018  loss_mask_0: 5.624  loss_ce_1: 1.978  loss_mask_1: 5.46  loss_ce_2: 2.184  loss_mask_2: 5.371  loss_ce_3: 2.233  loss_mask_3: 5.465  loss_ce_4: 2.208  loss_mask_4: 5.706  loss_ce_5: 2.198  loss_mask_5: 5.595  loss_ce_6: 2.219  loss_mask_6: 5.538  loss_ce_7: 2.179  loss_mask_7: 5.511  loss_ce_8: 2.156  loss_mask_8: 5.703  time: 2.5048  data_time: 0.3986  lr: 9.7448e-05  max_mem: 18427M
[01/24 02:13:39] d2.utils.events INFO:  eta: 1 day, 16:10:32  iter: 1719  total_loss: 74.95  loss_ce: 2.163  loss_mask: 5.279  loss_ce_0: 2.014  loss_mask_0: 5.521  loss_ce_1: 1.961  loss_mask_1: 5.173  loss_ce_2: 2.148  loss_mask_2: 5.176  loss_ce_3: 2.176  loss_mask_3: 5.309  loss_ce_4: 2.17  loss_mask_4: 5.377  loss_ce_5: 2.182  loss_mask_5: 5.691  loss_ce_6: 2.173  loss_mask_6: 5.508  loss_ce_7: 2.157  loss_mask_7: 5.158  loss_ce_8: 2.121  loss_mask_8: 5.201  time: 2.5042  data_time: 0.3842  lr: 9.7418e-05  max_mem: 18427M
[01/24 02:14:28] d2.utils.events INFO:  eta: 1 day, 16:06:54  iter: 1739  total_loss: 78.71  loss_ce: 2.172  loss_mask: 5.839  loss_ce_0: 2.02  loss_mask_0: 5.715  loss_ce_1: 2.017  loss_mask_1: 5.594  loss_ce_2: 2.14  loss_mask_2: 5.439  loss_ce_3: 2.186  loss_mask_3: 5.695  loss_ce_4: 2.155  loss_mask_4: 5.731  loss_ce_5: 2.173  loss_mask_5: 5.884  loss_ce_6: 2.18  loss_mask_6: 5.921  loss_ce_7: 2.17  loss_mask_7: 5.729  loss_ce_8: 2.14  loss_mask_8: 5.685  time: 2.5036  data_time: 0.3740  lr: 9.7388e-05  max_mem: 18427M
[01/24 02:15:21] d2.utils.events INFO:  eta: 1 day, 16:07:22  iter: 1759  total_loss: 75.02  loss_ce: 2.142  loss_mask: 5.382  loss_ce_0: 2.029  loss_mask_0: 5.635  loss_ce_1: 1.98  loss_mask_1: 5.205  loss_ce_2: 2.096  loss_mask_2: 5.252  loss_ce_3: 2.149  loss_mask_3: 5.304  loss_ce_4: 2.148  loss_mask_4: 5.486  loss_ce_5: 2.151  loss_mask_5: 5.443  loss_ce_6: 2.148  loss_mask_6: 5.427  loss_ce_7: 2.165  loss_mask_7: 5.652  loss_ce_8: 2.111  loss_mask_8: 5.663  time: 2.5052  data_time: 0.4427  lr: 9.7358e-05  max_mem: 18427M
[01/24 02:16:10] d2.utils.events INFO:  eta: 1 day, 16:08:03  iter: 1779  total_loss: 78.5  loss_ce: 2.161  loss_mask: 5.978  loss_ce_0: 2.045  loss_mask_0: 5.908  loss_ce_1: 1.968  loss_mask_1: 5.399  loss_ce_2: 2.091  loss_mask_2: 5.428  loss_ce_3: 2.129  loss_mask_3: 5.433  loss_ce_4: 2.101  loss_mask_4: 5.601  loss_ce_5: 2.138  loss_mask_5: 5.709  loss_ce_6: 2.108  loss_mask_6: 5.635  loss_ce_7: 2.12  loss_mask_7: 5.677  loss_ce_8: 2.148  loss_mask_8: 5.77  time: 2.5046  data_time: 0.3774  lr: 9.7328e-05  max_mem: 18427M
[01/24 02:17:00] d2.utils.events INFO:  eta: 1 day, 16:07:54  iter: 1799  total_loss: 78.89  loss_ce: 2.167  loss_mask: 6.022  loss_ce_0: 2.03  loss_mask_0: 6.257  loss_ce_1: 1.958  loss_mask_1: 5.439  loss_ce_2: 2.083  loss_mask_2: 5.512  loss_ce_3: 2.098  loss_mask_3: 5.477  loss_ce_4: 2.108  loss_mask_4: 6.022  loss_ce_5: 2.149  loss_mask_5: 6.007  loss_ce_6: 2.11  loss_mask_6: 5.812  loss_ce_7: 2.088  loss_mask_7: 5.965  loss_ce_8: 2.108  loss_mask_8: 5.836  time: 2.5046  data_time: 0.3759  lr: 9.7297e-05  max_mem: 18427M
[01/24 02:17:52] d2.utils.events INFO:  eta: 1 day, 16:02:12  iter: 1819  total_loss: 74.77  loss_ce: 2.183  loss_mask: 5.603  loss_ce_0: 2.049  loss_mask_0: 5.684  loss_ce_1: 1.973  loss_mask_1: 5.178  loss_ce_2: 2.092  loss_mask_2: 5.374  loss_ce_3: 2.111  loss_mask_3: 5.219  loss_ce_4: 2.092  loss_mask_4: 5.45  loss_ce_5: 2.116  loss_mask_5: 5.582  loss_ce_6: 2.109  loss_mask_6: 5.265  loss_ce_7: 2.113  loss_mask_7: 5.35  loss_ce_8: 2.106  loss_mask_8: 5.425  time: 2.5056  data_time: 0.4028  lr: 9.7267e-05  max_mem: 18427M
[01/24 02:18:42] d2.utils.events INFO:  eta: 1 day, 16:01:11  iter: 1839  total_loss: 74.64  loss_ce: 2.132  loss_mask: 5.463  loss_ce_0: 2.064  loss_mask_0: 5.644  loss_ce_1: 1.962  loss_mask_1: 5.233  loss_ce_2: 2.083  loss_mask_2: 5.416  loss_ce_3: 2.087  loss_mask_3: 5.353  loss_ce_4: 2.079  loss_mask_4: 5.496  loss_ce_5: 2.094  loss_mask_5: 5.476  loss_ce_6: 2.081  loss_mask_6: 5.433  loss_ce_7: 2.083  loss_mask_7: 5.481  loss_ce_8: 2.089  loss_mask_8: 5.317  time: 2.5055  data_time: 0.3654  lr: 9.7237e-05  max_mem: 18427M
[01/24 02:19:31] d2.utils.events INFO:  eta: 1 day, 16:00:33  iter: 1859  total_loss: 73.39  loss_ce: 2.152  loss_mask: 5.1  loss_ce_0: 2.034  loss_mask_0: 5.515  loss_ce_1: 1.981  loss_mask_1: 5.121  loss_ce_2: 2.076  loss_mask_2: 5.154  loss_ce_3: 2.106  loss_mask_3: 5.094  loss_ce_4: 2.107  loss_mask_4: 5.534  loss_ce_5: 2.129  loss_mask_5: 5.337  loss_ce_6: 2.101  loss_mask_6: 5.223  loss_ce_7: 2.115  loss_mask_7: 5.515  loss_ce_8: 2.101  loss_mask_8: 5.175  time: 2.5047  data_time: 0.3900  lr: 9.7207e-05  max_mem: 18427M
[01/24 02:20:19] d2.utils.events INFO:  eta: 1 day, 15:56:21  iter: 1879  total_loss: 73.85  loss_ce: 2.094  loss_mask: 5.388  loss_ce_0: 2.052  loss_mask_0: 5.643  loss_ce_1: 1.922  loss_mask_1: 5.153  loss_ce_2: 2.006  loss_mask_2: 5.085  loss_ce_3: 2.042  loss_mask_3: 5.243  loss_ce_4: 2.039  loss_mask_4: 5.487  loss_ce_5: 2.073  loss_mask_5: 5.463  loss_ce_6: 2.035  loss_mask_6: 5.381  loss_ce_7: 2.063  loss_mask_7: 5.203  loss_ce_8: 2.047  loss_mask_8: 5.36  time: 2.5035  data_time: 0.4051  lr: 9.7177e-05  max_mem: 18427M
[01/24 02:21:07] d2.utils.events INFO:  eta: 1 day, 15:55:19  iter: 1899  total_loss: 74.91  loss_ce: 2.114  loss_mask: 5.283  loss_ce_0: 2.017  loss_mask_0: 5.579  loss_ce_1: 1.946  loss_mask_1: 5.261  loss_ce_2: 2.048  loss_mask_2: 5.237  loss_ce_3: 2.074  loss_mask_3: 5.303  loss_ce_4: 2.091  loss_mask_4: 5.419  loss_ce_5: 2.067  loss_mask_5: 5.601  loss_ce_6: 2.058  loss_mask_6: 5.396  loss_ce_7: 2.089  loss_mask_7: 5.492  loss_ce_8: 2.096  loss_mask_8: 5.411  time: 2.5025  data_time: 0.3671  lr: 9.7147e-05  max_mem: 18427M
[01/24 02:21:55] d2.utils.events INFO:  eta: 1 day, 15:50:27  iter: 1919  total_loss: 74.66  loss_ce: 2.142  loss_mask: 5.333  loss_ce_0: 1.993  loss_mask_0: 5.789  loss_ce_1: 1.964  loss_mask_1: 5.137  loss_ce_2: 2.039  loss_mask_2: 5.005  loss_ce_3: 2.078  loss_mask_3: 5.241  loss_ce_4: 2.067  loss_mask_4: 5.194  loss_ce_5: 2.078  loss_mask_5: 5.638  loss_ce_6: 2.081  loss_mask_6: 5.556  loss_ce_7: 2.115  loss_mask_7: 5.639  loss_ce_8: 2.112  loss_mask_8: 5.778  time: 2.5013  data_time: 0.3684  lr: 9.7117e-05  max_mem: 18427M
[01/24 02:22:42] d2.utils.events INFO:  eta: 1 day, 15:46:09  iter: 1939  total_loss: 71.68  loss_ce: 2.083  loss_mask: 4.972  loss_ce_0: 2.018  loss_mask_0: 5.297  loss_ce_1: 1.924  loss_mask_1: 4.866  loss_ce_2: 2.035  loss_mask_2: 4.916  loss_ce_3: 2.067  loss_mask_3: 4.969  loss_ce_4: 2.013  loss_mask_4: 4.979  loss_ce_5: 2.037  loss_mask_5: 5.25  loss_ce_6: 2.073  loss_mask_6: 5.072  loss_ce_7: 2.07  loss_mask_7: 5.048  loss_ce_8: 2.052  loss_mask_8: 5.188  time: 2.5000  data_time: 0.3737  lr: 9.7087e-05  max_mem: 18427M
[01/24 02:23:29] d2.utils.events INFO:  eta: 1 day, 15:39:14  iter: 1959  total_loss: 72.21  loss_ce: 2.051  loss_mask: 5.272  loss_ce_0: 1.988  loss_mask_0: 5.549  loss_ce_1: 1.896  loss_mask_1: 4.946  loss_ce_2: 2.024  loss_mask_2: 5.049  loss_ce_3: 2.089  loss_mask_3: 5.031  loss_ce_4: 2.038  loss_mask_4: 5.105  loss_ce_5: 2.052  loss_mask_5: 5.285  loss_ce_6: 2.047  loss_mask_6: 5.061  loss_ce_7: 2.059  loss_mask_7: 5.136  loss_ce_8: 2.07  loss_mask_8: 5.353  time: 2.4986  data_time: 0.3614  lr: 9.7057e-05  max_mem: 18427M
[01/24 02:24:17] d2.utils.events INFO:  eta: 1 day, 15:32:23  iter: 1979  total_loss: 71.14  loss_ce: 2.037  loss_mask: 5.079  loss_ce_0: 1.991  loss_mask_0: 5.296  loss_ce_1: 1.901  loss_mask_1: 5.068  loss_ce_2: 2.028  loss_mask_2: 4.903  loss_ce_3: 2.075  loss_mask_3: 5.046  loss_ce_4: 2.038  loss_mask_4: 4.978  loss_ce_5: 2.035  loss_mask_5: 5.261  loss_ce_6: 2.022  loss_mask_6: 5.074  loss_ce_7: 2.037  loss_mask_7: 5.152  loss_ce_8: 2.056  loss_mask_8: 5.309  time: 2.4971  data_time: 0.3843  lr: 9.7027e-05  max_mem: 18427M
[01/24 02:25:05] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 02:25:05] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 02:25:05] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 02:28:47] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 15.542638432974474, 'error_1pix': 0.918159607088211, 'error_3pix': 0.8230800230223547, 'mIoU': 0.12276942583585139, 'fwIoU': 0.2994610032832909, 'IoU-0': nan, 'IoU-1': 0.00015049415558332147, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 4.092089403140731, 'IoU-13': 0.7573307217262865, 'IoU-14': 0.013010351864165692, 'IoU-15': 0.045393713459011865, 'IoU-16': 2.650999369762819, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 1.2092667562652716e-05, 'IoU-20': 2.531692131866146, 'IoU-21': 1.5496746922192028, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 1.558949686956667e-05, 'IoU-25': 0.33976529878672174, 'IoU-26': 0.000203665176759639, 'IoU-27': 0.0, 'IoU-28': 0.01748516178134794, 'IoU-29': 0.2008379287897142, 'IoU-30': 0.00015855472881414268, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 2.5791511596845664, 'IoU-34': 0.03747337480614845, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0003580180021112265, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.006401388238821705, 'IoU-42': 0.833836605137688, 'IoU-43': 0.0, 'IoU-44': 0.00031541208463409454, 'IoU-45': 0.0048636497524690795, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.00030601857080758915, 'IoU-51': 0.0, 'IoU-52': 0.0006580670877460388, 'IoU-53': 0.0016873107149692529, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.010856418229220774, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.00017522080819030013, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0002452884433678553, 'IoU-67': 1.638808231712829, 'IoU-68': 1.095109527074622, 'IoU-69': 0.0, 'IoU-70': 0.0032634256168138447, 'IoU-71': 0.014653749001851816, 'IoU-72': 0.0, 'IoU-73': 0.014223337915436347, 'IoU-74': 0.00023957372429442, 'IoU-75': 0.00786115122216471, 'IoU-76': 3.177012997795577e-05, 'IoU-77': 0.0, 'IoU-78': 0.11928589994098032, 'IoU-79': 0.028516173855334854, 'IoU-80': 0.00878457990151545, 'IoU-81': 1.4765558351620804, 'IoU-82': 1.45853921955013, 'IoU-83': 0.12226279962446189, 'IoU-84': 0.0003174016233506026, 'IoU-85': 0.07948847911384187, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 1.3031604659141793, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.6456778927274244, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0025725713255528243, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.1655651800816835, 'pACC': 2.733110595717475, 'ACC-0': nan, 'ACC-1': 0.000150494397733282, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 49.4629906107846, 'ACC-13': 1.2766740680133077, 'ACC-14': 0.013049192780574238, 'ACC-15': 0.04579099115114948, 'ACC-16': 4.905102432023526, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 1.2094233185402719e-05, 'ACC-20': 30.595704164219757, 'ACC-21': 4.993412789317369, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 1.5590322737453632e-05, 'ACC-25': 0.6310449348280069, 'ACC-26': 0.0002037444892057234, 'ACC-27': 0.0, 'ACC-28': 0.01808693434849182, 'ACC-29': 0.3300022963460677, 'ACC-30': 0.0001585682880210325, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 45.49044164861377, 'ACC-34': 0.0397512133853428, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.00035824870631700795, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.007137838743017116, 'ACC-42': 1.5580371865687055, 'ACC-43': 0.0, 'ACC-44': 0.0003154894417156201, 'ACC-45': 0.004911686700079507, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.00030611165578055125, 'ACC-51': 0.0, 'ACC-52': 0.0006584902386661287, 'ACC-53': 0.0016978192002128805, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.01097543924757468, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.00017523355866524415, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0002452953376306351, 'ACC-67': 16.17896910602206, 'ACC-68': 7.364005470815825, 'ACC-69': 0.0, 'ACC-70': 0.003272391311070341, 'ACC-71': 0.015315007880778895, 'ACC-72': 0.0, 'ACC-73': 0.014364202815472148, 'ACC-74': 0.00023964392398625445, 'ACC-75': 0.007906182875251574, 'ACC-76': 3.177213532896233e-05, 'ACC-77': 0.0, 'ACC-78': 0.12843370773106808, 'ACC-79': 0.04288196666277944, 'ACC-80': 0.009189193552614104, 'ACC-81': 12.22094431462233, 'ACC-82': 4.971625717345384, 'ACC-83': 0.13421139647186187, 'ACC-84': 0.0003175678656706075, 'ACC-85': 0.08373941626822165, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 40.507847347923935, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 2.715234849203627, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0025747133147953974, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 02:28:47] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 02:28:47] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 02:28:47] d2.evaluation.testing INFO: copypaste: 15.5426,0.9182,0.8231,0.1228,0.2995,1.1656,2.7331
[01/24 02:28:48] d2.utils.events INFO:  eta: 1 day, 15:30:17  iter: 1999  total_loss: 73  loss_ce: 2.022  loss_mask: 5.474  loss_ce_0: 1.954  loss_mask_0: 5.417  loss_ce_1: 1.886  loss_mask_1: 4.901  loss_ce_2: 1.99  loss_mask_2: 4.941  loss_ce_3: 2.036  loss_mask_3: 5.149  loss_ce_4: 2.022  loss_mask_4: 5.222  loss_ce_5: 2.048  loss_mask_5: 5.301  loss_ce_6: 2.026  loss_mask_6: 5.181  loss_ce_7: 2.047  loss_mask_7: 5.15  loss_ce_8: 2.033  loss_mask_8: 5.418  time: 2.4962  data_time: 0.3650  lr: 9.6996e-05  max_mem: 18427M
[01/24 02:29:39] d2.utils.events INFO:  eta: 1 day, 15:28:32  iter: 2019  total_loss: 73.28  loss_ce: 2.029  loss_mask: 5.53  loss_ce_0: 1.985  loss_mask_0: 5.566  loss_ce_1: 1.928  loss_mask_1: 5.028  loss_ce_2: 2.034  loss_mask_2: 5.176  loss_ce_3: 2.084  loss_mask_3: 5.106  loss_ce_4: 2.085  loss_mask_4: 5.208  loss_ce_5: 2.117  loss_mask_5: 5.368  loss_ce_6: 2.096  loss_mask_6: 5.501  loss_ce_7: 2.077  loss_mask_7: 5.335  loss_ce_8: 2.068  loss_mask_8: 5.696  time: 2.4970  data_time: 0.4154  lr: 9.6966e-05  max_mem: 18427M
[01/24 02:30:27] d2.utils.events INFO:  eta: 1 day, 15:27:59  iter: 2039  total_loss: 75.93  loss_ce: 2.013  loss_mask: 5.741  loss_ce_0: 1.982  loss_mask_0: 5.638  loss_ce_1: 1.915  loss_mask_1: 5.265  loss_ce_2: 2.018  loss_mask_2: 5.387  loss_ce_3: 2.083  loss_mask_3: 5.369  loss_ce_4: 2.14  loss_mask_4: 5.573  loss_ce_5: 2.225  loss_mask_5: 5.606  loss_ce_6: 2.074  loss_mask_6: 5.72  loss_ce_7: 2.065  loss_mask_7: 5.502  loss_ce_8: 2.044  loss_mask_8: 5.447  time: 2.4959  data_time: 0.3522  lr: 9.6936e-05  max_mem: 18427M
[01/24 02:31:14] d2.utils.events INFO:  eta: 1 day, 15:23:11  iter: 2059  total_loss: 72.67  loss_ce: 2.034  loss_mask: 5.619  loss_ce_0: 1.969  loss_mask_0: 5.33  loss_ce_1: 1.906  loss_mask_1: 5.021  loss_ce_2: 1.992  loss_mask_2: 4.91  loss_ce_3: 2.021  loss_mask_3: 4.939  loss_ce_4: 2.024  loss_mask_4: 5.319  loss_ce_5: 2.06  loss_mask_5: 5.217  loss_ce_6: 2.05  loss_mask_6: 5.252  loss_ce_7: 2.081  loss_mask_7: 5.331  loss_ce_8: 2.059  loss_mask_8: 5.408  time: 2.4947  data_time: 0.3422  lr: 9.6906e-05  max_mem: 18427M
[01/24 02:32:08] d2.utils.events INFO:  eta: 1 day, 15:24:44  iter: 2079  total_loss: 72.38  loss_ce: 2.032  loss_mask: 5.247  loss_ce_0: 1.971  loss_mask_0: 5.365  loss_ce_1: 1.916  loss_mask_1: 4.977  loss_ce_2: 2.023  loss_mask_2: 4.945  loss_ce_3: 2.054  loss_mask_3: 5.186  loss_ce_4: 2.043  loss_mask_4: 5.521  loss_ce_5: 2.042  loss_mask_5: 5.374  loss_ce_6: 2.031  loss_mask_6: 5.18  loss_ce_7: 2.075  loss_mask_7: 5.071  loss_ce_8: 2.06  loss_mask_8: 5.069  time: 2.4963  data_time: 0.4269  lr: 9.6876e-05  max_mem: 18427M
[01/24 02:32:56] d2.utils.events INFO:  eta: 1 day, 15:22:10  iter: 2099  total_loss: 75.15  loss_ce: 2.036  loss_mask: 5.771  loss_ce_0: 1.967  loss_mask_0: 5.488  loss_ce_1: 1.942  loss_mask_1: 5.253  loss_ce_2: 2.035  loss_mask_2: 5.113  loss_ce_3: 2.105  loss_mask_3: 5.309  loss_ce_4: 2.055  loss_mask_4: 5.381  loss_ce_5: 2.05  loss_mask_5: 5.454  loss_ce_6: 2.039  loss_mask_6: 5.524  loss_ce_7: 2.131  loss_mask_7: 5.304  loss_ce_8: 2.13  loss_mask_8: 5.98  time: 2.4957  data_time: 0.3744  lr: 9.6846e-05  max_mem: 18445M
[01/24 02:33:46] d2.utils.events INFO:  eta: 1 day, 15:15:59  iter: 2119  total_loss: 80.41  loss_ce: 2.134  loss_mask: 5.855  loss_ce_0: 1.964  loss_mask_0: 5.638  loss_ce_1: 2.037  loss_mask_1: 5.396  loss_ce_2: 2.27  loss_mask_2: 5.442  loss_ce_3: 2.335  loss_mask_3: 6.244  loss_ce_4: 2.198  loss_mask_4: 5.626  loss_ce_5: 2.187  loss_mask_5: 5.556  loss_ce_6: 2.293  loss_mask_6: 6.719  loss_ce_7: 2.27  loss_mask_7: 5.959  loss_ce_8: 2.289  loss_mask_8: 5.98  time: 2.4954  data_time: 0.3830  lr: 9.6816e-05  max_mem: 18445M
[01/24 02:34:36] d2.utils.events INFO:  eta: 1 day, 15:17:33  iter: 2139  total_loss: 80.76  loss_ce: 2.034  loss_mask: 6.318  loss_ce_0: 1.958  loss_mask_0: 5.669  loss_ce_1: 1.967  loss_mask_1: 5.642  loss_ce_2: 2.134  loss_mask_2: 5.462  loss_ce_3: 2.179  loss_mask_3: 5.867  loss_ce_4: 2.096  loss_mask_4: 5.833  loss_ce_5: 2.105  loss_mask_5: 6.108  loss_ce_6: 2.089  loss_mask_6: 6.066  loss_ce_7: 2.115  loss_mask_7: 6.849  loss_ce_8: 2.101  loss_mask_8: 6.133  time: 2.4956  data_time: 0.3785  lr: 9.6786e-05  max_mem: 18445M
[01/24 02:35:24] d2.utils.events INFO:  eta: 1 day, 15:19:06  iter: 2159  total_loss: 80.65  loss_ce: 2.145  loss_mask: 6.023  loss_ce_0: 1.955  loss_mask_0: 5.348  loss_ce_1: 2.065  loss_mask_1: 5.39  loss_ce_2: 2.169  loss_mask_2: 5.449  loss_ce_3: 2.158  loss_mask_3: 5.823  loss_ce_4: 2.164  loss_mask_4: 6.134  loss_ce_5: 2.115  loss_mask_5: 6.411  loss_ce_6: 2.243  loss_mask_6: 6.35  loss_ce_7: 2.12  loss_mask_7: 5.754  loss_ce_8: 2.18  loss_mask_8: 5.973  time: 2.4948  data_time: 0.3500  lr: 9.6756e-05  max_mem: 18445M
[01/24 02:36:16] d2.utils.events INFO:  eta: 1 day, 15:15:55  iter: 2179  total_loss: 73.27  loss_ce: 2.023  loss_mask: 5.24  loss_ce_0: 1.986  loss_mask_0: 5.611  loss_ce_1: 1.995  loss_mask_1: 5.328  loss_ce_2: 2.059  loss_mask_2: 5.197  loss_ce_3: 2.073  loss_mask_3: 5.325  loss_ce_4: 2.076  loss_mask_4: 5.472  loss_ce_5: 2.059  loss_mask_5: 5.659  loss_ce_6: 2.089  loss_mask_6: 5.526  loss_ce_7: 2.094  loss_mask_7: 5.314  loss_ce_8: 2.044  loss_mask_8: 5.275  time: 2.4957  data_time: 0.4006  lr: 9.6725e-05  max_mem: 18445M
[01/24 02:37:06] d2.utils.events INFO:  eta: 1 day, 15:16:12  iter: 2199  total_loss: 71.73  loss_ce: 2.033  loss_mask: 5.243  loss_ce_0: 1.993  loss_mask_0: 5.141  loss_ce_1: 2.015  loss_mask_1: 5.051  loss_ce_2: 2.06  loss_mask_2: 4.964  loss_ce_3: 2.071  loss_mask_3: 5.015  loss_ce_4: 2.074  loss_mask_4: 5.172  loss_ce_5: 2.095  loss_mask_5: 5.364  loss_ce_6: 2.069  loss_mask_6: 5.387  loss_ce_7: 2.106  loss_mask_7: 5.446  loss_ce_8: 2.061  loss_mask_8: 5.162  time: 2.4955  data_time: 0.3612  lr: 9.6695e-05  max_mem: 18445M
[01/24 02:37:56] d2.utils.events INFO:  eta: 1 day, 15:19:17  iter: 2219  total_loss: 75.28  loss_ce: 2.051  loss_mask: 5.313  loss_ce_0: 1.923  loss_mask_0: 5.571  loss_ce_1: 1.972  loss_mask_1: 5.352  loss_ce_2: 2.068  loss_mask_2: 5.211  loss_ce_3: 2.086  loss_mask_3: 5.298  loss_ce_4: 2.066  loss_mask_4: 5.293  loss_ce_5: 2.095  loss_mask_5: 5.453  loss_ce_6: 2.117  loss_mask_6: 5.563  loss_ce_7: 2.119  loss_mask_7: 5.603  loss_ce_8: 2.083  loss_mask_8: 5.2  time: 2.4956  data_time: 0.3761  lr: 9.6665e-05  max_mem: 18445M
[01/24 02:38:49] d2.utils.events INFO:  eta: 1 day, 15:19:17  iter: 2239  total_loss: 70.36  loss_ce: 2.008  loss_mask: 4.788  loss_ce_0: 1.99  loss_mask_0: 5.283  loss_ce_1: 1.98  loss_mask_1: 4.919  loss_ce_2: 2.014  loss_mask_2: 4.766  loss_ce_3: 2.049  loss_mask_3: 5.046  loss_ce_4: 2.031  loss_mask_4: 5.084  loss_ce_5: 2.024  loss_mask_5: 4.9  loss_ce_6: 2.047  loss_mask_6: 4.968  loss_ce_7: 2.038  loss_mask_7: 4.878  loss_ce_8: 2.033  loss_mask_8: 4.88  time: 2.4969  data_time: 0.4157  lr: 9.6635e-05  max_mem: 18445M
[01/24 02:39:36] d2.utils.events INFO:  eta: 1 day, 15:17:48  iter: 2259  total_loss: 68.93  loss_ce: 1.987  loss_mask: 4.85  loss_ce_0: 1.997  loss_mask_0: 5.1  loss_ce_1: 1.937  loss_mask_1: 4.848  loss_ce_2: 1.988  loss_mask_2: 4.738  loss_ce_3: 2.016  loss_mask_3: 4.752  loss_ce_4: 2.01  loss_mask_4: 4.844  loss_ce_5: 2.02  loss_mask_5: 5.101  loss_ce_6: 2.027  loss_mask_6: 5.079  loss_ce_7: 2.02  loss_mask_7: 4.912  loss_ce_8: 1.995  loss_mask_8: 4.673  time: 2.4958  data_time: 0.3738  lr: 9.6605e-05  max_mem: 18445M
[01/24 02:40:25] d2.utils.events INFO:  eta: 1 day, 15:16:59  iter: 2279  total_loss: 69.07  loss_ce: 1.988  loss_mask: 4.858  loss_ce_0: 1.944  loss_mask_0: 5.2  loss_ce_1: 1.919  loss_mask_1: 4.761  loss_ce_2: 1.982  loss_mask_2: 4.698  loss_ce_3: 2.03  loss_mask_3: 4.698  loss_ce_4: 2.034  loss_mask_4: 4.921  loss_ce_5: 2.027  loss_mask_5: 4.831  loss_ce_6: 2.015  loss_mask_6: 4.889  loss_ce_7: 2.031  loss_mask_7: 4.813  loss_ce_8: 2.025  loss_mask_8: 5  time: 2.4954  data_time: 0.3755  lr: 9.6575e-05  max_mem: 18445M
[01/24 02:41:17] d2.utils.events INFO:  eta: 1 day, 15:17:21  iter: 2299  total_loss: 67.47  loss_ce: 1.975  loss_mask: 4.8  loss_ce_0: 1.957  loss_mask_0: 5.092  loss_ce_1: 1.892  loss_mask_1: 4.642  loss_ce_2: 1.974  loss_mask_2: 4.624  loss_ce_3: 1.992  loss_mask_3: 4.745  loss_ce_4: 2  loss_mask_4: 4.944  loss_ce_5: 1.996  loss_mask_5: 4.866  loss_ce_6: 1.989  loss_mask_6: 4.949  loss_ce_7: 1.998  loss_mask_7: 4.801  loss_ce_8: 2  loss_mask_8: 4.782  time: 2.4964  data_time: 0.4180  lr: 9.6545e-05  max_mem: 18445M
[01/24 02:42:05] d2.utils.events INFO:  eta: 1 day, 15:16:25  iter: 2319  total_loss: 68.27  loss_ce: 1.975  loss_mask: 4.96  loss_ce_0: 1.953  loss_mask_0: 5.084  loss_ce_1: 1.884  loss_mask_1: 4.559  loss_ce_2: 1.961  loss_mask_2: 4.619  loss_ce_3: 1.979  loss_mask_3: 4.597  loss_ce_4: 1.997  loss_mask_4: 4.812  loss_ce_5: 2  loss_mask_5: 4.896  loss_ce_6: 2.008  loss_mask_6: 5.11  loss_ce_7: 2  loss_mask_7: 4.885  loss_ce_8: 1.984  loss_mask_8: 4.872  time: 2.4953  data_time: 0.3419  lr: 9.6515e-05  max_mem: 18445M
[01/24 02:42:55] d2.utils.events INFO:  eta: 1 day, 15:13:32  iter: 2339  total_loss: 68.91  loss_ce: 1.943  loss_mask: 4.767  loss_ce_0: 1.937  loss_mask_0: 5.186  loss_ce_1: 1.856  loss_mask_1: 4.712  loss_ce_2: 1.954  loss_mask_2: 4.777  loss_ce_3: 1.97  loss_mask_3: 4.757  loss_ce_4: 1.967  loss_mask_4: 4.866  loss_ce_5: 1.985  loss_mask_5: 5.136  loss_ce_6: 1.967  loss_mask_6: 5.021  loss_ce_7: 1.983  loss_mask_7: 4.899  loss_ce_8: 1.968  loss_mask_8: 4.814  time: 2.4955  data_time: 0.3917  lr: 9.6485e-05  max_mem: 18445M
[01/24 02:43:45] d2.utils.events INFO:  eta: 1 day, 15:11:34  iter: 2359  total_loss: 65.94  loss_ce: 1.947  loss_mask: 4.446  loss_ce_0: 1.925  loss_mask_0: 5.15  loss_ce_1: 1.869  loss_mask_1: 4.503  loss_ce_2: 1.975  loss_mask_2: 4.527  loss_ce_3: 1.98  loss_mask_3: 4.474  loss_ce_4: 1.999  loss_mask_4: 4.672  loss_ce_5: 1.995  loss_mask_5: 4.928  loss_ce_6: 1.984  loss_mask_6: 4.702  loss_ce_7: 1.98  loss_mask_7: 4.617  loss_ce_8: 1.966  loss_mask_8: 4.451  time: 2.4953  data_time: 0.4012  lr: 9.6454e-05  max_mem: 18445M
[01/24 02:44:33] d2.utils.events INFO:  eta: 1 day, 15:12:54  iter: 2379  total_loss: 66.69  loss_ce: 1.952  loss_mask: 4.684  loss_ce_0: 1.926  loss_mask_0: 5.205  loss_ce_1: 1.882  loss_mask_1: 4.597  loss_ce_2: 1.981  loss_mask_2: 4.598  loss_ce_3: 1.983  loss_mask_3: 4.647  loss_ce_4: 2.007  loss_mask_4: 4.741  loss_ce_5: 2.006  loss_mask_5: 4.863  loss_ce_6: 2  loss_mask_6: 4.696  loss_ce_7: 1.98  loss_mask_7: 4.61  loss_ce_8: 1.976  loss_mask_8: 4.528  time: 2.4947  data_time: 0.3445  lr: 9.6424e-05  max_mem: 18445M
[01/24 02:45:25] d2.utils.events INFO:  eta: 1 day, 15:11:05  iter: 2399  total_loss: 63.43  loss_ce: 1.941  loss_mask: 4.31  loss_ce_0: 1.899  loss_mask_0: 4.977  loss_ce_1: 1.862  loss_mask_1: 4.297  loss_ce_2: 1.935  loss_mask_2: 4.273  loss_ce_3: 1.944  loss_mask_3: 4.3  loss_ce_4: 1.958  loss_mask_4: 4.502  loss_ce_5: 1.961  loss_mask_5: 4.608  loss_ce_6: 1.969  loss_mask_6: 4.542  loss_ce_7: 1.956  loss_mask_7: 4.308  loss_ce_8: 1.955  loss_mask_8: 4.359  time: 2.4954  data_time: 0.3772  lr: 9.6394e-05  max_mem: 18445M
[01/24 02:46:13] d2.utils.events INFO:  eta: 1 day, 15:10:16  iter: 2419  total_loss: 63.11  loss_ce: 1.915  loss_mask: 4.366  loss_ce_0: 1.929  loss_mask_0: 4.683  loss_ce_1: 1.836  loss_mask_1: 4.212  loss_ce_2: 1.913  loss_mask_2: 4.253  loss_ce_3: 1.93  loss_mask_3: 4.29  loss_ce_4: 1.955  loss_mask_4: 4.457  loss_ce_5: 1.955  loss_mask_5: 4.4  loss_ce_6: 1.963  loss_mask_6: 4.324  loss_ce_7: 1.946  loss_mask_7: 4.231  loss_ce_8: 1.926  loss_mask_8: 4.358  time: 2.4947  data_time: 0.3791  lr: 9.6364e-05  max_mem: 18445M
[01/24 02:47:03] d2.utils.events INFO:  eta: 1 day, 15:11:09  iter: 2439  total_loss: 66.85  loss_ce: 1.971  loss_mask: 4.807  loss_ce_0: 1.878  loss_mask_0: 5.103  loss_ce_1: 1.829  loss_mask_1: 4.606  loss_ce_2: 1.936  loss_mask_2: 4.637  loss_ce_3: 1.965  loss_mask_3: 4.557  loss_ce_4: 1.977  loss_mask_4: 4.639  loss_ce_5: 1.963  loss_mask_5: 4.72  loss_ce_6: 1.981  loss_mask_6: 4.664  loss_ce_7: 1.97  loss_mask_7: 4.696  loss_ce_8: 1.966  loss_mask_8: 4.69  time: 2.4945  data_time: 0.3792  lr: 9.6334e-05  max_mem: 18445M
[01/24 02:47:54] d2.utils.events INFO:  eta: 1 day, 15:10:13  iter: 2459  total_loss: 65.9  loss_ce: 1.926  loss_mask: 4.712  loss_ce_0: 1.888  loss_mask_0: 5.026  loss_ce_1: 1.867  loss_mask_1: 4.599  loss_ce_2: 1.979  loss_mask_2: 4.554  loss_ce_3: 1.985  loss_mask_3: 4.654  loss_ce_4: 1.981  loss_mask_4: 4.719  loss_ce_5: 1.958  loss_mask_5: 4.747  loss_ce_6: 1.974  loss_mask_6: 4.634  loss_ce_7: 1.955  loss_mask_7: 4.557  loss_ce_8: 1.937  loss_mask_8: 4.495  time: 2.4951  data_time: 0.4042  lr: 9.6304e-05  max_mem: 18445M
[01/24 02:48:41] d2.utils.events INFO:  eta: 1 day, 15:08:49  iter: 2479  total_loss: 62.95  loss_ce: 1.924  loss_mask: 4.236  loss_ce_0: 1.897  loss_mask_0: 4.873  loss_ce_1: 1.873  loss_mask_1: 4.537  loss_ce_2: 1.97  loss_mask_2: 4.388  loss_ce_3: 1.963  loss_mask_3: 4.339  loss_ce_4: 1.959  loss_mask_4: 4.566  loss_ce_5: 1.946  loss_mask_5: 4.554  loss_ce_6: 1.957  loss_mask_6: 4.435  loss_ce_7: 1.947  loss_mask_7: 4.325  loss_ce_8: 1.922  loss_mask_8: 4.318  time: 2.4941  data_time: 0.3658  lr: 9.6274e-05  max_mem: 18445M
[01/24 02:49:29] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 02:49:29] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 02:49:29] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 02:53:21] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 15.007428137512365, 'error_1pix': 0.8752526395963603, 'error_3pix': 0.7961317744332773, 'mIoU': 0.41679644798832893, 'fwIoU': 5.977204945298419, 'IoU-0': nan, 'IoU-1': 55.54458975883565, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 8.534210331544897e-06, 'IoU-13': 0.40906270489084234, 'IoU-14': 0.0, 'IoU-15': 2.8284380277574526, 'IoU-16': 0.004139843002045172, 'IoU-17': 2.811434466337258e-05, 'IoU-18': 0.0, 'IoU-19': 0.12543504960792856, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 3.280216826587777, 'IoU-24': 0.12338203736819484, 'IoU-25': 0.0, 'IoU-26': 2.8767877228004135, 'IoU-27': 0.0002819032517624662, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.005920713258116287, 'IoU-32': 0.0, 'IoU-33': 0.7328646630241279, 'IoU-34': 1.4142086722466645, 'IoU-35': 0.00021059532805348677, 'IoU-36': 0.0, 'IoU-37': 0.0022347321964826332, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.00048721726300085977, 'IoU-42': 0.00016210665920412184, 'IoU-43': 0.05386987411023142, 'IoU-44': 1.446081067838434, 'IoU-45': 2.270307245598546e-05, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.008582320007073593, 'IoU-49': 1.7306894870930563, 'IoU-50': 0.0, 'IoU-51': 0.0059781889231869815, 'IoU-52': 0.0, 'IoU-53': 1.088242422105512e-05, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 3.238875628212317e-05, 'IoU-58': 0.0, 'IoU-59': 0.014823609857585195, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 4.9453029710193374e-05, 'IoU-66': 0.9626704661971097, 'IoU-67': 0.0, 'IoU-68': 0.8134390295244465, 'IoU-69': 0.0005258264387847057, 'IoU-70': 0.3610748099235227, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 2.2097503910153315e-05, 'IoU-74': 1.035502281727924, 'IoU-75': 0.0, 'IoU-76': 0.01456527294659444, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.9464853946313017, 'IoU-80': 0.057259139317724014, 'IoU-81': 0.0, 'IoU-82': 0.7629127696146518, 'IoU-83': 1.1129503233510223e-05, 'IoU-84': 0.0, 'IoU-85': 1.2496732821331134, 'IoU-86': 0.05829542390674568, 'IoU-87': 0.7535945371473505, 'IoU-88': 0.0014061395568400528, 'IoU-89': 0.9308866672440199, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.02780887217477706, 'IoU-93': 0.00013256992695397026, 'IoU-94': 0.0, 'IoU-95': 0.6118288291402363, 'IoU-96': 0.002679546462924694, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0027657066207559364, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.056088738220672646, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.7666902861506061, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.4337362072093838, 'pACC': 8.267840619889892, 'ACC-0': nan, 'ACC-1': 60.88580039688626, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 8.534253849332529e-06, 'ACC-13': 0.45054760128905885, 'ACC-14': 0.0, 'ACC-15': 11.183215644790009, 'ACC-16': 0.004411937346570311, 'ACC-17': 2.812787871258699e-05, 'ACC-18': 0.0, 'ACC-19': 0.13094426269835527, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 15.098566138913682, 'ACC-24': 0.12505933287075807, 'ACC-25': 0.0, 'ACC-26': 60.903232771236745, 'ACC-27': 0.00028194850097850224, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.0059693470492985816, 'ACC-32': 0.0, 'ACC-33': 0.8418132858132066, 'ACC-34': 2.1508101829454276, 'ACC-35': 0.00021070554390960756, 'ACC-36': 0.0, 'ACC-37': 0.0022461625237336215, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.00048759429743570437, 'ACC-42': 0.0001626155423198288, 'ACC-43': 0.054457864819909864, 'ACC-44': 6.065969272475611, 'ACC-45': 2.2704252850906813e-05, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.008626808510864203, 'ACC-49': 15.313199101590397, 'ACC-50': 0.0, 'ACC-51': 0.0060031107576951435, 'ACC-52': 0.0, 'ACC-53': 1.0883456411621029e-05, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 3.23950391014601e-05, 'ACC-58': 0.0, 'ACC-59': 0.015307662423158288, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 4.9458748189191584e-05, 'ACC-66': 8.676126753912767, 'ACC-67': 0.0, 'ACC-68': 6.515714032832445, 'ACC-69': 0.0005296027269879937, 'ACC-70': 0.847528169040933, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 2.2098773562264843e-05, 'ACC-74': 31.332854844298442, 'ACC-75': 0.0, 'ACC-76': 0.015144717840138712, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 28.384876900353333, 'ACC-80': 0.05897228545859328, 'ACC-81': 0.0, 'ACC-82': 2.307251435590862, 'ACC-83': 1.1129562689432114e-05, 'ACC-84': 0.0, 'ACC-85': 10.137109985636075, 'ACC-86': 0.060251857745850054, 'ACC-87': 1.5144163243413602, 'ACC-88': 0.001407663672951466, 'ACC-89': 3.309523952906398, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.03144019558617194, 'ACC-93': 0.00013258865651008094, 'ACC-94': 0.0, 'ACC-95': 1.4375497766543164, 'ACC-96': 0.002714463879228673, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.002776905709395275, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.05965111010421386, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 7.333869136463954, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 02:53:21] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 02:53:21] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 02:53:21] d2.evaluation.testing INFO: copypaste: 15.0074,0.8753,0.7961,0.4168,5.9772,1.4337,8.2678
[01/24 02:53:21] d2.utils.events INFO:  eta: 1 day, 15:03:56  iter: 2499  total_loss: 65.34  loss_ce: 1.946  loss_mask: 4.544  loss_ce_0: 1.882  loss_mask_0: 4.966  loss_ce_1: 1.848  loss_mask_1: 4.498  loss_ce_2: 1.952  loss_mask_2: 4.545  loss_ce_3: 1.955  loss_mask_3: 4.523  loss_ce_4: 1.948  loss_mask_4: 4.405  loss_ce_5: 1.945  loss_mask_5: 4.523  loss_ce_6: 1.96  loss_mask_6: 4.44  loss_ce_7: 1.962  loss_mask_7: 4.504  loss_ce_8: 1.96  loss_mask_8: 4.615  time: 2.4930  data_time: 0.3500  lr: 9.6244e-05  max_mem: 18445M
[01/24 02:54:09] d2.utils.events INFO:  eta: 1 day, 15:03:26  iter: 2519  total_loss: 64.34  loss_ce: 1.911  loss_mask: 4.385  loss_ce_0: 1.899  loss_mask_0: 4.892  loss_ce_1: 1.832  loss_mask_1: 4.409  loss_ce_2: 1.938  loss_mask_2: 4.51  loss_ce_3: 1.938  loss_mask_3: 4.566  loss_ce_4: 1.927  loss_mask_4: 4.428  loss_ce_5: 1.931  loss_mask_5: 4.49  loss_ce_6: 1.952  loss_mask_6: 4.376  loss_ce_7: 1.928  loss_mask_7: 4.287  loss_ce_8: 1.926  loss_mask_8: 4.476  time: 2.4919  data_time: 0.3411  lr: 9.6213e-05  max_mem: 18445M
[01/24 02:55:00] d2.utils.events INFO:  eta: 1 day, 14:59:28  iter: 2539  total_loss: 65.7  loss_ce: 1.916  loss_mask: 4.457  loss_ce_0: 1.863  loss_mask_0: 4.978  loss_ce_1: 1.841  loss_mask_1: 4.809  loss_ce_2: 1.945  loss_mask_2: 4.708  loss_ce_3: 1.948  loss_mask_3: 4.563  loss_ce_4: 1.96  loss_mask_4: 4.564  loss_ce_5: 1.962  loss_mask_5: 4.574  loss_ce_6: 1.968  loss_mask_6: 4.611  loss_ce_7: 1.95  loss_mask_7: 4.397  loss_ce_8: 1.94  loss_mask_8: 4.454  time: 2.4926  data_time: 0.3989  lr: 9.6183e-05  max_mem: 18445M
[01/24 02:55:49] d2.utils.events INFO:  eta: 1 day, 14:55:30  iter: 2559  total_loss: 65.75  loss_ce: 1.952  loss_mask: 4.748  loss_ce_0: 1.872  loss_mask_0: 4.9  loss_ce_1: 1.926  loss_mask_1: 4.661  loss_ce_2: 2.014  loss_mask_2: 4.63  loss_ce_3: 1.989  loss_mask_3: 4.692  loss_ce_4: 1.966  loss_mask_4: 4.534  loss_ce_5: 1.996  loss_mask_5: 4.661  loss_ce_6: 1.994  loss_mask_6: 4.431  loss_ce_7: 1.952  loss_mask_7: 4.536  loss_ce_8: 1.966  loss_mask_8: 4.452  time: 2.4921  data_time: 0.3529  lr: 9.6153e-05  max_mem: 18445M
[01/24 02:56:37] d2.utils.events INFO:  eta: 1 day, 14:53:44  iter: 2579  total_loss: 66.1  loss_ce: 1.953  loss_mask: 4.47  loss_ce_0: 1.839  loss_mask_0: 5.054  loss_ce_1: 1.811  loss_mask_1: 4.693  loss_ce_2: 1.94  loss_mask_2: 4.452  loss_ce_3: 1.966  loss_mask_3: 4.527  loss_ce_4: 1.967  loss_mask_4: 4.626  loss_ce_5: 1.995  loss_mask_5: 4.855  loss_ce_6: 2.004  loss_mask_6: 4.732  loss_ce_7: 1.97  loss_mask_7: 4.646  loss_ce_8: 1.966  loss_mask_8: 4.485  time: 2.4913  data_time: 0.3395  lr: 9.6123e-05  max_mem: 18445M
[01/24 02:57:27] d2.utils.events INFO:  eta: 1 day, 14:52:20  iter: 2599  total_loss: 63.34  loss_ce: 1.904  loss_mask: 4.262  loss_ce_0: 1.876  loss_mask_0: 4.838  loss_ce_1: 1.824  loss_mask_1: 4.418  loss_ce_2: 1.926  loss_mask_2: 4.384  loss_ce_3: 1.923  loss_mask_3: 4.289  loss_ce_4: 1.92  loss_mask_4: 4.347  loss_ce_5: 1.944  loss_mask_5: 4.552  loss_ce_6: 1.953  loss_mask_6: 4.399  loss_ce_7: 1.913  loss_mask_7: 4.404  loss_ce_8: 1.917  loss_mask_8: 4.292  time: 2.4916  data_time: 0.4187  lr: 9.6093e-05  max_mem: 18445M
[01/24 02:58:15] d2.utils.events INFO:  eta: 1 day, 14:51:31  iter: 2619  total_loss: 64.92  loss_ce: 1.904  loss_mask: 4.42  loss_ce_0: 1.854  loss_mask_0: 5.188  loss_ce_1: 1.816  loss_mask_1: 4.622  loss_ce_2: 1.921  loss_mask_2: 4.355  loss_ce_3: 1.938  loss_mask_3: 4.399  loss_ce_4: 1.931  loss_mask_4: 4.555  loss_ce_5: 1.952  loss_mask_5: 4.473  loss_ce_6: 1.974  loss_mask_6: 4.523  loss_ce_7: 1.927  loss_mask_7: 4.46  loss_ce_8: 1.924  loss_mask_8: 4.496  time: 2.4908  data_time: 0.3614  lr: 9.6063e-05  max_mem: 18445M
[01/24 02:59:03] d2.utils.events INFO:  eta: 1 day, 14:49:01  iter: 2639  total_loss: 63.59  loss_ce: 1.888  loss_mask: 4.455  loss_ce_0: 1.848  loss_mask_0: 5.006  loss_ce_1: 1.814  loss_mask_1: 4.398  loss_ce_2: 1.931  loss_mask_2: 4.338  loss_ce_3: 1.923  loss_mask_3: 4.336  loss_ce_4: 1.928  loss_mask_4: 4.413  loss_ce_5: 1.927  loss_mask_5: 4.449  loss_ce_6: 1.936  loss_mask_6: 4.459  loss_ce_7: 1.918  loss_mask_7: 4.371  loss_ce_8: 1.927  loss_mask_8: 4.254  time: 2.4901  data_time: 0.3513  lr: 9.6033e-05  max_mem: 18445M
[01/24 02:59:53] d2.utils.events INFO:  eta: 1 day, 14:43:32  iter: 2659  total_loss: 65.59  loss_ce: 1.978  loss_mask: 4.844  loss_ce_0: 1.833  loss_mask_0: 5.08  loss_ce_1: 1.824  loss_mask_1: 4.666  loss_ce_2: 1.951  loss_mask_2: 4.416  loss_ce_3: 1.962  loss_mask_3: 4.431  loss_ce_4: 1.949  loss_mask_4: 4.567  loss_ce_5: 1.958  loss_mask_5: 4.678  loss_ce_6: 1.973  loss_mask_6: 4.455  loss_ce_7: 1.962  loss_mask_7: 4.428  loss_ce_8: 2.024  loss_mask_8: 4.58  time: 2.4903  data_time: 0.3982  lr: 9.6003e-05  max_mem: 18445M
[01/24 03:00:43] d2.utils.events INFO:  eta: 1 day, 14:42:45  iter: 2679  total_loss: 64.88  loss_ce: 2.04  loss_mask: 4.809  loss_ce_0: 1.807  loss_mask_0: 5.028  loss_ce_1: 1.827  loss_mask_1: 4.391  loss_ce_2: 1.984  loss_mask_2: 4.265  loss_ce_3: 1.984  loss_mask_3: 4.393  loss_ce_4: 1.986  loss_mask_4: 4.497  loss_ce_5: 1.981  loss_mask_5: 4.459  loss_ce_6: 1.999  loss_mask_6: 4.565  loss_ce_7: 2.041  loss_mask_7: 4.649  loss_ce_8: 2.061  loss_mask_8: 4.662  time: 2.4901  data_time: 0.3754  lr: 9.5972e-05  max_mem: 18445M
[01/24 03:01:32] d2.utils.events INFO:  eta: 1 day, 14:41:45  iter: 2699  total_loss: 65.74  loss_ce: 1.974  loss_mask: 4.947  loss_ce_0: 1.786  loss_mask_0: 5.102  loss_ce_1: 1.804  loss_mask_1: 4.491  loss_ce_2: 1.962  loss_mask_2: 4.467  loss_ce_3: 1.963  loss_mask_3: 4.586  loss_ce_4: 1.953  loss_mask_4: 4.501  loss_ce_5: 1.972  loss_mask_5: 4.585  loss_ce_6: 2.011  loss_mask_6: 4.676  loss_ce_7: 1.997  loss_mask_7: 4.595  loss_ce_8: 1.994  loss_mask_8: 4.683  time: 2.4901  data_time: 0.3838  lr: 9.5942e-05  max_mem: 18445M
[01/24 03:02:22] d2.utils.events INFO:  eta: 1 day, 14:38:40  iter: 2719  total_loss: 67.67  loss_ce: 1.98  loss_mask: 4.967  loss_ce_0: 1.808  loss_mask_0: 5.257  loss_ce_1: 1.834  loss_mask_1: 5.077  loss_ce_2: 2.009  loss_mask_2: 4.724  loss_ce_3: 1.981  loss_mask_3: 4.708  loss_ce_4: 1.974  loss_mask_4: 5.003  loss_ce_5: 2.057  loss_mask_5: 5.267  loss_ce_6: 2.096  loss_mask_6: 4.736  loss_ce_7: 2.005  loss_mask_7: 4.73  loss_ce_8: 1.982  loss_mask_8: 4.681  time: 2.4898  data_time: 0.3883  lr: 9.5912e-05  max_mem: 18445M
[01/24 03:03:11] d2.utils.events INFO:  eta: 1 day, 14:37:51  iter: 2739  total_loss: 71.46  loss_ce: 2.036  loss_mask: 4.806  loss_ce_0: 1.779  loss_mask_0: 5.325  loss_ce_1: 1.926  loss_mask_1: 5.06  loss_ce_2: 2.054  loss_mask_2: 4.921  loss_ce_3: 2.051  loss_mask_3: 5.175  loss_ce_4: 2.01  loss_mask_4: 5.402  loss_ce_5: 2.205  loss_mask_5: 5.359  loss_ce_6: 2.188  loss_mask_6: 5.085  loss_ce_7: 2.077  loss_mask_7: 4.877  loss_ce_8: 2.079  loss_mask_8: 4.925  time: 2.4895  data_time: 0.3919  lr: 9.5882e-05  max_mem: 18445M
[01/24 03:04:03] d2.utils.events INFO:  eta: 1 day, 14:35:01  iter: 2759  total_loss: 69.6  loss_ce: 1.983  loss_mask: 4.585  loss_ce_0: 1.804  loss_mask_0: 5.337  loss_ce_1: 1.825  loss_mask_1: 4.684  loss_ce_2: 1.993  loss_mask_2: 4.64  loss_ce_3: 2.072  loss_mask_3: 5.133  loss_ce_4: 2.06  loss_mask_4: 4.971  loss_ce_5: 2.037  loss_mask_5: 5.197  loss_ce_6: 2.026  loss_mask_6: 4.973  loss_ce_7: 1.989  loss_mask_7: 4.899  loss_ce_8: 2.039  loss_mask_8: 4.909  time: 2.4904  data_time: 0.4260  lr: 9.5852e-05  max_mem: 18445M
[01/24 03:04:52] d2.utils.events INFO:  eta: 1 day, 14:33:47  iter: 2779  total_loss: 64.95  loss_ce: 1.947  loss_mask: 4.378  loss_ce_0: 1.789  loss_mask_0: 4.944  loss_ce_1: 1.834  loss_mask_1: 4.602  loss_ce_2: 1.972  loss_mask_2: 4.537  loss_ce_3: 1.981  loss_mask_3: 4.623  loss_ce_4: 1.976  loss_mask_4: 4.548  loss_ce_5: 2.02  loss_mask_5: 4.61  loss_ce_6: 1.982  loss_mask_6: 4.438  loss_ce_7: 1.969  loss_mask_7: 4.412  loss_ce_8: 1.952  loss_mask_8: 4.441  time: 2.4900  data_time: 0.3661  lr: 9.5822e-05  max_mem: 18445M
[01/24 03:05:40] d2.utils.events INFO:  eta: 1 day, 14:31:10  iter: 2799  total_loss: 68.44  loss_ce: 1.997  loss_mask: 4.422  loss_ce_0: 1.794  loss_mask_0: 5.016  loss_ce_1: 1.962  loss_mask_1: 4.99  loss_ce_2: 2.359  loss_mask_2: 4.996  loss_ce_3: 2.082  loss_mask_3: 5.103  loss_ce_4: 2.067  loss_mask_4: 5.049  loss_ce_5: 2.133  loss_mask_5: 5.208  loss_ce_6: 2.035  loss_mask_6: 4.631  loss_ce_7: 2.034  loss_mask_7: 4.729  loss_ce_8: 2.002  loss_mask_8: 4.413  time: 2.4892  data_time: 0.3636  lr: 9.5792e-05  max_mem: 18445M
[01/24 03:06:31] d2.utils.events INFO:  eta: 1 day, 14:30:49  iter: 2819  total_loss: 72.54  loss_ce: 2.033  loss_mask: 4.717  loss_ce_0: 1.789  loss_mask_0: 5.379  loss_ce_1: 1.963  loss_mask_1: 5.063  loss_ce_2: 2.453  loss_mask_2: 5.312  loss_ce_3: 2.173  loss_mask_3: 5.524  loss_ce_4: 2.267  loss_mask_4: 5.75  loss_ce_5: 2.096  loss_mask_5: 5.481  loss_ce_6: 1.997  loss_mask_6: 4.759  loss_ce_7: 2.016  loss_mask_7: 4.886  loss_ce_8: 2.006  loss_mask_8: 4.611  time: 2.4897  data_time: 0.4444  lr: 9.5761e-05  max_mem: 18445M
[01/24 03:07:19] d2.utils.events INFO:  eta: 1 day, 14:28:49  iter: 2839  total_loss: 68.55  loss_ce: 1.97  loss_mask: 4.669  loss_ce_0: 1.798  loss_mask_0: 5.21  loss_ce_1: 1.865  loss_mask_1: 4.613  loss_ce_2: 2.104  loss_mask_2: 4.924  loss_ce_3: 2.077  loss_mask_3: 5.216  loss_ce_4: 2.136  loss_mask_4: 5.211  loss_ce_5: 2.033  loss_mask_5: 4.974  loss_ce_6: 1.984  loss_mask_6: 4.43  loss_ce_7: 2.001  loss_mask_7: 4.497  loss_ce_8: 1.978  loss_mask_8: 4.458  time: 2.4892  data_time: 0.3639  lr: 9.5731e-05  max_mem: 18445M
[01/24 03:08:07] d2.utils.events INFO:  eta: 1 day, 14:27:49  iter: 2859  total_loss: 65.16  loss_ce: 1.997  loss_mask: 4.358  loss_ce_0: 1.781  loss_mask_0: 4.805  loss_ce_1: 1.807  loss_mask_1: 4.376  loss_ce_2: 2.008  loss_mask_2: 4.549  loss_ce_3: 1.995  loss_mask_3: 4.67  loss_ce_4: 2.11  loss_mask_4: 4.68  loss_ce_5: 1.985  loss_mask_5: 4.608  loss_ce_6: 1.984  loss_mask_6: 4.46  loss_ce_7: 1.972  loss_mask_7: 4.481  loss_ce_8: 1.951  loss_mask_8: 4.245  time: 2.4887  data_time: 0.3580  lr: 9.5701e-05  max_mem: 18445M
[01/24 03:09:00] d2.utils.events INFO:  eta: 1 day, 14:29:03  iter: 2879  total_loss: 65.16  loss_ce: 1.994  loss_mask: 4.422  loss_ce_0: 1.785  loss_mask_0: 5.127  loss_ce_1: 1.795  loss_mask_1: 4.437  loss_ce_2: 1.98  loss_mask_2: 4.46  loss_ce_3: 1.957  loss_mask_3: 4.558  loss_ce_4: 2.146  loss_mask_4: 4.815  loss_ce_5: 1.957  loss_mask_5: 4.589  loss_ce_6: 1.982  loss_mask_6: 4.64  loss_ce_7: 1.985  loss_mask_7: 4.313  loss_ce_8: 1.983  loss_mask_8: 4.402  time: 2.4895  data_time: 0.4404  lr: 9.5671e-05  max_mem: 18445M
[01/24 03:09:48] d2.utils.events INFO:  eta: 1 day, 14:28:14  iter: 2899  total_loss: 64.99  loss_ce: 1.969  loss_mask: 4.405  loss_ce_0: 1.782  loss_mask_0: 5.006  loss_ce_1: 1.795  loss_mask_1: 4.338  loss_ce_2: 1.968  loss_mask_2: 4.405  loss_ce_3: 1.956  loss_mask_3: 4.48  loss_ce_4: 2.117  loss_mask_4: 4.82  loss_ce_5: 1.988  loss_mask_5: 4.594  loss_ce_6: 2.015  loss_mask_6: 4.595  loss_ce_7: 1.992  loss_mask_7: 4.565  loss_ce_8: 1.963  loss_mask_8: 4.496  time: 2.4889  data_time: 0.3531  lr: 9.5641e-05  max_mem: 18445M
[01/24 03:10:37] d2.utils.events INFO:  eta: 1 day, 14:27:53  iter: 2919  total_loss: 65.04  loss_ce: 1.949  loss_mask: 4.39  loss_ce_0: 1.771  loss_mask_0: 4.802  loss_ce_1: 1.796  loss_mask_1: 4.293  loss_ce_2: 2.008  loss_mask_2: 4.337  loss_ce_3: 1.966  loss_mask_3: 4.562  loss_ce_4: 2.212  loss_mask_4: 4.574  loss_ce_5: 2.124  loss_mask_5: 4.682  loss_ce_6: 1.966  loss_mask_6: 4.505  loss_ce_7: 1.974  loss_mask_7: 4.541  loss_ce_8: 1.962  loss_mask_8: 4.287  time: 2.4886  data_time: 0.4101  lr: 9.5611e-05  max_mem: 18445M
[01/24 03:11:26] d2.utils.events INFO:  eta: 1 day, 14:31:27  iter: 2939  total_loss: 62.97  loss_ce: 1.976  loss_mask: 4.282  loss_ce_0: 1.761  loss_mask_0: 4.904  loss_ce_1: 1.8  loss_mask_1: 4.104  loss_ce_2: 2.045  loss_mask_2: 4.375  loss_ce_3: 1.986  loss_mask_3: 4.282  loss_ce_4: 2.362  loss_mask_4: 4.436  loss_ce_5: 2.252  loss_mask_5: 4.429  loss_ce_6: 1.978  loss_mask_6: 4.321  loss_ce_7: 1.962  loss_mask_7: 4.156  loss_ce_8: 1.97  loss_mask_8: 4.155  time: 2.4885  data_time: 0.3775  lr: 9.5581e-05  max_mem: 18445M
[01/24 03:12:14] d2.utils.events INFO:  eta: 1 day, 14:33:01  iter: 2959  total_loss: 67.97  loss_ce: 1.957  loss_mask: 4.524  loss_ce_0: 1.716  loss_mask_0: 4.875  loss_ce_1: 1.86  loss_mask_1: 4.541  loss_ce_2: 2.244  loss_mask_2: 4.958  loss_ce_3: 2.032  loss_mask_3: 4.899  loss_ce_4: 2.367  loss_mask_4: 4.976  loss_ce_5: 2.239  loss_mask_5: 5.214  loss_ce_6: 2.006  loss_mask_6: 4.438  loss_ce_7: 1.989  loss_mask_7: 4.498  loss_ce_8: 1.978  loss_mask_8: 4.506  time: 2.4878  data_time: 0.3862  lr: 9.555e-05  max_mem: 18445M
[01/24 03:13:02] d2.utils.events INFO:  eta: 1 day, 14:33:25  iter: 2979  total_loss: 67.22  loss_ce: 1.964  loss_mask: 4.544  loss_ce_0: 1.749  loss_mask_0: 4.972  loss_ce_1: 1.856  loss_mask_1: 4.555  loss_ce_2: 2.2  loss_mask_2: 5.033  loss_ce_3: 2.006  loss_mask_3: 4.823  loss_ce_4: 2.286  loss_mask_4: 4.77  loss_ce_5: 2.196  loss_mask_5: 4.809  loss_ce_6: 2  loss_mask_6: 4.541  loss_ce_7: 1.98  loss_mask_7: 4.469  loss_ce_8: 1.948  loss_mask_8: 4.416  time: 2.4873  data_time: 0.3597  lr: 9.552e-05  max_mem: 18445M
[01/24 03:13:53] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 03:13:53] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 03:13:53] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 03:17:27] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 19.616218619648578, 'error_1pix': 0.9361311662871439, 'error_3pix': 0.853115814999736, 'mIoU': 0.04874743116340973, 'fwIoU': 0.13851432909439604, 'IoU-0': nan, 'IoU-1': 0.0028280531583641743, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.00024087812653946167, 'IoU-13': 0.0, 'IoU-14': 0.13816952449802083, 'IoU-15': 0.0, 'IoU-16': 4.766209102649131e-05, 'IoU-17': 0.00020933193649568904, 'IoU-18': 0.0, 'IoU-19': 0.03817788512244589, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.00015304575238766677, 'IoU-23': 0.0, 'IoU-24': 0.0006859537554367551, 'IoU-25': 0.0, 'IoU-26': 2.7363605954101748e-05, 'IoU-27': 2.1107814600018306, 'IoU-28': 0.08606377175051479, 'IoU-29': 0.0, 'IoU-30': 0.0003830278355835902, 'IoU-31': 2.6192559683872567e-06, 'IoU-32': 1.802085117945701, 'IoU-33': 0.0, 'IoU-34': 2.4886204058797388, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.05144701922497359, 'IoU-41': 2.171189039640016, 'IoU-42': 0.0, 'IoU-43': 7.280676977731285e-06, 'IoU-44': 0.0, 'IoU-45': 0.00038927071643007764, 'IoU-46': 0.0, 'IoU-47': 0.00027259234725948006, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.03223021296480375, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.00016183074329701916, 'IoU-58': 6.926606988406176e-06, 'IoU-59': 0.06604121008403775, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.3378264616000524, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.007346671211284052, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.02292872850960787, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0011706255160139362, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 1.2812816917018432e-05, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.7694057633198689, 'pACC': 2.1009694623934787, 'ACC-0': nan, 'ACC-1': 0.002829034456525068, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.00024109267124364394, 'ACC-13': 0.0, 'ACC-14': 0.15605078972772685, 'ACC-15': 0.0, 'ACC-16': 4.7667990539175025e-05, 'ACC-17': 0.00020939643041592538, 'ACC-18': 0.0, 'ACC-19': 0.0500066306633439, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.00015315296425195399, 'ACC-23': 0.0, 'ACC-24': 0.0007015645231854135, 'ACC-25': 0.0, 'ACC-26': 2.7368662729127022e-05, 'ACC-27': 31.237542457919893, 'ACC-28': 0.15399255098427533, 'ACC-29': 0.0, 'ACC-30': 0.0003854849760511307, 'ACC-31': 2.61928347928854e-06, 'ACC-32': 21.3306058487999, 'ACC-33': 0.0, 'ACC-34': 8.552641733636692, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.05233356130022327, 'ACC-41': 83.64158378889822, 'ACC-42': 0.0, 'ACC-43': 7.281436665317537e-06, 'ACC-44': 0.0, 'ACC-45': 0.0003897563406072336, 'ACC-46': 0.0, 'ACC-47': 0.0002726415958803173, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.03453548391508202, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.00016197519550730047, 'ACC-58': 6.9266141850963085e-06, 'ACC-59': 0.0799631782221401, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 2.3983445017663305, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.007431472506583854, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.024253635588306274, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0011721474327040856, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 1.2812912135326903e-05, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 03:17:27] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 03:17:27] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 03:17:27] d2.evaluation.testing INFO: copypaste: 19.6162,0.9361,0.8531,0.0487,0.1385,0.7694,2.1010
[01/24 03:17:27] d2.utils.events INFO:  eta: 1 day, 14:33:45  iter: 2999  total_loss: 71.42  loss_ce: 2.03  loss_mask: 4.943  loss_ce_0: 1.739  loss_mask_0: 5.075  loss_ce_1: 1.872  loss_mask_1: 4.677  loss_ce_2: 2.047  loss_mask_2: 4.989  loss_ce_3: 2.082  loss_mask_3: 5.102  loss_ce_4: 2.253  loss_mask_4: 5.868  loss_ce_5: 2.159  loss_mask_5: 5.807  loss_ce_6: 2.052  loss_mask_6: 5.083  loss_ce_7: 1.995  loss_mask_7: 4.628  loss_ce_8: 1.979  loss_mask_8: 4.538  time: 2.4876  data_time: 0.4052  lr: 9.549e-05  max_mem: 18445M
[01/24 03:18:19] d2.utils.events INFO:  eta: 1 day, 14:33:46  iter: 3019  total_loss: 67.98  loss_ce: 1.989  loss_mask: 4.599  loss_ce_0: 1.795  loss_mask_0: 5.339  loss_ce_1: 1.883  loss_mask_1: 4.652  loss_ce_2: 2.026  loss_mask_2: 4.851  loss_ce_3: 2.001  loss_mask_3: 4.812  loss_ce_4: 2.065  loss_mask_4: 5.15  loss_ce_5: 2.032  loss_mask_5: 4.973  loss_ce_6: 2.023  loss_mask_6: 4.55  loss_ce_7: 1.988  loss_mask_7: 4.643  loss_ce_8: 2.016  loss_mask_8: 4.653  time: 2.4880  data_time: 0.4025  lr: 9.546e-05  max_mem: 18445M
[01/24 03:19:06] d2.utils.events INFO:  eta: 1 day, 14:32:57  iter: 3039  total_loss: 63.32  loss_ce: 2.007  loss_mask: 4.273  loss_ce_0: 1.799  loss_mask_0: 4.987  loss_ce_1: 1.872  loss_mask_1: 4.365  loss_ce_2: 1.99  loss_mask_2: 4.532  loss_ce_3: 1.997  loss_mask_3: 4.441  loss_ce_4: 2.044  loss_mask_4: 4.578  loss_ce_5: 2.023  loss_mask_5: 4.482  loss_ce_6: 1.978  loss_mask_6: 4.21  loss_ce_7: 1.97  loss_mask_7: 4.136  loss_ce_8: 1.968  loss_mask_8: 4.199  time: 2.4871  data_time: 0.3499  lr: 9.543e-05  max_mem: 18445M
[01/24 03:19:53] d2.utils.events INFO:  eta: 1 day, 14:32:59  iter: 3059  total_loss: 63.51  loss_ce: 2.001  loss_mask: 4.316  loss_ce_0: 1.778  loss_mask_0: 5.143  loss_ce_1: 1.869  loss_mask_1: 4.329  loss_ce_2: 1.981  loss_mask_2: 4.403  loss_ce_3: 2.004  loss_mask_3: 4.425  loss_ce_4: 2.068  loss_mask_4: 4.476  loss_ce_5: 2.02  loss_mask_5: 4.418  loss_ce_6: 1.98  loss_mask_6: 4.295  loss_ce_7: 1.968  loss_mask_7: 4.205  loss_ce_8: 1.969  loss_mask_8: 4.218  time: 2.4863  data_time: 0.3647  lr: 9.54e-05  max_mem: 18445M
[01/24 03:20:46] d2.utils.events INFO:  eta: 1 day, 14:32:38  iter: 3079  total_loss: 65.3  loss_ce: 2.034  loss_mask: 4.596  loss_ce_0: 1.766  loss_mask_0: 5.173  loss_ce_1: 1.871  loss_mask_1: 4.422  loss_ce_2: 1.985  loss_mask_2: 4.563  loss_ce_3: 2  loss_mask_3: 4.597  loss_ce_4: 2.134  loss_mask_4: 4.463  loss_ce_5: 2.078  loss_mask_5: 4.479  loss_ce_6: 2  loss_mask_6: 4.297  loss_ce_7: 1.973  loss_mask_7: 4.371  loss_ce_8: 1.982  loss_mask_8: 4.346  time: 2.4872  data_time: 0.4388  lr: 9.5369e-05  max_mem: 18445M
[01/24 03:21:33] d2.utils.events INFO:  eta: 1 day, 14:29:45  iter: 3099  total_loss: 64.51  loss_ce: 2.045  loss_mask: 4.367  loss_ce_0: 1.746  loss_mask_0: 4.986  loss_ce_1: 1.867  loss_mask_1: 4.279  loss_ce_2: 1.976  loss_mask_2: 4.595  loss_ce_3: 1.994  loss_mask_3: 4.479  loss_ce_4: 2.151  loss_mask_4: 4.476  loss_ce_5: 2.173  loss_mask_5: 4.586  loss_ce_6: 2.039  loss_mask_6: 4.237  loss_ce_7: 2.007  loss_mask_7: 4.283  loss_ce_8: 1.991  loss_mask_8: 4.172  time: 2.4865  data_time: 0.3806  lr: 9.5339e-05  max_mem: 18445M
[01/24 03:22:22] d2.utils.events INFO:  eta: 1 day, 14:28:40  iter: 3119  total_loss: 67.83  loss_ce: 2.019  loss_mask: 4.734  loss_ce_0: 1.733  loss_mask_0: 5.31  loss_ce_1: 1.893  loss_mask_1: 4.611  loss_ce_2: 2.007  loss_mask_2: 4.705  loss_ce_3: 2.025  loss_mask_3: 4.749  loss_ce_4: 2.116  loss_mask_4: 4.966  loss_ce_5: 2.124  loss_mask_5: 5.088  loss_ce_6: 2.026  loss_mask_6: 4.651  loss_ce_7: 1.994  loss_mask_7: 4.615  loss_ce_8: 1.995  loss_mask_8: 4.651  time: 2.4860  data_time: 0.3500  lr: 9.5309e-05  max_mem: 18445M
[01/24 03:23:08] d2.utils.events INFO:  eta: 1 day, 14:23:46  iter: 3139  total_loss: 65.58  loss_ce: 1.984  loss_mask: 4.59  loss_ce_0: 1.772  loss_mask_0: 5.31  loss_ce_1: 1.869  loss_mask_1: 4.495  loss_ce_2: 1.982  loss_mask_2: 4.663  loss_ce_3: 2.001  loss_mask_3: 4.68  loss_ce_4: 2.055  loss_mask_4: 4.681  loss_ce_5: 2.058  loss_mask_5: 4.615  loss_ce_6: 1.97  loss_mask_6: 4.455  loss_ce_7: 1.952  loss_mask_7: 4.493  loss_ce_8: 1.966  loss_mask_8: 4.468  time: 2.4849  data_time: 0.3589  lr: 9.5279e-05  max_mem: 18445M
[01/24 03:23:54] d2.utils.events INFO:  eta: 1 day, 14:20:02  iter: 3159  total_loss: 67.91  loss_ce: 1.984  loss_mask: 4.674  loss_ce_0: 1.797  loss_mask_0: 5.376  loss_ce_1: 1.887  loss_mask_1: 4.614  loss_ce_2: 1.992  loss_mask_2: 4.893  loss_ce_3: 1.981  loss_mask_3: 4.741  loss_ce_4: 2.088  loss_mask_4: 5.183  loss_ce_5: 2.077  loss_mask_5: 5.118  loss_ce_6: 1.985  loss_mask_6: 4.531  loss_ce_7: 1.964  loss_mask_7: 4.521  loss_ce_8: 1.947  loss_mask_8: 4.535  time: 2.4838  data_time: 0.3705  lr: 9.5249e-05  max_mem: 18445M
[01/24 03:24:42] d2.utils.events INFO:  eta: 1 day, 14:15:43  iter: 3179  total_loss: 68.26  loss_ce: 1.995  loss_mask: 4.741  loss_ce_0: 1.758  loss_mask_0: 5.33  loss_ce_1: 1.901  loss_mask_1: 4.757  loss_ce_2: 2.005  loss_mask_2: 4.875  loss_ce_3: 2.007  loss_mask_3: 4.858  loss_ce_4: 2.103  loss_mask_4: 5.091  loss_ce_5: 2.066  loss_mask_5: 5.185  loss_ce_6: 1.993  loss_mask_6: 4.751  loss_ce_7: 1.968  loss_mask_7: 4.678  loss_ce_8: 1.981  loss_mask_8: 4.618  time: 2.4832  data_time: 0.4181  lr: 9.5219e-05  max_mem: 18445M
[01/24 03:25:30] d2.utils.events INFO:  eta: 1 day, 14:13:47  iter: 3199  total_loss: 66.03  loss_ce: 1.964  loss_mask: 4.483  loss_ce_0: 1.754  loss_mask_0: 5.255  loss_ce_1: 1.868  loss_mask_1: 4.654  loss_ce_2: 1.978  loss_mask_2: 4.718  loss_ce_3: 2.017  loss_mask_3: 4.856  loss_ce_4: 2.173  loss_mask_4: 4.887  loss_ce_5: 2.096  loss_mask_5: 4.913  loss_ce_6: 1.965  loss_mask_6: 4.366  loss_ce_7: 1.951  loss_mask_7: 4.334  loss_ce_8: 1.943  loss_mask_8: 4.408  time: 2.4825  data_time: 0.3745  lr: 9.5188e-05  max_mem: 18445M
[01/24 03:26:18] d2.utils.events INFO:  eta: 1 day, 14:11:16  iter: 3219  total_loss: 67.71  loss_ce: 1.992  loss_mask: 4.325  loss_ce_0: 1.73  loss_mask_0: 5.148  loss_ce_1: 1.896  loss_mask_1: 4.484  loss_ce_2: 2.019  loss_mask_2: 4.536  loss_ce_3: 2.049  loss_mask_3: 5.075  loss_ce_4: 2.147  loss_mask_4: 5.178  loss_ce_5: 2.086  loss_mask_5: 5.138  loss_ce_6: 1.999  loss_mask_6: 4.628  loss_ce_7: 1.993  loss_mask_7: 4.528  loss_ce_8: 1.983  loss_mask_8: 4.395  time: 2.4819  data_time: 0.3823  lr: 9.5158e-05  max_mem: 18445M
[01/24 03:27:05] d2.utils.events INFO:  eta: 1 day, 14:05:31  iter: 3239  total_loss: 65.55  loss_ce: 1.965  loss_mask: 4.568  loss_ce_0: 1.771  loss_mask_0: 5.406  loss_ce_1: 1.86  loss_mask_1: 4.463  loss_ce_2: 1.964  loss_mask_2: 4.412  loss_ce_3: 1.983  loss_mask_3: 4.49  loss_ce_4: 2.032  loss_mask_4: 4.846  loss_ce_5: 1.992  loss_mask_5: 4.588  loss_ce_6: 1.973  loss_mask_6: 4.385  loss_ce_7: 1.947  loss_mask_7: 4.444  loss_ce_8: 1.963  loss_mask_8: 4.342  time: 2.4812  data_time: 0.4082  lr: 9.5128e-05  max_mem: 18445M
[01/24 03:27:51] d2.utils.events INFO:  eta: 1 day, 14:02:56  iter: 3259  total_loss: 64.39  loss_ce: 2.013  loss_mask: 4.452  loss_ce_0: 1.767  loss_mask_0: 5.058  loss_ce_1: 1.824  loss_mask_1: 4.29  loss_ce_2: 1.953  loss_mask_2: 4.411  loss_ce_3: 1.997  loss_mask_3: 4.319  loss_ce_4: 2.022  loss_mask_4: 4.488  loss_ce_5: 2.026  loss_mask_5: 4.716  loss_ce_6: 1.985  loss_mask_6: 4.357  loss_ce_7: 1.95  loss_mask_7: 4.296  loss_ce_8: 1.966  loss_mask_8: 4.279  time: 2.4801  data_time: 0.3736  lr: 9.5098e-05  max_mem: 18445M
[01/24 03:28:39] d2.utils.events INFO:  eta: 1 day, 13:59:53  iter: 3279  total_loss: 63.48  loss_ce: 2.008  loss_mask: 4.348  loss_ce_0: 1.748  loss_mask_0: 4.901  loss_ce_1: 1.826  loss_mask_1: 4.285  loss_ce_2: 1.955  loss_mask_2: 4.401  loss_ce_3: 1.979  loss_mask_3: 4.226  loss_ce_4: 1.99  loss_mask_4: 4.643  loss_ce_5: 2.03  loss_mask_5: 4.725  loss_ce_6: 1.966  loss_mask_6: 4.255  loss_ce_7: 1.951  loss_mask_7: 4.243  loss_ce_8: 1.957  loss_mask_8: 4.236  time: 2.4795  data_time: 0.3745  lr: 9.5068e-05  max_mem: 18445M
[01/24 03:29:26] d2.utils.events INFO:  eta: 1 day, 13:55:20  iter: 3299  total_loss: 62.81  loss_ce: 2.013  loss_mask: 4.292  loss_ce_0: 1.763  loss_mask_0: 4.674  loss_ce_1: 1.856  loss_mask_1: 4.235  loss_ce_2: 1.938  loss_mask_2: 4.211  loss_ce_3: 1.971  loss_mask_3: 4.254  loss_ce_4: 2.004  loss_mask_4: 4.525  loss_ce_5: 2.051  loss_mask_5: 4.445  loss_ce_6: 1.978  loss_mask_6: 4.203  loss_ce_7: 1.984  loss_mask_7: 4.212  loss_ce_8: 1.957  loss_mask_8: 4.367  time: 2.4787  data_time: 0.3730  lr: 9.5038e-05  max_mem: 18445M
[01/24 03:30:18] d2.utils.events INFO:  eta: 1 day, 13:59:02  iter: 3319  total_loss: 61.29  loss_ce: 1.993  loss_mask: 4.208  loss_ce_0: 1.72  loss_mask_0: 4.571  loss_ce_1: 1.818  loss_mask_1: 4.168  loss_ce_2: 1.934  loss_mask_2: 4.094  loss_ce_3: 1.968  loss_mask_3: 4.133  loss_ce_4: 1.996  loss_mask_4: 4.344  loss_ce_5: 2.039  loss_mask_5: 4.362  loss_ce_6: 1.969  loss_mask_6: 4.118  loss_ce_7: 1.978  loss_mask_7: 4.054  loss_ce_8: 1.962  loss_mask_8: 3.97  time: 2.4793  data_time: 0.4459  lr: 9.5007e-05  max_mem: 18445M
[01/24 03:31:05] d2.utils.events INFO:  eta: 1 day, 13:56:39  iter: 3339  total_loss: 63.12  loss_ce: 1.988  loss_mask: 4.164  loss_ce_0: 1.732  loss_mask_0: 4.796  loss_ce_1: 1.818  loss_mask_1: 4.214  loss_ce_2: 1.935  loss_mask_2: 4.253  loss_ce_3: 1.973  loss_mask_3: 4.444  loss_ce_4: 1.997  loss_mask_4: 4.608  loss_ce_5: 2.001  loss_mask_5: 4.472  loss_ce_6: 1.97  loss_mask_6: 4.262  loss_ce_7: 1.954  loss_mask_7: 4.173  loss_ce_8: 1.969  loss_mask_8: 4.334  time: 2.4787  data_time: 0.3751  lr: 9.4977e-05  max_mem: 18445M
[01/24 03:31:51] d2.utils.events INFO:  eta: 1 day, 13:53:01  iter: 3359  total_loss: 73.32  loss_ce: 2.176  loss_mask: 5.792  loss_ce_0: 1.707  loss_mask_0: 5.423  loss_ce_1: 1.833  loss_mask_1: 4.967  loss_ce_2: 2.069  loss_mask_2: 5.195  loss_ce_3: 2.175  loss_mask_3: 5.302  loss_ce_4: 2.058  loss_mask_4: 5.321  loss_ce_5: 2.162  loss_mask_5: 5.388  loss_ce_6: 2.017  loss_mask_6: 5.146  loss_ce_7: 2.137  loss_mask_7: 5.182  loss_ce_8: 2.041  loss_mask_8: 5.315  time: 2.4776  data_time: 0.3587  lr: 9.4947e-05  max_mem: 18445M
[01/24 03:32:43] d2.utils.events INFO:  eta: 1 day, 13:54:28  iter: 3379  total_loss: 66.74  loss_ce: 2.206  loss_mask: 5.137  loss_ce_0: 1.756  loss_mask_0: 4.951  loss_ce_1: 1.805  loss_mask_1: 4.375  loss_ce_2: 1.996  loss_mask_2: 4.471  loss_ce_3: 2.008  loss_mask_3: 4.648  loss_ce_4: 2.036  loss_mask_4: 4.901  loss_ce_5: 2.01  loss_mask_5: 4.534  loss_ce_6: 1.954  loss_mask_6: 4.541  loss_ce_7: 2.034  loss_mask_7: 4.558  loss_ce_8: 1.993  loss_mask_8: 4.831  time: 2.4782  data_time: 0.4048  lr: 9.4917e-05  max_mem: 18445M
[01/24 03:33:32] d2.utils.events INFO:  eta: 1 day, 13:53:20  iter: 3399  total_loss: 68.85  loss_ce: 2.193  loss_mask: 5.217  loss_ce_0: 1.74  loss_mask_0: 5.312  loss_ce_1: 1.813  loss_mask_1: 4.581  loss_ce_2: 2.037  loss_mask_2: 4.695  loss_ce_3: 2.042  loss_mask_3: 4.783  loss_ce_4: 2.127  loss_mask_4: 4.843  loss_ce_5: 2.028  loss_mask_5: 5.083  loss_ce_6: 2.024  loss_mask_6: 4.855  loss_ce_7: 2.041  loss_mask_7: 4.643  loss_ce_8: 2.032  loss_mask_8: 5.044  time: 2.4781  data_time: 0.3765  lr: 9.4887e-05  max_mem: 18445M
[01/24 03:34:20] d2.utils.events INFO:  eta: 1 day, 13:51:47  iter: 3419  total_loss: 70.29  loss_ce: 2.443  loss_mask: 5.171  loss_ce_0: 1.763  loss_mask_0: 5.406  loss_ce_1: 1.844  loss_mask_1: 4.572  loss_ce_2: 2.038  loss_mask_2: 4.919  loss_ce_3: 2.029  loss_mask_3: 5.072  loss_ce_4: 2.116  loss_mask_4: 5.016  loss_ce_5: 2.03  loss_mask_5: 5.209  loss_ce_6: 2.032  loss_mask_6: 4.911  loss_ce_7: 2.033  loss_mask_7: 4.584  loss_ce_8: 2.063  loss_mask_8: 5.657  time: 2.4777  data_time: 0.3679  lr: 9.4857e-05  max_mem: 18445M
[01/24 03:35:11] d2.utils.events INFO:  eta: 1 day, 13:51:44  iter: 3439  total_loss: 66.82  loss_ce: 2.454  loss_mask: 4.925  loss_ce_0: 1.773  loss_mask_0: 5.059  loss_ce_1: 1.806  loss_mask_1: 4.517  loss_ce_2: 2  loss_mask_2: 4.664  loss_ce_3: 1.977  loss_mask_3: 4.743  loss_ce_4: 2.088  loss_mask_4: 4.633  loss_ce_5: 1.959  loss_mask_5: 4.576  loss_ce_6: 1.933  loss_mask_6: 4.377  loss_ce_7: 1.988  loss_mask_7: 4.454  loss_ce_8: 1.968  loss_mask_8: 4.553  time: 2.4780  data_time: 0.4238  lr: 9.4826e-05  max_mem: 18445M
[01/24 03:35:58] d2.utils.events INFO:  eta: 1 day, 13:46:00  iter: 3459  total_loss: 66.38  loss_ce: 2.19  loss_mask: 4.591  loss_ce_0: 1.74  loss_mask_0: 5.202  loss_ce_1: 1.813  loss_mask_1: 4.445  loss_ce_2: 2.001  loss_mask_2: 4.589  loss_ce_3: 1.974  loss_mask_3: 4.648  loss_ce_4: 2.038  loss_mask_4: 4.945  loss_ce_5: 1.983  loss_mask_5: 4.608  loss_ce_6: 1.997  loss_mask_6: 4.508  loss_ce_7: 2.026  loss_mask_7: 4.45  loss_ce_8: 1.981  loss_mask_8: 4.598  time: 2.4773  data_time: 0.3781  lr: 9.4796e-05  max_mem: 18445M
[01/24 03:36:49] d2.utils.events INFO:  eta: 1 day, 13:49:22  iter: 3479  total_loss: 63.77  loss_ce: 2.096  loss_mask: 4.336  loss_ce_0: 1.726  loss_mask_0: 4.985  loss_ce_1: 1.8  loss_mask_1: 4.245  loss_ce_2: 1.981  loss_mask_2: 4.33  loss_ce_3: 1.99  loss_mask_3: 4.244  loss_ce_4: 2.014  loss_mask_4: 4.458  loss_ce_5: 1.994  loss_mask_5: 4.285  loss_ce_6: 1.989  loss_mask_6: 4.395  loss_ce_7: 2.032  loss_mask_7: 4.235  loss_ce_8: 2.002  loss_mask_8: 4.406  time: 2.4777  data_time: 0.4364  lr: 9.4766e-05  max_mem: 18445M
[01/24 03:37:39] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 03:37:40] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 03:37:40] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 03:41:21] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 23.543618670599493, 'error_1pix': 0.9510239789808526, 'error_3pix': 0.8871026444010635, 'mIoU': 0.02558985018642855, 'fwIoU': 0.059860857139557445, 'IoU-0': nan, 'IoU-1': 0.027057583793169717, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.03203821790558865, 'IoU-15': 0.011257187214624494, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 1.2092291025409955e-05, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.007153663564607632, 'IoU-23': 0.005461881248257313, 'IoU-24': 8.105859785273903e-05, 'IoU-25': 0.0009161708060402427, 'IoU-26': 0.019316624468098575, 'IoU-27': 0.001384906383847015, 'IoU-28': 2.8788267560346614e-06, 'IoU-29': 0.0, 'IoU-30': 0.0005752737996564552, 'IoU-31': 0.0, 'IoU-32': 0.01646452563192543, 'IoU-33': 0.0005583179066127995, 'IoU-34': 1.3023086622637405, 'IoU-35': 1.7381562320348924, 'IoU-36': 0.0, 'IoU-37': 1.1372881353040792e-05, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0014875261160867213, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.00011285069856220565, 'IoU-44': 0.0, 'IoU-45': 0.006719370873950093, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.04349214621161888, 'IoU-49': 5.44686389095088e-05, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 3.8144152218562434e-05, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.02254803121408922, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 4.236082377823177e-05, 'IoU-70': 0.0, 'IoU-71': 0.006364701104308563, 'IoU-72': 0.0, 'IoU-73': 0.007668162472497628, 'IoU-74': 0.0033533315348799036, 'IoU-75': 0.0, 'IoU-76': 0.5669369500169689, 'IoU-77': 4.366426589616703e-05, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.08067852484158475, 'IoU-81': 0.7392438914642594, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.07558458544904254, 'IoU-87': 0.0, 'IoU-88': 0.004273178138019644, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0149721200550141, 'IoU-93': 0.11648810092413986, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.03762012221545898, 'IoU-100': 0.00012160923062704152, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0023506486027157045, 'IoU-104': 0.0, 'IoU-105': 5.107061891972362e-05, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.004225849027121106, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.016023177485564907, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5443488434524796, 'pACC': 1.6177711174941152, 'ACC-0': nan, 'ACC-1': 0.02853972289002485, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0663913811526837, 'ACC-15': 0.013142510727061001, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 1.2094233185402719e-05, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.009782297516674808, 'ACC-23': 0.005833758724273398, 'ACC-24': 8.10696782347589e-05, 'ACC-25': 0.0009166790055804001, 'ACC-26': 0.01967198657719141, 'ACC-27': 0.0013871866248142313, 'ACC-28': 2.881920705623299e-06, 'ACC-29': 0.0, 'ACC-30': 0.0005768604960765148, 'ACC-31': 0.0, 'ACC-32': 0.016500898860479757, 'ACC-33': 0.0005627323288266091, 'ACC-34': 6.61259303696045, 'ACC-35': 92.33897653608015, 'ACC-36': 0.0, 'ACC-37': 1.1372974803714539e-05, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0014899996698748165, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.00011286226831242183, 'ACC-44': 0.0, 'ACC-45': 0.006852900318832038, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.11257321506023105, 'ACC-49': 5.4483187691448816e-05, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 3.814446504104281e-05, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.029782942243986275, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 4.2368218159039483e-05, 'ACC-70': 0.0, 'ACC-71': 0.006395035688158213, 'ACC-72': 0.0, 'ACC-73': 0.007690373199668164, 'ACC-74': 0.003649123387972511, 'ACC-75': 0.0, 'ACC-76': 2.521828516042175, 'ACC-77': 4.366489030615419e-05, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.08172963844448959, 'ACC-81': 2.3287649983324417, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.09449853461457962, 'ACC-87': 0.0, 'ACC-88': 0.00428583314711116, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.015129972005285822, 'ACC-93': 0.12288022043895389, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.039223793145208255, 'ACC-100': 0.000121639999124192, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0023613866062151692, 'ACC-104': 0.0, 'ACC-105': 5.107837951797843e-05, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.004243401510650938, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.01615081086088741, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 03:41:21] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 03:41:21] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 03:41:21] d2.evaluation.testing INFO: copypaste: 23.5436,0.9510,0.8871,0.0256,0.0599,0.5443,1.6178
[01/24 03:41:21] d2.utils.events INFO:  eta: 1 day, 13:51:48  iter: 3499  total_loss: 66.65  loss_ce: 2.124  loss_mask: 4.654  loss_ce_0: 1.721  loss_mask_0: 4.998  loss_ce_1: 1.813  loss_mask_1: 4.263  loss_ce_2: 1.979  loss_mask_2: 4.16  loss_ce_3: 1.996  loss_mask_3: 4.269  loss_ce_4: 2.033  loss_mask_4: 4.426  loss_ce_5: 2.015  loss_mask_5: 4.572  loss_ce_6: 2.026  loss_mask_6: 5.081  loss_ce_7: 2.067  loss_mask_7: 5.019  loss_ce_8: 2.014  loss_mask_8: 4.718  time: 2.4778  data_time: 0.4256  lr: 9.4736e-05  max_mem: 18445M
[01/24 03:42:14] d2.utils.events INFO:  eta: 1 day, 13:55:27  iter: 3519  total_loss: 70.41  loss_ce: 2.088  loss_mask: 4.687  loss_ce_0: 1.736  loss_mask_0: 5.176  loss_ce_1: 1.808  loss_mask_1: 4.353  loss_ce_2: 1.975  loss_mask_2: 4.579  loss_ce_3: 1.997  loss_mask_3: 4.471  loss_ce_4: 2.042  loss_mask_4: 4.719  loss_ce_5: 2.06  loss_mask_5: 4.962  loss_ce_6: 2.215  loss_mask_6: 6.864  loss_ce_7: 2.198  loss_mask_7: 5.158  loss_ce_8: 2.035  loss_mask_8: 5.139  time: 2.4789  data_time: 0.5197  lr: 9.4706e-05  max_mem: 18445M
[01/24 03:43:03] d2.utils.events INFO:  eta: 1 day, 13:52:24  iter: 3539  total_loss: 68.15  loss_ce: 2.05  loss_mask: 4.726  loss_ce_0: 1.792  loss_mask_0: 5.158  loss_ce_1: 1.847  loss_mask_1: 4.17  loss_ce_2: 1.957  loss_mask_2: 4.306  loss_ce_3: 1.978  loss_mask_3: 4.376  loss_ce_4: 2.021  loss_mask_4: 4.59  loss_ce_5: 2.02  loss_mask_5: 4.59  loss_ce_6: 2.11  loss_mask_6: 5.593  loss_ce_7: 1.997  loss_mask_7: 4.673  loss_ce_8: 1.987  loss_mask_8: 4.769  time: 2.4788  data_time: 0.4327  lr: 9.4675e-05  max_mem: 18445M
[01/24 03:43:54] d2.utils.events INFO:  eta: 1 day, 13:54:50  iter: 3559  total_loss: 69.39  loss_ce: 2.125  loss_mask: 5.107  loss_ce_0: 1.765  loss_mask_0: 5.492  loss_ce_1: 1.839  loss_mask_1: 4.491  loss_ce_2: 1.967  loss_mask_2: 4.585  loss_ce_3: 1.988  loss_mask_3: 4.721  loss_ce_4: 2.023  loss_mask_4: 4.811  loss_ce_5: 2.028  loss_mask_5: 4.808  loss_ce_6: 2.077  loss_mask_6: 5.467  loss_ce_7: 2.066  loss_mask_7: 5.075  loss_ce_8: 2.05  loss_mask_8: 4.935  time: 2.4790  data_time: 0.4407  lr: 9.4645e-05  max_mem: 18445M
[01/24 03:44:47] d2.utils.events INFO:  eta: 1 day, 13:58:13  iter: 3579  total_loss: 66.46  loss_ce: 2.054  loss_mask: 4.614  loss_ce_0: 1.766  loss_mask_0: 5.181  loss_ce_1: 1.85  loss_mask_1: 4.382  loss_ce_2: 1.965  loss_mask_2: 4.337  loss_ce_3: 1.98  loss_mask_3: 4.485  loss_ce_4: 2.005  loss_mask_4: 4.539  loss_ce_5: 2.022  loss_mask_5: 4.556  loss_ce_6: 2.049  loss_mask_6: 4.989  loss_ce_7: 2.058  loss_mask_7: 4.837  loss_ce_8: 2.003  loss_mask_8: 4.788  time: 2.4800  data_time: 0.5060  lr: 9.4615e-05  max_mem: 18445M
[01/24 03:45:38] d2.utils.events INFO:  eta: 1 day, 13:58:56  iter: 3599  total_loss: 66.46  loss_ce: 2.017  loss_mask: 4.565  loss_ce_0: 1.737  loss_mask_0: 5.198  loss_ce_1: 1.835  loss_mask_1: 4.312  loss_ce_2: 1.948  loss_mask_2: 4.425  loss_ce_3: 1.978  loss_mask_3: 4.544  loss_ce_4: 1.976  loss_mask_4: 4.544  loss_ce_5: 1.997  loss_mask_5: 4.573  loss_ce_6: 2.18  loss_mask_6: 5.064  loss_ce_7: 2.084  loss_mask_7: 4.671  loss_ce_8: 1.996  loss_mask_8: 4.598  time: 2.4803  data_time: 0.5239  lr: 9.4585e-05  max_mem: 18445M
[01/24 03:46:31] d2.utils.events INFO:  eta: 1 day, 14:03:20  iter: 3619  total_loss: 64  loss_ce: 1.955  loss_mask: 4.449  loss_ce_0: 1.779  loss_mask_0: 4.913  loss_ce_1: 1.815  loss_mask_1: 4.195  loss_ce_2: 1.921  loss_mask_2: 4.138  loss_ce_3: 1.958  loss_mask_3: 4.316  loss_ce_4: 1.967  loss_mask_4: 4.424  loss_ce_5: 1.972  loss_mask_5: 4.467  loss_ce_6: 2.179  loss_mask_6: 5.169  loss_ce_7: 2.004  loss_mask_7: 4.434  loss_ce_8: 1.975  loss_mask_8: 4.342  time: 2.4814  data_time: 0.5517  lr: 9.4555e-05  max_mem: 18446M
[01/24 03:47:24] d2.utils.events INFO:  eta: 1 day, 14:04:22  iter: 3639  total_loss: 63.96  loss_ce: 1.939  loss_mask: 4.438  loss_ce_0: 1.778  loss_mask_0: 5.115  loss_ce_1: 1.778  loss_mask_1: 4.121  loss_ce_2: 1.913  loss_mask_2: 4.265  loss_ce_3: 1.935  loss_mask_3: 4.406  loss_ce_4: 1.971  loss_mask_4: 4.546  loss_ce_5: 1.97  loss_mask_5: 4.662  loss_ce_6: 2.196  loss_mask_6: 4.882  loss_ce_7: 1.999  loss_mask_7: 4.459  loss_ce_8: 1.937  loss_mask_8: 4.331  time: 2.4822  data_time: 0.6450  lr: 9.4525e-05  max_mem: 18446M
[01/24 03:48:15] d2.utils.events INFO:  eta: 1 day, 14:04:12  iter: 3659  total_loss: 65.46  loss_ce: 1.945  loss_mask: 4.438  loss_ce_0: 1.729  loss_mask_0: 5.179  loss_ce_1: 1.806  loss_mask_1: 4.388  loss_ce_2: 1.963  loss_mask_2: 4.335  loss_ce_3: 1.973  loss_mask_3: 4.547  loss_ce_4: 1.984  loss_mask_4: 4.578  loss_ce_5: 1.997  loss_mask_5: 4.46  loss_ce_6: 2.248  loss_mask_6: 4.856  loss_ce_7: 2.036  loss_mask_7: 4.552  loss_ce_8: 1.973  loss_mask_8: 4.547  time: 2.4824  data_time: 0.4539  lr: 9.4494e-05  max_mem: 18446M
[01/24 03:49:08] d2.utils.events INFO:  eta: 1 day, 14:04:56  iter: 3679  total_loss: 66.92  loss_ce: 1.996  loss_mask: 4.517  loss_ce_0: 1.724  loss_mask_0: 5.285  loss_ce_1: 1.797  loss_mask_1: 4.446  loss_ce_2: 1.973  loss_mask_2: 4.443  loss_ce_3: 1.973  loss_mask_3: 4.522  loss_ce_4: 2.018  loss_mask_4: 4.683  loss_ce_5: 2.023  loss_mask_5: 4.76  loss_ce_6: 2.223  loss_mask_6: 5.179  loss_ce_7: 2.048  loss_mask_7: 4.767  loss_ce_8: 2.045  loss_mask_8: 4.556  time: 2.4834  data_time: 0.4990  lr: 9.4464e-05  max_mem: 18446M
[01/24 03:50:00] d2.utils.events INFO:  eta: 1 day, 14:05:07  iter: 3699  total_loss: 63.38  loss_ce: 1.943  loss_mask: 4.335  loss_ce_0: 1.755  loss_mask_0: 5.109  loss_ce_1: 1.803  loss_mask_1: 4.049  loss_ce_2: 1.937  loss_mask_2: 4.157  loss_ce_3: 1.952  loss_mask_3: 4.244  loss_ce_4: 1.967  loss_mask_4: 4.397  loss_ce_5: 1.986  loss_mask_5: 4.396  loss_ce_6: 2.11  loss_mask_6: 4.678  loss_ce_7: 1.98  loss_mask_7: 4.327  loss_ce_8: 1.98  loss_mask_8: 4.273  time: 2.4839  data_time: 0.5879  lr: 9.4434e-05  max_mem: 18446M
[01/24 03:50:54] d2.utils.events INFO:  eta: 1 day, 14:06:45  iter: 3719  total_loss: 62.51  loss_ce: 1.941  loss_mask: 4.264  loss_ce_0: 1.733  loss_mask_0: 4.973  loss_ce_1: 1.793  loss_mask_1: 4.047  loss_ce_2: 1.925  loss_mask_2: 4.077  loss_ce_3: 1.932  loss_mask_3: 4.108  loss_ce_4: 1.957  loss_mask_4: 4.088  loss_ce_5: 1.966  loss_mask_5: 4.203  loss_ce_6: 2.133  loss_mask_6: 4.626  loss_ce_7: 1.988  loss_mask_7: 4.364  loss_ce_8: 1.987  loss_mask_8: 4.267  time: 2.4852  data_time: 0.6333  lr: 9.4404e-05  max_mem: 18446M
[01/24 03:51:49] d2.utils.events INFO:  eta: 1 day, 14:09:18  iter: 3739  total_loss: 65.03  loss_ce: 1.964  loss_mask: 4.544  loss_ce_0: 1.736  loss_mask_0: 5.32  loss_ce_1: 1.795  loss_mask_1: 4.309  loss_ce_2: 1.92  loss_mask_2: 4.284  loss_ce_3: 1.933  loss_mask_3: 4.542  loss_ce_4: 1.938  loss_mask_4: 4.458  loss_ce_5: 1.956  loss_mask_5: 4.502  loss_ce_6: 2.072  loss_mask_6: 4.765  loss_ce_7: 1.98  loss_mask_7: 4.494  loss_ce_8: 1.969  loss_mask_8: 4.395  time: 2.4866  data_time: 0.6683  lr: 9.4374e-05  max_mem: 18446M
[01/24 03:52:42] d2.utils.events INFO:  eta: 1 day, 14:08:46  iter: 3759  total_loss: 64.98  loss_ce: 1.967  loss_mask: 4.458  loss_ce_0: 1.744  loss_mask_0: 5.224  loss_ce_1: 1.798  loss_mask_1: 4.23  loss_ce_2: 1.95  loss_mask_2: 4.381  loss_ce_3: 1.962  loss_mask_3: 4.517  loss_ce_4: 1.981  loss_mask_4: 4.422  loss_ce_5: 1.997  loss_mask_5: 4.566  loss_ce_6: 2.127  loss_mask_6: 4.808  loss_ce_7: 1.99  loss_mask_7: 4.389  loss_ce_8: 1.981  loss_mask_8: 4.465  time: 2.4874  data_time: 0.6047  lr: 9.4343e-05  max_mem: 18446M
[01/24 03:53:41] d2.utils.events INFO:  eta: 1 day, 14:17:41  iter: 3779  total_loss: 64.44  loss_ce: 1.964  loss_mask: 4.36  loss_ce_0: 1.702  loss_mask_0: 5.279  loss_ce_1: 1.789  loss_mask_1: 4.259  loss_ce_2: 1.945  loss_mask_2: 4.213  loss_ce_3: 2.019  loss_mask_3: 4.301  loss_ce_4: 2.003  loss_mask_4: 4.518  loss_ce_5: 1.999  loss_mask_5: 4.446  loss_ce_6: 2.127  loss_mask_6: 4.707  loss_ce_7: 1.986  loss_mask_7: 4.406  loss_ce_8: 1.989  loss_mask_8: 4.389  time: 2.4900  data_time: 0.7634  lr: 9.4313e-05  max_mem: 18446M
[01/24 03:54:37] d2.utils.events INFO:  eta: 1 day, 14:21:55  iter: 3799  total_loss: 64.41  loss_ce: 1.921  loss_mask: 4.345  loss_ce_0: 1.739  loss_mask_0: 5.05  loss_ce_1: 1.796  loss_mask_1: 4.282  loss_ce_2: 1.953  loss_mask_2: 4.208  loss_ce_3: 1.985  loss_mask_3: 4.446  loss_ce_4: 1.995  loss_mask_4: 4.458  loss_ce_5: 2.006  loss_mask_5: 4.662  loss_ce_6: 2.034  loss_mask_6: 4.763  loss_ce_7: 1.983  loss_mask_7: 4.355  loss_ce_8: 1.962  loss_mask_8: 4.284  time: 2.4914  data_time: 0.7272  lr: 9.4283e-05  max_mem: 18446M
[01/24 03:55:34] d2.utils.events INFO:  eta: 1 day, 14:22:56  iter: 3819  total_loss: 61.93  loss_ce: 1.929  loss_mask: 4.204  loss_ce_0: 1.741  loss_mask_0: 5.04  loss_ce_1: 1.801  loss_mask_1: 4.111  loss_ce_2: 1.93  loss_mask_2: 4.056  loss_ce_3: 1.947  loss_mask_3: 4.121  loss_ce_4: 1.97  loss_mask_4: 4.292  loss_ce_5: 1.978  loss_mask_5: 4.361  loss_ce_6: 1.995  loss_mask_6: 4.286  loss_ce_7: 1.972  loss_mask_7: 4.21  loss_ce_8: 1.954  loss_mask_8: 4.222  time: 2.4933  data_time: 0.7919  lr: 9.4253e-05  max_mem: 18446M
[01/24 03:56:30] d2.utils.events INFO:  eta: 1 day, 14:31:06  iter: 3839  total_loss: 61.09  loss_ce: 1.905  loss_mask: 4.161  loss_ce_0: 1.736  loss_mask_0: 4.993  loss_ce_1: 1.778  loss_mask_1: 4.107  loss_ce_2: 1.919  loss_mask_2: 4.113  loss_ce_3: 1.936  loss_mask_3: 4.151  loss_ce_4: 1.963  loss_mask_4: 4.267  loss_ce_5: 1.951  loss_mask_5: 4.232  loss_ce_6: 1.975  loss_mask_6: 4.102  loss_ce_7: 1.944  loss_mask_7: 4.168  loss_ce_8: 1.944  loss_mask_8: 4.109  time: 2.4949  data_time: 0.7708  lr: 9.4223e-05  max_mem: 18446M
[01/24 03:57:24] d2.utils.events INFO:  eta: 1 day, 14:34:07  iter: 3859  total_loss: 63.74  loss_ce: 1.935  loss_mask: 4.37  loss_ce_0: 1.699  loss_mask_0: 5.071  loss_ce_1: 1.805  loss_mask_1: 4.347  loss_ce_2: 1.917  loss_mask_2: 4.248  loss_ce_3: 1.951  loss_mask_3: 4.415  loss_ce_4: 1.978  loss_mask_4: 4.388  loss_ce_5: 1.962  loss_mask_5: 4.455  loss_ce_6: 1.981  loss_mask_6: 4.463  loss_ce_7: 1.968  loss_mask_7: 4.341  loss_ce_8: 1.95  loss_mask_8: 4.335  time: 2.4960  data_time: 0.6822  lr: 9.4192e-05  max_mem: 18446M
[01/24 03:58:24] d2.utils.events INFO:  eta: 1 day, 14:37:37  iter: 3879  total_loss: 61.09  loss_ce: 1.91  loss_mask: 4.028  loss_ce_0: 1.691  loss_mask_0: 4.978  loss_ce_1: 1.733  loss_mask_1: 4.03  loss_ce_2: 1.912  loss_mask_2: 4.044  loss_ce_3: 1.934  loss_mask_3: 4.071  loss_ce_4: 1.937  loss_mask_4: 4.224  loss_ce_5: 1.949  loss_mask_5: 4.238  loss_ce_6: 2  loss_mask_6: 4.258  loss_ce_7: 1.941  loss_mask_7: 4.254  loss_ce_8: 1.932  loss_mask_8: 4.053  time: 2.4986  data_time: 0.7791  lr: 9.4162e-05  max_mem: 18446M
[01/24 03:59:12] d2.utils.events INFO:  eta: 1 day, 14:35:46  iter: 3899  total_loss: 58.64  loss_ce: 1.898  loss_mask: 3.872  loss_ce_0: 1.678  loss_mask_0: 4.876  loss_ce_1: 1.746  loss_mask_1: 3.823  loss_ce_2: 1.909  loss_mask_2: 3.852  loss_ce_3: 1.929  loss_mask_3: 3.995  loss_ce_4: 1.923  loss_mask_4: 3.937  loss_ce_5: 1.932  loss_mask_5: 3.91  loss_ce_6: 2  loss_mask_6: 4.136  loss_ce_7: 1.933  loss_mask_7: 3.889  loss_ce_8: 1.908  loss_mask_8: 3.889  time: 2.4981  data_time: 0.3564  lr: 9.4132e-05  max_mem: 18446M
[01/24 04:00:01] d2.utils.events INFO:  eta: 1 day, 14:31:39  iter: 3919  total_loss: 60.99  loss_ce: 1.969  loss_mask: 4.056  loss_ce_0: 1.639  loss_mask_0: 4.851  loss_ce_1: 1.71  loss_mask_1: 4.022  loss_ce_2: 1.913  loss_mask_2: 3.878  loss_ce_3: 1.951  loss_mask_3: 4.144  loss_ce_4: 1.932  loss_mask_4: 4.072  loss_ce_5: 1.968  loss_mask_5: 4.112  loss_ce_6: 2.274  loss_mask_6: 4.304  loss_ce_7: 1.958  loss_mask_7: 4.153  loss_ce_8: 1.978  loss_mask_8: 4.118  time: 2.4978  data_time: 0.3964  lr: 9.4102e-05  max_mem: 18446M
[01/24 04:00:51] d2.utils.events INFO:  eta: 1 day, 14:31:27  iter: 3939  total_loss: 63.86  loss_ce: 1.939  loss_mask: 4.333  loss_ce_0: 1.671  loss_mask_0: 5.003  loss_ce_1: 1.753  loss_mask_1: 4.226  loss_ce_2: 1.935  loss_mask_2: 4.199  loss_ce_3: 1.981  loss_mask_3: 4.371  loss_ce_4: 1.947  loss_mask_4: 4.425  loss_ce_5: 1.974  loss_mask_5: 4.36  loss_ce_6: 2.067  loss_mask_6: 4.605  loss_ce_7: 1.955  loss_mask_7: 4.332  loss_ce_8: 1.946  loss_mask_8: 4.34  time: 2.4978  data_time: 0.4162  lr: 9.4072e-05  max_mem: 18446M
[01/24 04:01:41] d2.utils.events INFO:  eta: 1 day, 14:34:19  iter: 3959  total_loss: 62.21  loss_ce: 1.943  loss_mask: 4.149  loss_ce_0: 1.627  loss_mask_0: 4.921  loss_ce_1: 1.745  loss_mask_1: 4.169  loss_ce_2: 1.913  loss_mask_2: 4.056  loss_ce_3: 1.949  loss_mask_3: 4.293  loss_ce_4: 1.958  loss_mask_4: 4.164  loss_ce_5: 1.989  loss_mask_5: 4.241  loss_ce_6: 2.043  loss_mask_6: 4.313  loss_ce_7: 1.97  loss_mask_7: 4.166  loss_ce_8: 1.942  loss_mask_8: 4.084  time: 2.4977  data_time: 0.4103  lr: 9.4041e-05  max_mem: 18446M
[01/24 04:02:33] d2.utils.events INFO:  eta: 1 day, 14:37:51  iter: 3979  total_loss: 60.8  loss_ce: 1.947  loss_mask: 3.982  loss_ce_0: 1.625  loss_mask_0: 4.929  loss_ce_1: 1.747  loss_mask_1: 4.007  loss_ce_2: 1.926  loss_mask_2: 3.885  loss_ce_3: 1.965  loss_mask_3: 4.043  loss_ce_4: 1.954  loss_mask_4: 4.027  loss_ce_5: 1.975  loss_mask_5: 4.117  loss_ce_6: 2.026  loss_mask_6: 4.261  loss_ce_7: 1.962  loss_mask_7: 4.084  loss_ce_8: 1.95  loss_mask_8: 3.998  time: 2.4983  data_time: 0.4765  lr: 9.4011e-05  max_mem: 18446M
[01/24 04:03:22] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 04:03:23] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 04:03:23] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 04:07:13] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 15.286809788876386, 'error_1pix': 0.9207817919406667, 'error_3pix': 0.825153739003979, 'mIoU': 0.0905669010373138, 'fwIoU': 0.6328037851951402, 'IoU-0': nan, 'IoU-1': 4.508977480523403, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0001336377872101308, 'IoU-14': 1.4973483712075395, 'IoU-15': 0.09368637664819515, 'IoU-16': 5.031561795457215e-05, 'IoU-17': 0.0, 'IoU-18': 0.0004369552754279212, 'IoU-19': 0.014413651543241961, 'IoU-20': 0.0002244469665177702, 'IoU-21': 0.0, 'IoU-22': 0.00022193680532566217, 'IoU-23': 0.015109363492298996, 'IoU-24': 6.231396555047192e-06, 'IoU-25': 0.0002951696297917255, 'IoU-26': 0.00019697415574831349, 'IoU-27': 0.010390468988129974, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.023031339236790817, 'IoU-31': 2.952574616900263, 'IoU-32': 1.5031580301533631, 'IoU-33': 0.03493056391657814, 'IoU-34': 0.4129917038297527, 'IoU-35': 1.663459332245283e-05, 'IoU-36': 0.005592316400762438, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.000107053353984639, 'IoU-41': 0.0, 'IoU-42': 2.6629689891678345, 'IoU-43': 0.011688370376863235, 'IoU-44': 0.025613992104125276, 'IoU-45': 7.568006102840121e-06, 'IoU-46': 0.02942078710584112, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0018197878949154222, 'IoU-50': 0.0014246973399772188, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 1.0401727616017902, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 3.1740832295408114e-05, 'IoU-68': 0.2509148345522717, 'IoU-69': 0.09860577624654085, 'IoU-70': 2.1180393944737177e-05, 'IoU-71': 0.0002974676250559404, 'IoU-72': 0.03626042610492146, 'IoU-73': 0.0003752973127387829, 'IoU-74': 0.01935379644588045, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 1.3114824098085558, 'IoU-79': 0.00031170910771709373, 'IoU-80': 0.0010930800744089419, 'IoU-81': 0.0, 'IoU-82': 0.7486237383588392, 'IoU-83': 0.0, 'IoU-84': 0.004558762961097768, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.00018847881761960302, 'IoU-89': 0.055969000889358474, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.010704575634706706, 'IoU-93': 0.0, 'IoU-94': 0.00010610812964109381, 'IoU-95': 0.00037737510456435186, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.002558648744486112, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.9953227540072008, 'pACC': 2.9461676248669524, 'ACC-0': nan, 'ACC-1': 4.566653181587967, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0001336702119719943, 'ACC-14': 8.776518817920834, 'ACC-15': 0.10850149806531778, 'ACC-16': 5.031621223579586e-05, 'ACC-17': 0.0, 'ACC-18': 0.00043875679009710997, 'ACC-19': 0.014500985589297861, 'ACC-20': 0.00022477938365369837, 'ACC-21': 0.0, 'ACC-22': 0.00022276794800284218, 'ACC-23': 0.016891688009364247, 'ACC-24': 6.236129094981454e-06, 'ACC-25': 0.00029520171366148476, 'ACC-26': 0.0001976625641548063, 'ACC-27': 0.011145424243680195, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.024064104675191864, 'ACC-31': 78.42451670290882, 'ACC-32': 4.864389733907306, 'ACC-33': 0.035412145586109, 'ACC-34': 0.5521571397372066, 'ACC-35': 1.663464820339007e-05, 'ACC-36': 0.0056641272815718515, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0001070841651860751, 'ACC-41': 0.0, 'ACC-42': 54.53755162292255, 'ACC-43': 0.011704909439497943, 'ACC-44': 0.02589881507901863, 'ACC-45': 7.568084283635603e-06, 'ACC-46': 0.030090473064870234, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0018297270533044895, 'ACC-50': 0.001426951256946262, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 4.777677221094559, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 3.174104050939715e-05, 'ACC-68': 0.28963523327933643, 'ACC-69': 0.1376331566896398, 'ACC-70': 2.1180526285244924e-05, 'ACC-71': 0.0002976999372073651, 'ACC-72': 0.03686142864651962, 'ACC-73': 0.0003756791505585023, 'ACC-74': 0.019574551427422694, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 29.57767616071173, 'ACC-79': 0.00031186884845657776, 'ACC-80': 0.0010947414701670234, 'ACC-81': 0.0, 'ACC-82': 4.155298314194747, 'ACC-83': 0.0, 'ACC-84': 0.0045933923427355725, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.00018852638477028562, 'ACC-89': 0.07398175466937754, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.013053866824109384, 'ACC-93': 0.0, 'ACC-94': 0.0001064344813660592, 'ACC-95': 0.0003777516849299113, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0025593397987274964, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 04:07:13] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 04:07:13] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 04:07:13] d2.evaluation.testing INFO: copypaste: 15.2868,0.9208,0.8252,0.0906,0.6328,0.9953,2.9462
[01/24 04:07:13] d2.utils.events INFO:  eta: 1 day, 14:36:14  iter: 3999  total_loss: 59.3  loss_ce: 1.934  loss_mask: 3.99  loss_ce_0: 1.655  loss_mask_0: 4.833  loss_ce_1: 1.729  loss_mask_1: 3.956  loss_ce_2: 1.899  loss_mask_2: 3.893  loss_ce_3: 1.927  loss_mask_3: 3.933  loss_ce_4: 1.945  loss_mask_4: 3.955  loss_ce_5: 1.984  loss_mask_5: 4.062  loss_ce_6: 1.965  loss_mask_6: 3.87  loss_ce_7: 1.931  loss_mask_7: 3.964  loss_ce_8: 1.961  loss_mask_8: 4.007  time: 2.4981  data_time: 0.4012  lr: 9.3981e-05  max_mem: 18446M
[01/24 04:08:06] d2.utils.events INFO:  eta: 1 day, 14:36:19  iter: 4019  total_loss: 61.61  loss_ce: 1.926  loss_mask: 4.048  loss_ce_0: 1.655  loss_mask_0: 5.155  loss_ce_1: 1.734  loss_mask_1: 4.008  loss_ce_2: 1.931  loss_mask_2: 3.958  loss_ce_3: 1.953  loss_mask_3: 4.101  loss_ce_4: 1.945  loss_mask_4: 4.136  loss_ce_5: 1.975  loss_mask_5: 4.305  loss_ce_6: 1.984  loss_mask_6: 4.165  loss_ce_7: 1.952  loss_mask_7: 4.265  loss_ce_8: 1.943  loss_mask_8: 3.955  time: 2.4988  data_time: 0.5065  lr: 9.3951e-05  max_mem: 18446M
[01/24 04:08:55] d2.utils.events INFO:  eta: 1 day, 14:37:20  iter: 4039  total_loss: 59.74  loss_ce: 1.924  loss_mask: 3.955  loss_ce_0: 1.683  loss_mask_0: 4.923  loss_ce_1: 1.714  loss_mask_1: 3.85  loss_ce_2: 1.907  loss_mask_2: 3.886  loss_ce_3: 1.949  loss_mask_3: 4.052  loss_ce_4: 1.94  loss_mask_4: 4.124  loss_ce_5: 1.961  loss_mask_5: 4.09  loss_ce_6: 2.004  loss_mask_6: 4.179  loss_ce_7: 1.942  loss_mask_7: 3.979  loss_ce_8: 1.969  loss_mask_8: 3.944  time: 2.4985  data_time: 0.4602  lr: 9.3921e-05  max_mem: 18446M
[01/24 04:09:49] d2.utils.events INFO:  eta: 1 day, 14:44:31  iter: 4059  total_loss: 61.56  loss_ce: 1.944  loss_mask: 4.174  loss_ce_0: 1.659  loss_mask_0: 4.967  loss_ce_1: 1.72  loss_mask_1: 4.094  loss_ce_2: 1.916  loss_mask_2: 4.083  loss_ce_3: 1.931  loss_mask_3: 4.134  loss_ce_4: 1.933  loss_mask_4: 4.141  loss_ce_5: 1.937  loss_mask_5: 4.202  loss_ce_6: 1.993  loss_mask_6: 4.256  loss_ce_7: 1.958  loss_mask_7: 4.25  loss_ce_8: 1.986  loss_mask_8: 4.195  time: 2.4994  data_time: 0.4879  lr: 9.389e-05  max_mem: 18446M
[01/24 04:10:36] d2.utils.events INFO:  eta: 1 day, 14:35:40  iter: 4079  total_loss: 58.56  loss_ce: 1.898  loss_mask: 3.838  loss_ce_0: 1.675  loss_mask_0: 4.95  loss_ce_1: 1.67  loss_mask_1: 3.947  loss_ce_2: 1.895  loss_mask_2: 3.762  loss_ce_3: 1.906  loss_mask_3: 3.843  loss_ce_4: 1.904  loss_mask_4: 3.947  loss_ce_5: 1.913  loss_mask_5: 3.761  loss_ce_6: 1.962  loss_mask_6: 3.969  loss_ce_7: 1.927  loss_mask_7: 4.212  loss_ce_8: 1.963  loss_mask_8: 3.795  time: 2.4986  data_time: 0.3812  lr: 9.386e-05  max_mem: 18446M
[01/24 04:11:24] d2.utils.events INFO:  eta: 1 day, 14:38:12  iter: 4099  total_loss: 61.18  loss_ce: 1.919  loss_mask: 3.975  loss_ce_0: 1.652  loss_mask_0: 4.844  loss_ce_1: 1.723  loss_mask_1: 3.99  loss_ce_2: 1.929  loss_mask_2: 4.114  loss_ce_3: 1.939  loss_mask_3: 4.161  loss_ce_4: 1.942  loss_mask_4: 4.143  loss_ce_5: 1.952  loss_mask_5: 4.211  loss_ce_6: 1.98  loss_mask_6: 4.126  loss_ce_7: 1.946  loss_mask_7: 4.116  loss_ce_8: 1.988  loss_mask_8: 4.038  time: 2.4983  data_time: 0.4059  lr: 9.383e-05  max_mem: 18446M
[01/24 04:12:17] d2.utils.events INFO:  eta: 1 day, 14:40:35  iter: 4119  total_loss: 60.76  loss_ce: 1.896  loss_mask: 3.925  loss_ce_0: 1.641  loss_mask_0: 4.915  loss_ce_1: 1.723  loss_mask_1: 4.052  loss_ce_2: 1.919  loss_mask_2: 4.059  loss_ce_3: 1.935  loss_mask_3: 4.073  loss_ce_4: 1.942  loss_mask_4: 4.077  loss_ce_5: 1.957  loss_mask_5: 4.226  loss_ce_6: 1.973  loss_mask_6: 4.269  loss_ce_7: 1.926  loss_mask_7: 4.047  loss_ce_8: 1.928  loss_mask_8: 3.925  time: 2.4988  data_time: 0.4273  lr: 9.38e-05  max_mem: 18446M
[01/24 04:13:04] d2.utils.events INFO:  eta: 1 day, 14:41:04  iter: 4139  total_loss: 59.05  loss_ce: 1.887  loss_mask: 3.862  loss_ce_0: 1.624  loss_mask_0: 4.983  loss_ce_1: 1.706  loss_mask_1: 3.948  loss_ce_2: 1.893  loss_mask_2: 3.887  loss_ce_3: 1.918  loss_mask_3: 3.913  loss_ce_4: 1.904  loss_mask_4: 3.942  loss_ce_5: 1.921  loss_mask_5: 3.95  loss_ce_6: 1.979  loss_mask_6: 4.223  loss_ce_7: 1.913  loss_mask_7: 3.964  loss_ce_8: 1.927  loss_mask_8: 3.846  time: 2.4982  data_time: 0.3685  lr: 9.377e-05  max_mem: 18446M
[01/24 04:13:52] d2.utils.events INFO:  eta: 1 day, 14:40:14  iter: 4159  total_loss: 58.29  loss_ce: 1.878  loss_mask: 3.861  loss_ce_0: 1.611  loss_mask_0: 4.705  loss_ce_1: 1.702  loss_mask_1: 3.787  loss_ce_2: 1.891  loss_mask_2: 3.781  loss_ce_3: 1.912  loss_mask_3: 3.968  loss_ce_4: 1.88  loss_mask_4: 4.003  loss_ce_5: 1.909  loss_mask_5: 3.885  loss_ce_6: 1.946  loss_mask_6: 4.022  loss_ce_7: 1.905  loss_mask_7: 3.836  loss_ce_8: 1.949  loss_mask_8: 3.745  time: 2.4977  data_time: 0.3653  lr: 9.3739e-05  max_mem: 18446M
[01/24 04:14:44] d2.utils.events INFO:  eta: 1 day, 14:40:11  iter: 4179  total_loss: 59.32  loss_ce: 1.874  loss_mask: 4.008  loss_ce_0: 1.655  loss_mask_0: 4.765  loss_ce_1: 1.676  loss_mask_1: 4.012  loss_ce_2: 1.905  loss_mask_2: 3.994  loss_ce_3: 1.903  loss_mask_3: 3.942  loss_ce_4: 1.889  loss_mask_4: 3.965  loss_ce_5: 1.899  loss_mask_5: 3.931  loss_ce_6: 1.983  loss_mask_6: 4.063  loss_ce_7: 1.907  loss_mask_7: 3.997  loss_ce_8: 1.94  loss_mask_8: 3.964  time: 2.4981  data_time: 0.4351  lr: 9.3709e-05  max_mem: 18446M
[01/24 04:15:31] d2.utils.events INFO:  eta: 1 day, 14:39:09  iter: 4199  total_loss: 60.63  loss_ce: 1.875  loss_mask: 4.142  loss_ce_0: 1.643  loss_mask_0: 5.105  loss_ce_1: 1.691  loss_mask_1: 4.017  loss_ce_2: 1.911  loss_mask_2: 4.138  loss_ce_3: 1.921  loss_mask_3: 4.004  loss_ce_4: 1.917  loss_mask_4: 4.032  loss_ce_5: 1.907  loss_mask_5: 4.037  loss_ce_6: 1.962  loss_mask_6: 4.078  loss_ce_7: 1.915  loss_mask_7: 4.071  loss_ce_8: 1.932  loss_mask_8: 4.11  time: 2.4975  data_time: 0.3869  lr: 9.3679e-05  max_mem: 18446M
[01/24 04:16:21] d2.utils.events INFO:  eta: 1 day, 14:42:10  iter: 4219  total_loss: 59.27  loss_ce: 1.87  loss_mask: 4.003  loss_ce_0: 1.642  loss_mask_0: 4.68  loss_ce_1: 1.676  loss_mask_1: 3.909  loss_ce_2: 1.905  loss_mask_2: 3.969  loss_ce_3: 1.913  loss_mask_3: 3.968  loss_ce_4: 1.897  loss_mask_4: 3.931  loss_ce_5: 1.906  loss_mask_5: 3.949  loss_ce_6: 1.94  loss_mask_6: 4.017  loss_ce_7: 1.898  loss_mask_7: 3.904  loss_ce_8: 1.912  loss_mask_8: 3.955  time: 2.4974  data_time: 0.4245  lr: 9.3649e-05  max_mem: 18446M
[01/24 04:17:11] d2.utils.events INFO:  eta: 1 day, 14:45:04  iter: 4239  total_loss: 57.26  loss_ce: 1.824  loss_mask: 3.756  loss_ce_0: 1.644  loss_mask_0: 4.498  loss_ce_1: 1.648  loss_mask_1: 3.883  loss_ce_2: 1.874  loss_mask_2: 3.849  loss_ce_3: 1.896  loss_mask_3: 3.824  loss_ce_4: 1.883  loss_mask_4: 3.771  loss_ce_5: 1.895  loss_mask_5: 3.742  loss_ce_6: 1.927  loss_mask_6: 3.945  loss_ce_7: 1.866  loss_mask_7: 3.802  loss_ce_8: 1.879  loss_mask_8: 3.716  time: 2.4974  data_time: 0.4223  lr: 9.3618e-05  max_mem: 18446M
[01/24 04:17:58] d2.utils.events INFO:  eta: 1 day, 14:45:09  iter: 4259  total_loss: 56.92  loss_ce: 1.861  loss_mask: 3.758  loss_ce_0: 1.6  loss_mask_0: 4.534  loss_ce_1: 1.659  loss_mask_1: 3.806  loss_ce_2: 1.91  loss_mask_2: 3.79  loss_ce_3: 1.911  loss_mask_3: 3.788  loss_ce_4: 1.902  loss_mask_4: 3.793  loss_ce_5: 1.901  loss_mask_5: 3.837  loss_ce_6: 1.932  loss_mask_6: 3.72  loss_ce_7: 1.907  loss_mask_7: 3.736  loss_ce_8: 1.9  loss_mask_8: 3.721  time: 2.4969  data_time: 0.3734  lr: 9.3588e-05  max_mem: 18446M
[01/24 04:18:48] d2.utils.events INFO:  eta: 1 day, 14:46:06  iter: 4279  total_loss: 57.48  loss_ce: 1.83  loss_mask: 3.834  loss_ce_0: 1.615  loss_mask_0: 4.606  loss_ce_1: 1.627  loss_mask_1: 3.919  loss_ce_2: 1.87  loss_mask_2: 3.833  loss_ce_3: 1.895  loss_mask_3: 3.924  loss_ce_4: 1.892  loss_mask_4: 3.823  loss_ce_5: 1.886  loss_mask_5: 3.842  loss_ce_6: 1.93  loss_mask_6: 3.968  loss_ce_7: 1.879  loss_mask_7: 3.933  loss_ce_8: 1.875  loss_mask_8: 3.778  time: 2.4967  data_time: 0.4038  lr: 9.3558e-05  max_mem: 18446M
[01/24 04:19:36] d2.utils.events INFO:  eta: 1 day, 14:46:38  iter: 4299  total_loss: 57.28  loss_ce: 1.839  loss_mask: 3.746  loss_ce_0: 1.579  loss_mask_0: 4.699  loss_ce_1: 1.649  loss_mask_1: 3.843  loss_ce_2: 1.878  loss_mask_2: 3.818  loss_ce_3: 1.9  loss_mask_3: 3.778  loss_ce_4: 1.883  loss_mask_4: 3.852  loss_ce_5: 1.888  loss_mask_5: 3.775  loss_ce_6: 1.914  loss_mask_6: 3.762  loss_ce_7: 1.885  loss_mask_7: 3.828  loss_ce_8: 1.888  loss_mask_8: 3.764  time: 2.4963  data_time: 0.3775  lr: 9.3528e-05  max_mem: 18446M
[01/24 04:20:22] d2.utils.events INFO:  eta: 1 day, 14:41:44  iter: 4319  total_loss: 57.87  loss_ce: 1.832  loss_mask: 3.85  loss_ce_0: 1.538  loss_mask_0: 4.807  loss_ce_1: 1.594  loss_mask_1: 3.954  loss_ce_2: 1.859  loss_mask_2: 3.856  loss_ce_3: 1.897  loss_mask_3: 3.92  loss_ce_4: 1.885  loss_mask_4: 3.867  loss_ce_5: 1.872  loss_mask_5: 3.87  loss_ce_6: 1.92  loss_mask_6: 3.964  loss_ce_7: 1.888  loss_mask_7: 3.876  loss_ce_8: 1.914  loss_mask_8: 3.851  time: 2.4954  data_time: 0.3501  lr: 9.3498e-05  max_mem: 18446M
[01/24 04:21:14] d2.utils.events INFO:  eta: 1 day, 14:44:01  iter: 4339  total_loss: 59.08  loss_ce: 1.878  loss_mask: 3.904  loss_ce_0: 1.542  loss_mask_0: 4.985  loss_ce_1: 1.59  loss_mask_1: 4.109  loss_ce_2: 1.899  loss_mask_2: 3.905  loss_ce_3: 1.938  loss_mask_3: 3.96  loss_ce_4: 1.917  loss_mask_4: 3.971  loss_ce_5: 1.906  loss_mask_5: 4.029  loss_ce_6: 1.938  loss_mask_6: 4.121  loss_ce_7: 1.905  loss_mask_7: 3.983  loss_ce_8: 1.953  loss_mask_8: 3.921  time: 2.4958  data_time: 0.4530  lr: 9.3467e-05  max_mem: 18446M
[01/24 04:22:02] d2.utils.events INFO:  eta: 1 day, 14:44:34  iter: 4359  total_loss: 58.22  loss_ce: 1.892  loss_mask: 3.839  loss_ce_0: 1.503  loss_mask_0: 4.731  loss_ce_1: 1.564  loss_mask_1: 4.017  loss_ce_2: 1.972  loss_mask_2: 4.003  loss_ce_3: 2.01  loss_mask_3: 3.936  loss_ce_4: 1.987  loss_mask_4: 4.099  loss_ce_5: 1.894  loss_mask_5: 3.907  loss_ce_6: 1.929  loss_mask_6: 3.875  loss_ce_7: 1.884  loss_mask_7: 3.735  loss_ce_8: 2.009  loss_mask_8: 3.839  time: 2.4953  data_time: 0.3900  lr: 9.3437e-05  max_mem: 18446M
[01/24 04:22:49] d2.utils.events INFO:  eta: 1 day, 14:41:36  iter: 4379  total_loss: 58.4  loss_ce: 1.852  loss_mask: 3.818  loss_ce_0: 1.511  loss_mask_0: 4.701  loss_ce_1: 1.591  loss_mask_1: 3.914  loss_ce_2: 1.938  loss_mask_2: 3.902  loss_ce_3: 1.96  loss_mask_3: 3.96  loss_ce_4: 1.971  loss_mask_4: 3.997  loss_ce_5: 1.879  loss_mask_5: 3.818  loss_ce_6: 1.91  loss_mask_6: 3.785  loss_ce_7: 1.863  loss_mask_7: 3.765  loss_ce_8: 1.957  loss_mask_8: 3.796  time: 2.4948  data_time: 0.3694  lr: 9.3407e-05  max_mem: 18446M
[01/24 04:23:40] d2.utils.events INFO:  eta: 1 day, 14:42:43  iter: 4399  total_loss: 55.5  loss_ce: 1.832  loss_mask: 3.684  loss_ce_0: 1.499  loss_mask_0: 4.449  loss_ce_1: 1.571  loss_mask_1: 3.739  loss_ce_2: 1.902  loss_mask_2: 3.638  loss_ce_3: 1.938  loss_mask_3: 3.677  loss_ce_4: 1.981  loss_mask_4: 3.731  loss_ce_5: 1.86  loss_mask_5: 3.721  loss_ce_6: 1.891  loss_mask_6: 3.715  loss_ce_7: 1.851  loss_mask_7: 3.669  loss_ce_8: 1.907  loss_mask_8: 3.573  time: 2.4950  data_time: 0.4421  lr: 9.3377e-05  max_mem: 18446M
[01/24 04:24:27] d2.utils.events INFO:  eta: 1 day, 14:41:13  iter: 4419  total_loss: 57.86  loss_ce: 1.828  loss_mask: 3.867  loss_ce_0: 1.534  loss_mask_0: 4.668  loss_ce_1: 1.589  loss_mask_1: 3.883  loss_ce_2: 1.907  loss_mask_2: 3.947  loss_ce_3: 1.906  loss_mask_3: 3.957  loss_ce_4: 1.908  loss_mask_4: 3.998  loss_ce_5: 1.858  loss_mask_5: 3.787  loss_ce_6: 1.891  loss_mask_6: 3.805  loss_ce_7: 1.877  loss_mask_7: 3.943  loss_ce_8: 1.899  loss_mask_8: 3.865  time: 2.4942  data_time: 0.3533  lr: 9.3346e-05  max_mem: 18446M
[01/24 04:25:14] d2.utils.events INFO:  eta: 1 day, 14:37:38  iter: 4439  total_loss: 56.88  loss_ce: 1.841  loss_mask: 3.731  loss_ce_0: 1.543  loss_mask_0: 4.849  loss_ce_1: 1.578  loss_mask_1: 3.921  loss_ce_2: 1.871  loss_mask_2: 3.775  loss_ce_3: 1.898  loss_mask_3: 3.854  loss_ce_4: 1.897  loss_mask_4: 3.859  loss_ce_5: 1.891  loss_mask_5: 3.836  loss_ce_6: 1.903  loss_mask_6: 3.791  loss_ce_7: 1.873  loss_mask_7: 3.718  loss_ce_8: 1.902  loss_mask_8: 3.768  time: 2.4937  data_time: 0.3914  lr: 9.3316e-05  max_mem: 18446M
[01/24 04:25:59] d2.utils.events INFO:  eta: 1 day, 14:36:10  iter: 4459  total_loss: 57.5  loss_ce: 1.839  loss_mask: 3.778  loss_ce_0: 1.526  loss_mask_0: 4.683  loss_ce_1: 1.603  loss_mask_1: 3.988  loss_ce_2: 1.905  loss_mask_2: 3.809  loss_ce_3: 1.894  loss_mask_3: 3.735  loss_ce_4: 1.874  loss_mask_4: 3.764  loss_ce_5: 1.857  loss_mask_5: 3.752  loss_ce_6: 1.913  loss_mask_6: 3.828  loss_ce_7: 1.885  loss_mask_7: 3.816  loss_ce_8: 1.897  loss_mask_8: 3.762  time: 2.4926  data_time: 0.3684  lr: 9.3286e-05  max_mem: 18446M
[01/24 04:26:44] d2.utils.events INFO:  eta: 1 day, 14:31:18  iter: 4479  total_loss: 56.3  loss_ce: 1.814  loss_mask: 3.661  loss_ce_0: 1.499  loss_mask_0: 4.534  loss_ce_1: 1.553  loss_mask_1: 3.847  loss_ce_2: 1.864  loss_mask_2: 3.732  loss_ce_3: 1.859  loss_mask_3: 3.676  loss_ce_4: 1.852  loss_mask_4: 3.749  loss_ce_5: 1.843  loss_mask_5: 3.653  loss_ce_6: 1.895  loss_mask_6: 3.744  loss_ce_7: 1.848  loss_mask_7: 3.723  loss_ce_8: 1.894  loss_mask_8: 3.689  time: 2.4914  data_time: 0.3591  lr: 9.3256e-05  max_mem: 18446M
[01/24 04:27:31] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 04:27:31] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 04:27:31] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 04:30:54] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 10.4680359845636, 'error_1pix': 0.798702139742679, 'error_3pix': 0.6802242539241056, 'mIoU': 0.5746246589878757, 'fwIoU': 6.182500144172405, 'IoU-0': nan, 'IoU-1': 52.63951446089313, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.11381699179555209, 'IoU-13': 7.190654589019685, 'IoU-14': 2.3018291374471045, 'IoU-15': 0.14869754537895882, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.01019476506421986, 'IoU-19': 0.8099282680660881, 'IoU-20': 0.00027699275977858303, 'IoU-21': 0.14140910939166054, 'IoU-22': 0.0, 'IoU-23': 0.6921002441376487, 'IoU-24': 0.2538652135505487, 'IoU-25': 0.00013975891835044847, 'IoU-26': 1.5285684280956275, 'IoU-27': 0.5097991522956049, 'IoU-28': 4.288608945309309, 'IoU-29': 8.06319003772444e-06, 'IoU-30': 0.5364789911598512, 'IoU-31': 1.5172840258003275, 'IoU-32': 1.5498695193033207, 'IoU-33': 4.344877458146292, 'IoU-34': 3.3675547301730107, 'IoU-35': 1.146863319062634, 'IoU-36': 0.01865939949583334, 'IoU-37': 0.8233499286108833, 'IoU-38': 0.0, 'IoU-39': 1.6504326064734742, 'IoU-40': 3.119407040127155, 'IoU-41': 2.903751974088436, 'IoU-42': 0.0038670881792782076, 'IoU-43': 0.0011942822412735448, 'IoU-44': 0.0029477853374721722, 'IoU-45': 1.470010062224866, 'IoU-46': 1.2345398065632499e-05, 'IoU-47': 3.455308801519806, 'IoU-48': 0.0, 'IoU-49': 0.12047096574949757, 'IoU-50': 8.468756991135328e-05, 'IoU-51': 0.002938570782472699, 'IoU-52': 0.0, 'IoU-53': 0.0012715688507799825, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.010250205506571186, 'IoU-63': 0.00365945077528407, 'IoU-64': 0.046993007091599884, 'IoU-65': 3.95660748999646e-05, 'IoU-66': 3.065967980256801e-05, 'IoU-67': 0.0, 'IoU-68': 1.5749700339026051, 'IoU-69': 1.592701105400451, 'IoU-70': 0.0, 'IoU-71': 0.0008377138788246874, 'IoU-72': 0.0, 'IoU-73': 0.6703263118755002, 'IoU-74': 0.0067692352491790266, 'IoU-75': 0.0, 'IoU-76': 0.06317859667306623, 'IoU-77': 2.08973713352728, 'IoU-78': 0.0037107210484836166, 'IoU-79': 0.1514268441161451, 'IoU-80': 1.268372618736049, 'IoU-81': 0.0, 'IoU-82': 1.6810544282473996, 'IoU-83': 0.0, 'IoU-84': 0.31607770853642714, 'IoU-85': 0.0, 'IoU-86': 1.426002748183666, 'IoU-87': 0.03657412649527615, 'IoU-88': 0.0, 'IoU-89': 0.4838370065903865, 'IoU-90': 0.0, 'IoU-91': 0.030450978592815328, 'IoU-92': 0.0, 'IoU-93': 0.45867786260276033, 'IoU-94': 0.003735192498439381, 'IoU-95': 0.0, 'IoU-96': 1.140173119632034, 'IoU-97': 0.0, 'IoU-98': 0.005017667706201677, 'IoU-99': 0.0001349703826776697, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.03440693717500404, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 8.503912366616135e-05, 'IoU-110': 0.06943866943866944, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0037157833727437086, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.000209900767313245, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.24633232185897683, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0003412419957424374, 'IoU-127': 0.0, 'IoU-128': 0.00018279719930317708, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0010037399349978019, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.2261059435805427, 'IoU-139': 0.005192263851377938, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0016206010809409208, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.006673417457079771, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.00011451212110801929, 'IoU-154': 0.0006916558636607962, 'IoU-155': 0.0, 'IoU-156': 0.0010338722392380362, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.018793780505564, 'pACC': 13.453942670453534, 'ACC-0': nan, 'ACC-1': 99.55973319329634, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.11439740572337785, 'ACC-13': 23.684567140106978, 'ACC-14': 2.813301056117524, 'ACC-15': 0.15174514989771773, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.010198856814706293, 'ACC-19': 0.9416116424410105, 'ACC-20': 0.0002771252675182583, 'ACC-21': 0.14331253848376108, 'ACC-22': 0.0, 'ACC-23': 0.863777283794623, 'ACC-24': 0.2663669000984903, 'ACC-25': 0.00013983239068175593, 'ACC-26': 2.68873695902227, 'ACC-27': 0.5764070569454206, 'ACC-28': 51.45665673393482, 'ACC-29': 8.064900729405751e-06, 'ACC-30': 0.6032976572000215, 'ACC-31': 2.17510276758731, 'ACC-32': 2.4782801775752246, 'ACC-33': 19.26613534260958, 'ACC-34': 18.686822524597144, 'ACC-35': 1.4546473090004841, 'ACC-36': 0.01874067076858727, 'ACC-37': 1.0290097007778858, 'ACC-38': 0.0, 'ACC-39': 2.9974656291762862, 'ACC-40': 7.439485743900387, 'ACC-41': 6.951977277834853, 'ACC-42': 0.003874492051794181, 'ACC-43': 0.001197796331444735, 'ACC-44': 0.002950543301499493, 'ACC-45': 2.112649647987588, 'ACC-46': 1.2345653609766234e-05, 'ACC-47': 34.94747666155989, 'ACC-48': 0.0, 'ACC-49': 0.1265462839446718, 'ACC-50': 8.476938160076805e-05, 'ACC-51': 0.0029462503383662934, 'ACC-52': 0.0, 'ACC-53': 0.0012733644001596603, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.010278488324408369, 'ACC-63': 0.0036706819130930086, 'ACC-64': 0.050712673290092374, 'ACC-65': 3.9566998551353265e-05, 'ACC-66': 3.066191720382939e-05, 'ACC-67': 0.0, 'ACC-68': 15.792412333563568, 'ACC-69': 5.031490707749433, 'ACC-70': 0.0, 'ACC-71': 0.0008379701936207314, 'ACC-72': 0.0, 'ACC-73': 1.1858201893511313, 'ACC-74': 0.006786280211065297, 'ACC-75': 0.0, 'ACC-76': 0.06988810701194081, 'ACC-77': 9.444901349004954, 'ACC-78': 0.0037158037904748086, 'ACC-79': 0.16454423208032226, 'ACC-80': 3.1714881550631624, 'ACC-81': 0.0, 'ACC-82': 38.9638678223551, 'ACC-83': 0.0, 'ACC-84': 0.38788646449767056, 'ACC-85': 0.0, 'ACC-86': 3.857518171312835, 'ACC-87': 0.039676946702959515, 'ACC-88': 0.0, 'ACC-89': 0.648909935093631, 'ACC-90': 0.0, 'ACC-91': 0.031066288083418225, 'ACC-92': 0.0, 'ACC-93': 0.6464875570702091, 'ACC-94': 0.0038620511809970056, 'ACC-95': 0.0, 'ACC-96': 23.478780303117354, 'ACC-97': 0.0, 'ACC-98': 0.005090988787367993, 'ACC-99': 0.00013498847198449253, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.03530272976291678, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 8.504811597161094e-05, 'ACC-110': 0.07039689940499867, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.003717205230180645, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.00020993434513290313, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.3505247015309798, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.00034153316514722357, 'ACC-127': 0.0, 'ACC-128': 0.00018295114838435842, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0010053181329231636, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.5596872858339468, 'ACC-139': 0.005246963934501493, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0016245487364620937, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0069974819206363855, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.00011451290789497792, 'ACC-154': 0.0008219174865293595, 'ACC-155': 0.0, 'ACC-156': 0.0010342130608181918, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 04:30:54] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 04:30:54] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 04:30:54] d2.evaluation.testing INFO: copypaste: 10.4680,0.7987,0.6802,0.5746,6.1825,2.0188,13.4539
[01/24 04:30:54] d2.utils.events INFO:  eta: 1 day, 14:26:58  iter: 4499  total_loss: 58.21  loss_ce: 1.856  loss_mask: 3.927  loss_ce_0: 1.506  loss_mask_0: 4.723  loss_ce_1: 1.578  loss_mask_1: 3.932  loss_ce_2: 1.905  loss_mask_2: 3.852  loss_ce_3: 1.907  loss_mask_3: 3.843  loss_ce_4: 1.908  loss_mask_4: 3.851  loss_ce_5: 1.888  loss_mask_5: 3.87  loss_ce_6: 1.927  loss_mask_6: 3.938  loss_ce_7: 1.88  loss_mask_7: 3.803  loss_ce_8: 1.908  loss_mask_8: 3.915  time: 2.4907  data_time: 0.3729  lr: 9.3225e-05  max_mem: 18446M
[01/24 04:31:41] d2.utils.events INFO:  eta: 1 day, 14:14:14  iter: 4519  total_loss: 57.07  loss_ce: 1.851  loss_mask: 3.898  loss_ce_0: 1.491  loss_mask_0: 4.577  loss_ce_1: 1.55  loss_mask_1: 3.9  loss_ce_2: 1.875  loss_mask_2: 3.769  loss_ce_3: 1.875  loss_mask_3: 3.684  loss_ce_4: 1.88  loss_mask_4: 3.832  loss_ce_5: 1.871  loss_mask_5: 3.746  loss_ce_6: 1.909  loss_mask_6: 3.816  loss_ce_7: 1.877  loss_mask_7: 3.723  loss_ce_8: 1.898  loss_mask_8: 3.731  time: 2.4901  data_time: 0.3703  lr: 9.3195e-05  max_mem: 18446M
[01/24 04:32:28] d2.utils.events INFO:  eta: 1 day, 14:09:50  iter: 4539  total_loss: 55.74  loss_ce: 1.83  loss_mask: 3.723  loss_ce_0: 1.49  loss_mask_0: 4.493  loss_ce_1: 1.538  loss_mask_1: 3.798  loss_ce_2: 1.866  loss_mask_2: 3.623  loss_ce_3: 1.866  loss_mask_3: 3.685  loss_ce_4: 1.87  loss_mask_4: 3.732  loss_ce_5: 1.869  loss_mask_5: 3.69  loss_ce_6: 1.902  loss_mask_6: 3.826  loss_ce_7: 1.883  loss_mask_7: 3.639  loss_ce_8: 1.877  loss_mask_8: 3.688  time: 2.4895  data_time: 0.3696  lr: 9.3165e-05  max_mem: 18446M
[01/24 04:33:16] d2.utils.events INFO:  eta: 1 day, 14:04:18  iter: 4559  total_loss: 56.45  loss_ce: 1.847  loss_mask: 3.694  loss_ce_0: 1.45  loss_mask_0: 4.743  loss_ce_1: 1.516  loss_mask_1: 3.855  loss_ce_2: 1.862  loss_mask_2: 3.762  loss_ce_3: 1.862  loss_mask_3: 3.655  loss_ce_4: 1.864  loss_mask_4: 3.737  loss_ce_5: 1.864  loss_mask_5: 3.726  loss_ce_6: 1.911  loss_mask_6: 3.71  loss_ce_7: 1.884  loss_mask_7: 3.649  loss_ce_8: 1.876  loss_mask_8: 3.678  time: 2.4891  data_time: 0.3722  lr: 9.3135e-05  max_mem: 18446M
[01/24 04:34:08] d2.utils.events INFO:  eta: 1 day, 14:01:44  iter: 4579  total_loss: 55.37  loss_ce: 1.849  loss_mask: 3.64  loss_ce_0: 1.454  loss_mask_0: 4.642  loss_ce_1: 1.475  loss_mask_1: 3.854  loss_ce_2: 1.851  loss_mask_2: 3.582  loss_ce_3: 1.876  loss_mask_3: 3.526  loss_ce_4: 1.872  loss_mask_4: 3.587  loss_ce_5: 1.87  loss_mask_5: 3.634  loss_ce_6: 1.905  loss_mask_6: 3.55  loss_ce_7: 1.878  loss_mask_7: 3.512  loss_ce_8: 1.89  loss_mask_8: 3.597  time: 2.4895  data_time: 0.4531  lr: 9.3105e-05  max_mem: 18446M
[01/24 04:34:55] d2.utils.events INFO:  eta: 1 day, 13:55:08  iter: 4599  total_loss: 55.39  loss_ce: 1.86  loss_mask: 3.643  loss_ce_0: 1.403  loss_mask_0: 4.586  loss_ce_1: 1.445  loss_mask_1: 3.931  loss_ce_2: 1.859  loss_mask_2: 3.633  loss_ce_3: 1.869  loss_mask_3: 3.664  loss_ce_4: 1.857  loss_mask_4: 3.561  loss_ce_5: 1.859  loss_mask_5: 3.563  loss_ce_6: 1.92  loss_mask_6: 3.62  loss_ce_7: 1.921  loss_mask_7: 3.597  loss_ce_8: 1.894  loss_mask_8: 3.644  time: 2.4890  data_time: 0.3488  lr: 9.3074e-05  max_mem: 18446M
[01/24 04:35:43] d2.utils.events INFO:  eta: 1 day, 13:45:36  iter: 4619  total_loss: 55.94  loss_ce: 1.858  loss_mask: 3.777  loss_ce_0: 1.431  loss_mask_0: 4.666  loss_ce_1: 1.443  loss_mask_1: 4.014  loss_ce_2: 1.884  loss_mask_2: 3.611  loss_ce_3: 1.868  loss_mask_3: 3.662  loss_ce_4: 1.853  loss_mask_4: 3.676  loss_ce_5: 1.866  loss_mask_5: 3.673  loss_ce_6: 1.921  loss_mask_6: 3.883  loss_ce_7: 1.922  loss_mask_7: 3.828  loss_ce_8: 1.888  loss_mask_8: 3.665  time: 2.4886  data_time: 0.3804  lr: 9.3044e-05  max_mem: 18446M
[01/24 04:36:34] d2.utils.events INFO:  eta: 1 day, 13:45:37  iter: 4639  total_loss: 55.85  loss_ce: 1.843  loss_mask: 3.651  loss_ce_0: 1.443  loss_mask_0: 4.623  loss_ce_1: 1.434  loss_mask_1: 3.892  loss_ce_2: 1.881  loss_mask_2: 3.68  loss_ce_3: 1.882  loss_mask_3: 3.682  loss_ce_4: 1.875  loss_mask_4: 3.684  loss_ce_5: 1.889  loss_mask_5: 3.653  loss_ce_6: 1.926  loss_mask_6: 3.754  loss_ce_7: 1.915  loss_mask_7: 3.633  loss_ce_8: 1.885  loss_mask_8: 3.691  time: 2.4889  data_time: 0.4080  lr: 9.3014e-05  max_mem: 18446M
[01/24 04:37:21] d2.utils.events INFO:  eta: 1 day, 13:40:50  iter: 4659  total_loss: 56.61  loss_ce: 1.832  loss_mask: 3.707  loss_ce_0: 1.515  loss_mask_0: 4.828  loss_ce_1: 1.444  loss_mask_1: 4.086  loss_ce_2: 1.846  loss_mask_2: 3.803  loss_ce_3: 1.855  loss_mask_3: 3.88  loss_ce_4: 1.856  loss_mask_4: 3.752  loss_ce_5: 1.862  loss_mask_5: 3.74  loss_ce_6: 1.91  loss_mask_6: 3.735  loss_ce_7: 1.875  loss_mask_7: 3.732  loss_ce_8: 1.869  loss_mask_8: 3.763  time: 2.4882  data_time: 0.3563  lr: 9.2984e-05  max_mem: 18446M
[01/24 04:38:10] d2.utils.events INFO:  eta: 1 day, 13:35:34  iter: 4679  total_loss: 54.36  loss_ce: 1.822  loss_mask: 3.578  loss_ce_0: 1.45  loss_mask_0: 4.563  loss_ce_1: 1.441  loss_mask_1: 3.791  loss_ce_2: 1.836  loss_mask_2: 3.533  loss_ce_3: 1.851  loss_mask_3: 3.542  loss_ce_4: 1.851  loss_mask_4: 3.458  loss_ce_5: 1.873  loss_mask_5: 3.585  loss_ce_6: 1.892  loss_mask_6: 3.545  loss_ce_7: 1.863  loss_mask_7: 3.452  loss_ce_8: 1.858  loss_mask_8: 3.552  time: 2.4881  data_time: 0.4185  lr: 9.2953e-05  max_mem: 18446M
[01/24 04:39:00] d2.utils.events INFO:  eta: 1 day, 13:33:38  iter: 4699  total_loss: 57.09  loss_ce: 1.857  loss_mask: 3.827  loss_ce_0: 1.444  loss_mask_0: 5.089  loss_ce_1: 1.443  loss_mask_1: 4.234  loss_ce_2: 1.872  loss_mask_2: 3.767  loss_ce_3: 1.88  loss_mask_3: 3.758  loss_ce_4: 1.887  loss_mask_4: 3.7  loss_ce_5: 1.895  loss_mask_5: 3.776  loss_ce_6: 1.935  loss_mask_6: 3.828  loss_ce_7: 1.898  loss_mask_7: 3.752  loss_ce_8: 1.904  loss_mask_8: 3.773  time: 2.4881  data_time: 0.4054  lr: 9.2923e-05  max_mem: 18446M
[01/24 04:39:48] d2.utils.events INFO:  eta: 1 day, 13:23:46  iter: 4719  total_loss: 55.65  loss_ce: 1.826  loss_mask: 3.685  loss_ce_0: 1.409  loss_mask_0: 4.618  loss_ce_1: 1.425  loss_mask_1: 4.076  loss_ce_2: 1.841  loss_mask_2: 3.624  loss_ce_3: 1.854  loss_mask_3: 3.513  loss_ce_4: 1.849  loss_mask_4: 3.625  loss_ce_5: 1.859  loss_mask_5: 3.583  loss_ce_6: 1.886  loss_mask_6: 3.606  loss_ce_7: 1.861  loss_mask_7: 3.613  loss_ce_8: 1.873  loss_mask_8: 3.708  time: 2.4877  data_time: 0.3846  lr: 9.2893e-05  max_mem: 18446M
[01/24 04:40:39] d2.utils.events INFO:  eta: 1 day, 13:20:53  iter: 4739  total_loss: 60.7  loss_ce: 2.062  loss_mask: 4.226  loss_ce_0: 1.34  loss_mask_0: 4.703  loss_ce_1: 1.435  loss_mask_1: 4.291  loss_ce_2: 1.934  loss_mask_2: 3.768  loss_ce_3: 1.975  loss_mask_3: 3.835  loss_ce_4: 1.969  loss_mask_4: 3.809  loss_ce_5: 1.964  loss_mask_5: 3.895  loss_ce_6: 2.02  loss_mask_6: 4.177  loss_ce_7: 2.146  loss_mask_7: 4.379  loss_ce_8: 2.091  loss_mask_8: 4.205  time: 2.4879  data_time: 0.4360  lr: 9.2863e-05  max_mem: 18446M
[01/24 04:41:26] d2.utils.events INFO:  eta: 1 day, 13:15:07  iter: 4759  total_loss: 57.41  loss_ce: 1.922  loss_mask: 3.943  loss_ce_0: 1.436  loss_mask_0: 4.716  loss_ce_1: 1.421  loss_mask_1: 4.121  loss_ce_2: 1.865  loss_mask_2: 3.754  loss_ce_3: 1.888  loss_mask_3: 3.698  loss_ce_4: 1.876  loss_mask_4: 3.682  loss_ce_5: 1.895  loss_mask_5: 3.684  loss_ce_6: 1.919  loss_mask_6: 3.718  loss_ce_7: 1.955  loss_mask_7: 3.811  loss_ce_8: 1.968  loss_mask_8: 3.866  time: 2.4873  data_time: 0.3481  lr: 9.2832e-05  max_mem: 18446M
[01/24 04:42:13] d2.utils.events INFO:  eta: 1 day, 13:07:42  iter: 4779  total_loss: 57.61  loss_ce: 1.856  loss_mask: 3.876  loss_ce_0: 1.482  loss_mask_0: 4.895  loss_ce_1: 1.427  loss_mask_1: 4.178  loss_ce_2: 1.828  loss_mask_2: 3.887  loss_ce_3: 1.848  loss_mask_3: 3.866  loss_ce_4: 1.837  loss_mask_4: 3.801  loss_ce_5: 1.854  loss_mask_5: 3.808  loss_ce_6: 1.903  loss_mask_6: 3.94  loss_ce_7: 1.891  loss_mask_7: 3.883  loss_ce_8: 1.882  loss_mask_8: 3.926  time: 2.4868  data_time: 0.3714  lr: 9.2802e-05  max_mem: 18446M
[01/24 04:43:04] d2.utils.events INFO:  eta: 1 day, 13:04:49  iter: 4799  total_loss: 54.05  loss_ce: 1.82  loss_mask: 3.478  loss_ce_0: 1.422  loss_mask_0: 4.579  loss_ce_1: 1.395  loss_mask_1: 3.854  loss_ce_2: 1.842  loss_mask_2: 3.57  loss_ce_3: 1.871  loss_mask_3: 3.511  loss_ce_4: 1.85  loss_mask_4: 3.525  loss_ce_5: 1.839  loss_mask_5: 3.546  loss_ce_6: 1.888  loss_mask_6: 3.589  loss_ce_7: 1.869  loss_mask_7: 3.541  loss_ce_8: 1.854  loss_mask_8: 3.513  time: 2.4871  data_time: 0.4195  lr: 9.2772e-05  max_mem: 18446M
[01/24 04:43:52] d2.utils.events INFO:  eta: 1 day, 12:58:17  iter: 4819  total_loss: 57.75  loss_ce: 1.852  loss_mask: 3.826  loss_ce_0: 1.46  loss_mask_0: 4.737  loss_ce_1: 1.435  loss_mask_1: 4.086  loss_ce_2: 1.88  loss_mask_2: 3.778  loss_ce_3: 1.898  loss_mask_3: 3.806  loss_ce_4: 1.883  loss_mask_4: 3.828  loss_ce_5: 1.859  loss_mask_5: 3.748  loss_ce_6: 1.908  loss_mask_6: 3.765  loss_ce_7: 1.896  loss_mask_7: 3.723  loss_ce_8: 1.895  loss_mask_8: 3.857  time: 2.4866  data_time: 0.3716  lr: 9.2742e-05  max_mem: 18446M
[01/24 04:44:38] d2.utils.events INFO:  eta: 1 day, 12:48:36  iter: 4839  total_loss: 54.05  loss_ce: 1.804  loss_mask: 3.54  loss_ce_0: 1.452  loss_mask_0: 4.461  loss_ce_1: 1.412  loss_mask_1: 3.797  loss_ce_2: 1.849  loss_mask_2: 3.506  loss_ce_3: 1.875  loss_mask_3: 3.586  loss_ce_4: 1.854  loss_mask_4: 3.488  loss_ce_5: 1.84  loss_mask_5: 3.454  loss_ce_6: 1.887  loss_mask_6: 3.588  loss_ce_7: 1.867  loss_mask_7: 3.506  loss_ce_8: 1.85  loss_mask_8: 3.584  time: 2.4858  data_time: 0.3576  lr: 9.2711e-05  max_mem: 18446M
[01/24 04:45:29] d2.utils.events INFO:  eta: 1 day, 12:46:05  iter: 4859  total_loss: 53.45  loss_ce: 1.79  loss_mask: 3.555  loss_ce_0: 1.421  loss_mask_0: 4.444  loss_ce_1: 1.391  loss_mask_1: 3.802  loss_ce_2: 1.831  loss_mask_2: 3.38  loss_ce_3: 1.86  loss_mask_3: 3.485  loss_ce_4: 1.848  loss_mask_4: 3.389  loss_ce_5: 1.832  loss_mask_5: 3.37  loss_ce_6: 1.892  loss_mask_6: 3.549  loss_ce_7: 1.874  loss_mask_7: 3.487  loss_ce_8: 1.849  loss_mask_8: 3.496  time: 2.4861  data_time: 0.4358  lr: 9.2681e-05  max_mem: 18446M
[01/24 04:46:15] d2.utils.events INFO:  eta: 1 day, 12:39:51  iter: 4879  total_loss: 54.9  loss_ce: 1.79  loss_mask: 3.58  loss_ce_0: 1.406  loss_mask_0: 4.441  loss_ce_1: 1.394  loss_mask_1: 3.942  loss_ce_2: 1.829  loss_mask_2: 3.544  loss_ce_3: 1.863  loss_mask_3: 3.578  loss_ce_4: 1.862  loss_mask_4: 3.634  loss_ce_5: 1.863  loss_mask_5: 3.706  loss_ce_6: 1.903  loss_mask_6: 3.696  loss_ce_7: 1.867  loss_mask_7: 3.619  loss_ce_8: 1.856  loss_mask_8: 3.5  time: 2.4853  data_time: 0.3509  lr: 9.2651e-05  max_mem: 18446M
[01/24 04:47:03] d2.utils.events INFO:  eta: 1 day, 12:38:07  iter: 4899  total_loss: 54.72  loss_ce: 1.773  loss_mask: 3.58  loss_ce_0: 1.396  loss_mask_0: 4.547  loss_ce_1: 1.376  loss_mask_1: 3.97  loss_ce_2: 1.831  loss_mask_2: 3.558  loss_ce_3: 1.861  loss_mask_3: 3.593  loss_ce_4: 1.863  loss_mask_4: 3.589  loss_ce_5: 1.838  loss_mask_5: 3.618  loss_ce_6: 1.885  loss_mask_6: 3.651  loss_ce_7: 1.86  loss_mask_7: 3.635  loss_ce_8: 1.849  loss_mask_8: 3.513  time: 2.4849  data_time: 0.3774  lr: 9.2621e-05  max_mem: 18446M
[01/24 04:47:54] d2.utils.events INFO:  eta: 1 day, 12:39:56  iter: 4919  total_loss: 54.37  loss_ce: 1.8  loss_mask: 3.501  loss_ce_0: 1.386  loss_mask_0: 4.34  loss_ce_1: 1.386  loss_mask_1: 3.835  loss_ce_2: 1.823  loss_mask_2: 3.466  loss_ce_3: 1.856  loss_mask_3: 3.58  loss_ce_4: 1.852  loss_mask_4: 3.509  loss_ce_5: 1.842  loss_mask_5: 3.567  loss_ce_6: 1.891  loss_mask_6: 3.513  loss_ce_7: 1.864  loss_mask_7: 3.528  loss_ce_8: 1.862  loss_mask_8: 3.556  time: 2.4852  data_time: 0.4259  lr: 9.259e-05  max_mem: 18446M
[01/24 04:48:40] d2.utils.events INFO:  eta: 1 day, 12:36:09  iter: 4939  total_loss: 53.8  loss_ce: 1.817  loss_mask: 3.408  loss_ce_0: 1.406  loss_mask_0: 4.584  loss_ce_1: 1.399  loss_mask_1: 3.978  loss_ce_2: 1.846  loss_mask_2: 3.476  loss_ce_3: 1.851  loss_mask_3: 3.45  loss_ce_4: 1.868  loss_mask_4: 3.449  loss_ce_5: 1.833  loss_mask_5: 3.462  loss_ce_6: 1.889  loss_mask_6: 3.507  loss_ce_7: 1.87  loss_mask_7: 3.506  loss_ce_8: 1.858  loss_mask_8: 3.522  time: 2.4845  data_time: 0.3572  lr: 9.256e-05  max_mem: 18446M
[01/24 04:49:28] d2.utils.events INFO:  eta: 1 day, 12:35:21  iter: 4959  total_loss: 52.38  loss_ce: 1.747  loss_mask: 3.444  loss_ce_0: 1.396  loss_mask_0: 4.386  loss_ce_1: 1.349  loss_mask_1: 3.824  loss_ce_2: 1.792  loss_mask_2: 3.486  loss_ce_3: 1.807  loss_mask_3: 3.495  loss_ce_4: 1.805  loss_mask_4: 3.458  loss_ce_5: 1.783  loss_mask_5: 3.398  loss_ce_6: 1.844  loss_mask_6: 3.446  loss_ce_7: 1.804  loss_mask_7: 3.535  loss_ce_8: 1.807  loss_mask_8: 3.508  time: 2.4841  data_time: 0.3877  lr: 9.253e-05  max_mem: 18446M
[01/24 04:50:17] d2.utils.events INFO:  eta: 1 day, 12:31:19  iter: 4979  total_loss: 55  loss_ce: 1.797  loss_mask: 3.541  loss_ce_0: 1.414  loss_mask_0: 4.636  loss_ce_1: 1.372  loss_mask_1: 4.03  loss_ce_2: 1.838  loss_mask_2: 3.684  loss_ce_3: 1.837  loss_mask_3: 3.541  loss_ce_4: 1.839  loss_mask_4: 3.634  loss_ce_5: 1.836  loss_mask_5: 3.573  loss_ce_6: 1.882  loss_mask_6: 3.599  loss_ce_7: 1.854  loss_mask_7: 3.624  loss_ce_8: 1.852  loss_mask_8: 3.675  time: 2.4840  data_time: 0.3989  lr: 9.25e-05  max_mem: 18446M
[01/24 04:51:05] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/model_0004999.pth
[01/24 04:51:06] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 04:51:06] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 04:51:06] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 04:55:20] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 9.57138368461718, 'error_1pix': 0.7694784992078492, 'error_3pix': 0.6186777477158658, 'mIoU': 0.7254727652976013, 'fwIoU': 9.185278992951467, 'IoU-0': nan, 'IoU-1': 81.91799663259741, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.012934036350906373, 'IoU-13': 2.123464110528179, 'IoU-14': 8.946528933286992, 'IoU-15': 2.6886530043986363e-05, 'IoU-16': 0.013993279047380089, 'IoU-17': 0.0, 'IoU-18': 0.0024567678184167128, 'IoU-19': 0.014645316128987293, 'IoU-20': 1.231590569045954e-05, 'IoU-21': 0.0, 'IoU-22': 2.7844114059180937e-05, 'IoU-23': 4.782754159469174, 'IoU-24': 0.07902111801784573, 'IoU-25': 0.20120581657093384, 'IoU-26': 0.07406500665091614, 'IoU-27': 0.0022074403183737113, 'IoU-28': 0.01322965718665108, 'IoU-29': 0.0, 'IoU-30': 0.25451750867078793, 'IoU-31': 3.641494678949625, 'IoU-32': 0.285939922840783, 'IoU-33': 4.397894618263768, 'IoU-34': 3.0822896283544217, 'IoU-35': 1.940580909568569e-05, 'IoU-36': 0.007750146652307329, 'IoU-37': 2.219773045980074, 'IoU-38': 3.3971547481511877, 'IoU-39': 0.003122288918605601, 'IoU-40': 0.01638011053138009, 'IoU-41': 0.08991754596445994, 'IoU-42': 2.4801444784597515, 'IoU-43': 0.0018614063589051984, 'IoU-44': 2.3113782512106553, 'IoU-45': 0.008868305364587912, 'IoU-46': 3.9538140380759557, 'IoU-47': 0.0, 'IoU-48': 0.0002874869746286111, 'IoU-49': 0.0, 'IoU-50': 0.0022331587974773674, 'IoU-51': 2.5138177017612715e-05, 'IoU-52': 1.1105239606249997, 'IoU-53': 0.0006581513127942983, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.001651475926998247, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0005069483726542462, 'IoU-64': 0.0, 'IoU-65': 0.005151308841984785, 'IoU-66': 0.0, 'IoU-67': 0.012467394184044852, 'IoU-68': 2.1573176430182945e-05, 'IoU-69': 1.6032594965116762, 'IoU-70': 0.0, 'IoU-71': 0.00078214023532066, 'IoU-72': 0.0, 'IoU-73': 0.06903825929354654, 'IoU-74': 2.1772163523406425, 'IoU-75': 0.0, 'IoU-76': 0.1258297387752397, 'IoU-77': 0.0, 'IoU-78': 0.43026483220613193, 'IoU-79': 0.0, 'IoU-80': 2.470651663044728, 'IoU-81': 0.0, 'IoU-82': 1.132282378439815, 'IoU-83': 0.0, 'IoU-84': 0.04355300933205375, 'IoU-85': 0.0, 'IoU-86': 0.3064254178594575, 'IoU-87': 1.6850117190431506, 'IoU-88': 2.195329808911944, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0027222046986878296, 'IoU-92': 0.9504660508604714, 'IoU-93': 0.44747872423405194, 'IoU-94': 1.5198619357417572e-05, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0005230888722582703, 'IoU-99': 0.0005773970977327348, 'IoU-100': 0.0010944189699288122, 'IoU-101': 0.0017374588184722332, 'IoU-102': 0.0005276462448516017, 'IoU-103': 0.0015489885222297456, 'IoU-104': 0.024499055270047077, 'IoU-105': 0.003199739145075411, 'IoU-106': 0.0, 'IoU-107': 0.0654395744683733, 'IoU-108': 8.279847816397135e-05, 'IoU-109': 0.0040273272459671805, 'IoU-110': 0.032696823761554354, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.04038373409020131, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0036898462810039333, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.3475225699100335, 'pACC': 14.457413031838048, 'ACC-0': nan, 'ACC-1': 99.01459954826439, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.012995535049071107, 'ACC-13': 2.5513025767221955, 'ACC-14': 83.11423749359584, 'ACC-15': 2.689129799063821e-05, 'ACC-16': 0.014011740996820838, 'ACC-17': 0.0, 'ACC-18': 0.0024594258165987664, 'ACC-19': 0.014739846694709565, 'ACC-20': 1.2316678556367032e-05, 'ACC-21': 0.0, 'ACC-22': 2.7845993500355272e-05, 'ACC-23': 25.887962694179738, 'ACC-24': 0.0812692343657983, 'ACC-25': 0.21600064757933815, 'ACC-26': 0.0775171757364641, 'ACC-27': 0.002210476247671458, 'ACC-28': 0.013337529025624626, 'ACC-29': 0.0, 'ACC-30': 0.2779674749648696, 'ACC-31': 11.058981549243315, 'ACC-32': 0.3067337363963001, 'ACC-33': 46.92524912260175, 'ACC-34': 7.869032595303851, 'ACC-35': 1.940708957062175e-05, 'ACC-36': 0.007763170096126295, 'ACC-37': 5.352340872393033, 'ACC-38': 7.620552703184613, 'ACC-39': 0.003132191466287887, 'ACC-40': 0.016478723248348585, 'ACC-41': 0.09285962508942192, 'ACC-42': 4.594451154692312, 'ACC-43': 0.0018676885046539483, 'ACC-44': 3.7773694260902886, 'ACC-45': 0.008926555412548194, 'ACC-46': 20.181481108063565, 'ACC-47': 0.0, 'ACC-48': 0.00028756028369547344, 'ACC-49': 0.0, 'ACC-50': 0.00223696979224249, 'ACC-51': 2.5138654764217517e-05, 'ACC-52': 1.4553365930342186, 'ACC-53': 0.0006584491129030723, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0016603155254690167, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0005072550382414962, 'ACC-64': 0.0, 'ACC-65': 0.005163493310951601, 'ACC-66': 0.0, 'ACC-67': 0.012527130654375407, 'ACC-68': 2.157431905246454e-05, 'ACC-69': 37.580990821031456, 'ACC-70': 0.0, 'ACC-71': 0.0007828405756193674, 'ACC-72': 0.0, 'ACC-73': 0.07415243468817967, 'ACC-74': 6.31158916927107, 'ACC-75': 0.0, 'ACC-76': 0.1319073151740753, 'ACC-77': 0.0, 'ACC-78': 0.5372275844413638, 'ACC-79': 0.0, 'ACC-80': 15.616874101745273, 'ACC-81': 0.0, 'ACC-82': 5.583688438472732, 'ACC-83': 0.0, 'ACC-84': 0.04614941590763221, 'ACC-85': 0.0, 'ACC-86': 0.44944020083162034, 'ACC-87': 4.653470870294189, 'ACC-88': 41.70942654547017, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0027351396867135625, 'ACC-92': 16.62621816537998, 'ACC-93': 0.578086542383953, 'ACC-94': 1.520492590943703e-05, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0005235414001194035, 'ACC-99': 0.0005785220227906823, 'ACC-100': 0.001094759992117728, 'ACC-101': 0.0017409740169300049, 'ACC-102': 0.0005437245129134571, 'ACC-103': 0.0015585151601020118, 'ACC-104': 0.0405302378200241, 'ACC-105': 0.003217937909632642, 'ACC-106': 0.0, 'ACC-107': 0.10511446462061973, 'ACC-108': 8.29089546369182e-05, 'ACC-109': 0.004053960194646788, 'ACC-110': 0.03453603234282868, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0479605490655962, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0036999426224282555, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 04:55:20] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 04:55:20] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 04:55:20] d2.evaluation.testing INFO: copypaste: 9.5714,0.7695,0.6187,0.7255,9.1853,2.3475,14.4574
[01/24 04:55:20] d2.utils.events INFO:  eta: 1 day, 12:29:31  iter: 4999  total_loss: 55.04  loss_ce: 1.799  loss_mask: 3.569  loss_ce_0: 1.362  loss_mask_0: 4.738  loss_ce_1: 1.346  loss_mask_1: 4.009  loss_ce_2: 1.827  loss_mask_2: 3.576  loss_ce_3: 1.863  loss_mask_3: 3.635  loss_ce_4: 1.857  loss_mask_4: 3.532  loss_ce_5: 1.834  loss_mask_5: 3.533  loss_ce_6: 1.897  loss_mask_6: 3.553  loss_ce_7: 1.864  loss_mask_7: 3.575  loss_ce_8: 1.847  loss_mask_8: 3.6  time: 2.4837  data_time: 0.3719  lr: 9.2469e-05  max_mem: 18446M
[01/24 04:56:06] d2.utils.events INFO:  eta: 1 day, 12:22:44  iter: 5019  total_loss: 52.9  loss_ce: 1.763  loss_mask: 3.544  loss_ce_0: 1.344  loss_mask_0: 4.312  loss_ce_1: 1.312  loss_mask_1: 3.974  loss_ce_2: 1.79  loss_mask_2: 3.549  loss_ce_3: 1.834  loss_mask_3: 3.425  loss_ce_4: 1.816  loss_mask_4: 3.458  loss_ce_5: 1.822  loss_mask_5: 3.428  loss_ce_6: 1.863  loss_mask_6: 3.424  loss_ce_7: 1.851  loss_mask_7: 3.45  loss_ce_8: 1.812  loss_mask_8: 3.396  time: 2.4829  data_time: 0.3289  lr: 9.2439e-05  max_mem: 18446M
[01/24 04:56:58] d2.utils.events INFO:  eta: 1 day, 12:23:36  iter: 5039  total_loss: 52.11  loss_ce: 1.767  loss_mask: 3.373  loss_ce_0: 1.302  loss_mask_0: 4.228  loss_ce_1: 1.313  loss_mask_1: 3.775  loss_ce_2: 1.795  loss_mask_2: 3.367  loss_ce_3: 1.819  loss_mask_3: 3.368  loss_ce_4: 1.824  loss_mask_4: 3.358  loss_ce_5: 1.808  loss_mask_5: 3.397  loss_ce_6: 1.849  loss_mask_6: 3.356  loss_ce_7: 1.851  loss_mask_7: 3.326  loss_ce_8: 1.814  loss_mask_8: 3.316  time: 2.4834  data_time: 0.4356  lr: 9.2409e-05  max_mem: 18446M
[01/24 04:57:44] d2.utils.events INFO:  eta: 1 day, 12:14:40  iter: 5059  total_loss: 54.15  loss_ce: 1.788  loss_mask: 3.561  loss_ce_0: 1.335  loss_mask_0: 4.564  loss_ce_1: 1.307  loss_mask_1: 4.114  loss_ce_2: 1.789  loss_mask_2: 3.63  loss_ce_3: 1.839  loss_mask_3: 3.503  loss_ce_4: 1.832  loss_mask_4: 3.535  loss_ce_5: 1.817  loss_mask_5: 3.606  loss_ce_6: 1.871  loss_mask_6: 3.645  loss_ce_7: 1.852  loss_mask_7: 3.571  loss_ce_8: 1.84  loss_mask_8: 3.602  time: 2.4827  data_time: 0.3730  lr: 9.2378e-05  max_mem: 18446M
[01/24 04:58:32] d2.utils.events INFO:  eta: 1 day, 12:17:39  iter: 5079  total_loss: 57.51  loss_ce: 1.804  loss_mask: 3.857  loss_ce_0: 1.279  loss_mask_0: 4.843  loss_ce_1: 1.276  loss_mask_1: 4.387  loss_ce_2: 1.786  loss_mask_2: 3.848  loss_ce_3: 1.825  loss_mask_3: 3.834  loss_ce_4: 1.85  loss_mask_4: 3.791  loss_ce_5: 1.833  loss_mask_5: 3.791  loss_ce_6: 1.872  loss_mask_6: 3.901  loss_ce_7: 1.867  loss_mask_7: 3.777  loss_ce_8: 1.831  loss_mask_8: 3.866  time: 2.4823  data_time: 0.3771  lr: 9.2348e-05  max_mem: 18446M
[01/24 04:59:23] d2.utils.events INFO:  eta: 1 day, 12:19:49  iter: 5099  total_loss: 51.31  loss_ce: 1.773  loss_mask: 3.352  loss_ce_0: 1.335  loss_mask_0: 4.47  loss_ce_1: 1.265  loss_mask_1: 3.831  loss_ce_2: 1.739  loss_mask_2: 3.363  loss_ce_3: 1.772  loss_mask_3: 3.219  loss_ce_4: 1.796  loss_mask_4: 3.269  loss_ce_5: 1.785  loss_mask_5: 3.309  loss_ce_6: 1.831  loss_mask_6: 3.324  loss_ce_7: 1.835  loss_mask_7: 3.34  loss_ce_8: 1.801  loss_mask_8: 3.385  time: 2.4826  data_time: 0.4289  lr: 9.2318e-05  max_mem: 18446M
[01/24 05:00:08] d2.utils.events INFO:  eta: 1 day, 12:12:17  iter: 5119  total_loss: 52.5  loss_ce: 1.753  loss_mask: 3.422  loss_ce_0: 1.287  loss_mask_0: 4.215  loss_ce_1: 1.286  loss_mask_1: 3.976  loss_ce_2: 1.743  loss_mask_2: 3.429  loss_ce_3: 1.772  loss_mask_3: 3.404  loss_ce_4: 1.795  loss_mask_4: 3.463  loss_ce_5: 1.776  loss_mask_5: 3.415  loss_ce_6: 1.813  loss_mask_6: 3.388  loss_ce_7: 1.83  loss_mask_7: 3.355  loss_ce_8: 1.797  loss_mask_8: 3.425  time: 2.4818  data_time: 0.3765  lr: 9.2288e-05  max_mem: 18446M
[01/24 05:00:57] d2.utils.events INFO:  eta: 1 day, 12:14:48  iter: 5139  total_loss: 52.61  loss_ce: 1.757  loss_mask: 3.462  loss_ce_0: 1.278  loss_mask_0: 4.368  loss_ce_1: 1.257  loss_mask_1: 4.004  loss_ce_2: 1.729  loss_mask_2: 3.465  loss_ce_3: 1.778  loss_mask_3: 3.476  loss_ce_4: 1.793  loss_mask_4: 3.472  loss_ce_5: 1.787  loss_mask_5: 3.412  loss_ce_6: 1.81  loss_mask_6: 3.411  loss_ce_7: 1.818  loss_mask_7: 3.38  loss_ce_8: 1.802  loss_mask_8: 3.466  time: 2.4816  data_time: 0.3559  lr: 9.2257e-05  max_mem: 18446M
[01/24 05:01:46] d2.utils.events INFO:  eta: 1 day, 12:12:26  iter: 5159  total_loss: 51.5  loss_ce: 1.75  loss_mask: 3.451  loss_ce_0: 1.255  loss_mask_0: 4.191  loss_ce_1: 1.264  loss_mask_1: 3.879  loss_ce_2: 1.729  loss_mask_2: 3.332  loss_ce_3: 1.765  loss_mask_3: 3.327  loss_ce_4: 1.791  loss_mask_4: 3.409  loss_ce_5: 1.793  loss_mask_5: 3.416  loss_ce_6: 1.821  loss_mask_6: 3.364  loss_ce_7: 1.824  loss_mask_7: 3.449  loss_ce_8: 1.795  loss_mask_8: 3.399  time: 2.4814  data_time: 0.4016  lr: 9.2227e-05  max_mem: 18446M
[01/24 05:02:32] d2.utils.events INFO:  eta: 1 day, 12:06:41  iter: 5179  total_loss: 52.49  loss_ce: 1.781  loss_mask: 3.425  loss_ce_0: 1.242  loss_mask_0: 4.296  loss_ce_1: 1.246  loss_mask_1: 3.984  loss_ce_2: 1.734  loss_mask_2: 3.402  loss_ce_3: 1.78  loss_mask_3: 3.377  loss_ce_4: 1.793  loss_mask_4: 3.41  loss_ce_5: 1.807  loss_mask_5: 3.458  loss_ce_6: 1.852  loss_mask_6: 3.381  loss_ce_7: 1.846  loss_mask_7: 3.376  loss_ce_8: 1.83  loss_mask_8: 3.433  time: 2.4808  data_time: 0.3486  lr: 9.2197e-05  max_mem: 18446M
[01/24 05:03:20] d2.utils.events INFO:  eta: 1 day, 12:06:18  iter: 5199  total_loss: 53.35  loss_ce: 1.78  loss_mask: 3.494  loss_ce_0: 1.227  loss_mask_0: 4.224  loss_ce_1: 1.226  loss_mask_1: 4.016  loss_ce_2: 1.727  loss_mask_2: 3.465  loss_ce_3: 1.776  loss_mask_3: 3.563  loss_ce_4: 1.793  loss_mask_4: 3.481  loss_ce_5: 1.796  loss_mask_5: 3.543  loss_ce_6: 1.837  loss_mask_6: 3.561  loss_ce_7: 1.82  loss_mask_7: 3.47  loss_ce_8: 1.827  loss_mask_8: 3.476  time: 2.4805  data_time: 0.3920  lr: 9.2167e-05  max_mem: 18446M
[01/24 05:04:09] d2.utils.events INFO:  eta: 1 day, 12:03:56  iter: 5219  total_loss: 54.42  loss_ce: 1.771  loss_mask: 3.638  loss_ce_0: 1.247  loss_mask_0: 4.774  loss_ce_1: 1.252  loss_mask_1: 4.232  loss_ce_2: 1.73  loss_mask_2: 3.507  loss_ce_3: 1.777  loss_mask_3: 3.567  loss_ce_4: 1.812  loss_mask_4: 3.576  loss_ce_5: 1.809  loss_mask_5: 3.609  loss_ce_6: 1.836  loss_mask_6: 3.536  loss_ce_7: 1.825  loss_mask_7: 3.596  loss_ce_8: 1.826  loss_mask_8: 3.526  time: 2.4802  data_time: 0.3945  lr: 9.2136e-05  max_mem: 18446M
[01/24 05:04:55] d2.utils.events INFO:  eta: 1 day, 12:00:11  iter: 5239  total_loss: 52  loss_ce: 1.746  loss_mask: 3.351  loss_ce_0: 1.213  loss_mask_0: 4.428  loss_ce_1: 1.214  loss_mask_1: 4.028  loss_ce_2: 1.686  loss_mask_2: 3.383  loss_ce_3: 1.74  loss_mask_3: 3.32  loss_ce_4: 1.767  loss_mask_4: 3.34  loss_ce_5: 1.765  loss_mask_5: 3.352  loss_ce_6: 1.808  loss_mask_6: 3.391  loss_ce_7: 1.794  loss_mask_7: 3.318  loss_ce_8: 1.794  loss_mask_8: 3.403  time: 2.4796  data_time: 0.4104  lr: 9.2106e-05  max_mem: 18446M
[01/24 05:05:44] d2.utils.events INFO:  eta: 1 day, 12:01:47  iter: 5259  total_loss: 54.47  loss_ce: 1.828  loss_mask: 3.637  loss_ce_0: 1.233  loss_mask_0: 4.524  loss_ce_1: 1.26  loss_mask_1: 4.214  loss_ce_2: 1.713  loss_mask_2: 3.612  loss_ce_3: 1.78  loss_mask_3: 3.533  loss_ce_4: 1.828  loss_mask_4: 3.574  loss_ce_5: 1.83  loss_mask_5: 3.603  loss_ce_6: 1.848  loss_mask_6: 3.713  loss_ce_7: 1.885  loss_mask_7: 3.608  loss_ce_8: 1.873  loss_mask_8: 3.614  time: 2.4795  data_time: 0.3998  lr: 9.2076e-05  max_mem: 18446M
[01/24 05:06:33] d2.utils.events INFO:  eta: 1 day, 12:01:00  iter: 5279  total_loss: 51.14  loss_ce: 1.833  loss_mask: 3.357  loss_ce_0: 1.204  loss_mask_0: 4.246  loss_ce_1: 1.228  loss_mask_1: 3.818  loss_ce_2: 1.677  loss_mask_2: 3.283  loss_ce_3: 1.751  loss_mask_3: 3.164  loss_ce_4: 1.818  loss_mask_4: 3.273  loss_ce_5: 1.805  loss_mask_5: 3.279  loss_ce_6: 1.834  loss_mask_6: 3.363  loss_ce_7: 1.841  loss_mask_7: 3.278  loss_ce_8: 1.849  loss_mask_8: 3.301  time: 2.4794  data_time: 0.3867  lr: 9.2045e-05  max_mem: 18446M
[01/24 05:07:20] d2.utils.events INFO:  eta: 1 day, 12:00:02  iter: 5299  total_loss: 53.1  loss_ce: 1.781  loss_mask: 3.487  loss_ce_0: 1.232  loss_mask_0: 4.44  loss_ce_1: 1.231  loss_mask_1: 4.149  loss_ce_2: 1.665  loss_mask_2: 3.489  loss_ce_3: 1.744  loss_mask_3: 3.34  loss_ce_4: 1.786  loss_mask_4: 3.52  loss_ce_5: 1.79  loss_mask_5: 3.578  loss_ce_6: 1.822  loss_mask_6: 3.759  loss_ce_7: 1.863  loss_mask_7: 3.482  loss_ce_8: 1.82  loss_mask_8: 3.664  time: 2.4788  data_time: 0.3828  lr: 9.2015e-05  max_mem: 18446M
[01/24 05:08:09] d2.utils.events INFO:  eta: 1 day, 12:01:18  iter: 5319  total_loss: 53.13  loss_ce: 1.795  loss_mask: 3.46  loss_ce_0: 1.173  loss_mask_0: 4.046  loss_ce_1: 1.202  loss_mask_1: 4.055  loss_ce_2: 1.666  loss_mask_2: 3.489  loss_ce_3: 1.758  loss_mask_3: 3.377  loss_ce_4: 1.82  loss_mask_4: 3.49  loss_ce_5: 1.801  loss_mask_5: 3.53  loss_ce_6: 1.846  loss_mask_6: 3.507  loss_ce_7: 1.865  loss_mask_7: 3.504  loss_ce_8: 1.822  loss_mask_8: 3.417  time: 2.4788  data_time: 0.4050  lr: 9.1985e-05  max_mem: 18446M
[01/24 05:08:55] d2.utils.events INFO:  eta: 1 day, 11:55:33  iter: 5339  total_loss: 53.62  loss_ce: 1.809  loss_mask: 3.675  loss_ce_0: 1.173  loss_mask_0: 4.321  loss_ce_1: 1.209  loss_mask_1: 4.211  loss_ce_2: 1.664  loss_mask_2: 3.553  loss_ce_3: 1.763  loss_mask_3: 3.416  loss_ce_4: 1.821  loss_mask_4: 3.406  loss_ce_5: 1.834  loss_mask_5: 3.492  loss_ce_6: 1.835  loss_mask_6: 3.443  loss_ce_7: 1.85  loss_mask_7: 3.69  loss_ce_8: 1.846  loss_mask_8: 3.551  time: 2.4781  data_time: 0.3904  lr: 9.1955e-05  max_mem: 18446M
[01/24 05:09:42] d2.utils.events INFO:  eta: 1 day, 11:54:50  iter: 5359  total_loss: 51.88  loss_ce: 1.795  loss_mask: 3.394  loss_ce_0: 1.195  loss_mask_0: 4.106  loss_ce_1: 1.203  loss_mask_1: 3.917  loss_ce_2: 1.684  loss_mask_2: 3.381  loss_ce_3: 1.746  loss_mask_3: 3.271  loss_ce_4: 1.789  loss_mask_4: 3.357  loss_ce_5: 1.797  loss_mask_5: 3.402  loss_ce_6: 1.801  loss_mask_6: 3.385  loss_ce_7: 1.859  loss_mask_7: 3.605  loss_ce_8: 1.817  loss_mask_8: 3.363  time: 2.4775  data_time: 0.3404  lr: 9.1924e-05  max_mem: 18446M
[01/24 05:10:32] d2.utils.events INFO:  eta: 1 day, 11:57:33  iter: 5379  total_loss: 52.12  loss_ce: 1.771  loss_mask: 3.419  loss_ce_0: 1.232  loss_mask_0: 4.215  loss_ce_1: 1.186  loss_mask_1: 3.959  loss_ce_2: 1.671  loss_mask_2: 3.386  loss_ce_3: 1.742  loss_mask_3: 3.345  loss_ce_4: 1.774  loss_mask_4: 3.347  loss_ce_5: 1.784  loss_mask_5: 3.377  loss_ce_6: 1.793  loss_mask_6: 3.358  loss_ce_7: 1.806  loss_mask_7: 3.498  loss_ce_8: 1.803  loss_mask_8: 3.457  time: 2.4777  data_time: 0.4464  lr: 9.1894e-05  max_mem: 18446M
[01/24 05:11:19] d2.utils.events INFO:  eta: 1 day, 11:54:32  iter: 5399  total_loss: 50.87  loss_ce: 1.79  loss_mask: 3.296  loss_ce_0: 1.133  loss_mask_0: 4.14  loss_ce_1: 1.18  loss_mask_1: 3.995  loss_ce_2: 1.674  loss_mask_2: 3.345  loss_ce_3: 1.792  loss_mask_3: 3.321  loss_ce_4: 1.818  loss_mask_4: 3.286  loss_ce_5: 1.823  loss_mask_5: 3.292  loss_ce_6: 1.809  loss_mask_6: 3.27  loss_ce_7: 1.822  loss_mask_7: 3.292  loss_ce_8: 1.828  loss_mask_8: 3.289  time: 2.4772  data_time: 0.3955  lr: 9.1864e-05  max_mem: 18446M
[01/24 05:12:05] d2.utils.events INFO:  eta: 1 day, 11:52:28  iter: 5419  total_loss: 51.74  loss_ce: 1.803  loss_mask: 3.456  loss_ce_0: 1.192  loss_mask_0: 4.281  loss_ce_1: 1.21  loss_mask_1: 3.894  loss_ce_2: 1.693  loss_mask_2: 3.368  loss_ce_3: 1.751  loss_mask_3: 3.282  loss_ce_4: 1.797  loss_mask_4: 3.295  loss_ce_5: 1.786  loss_mask_5: 3.34  loss_ce_6: 1.786  loss_mask_6: 3.34  loss_ce_7: 1.81  loss_mask_7: 3.49  loss_ce_8: 1.823  loss_mask_8: 3.465  time: 2.4766  data_time: 0.3890  lr: 9.1834e-05  max_mem: 18446M
[01/24 05:12:56] d2.utils.events INFO:  eta: 1 day, 11:54:58  iter: 5439  total_loss: 52.69  loss_ce: 1.822  loss_mask: 3.457  loss_ce_0: 1.124  loss_mask_0: 4.35  loss_ce_1: 1.211  loss_mask_1: 4.012  loss_ce_2: 1.688  loss_mask_2: 3.461  loss_ce_3: 1.78  loss_mask_3: 3.402  loss_ce_4: 1.808  loss_mask_4: 3.405  loss_ce_5: 1.808  loss_mask_5: 3.38  loss_ce_6: 1.841  loss_mask_6: 3.463  loss_ce_7: 1.851  loss_mask_7: 3.581  loss_ce_8: 1.824  loss_mask_8: 3.398  time: 2.4769  data_time: 0.4130  lr: 9.1803e-05  max_mem: 18446M
[01/24 05:13:42] d2.utils.events INFO:  eta: 1 day, 11:56:00  iter: 5459  total_loss: 53.55  loss_ce: 1.826  loss_mask: 3.476  loss_ce_0: 1.155  loss_mask_0: 4.41  loss_ce_1: 1.227  loss_mask_1: 4.341  loss_ce_2: 1.682  loss_mask_2: 3.678  loss_ce_3: 1.774  loss_mask_3: 3.592  loss_ce_4: 1.785  loss_mask_4: 3.432  loss_ce_5: 1.78  loss_mask_5: 3.468  loss_ce_6: 1.8  loss_mask_6: 3.419  loss_ce_7: 1.859  loss_mask_7: 3.472  loss_ce_8: 1.846  loss_mask_8: 3.374  time: 2.4762  data_time: 0.3753  lr: 9.1773e-05  max_mem: 18446M
[01/24 05:14:29] d2.utils.events INFO:  eta: 1 day, 11:58:28  iter: 5479  total_loss: 54.79  loss_ce: 1.833  loss_mask: 3.724  loss_ce_0: 1.155  loss_mask_0: 4.428  loss_ce_1: 1.209  loss_mask_1: 4.243  loss_ce_2: 1.7  loss_mask_2: 3.618  loss_ce_3: 1.794  loss_mask_3: 3.499  loss_ce_4: 1.811  loss_mask_4: 3.564  loss_ce_5: 1.78  loss_mask_5: 3.446  loss_ce_6: 1.811  loss_mask_6: 3.538  loss_ce_7: 1.878  loss_mask_7: 3.674  loss_ce_8: 1.849  loss_mask_8: 3.593  time: 2.4758  data_time: 0.3884  lr: 9.1743e-05  max_mem: 18446M
[01/24 05:15:20] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 05:15:20] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 05:15:20] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 05:19:20] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 9.914165965153732, 'error_1pix': 0.8381488559737648, 'error_3pix': 0.7132226788473206, 'mIoU': 0.5944982666566399, 'fwIoU': 6.52344911759139, 'IoU-0': nan, 'IoU-1': 57.562835466092544, 'IoU-2': 1.846293823630198e-05, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 6.233788254420847e-06, 'IoU-11': 6.743471570993934e-05, 'IoU-12': 0.0, 'IoU-13': 0.0006203880739587457, 'IoU-14': 0.002534591072284741, 'IoU-15': 0.22799290211214557, 'IoU-16': 0.006072549438139809, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 1.4983088117766505, 'IoU-20': 0.060818221340960085, 'IoU-21': 0.0013008624569249313, 'IoU-22': 2.7798476832499225e-06, 'IoU-23': 0.0, 'IoU-24': 0.001540029320792113, 'IoU-25': 2.0889984471189353, 'IoU-26': 3.791455186863265, 'IoU-27': 0.32435335031826906, 'IoU-28': 7.779249560573243e-05, 'IoU-29': 0.004012431770531444, 'IoU-30': 0.1520527491995847, 'IoU-31': 0.7456336455252569, 'IoU-32': 3.9257998525739266, 'IoU-33': 3.599016620129094, 'IoU-34': 3.0973246584720817, 'IoU-35': 0.4127753003622682, 'IoU-36': 3.0043250952791616, 'IoU-37': 0.016623981469877445, 'IoU-38': 0.0695219637587689, 'IoU-39': 3.7007857845440495, 'IoU-40': 0.035362332668833464, 'IoU-41': 0.0045887939221272555, 'IoU-42': 2.964796794500869, 'IoU-43': 0.20384165028307777, 'IoU-44': 4.738519810719845, 'IoU-45': 0.005876337404574621, 'IoU-46': 0.0, 'IoU-47': 0.03270782746444707, 'IoU-48': 3.539143368043482e-05, 'IoU-49': 0.0, 'IoU-50': 0.20552865484945246, 'IoU-51': 0.09440298270183596, 'IoU-52': 0.0, 'IoU-53': 0.006536905914525092, 'IoU-54': 1.1203224646556466e-05, 'IoU-55': 0.00039643980487587824, 'IoU-56': 0.1859071126271221, 'IoU-57': 0.04421698900145717, 'IoU-58': 0.0, 'IoU-59': 0.7341146533908333, 'IoU-60': 0.0003867173482112705, 'IoU-61': 0.23391606125419076, 'IoU-62': 0.7800620952920483, 'IoU-63': 0.0, 'IoU-64': 0.07388626234611805, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 2.9847918012839836, 'IoU-68': 1.3876029547551203, 'IoU-69': 0.056936016727801714, 'IoU-70': 0.005008466818384524, 'IoU-71': 2.07095469839469, 'IoU-72': 0.11709748150958672, 'IoU-73': 0.21299878589122412, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 2.962120966071462, 'IoU-77': 0.0454504588937865, 'IoU-78': 0.0017960849339739224, 'IoU-79': 0.4364911420134992, 'IoU-80': 0.08248640557435595, 'IoU-81': 0.0, 'IoU-82': 0.0004048761483862087, 'IoU-83': 8.850835214596797e-05, 'IoU-84': 0.2042512392818864, 'IoU-85': 0.0024784973146170066, 'IoU-86': 0.3085986801934672, 'IoU-87': 0.12803641602314086, 'IoU-88': 0.0, 'IoU-89': 1.427167010082858, 'IoU-90': 0.02861644724151828, 'IoU-91': 0.13523032700670642, 'IoU-92': 1.2026063388035486, 'IoU-93': 2.6218462010250594, 'IoU-94': 0.03238210829520946, 'IoU-95': 0.0, 'IoU-96': 0.00014986102887255885, 'IoU-97': 0.004345894908732785, 'IoU-98': 0.0, 'IoU-99': 0.021047623056690105, 'IoU-100': 0.002208393312822965, 'IoU-101': 0.0, 'IoU-102': 0.6973461653563271, 'IoU-103': 0.0035271220400685767, 'IoU-104': 0.007049746818954208, 'IoU-105': 0.1900403563618149, 'IoU-106': 0.00816665827388154, 'IoU-107': 0.0004068834921670859, 'IoU-108': 0.4168242683276748, 'IoU-109': 0.05085386870645998, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.3281800565226403, 'IoU-113': 0.0, 'IoU-114': 0.00032787315243478605, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 8.025327934962743e-05, 'IoU-118': 1.6687707437218924, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0013019765305710598, 'IoU-122': 0.0, 'IoU-123': 0.011945635979497118, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.00022753723931342914, 'IoU-127': 0.0, 'IoU-128': 0.001767488691119771, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.22818453628606172, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.142185654348554, 'pACC': 9.740244114902463, 'ACC-0': nan, 'ACC-1': 63.86461017416638, 'ACC-2': 1.848959257812962e-05, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 6.234172993313226e-06, 'ACC-11': 6.76375468359575e-05, 'ACC-12': 0.0, 'ACC-13': 0.0006217690162939735, 'ACC-14': 0.0025370456841641463, 'ACC-15': 0.2640407656431692, 'ACC-16': 0.0060829652371380575, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 5.2034319563625555, 'ACC-20': 0.062347026852329915, 'ACC-21': 0.0013079839459786467, 'ACC-22': 2.7845993500355275e-06, 'ACC-23': 0.0, 'ACC-24': 0.0015465600155554005, 'ACC-25': 22.588365914021413, 'ACC-26': 47.943237393499786, 'ACC-27': 0.4135705196902965, 'ACC-28': 7.781185905182907e-05, 'ACC-29': 0.0040163205632440645, 'ACC-30': 0.15693066035681527, 'ACC-31': 0.905711557169267, 'ACC-32': 14.302170328363015, 'ACC-33': 9.232720753965342, 'ACC-34': 8.053482372162586, 'ACC-35': 0.43222638159278587, 'ACC-36': 10.111218030152996, 'ACC-37': 0.016704056742955727, 'ACC-38': 0.07051536070479153, 'ACC-39': 18.577357447324577, 'ACC-40': 0.03569574157788395, 'ACC-41': 0.00460167118204946, 'ACC-42': 7.505428442639082, 'ACC-43': 0.20832918443140008, 'ACC-44': 30.378664768376257, 'ACC-45': 0.005891753614810318, 'ACC-46': 0.0, 'ACC-47': 0.032797931979415045, 'ACC-48': 3.5392034916365964e-05, 'ACC-49': 0.0, 'ACC-50': 0.21716031802081198, 'ACC-51': 0.09703017965892678, 'ACC-52': 0.0, 'ACC-53': 0.006546399031590049, 'ACC-54': 1.1203306857678567e-05, 'ACC-55': 0.0003964671111595551, 'ACC-56': 0.19714966756462976, 'ACC-57': 0.044640363881812015, 'ACC-58': 0.0, 'ACC-59': 1.0384119580838083, 'ACC-60': 0.0003867932064588466, 'ACC-61': 0.2452194805333561, 'ACC-62': 0.9985643414091465, 'ACC-63': 0.0, 'ACC-64': 0.08337684594178321, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 25.679993601006235, 'ACC-68': 8.775602379259054, 'ACC-69': 0.06355232723855923, 'ACC-70': 0.00507273604531616, 'ACC-71': 33.87548534737448, 'ACC-72': 0.1231795354257261, 'ACC-73': 0.2698923215159405, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 11.610088966215205, 'ACC-77': 0.04679784618562076, 'ACC-78': 0.0017968961613639375, 'ACC-79': 0.5360023069384247, 'ACC-80': 0.08354314956678648, 'ACC-81': 0.0, 'ACC-82': 0.0004050415066283917, 'ACC-83': 8.903650151545691e-05, 'ACC-84': 0.22132211895343695, 'ACC-85': 0.0024996840677081094, 'ACC-86': 0.4111379964389622, 'ACC-87': 0.13820252542603473, 'ACC-88': 0.0, 'ACC-89': 3.809970675087996, 'ACC-90': 0.028776149951748816, 'ACC-91': 0.15297731521409885, 'ACC-92': 3.3374386180306326, 'ACC-93': 62.00433388121913, 'ACC-94': 0.033800550296678514, 'ACC-95': 0.0, 'ACC-96': 0.00014987837369974266, 'ACC-97': 0.004348697761910167, 'ACC-98': 0.0, 'ACC-99': 0.02130889450612346, 'ACC-100': 0.0022097933174228214, 'ACC-101': 0.0, 'ACC-102': 9.28912550974173, 'ACC-103': 0.0035420799093227543, 'ACC-104': 0.007107547773050342, 'ACC-105': 0.29204063489404175, 'ACC-106': 0.008207603597395278, 'ACC-107': 0.0004079474694202577, 'ACC-108': 0.7619885657497028, 'ACC-109': 0.06749985470946855, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.39938900489076357, 'ACC-113': 0.0, 'ACC-114': 0.00032798869678064515, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 8.036472727827975e-05, 'ACC-118': 5.523414607315709, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0013626286378210296, 'ACC-122': 0.0, 'ACC-123': 0.012434153263767865, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.00022768877676481572, 'ACC-127': 0.0, 'ACC-128': 0.0017685277677154648, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.37547745282481043, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 05:19:20] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 05:19:20] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 05:19:20] d2.evaluation.testing INFO: copypaste: 9.9142,0.8381,0.7132,0.5945,6.5234,2.1422,9.7402
[01/24 05:19:20] d2.utils.events INFO:  eta: 1 day, 12:00:34  iter: 5499  total_loss: 52.17  loss_ce: 1.768  loss_mask: 3.357  loss_ce_0: 1.171  loss_mask_0: 4.14  loss_ce_1: 1.189  loss_mask_1: 4.03  loss_ce_2: 1.651  loss_mask_2: 3.462  loss_ce_3: 1.756  loss_mask_3: 3.338  loss_ce_4: 1.8  loss_mask_4: 3.267  loss_ce_5: 1.777  loss_mask_5: 3.281  loss_ce_6: 1.789  loss_mask_6: 3.337  loss_ce_7: 1.839  loss_mask_7: 3.583  loss_ce_8: 1.81  loss_mask_8: 3.346  time: 2.4759  data_time: 0.4231  lr: 9.1712e-05  max_mem: 18446M
[01/24 05:20:11] d2.utils.events INFO:  eta: 1 day, 12:02:53  iter: 5519  total_loss: 54.44  loss_ce: 1.806  loss_mask: 3.569  loss_ce_0: 1.135  loss_mask_0: 4.578  loss_ce_1: 1.166  loss_mask_1: 4.182  loss_ce_2: 1.676  loss_mask_2: 3.712  loss_ce_3: 1.819  loss_mask_3: 3.586  loss_ce_4: 1.84  loss_mask_4: 3.613  loss_ce_5: 1.823  loss_mask_5: 3.599  loss_ce_6: 1.824  loss_mask_6: 3.602  loss_ce_7: 1.836  loss_mask_7: 3.593  loss_ce_8: 1.826  loss_mask_8: 3.522  time: 2.4762  data_time: 0.4430  lr: 9.1682e-05  max_mem: 18446M
[01/24 05:20:58] d2.utils.events INFO:  eta: 1 day, 12:02:02  iter: 5539  total_loss: 52.03  loss_ce: 1.764  loss_mask: 3.401  loss_ce_0: 1.115  loss_mask_0: 4.412  loss_ce_1: 1.157  loss_mask_1: 4.047  loss_ce_2: 1.626  loss_mask_2: 3.445  loss_ce_3: 1.769  loss_mask_3: 3.436  loss_ce_4: 1.8  loss_mask_4: 3.373  loss_ce_5: 1.79  loss_mask_5: 3.448  loss_ce_6: 1.793  loss_mask_6: 3.512  loss_ce_7: 1.83  loss_mask_7: 3.489  loss_ce_8: 1.819  loss_mask_8: 3.359  time: 2.4757  data_time: 0.4142  lr: 9.1652e-05  max_mem: 18446M
[01/24 05:21:44] d2.utils.events INFO:  eta: 1 day, 11:59:33  iter: 5559  total_loss: 52.28  loss_ce: 1.851  loss_mask: 3.608  loss_ce_0: 1.096  loss_mask_0: 4.051  loss_ce_1: 1.167  loss_mask_1: 3.929  loss_ce_2: 1.617  loss_mask_2: 3.479  loss_ce_3: 1.756  loss_mask_3: 3.37  loss_ce_4: 1.802  loss_mask_4: 3.375  loss_ce_5: 1.8  loss_mask_5: 3.369  loss_ce_6: 1.785  loss_mask_6: 3.481  loss_ce_7: 1.814  loss_mask_7: 3.408  loss_ce_8: 1.854  loss_mask_8: 3.409  time: 2.4752  data_time: 0.3479  lr: 9.1621e-05  max_mem: 18446M
[01/24 05:22:33] d2.utils.events INFO:  eta: 1 day, 11:58:06  iter: 5579  total_loss: 53.77  loss_ce: 2.099  loss_mask: 3.791  loss_ce_0: 1.107  loss_mask_0: 4.238  loss_ce_1: 1.158  loss_mask_1: 3.978  loss_ce_2: 1.628  loss_mask_2: 3.545  loss_ce_3: 1.756  loss_mask_3: 3.498  loss_ce_4: 1.85  loss_mask_4: 3.585  loss_ce_5: 1.834  loss_mask_5: 3.554  loss_ce_6: 1.865  loss_mask_6: 3.548  loss_ce_7: 1.862  loss_mask_7: 3.55  loss_ce_8: 2.001  loss_mask_8: 3.422  time: 2.4751  data_time: 0.4191  lr: 9.1591e-05  max_mem: 18446M
[01/24 05:23:20] d2.utils.events INFO:  eta: 1 day, 11:57:39  iter: 5599  total_loss: 53.13  loss_ce: 1.958  loss_mask: 3.629  loss_ce_0: 1.113  loss_mask_0: 4.363  loss_ce_1: 1.162  loss_mask_1: 4.063  loss_ce_2: 1.626  loss_mask_2: 3.487  loss_ce_3: 1.78  loss_mask_3: 3.276  loss_ce_4: 1.827  loss_mask_4: 3.442  loss_ce_5: 1.836  loss_mask_5: 3.493  loss_ce_6: 1.835  loss_mask_6: 3.547  loss_ce_7: 1.85  loss_mask_7: 3.34  loss_ce_8: 1.908  loss_mask_8: 3.506  time: 2.4746  data_time: 0.3943  lr: 9.1561e-05  max_mem: 18446M
[01/24 05:24:08] d2.utils.events INFO:  eta: 1 day, 11:56:52  iter: 5619  total_loss: 51.21  loss_ce: 1.876  loss_mask: 3.486  loss_ce_0: 1.127  loss_mask_0: 4.247  loss_ce_1: 1.19  loss_mask_1: 3.902  loss_ce_2: 1.649  loss_mask_2: 3.412  loss_ce_3: 1.767  loss_mask_3: 3.288  loss_ce_4: 1.828  loss_mask_4: 3.215  loss_ce_5: 1.827  loss_mask_5: 3.37  loss_ce_6: 1.824  loss_mask_6: 3.315  loss_ce_7: 1.858  loss_mask_7: 3.245  loss_ce_8: 1.899  loss_mask_8: 3.368  time: 2.4743  data_time: 0.3810  lr: 9.1531e-05  max_mem: 18446M
[01/24 05:24:56] d2.utils.events INFO:  eta: 1 day, 11:55:01  iter: 5639  total_loss: 50.82  loss_ce: 1.837  loss_mask: 3.454  loss_ce_0: 1.104  loss_mask_0: 4.058  loss_ce_1: 1.149  loss_mask_1: 4.071  loss_ce_2: 1.624  loss_mask_2: 3.297  loss_ce_3: 1.762  loss_mask_3: 3.376  loss_ce_4: 1.793  loss_mask_4: 3.328  loss_ce_5: 1.801  loss_mask_5: 3.265  loss_ce_6: 1.794  loss_mask_6: 3.33  loss_ce_7: 1.802  loss_mask_7: 3.205  loss_ce_8: 1.873  loss_mask_8: 3.318  time: 2.4740  data_time: 0.3877  lr: 9.15e-05  max_mem: 18446M
[01/24 05:25:42] d2.utils.events INFO:  eta: 1 day, 11:54:14  iter: 5659  total_loss: 51.2  loss_ce: 1.841  loss_mask: 3.375  loss_ce_0: 1.099  loss_mask_0: 4.147  loss_ce_1: 1.173  loss_mask_1: 3.982  loss_ce_2: 1.648  loss_mask_2: 3.563  loss_ce_3: 1.758  loss_mask_3: 3.395  loss_ce_4: 1.783  loss_mask_4: 3.368  loss_ce_5: 1.79  loss_mask_5: 3.26  loss_ce_6: 1.799  loss_mask_6: 3.345  loss_ce_7: 1.829  loss_mask_7: 3.225  loss_ce_8: 1.873  loss_mask_8: 3.328  time: 2.4734  data_time: 0.3329  lr: 9.147e-05  max_mem: 18446M
[01/24 05:26:29] d2.utils.events INFO:  eta: 1 day, 11:51:58  iter: 5679  total_loss: 50.79  loss_ce: 1.849  loss_mask: 3.484  loss_ce_0: 1.068  loss_mask_0: 4.122  loss_ce_1: 1.145  loss_mask_1: 3.968  loss_ce_2: 1.654  loss_mask_2: 3.434  loss_ce_3: 1.764  loss_mask_3: 3.317  loss_ce_4: 1.78  loss_mask_4: 3.317  loss_ce_5: 1.801  loss_mask_5: 3.315  loss_ce_6: 1.794  loss_mask_6: 3.398  loss_ce_7: 1.857  loss_mask_7: 3.257  loss_ce_8: 1.901  loss_mask_8: 3.453  time: 2.4730  data_time: 0.3825  lr: 9.144e-05  max_mem: 18446M
[01/24 05:27:17] d2.utils.events INFO:  eta: 1 day, 11:46:31  iter: 5699  total_loss: 51.2  loss_ce: 1.855  loss_mask: 3.421  loss_ce_0: 1.074  loss_mask_0: 3.862  loss_ce_1: 1.147  loss_mask_1: 3.938  loss_ce_2: 1.64  loss_mask_2: 3.423  loss_ce_3: 1.76  loss_mask_3: 3.276  loss_ce_4: 1.8  loss_mask_4: 3.348  loss_ce_5: 1.809  loss_mask_5: 3.334  loss_ce_6: 1.794  loss_mask_6: 3.329  loss_ce_7: 1.825  loss_mask_7: 3.29  loss_ce_8: 1.891  loss_mask_8: 3.455  time: 2.4727  data_time: 0.3885  lr: 9.1409e-05  max_mem: 18446M
[01/24 05:28:03] d2.utils.events INFO:  eta: 1 day, 11:41:28  iter: 5719  total_loss: 54.52  loss_ce: 1.997  loss_mask: 3.57  loss_ce_0: 1.059  loss_mask_0: 4.236  loss_ce_1: 1.111  loss_mask_1: 4.254  loss_ce_2: 1.653  loss_mask_2: 3.85  loss_ce_3: 1.768  loss_mask_3: 3.65  loss_ce_4: 1.795  loss_mask_4: 3.567  loss_ce_5: 1.816  loss_mask_5: 3.549  loss_ce_6: 1.818  loss_mask_6: 3.594  loss_ce_7: 1.896  loss_mask_7: 3.6  loss_ce_8: 1.968  loss_mask_8: 3.646  time: 2.4720  data_time: 0.3775  lr: 9.1379e-05  max_mem: 18446M
[01/24 05:28:48] d2.utils.events INFO:  eta: 1 day, 11:35:58  iter: 5739  total_loss: 52.74  loss_ce: 2.062  loss_mask: 3.743  loss_ce_0: 1.085  loss_mask_0: 4.064  loss_ce_1: 1.1  loss_mask_1: 4  loss_ce_2: 1.628  loss_mask_2: 3.438  loss_ce_3: 1.749  loss_mask_3: 3.347  loss_ce_4: 1.812  loss_mask_4: 3.314  loss_ce_5: 1.815  loss_mask_5: 3.467  loss_ce_6: 1.818  loss_mask_6: 3.352  loss_ce_7: 1.847  loss_mask_7: 3.324  loss_ce_8: 1.954  loss_mask_8: 3.559  time: 2.4713  data_time: 0.3584  lr: 9.1349e-05  max_mem: 18446M
[01/24 05:29:33] d2.utils.events INFO:  eta: 1 day, 11:32:49  iter: 5759  total_loss: 52.09  loss_ce: 1.903  loss_mask: 3.649  loss_ce_0: 1.033  loss_mask_0: 4.071  loss_ce_1: 1.104  loss_mask_1: 3.967  loss_ce_2: 1.623  loss_mask_2: 3.445  loss_ce_3: 1.759  loss_mask_3: 3.328  loss_ce_4: 1.79  loss_mask_4: 3.268  loss_ce_5: 1.795  loss_mask_5: 3.26  loss_ce_6: 1.82  loss_mask_6: 3.383  loss_ce_7: 1.888  loss_mask_7: 3.483  loss_ce_8: 1.897  loss_mask_8: 3.349  time: 2.4705  data_time: 0.3717  lr: 9.1319e-05  max_mem: 18446M
[01/24 05:30:18] d2.utils.events INFO:  eta: 1 day, 11:30:27  iter: 5779  total_loss: 53.53  loss_ce: 1.84  loss_mask: 3.519  loss_ce_0: 1.09  loss_mask_0: 4.12  loss_ce_1: 1.113  loss_mask_1: 4.151  loss_ce_2: 1.631  loss_mask_2: 3.505  loss_ce_3: 1.752  loss_mask_3: 3.492  loss_ce_4: 1.79  loss_mask_4: 3.439  loss_ce_5: 1.806  loss_mask_5: 3.476  loss_ce_6: 1.804  loss_mask_6: 3.454  loss_ce_7: 1.869  loss_mask_7: 3.687  loss_ce_8: 1.89  loss_mask_8: 3.504  time: 2.4697  data_time: 0.3997  lr: 9.1288e-05  max_mem: 18446M
[01/24 05:31:02] d2.utils.events INFO:  eta: 1 day, 11:25:58  iter: 5799  total_loss: 52.61  loss_ce: 1.845  loss_mask: 3.52  loss_ce_0: 1.009  loss_mask_0: 3.997  loss_ce_1: 1.031  loss_mask_1: 3.796  loss_ce_2: 1.627  loss_mask_2: 3.449  loss_ce_3: 1.751  loss_mask_3: 3.334  loss_ce_4: 1.796  loss_mask_4: 3.439  loss_ce_5: 1.812  loss_mask_5: 3.349  loss_ce_6: 1.836  loss_mask_6: 3.409  loss_ce_7: 1.839  loss_mask_7: 3.567  loss_ce_8: 1.889  loss_mask_8: 3.378  time: 2.4689  data_time: 0.3922  lr: 9.1258e-05  max_mem: 18446M
[01/24 05:31:48] d2.utils.events INFO:  eta: 1 day, 11:22:13  iter: 5819  total_loss: 51.09  loss_ce: 1.807  loss_mask: 3.351  loss_ce_0: 1.065  loss_mask_0: 4.044  loss_ce_1: 1.098  loss_mask_1: 4.014  loss_ce_2: 1.586  loss_mask_2: 3.33  loss_ce_3: 1.73  loss_mask_3: 3.171  loss_ce_4: 1.799  loss_mask_4: 3.27  loss_ce_5: 1.79  loss_mask_5: 3.326  loss_ce_6: 1.802  loss_mask_6: 3.206  loss_ce_7: 1.831  loss_mask_7: 3.27  loss_ce_8: 1.878  loss_mask_8: 3.356  time: 2.4682  data_time: 0.3940  lr: 9.1228e-05  max_mem: 18446M
[01/24 05:32:33] d2.utils.events INFO:  eta: 1 day, 11:20:52  iter: 5839  total_loss: 51.92  loss_ce: 1.835  loss_mask: 3.473  loss_ce_0: 1.097  loss_mask_0: 4.128  loss_ce_1: 1.091  loss_mask_1: 4.166  loss_ce_2: 1.606  loss_mask_2: 3.402  loss_ce_3: 1.767  loss_mask_3: 3.309  loss_ce_4: 1.78  loss_mask_4: 3.404  loss_ce_5: 1.81  loss_mask_5: 3.491  loss_ce_6: 1.793  loss_mask_6: 3.383  loss_ce_7: 1.849  loss_mask_7: 3.404  loss_ce_8: 1.876  loss_mask_8: 3.382  time: 2.4674  data_time: 0.3659  lr: 9.1197e-05  max_mem: 18446M
[01/24 05:33:17] d2.utils.events INFO:  eta: 1 day, 11:15:01  iter: 5859  total_loss: 51.05  loss_ce: 1.808  loss_mask: 3.277  loss_ce_0: 1.06  loss_mask_0: 3.952  loss_ce_1: 1.074  loss_mask_1: 3.853  loss_ce_2: 1.579  loss_mask_2: 3.44  loss_ce_3: 1.73  loss_mask_3: 3.256  loss_ce_4: 1.787  loss_mask_4: 3.298  loss_ce_5: 1.781  loss_mask_5: 3.374  loss_ce_6: 1.806  loss_mask_6: 3.286  loss_ce_7: 1.86  loss_mask_7: 3.386  loss_ce_8: 1.832  loss_mask_8: 3.288  time: 2.4666  data_time: 0.3765  lr: 9.1167e-05  max_mem: 18446M
[01/24 05:34:03] d2.utils.events INFO:  eta: 1 day, 11:13:25  iter: 5879  total_loss: 51.19  loss_ce: 1.769  loss_mask: 3.348  loss_ce_0: 1.088  loss_mask_0: 4.127  loss_ce_1: 1.143  loss_mask_1: 3.939  loss_ce_2: 1.578  loss_mask_2: 3.489  loss_ce_3: 1.708  loss_mask_3: 3.297  loss_ce_4: 1.766  loss_mask_4: 3.239  loss_ce_5: 1.764  loss_mask_5: 3.297  loss_ce_6: 1.785  loss_mask_6: 3.342  loss_ce_7: 1.797  loss_mask_7: 3.312  loss_ce_8: 1.842  loss_mask_8: 3.357  time: 2.4660  data_time: 0.3849  lr: 9.1137e-05  max_mem: 18446M
[01/24 05:34:48] d2.utils.events INFO:  eta: 1 day, 11:10:20  iter: 5899  total_loss: 49.89  loss_ce: 1.796  loss_mask: 3.306  loss_ce_0: 1.07  loss_mask_0: 4.049  loss_ce_1: 1.099  loss_mask_1: 3.854  loss_ce_2: 1.585  loss_mask_2: 3.467  loss_ce_3: 1.729  loss_mask_3: 3.324  loss_ce_4: 1.79  loss_mask_4: 3.284  loss_ce_5: 1.774  loss_mask_5: 3.241  loss_ce_6: 1.783  loss_mask_6: 3.29  loss_ce_7: 1.821  loss_mask_7: 3.188  loss_ce_8: 1.842  loss_mask_8: 3.19  time: 2.4653  data_time: 0.3540  lr: 9.1106e-05  max_mem: 18446M
[01/24 05:35:35] d2.utils.events INFO:  eta: 1 day, 11:06:14  iter: 5919  total_loss: 51.84  loss_ce: 1.808  loss_mask: 3.465  loss_ce_0: 1.012  loss_mask_0: 4.232  loss_ce_1: 1.006  loss_mask_1: 4.176  loss_ce_2: 1.546  loss_mask_2: 3.581  loss_ce_3: 1.707  loss_mask_3: 3.4  loss_ce_4: 1.795  loss_mask_4: 3.37  loss_ce_5: 1.789  loss_mask_5: 3.392  loss_ce_6: 1.793  loss_mask_6: 3.465  loss_ce_7: 1.811  loss_mask_7: 3.397  loss_ce_8: 1.855  loss_mask_8: 3.409  time: 2.4649  data_time: 0.3794  lr: 9.1076e-05  max_mem: 18446M
[01/24 05:36:25] d2.utils.events INFO:  eta: 1 day, 11:10:30  iter: 5939  total_loss: 50.55  loss_ce: 1.769  loss_mask: 3.343  loss_ce_0: 1.062  loss_mask_0: 4.044  loss_ce_1: 1.003  loss_mask_1: 3.927  loss_ce_2: 1.528  loss_mask_2: 3.375  loss_ce_3: 1.693  loss_mask_3: 3.261  loss_ce_4: 1.758  loss_mask_4: 3.254  loss_ce_5: 1.753  loss_mask_5: 3.295  loss_ce_6: 1.773  loss_mask_6: 3.275  loss_ce_7: 1.827  loss_mask_7: 3.344  loss_ce_8: 1.828  loss_mask_8: 3.277  time: 2.4649  data_time: 0.4054  lr: 9.1046e-05  max_mem: 18446M
[01/24 05:37:12] d2.utils.events INFO:  eta: 1 day, 11:09:06  iter: 5959  total_loss: 51.06  loss_ce: 1.799  loss_mask: 3.472  loss_ce_0: 1.028  loss_mask_0: 4.143  loss_ce_1: 1.033  loss_mask_1: 4.157  loss_ce_2: 1.545  loss_mask_2: 3.423  loss_ce_3: 1.694  loss_mask_3: 3.33  loss_ce_4: 1.763  loss_mask_4: 3.311  loss_ce_5: 1.754  loss_mask_5: 3.299  loss_ce_6: 1.78  loss_mask_6: 3.405  loss_ce_7: 1.791  loss_mask_7: 3.35  loss_ce_8: 1.831  loss_mask_8: 3.406  time: 2.4645  data_time: 0.3804  lr: 9.1015e-05  max_mem: 18446M
[01/24 05:37:57] d2.utils.events INFO:  eta: 1 day, 11:05:09  iter: 5979  total_loss: 49.17  loss_ce: 1.767  loss_mask: 3.298  loss_ce_0: 1.069  loss_mask_0: 3.781  loss_ce_1: 1.038  loss_mask_1: 3.795  loss_ce_2: 1.541  loss_mask_2: 3.333  loss_ce_3: 1.684  loss_mask_3: 3.192  loss_ce_4: 1.747  loss_mask_4: 3.065  loss_ce_5: 1.741  loss_mask_5: 3.13  loss_ce_6: 1.758  loss_mask_6: 3.16  loss_ce_7: 1.791  loss_mask_7: 3.212  loss_ce_8: 1.843  loss_mask_8: 3.183  time: 2.4638  data_time: 0.3797  lr: 9.0985e-05  max_mem: 18446M
[01/24 05:38:48] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 05:38:48] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 05:38:48] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 05:42:49] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 9.817875073502185, 'error_1pix': 0.8018355657023779, 'error_3pix': 0.6716191767237872, 'mIoU': 0.8122763323980021, 'fwIoU': 10.227112807045707, 'IoU-0': nan, 'IoU-1': 92.39340931226796, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.00013401412508878436, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.4930315700058503, 'IoU-13': 0.1624903788591465, 'IoU-14': 0.04169452431188516, 'IoU-15': 0.001318516599990688, 'IoU-16': 0.00026205765660208206, 'IoU-17': 3.556760299525049, 'IoU-18': 2.9837096910144835e-05, 'IoU-19': 0.005609437655684514, 'IoU-20': 5.849480490704914e-05, 'IoU-21': 0.004267270507357545, 'IoU-22': 0.0023560174981725568, 'IoU-23': 0.04169880136567669, 'IoU-24': 1.8146301139766972, 'IoU-25': 0.0, 'IoU-26': 3.525972895179757, 'IoU-27': 0.45039983534738215, 'IoU-28': 0.010838272592043837, 'IoU-29': 0.6403478355438673, 'IoU-30': 1.2479909019297355, 'IoU-31': 0.0019190803271825606, 'IoU-32': 2.6733116642271826, 'IoU-33': 0.07520442785708824, 'IoU-34': 4.50881981137351, 'IoU-35': 1.8176814210308336, 'IoU-36': 4.03500347472802, 'IoU-37': 0.7282667041200716, 'IoU-38': 3.7680792818516538, 'IoU-39': 0.10938920663012199, 'IoU-40': 1.998104517878556, 'IoU-41': 0.0, 'IoU-42': 4.351465215880279, 'IoU-43': 0.9358704116159806, 'IoU-44': 0.05960327610494144, 'IoU-45': 0.0, 'IoU-46': 4.821904172019846, 'IoU-47': 0.02927760746162178, 'IoU-48': 0.003001165327302715, 'IoU-49': 0.42943423658253793, 'IoU-50': 0.185249944235716, 'IoU-51': 0.0, 'IoU-52': 1.7689181269059753, 'IoU-53': 0.06437061343146151, 'IoU-54': 0.00023487458032945521, 'IoU-55': 0.7054100788713007, 'IoU-56': 0.0, 'IoU-57': 2.033296845524319, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 2.5006445411304764e-05, 'IoU-62': 0.00035043687212663667, 'IoU-63': 0.040392046217654465, 'IoU-64': 1.8176511033561227, 'IoU-65': 0.0012547262177513131, 'IoU-66': 0.03994781094036598, 'IoU-67': 0.47125284865718, 'IoU-68': 0.7134019701744244, 'IoU-69': 2.592952437200388, 'IoU-70': 0.40169946397432355, 'IoU-71': 0.05863267851879037, 'IoU-72': 0.0, 'IoU-73': 0.04217651949131627, 'IoU-74': 0.0011649838094469735, 'IoU-75': 1.0920123013001717e-05, 'IoU-76': 0.00218830178267309, 'IoU-77': 0.00014182778484855957, 'IoU-78': 2.2385518238130344, 'IoU-79': 0.004259804076495089, 'IoU-80': 0.44238112910681554, 'IoU-81': 0.048517431101666196, 'IoU-82': 2.6378075656063658, 'IoU-83': 3.3299342104898034e-05, 'IoU-84': 0.0022877145312795695, 'IoU-85': 0.08026689190478317, 'IoU-86': 1.8484548973225534, 'IoU-87': 0.0019430132542832446, 'IoU-88': 0.0010417503413928829, 'IoU-89': 1.2801669747388491e-05, 'IoU-90': 0.0, 'IoU-91': 0.004923495108020671, 'IoU-92': 0.03522003220332306, 'IoU-93': 0.03035863679066164, 'IoU-94': 0.3321695437623982, 'IoU-95': 0.0, 'IoU-96': 0.4821943115436982, 'IoU-97': 0.0, 'IoU-98': 0.00027059029814721413, 'IoU-99': 0.0006932388987900093, 'IoU-100': 0.03332940861402753, 'IoU-101': 8.597306463884865e-05, 'IoU-102': 0.1361863367543434, 'IoU-103': 0.17154461216845393, 'IoU-104': 0.0003933137643347504, 'IoU-105': 0.0, 'IoU-106': 0.051922558341693986, 'IoU-107': 0.0, 'IoU-108': 0.0008507989551091026, 'IoU-109': 0.001358432640419484, 'IoU-110': 0.0, 'IoU-111': 0.32999154889653126, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.001379021526163123, 'IoU-115': 0.8033985140694646, 'IoU-116': 7.7407708724081e-05, 'IoU-117': 0.001435979830865509, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0008829290090740575, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0009136976062950109, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.5510396059716792, 'IoU-135': 0.0003527857017366229, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.00016529813585027295, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.209115193755698, 'pACC': 13.266161756433206, 'ACC-0': nan, 'ACC-1': 98.42987503409273, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.00013409553233914906, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.5165677176827862, 'ACC-13': 0.16604473225036293, 'ACC-14': 0.04199078228144422, 'ACC-15': 0.0013298969188097441, 'ACC-16': 0.0002621739479654626, 'ACC-17': 20.3564802335239, 'ACC-18': 2.9847400686878236e-05, 'ACC-19': 0.005623818431212265, 'ACC-20': 5.850422314274341e-05, 'ACC-21': 0.004274144336058369, 'ACC-22': 0.0023585556494800917, 'ACC-23': 0.042680315264368024, 'ACC-24': 3.3993919212880774, 'ACC-25': 0.0, 'ACC-26': 40.63159271172512, 'ACC-27': 0.5525288383975513, 'ACC-28': 0.010896542187961693, 'ACC-29': 0.7395191372835899, 'ACC-30': 6.089309323287686, 'ACC-31': 0.0019487469085906737, 'ACC-32': 5.047001305400834, 'ACC-33': 0.081898977663897, 'ACC-34': 17.9156161564781, 'ACC-35': 4.5078870827881214, 'ACC-36': 12.47022428299876, 'ACC-37': 0.8233891595704279, 'ACC-38': 10.026845205579043, 'ACC-39': 0.11285398778344288, 'ACC-40': 3.4132863484731066, 'ACC-41': 0.0, 'ACC-42': 20.49462415995374, 'ACC-43': 1.173148668332635, 'ACC-44': 0.06054529195106127, 'ACC-45': 0.0, 'ACC-46': 30.74067337310006, 'ACC-47': 0.029713673926018955, 'ACC-48': 0.0030038989635265616, 'ACC-49': 0.48685722494514566, 'ACC-50': 0.19771045435352466, 'ACC-51': 0.0, 'ACC-52': 2.8499196223819787, 'ACC-53': 0.06532250538254941, 'ACC-54': 0.0002352694440112499, 'ACC-55': 0.7730280228871588, 'ACC-56': 0.0, 'ACC-57': 3.753425289459393, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 2.5041134236505832e-05, 'ACC-62': 0.0003505025856575744, 'ACC-63': 0.04102309836542137, 'ACC-64': 3.0643748557570105, 'ACC-65': 0.0012562522040054662, 'ACC-66': 0.04163888356280031, 'ACC-67': 0.9251455273805621, 'ACC-68': 0.9484178527058672, 'ACC-69': 29.82591216920087, 'ACC-70': 2.6172988135940005, 'ACC-71': 0.0662327230668386, 'ACC-72': 0.0, 'ACC-73': 0.04592125146238634, 'ACC-74': 0.0011655409030240558, 'ACC-75': 1.0920142092888913e-05, 'ACC-76': 0.0021922773376984008, 'ACC-77': 0.00014191089349500113, 'ACC-78': 5.565941319582863, 'ACC-79': 0.004488683783142888, 'ACC-80': 2.269531763592017, 'ACC-81': 0.05853629349918063, 'ACC-82': 50.429197732037586, 'ACC-83': 3.338868806829634e-05, 'ACC-84': 0.0022910253166236686, 'ACC-85': 0.08276731690855739, 'ACC-86': 31.955481691724174, 'ACC-87': 0.001945308210228357, 'ACC-88': 0.001043179329062247, 'ACC-89': 1.2812912135326903e-05, 'ACC-90': 0.0, 'ACC-91': 0.0049531882883768, 'ACC-92': 0.15967524027007, 'ACC-93': 0.03148243988467144, 'ACC-94': 0.5256799034669665, 'ACC-95': 0.0, 'ACC-96': 2.50643269653343, 'ACC-97': 0.0, 'ACC-98': 0.00027079727592382944, 'ACC-99': 0.0006942264273488187, 'ACC-100': 0.040343933042857015, 'ACC-101': 8.597402552740766e-05, 'ACC-102': 0.20346624376982328, 'ACC-103': 0.20121375271559458, 'ACC-104': 0.0003934974545633408, 'ACC-105': 0.0, 'ACC-106': 0.05690255529184587, 'ACC-107': 0.0, 'ACC-108': 0.000856725864581488, 'ACC-109': 0.001360769855545775, 'ACC-110': 0.0, 'ACC-111': 2.1357424485588776, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0013848411641849462, 'ACC-115': 3.695104716371236, 'ACC-116': 7.860510524437541e-05, 'ACC-117': 0.0014465650910090353, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0008881538045548475, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.000914755741921792, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.6077380439465748, 'ACC-135': 0.0003563080782167493, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0001656487550667813, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 05:42:49] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 05:42:49] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 05:42:49] d2.evaluation.testing INFO: copypaste: 9.8179,0.8018,0.6716,0.8123,10.2271,2.2091,13.2662
[01/24 05:42:49] d2.utils.events INFO:  eta: 1 day, 11:06:31  iter: 5999  total_loss: 50.91  loss_ce: 1.786  loss_mask: 3.321  loss_ce_0: 1.044  loss_mask_0: 4.046  loss_ce_1: 1.061  loss_mask_1: 4.011  loss_ce_2: 1.513  loss_mask_2: 3.454  loss_ce_3: 1.692  loss_mask_3: 3.29  loss_ce_4: 1.76  loss_mask_4: 3.273  loss_ce_5: 1.776  loss_mask_5: 3.31  loss_ce_6: 1.758  loss_mask_6: 3.299  loss_ce_7: 1.812  loss_mask_7: 3.338  loss_ce_8: 1.854  loss_mask_8: 3.492  time: 2.4641  data_time: 0.4657  lr: 9.0955e-05  max_mem: 18446M
[01/24 05:43:40] d2.utils.events INFO:  eta: 1 day, 11:08:59  iter: 6019  total_loss: 50.65  loss_ce: 1.787  loss_mask: 3.302  loss_ce_0: 1.127  loss_mask_0: 4.156  loss_ce_1: 1.112  loss_mask_1: 4.184  loss_ce_2: 1.518  loss_mask_2: 3.506  loss_ce_3: 1.678  loss_mask_3: 3.251  loss_ce_4: 1.758  loss_mask_4: 3.185  loss_ce_5: 1.794  loss_mask_5: 3.263  loss_ce_6: 1.763  loss_mask_6: 3.22  loss_ce_7: 1.785  loss_mask_7: 3.245  loss_ce_8: 1.823  loss_mask_8: 3.353  time: 2.4643  data_time: 0.4126  lr: 9.0924e-05  max_mem: 18446M
[01/24 05:44:26] d2.utils.events INFO:  eta: 1 day, 11:05:11  iter: 6039  total_loss: 50.21  loss_ce: 1.758  loss_mask: 3.277  loss_ce_0: 1.087  loss_mask_0: 4.092  loss_ce_1: 1.135  loss_mask_1: 4.05  loss_ce_2: 1.5  loss_mask_2: 3.487  loss_ce_3: 1.668  loss_mask_3: 3.23  loss_ce_4: 1.744  loss_mask_4: 3.187  loss_ce_5: 1.762  loss_mask_5: 3.278  loss_ce_6: 1.734  loss_mask_6: 3.24  loss_ce_7: 1.771  loss_mask_7: 3.295  loss_ce_8: 1.808  loss_mask_8: 3.23  time: 2.4638  data_time: 0.3751  lr: 9.0894e-05  max_mem: 18446M
[01/24 05:45:13] d2.utils.events INFO:  eta: 1 day, 11:04:11  iter: 6059  total_loss: 52.48  loss_ce: 1.779  loss_mask: 3.427  loss_ce_0: 1.097  loss_mask_0: 4.289  loss_ce_1: 1.129  loss_mask_1: 4.213  loss_ce_2: 1.512  loss_mask_2: 3.572  loss_ce_3: 1.671  loss_mask_3: 3.486  loss_ce_4: 1.752  loss_mask_4: 3.446  loss_ce_5: 1.778  loss_mask_5: 3.414  loss_ce_6: 1.742  loss_mask_6: 3.356  loss_ce_7: 1.81  loss_mask_7: 3.443  loss_ce_8: 1.787  loss_mask_8: 3.453  time: 2.4633  data_time: 0.4048  lr: 9.0864e-05  max_mem: 18446M
[01/24 05:46:03] d2.utils.events INFO:  eta: 1 day, 11:03:50  iter: 6079  total_loss: 50.55  loss_ce: 1.742  loss_mask: 3.38  loss_ce_0: 1.092  loss_mask_0: 4.346  loss_ce_1: 1.093  loss_mask_1: 3.97  loss_ce_2: 1.461  loss_mask_2: 3.521  loss_ce_3: 1.656  loss_mask_3: 3.306  loss_ce_4: 1.744  loss_mask_4: 3.229  loss_ce_5: 1.758  loss_mask_5: 3.289  loss_ce_6: 1.746  loss_mask_6: 3.281  loss_ce_7: 1.786  loss_mask_7: 3.329  loss_ce_8: 1.787  loss_mask_8: 3.318  time: 2.4634  data_time: 0.4339  lr: 9.0833e-05  max_mem: 18446M
[01/24 05:46:49] d2.utils.events INFO:  eta: 1 day, 10:59:45  iter: 6099  total_loss: 50.32  loss_ce: 1.76  loss_mask: 3.385  loss_ce_0: 1.077  loss_mask_0: 4.143  loss_ce_1: 1.094  loss_mask_1: 4.105  loss_ce_2: 1.459  loss_mask_2: 3.459  loss_ce_3: 1.654  loss_mask_3: 3.312  loss_ce_4: 1.769  loss_mask_4: 3.255  loss_ce_5: 1.771  loss_mask_5: 3.207  loss_ce_6: 1.759  loss_mask_6: 3.231  loss_ce_7: 1.796  loss_mask_7: 3.28  loss_ce_8: 1.799  loss_mask_8: 3.309  time: 2.4629  data_time: 0.3891  lr: 9.0803e-05  max_mem: 18446M
[01/24 05:47:35] d2.utils.events INFO:  eta: 1 day, 10:58:58  iter: 6119  total_loss: 49.83  loss_ce: 1.721  loss_mask: 3.263  loss_ce_0: 1.068  loss_mask_0: 4.176  loss_ce_1: 1.106  loss_mask_1: 4.021  loss_ce_2: 1.428  loss_mask_2: 3.388  loss_ce_3: 1.647  loss_mask_3: 3.227  loss_ce_4: 1.745  loss_mask_4: 3.262  loss_ce_5: 1.767  loss_mask_5: 3.252  loss_ce_6: 1.742  loss_mask_6: 3.207  loss_ce_7: 1.786  loss_mask_7: 3.277  loss_ce_8: 1.782  loss_mask_8: 3.367  time: 2.4624  data_time: 0.3823  lr: 9.0773e-05  max_mem: 18446M
[01/24 05:48:24] d2.utils.events INFO:  eta: 1 day, 10:58:18  iter: 6139  total_loss: 49.32  loss_ce: 1.711  loss_mask: 3.169  loss_ce_0: 1.047  loss_mask_0: 4.017  loss_ce_1: 1.107  loss_mask_1: 3.91  loss_ce_2: 1.444  loss_mask_2: 3.426  loss_ce_3: 1.635  loss_mask_3: 3.218  loss_ce_4: 1.735  loss_mask_4: 3.202  loss_ce_5: 1.753  loss_mask_5: 3.101  loss_ce_6: 1.727  loss_mask_6: 3.1  loss_ce_7: 1.777  loss_mask_7: 3.208  loss_ce_8: 1.782  loss_mask_8: 3.182  time: 2.4623  data_time: 0.4143  lr: 9.0743e-05  max_mem: 18446M
[01/24 05:49:09] d2.utils.events INFO:  eta: 1 day, 10:54:11  iter: 6159  total_loss: 48.01  loss_ce: 1.683  loss_mask: 3.163  loss_ce_0: 1.009  loss_mask_0: 3.7  loss_ce_1: 1.073  loss_mask_1: 3.564  loss_ce_2: 1.426  loss_mask_2: 3.393  loss_ce_3: 1.616  loss_mask_3: 3.125  loss_ce_4: 1.732  loss_mask_4: 3.129  loss_ce_5: 1.726  loss_mask_5: 3.116  loss_ce_6: 1.7  loss_mask_6: 3.158  loss_ce_7: 1.763  loss_mask_7: 3.128  loss_ce_8: 1.753  loss_mask_8: 3.185  time: 2.4616  data_time: 0.3665  lr: 9.0712e-05  max_mem: 18446M
[01/24 05:49:56] d2.utils.events INFO:  eta: 1 day, 10:54:58  iter: 6179  total_loss: 51.96  loss_ce: 1.739  loss_mask: 3.431  loss_ce_0: 1.012  loss_mask_0: 4.297  loss_ce_1: 1.051  loss_mask_1: 4.311  loss_ce_2: 1.425  loss_mask_2: 3.688  loss_ce_3: 1.622  loss_mask_3: 3.453  loss_ce_4: 1.762  loss_mask_4: 3.343  loss_ce_5: 1.762  loss_mask_5: 3.347  loss_ce_6: 1.76  loss_mask_6: 3.403  loss_ce_7: 1.808  loss_mask_7: 3.313  loss_ce_8: 1.815  loss_mask_8: 3.584  time: 2.4613  data_time: 0.3997  lr: 9.0682e-05  max_mem: 18446M
[01/24 05:50:46] d2.utils.events INFO:  eta: 1 day, 10:54:46  iter: 6199  total_loss: 50.73  loss_ce: 1.731  loss_mask: 3.348  loss_ce_0: 0.9865  loss_mask_0: 4.231  loss_ce_1: 0.9793  loss_mask_1: 4.08  loss_ce_2: 1.409  loss_mask_2: 3.682  loss_ce_3: 1.634  loss_mask_3: 3.358  loss_ce_4: 1.761  loss_mask_4: 3.214  loss_ce_5: 1.75  loss_mask_5: 3.224  loss_ce_6: 1.744  loss_mask_6: 3.261  loss_ce_7: 1.79  loss_mask_7: 3.336  loss_ce_8: 1.805  loss_mask_8: 3.337  time: 2.4613  data_time: 0.4499  lr: 9.0652e-05  max_mem: 18446M
[01/24 05:51:31] d2.utils.events INFO:  eta: 1 day, 10:51:03  iter: 6219  total_loss: 49.86  loss_ce: 1.762  loss_mask: 3.304  loss_ce_0: 0.9805  loss_mask_0: 3.98  loss_ce_1: 0.9608  loss_mask_1: 3.878  loss_ce_2: 1.418  loss_mask_2: 3.606  loss_ce_3: 1.625  loss_mask_3: 3.289  loss_ce_4: 1.782  loss_mask_4: 3.194  loss_ce_5: 1.766  loss_mask_5: 3.217  loss_ce_6: 1.746  loss_mask_6: 3.227  loss_ce_7: 1.802  loss_mask_7: 3.282  loss_ce_8: 1.811  loss_mask_8: 3.24  time: 2.4607  data_time: 0.3593  lr: 9.0621e-05  max_mem: 18446M
[01/24 05:52:17] d2.utils.events INFO:  eta: 1 day, 10:50:29  iter: 6239  total_loss: 50.78  loss_ce: 1.759  loss_mask: 3.367  loss_ce_0: 0.9762  loss_mask_0: 4.112  loss_ce_1: 0.9768  loss_mask_1: 3.986  loss_ce_2: 1.402  loss_mask_2: 3.594  loss_ce_3: 1.616  loss_mask_3: 3.328  loss_ce_4: 1.802  loss_mask_4: 3.335  loss_ce_5: 1.776  loss_mask_5: 3.283  loss_ce_6: 1.746  loss_mask_6: 3.32  loss_ce_7: 1.785  loss_mask_7: 3.305  loss_ce_8: 1.803  loss_mask_8: 3.373  time: 2.4602  data_time: 0.3764  lr: 9.0591e-05  max_mem: 18446M
[01/24 05:53:06] d2.utils.events INFO:  eta: 1 day, 10:48:44  iter: 6259  total_loss: 50.62  loss_ce: 1.718  loss_mask: 3.268  loss_ce_0: 0.9839  loss_mask_0: 4.097  loss_ce_1: 0.9722  loss_mask_1: 3.918  loss_ce_2: 1.377  loss_mask_2: 3.612  loss_ce_3: 1.601  loss_mask_3: 3.296  loss_ce_4: 1.78  loss_mask_4: 3.302  loss_ce_5: 1.777  loss_mask_5: 3.32  loss_ce_6: 1.734  loss_mask_6: 3.266  loss_ce_7: 1.749  loss_mask_7: 3.263  loss_ce_8: 1.772  loss_mask_8: 3.32  time: 2.4602  data_time: 0.3846  lr: 9.0561e-05  max_mem: 18446M
[01/24 05:53:52] d2.utils.events INFO:  eta: 1 day, 10:44:28  iter: 6279  total_loss: 50.83  loss_ce: 1.742  loss_mask: 3.282  loss_ce_0: 0.9541  loss_mask_0: 4.148  loss_ce_1: 0.9376  loss_mask_1: 4.005  loss_ce_2: 1.368  loss_mask_2: 3.705  loss_ce_3: 1.615  loss_mask_3: 3.369  loss_ce_4: 1.803  loss_mask_4: 3.29  loss_ce_5: 1.811  loss_mask_5: 3.273  loss_ce_6: 1.759  loss_mask_6: 3.343  loss_ce_7: 1.793  loss_mask_7: 3.319  loss_ce_8: 1.817  loss_mask_8: 3.381  time: 2.4597  data_time: 0.3470  lr: 9.053e-05  max_mem: 18446M
[01/24 05:54:40] d2.utils.events INFO:  eta: 1 day, 10:43:34  iter: 6299  total_loss: 49.83  loss_ce: 1.738  loss_mask: 3.27  loss_ce_0: 0.9961  loss_mask_0: 4.088  loss_ce_1: 0.9381  loss_mask_1: 3.93  loss_ce_2: 1.381  loss_mask_2: 3.531  loss_ce_3: 1.624  loss_mask_3: 3.265  loss_ce_4: 1.754  loss_mask_4: 3.292  loss_ce_5: 1.781  loss_mask_5: 3.324  loss_ce_6: 1.73  loss_mask_6: 3.161  loss_ce_7: 1.752  loss_mask_7: 3.186  loss_ce_8: 1.767  loss_mask_8: 3.186  time: 2.4594  data_time: 0.4074  lr: 9.05e-05  max_mem: 18446M
[01/24 05:55:29] d2.utils.events INFO:  eta: 1 day, 10:39:41  iter: 6319  total_loss: 53.14  loss_ce: 1.809  loss_mask: 3.474  loss_ce_0: 0.9943  loss_mask_0: 4.444  loss_ce_1: 0.997  loss_mask_1: 4.3  loss_ce_2: 1.429  loss_mask_2: 3.706  loss_ce_3: 1.691  loss_mask_3: 3.504  loss_ce_4: 1.888  loss_mask_4: 3.588  loss_ce_5: 1.866  loss_mask_5: 3.577  loss_ce_6: 1.893  loss_mask_6: 3.608  loss_ce_7: 1.9  loss_mask_7: 3.699  loss_ce_8: 1.846  loss_mask_8: 3.514  time: 2.4594  data_time: 0.3772  lr: 9.047e-05  max_mem: 18446M
[01/24 05:56:15] d2.utils.events INFO:  eta: 1 day, 10:38:25  iter: 6339  total_loss: 52.03  loss_ce: 1.73  loss_mask: 3.483  loss_ce_0: 1.05  loss_mask_0: 4.158  loss_ce_1: 1.007  loss_mask_1: 4.074  loss_ce_2: 1.364  loss_mask_2: 3.588  loss_ce_3: 1.617  loss_mask_3: 3.405  loss_ce_4: 1.778  loss_mask_4: 3.436  loss_ce_5: 1.795  loss_mask_5: 3.538  loss_ce_6: 1.789  loss_mask_6: 3.397  loss_ce_7: 1.799  loss_mask_7: 3.514  loss_ce_8: 1.797  loss_mask_8: 3.368  time: 2.4588  data_time: 0.3513  lr: 9.0439e-05  max_mem: 18446M
[01/24 05:57:03] d2.utils.events INFO:  eta: 1 day, 10:40:22  iter: 6359  total_loss: 50.03  loss_ce: 1.735  loss_mask: 3.26  loss_ce_0: 1.045  loss_mask_0: 4.023  loss_ce_1: 1.017  loss_mask_1: 3.945  loss_ce_2: 1.377  loss_mask_2: 3.507  loss_ce_3: 1.617  loss_mask_3: 3.324  loss_ce_4: 1.782  loss_mask_4: 3.248  loss_ce_5: 1.796  loss_mask_5: 3.285  loss_ce_6: 1.754  loss_mask_6: 3.263  loss_ce_7: 1.771  loss_mask_7: 3.278  loss_ce_8: 1.763  loss_mask_8: 3.243  time: 2.4587  data_time: 0.3877  lr: 9.0409e-05  max_mem: 18446M
[01/24 05:57:50] d2.utils.events INFO:  eta: 1 day, 10:35:34  iter: 6379  total_loss: 47.81  loss_ce: 1.699  loss_mask: 3.05  loss_ce_0: 1.083  loss_mask_0: 3.901  loss_ce_1: 1.019  loss_mask_1: 3.794  loss_ce_2: 1.356  loss_mask_2: 3.356  loss_ce_3: 1.578  loss_mask_3: 3.107  loss_ce_4: 1.71  loss_mask_4: 3.058  loss_ce_5: 1.721  loss_mask_5: 3.079  loss_ce_6: 1.762  loss_mask_6: 3.198  loss_ce_7: 1.734  loss_mask_7: 3.232  loss_ce_8: 1.734  loss_mask_8: 3.05  time: 2.4583  data_time: 0.3527  lr: 9.0379e-05  max_mem: 18446M
[01/24 05:58:35] d2.utils.events INFO:  eta: 1 day, 10:34:16  iter: 6399  total_loss: 51.37  loss_ce: 1.741  loss_mask: 3.464  loss_ce_0: 0.9638  loss_mask_0: 4.051  loss_ce_1: 0.9267  loss_mask_1: 4.105  loss_ce_2: 1.356  loss_mask_2: 3.732  loss_ce_3: 1.576  loss_mask_3: 3.377  loss_ce_4: 1.754  loss_mask_4: 3.312  loss_ce_5: 1.74  loss_mask_5: 3.407  loss_ce_6: 1.786  loss_mask_6: 3.367  loss_ce_7: 1.77  loss_mask_7: 3.385  loss_ce_8: 1.794  loss_mask_8: 3.426  time: 2.4577  data_time: 0.3531  lr: 9.0348e-05  max_mem: 18446M
[01/24 05:59:25] d2.utils.events INFO:  eta: 1 day, 10:35:40  iter: 6419  total_loss: 49.57  loss_ce: 1.73  loss_mask: 3.217  loss_ce_0: 0.9693  loss_mask_0: 4.012  loss_ce_1: 0.9088  loss_mask_1: 3.923  loss_ce_2: 1.332  loss_mask_2: 3.582  loss_ce_3: 1.574  loss_mask_3: 3.283  loss_ce_4: 1.754  loss_mask_4: 3.202  loss_ce_5: 1.748  loss_mask_5: 3.257  loss_ce_6: 1.766  loss_mask_6: 3.285  loss_ce_7: 1.795  loss_mask_7: 3.329  loss_ce_8: 1.769  loss_mask_8: 3.259  time: 2.4578  data_time: 0.4260  lr: 9.0318e-05  max_mem: 18446M
[01/24 06:00:11] d2.utils.events INFO:  eta: 1 day, 10:30:53  iter: 6439  total_loss: 48.83  loss_ce: 1.706  loss_mask: 3.127  loss_ce_0: 0.9736  loss_mask_0: 3.979  loss_ce_1: 0.9096  loss_mask_1: 3.929  loss_ce_2: 1.355  loss_mask_2: 3.544  loss_ce_3: 1.609  loss_mask_3: 3.249  loss_ce_4: 1.795  loss_mask_4: 3.119  loss_ce_5: 1.75  loss_mask_5: 3.172  loss_ce_6: 1.747  loss_mask_6: 3.144  loss_ce_7: 1.791  loss_mask_7: 3.219  loss_ce_8: 1.748  loss_mask_8: 3.11  time: 2.4573  data_time: 0.3748  lr: 9.0288e-05  max_mem: 18446M
[01/24 06:00:58] d2.utils.events INFO:  eta: 1 day, 10:29:33  iter: 6459  total_loss: 50.06  loss_ce: 1.711  loss_mask: 3.229  loss_ce_0: 0.9631  loss_mask_0: 4.097  loss_ce_1: 0.9263  loss_mask_1: 4.003  loss_ce_2: 1.367  loss_mask_2: 3.737  loss_ce_3: 1.592  loss_mask_3: 3.3  loss_ce_4: 1.783  loss_mask_4: 3.304  loss_ce_5: 1.77  loss_mask_5: 3.272  loss_ce_6: 1.735  loss_mask_6: 3.285  loss_ce_7: 1.812  loss_mask_7: 3.149  loss_ce_8: 1.756  loss_mask_8: 3.194  time: 2.4569  data_time: 0.3462  lr: 9.0257e-05  max_mem: 18446M
[01/24 06:01:47] d2.utils.events INFO:  eta: 1 day, 10:31:33  iter: 6479  total_loss: 49.13  loss_ce: 1.733  loss_mask: 3.213  loss_ce_0: 0.935  loss_mask_0: 3.799  loss_ce_1: 0.9052  loss_mask_1: 3.885  loss_ce_2: 1.39  loss_mask_2: 3.456  loss_ce_3: 1.583  loss_mask_3: 3.301  loss_ce_4: 1.741  loss_mask_4: 3.175  loss_ce_5: 1.765  loss_mask_5: 3.242  loss_ce_6: 1.715  loss_mask_6: 3.169  loss_ce_7: 1.792  loss_mask_7: 3.158  loss_ce_8: 1.777  loss_mask_8: 3.167  time: 2.4570  data_time: 0.4262  lr: 9.0227e-05  max_mem: 18446M
[01/24 06:02:33] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 06:02:34] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 06:02:34] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 06:06:51] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 7.904613729403086, 'error_1pix': 0.75174104012395, 'error_3pix': 0.5826181317763368, 'mIoU': 0.994980808055858, 'fwIoU': 9.609708602030762, 'IoU-0': nan, 'IoU-1': 79.17278462770683, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.00011844666549259006, 'IoU-11': 0.0, 'IoU-12': 8.927923963223897, 'IoU-13': 8.28471710481745, 'IoU-14': 6.349912474794982, 'IoU-15': 1.6632726826221733, 'IoU-16': 0.00016415702350061357, 'IoU-17': 1.5626580726306594e-05, 'IoU-18': 0.23910424436760103, 'IoU-19': 0.00522175190590928, 'IoU-20': 4.617281963095912e-05, 'IoU-21': 8.97867913873038e-06, 'IoU-22': 0.09685444205211194, 'IoU-23': 0.00030783279010497403, 'IoU-24': 4.7941931264121775, 'IoU-25': 1.890376365803153, 'IoU-26': 1.6453637371085204, 'IoU-27': 3.0773895349310996, 'IoU-28': 0.00676426871948736, 'IoU-29': 4.628400743968738, 'IoU-30': 5.586997251383723, 'IoU-31': 5.192752543343659, 'IoU-32': 1.6234835803971952, 'IoU-33': 2.8406261252254636, 'IoU-34': 4.231138786736225, 'IoU-35': 0.0016383156739905938, 'IoU-36': 0.5921956774423784, 'IoU-37': 3.6018613298256903, 'IoU-38': 0.11028167397804062, 'IoU-39': 5.348862149927002e-05, 'IoU-40': 4.786896697210173, 'IoU-41': 3.385822841966245e-05, 'IoU-42': 4.552001342129258, 'IoU-43': 0.13385379178714005, 'IoU-44': 0.5007045804782112, 'IoU-45': 0.0, 'IoU-46': 0.00020145127968636422, 'IoU-47': 2.389686940378315, 'IoU-48': 0.0003005628215635437, 'IoU-49': 0.0, 'IoU-50': 0.4000982498616144, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.18390217987876975, 'IoU-54': 0.2157914728960398, 'IoU-55': 5.91735724198133e-06, 'IoU-56': 3.3624145366994393, 'IoU-57': 0.00017486051150326354, 'IoU-58': 1.8075443509285343, 'IoU-59': 0.0002605210495425436, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 1.7524905080732857e-05, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.727863489502396, 'IoU-67': 0.0, 'IoU-68': 0.09404657512490264, 'IoU-69': 3.1771913247426315e-05, 'IoU-70': 0.9443902026461748, 'IoU-71': 0.0, 'IoU-72': 1.6229950197389238, 'IoU-73': 2.5531045621875035, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 1.7776318094029033, 'IoU-77': 2.231090548332452, 'IoU-78': 0.00045432343041227745, 'IoU-79': 2.2110292021758684, 'IoU-80': 0.003896842863774409, 'IoU-81': 0.0171140118963844, 'IoU-82': 0.0005511108031888846, 'IoU-83': 1.1644160993653565, 'IoU-84': 0.0, 'IoU-85': 0.3000427256388939, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.01296184566653784, 'IoU-89': 1.690276481544704, 'IoU-90': 0.00018236679798812948, 'IoU-91': 0.0002993629420519071, 'IoU-92': 3.137530740473486, 'IoU-93': 1.4864188027000504, 'IoU-94': 0.08703396994759678, 'IoU-95': 0.0038502189694654162, 'IoU-96': 0.0001498716349446699, 'IoU-97': 0.0014206911165896155, 'IoU-98': 1.4817288822923005, 'IoU-99': 0.014255589836091497, 'IoU-100': 0.0, 'IoU-101': 0.010289987080349554, 'IoU-102': 1.4139843145143742, 'IoU-103': 0.043566377007862166, 'IoU-104': 1.3393880616069047, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.001808280610081, 'IoU-109': 0.0007644409261286757, 'IoU-110': 0.00207367808281549, 'IoU-111': 0.00015658371905122792, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.911902230310866, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.29181222160872744, 'IoU-118': 0.22795674474719763, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.21303203447499913, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0003656028638891005, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.5942589937602467, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.6999880983493765, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.00024814552577074, 'IoU-141': 8.02292631423556e-05, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.7272367858750722, 'IoU-150': 0.004178450212816066, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.07880907266690682, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.011789800552850956, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.7542985571186756, 'pACC': 14.989540293232423, 'ACC-0': nan, 'ACC-1': 96.71940341661403, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.00011844928687295129, 'ACC-11': 0.0, 'ACC-12': 28.992148998513844, 'ACC-13': 17.547421381105337, 'ACC-14': 42.24754415048256, 'ACC-15': 3.2147911135310023, 'ACC-16': 0.00016418974519049175, 'ACC-17': 1.5626599284770553e-05, 'ACC-18': 0.2530074614024607, 'ACC-19': 0.005233779410983027, 'ACC-20': 4.618754458637638e-05, 'ACC-21': 8.979294823652037e-06, 'ACC-22': 0.09933501261381737, 'ACC-23': 0.00030784202254525246, 'ACC-24': 12.570280785142373, 'ACC-25': 2.808086103192886, 'ACC-26': 2.2157790984002257, 'ACC-27': 4.908413258684648, 'ACC-28': 0.006769631737509129, 'ACC-29': 9.863862862707485, 'ACC-30': 16.67769582014813, 'ACC-31': 18.929176670146823, 'ACC-32': 2.1366417346818958, 'ACC-33': 4.653956323915927, 'ACC-34': 9.790901821529378, 'ACC-35': 0.001638512848033922, 'ACC-36': 0.6321187968352353, 'ACC-37': 6.763542234693447, 'ACC-38': 0.11474299494446906, 'ACC-39': 5.349093585690889e-05, 'ACC-40': 19.600339866783013, 'ACC-41': 3.386071509970169e-05, 'ACC-42': 47.62352055649584, 'ACC-43': 0.1404079432173181, 'ACC-44': 0.5499016820176181, 'ACC-45': 0.0, 'ACC-46': 0.00020164567562618182, 'ACC-47': 5.52355259156274, 'ACC-48': 0.0003008322967891107, 'ACC-49': 0.0, 'ACC-50': 0.4355686297151909, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.19106996076241878, 'ACC-54': 0.22632360348539357, 'ACC-55': 5.917419569545597e-06, 'ACC-56': 27.028150742348505, 'ACC-57': 0.00017493321114788452, 'ACC-58': 3.026611774634573, 'ACC-59': 0.0002605876385265273, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 1.752512928287872e-05, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.9378049583181898, 'ACC-67': 0.0, 'ACC-68': 0.09607044274062458, 'ACC-69': 3.177616361927961e-05, 'ACC-70': 1.2582185737118323, 'ACC-71': 0.0, 'ACC-72': 9.300116174750345, 'ACC-73': 23.53444248551094, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 3.9609897486146286, 'ACC-77': 6.1638559940650675, 'ACC-78': 0.0004547700161476632, 'ACC-79': 25.682533328477092, 'ACC-80': 0.003914530105445719, 'ACC-81': 0.01722959235116901, 'ACC-82': 0.0005513064951330888, 'ACC-83': 1.793940821221494, 'ACC-84': 0.0, 'ACC-85': 0.3244265886765238, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.012995752123498355, 'ACC-89': 13.45428807808496, 'ACC-90': 0.00018237487520347825, 'ACC-91': 0.0002993685229238725, 'ACC-92': 15.150704617300583, 'ACC-93': 2.364424047398382, 'ACC-94': 0.0911991456048033, 'ACC-95': 0.0038719547705315907, 'ACC-96': 0.00014987837369974266, 'ACC-97': 0.001421031158419464, 'ACC-98': 2.7567523752080403, 'ACC-99': 0.01428949396292985, 'ACC-100': 0.0, 'ACC-101': 0.01044584410158003, 'ACC-102': 12.05783869506117, 'ACC-103': 0.04375649381316709, 'ACC-104': 2.4641548412483707, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0018239970020122002, 'ACC-109': 0.0007654330437444984, 'ACC-110': 0.0020775817189670263, 'ACC-111': 0.00015669653616038956, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 13.449395170621543, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.32555751020431123, 'ACC-118': 0.30138174587279576, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.2733958186265925, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.00036590229676871684, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 1.1767583851909937, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 4.899521121942876, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.000248473132600172, 'ACC-141': 8.415539124682945e-05, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 1.2908832951852254, 'ACC-150': 0.004586156686043178, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.08552665933715428, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.011790399349895519, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 06:06:51] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 06:06:51] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 06:06:51] d2.evaluation.testing INFO: copypaste: 7.9046,0.7517,0.5826,0.9950,9.6097,2.7543,14.9895
[01/24 06:06:51] d2.utils.events INFO:  eta: 1 day, 10:27:55  iter: 6499  total_loss: 50.58  loss_ce: 1.776  loss_mask: 3.443  loss_ce_0: 0.9771  loss_mask_0: 4.234  loss_ce_1: 0.8871  loss_mask_1: 4.042  loss_ce_2: 1.363  loss_mask_2: 3.66  loss_ce_3: 1.583  loss_mask_3: 3.334  loss_ce_4: 1.769  loss_mask_4: 3.252  loss_ce_5: 1.789  loss_mask_5: 3.32  loss_ce_6: 1.742  loss_mask_6: 3.33  loss_ce_7: 1.84  loss_mask_7: 3.38  loss_ce_8: 1.815  loss_mask_8: 3.275  time: 2.4565  data_time: 0.3385  lr: 9.0196e-05  max_mem: 18446M
[01/24 06:07:38] d2.utils.events INFO:  eta: 1 day, 10:24:04  iter: 6519  total_loss: 50.84  loss_ce: 1.76  loss_mask: 3.18  loss_ce_0: 1.008  loss_mask_0: 4.163  loss_ce_1: 0.9444  loss_mask_1: 4.153  loss_ce_2: 1.388  loss_mask_2: 3.585  loss_ce_3: 1.614  loss_mask_3: 3.315  loss_ce_4: 1.803  loss_mask_4: 3.349  loss_ce_5: 1.828  loss_mask_5: 3.268  loss_ce_6: 1.776  loss_mask_6: 3.278  loss_ce_7: 1.868  loss_mask_7: 3.39  loss_ce_8: 1.819  loss_mask_8: 3.223  time: 2.4561  data_time: 0.4033  lr: 9.0166e-05  max_mem: 18446M
[01/24 06:08:26] d2.utils.events INFO:  eta: 1 day, 10:23:59  iter: 6539  total_loss: 49.3  loss_ce: 1.736  loss_mask: 3.078  loss_ce_0: 0.9905  loss_mask_0: 4.116  loss_ce_1: 0.8525  loss_mask_1: 3.779  loss_ce_2: 1.286  loss_mask_2: 3.607  loss_ce_3: 1.58  loss_mask_3: 3.229  loss_ce_4: 1.762  loss_mask_4: 3.126  loss_ce_5: 1.783  loss_mask_5: 3.257  loss_ce_6: 1.734  loss_mask_6: 3.161  loss_ce_7: 1.819  loss_mask_7: 3.199  loss_ce_8: 1.786  loss_mask_8: 3.134  time: 2.4559  data_time: 0.4288  lr: 9.0136e-05  max_mem: 18446M
[01/24 06:09:13] d2.utils.events INFO:  eta: 1 day, 10:25:18  iter: 6559  total_loss: 49.37  loss_ce: 1.722  loss_mask: 3.192  loss_ce_0: 0.995  loss_mask_0: 3.944  loss_ce_1: 0.9477  loss_mask_1: 3.939  loss_ce_2: 1.395  loss_mask_2: 3.538  loss_ce_3: 1.602  loss_mask_3: 3.268  loss_ce_4: 1.748  loss_mask_4: 3.214  loss_ce_5: 1.777  loss_mask_5: 3.257  loss_ce_6: 1.748  loss_mask_6: 3.179  loss_ce_7: 1.806  loss_mask_7: 3.265  loss_ce_8: 1.78  loss_mask_8: 3.199  time: 2.4556  data_time: 0.3798  lr: 9.0105e-05  max_mem: 18446M
[01/24 06:10:00] d2.utils.events INFO:  eta: 1 day, 10:22:26  iter: 6579  total_loss: 50.23  loss_ce: 1.711  loss_mask: 3.326  loss_ce_0: 0.9691  loss_mask_0: 4.038  loss_ce_1: 0.8896  loss_mask_1: 3.859  loss_ce_2: 1.363  loss_mask_2: 3.611  loss_ce_3: 1.565  loss_mask_3: 3.351  loss_ce_4: 1.768  loss_mask_4: 3.29  loss_ce_5: 1.803  loss_mask_5: 3.25  loss_ce_6: 1.738  loss_mask_6: 3.268  loss_ce_7: 1.81  loss_mask_7: 3.376  loss_ce_8: 1.794  loss_mask_8: 3.321  time: 2.4552  data_time: 0.3804  lr: 9.0075e-05  max_mem: 18446M
[01/24 06:10:48] d2.utils.events INFO:  eta: 1 day, 10:22:16  iter: 6599  total_loss: 49.28  loss_ce: 1.682  loss_mask: 3.268  loss_ce_0: 1.041  loss_mask_0: 3.965  loss_ce_1: 0.8893  loss_mask_1: 3.907  loss_ce_2: 1.35  loss_mask_2: 3.508  loss_ce_3: 1.554  loss_mask_3: 3.298  loss_ce_4: 1.736  loss_mask_4: 3.304  loss_ce_5: 1.779  loss_mask_5: 3.301  loss_ce_6: 1.712  loss_mask_6: 3.354  loss_ce_7: 1.804  loss_mask_7: 3.35  loss_ce_8: 1.753  loss_mask_8: 3.236  time: 2.4550  data_time: 0.4034  lr: 9.0045e-05  max_mem: 18446M
[01/24 06:11:35] d2.utils.events INFO:  eta: 1 day, 10:23:17  iter: 6619  total_loss: 48.75  loss_ce: 1.711  loss_mask: 3.184  loss_ce_0: 0.9354  loss_mask_0: 3.818  loss_ce_1: 0.929  loss_mask_1: 3.68  loss_ce_2: 1.353  loss_mask_2: 3.438  loss_ce_3: 1.572  loss_mask_3: 3.183  loss_ce_4: 1.74  loss_mask_4: 3.187  loss_ce_5: 1.771  loss_mask_5: 3.154  loss_ce_6: 1.747  loss_mask_6: 3.133  loss_ce_7: 1.81  loss_mask_7: 3.179  loss_ce_8: 1.781  loss_mask_8: 3.175  time: 2.4547  data_time: 0.4151  lr: 9.0014e-05  max_mem: 18446M
[01/24 06:12:22] d2.utils.events INFO:  eta: 1 day, 10:20:03  iter: 6639  total_loss: 49.89  loss_ce: 1.753  loss_mask: 3.184  loss_ce_0: 0.9227  loss_mask_0: 4.112  loss_ce_1: 0.9179  loss_mask_1: 3.871  loss_ce_2: 1.363  loss_mask_2: 3.496  loss_ce_3: 1.601  loss_mask_3: 3.368  loss_ce_4: 1.785  loss_mask_4: 3.354  loss_ce_5: 1.815  loss_mask_5: 3.254  loss_ce_6: 1.778  loss_mask_6: 3.146  loss_ce_7: 1.832  loss_mask_7: 3.24  loss_ce_8: 1.781  loss_mask_8: 3.297  time: 2.4544  data_time: 0.3844  lr: 8.9984e-05  max_mem: 18446M
[01/24 06:13:10] d2.utils.events INFO:  eta: 1 day, 10:21:26  iter: 6659  total_loss: 48.76  loss_ce: 1.7  loss_mask: 3.023  loss_ce_0: 0.935  loss_mask_0: 3.975  loss_ce_1: 0.892  loss_mask_1: 3.897  loss_ce_2: 1.338  loss_mask_2: 3.643  loss_ce_3: 1.601  loss_mask_3: 3.394  loss_ce_4: 1.764  loss_mask_4: 3.275  loss_ce_5: 1.814  loss_mask_5: 3.15  loss_ce_6: 1.779  loss_mask_6: 3.058  loss_ce_7: 1.818  loss_mask_7: 3.124  loss_ce_8: 1.788  loss_mask_8: 3.143  time: 2.4542  data_time: 0.4267  lr: 8.9954e-05  max_mem: 18446M
[01/24 06:13:57] d2.utils.events INFO:  eta: 1 day, 10:20:40  iter: 6679  total_loss: 51.6  loss_ce: 1.739  loss_mask: 3.274  loss_ce_0: 1.042  loss_mask_0: 4.2  loss_ce_1: 0.983  loss_mask_1: 3.995  loss_ce_2: 1.443  loss_mask_2: 3.679  loss_ce_3: 1.634  loss_mask_3: 3.462  loss_ce_4: 1.793  loss_mask_4: 3.365  loss_ce_5: 1.829  loss_mask_5: 3.321  loss_ce_6: 1.824  loss_mask_6: 3.427  loss_ce_7: 1.813  loss_mask_7: 3.494  loss_ce_8: 1.824  loss_mask_8: 3.389  time: 2.4540  data_time: 0.3794  lr: 8.9923e-05  max_mem: 18446M
[01/24 06:14:43] d2.utils.events INFO:  eta: 1 day, 10:18:24  iter: 6699  total_loss: 51.07  loss_ce: 1.791  loss_mask: 3.43  loss_ce_0: 1.031  loss_mask_0: 4.279  loss_ce_1: 0.9693  loss_mask_1: 4.081  loss_ce_2: 1.353  loss_mask_2: 3.648  loss_ce_3: 1.58  loss_mask_3: 3.302  loss_ce_4: 1.77  loss_mask_4: 3.337  loss_ce_5: 1.811  loss_mask_5: 3.477  loss_ce_6: 1.757  loss_mask_6: 3.32  loss_ce_7: 1.806  loss_mask_7: 3.283  loss_ce_8: 1.76  loss_mask_8: 3.359  time: 2.4535  data_time: 0.3585  lr: 8.9893e-05  max_mem: 18446M
[01/24 06:15:34] d2.utils.events INFO:  eta: 1 day, 10:22:02  iter: 6719  total_loss: 51.14  loss_ce: 1.799  loss_mask: 3.378  loss_ce_0: 0.9552  loss_mask_0: 4.372  loss_ce_1: 0.8885  loss_mask_1: 4.213  loss_ce_2: 1.307  loss_mask_2: 3.66  loss_ce_3: 1.545  loss_mask_3: 3.395  loss_ce_4: 1.742  loss_mask_4: 3.374  loss_ce_5: 1.81  loss_mask_5: 3.339  loss_ce_6: 1.751  loss_mask_6: 3.302  loss_ce_7: 1.799  loss_mask_7: 3.324  loss_ce_8: 1.809  loss_mask_8: 3.365  time: 2.4537  data_time: 0.4076  lr: 8.9863e-05  max_mem: 18446M
[01/24 06:16:20] d2.utils.events INFO:  eta: 1 day, 10:21:29  iter: 6739  total_loss: 47.54  loss_ce: 1.732  loss_mask: 3.118  loss_ce_0: 0.9332  loss_mask_0: 3.687  loss_ce_1: 0.934  loss_mask_1: 3.75  loss_ce_2: 1.31  loss_mask_2: 3.558  loss_ce_3: 1.556  loss_mask_3: 3.224  loss_ce_4: 1.732  loss_mask_4: 3.005  loss_ce_5: 1.772  loss_mask_5: 3.196  loss_ce_6: 1.723  loss_mask_6: 3.126  loss_ce_7: 1.785  loss_mask_7: 3.124  loss_ce_8: 1.764  loss_mask_8: 3.047  time: 2.4533  data_time: 0.3726  lr: 8.9832e-05  max_mem: 18446M
[01/24 06:17:07] d2.utils.events INFO:  eta: 1 day, 10:22:30  iter: 6759  total_loss: 50.42  loss_ce: 1.72  loss_mask: 3.273  loss_ce_0: 0.9703  loss_mask_0: 3.831  loss_ce_1: 1.014  loss_mask_1: 3.907  loss_ce_2: 1.366  loss_mask_2: 3.637  loss_ce_3: 1.6  loss_mask_3: 3.362  loss_ce_4: 1.762  loss_mask_4: 3.324  loss_ce_5: 1.806  loss_mask_5: 3.292  loss_ce_6: 1.749  loss_mask_6: 3.329  loss_ce_7: 1.831  loss_mask_7: 3.228  loss_ce_8: 1.743  loss_mask_8: 3.176  time: 2.4529  data_time: 0.3869  lr: 8.9802e-05  max_mem: 18446M
[01/24 06:17:56] d2.utils.events INFO:  eta: 1 day, 10:26:33  iter: 6779  total_loss: 48.8  loss_ce: 1.709  loss_mask: 3.038  loss_ce_0: 0.9449  loss_mask_0: 3.922  loss_ce_1: 0.9958  loss_mask_1: 4.058  loss_ce_2: 1.363  loss_mask_2: 3.58  loss_ce_3: 1.579  loss_mask_3: 3.228  loss_ce_4: 1.749  loss_mask_4: 3.058  loss_ce_5: 1.761  loss_mask_5: 3.145  loss_ce_6: 1.733  loss_mask_6: 3.071  loss_ce_7: 1.81  loss_mask_7: 3.066  loss_ce_8: 1.75  loss_mask_8: 3.111  time: 2.4530  data_time: 0.4205  lr: 8.9772e-05  max_mem: 18446M
[01/24 06:18:42] d2.utils.events INFO:  eta: 1 day, 10:26:37  iter: 6799  total_loss: 49.87  loss_ce: 1.695  loss_mask: 3.38  loss_ce_0: 0.9712  loss_mask_0: 4.165  loss_ce_1: 0.9794  loss_mask_1: 3.938  loss_ce_2: 1.345  loss_mask_2: 3.65  loss_ce_3: 1.549  loss_mask_3: 3.374  loss_ce_4: 1.735  loss_mask_4: 3.31  loss_ce_5: 1.749  loss_mask_5: 3.303  loss_ce_6: 1.719  loss_mask_6: 3.261  loss_ce_7: 1.825  loss_mask_7: 3.244  loss_ce_8: 1.736  loss_mask_8: 3.21  time: 2.4525  data_time: 0.3555  lr: 8.9741e-05  max_mem: 18446M
[01/24 06:19:28] d2.utils.events INFO:  eta: 1 day, 10:26:15  iter: 6819  total_loss: 48.66  loss_ce: 1.735  loss_mask: 3.2  loss_ce_0: 0.9298  loss_mask_0: 3.762  loss_ce_1: 1.063  loss_mask_1: 4.021  loss_ce_2: 1.383  loss_mask_2: 3.514  loss_ce_3: 1.596  loss_mask_3: 3.246  loss_ce_4: 1.783  loss_mask_4: 3.096  loss_ce_5: 1.808  loss_mask_5: 3.17  loss_ce_6: 1.739  loss_mask_6: 3.126  loss_ce_7: 1.847  loss_mask_7: 3.097  loss_ce_8: 1.783  loss_mask_8: 3.158  time: 2.4520  data_time: 0.3869  lr: 8.9711e-05  max_mem: 18446M
[01/24 06:20:17] d2.utils.events INFO:  eta: 1 day, 10:28:01  iter: 6839  total_loss: 49.37  loss_ce: 1.732  loss_mask: 3.228  loss_ce_0: 0.9232  loss_mask_0: 3.948  loss_ce_1: 1.02  loss_mask_1: 3.892  loss_ce_2: 1.342  loss_mask_2: 3.547  loss_ce_3: 1.568  loss_mask_3: 3.297  loss_ce_4: 1.756  loss_mask_4: 3.187  loss_ce_5: 1.79  loss_mask_5: 3.182  loss_ce_6: 1.754  loss_mask_6: 3.172  loss_ce_7: 1.823  loss_mask_7: 3.201  loss_ce_8: 1.785  loss_mask_8: 3.262  time: 2.4521  data_time: 0.4147  lr: 8.968e-05  max_mem: 18446M
[01/24 06:21:03] d2.utils.events INFO:  eta: 1 day, 10:30:00  iter: 6859  total_loss: 48.11  loss_ce: 1.683  loss_mask: 3.061  loss_ce_0: 0.9509  loss_mask_0: 3.828  loss_ce_1: 0.9777  loss_mask_1: 3.997  loss_ce_2: 1.319  loss_mask_2: 3.498  loss_ce_3: 1.535  loss_mask_3: 3.232  loss_ce_4: 1.732  loss_mask_4: 3.163  loss_ce_5: 1.75  loss_mask_5: 3.116  loss_ce_6: 1.755  loss_mask_6: 3.118  loss_ce_7: 1.833  loss_mask_7: 3.106  loss_ce_8: 1.743  loss_mask_8: 3.114  time: 2.4516  data_time: 0.3504  lr: 8.965e-05  max_mem: 18446M
[01/24 06:21:49] d2.utils.events INFO:  eta: 1 day, 10:29:46  iter: 6879  total_loss: 49.56  loss_ce: 1.68  loss_mask: 3.141  loss_ce_0: 0.9356  loss_mask_0: 4.029  loss_ce_1: 1.056  loss_mask_1: 4.105  loss_ce_2: 1.348  loss_mask_2: 3.632  loss_ce_3: 1.521  loss_mask_3: 3.341  loss_ce_4: 1.72  loss_mask_4: 3.208  loss_ce_5: 1.737  loss_mask_5: 3.294  loss_ce_6: 1.724  loss_mask_6: 3.233  loss_ce_7: 1.792  loss_mask_7: 3.178  loss_ce_8: 1.77  loss_mask_8: 3.264  time: 2.4511  data_time: 0.3745  lr: 8.962e-05  max_mem: 18446M
[01/24 06:22:40] d2.utils.events INFO:  eta: 1 day, 10:32:59  iter: 6899  total_loss: 50.59  loss_ce: 1.73  loss_mask: 3.213  loss_ce_0: 0.9446  loss_mask_0: 4.014  loss_ce_1: 1.138  loss_mask_1: 4.124  loss_ce_2: 1.305  loss_mask_2: 3.571  loss_ce_3: 1.527  loss_mask_3: 3.3  loss_ce_4: 1.709  loss_mask_4: 3.244  loss_ce_5: 1.755  loss_mask_5: 3.179  loss_ce_6: 1.752  loss_mask_6: 3.183  loss_ce_7: 1.843  loss_mask_7: 3.281  loss_ce_8: 1.814  loss_mask_8: 3.279  time: 2.4514  data_time: 0.4406  lr: 8.9589e-05  max_mem: 18446M
[01/24 06:23:26] d2.utils.events INFO:  eta: 1 day, 10:32:34  iter: 6919  total_loss: 51.26  loss_ce: 1.688  loss_mask: 3.175  loss_ce_0: 0.9772  loss_mask_0: 3.999  loss_ce_1: 1.09  loss_mask_1: 4.143  loss_ce_2: 1.361  loss_mask_2: 3.841  loss_ce_3: 1.528  loss_mask_3: 3.393  loss_ce_4: 1.728  loss_mask_4: 3.396  loss_ce_5: 1.753  loss_mask_5: 3.376  loss_ce_6: 1.736  loss_mask_6: 3.227  loss_ce_7: 1.814  loss_mask_7: 3.188  loss_ce_8: 1.78  loss_mask_8: 3.404  time: 2.4510  data_time: 0.3619  lr: 8.9559e-05  max_mem: 18446M
[01/24 06:24:12] d2.utils.events INFO:  eta: 1 day, 10:27:56  iter: 6939  total_loss: 49.81  loss_ce: 1.713  loss_mask: 3.257  loss_ce_0: 0.928  loss_mask_0: 4.148  loss_ce_1: 1.024  loss_mask_1: 4.17  loss_ce_2: 1.273  loss_mask_2: 3.624  loss_ce_3: 1.489  loss_mask_3: 3.363  loss_ce_4: 1.707  loss_mask_4: 3.212  loss_ce_5: 1.762  loss_mask_5: 3.263  loss_ce_6: 1.763  loss_mask_6: 3.205  loss_ce_7: 1.84  loss_mask_7: 3.256  loss_ce_8: 1.791  loss_mask_8: 3.259  time: 2.4506  data_time: 0.3601  lr: 8.9529e-05  max_mem: 18446M
[01/24 06:25:01] d2.utils.events INFO:  eta: 1 day, 10:28:45  iter: 6959  total_loss: 47.38  loss_ce: 1.711  loss_mask: 3.113  loss_ce_0: 0.8893  loss_mask_0: 3.857  loss_ce_1: 0.9775  loss_mask_1: 3.865  loss_ce_2: 1.27  loss_mask_2: 3.448  loss_ce_3: 1.48  loss_mask_3: 3.15  loss_ce_4: 1.707  loss_mask_4: 3.076  loss_ce_5: 1.744  loss_mask_5: 3.058  loss_ce_6: 1.776  loss_mask_6: 3.011  loss_ce_7: 1.819  loss_mask_7: 3.101  loss_ce_8: 1.76  loss_mask_8: 3.067  time: 2.4505  data_time: 0.4028  lr: 8.9498e-05  max_mem: 18446M
[01/24 06:25:47] d2.utils.events INFO:  eta: 1 day, 10:29:29  iter: 6979  total_loss: 50.54  loss_ce: 1.739  loss_mask: 3.238  loss_ce_0: 0.9151  loss_mask_0: 4.001  loss_ce_1: 1.084  loss_mask_1: 4.112  loss_ce_2: 1.343  loss_mask_2: 3.799  loss_ce_3: 1.496  loss_mask_3: 3.404  loss_ce_4: 1.721  loss_mask_4: 3.276  loss_ce_5: 1.738  loss_mask_5: 3.219  loss_ce_6: 1.772  loss_mask_6: 3.219  loss_ce_7: 1.837  loss_mask_7: 3.281  loss_ce_8: 1.786  loss_mask_8: 3.311  time: 2.4501  data_time: 0.3718  lr: 8.9468e-05  max_mem: 18446M
[01/24 06:26:35] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 06:26:35] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 06:26:35] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 06:30:55] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 9.063277481412928, 'error_1pix': 0.7694648876076076, 'error_3pix': 0.6274474827753278, 'mIoU': 0.9006495384408453, 'fwIoU': 9.142554845254407, 'IoU-0': nan, 'IoU-1': 79.24576340685957, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.3986764450036714, 'IoU-12': 11.156380270031217, 'IoU-13': 0.7931174707256159, 'IoU-14': 5.15301814290786, 'IoU-15': 1.276113177910282, 'IoU-16': 0.01698841109791793, 'IoU-17': 1.8749349046037807e-05, 'IoU-18': 0.0354227894051072, 'IoU-19': 0.19990802385913028, 'IoU-20': 0.008348814319827518, 'IoU-21': 0.00043998297056388214, 'IoU-22': 0.044114761773169815, 'IoU-23': 0.0005034098130099413, 'IoU-24': 0.03279636416875209, 'IoU-25': 0.03858562130162655, 'IoU-26': 4.208580172998007, 'IoU-27': 0.18439154581908987, 'IoU-28': 0.23497035896699095, 'IoU-29': 0.11113761803135665, 'IoU-30': 6.310911295630314, 'IoU-31': 3.629829592870868, 'IoU-32': 0.11242678228001245, 'IoU-33': 0.9943561490353364, 'IoU-34': 0.0015365337905751547, 'IoU-35': 4.5998935068234434, 'IoU-36': 0.003175182033978437, 'IoU-37': 0.5969124799497444, 'IoU-38': 0.0736566696463974, 'IoU-39': 5.979993532290068, 'IoU-40': 0.574043669795038, 'IoU-41': 0.4583540681831889, 'IoU-42': 0.09853200419166251, 'IoU-43': 0.016992333150467942, 'IoU-44': 0.018622838758839258, 'IoU-45': 0.03456576512283356, 'IoU-46': 0.006384302098762234, 'IoU-47': 0.016391424917209695, 'IoU-48': 0.3857554650120174, 'IoU-49': 0.4393566543505374, 'IoU-50': 0.5932439084508414, 'IoU-51': 3.484149258493726, 'IoU-52': 0.0, 'IoU-53': 0.03355554621804659, 'IoU-54': 0.0006888079791516305, 'IoU-55': 8.284314354935649e-05, 'IoU-56': 0.125590380554103, 'IoU-57': 0.0, 'IoU-58': 0.16339090188260316, 'IoU-59': 0.05941868929529605, 'IoU-60': 0.00032362566834620495, 'IoU-61': 0.21837464306164095, 'IoU-62': 0.232718059503669, 'IoU-63': 0.007958539135702651, 'IoU-64': 0.0, 'IoU-65': 0.00105804420627353, 'IoU-66': 0.2201659431012013, 'IoU-67': 2.5106321516431467, 'IoU-68': 0.04322094297984072, 'IoU-69': 0.0029744563811793276, 'IoU-70': 0.044215936374080576, 'IoU-71': 0.0005282210340917157, 'IoU-72': 0.39143973213262123, 'IoU-73': 0.568839113197201, 'IoU-74': 4.356770726683217e-05, 'IoU-75': 0.7983813680078042, 'IoU-76': 0.2831674063804475, 'IoU-77': 0.3087241030957412, 'IoU-78': 0.0216549525568665, 'IoU-79': 0.0542126174908488, 'IoU-80': 0.3672326866539462, 'IoU-81': 0.5407538746472045, 'IoU-82': 0.14683024144926868, 'IoU-83': 0.7613069034149893, 'IoU-84': 1.3086937582077705, 'IoU-85': 1.4602583029324447, 'IoU-86': 3.1998320973451246, 'IoU-87': 0.011898056095595102, 'IoU-88': 0.21775949954468363, 'IoU-89': 2.341051460752978, 'IoU-90': 0.00020839465780294724, 'IoU-91': 0.00526598947127837, 'IoU-92': 0.0006820427521448113, 'IoU-93': 1.428728650991224, 'IoU-94': 1.206000227638876, 'IoU-95': 0.2708083798692029, 'IoU-96': 2.5759873504392705, 'IoU-97': 0.06309865560071626, 'IoU-98': 0.9422591746355571, 'IoU-99': 0.0011339507150424136, 'IoU-100': 0.07598108974808018, 'IoU-101': 0.006487584070032207, 'IoU-102': 1.3020103333863278, 'IoU-103': 0.000118043769213099, 'IoU-104': 0.10075889627909239, 'IoU-105': 0.0, 'IoU-106': 0.4409023176496992, 'IoU-107': 0.0006254514127587737, 'IoU-108': 0.03348192066775619, 'IoU-109': 1.463249357662904, 'IoU-110': 1.8128435784948702, 'IoU-111': 0.6035846734699003, 'IoU-112': 0.3958141843848635, 'IoU-113': 0.0, 'IoU-114': 0.05344283068053762, 'IoU-115': 0.004766174124478207, 'IoU-116': 0.0, 'IoU-117': 0.42836508661351946, 'IoU-118': 0.0, 'IoU-119': 0.00021429235734879212, 'IoU-120': 0.0, 'IoU-121': 0.49472303284379837, 'IoU-122': 0.0003771834205255674, 'IoU-123': 1.7838247039708235, 'IoU-124': 0.0029925328430479526, 'IoU-125': 0.000856408639664459, 'IoU-126': 0.9215093721980326, 'IoU-127': 0.34660362580963167, 'IoU-128': 0.0077826111889372235, 'IoU-129': 0.005580415964205972, 'IoU-130': 0.012613529164788946, 'IoU-131': 1.37080866731018, 'IoU-132': 0.009591199585033815, 'IoU-133': 0.0, 'IoU-134': 1.0413293576051512, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.00015262014448549078, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 8.265173204969683e-05, 'IoU-141': 0.21317568034057124, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.006611428479532269, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 2.080969659972409, 'IoU-150': 0.000831789324399916, 'IoU-151': 0.0, 'IoU-152': 1.055193756784731, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.00649881046282999, 'IoU-157': 0.0, 'IoU-158': 0.7691613175058365, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.4336531228313296, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.004856742833792211, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0037217126577308345, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 1.1190543875238843, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.868168173852448, 'pACC': 14.296810790969044, 'ACC-0': nan, 'ACC-1': 95.32529617785389, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.46201314392331155, 'ACC-12': 44.58966923450986, 'ACC-13': 0.9120743877159991, 'ACC-14': 51.429343705889394, 'ACC-15': 2.4211677932409263, 'ACC-16': 0.01722138569312529, 'ACC-17': 1.875191914172466e-05, 'ACC-18': 0.03628846975510655, 'ACC-19': 0.21229007510337397, 'ACC-20': 0.008393816436164133, 'ACC-21': 0.0004399854463589498, 'ACC-22': 0.044879387724522594, 'ACC-23': 0.0005059581756684348, 'ACC-24': 0.03310760936525653, 'ACC-25': 0.040582467162305166, 'ACC-26': 15.22545772187813, 'ACC-27': 0.18919872209661415, 'ACC-28': 0.24583648195178426, 'ACC-29': 0.11340325745641741, 'ACC-30': 25.159830682969197, 'ACC-31': 8.591265527767286, 'ACC-32': 0.12167518121348844, 'ACC-33': 1.1702061625588587, 'ACC-34': 0.0015406330890436392, 'ACC-35': 13.646874087606875, 'ACC-36': 0.003184187663854132, 'ACC-37': 0.6539090890454738, 'ACC-38': 0.07446656576486278, 'ACC-39': 44.30329705350232, 'ACC-40': 0.6587603673916969, 'ACC-41': 0.48094743906163295, 'ACC-42': 0.10099839226255453, 'ACC-43': 0.017096813290165578, 'ACC-44': 0.018746526031033835, 'ACC-45': 0.03466182601905106, 'ACC-46': 0.006390933351988987, 'ACC-47': 0.016929339094193457, 'ACC-48': 0.4079507144678569, 'ACC-49': 0.46846006856799977, 'ACC-50': 0.7029783533849027, 'ACC-51': 13.6140194858763, 'ACC-52': 0.0, 'ACC-53': 0.03376592351705424, 'ACC-54': 0.0006890033717472318, 'ACC-55': 8.284387397363837e-05, 'ACC-56': 0.1298437589997097, 'ACC-57': 0.0, 'ACC-58': 0.16923796438445812, 'ACC-59': 0.06204963941371653, 'ACC-60': 0.0003236432952002594, 'ACC-61': 0.2343599753194581, 'ACC-62': 0.4356834765370064, 'ACC-63': 0.007986961147584286, 'ACC-64': 0.0, 'ACC-65': 0.0010584172112486998, 'ACC-66': 0.28779275487514266, 'ACC-67': 15.38226898923619, 'ACC-68': 0.04397924938844896, 'ACC-69': 0.0029869593802122835, 'ACC-70': 0.044923896251004486, 'ACC-71': 0.0005292443328130935, 'ACC-72': 3.374680497163786, 'ACC-73': 1.015571237827443, 'ACC-74': 4.357162254295536e-05, 'ACC-75': 1.249406217273699, 'ACC-76': 0.3269776353821277, 'ACC-77': 0.8084117791281388, 'ACC-78': 0.021862236629927905, 'ACC-79': 0.07336714659940992, 'ACC-80': 0.6150235463409041, 'ACC-81': 6.0651267510750495, 'ACC-82': 0.17584426964153152, 'ACC-83': 2.9623557010461457, 'ACC-84': 3.660514053909187, 'ACC-85': 2.2129263292185755, 'ACC-86': 36.50746744757312, 'ACC-87': 0.012846374973206131, 'ACC-88': 0.23557000198329756, 'ACC-89': 20.05744797284995, 'ACC-90': 0.00020842842880397516, 'ACC-91': 0.0052797721315664785, 'ACC-92': 0.000682555128058007, 'ACC-93': 2.3734106118951765, 'ACC-94': 2.3779439777545854, 'ACC-95': 0.30725377672986665, 'ACC-96': 24.20077773553428, 'ACC-97': 0.06461411556475972, 'ACC-98': 1.6576403916884013, 'ACC-99': 0.0011377599781550083, 'ACC-100': 0.08026212608877936, 'ACC-101': 0.00661999996561039, 'ACC-102': 5.163502492070684, 'ACC-103': 0.00011806933031075848, 'ACC-104': 0.10400629595927302, 'ACC-105': 0.0, 'ACC-106': 0.5259684120017716, 'ACC-107': 0.0006255194531110617, 'ACC-108': 0.04090175095421297, 'ACC-109': 2.814724096824445, 'ACC-110': 7.204481313657932, 'ACC-111': 1.3331427903453623, 'ACC-112': 0.48737470296068375, 'ACC-113': 0.0, 'ACC-114': 0.05637761265773979, 'ACC-115': 0.004773502924240374, 'ACC-116': 0.0, 'ACC-117': 0.6012085247688107, 'ACC-118': 0.0, 'ACC-119': 0.0002144508107741803, 'ACC-120': 0.0, 'ACC-121': 1.430760069712081, 'ACC-122': 0.000377404776057441, 'ACC-123': 31.256204741162374, 'ACC-124': 0.0030365973914030196, 'ACC-125': 0.0008701677139497674, 'ACC-126': 1.7562204573812148, 'ACC-127': 0.6464409535646534, 'ACC-128': 0.00811083424503989, 'ACC-129': 0.005647735665889999, 'ACC-130': 0.013736866137141647, 'ACC-131': 13.648117614455382, 'ACC-132': 0.009852117702647002, 'ACC-133': 0.0, 'ACC-134': 3.7464541146057733, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.00015264647001221935, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 8.282437753339065e-05, 'ACC-141': 0.3377997404647734, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.00667870036101083, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 3.1528219627632548, 'ACC-150': 0.0008338466701896688, 'ACC-151': 0.0, 'ACC-152': 5.767309832085778, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0065931082627159725, 'ACC-157': 0.0, 'ACC-158': 1.7674098265333054, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.5977369897739072, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.00509881144946902, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0037628926108077797, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 19.328544303675216, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 06:30:55] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 06:30:55] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 06:30:55] d2.evaluation.testing INFO: copypaste: 9.0633,0.7695,0.6274,0.9006,9.1426,2.8682,14.2968
[01/24 06:30:55] d2.utils.events INFO:  eta: 1 day, 10:25:22  iter: 6999  total_loss: 50.26  loss_ce: 1.726  loss_mask: 3.278  loss_ce_0: 0.905  loss_mask_0: 4.133  loss_ce_1: 1.033  loss_mask_1: 4.017  loss_ce_2: 1.324  loss_mask_2: 3.697  loss_ce_3: 1.5  loss_mask_3: 3.379  loss_ce_4: 1.744  loss_mask_4: 3.291  loss_ce_5: 1.775  loss_mask_5: 3.294  loss_ce_6: 1.786  loss_mask_6: 3.215  loss_ce_7: 1.819  loss_mask_7: 3.267  loss_ce_8: 1.776  loss_mask_8: 3.287  time: 2.4499  data_time: 0.3985  lr: 8.9437e-05  max_mem: 18465M
[01/24 06:31:40] d2.utils.events INFO:  eta: 1 day, 10:19:19  iter: 7019  total_loss: 47.38  loss_ce: 1.687  loss_mask: 3.211  loss_ce_0: 0.9437  loss_mask_0: 3.747  loss_ce_1: 1.082  loss_mask_1: 3.638  loss_ce_2: 1.369  loss_mask_2: 3.381  loss_ce_3: 1.508  loss_mask_3: 3.141  loss_ce_4: 1.677  loss_mask_4: 3.018  loss_ce_5: 1.73  loss_mask_5: 3.096  loss_ce_6: 1.719  loss_mask_6: 3.03  loss_ce_7: 1.802  loss_mask_7: 3.033  loss_ce_8: 1.731  loss_mask_8: 3.028  time: 2.4493  data_time: 0.3711  lr: 8.9407e-05  max_mem: 18465M
[01/24 06:32:25] d2.utils.events INFO:  eta: 1 day, 10:18:33  iter: 7039  total_loss: 49.54  loss_ce: 1.704  loss_mask: 3.205  loss_ce_0: 0.9065  loss_mask_0: 3.957  loss_ce_1: 1.03  loss_mask_1: 4.034  loss_ce_2: 1.309  loss_mask_2: 3.685  loss_ce_3: 1.445  loss_mask_3: 3.348  loss_ce_4: 1.703  loss_mask_4: 3.206  loss_ce_5: 1.755  loss_mask_5: 3.249  loss_ce_6: 1.746  loss_mask_6: 3.193  loss_ce_7: 1.815  loss_mask_7: 3.22  loss_ce_8: 1.776  loss_mask_8: 3.154  time: 2.4488  data_time: 0.4044  lr: 8.9377e-05  max_mem: 18465M
[01/24 06:33:11] d2.utils.events INFO:  eta: 1 day, 10:17:18  iter: 7059  total_loss: 52.83  loss_ce: 1.788  loss_mask: 3.468  loss_ce_0: 0.9201  loss_mask_0: 4.392  loss_ce_1: 1.02  loss_mask_1: 4.245  loss_ce_2: 1.37  loss_mask_2: 3.884  loss_ce_3: 1.528  loss_mask_3: 3.629  loss_ce_4: 1.748  loss_mask_4: 3.529  loss_ce_5: 1.79  loss_mask_5: 3.56  loss_ce_6: 1.783  loss_mask_6: 3.324  loss_ce_7: 1.836  loss_mask_7: 3.408  loss_ce_8: 1.812  loss_mask_8: 3.401  time: 2.4483  data_time: 0.3821  lr: 8.9346e-05  max_mem: 18465M
[01/24 06:33:56] d2.utils.events INFO:  eta: 1 day, 10:14:27  iter: 7079  total_loss: 49.49  loss_ce: 1.716  loss_mask: 3.214  loss_ce_0: 0.9305  loss_mask_0: 4.047  loss_ce_1: 1.049  loss_mask_1: 4.035  loss_ce_2: 1.321  loss_mask_2: 3.674  loss_ce_3: 1.504  loss_mask_3: 3.314  loss_ce_4: 1.713  loss_mask_4: 3.179  loss_ce_5: 1.759  loss_mask_5: 3.194  loss_ce_6: 1.75  loss_mask_6: 3.139  loss_ce_7: 1.824  loss_mask_7: 3.132  loss_ce_8: 1.766  loss_mask_8: 3.256  time: 2.4477  data_time: 0.3714  lr: 8.9316e-05  max_mem: 18465M
[01/24 06:34:41] d2.utils.events INFO:  eta: 1 day, 10:11:55  iter: 7099  total_loss: 48.21  loss_ce: 1.669  loss_mask: 3.086  loss_ce_0: 0.8885  loss_mask_0: 3.881  loss_ce_1: 0.9932  loss_mask_1: 3.763  loss_ce_2: 1.257  loss_mask_2: 3.568  loss_ce_3: 1.486  loss_mask_3: 3.303  loss_ce_4: 1.685  loss_mask_4: 3.152  loss_ce_5: 1.729  loss_mask_5: 3.145  loss_ce_6: 1.716  loss_mask_6: 3.067  loss_ce_7: 1.778  loss_mask_7: 3.139  loss_ce_8: 1.776  loss_mask_8: 3.086  time: 2.4472  data_time: 0.3656  lr: 8.9286e-05  max_mem: 18465M
[01/24 06:35:26] d2.utils.events INFO:  eta: 1 day, 10:12:25  iter: 7119  total_loss: 50.31  loss_ce: 1.693  loss_mask: 3.367  loss_ce_0: 0.9306  loss_mask_0: 3.985  loss_ce_1: 1.005  loss_mask_1: 3.836  loss_ce_2: 1.253  loss_mask_2: 3.636  loss_ce_3: 1.478  loss_mask_3: 3.401  loss_ce_4: 1.689  loss_mask_4: 3.246  loss_ce_5: 1.743  loss_mask_5: 3.282  loss_ce_6: 1.741  loss_mask_6: 3.296  loss_ce_7: 1.769  loss_mask_7: 3.291  loss_ce_8: 1.728  loss_mask_8: 3.239  time: 2.4467  data_time: 0.4049  lr: 8.9255e-05  max_mem: 18465M
[01/24 06:36:12] d2.utils.events INFO:  eta: 1 day, 10:06:22  iter: 7139  total_loss: 50.37  loss_ce: 1.733  loss_mask: 3.281  loss_ce_0: 0.8976  loss_mask_0: 3.894  loss_ce_1: 0.9678  loss_mask_1: 3.948  loss_ce_2: 1.338  loss_mask_2: 3.706  loss_ce_3: 1.516  loss_mask_3: 3.468  loss_ce_4: 1.703  loss_mask_4: 3.351  loss_ce_5: 1.77  loss_mask_5: 3.257  loss_ce_6: 1.761  loss_mask_6: 3.326  loss_ce_7: 1.795  loss_mask_7: 3.262  loss_ce_8: 1.771  loss_mask_8: 3.285  time: 2.4462  data_time: 0.4167  lr: 8.9225e-05  max_mem: 18465M
[01/24 06:36:58] d2.utils.events INFO:  eta: 1 day, 10:05:19  iter: 7159  total_loss: 49.72  loss_ce: 1.733  loss_mask: 3.197  loss_ce_0: 0.9199  loss_mask_0: 4.135  loss_ce_1: 0.9723  loss_mask_1: 3.951  loss_ce_2: 1.314  loss_mask_2: 3.694  loss_ce_3: 1.507  loss_mask_3: 3.349  loss_ce_4: 1.721  loss_mask_4: 3.237  loss_ce_5: 1.783  loss_mask_5: 3.211  loss_ce_6: 1.782  loss_mask_6: 3.263  loss_ce_7: 1.82  loss_mask_7: 3.318  loss_ce_8: 1.799  loss_mask_8: 3.266  time: 2.4458  data_time: 0.3942  lr: 8.9194e-05  max_mem: 18490M
[01/24 06:37:44] d2.utils.events INFO:  eta: 1 day, 10:04:33  iter: 7179  total_loss: 49.33  loss_ce: 1.699  loss_mask: 3.326  loss_ce_0: 0.8517  loss_mask_0: 3.937  loss_ce_1: 0.8398  loss_mask_1: 3.869  loss_ce_2: 1.322  loss_mask_2: 3.634  loss_ce_3: 1.499  loss_mask_3: 3.423  loss_ce_4: 1.706  loss_mask_4: 3.337  loss_ce_5: 1.771  loss_mask_5: 3.289  loss_ce_6: 1.761  loss_mask_6: 3.267  loss_ce_7: 1.787  loss_mask_7: 3.322  loss_ce_8: 1.764  loss_mask_8: 3.295  time: 2.4454  data_time: 0.3884  lr: 8.9164e-05  max_mem: 18490M
[01/24 06:38:29] d2.utils.events INFO:  eta: 1 day, 10:01:12  iter: 7199  total_loss: 48.54  loss_ce: 1.685  loss_mask: 3.067  loss_ce_0: 0.9662  loss_mask_0: 3.983  loss_ce_1: 1.029  loss_mask_1: 3.943  loss_ce_2: 1.335  loss_mask_2: 3.644  loss_ce_3: 1.492  loss_mask_3: 3.332  loss_ce_4: 1.688  loss_mask_4: 3.174  loss_ce_5: 1.737  loss_mask_5: 3.072  loss_ce_6: 1.73  loss_mask_6: 3.114  loss_ce_7: 1.77  loss_mask_7: 3.118  loss_ce_8: 1.779  loss_mask_8: 3.246  time: 2.4449  data_time: 0.3725  lr: 8.9134e-05  max_mem: 18490M
[01/24 06:39:19] d2.utils.events INFO:  eta: 1 day, 10:03:33  iter: 7219  total_loss: 47.32  loss_ce: 1.676  loss_mask: 2.988  loss_ce_0: 0.8659  loss_mask_0: 3.913  loss_ce_1: 0.8974  loss_mask_1: 3.776  loss_ce_2: 1.267  loss_mask_2: 3.555  loss_ce_3: 1.446  loss_mask_3: 3.201  loss_ce_4: 1.677  loss_mask_4: 3.035  loss_ce_5: 1.75  loss_mask_5: 3.02  loss_ce_6: 1.731  loss_mask_6: 3.101  loss_ce_7: 1.764  loss_mask_7: 3.071  loss_ce_8: 1.763  loss_mask_8: 3.112  time: 2.4450  data_time: 0.3927  lr: 8.9103e-05  max_mem: 18490M
[01/24 06:40:06] d2.utils.events INFO:  eta: 1 day, 10:02:29  iter: 7239  total_loss: 50.61  loss_ce: 1.728  loss_mask: 3.203  loss_ce_0: 0.8867  loss_mask_0: 3.948  loss_ce_1: 0.9979  loss_mask_1: 3.906  loss_ce_2: 1.318  loss_mask_2: 3.762  loss_ce_3: 1.515  loss_mask_3: 3.51  loss_ce_4: 1.764  loss_mask_4: 3.334  loss_ce_5: 1.793  loss_mask_5: 3.277  loss_ce_6: 1.814  loss_mask_6: 3.502  loss_ce_7: 1.814  loss_mask_7: 3.327  loss_ce_8: 1.811  loss_mask_8: 3.177  time: 2.4447  data_time: 0.3903  lr: 8.9073e-05  max_mem: 18490M
[01/24 06:40:52] d2.utils.events INFO:  eta: 1 day, 10:01:27  iter: 7259  total_loss: 50.89  loss_ce: 1.798  loss_mask: 3.348  loss_ce_0: 0.8651  loss_mask_0: 4.065  loss_ce_1: 0.9891  loss_mask_1: 3.985  loss_ce_2: 1.375  loss_mask_2: 3.757  loss_ce_3: 1.56  loss_mask_3: 3.472  loss_ce_4: 1.768  loss_mask_4: 3.359  loss_ce_5: 1.816  loss_mask_5: 3.339  loss_ce_6: 1.81  loss_mask_6: 3.32  loss_ce_7: 1.824  loss_mask_7: 3.285  loss_ce_8: 1.866  loss_mask_8: 3.369  time: 2.4444  data_time: 0.4059  lr: 8.9043e-05  max_mem: 18490M
[01/24 06:41:42] d2.utils.events INFO:  eta: 1 day, 10:01:42  iter: 7279  total_loss: 50.29  loss_ce: 1.717  loss_mask: 3.302  loss_ce_0: 0.8933  loss_mask_0: 4.116  loss_ce_1: 1.005  loss_mask_1: 4.06  loss_ce_2: 1.277  loss_mask_2: 3.771  loss_ce_3: 1.501  loss_mask_3: 3.491  loss_ce_4: 1.731  loss_mask_4: 3.344  loss_ce_5: 1.795  loss_mask_5: 3.254  loss_ce_6: 1.767  loss_mask_6: 3.331  loss_ce_7: 1.813  loss_mask_7: 3.251  loss_ce_8: 1.817  loss_mask_8: 3.251  time: 2.4445  data_time: 0.4249  lr: 8.9012e-05  max_mem: 18490M
[01/24 06:42:29] d2.utils.events INFO:  eta: 1 day, 10:00:27  iter: 7299  total_loss: 51.46  loss_ce: 1.734  loss_mask: 3.328  loss_ce_0: 0.846  loss_mask_0: 3.998  loss_ce_1: 0.9353  loss_mask_1: 4.08  loss_ce_2: 1.26  loss_mask_2: 3.872  loss_ce_3: 1.484  loss_mask_3: 3.47  loss_ce_4: 1.708  loss_mask_4: 3.354  loss_ce_5: 1.785  loss_mask_5: 3.329  loss_ce_6: 1.75  loss_mask_6: 3.329  loss_ce_7: 1.819  loss_mask_7: 3.285  loss_ce_8: 1.827  loss_mask_8: 3.374  time: 2.4442  data_time: 0.4094  lr: 8.8982e-05  max_mem: 18490M
[01/24 06:43:14] d2.utils.events INFO:  eta: 1 day, 9:58:31  iter: 7319  total_loss: 47.29  loss_ce: 1.689  loss_mask: 3.105  loss_ce_0: 0.9059  loss_mask_0: 3.682  loss_ce_1: 0.973  loss_mask_1: 3.62  loss_ce_2: 1.291  loss_mask_2: 3.409  loss_ce_3: 1.457  loss_mask_3: 3.198  loss_ce_4: 1.667  loss_mask_4: 3.064  loss_ce_5: 1.715  loss_mask_5: 3.094  loss_ce_6: 1.711  loss_mask_6: 3.05  loss_ce_7: 1.751  loss_mask_7: 3.084  loss_ce_8: 1.777  loss_mask_8: 3.145  time: 2.4437  data_time: 0.3738  lr: 8.8951e-05  max_mem: 18490M
[01/24 06:44:04] d2.utils.events INFO:  eta: 1 day, 10:00:00  iter: 7339  total_loss: 49.65  loss_ce: 1.764  loss_mask: 3.207  loss_ce_0: 0.8475  loss_mask_0: 3.994  loss_ce_1: 0.9534  loss_mask_1: 3.771  loss_ce_2: 1.296  loss_mask_2: 3.66  loss_ce_3: 1.526  loss_mask_3: 3.342  loss_ce_4: 1.774  loss_mask_4: 3.216  loss_ce_5: 1.811  loss_mask_5: 3.238  loss_ce_6: 1.882  loss_mask_6: 3.345  loss_ce_7: 1.858  loss_mask_7: 3.266  loss_ce_8: 1.837  loss_mask_8: 3.36  time: 2.4438  data_time: 0.4241  lr: 8.8921e-05  max_mem: 18490M
[01/24 06:44:49] d2.utils.events INFO:  eta: 1 day, 9:57:23  iter: 7359  total_loss: 50.72  loss_ce: 1.712  loss_mask: 3.239  loss_ce_0: 0.9016  loss_mask_0: 3.968  loss_ce_1: 0.9663  loss_mask_1: 3.87  loss_ce_2: 1.358  loss_mask_2: 3.704  loss_ce_3: 1.519  loss_mask_3: 3.47  loss_ce_4: 1.751  loss_mask_4: 3.373  loss_ce_5: 1.796  loss_mask_5: 3.2  loss_ce_6: 1.813  loss_mask_6: 3.284  loss_ce_7: 1.827  loss_mask_7: 3.262  loss_ce_8: 1.797  loss_mask_8: 3.283  time: 2.4433  data_time: 0.3639  lr: 8.8891e-05  max_mem: 18490M
[01/24 06:45:36] d2.utils.events INFO:  eta: 1 day, 9:56:37  iter: 7379  total_loss: 51.03  loss_ce: 1.731  loss_mask: 3.37  loss_ce_0: 0.8486  loss_mask_0: 4.201  loss_ce_1: 0.9304  loss_mask_1: 4.151  loss_ce_2: 1.268  loss_mask_2: 3.764  loss_ce_3: 1.482  loss_mask_3: 3.526  loss_ce_4: 1.75  loss_mask_4: 3.364  loss_ce_5: 1.789  loss_mask_5: 3.314  loss_ce_6: 1.775  loss_mask_6: 3.298  loss_ce_7: 1.831  loss_mask_7: 3.407  loss_ce_8: 1.809  loss_mask_8: 3.33  time: 2.4430  data_time: 0.3545  lr: 8.886e-05  max_mem: 18490M
[01/24 06:46:26] d2.utils.events INFO:  eta: 1 day, 9:57:59  iter: 7399  total_loss: 52.94  loss_ce: 1.781  loss_mask: 3.565  loss_ce_0: 0.9941  loss_mask_0: 4.291  loss_ce_1: 1.137  loss_mask_1: 4.195  loss_ce_2: 1.489  loss_mask_2: 3.965  loss_ce_3: 1.548  loss_mask_3: 3.631  loss_ce_4: 1.766  loss_mask_4: 3.466  loss_ce_5: 1.787  loss_mask_5: 3.363  loss_ce_6: 1.811  loss_mask_6: 3.402  loss_ce_7: 1.842  loss_mask_7: 3.285  loss_ce_8: 1.836  loss_mask_8: 3.439  time: 2.4431  data_time: 0.4376  lr: 8.883e-05  max_mem: 18490M
[01/24 06:47:13] d2.utils.events INFO:  eta: 1 day, 9:56:45  iter: 7419  total_loss: 54.13  loss_ce: 1.829  loss_mask: 3.54  loss_ce_0: 0.9159  loss_mask_0: 4.022  loss_ce_1: 1.068  loss_mask_1: 4.104  loss_ce_2: 1.423  loss_mask_2: 3.824  loss_ce_3: 1.553  loss_mask_3: 3.531  loss_ce_4: 1.826  loss_mask_4: 3.485  loss_ce_5: 1.889  loss_mask_5: 3.362  loss_ce_6: 2.158  loss_mask_6: 4.073  loss_ce_7: 1.87  loss_mask_7: 3.373  loss_ce_8: 1.944  loss_mask_8: 3.768  time: 2.4429  data_time: 0.3806  lr: 8.8799e-05  max_mem: 18490M
[01/24 06:47:59] d2.utils.events INFO:  eta: 1 day, 9:55:56  iter: 7439  total_loss: 53.01  loss_ce: 1.797  loss_mask: 3.491  loss_ce_0: 0.8482  loss_mask_0: 4.152  loss_ce_1: 0.9878  loss_mask_1: 4.028  loss_ce_2: 1.397  loss_mask_2: 3.848  loss_ce_3: 1.565  loss_mask_3: 3.541  loss_ce_4: 1.95  loss_mask_4: 3.654  loss_ce_5: 1.918  loss_mask_5: 3.416  loss_ce_6: 2.12  loss_mask_6: 4.012  loss_ce_7: 1.953  loss_mask_7: 3.531  loss_ce_8: 1.92  loss_mask_8: 3.518  time: 2.4425  data_time: 0.3775  lr: 8.8769e-05  max_mem: 18490M
[01/24 06:48:48] d2.utils.events INFO:  eta: 1 day, 9:59:10  iter: 7459  total_loss: 51.85  loss_ce: 1.769  loss_mask: 3.339  loss_ce_0: 0.8114  loss_mask_0: 3.881  loss_ce_1: 0.9611  loss_mask_1: 3.956  loss_ce_2: 1.422  loss_mask_2: 3.662  loss_ce_3: 1.567  loss_mask_3: 3.477  loss_ce_4: 1.932  loss_mask_4: 3.674  loss_ce_5: 1.911  loss_mask_5: 3.397  loss_ce_6: 1.97  loss_mask_6: 3.578  loss_ce_7: 1.91  loss_mask_7: 3.359  loss_ce_8: 1.856  loss_mask_8: 3.256  time: 2.4426  data_time: 0.4341  lr: 8.8739e-05  max_mem: 18490M
[01/24 06:49:35] d2.utils.events INFO:  eta: 1 day, 9:54:30  iter: 7479  total_loss: 53.39  loss_ce: 1.795  loss_mask: 3.504  loss_ce_0: 0.8517  loss_mask_0: 4.013  loss_ce_1: 0.9668  loss_mask_1: 3.753  loss_ce_2: 1.388  loss_mask_2: 3.707  loss_ce_3: 1.58  loss_mask_3: 3.494  loss_ce_4: 1.913  loss_mask_4: 3.769  loss_ce_5: 1.988  loss_mask_5: 3.575  loss_ce_6: 1.978  loss_mask_6: 3.535  loss_ce_7: 1.927  loss_mask_7: 3.647  loss_ce_8: 1.892  loss_mask_8: 3.427  time: 2.4423  data_time: 0.3879  lr: 8.8708e-05  max_mem: 18490M
[01/24 06:50:21] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 06:50:22] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 06:50:22] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 06:54:31] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 7.465336282740543, 'error_1pix': 0.7520696252950101, 'error_3pix': 0.5787763759446989, 'mIoU': 1.0357776971657253, 'fwIoU': 10.645533975910688, 'IoU-0': nan, 'IoU-1': 90.65624535998232, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 8.116254414599864e-06, 'IoU-12': 0.5611602469054898, 'IoU-13': 11.200016152824249, 'IoU-14': 8.056312556260844, 'IoU-15': 4.6854962952136034, 'IoU-16': 0.0, 'IoU-17': 3.746523694327126e-05, 'IoU-18': 0.0, 'IoU-19': 0.5558390341993054, 'IoU-20': 1.2315402886705807e-05, 'IoU-21': 0.06094397743431309, 'IoU-22': 5.316978016921513, 'IoU-23': 0.0, 'IoU-24': 0.16762511733580782, 'IoU-25': 9.322103182071955e-06, 'IoU-26': 4.120407261479678, 'IoU-27': 0.37458866666223833, 'IoU-28': 0.00016711079240970105, 'IoU-29': 4.844633220584084, 'IoU-30': 5.081015377595574, 'IoU-31': 0.07710859979560881, 'IoU-32': 0.006489838751303105, 'IoU-33': 0.003532445814406952, 'IoU-34': 0.0004233024484763891, 'IoU-35': 0.11742417129304752, 'IoU-36': 3.5311023699657715, 'IoU-37': 2.514785078396332, 'IoU-38': 0.4335341957276458, 'IoU-39': 3.6863861658400903, 'IoU-40': 0.08805020588209905, 'IoU-41': 0.8676208915534521, 'IoU-42': 5.6296319227944185, 'IoU-43': 0.0007603637303590135, 'IoU-44': 0.3896167983746956, 'IoU-45': 0.30037937597402314, 'IoU-46': 0.0, 'IoU-47': 0.31182491118129185, 'IoU-48': 3.5723813794673425, 'IoU-49': 0.004363731440362965, 'IoU-50': 0.0, 'IoU-51': 5.362198065592768, 'IoU-52': 0.0, 'IoU-53': 1.2290965167549062, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 3.837830794502041, 'IoU-58': 0.0, 'IoU-59': 0.003346091111235371, 'IoU-60': 0.0, 'IoU-61': 0.16397472044065842, 'IoU-62': 0.0, 'IoU-63': 0.13621313608286142, 'IoU-64': 0.0, 'IoU-65': 2.929352168289636, 'IoU-66': 0.09737286279111736, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.002028558124934712, 'IoU-70': 3.176733434897031e-05, 'IoU-71': 2.0961116872687766, 'IoU-72': 0.0, 'IoU-73': 0.42417053328075843, 'IoU-74': 0.0, 'IoU-75': 1.689028992422546, 'IoU-76': 0.008917343716428048, 'IoU-77': 1.1209663250511375, 'IoU-78': 0.2584608481419317, 'IoU-79': 0.17522131269780203, 'IoU-80': 0.04085301810405779, 'IoU-81': 0.0, 'IoU-82': 3.2044154264073157, 'IoU-83': 0.0, 'IoU-84': 0.1828276481738306, 'IoU-85': 0.0, 'IoU-86': 1.5273781339087693, 'IoU-87': 0.08079031972484235, 'IoU-88': 3.2736906228492137, 'IoU-89': 0.7426984521700885, 'IoU-90': 0.0014062868051624789, 'IoU-91': 0.0064274196156457195, 'IoU-92': 0.0002268810673846696, 'IoU-93': 1.6875610795186253, 'IoU-94': 2.0107580246169445, 'IoU-95': 0.0, 'IoU-96': 0.05130475492293175, 'IoU-97': 0.9996472710751981, 'IoU-98': 0.0817253633256023, 'IoU-99': 0.0, 'IoU-100': 0.00020271870104343368, 'IoU-101': 0.010596362886915574, 'IoU-102': 0.09833646610276817, 'IoU-103': 0.05837758000763212, 'IoU-104': 0.25794094457622735, 'IoU-105': 0.0, 'IoU-106': 0.0007855348471113527, 'IoU-107': 1.8516564885347138, 'IoU-108': 0.0007175301728337004, 'IoU-109': 0.1234427107324327, 'IoU-110': 0.6214731565743142, 'IoU-111': 6.267323273234926e-05, 'IoU-112': 0.001197938348102915, 'IoU-113': 0.0, 'IoU-114': 0.0003270378546316736, 'IoU-115': 1.8320064936901006, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.04270140637658947, 'IoU-122': 0.0, 'IoU-123': 0.0019216792520233064, 'IoU-124': 0.0, 'IoU-125': 0.0005953808191032807, 'IoU-126': 0.1200729079058231, 'IoU-127': 0.0017912935045964013, 'IoU-128': 0.0, 'IoU-129': 0.04670754526217458, 'IoU-130': 0.0, 'IoU-131': 6.642280640342423e-05, 'IoU-132': 0.04086721227320107, 'IoU-133': 0.0, 'IoU-134': 0.001649303169410924, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0012394297301183076, 'IoU-141': 0.05482017382396722, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 9.277220989898033e-05, 'IoU-148': 0.0, 'IoU-149': 1.3783234805702256, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 1.1627616434061159, 'IoU-156': 0.0, 'IoU-157': 0.03817378616150023, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.03897904178074356, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.4382937987688814, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0001931542278563164, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 3.1403616650972674, 'pACC': 14.817669336489145, 'ACC-0': nan, 'ACC-1': 95.29908976868087, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 8.1165056203149e-06, 'ACC-12': 0.5820809173571874, 'ACC-13': 30.74862265504727, 'ACC-14': 16.70175711288055, 'ACC-15': 8.090655259280274, 'ACC-16': 0.0, 'ACC-17': 3.750383828344932e-05, 'ACC-18': 0.0, 'ACC-19': 0.6390955642162359, 'ACC-20': 1.2316678556367032e-05, 'ACC-21': 0.0685629021751324, 'ACC-22': 39.1150526557991, 'ACC-23': 0.0, 'ACC-24': 0.17674125274541685, 'ACC-25': 9.322159378783728e-06, 'ACC-26': 13.882182468394896, 'ACC-27': 0.39749945513452184, 'ACC-28': 0.0001671514009261513, 'ACC-29': 25.939981653963823, 'ACC-30': 52.78604892143354, 'ACC-31': 0.07772199868092884, 'ACC-32': 0.006496416874204629, 'ACC-33': 0.003536358492829148, 'ACC-34': 0.00042331413848488783, 'ACC-35': 0.12412774489369668, 'ACC-36': 8.02048917891364, 'ACC-37': 3.510831635419276, 'ACC-38': 0.46590311185416117, 'ACC-39': 7.069287789882611, 'ACC-40': 0.0898772696144612, 'ACC-41': 0.9520583403868025, 'ACC-42': 17.074313782738354, 'ACC-43': 0.0007609101315256827, 'ACC-44': 0.40986739118338944, 'ACC-45': 0.306174417778762, 'ACC-46': 0.0, 'ACC-47': 0.3393876665717675, 'ACC-48': 7.381216810013257, 'ACC-49': 0.004367735546597813, 'ACC-50': 0.0, 'ACC-51': 43.3637118892966, 'ACC-52': 0.0, 'ACC-53': 1.8376661733740047, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 12.924843120544145, 'ACC-58': 0.0, 'ACC-59': 0.003350412495341065, 'ACC-60': 0.0, 'ACC-61': 0.17579710938501644, 'ACC-62': 0.0, 'ACC-63': 0.14850582955935585, 'ACC-64': 0.0, 'ACC-65': 10.936080997602735, 'ACC-66': 0.10312624819554617, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0020548585807134154, 'ACC-70': 3.177078942786739e-05, 'ACC-71': 3.229118141117488, 'ACC-72': 0.0, 'ACC-73': 0.7173261898311167, 'ACC-74': 0.0, 'ACC-75': 14.888347007171257, 'ACC-76': 0.008949151450991058, 'ACC-77': 9.121802993184566, 'ACC-78': 0.2652751147850613, 'ACC-79': 0.22666182378897706, 'ACC-80': 0.04590173578447791, 'ACC-81': 0.0, 'ACC-82': 42.095423728546585, 'ACC-83': 0.0, 'ACC-84': 0.1958372977333707, 'ACC-85': 0.0, 'ACC-86': 8.24335773962446, 'ACC-87': 0.17266751428272203, 'ACC-88': 16.649318049792583, 'ACC-89': 1.0588718717755508, 'ACC-90': 0.0014068918944268323, 'ACC-91': 0.006463638563129065, 'ACC-92': 0.00022751837601933566, 'ACC-93': 3.5538916170232637, 'ACC-94': 9.373669568982924, 'ACC-95': 0.0, 'ACC-96': 0.05843591259026633, 'ACC-97': 1.4454455009725504, 'ACC-98': 0.0890020380202986, 'ACC-99': 0.0, 'ACC-100': 0.0002027333318736533, 'ACC-101': 0.010940194748362624, 'ACC-102': 0.10695514272768465, 'ACC-103': 0.062458675734391234, 'ACC-104': 0.2998696539681759, 'ACC-105': 0.0, 'ACC-106': 0.0007866712713158414, 'ACC-107': 24.502358480303208, 'ACC-108': 0.0007185442735199578, 'ACC-109': 0.15711221957155594, 'ACC-110': 2.291843624940495, 'ACC-111': 6.267861446415583e-05, 'ACC-112': 0.0012011699395210935, 'ACC-113': 0.0, 'ACC-114': 0.00032798869678064515, 'ACC-115': 32.60851262159277, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0504172595993781, 'ACC-122': 0.0, 'ACC-123': 0.0019243332432021694, 'ACC-124': 0.0, 'ACC-125': 0.000598240303340465, 'ACC-126': 0.18032951119773405, 'ACC-127': 0.0018105953704828568, 'ACC-128': 0.0, 'ACC-129': 0.05145714717810887, 'ACC-130': 0.0, 'ACC-131': 6.645785608285434e-05, 'ACC-132': 0.04369782817772684, 'ACC-133': 0.0, 'ACC-134': 0.0016544592847910385, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0012423656630008598, 'ACC-141': 0.05764644300407817, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 9.285197630788973e-05, 'ACC-148': 0.0, 'ACC-149': 10.998114736392687, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 19.673472808710677, 'ACC-156': 0.0, 'ACC-157': 0.041375574528434135, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.04114278653212648, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.5538364160630143, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.00019315795878395477, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 06:54:31] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 06:54:31] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 06:54:31] d2.evaluation.testing INFO: copypaste: 7.4653,0.7521,0.5788,1.0358,10.6455,3.1404,14.8177
[01/24 06:54:31] d2.utils.events INFO:  eta: 1 day, 9:53:48  iter: 7499  total_loss: 54.05  loss_ce: 1.772  loss_mask: 3.176  loss_ce_0: 0.9811  loss_mask_0: 4.501  loss_ce_1: 1.031  loss_mask_1: 4.241  loss_ce_2: 1.349  loss_mask_2: 3.687  loss_ce_3: 1.599  loss_mask_3: 3.552  loss_ce_4: 2.058  loss_mask_4: 3.965  loss_ce_5: 1.95  loss_mask_5: 3.524  loss_ce_6: 1.943  loss_mask_6: 3.642  loss_ce_7: 1.882  loss_mask_7: 3.253  loss_ce_8: 1.873  loss_mask_8: 3.311  time: 2.4419  data_time: 0.3623  lr: 8.8678e-05  max_mem: 18490M
[01/24 06:55:17] d2.utils.events INFO:  eta: 1 day, 9:52:51  iter: 7519  total_loss: 50.57  loss_ce: 1.736  loss_mask: 3.239  loss_ce_0: 0.9165  loss_mask_0: 3.989  loss_ce_1: 0.947  loss_mask_1: 3.977  loss_ce_2: 1.339  loss_mask_2: 3.749  loss_ce_3: 1.555  loss_mask_3: 3.487  loss_ce_4: 1.937  loss_mask_4: 3.496  loss_ce_5: 1.897  loss_mask_5: 3.371  loss_ce_6: 1.885  loss_mask_6: 3.433  loss_ce_7: 1.87  loss_mask_7: 3.322  loss_ce_8: 1.817  loss_mask_8: 3.25  time: 2.4416  data_time: 0.3869  lr: 8.8647e-05  max_mem: 18490M
[01/24 06:56:07] d2.utils.events INFO:  eta: 1 day, 9:52:34  iter: 7539  total_loss: 53.55  loss_ce: 1.83  loss_mask: 3.453  loss_ce_0: 0.9754  loss_mask_0: 4.097  loss_ce_1: 0.9449  loss_mask_1: 4.106  loss_ce_2: 1.349  loss_mask_2: 3.647  loss_ce_3: 1.633  loss_mask_3: 3.564  loss_ce_4: 1.979  loss_mask_4: 3.65  loss_ce_5: 2.043  loss_mask_5: 3.588  loss_ce_6: 1.949  loss_mask_6: 3.566  loss_ce_7: 1.928  loss_mask_7: 3.743  loss_ce_8: 1.897  loss_mask_8: 3.532  time: 2.4417  data_time: 0.4256  lr: 8.8617e-05  max_mem: 18490M
[01/24 06:56:53] d2.utils.events INFO:  eta: 1 day, 9:51:29  iter: 7559  total_loss: 54.57  loss_ce: 1.869  loss_mask: 3.847  loss_ce_0: 1.04  loss_mask_0: 4.422  loss_ce_1: 1.038  loss_mask_1: 4.248  loss_ce_2: 1.391  loss_mask_2: 3.737  loss_ce_3: 1.647  loss_mask_3: 3.512  loss_ce_4: 1.919  loss_mask_4: 3.542  loss_ce_5: 2.026  loss_mask_5: 3.74  loss_ce_6: 1.99  loss_mask_6: 3.714  loss_ce_7: 1.95  loss_mask_7: 3.702  loss_ce_8: 1.913  loss_mask_8: 3.797  time: 2.4413  data_time: 0.3422  lr: 8.8587e-05  max_mem: 18490M
[01/24 06:57:41] d2.utils.events INFO:  eta: 1 day, 9:50:42  iter: 7579  total_loss: 57.84  loss_ce: 2.137  loss_mask: 4.025  loss_ce_0: 1.082  loss_mask_0: 4.738  loss_ce_1: 1.093  loss_mask_1: 4.467  loss_ce_2: 1.432  loss_mask_2: 3.999  loss_ce_3: 1.651  loss_mask_3: 3.696  loss_ce_4: 1.914  loss_mask_4: 3.861  loss_ce_5: 2.152  loss_mask_5: 4.137  loss_ce_6: 1.999  loss_mask_6: 3.804  loss_ce_7: 1.921  loss_mask_7: 3.561  loss_ce_8: 1.917  loss_mask_8: 3.909  time: 2.4412  data_time: 0.3865  lr: 8.8556e-05  max_mem: 18490M
[01/24 06:58:32] d2.utils.events INFO:  eta: 1 day, 9:52:02  iter: 7599  total_loss: 61.56  loss_ce: 2.153  loss_mask: 4.456  loss_ce_0: 1.251  loss_mask_0: 5.307  loss_ce_1: 1.109  loss_mask_1: 4.639  loss_ce_2: 1.53  loss_mask_2: 4.4  loss_ce_3: 1.738  loss_mask_3: 4.042  loss_ce_4: 1.953  loss_mask_4: 3.899  loss_ce_5: 2.149  loss_mask_5: 4.713  loss_ce_6: 2.003  loss_mask_6: 4.156  loss_ce_7: 2.082  loss_mask_7: 3.952  loss_ce_8: 1.967  loss_mask_8: 4.013  time: 2.4414  data_time: 0.3989  lr: 8.8526e-05  max_mem: 18490M
[01/24 06:59:19] d2.utils.events INFO:  eta: 1 day, 9:49:58  iter: 7619  total_loss: 61.17  loss_ce: 2.113  loss_mask: 4.29  loss_ce_0: 1.317  loss_mask_0: 5.55  loss_ce_1: 1.119  loss_mask_1: 4.831  loss_ce_2: 1.447  loss_mask_2: 4.275  loss_ce_3: 1.734  loss_mask_3: 3.929  loss_ce_4: 1.95  loss_mask_4: 4.052  loss_ce_5: 2.086  loss_mask_5: 4.267  loss_ce_6: 1.99  loss_mask_6: 3.907  loss_ce_7: 2.062  loss_mask_7: 4.177  loss_ce_8: 1.933  loss_mask_8: 3.798  time: 2.4412  data_time: 0.3539  lr: 8.8495e-05  max_mem: 18490M
[01/24 07:00:10] d2.utils.events INFO:  eta: 1 day, 9:53:00  iter: 7639  total_loss: 59.12  loss_ce: 2.035  loss_mask: 4.194  loss_ce_0: 1.327  loss_mask_0: 4.838  loss_ce_1: 1.228  loss_mask_1: 4.339  loss_ce_2: 1.492  loss_mask_2: 4.04  loss_ce_3: 1.804  loss_mask_3: 3.882  loss_ce_4: 2.091  loss_mask_4: 4.057  loss_ce_5: 2.06  loss_mask_5: 3.922  loss_ce_6: 1.975  loss_mask_6: 3.717  loss_ce_7: 2.066  loss_mask_7: 3.811  loss_ce_8: 1.947  loss_mask_8: 3.818  time: 2.4414  data_time: 0.3953  lr: 8.8465e-05  max_mem: 18490M
[01/24 07:00:58] d2.utils.events INFO:  eta: 1 day, 9:53:08  iter: 7659  total_loss: 58.64  loss_ce: 2.026  loss_mask: 4.27  loss_ce_0: 1.335  loss_mask_0: 4.836  loss_ce_1: 1.205  loss_mask_1: 4.301  loss_ce_2: 1.511  loss_mask_2: 4.151  loss_ce_3: 1.829  loss_mask_3: 3.826  loss_ce_4: 1.988  loss_mask_4: 3.953  loss_ce_5: 2.044  loss_mask_5: 3.841  loss_ce_6: 2.02  loss_mask_6: 3.97  loss_ce_7: 2.13  loss_mask_7: 4.001  loss_ce_8: 1.951  loss_mask_8: 4.076  time: 2.4413  data_time: 0.4036  lr: 8.8434e-05  max_mem: 18490M
[01/24 07:01:45] d2.utils.events INFO:  eta: 1 day, 9:53:19  iter: 7679  total_loss: 58.33  loss_ce: 2.031  loss_mask: 4.131  loss_ce_0: 1.37  loss_mask_0: 4.961  loss_ce_1: 1.208  loss_mask_1: 4.296  loss_ce_2: 1.515  loss_mask_2: 3.908  loss_ce_3: 1.79  loss_mask_3: 3.742  loss_ce_4: 1.992  loss_mask_4: 3.751  loss_ce_5: 2.036  loss_mask_5: 3.789  loss_ce_6: 2.033  loss_mask_6: 3.787  loss_ce_7: 2.143  loss_mask_7: 3.961  loss_ce_8: 1.932  loss_mask_8: 4.042  time: 2.4411  data_time: 0.3788  lr: 8.8404e-05  max_mem: 18490M
[01/24 07:02:38] d2.utils.events INFO:  eta: 1 day, 9:57:02  iter: 7699  total_loss: 62.38  loss_ce: 2.014  loss_mask: 4.113  loss_ce_0: 1.379  loss_mask_0: 5.213  loss_ce_1: 1.273  loss_mask_1: 4.977  loss_ce_2: 1.595  loss_mask_2: 4.267  loss_ce_3: 1.89  loss_mask_3: 4.108  loss_ce_4: 2.095  loss_mask_4: 4.969  loss_ce_5: 2.061  loss_mask_5: 5.071  loss_ce_6: 2.064  loss_mask_6: 3.924  loss_ce_7: 2.071  loss_mask_7: 3.811  loss_ce_8: 1.966  loss_mask_8: 3.812  time: 2.4417  data_time: 0.4201  lr: 8.8374e-05  max_mem: 18490M
[01/24 07:03:26] d2.utils.events INFO:  eta: 1 day, 9:54:17  iter: 7719  total_loss: 61.3  loss_ce: 2.001  loss_mask: 3.877  loss_ce_0: 1.384  loss_mask_0: 4.872  loss_ce_1: 1.389  loss_mask_1: 4.553  loss_ce_2: 1.553  loss_mask_2: 4.166  loss_ce_3: 1.837  loss_mask_3: 3.894  loss_ce_4: 2.03  loss_mask_4: 4.592  loss_ce_5: 2.095  loss_mask_5: 4.52  loss_ce_6: 2.067  loss_mask_6: 4.271  loss_ce_7: 2.088  loss_mask_7: 3.964  loss_ce_8: 2.097  loss_mask_8: 4.089  time: 2.4415  data_time: 0.3681  lr: 8.8343e-05  max_mem: 18490M
[01/24 07:04:13] d2.utils.events INFO:  eta: 1 day, 9:55:53  iter: 7739  total_loss: 59.46  loss_ce: 1.972  loss_mask: 3.831  loss_ce_0: 1.298  loss_mask_0: 4.856  loss_ce_1: 1.386  loss_mask_1: 4.479  loss_ce_2: 1.538  loss_mask_2: 3.934  loss_ce_3: 1.839  loss_mask_3: 3.77  loss_ce_4: 2.047  loss_mask_4: 4.195  loss_ce_5: 2.021  loss_mask_5: 3.844  loss_ce_6: 2.062  loss_mask_6: 4.025  loss_ce_7: 2.036  loss_mask_7: 3.975  loss_ce_8: 2.079  loss_mask_8: 3.944  time: 2.4413  data_time: 0.3726  lr: 8.8313e-05  max_mem: 18490M
[01/24 07:05:05] d2.utils.events INFO:  eta: 1 day, 9:58:44  iter: 7759  total_loss: 59.32  loss_ce: 1.938  loss_mask: 3.798  loss_ce_0: 1.345  loss_mask_0: 4.524  loss_ce_1: 1.496  loss_mask_1: 4.307  loss_ce_2: 1.555  loss_mask_2: 3.755  loss_ce_3: 1.773  loss_mask_3: 3.698  loss_ce_4: 1.966  loss_mask_4: 3.861  loss_ce_5: 2.018  loss_mask_5: 3.733  loss_ce_6: 2.297  loss_mask_6: 4.344  loss_ce_7: 2.094  loss_mask_7: 4.032  loss_ce_8: 2.055  loss_mask_8: 4  time: 2.4417  data_time: 0.4095  lr: 8.8282e-05  max_mem: 18490M
[01/24 07:05:52] d2.utils.events INFO:  eta: 1 day, 9:56:18  iter: 7779  total_loss: 60.46  loss_ce: 1.966  loss_mask: 4.403  loss_ce_0: 1.173  loss_mask_0: 4.677  loss_ce_1: 1.277  loss_mask_1: 4.348  loss_ce_2: 1.528  loss_mask_2: 3.912  loss_ce_3: 1.782  loss_mask_3: 3.739  loss_ce_4: 1.946  loss_mask_4: 3.85  loss_ce_5: 2.028  loss_mask_5: 3.973  loss_ce_6: 2.218  loss_mask_6: 4.327  loss_ce_7: 2.119  loss_mask_7: 4.354  loss_ce_8: 2.094  loss_mask_8: 4.535  time: 2.4415  data_time: 0.3702  lr: 8.8252e-05  max_mem: 18490M
[01/24 07:06:40] d2.utils.events INFO:  eta: 1 day, 9:58:33  iter: 7799  total_loss: 56.84  loss_ce: 1.952  loss_mask: 4.079  loss_ce_0: 1.168  loss_mask_0: 4.523  loss_ce_1: 1.255  loss_mask_1: 4.32  loss_ce_2: 1.434  loss_mask_2: 3.847  loss_ce_3: 1.78  loss_mask_3: 3.656  loss_ce_4: 1.887  loss_mask_4: 3.608  loss_ce_5: 1.934  loss_mask_5: 3.559  loss_ce_6: 2.086  loss_mask_6: 3.852  loss_ce_7: 2.089  loss_mask_7: 4.036  loss_ce_8: 2.056  loss_mask_8: 4.099  time: 2.4414  data_time: 0.3778  lr: 8.8222e-05  max_mem: 18490M
[01/24 07:07:31] d2.utils.events INFO:  eta: 1 day, 9:59:59  iter: 7819  total_loss: 56.89  loss_ce: 1.892  loss_mask: 3.607  loss_ce_0: 1.141  loss_mask_0: 4.434  loss_ce_1: 1.248  loss_mask_1: 4.355  loss_ce_2: 1.452  loss_mask_2: 3.777  loss_ce_3: 1.961  loss_mask_3: 3.881  loss_ce_4: 1.91  loss_mask_4: 3.947  loss_ce_5: 1.915  loss_mask_5: 3.599  loss_ce_6: 1.939  loss_mask_6: 3.757  loss_ce_7: 2.024  loss_mask_7: 4.049  loss_ce_8: 1.97  loss_mask_8: 3.7  time: 2.4416  data_time: 0.4014  lr: 8.8191e-05  max_mem: 18490M
[01/24 07:08:17] d2.utils.events INFO:  eta: 1 day, 9:58:09  iter: 7839  total_loss: 55.15  loss_ce: 1.883  loss_mask: 3.631  loss_ce_0: 1.144  loss_mask_0: 4.446  loss_ce_1: 1.217  loss_mask_1: 4.303  loss_ce_2: 1.493  loss_mask_2: 3.826  loss_ce_3: 1.827  loss_mask_3: 3.599  loss_ce_4: 1.919  loss_mask_4: 3.552  loss_ce_5: 1.948  loss_mask_5: 3.605  loss_ce_6: 2.119  loss_mask_6: 3.679  loss_ce_7: 1.98  loss_mask_7: 3.775  loss_ce_8: 1.955  loss_mask_8: 3.601  time: 2.4413  data_time: 0.3719  lr: 8.8161e-05  max_mem: 18490M
[01/24 07:09:06] d2.utils.events INFO:  eta: 1 day, 10:00:15  iter: 7859  total_loss: 57.62  loss_ce: 1.973  loss_mask: 3.645  loss_ce_0: 1.148  loss_mask_0: 4.537  loss_ce_1: 1.269  loss_mask_1: 4.503  loss_ce_2: 1.638  loss_mask_2: 3.949  loss_ce_3: 1.829  loss_mask_3: 3.654  loss_ce_4: 1.994  loss_mask_4: 3.722  loss_ce_5: 2.038  loss_mask_5: 3.847  loss_ce_6: 2.115  loss_mask_6: 3.768  loss_ce_7: 1.921  loss_mask_7: 3.956  loss_ce_8: 1.936  loss_mask_8: 3.641  time: 2.4413  data_time: 0.3768  lr: 8.813e-05  max_mem: 18490M
[01/24 07:09:56] d2.utils.events INFO:  eta: 1 day, 10:01:46  iter: 7879  total_loss: 55.43  loss_ce: 1.924  loss_mask: 3.544  loss_ce_0: 1.227  loss_mask_0: 4.518  loss_ce_1: 1.387  loss_mask_1: 4.251  loss_ce_2: 1.645  loss_mask_2: 3.797  loss_ce_3: 1.846  loss_mask_3: 3.536  loss_ce_4: 1.971  loss_mask_4: 3.512  loss_ce_5: 1.948  loss_mask_5: 3.582  loss_ce_6: 1.992  loss_mask_6: 3.659  loss_ce_7: 1.995  loss_mask_7: 3.821  loss_ce_8: 1.968  loss_mask_8: 3.419  time: 2.4414  data_time: 0.4122  lr: 8.81e-05  max_mem: 18490M
[01/24 07:10:43] d2.utils.events INFO:  eta: 1 day, 9:56:21  iter: 7899  total_loss: 57.87  loss_ce: 1.973  loss_mask: 3.807  loss_ce_0: 1.098  loss_mask_0: 4.69  loss_ce_1: 1.228  loss_mask_1: 4.614  loss_ce_2: 1.728  loss_mask_2: 3.819  loss_ce_3: 1.868  loss_mask_3: 3.721  loss_ce_4: 1.929  loss_mask_4: 3.877  loss_ce_5: 1.955  loss_mask_5: 3.913  loss_ce_6: 1.929  loss_mask_6: 3.931  loss_ce_7: 1.987  loss_mask_7: 3.943  loss_ce_8: 1.945  loss_mask_8: 3.579  time: 2.4411  data_time: 0.3648  lr: 8.8069e-05  max_mem: 18490M
[01/24 07:11:30] d2.utils.events INFO:  eta: 1 day, 9:55:34  iter: 7919  total_loss: 53.33  loss_ce: 1.915  loss_mask: 3.424  loss_ce_0: 1.001  loss_mask_0: 3.973  loss_ce_1: 1.151  loss_mask_1: 3.888  loss_ce_2: 1.681  loss_mask_2: 3.351  loss_ce_3: 1.853  loss_mask_3: 3.343  loss_ce_4: 1.93  loss_mask_4: 3.318  loss_ce_5: 1.968  loss_mask_5: 3.329  loss_ce_6: 2.063  loss_mask_6: 3.585  loss_ce_7: 1.977  loss_mask_7: 4.02  loss_ce_8: 1.87  loss_mask_8: 3.47  time: 2.4410  data_time: 0.3755  lr: 8.8039e-05  max_mem: 18490M
[01/24 07:12:19] d2.utils.events INFO:  eta: 1 day, 9:58:22  iter: 7939  total_loss: 56.15  loss_ce: 2  loss_mask: 3.754  loss_ce_0: 1.063  loss_mask_0: 4.395  loss_ce_1: 1.206  loss_mask_1: 4.583  loss_ce_2: 1.738  loss_mask_2: 3.796  loss_ce_3: 1.884  loss_mask_3: 3.555  loss_ce_4: 1.952  loss_mask_4: 3.643  loss_ce_5: 2.06  loss_mask_5: 3.666  loss_ce_6: 2.016  loss_mask_6: 3.627  loss_ce_7: 1.949  loss_mask_7: 3.871  loss_ce_8: 1.946  loss_mask_8: 3.653  time: 2.4409  data_time: 0.4123  lr: 8.8009e-05  max_mem: 18490M
[01/24 07:13:05] d2.utils.events INFO:  eta: 1 day, 9:54:00  iter: 7959  total_loss: 54.61  loss_ce: 1.895  loss_mask: 3.706  loss_ce_0: 1.151  loss_mask_0: 4.165  loss_ce_1: 1.167  loss_mask_1: 4.174  loss_ce_2: 1.674  loss_mask_2: 3.586  loss_ce_3: 1.856  loss_mask_3: 3.364  loss_ce_4: 1.892  loss_mask_4: 3.642  loss_ce_5: 2.028  loss_mask_5: 3.443  loss_ce_6: 2.022  loss_mask_6: 3.863  loss_ce_7: 1.952  loss_mask_7: 3.603  loss_ce_8: 1.908  loss_mask_8: 3.495  time: 2.4406  data_time: 0.3780  lr: 8.7978e-05  max_mem: 18490M
[01/24 07:13:55] d2.utils.events INFO:  eta: 1 day, 9:56:35  iter: 7979  total_loss: 54.2  loss_ce: 1.844  loss_mask: 3.362  loss_ce_0: 1.051  loss_mask_0: 4.43  loss_ce_1: 1.146  loss_mask_1: 4.328  loss_ce_2: 1.563  loss_mask_2: 3.733  loss_ce_3: 1.786  loss_mask_3: 3.38  loss_ce_4: 1.901  loss_mask_4: 3.465  loss_ce_5: 1.917  loss_mask_5: 3.376  loss_ce_6: 1.981  loss_mask_6: 3.522  loss_ce_7: 1.936  loss_mask_7: 3.587  loss_ce_8: 1.935  loss_mask_8: 3.704  time: 2.4407  data_time: 0.4438  lr: 8.7948e-05  max_mem: 18490M
[01/24 07:14:42] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 07:14:42] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 07:14:42] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 07:18:16] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 18.65019354966455, 'error_1pix': 0.9645577157596712, 'error_3pix': 0.9178404091810063, 'mIoU': 0.0488148817709268, 'fwIoU': 0.08944989332401738, 'IoU-0': nan, 'IoU-1': 1.9516552528157085e-05, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.003776812801128133, 'IoU-11': 0.0, 'IoU-12': 0.007856004408667024, 'IoU-13': 0.0058142222516285175, 'IoU-14': 0.059945907492010064, 'IoU-15': 0.0006072997711713076, 'IoU-16': 0.00795187362573944, 'IoU-17': 0.0006184139113646081, 'IoU-18': 0.0, 'IoU-19': 0.01052818058050907, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.003024280440441624, 'IoU-23': 0.0, 'IoU-24': 0.05940385763610009, 'IoU-25': 0.0, 'IoU-26': 1.0137727235283072, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.375991038881647, 'IoU-30': 0.09983857828230619, 'IoU-31': 0.0, 'IoU-32': 5.348424876839815e-06, 'IoU-33': 0.02844932023542026, 'IoU-34': 1.1788300099017965, 'IoU-35': 0.0, 'IoU-36': 0.008092155682336923, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.21088591331821419, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 5.46106576848882e-05, 'IoU-44': 1.4747461812038474, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0002548568934674371, 'IoU-48': 0.00023739921249405676, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.03888680275262555, 'IoU-52': 0.0, 'IoU-53': 0.45236885134643956, 'IoU-54': 0.0, 'IoU-55': 0.28632254659199435, 'IoU-56': 0.055007023422325524, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 1.4724172066925505, 'IoU-60': 0.0, 'IoU-61': 0.0005678620217089536, 'IoU-62': 0.0, 'IoU-63': 0.3566513065301334, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.11870561423021335, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0657614978022797, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.3722132535440646, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 1.010823176591939, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.055269956392411806, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0008143491646688798, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.019938554610283925, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0363545471387807, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0014035734981262295, 'IoU-114': 0.006337201450284135, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0013524472774994795, 'IoU-124': 0.0, 'IoU-125': 0.20157256289541592, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.09626159549599002, 'IoU-133': 0.0, 'IoU-134': 0.000896098730779544, 'IoU-135': 0.17048370667217375, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.001343059471568774, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.7031308454624979, 'pACC': 1.1423427195401552, 'ACC-0': nan, 'ACC-1': 1.9516564547543778e-05, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.004008573234700405, 'ACC-11': 0.0, 'ACC-12': 0.007926188262567585, 'ACC-13': 0.006987306534899702, 'ACC-14': 0.07971889962012826, 'ACC-15': 0.0006380571614142339, 'ACC-16': 0.010457827479955677, 'ACC-17': 0.0006188133316769139, 'ACC-18': 0.0, 'ACC-19': 0.01057640692063468, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0034194880018436273, 'ACC-23': 0.0, 'ACC-24': 0.07010032715668651, 'ACC-25': 0.0, 'ACC-26': 3.258464329129456, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 5.387877905790454, 'ACC-30': 0.10424224575782669, 'ACC-31': 0.0, 'ACC-32': 5.4136807285038575e-06, 'ACC-33': 0.02948774533237099, 'ACC-34': 5.615227490745835, 'ACC-35': 0.0, 'ACC-36': 0.008094742133412311, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.24369602403531623, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 5.4610774989881535e-05, 'ACC-44': 30.886907503658247, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0002598615210734275, 'ACC-48': 0.0002388962356854703, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.03979449049175633, 'ACC-52': 0.0, 'ACC-53': 2.792025582652641, 'ACC-54': 0.0, 'ACC-55': 0.5001107149201462, 'ACC-56': 0.056587313888387, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 78.40466311900174, 'ACC-60': 0.0, 'ACC-61': 0.0005759460874396342, 'ACC-62': 0.0, 'ACC-63': 0.6350464166028447, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.15773512273556634, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.07839971804483409, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 2.5543322611852903, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 3.197205965128122, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.057874986899918504, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0008160044790319322, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.02177292196481599, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.03983086764670445, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0014564596586682755, 'ACC-114': 0.006669103501206451, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.001381572584863096, 'ACC-124': 0.0, 'ACC-125': 0.33969172133314046, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.10495521307717828, 'ACC-133': 0.0, 'ACC-134': 0.0008961654459284791, 'ACC-135': 0.278846702012428, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.001425786392484775, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 07:18:16] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 07:18:16] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 07:18:16] d2.evaluation.testing INFO: copypaste: 18.6502,0.9646,0.9178,0.0488,0.0894,0.7031,1.1423
[01/24 07:18:16] d2.utils.events INFO:  eta: 1 day, 9:55:47  iter: 7999  total_loss: 59.41  loss_ce: 2.026  loss_mask: 4.738  loss_ce_0: 1.223  loss_mask_0: 4.416  loss_ce_1: 1.198  loss_mask_1: 4.248  loss_ce_2: 1.587  loss_mask_2: 3.757  loss_ce_3: 1.815  loss_mask_3: 3.609  loss_ce_4: 1.929  loss_mask_4: 3.719  loss_ce_5: 1.909  loss_mask_5: 3.773  loss_ce_6: 2.015  loss_mask_6: 3.69  loss_ce_7: 2.051  loss_mask_7: 3.863  loss_ce_8: 2.07  loss_mask_8: 4.847  time: 2.4405  data_time: 0.3841  lr: 8.7917e-05  max_mem: 18490M
[01/24 07:19:07] d2.utils.events INFO:  eta: 1 day, 9:59:11  iter: 8019  total_loss: 55.58  loss_ce: 1.966  loss_mask: 3.712  loss_ce_0: 1.266  loss_mask_0: 4.676  loss_ce_1: 1.193  loss_mask_1: 4.393  loss_ce_2: 1.491  loss_mask_2: 3.528  loss_ce_3: 1.75  loss_mask_3: 3.312  loss_ce_4: 1.891  loss_mask_4: 3.651  loss_ce_5: 1.923  loss_mask_5: 3.751  loss_ce_6: 1.92  loss_mask_6: 3.673  loss_ce_7: 1.99  loss_mask_7: 3.612  loss_ce_8: 2.005  loss_mask_8: 4.023  time: 2.4408  data_time: 0.4217  lr: 8.7887e-05  max_mem: 18490M
[01/24 07:19:54] d2.utils.events INFO:  eta: 1 day, 10:00:20  iter: 8039  total_loss: 55.11  loss_ce: 1.943  loss_mask: 3.582  loss_ce_0: 1.231  loss_mask_0: 4.399  loss_ce_1: 1.269  loss_mask_1: 4.137  loss_ce_2: 1.535  loss_mask_2: 3.661  loss_ce_3: 1.739  loss_mask_3: 3.461  loss_ce_4: 1.921  loss_mask_4: 3.705  loss_ce_5: 1.919  loss_mask_5: 3.651  loss_ce_6: 1.889  loss_mask_6: 3.861  loss_ce_7: 1.899  loss_mask_7: 3.486  loss_ce_8: 2.045  loss_mask_8: 3.801  time: 2.4405  data_time: 0.3577  lr: 8.7856e-05  max_mem: 18490M
[01/24 07:20:40] d2.utils.events INFO:  eta: 1 day, 10:00:26  iter: 8059  total_loss: 54.64  loss_ce: 1.852  loss_mask: 3.41  loss_ce_0: 1.175  loss_mask_0: 4.468  loss_ce_1: 1.254  loss_mask_1: 4.23  loss_ce_2: 1.48  loss_mask_2: 3.683  loss_ce_3: 1.731  loss_mask_3: 3.432  loss_ce_4: 1.872  loss_mask_4: 3.578  loss_ce_5: 1.919  loss_mask_5: 3.611  loss_ce_6: 1.914  loss_mask_6: 3.452  loss_ce_7: 1.961  loss_mask_7: 3.608  loss_ce_8: 1.959  loss_mask_8: 3.552  time: 2.4403  data_time: 0.3518  lr: 8.7826e-05  max_mem: 18490M
[01/24 07:21:30] d2.utils.events INFO:  eta: 1 day, 10:03:27  iter: 8079  total_loss: 55.27  loss_ce: 1.856  loss_mask: 3.552  loss_ce_0: 1.053  loss_mask_0: 4.279  loss_ce_1: 1.187  loss_mask_1: 4.253  loss_ce_2: 1.544  loss_mask_2: 3.719  loss_ce_3: 1.736  loss_mask_3: 3.632  loss_ce_4: 1.894  loss_mask_4: 3.638  loss_ce_5: 1.948  loss_mask_5: 3.925  loss_ce_6: 1.885  loss_mask_6: 3.464  loss_ce_7: 1.921  loss_mask_7: 3.559  loss_ce_8: 1.966  loss_mask_8: 3.46  time: 2.4404  data_time: 0.3939  lr: 8.7796e-05  max_mem: 18490M
[01/24 07:22:17] d2.utils.events INFO:  eta: 1 day, 10:03:12  iter: 8099  total_loss: 56.4  loss_ce: 1.876  loss_mask: 3.471  loss_ce_0: 1.057  loss_mask_0: 4.504  loss_ce_1: 1.215  loss_mask_1: 4.541  loss_ce_2: 1.63  loss_mask_2: 4.011  loss_ce_3: 1.743  loss_mask_3: 3.746  loss_ce_4: 1.913  loss_mask_4: 3.738  loss_ce_5: 1.978  loss_mask_5: 4.159  loss_ce_6: 1.922  loss_mask_6: 3.891  loss_ce_7: 1.961  loss_mask_7: 3.738  loss_ce_8: 1.971  loss_mask_8: 3.688  time: 2.4401  data_time: 0.3879  lr: 8.7765e-05  max_mem: 18490M
[01/24 07:23:03] d2.utils.events INFO:  eta: 1 day, 10:02:42  iter: 8119  total_loss: 55.69  loss_ce: 1.877  loss_mask: 3.531  loss_ce_0: 1.118  loss_mask_0: 4.477  loss_ce_1: 1.198  loss_mask_1: 4.39  loss_ce_2: 1.579  loss_mask_2: 4.018  loss_ce_3: 1.751  loss_mask_3: 3.779  loss_ce_4: 1.9  loss_mask_4: 3.585  loss_ce_5: 1.952  loss_mask_5: 3.898  loss_ce_6: 1.941  loss_mask_6: 3.534  loss_ce_7: 1.988  loss_mask_7: 3.557  loss_ce_8: 1.992  loss_mask_8: 3.579  time: 2.4398  data_time: 0.3768  lr: 8.7735e-05  max_mem: 18490M
[01/24 07:23:54] d2.utils.events INFO:  eta: 1 day, 10:08:16  iter: 8139  total_loss: 54.95  loss_ce: 1.859  loss_mask: 3.312  loss_ce_0: 1.22  loss_mask_0: 4.371  loss_ce_1: 1.22  loss_mask_1: 4.356  loss_ce_2: 1.541  loss_mask_2: 3.973  loss_ce_3: 1.712  loss_mask_3: 3.706  loss_ce_4: 1.89  loss_mask_4: 3.453  loss_ce_5: 1.865  loss_mask_5: 3.503  loss_ce_6: 1.918  loss_mask_6: 3.394  loss_ce_7: 2.058  loss_mask_7: 3.501  loss_ce_8: 1.984  loss_mask_8: 3.47  time: 2.4400  data_time: 0.4362  lr: 8.7704e-05  max_mem: 18490M
[01/24 07:24:42] d2.utils.events INFO:  eta: 1 day, 10:09:31  iter: 8159  total_loss: 54.36  loss_ce: 1.902  loss_mask: 3.312  loss_ce_0: 1.173  loss_mask_0: 4.538  loss_ce_1: 1.184  loss_mask_1: 4.245  loss_ce_2: 1.599  loss_mask_2: 3.864  loss_ce_3: 1.855  loss_mask_3: 3.74  loss_ce_4: 1.958  loss_mask_4: 3.477  loss_ce_5: 1.898  loss_mask_5: 3.507  loss_ce_6: 1.942  loss_mask_6: 3.349  loss_ce_7: 2.042  loss_mask_7: 3.381  loss_ce_8: 1.967  loss_mask_8: 3.457  time: 2.4399  data_time: 0.3800  lr: 8.7674e-05  max_mem: 18490M
[01/24 07:25:31] d2.utils.events INFO:  eta: 1 day, 10:11:36  iter: 8179  total_loss: 58.53  loss_ce: 2.051  loss_mask: 3.824  loss_ce_0: 1.161  loss_mask_0: 4.727  loss_ce_1: 1.239  loss_mask_1: 4.384  loss_ce_2: 1.682  loss_mask_2: 4.149  loss_ce_3: 1.898  loss_mask_3: 3.918  loss_ce_4: 2.025  loss_mask_4: 3.726  loss_ce_5: 1.987  loss_mask_5: 3.926  loss_ce_6: 2.129  loss_mask_6: 4.128  loss_ce_7: 2.022  loss_mask_7: 3.756  loss_ce_8: 2.109  loss_mask_8: 3.754  time: 2.4399  data_time: 0.3813  lr: 8.7643e-05  max_mem: 18490M
[01/24 07:26:21] d2.utils.events INFO:  eta: 1 day, 10:15:06  iter: 8199  total_loss: 58.63  loss_ce: 1.946  loss_mask: 3.725  loss_ce_0: 1.161  loss_mask_0: 4.67  loss_ce_1: 1.242  loss_mask_1: 4.553  loss_ce_2: 1.635  loss_mask_2: 3.999  loss_ce_3: 1.844  loss_mask_3: 3.95  loss_ce_4: 2.005  loss_mask_4: 3.766  loss_ce_5: 1.992  loss_mask_5: 3.972  loss_ce_6: 2.063  loss_mask_6: 4.565  loss_ce_7: 1.983  loss_mask_7: 3.675  loss_ce_8: 2.009  loss_mask_8: 3.664  time: 2.4402  data_time: 0.4177  lr: 8.7613e-05  max_mem: 18490M
[01/24 07:27:07] d2.utils.events INFO:  eta: 1 day, 10:11:31  iter: 8219  total_loss: 55.57  loss_ce: 1.906  loss_mask: 3.624  loss_ce_0: 1.129  loss_mask_0: 4.534  loss_ce_1: 1.243  loss_mask_1: 4.202  loss_ce_2: 1.609  loss_mask_2: 3.835  loss_ce_3: 1.824  loss_mask_3: 3.604  loss_ce_4: 1.935  loss_mask_4: 3.622  loss_ce_5: 1.922  loss_mask_5: 3.675  loss_ce_6: 1.98  loss_mask_6: 3.59  loss_ce_7: 1.966  loss_mask_7: 3.561  loss_ce_8: 2  loss_mask_8: 3.522  time: 2.4398  data_time: 0.3602  lr: 8.7582e-05  max_mem: 18490M
[01/24 07:27:56] d2.utils.events INFO:  eta: 1 day, 10:12:44  iter: 8239  total_loss: 51.87  loss_ce: 1.873  loss_mask: 3.16  loss_ce_0: 1.089  loss_mask_0: 4.182  loss_ce_1: 1.159  loss_mask_1: 3.872  loss_ce_2: 1.645  loss_mask_2: 3.458  loss_ce_3: 1.852  loss_mask_3: 3.321  loss_ce_4: 1.905  loss_mask_4: 3.277  loss_ce_5: 1.879  loss_mask_5: 3.329  loss_ce_6: 1.949  loss_mask_6: 3.437  loss_ce_7: 1.985  loss_mask_7: 3.484  loss_ce_8: 1.936  loss_mask_8: 3.387  time: 2.4397  data_time: 0.3891  lr: 8.7552e-05  max_mem: 18490M
[01/24 07:28:43] d2.utils.events INFO:  eta: 1 day, 10:13:40  iter: 8259  total_loss: 53.1  loss_ce: 1.826  loss_mask: 3.298  loss_ce_0: 1.093  loss_mask_0: 4.162  loss_ce_1: 1.153  loss_mask_1: 4.05  loss_ce_2: 1.631  loss_mask_2: 3.557  loss_ce_3: 1.794  loss_mask_3: 3.393  loss_ce_4: 1.924  loss_mask_4: 3.326  loss_ce_5: 1.911  loss_mask_5: 3.459  loss_ce_6: 1.882  loss_mask_6: 3.353  loss_ce_7: 1.963  loss_mask_7: 3.698  loss_ce_8: 1.907  loss_mask_8: 3.495  time: 2.4396  data_time: 0.3872  lr: 8.7522e-05  max_mem: 18490M
[01/24 07:29:31] d2.utils.events INFO:  eta: 1 day, 10:12:52  iter: 8279  total_loss: 53.38  loss_ce: 1.838  loss_mask: 3.535  loss_ce_0: 1.074  loss_mask_0: 4.179  loss_ce_1: 1.131  loss_mask_1: 4.057  loss_ce_2: 1.538  loss_mask_2: 3.575  loss_ce_3: 1.768  loss_mask_3: 3.374  loss_ce_4: 1.89  loss_mask_4: 3.468  loss_ce_5: 1.926  loss_mask_5: 3.389  loss_ce_6: 1.901  loss_mask_6: 3.483  loss_ce_7: 1.938  loss_mask_7: 3.56  loss_ce_8: 1.91  loss_mask_8: 3.568  time: 2.4395  data_time: 0.3786  lr: 8.7491e-05  max_mem: 18490M
[01/24 07:30:21] d2.utils.events INFO:  eta: 1 day, 10:13:45  iter: 8299  total_loss: 53.29  loss_ce: 1.803  loss_mask: 3.432  loss_ce_0: 1.165  loss_mask_0: 4.324  loss_ce_1: 1.21  loss_mask_1: 4.164  loss_ce_2: 1.573  loss_mask_2: 3.665  loss_ce_3: 1.745  loss_mask_3: 3.442  loss_ce_4: 1.884  loss_mask_4: 3.486  loss_ce_5: 1.861  loss_mask_5: 3.469  loss_ce_6: 1.921  loss_mask_6: 3.601  loss_ce_7: 1.912  loss_mask_7: 3.619  loss_ce_8: 1.886  loss_mask_8: 3.616  time: 2.4396  data_time: 0.4460  lr: 8.7461e-05  max_mem: 18490M
[01/24 07:31:07] d2.utils.events INFO:  eta: 1 day, 10:13:39  iter: 8319  total_loss: 51.76  loss_ce: 1.795  loss_mask: 3.327  loss_ce_0: 1.106  loss_mask_0: 4.114  loss_ce_1: 1.051  loss_mask_1: 4.045  loss_ce_2: 1.551  loss_mask_2: 3.415  loss_ce_3: 1.703  loss_mask_3: 3.394  loss_ce_4: 1.821  loss_mask_4: 3.401  loss_ce_5: 1.834  loss_mask_5: 3.332  loss_ce_6: 1.862  loss_mask_6: 3.483  loss_ce_7: 1.903  loss_mask_7: 3.622  loss_ce_8: 1.856  loss_mask_8: 3.442  time: 2.4393  data_time: 0.3761  lr: 8.743e-05  max_mem: 18490M
[01/24 07:31:54] d2.utils.events INFO:  eta: 1 day, 10:10:47  iter: 8339  total_loss: 53.54  loss_ce: 1.871  loss_mask: 3.608  loss_ce_0: 1.068  loss_mask_0: 4.069  loss_ce_1: 1.142  loss_mask_1: 4.151  loss_ce_2: 1.51  loss_mask_2: 3.48  loss_ce_3: 1.705  loss_mask_3: 3.361  loss_ce_4: 1.854  loss_mask_4: 3.43  loss_ce_5: 1.891  loss_mask_5: 3.498  loss_ce_6: 1.935  loss_mask_6: 3.591  loss_ce_7: 1.945  loss_mask_7: 3.802  loss_ce_8: 1.961  loss_mask_8: 3.71  time: 2.4391  data_time: 0.3865  lr: 8.74e-05  max_mem: 18490M
[01/24 07:32:44] d2.utils.events INFO:  eta: 1 day, 10:12:03  iter: 8359  total_loss: 51.38  loss_ce: 1.779  loss_mask: 3.236  loss_ce_0: 1.065  loss_mask_0: 3.96  loss_ce_1: 1.117  loss_mask_1: 3.992  loss_ce_2: 1.532  loss_mask_2: 3.369  loss_ce_3: 1.7  loss_mask_3: 3.274  loss_ce_4: 1.819  loss_mask_4: 3.236  loss_ce_5: 1.832  loss_mask_5: 3.34  loss_ce_6: 1.913  loss_mask_6: 3.64  loss_ce_7: 1.931  loss_mask_7: 3.564  loss_ce_8: 1.857  loss_mask_8: 3.19  time: 2.4392  data_time: 0.4139  lr: 8.7369e-05  max_mem: 18490M
[01/24 07:33:30] d2.utils.events INFO:  eta: 1 day, 10:10:49  iter: 8379  total_loss: 50.69  loss_ce: 1.749  loss_mask: 3.308  loss_ce_0: 1.016  loss_mask_0: 3.821  loss_ce_1: 0.9973  loss_mask_1: 3.789  loss_ce_2: 1.564  loss_mask_2: 3.436  loss_ce_3: 1.68  loss_mask_3: 3.325  loss_ce_4: 1.771  loss_mask_4: 3.283  loss_ce_5: 1.802  loss_mask_5: 3.305  loss_ce_6: 1.892  loss_mask_6: 3.426  loss_ce_7: 1.896  loss_mask_7: 3.558  loss_ce_8: 1.851  loss_mask_8: 3.194  time: 2.4388  data_time: 0.3760  lr: 8.7339e-05  max_mem: 18490M
[01/24 07:34:16] d2.utils.events INFO:  eta: 1 day, 10:07:55  iter: 8399  total_loss: 55.44  loss_ce: 1.831  loss_mask: 3.528  loss_ce_0: 1.012  loss_mask_0: 4.358  loss_ce_1: 1.237  loss_mask_1: 4.418  loss_ce_2: 1.597  loss_mask_2: 3.623  loss_ce_3: 1.759  loss_mask_3: 3.567  loss_ce_4: 1.913  loss_mask_4: 3.587  loss_ce_5: 1.888  loss_mask_5: 3.631  loss_ce_6: 2.022  loss_mask_6: 3.956  loss_ce_7: 1.99  loss_mask_7: 3.803  loss_ce_8: 1.944  loss_mask_8: 3.502  time: 2.4385  data_time: 0.3963  lr: 8.7308e-05  max_mem: 18490M
[01/24 07:35:02] d2.utils.events INFO:  eta: 1 day, 10:07:08  iter: 8419  total_loss: 51.89  loss_ce: 1.794  loss_mask: 3.329  loss_ce_0: 1.079  loss_mask_0: 4.162  loss_ce_1: 1.067  loss_mask_1: 4.01  loss_ce_2: 1.504  loss_mask_2: 3.555  loss_ce_3: 1.718  loss_mask_3: 3.399  loss_ce_4: 1.823  loss_mask_4: 3.41  loss_ce_5: 1.833  loss_mask_5: 3.377  loss_ce_6: 1.943  loss_mask_6: 3.572  loss_ce_7: 1.949  loss_mask_7: 3.409  loss_ce_8: 1.871  loss_mask_8: 3.258  time: 2.4382  data_time: 0.3736  lr: 8.7278e-05  max_mem: 18490M
[01/24 07:35:47] d2.utils.events INFO:  eta: 1 day, 10:03:46  iter: 8439  total_loss: 51.03  loss_ce: 1.758  loss_mask: 3.192  loss_ce_0: 0.9452  loss_mask_0: 3.745  loss_ce_1: 1.032  loss_mask_1: 3.921  loss_ce_2: 1.505  loss_mask_2: 3.512  loss_ce_3: 1.712  loss_mask_3: 3.264  loss_ce_4: 1.806  loss_mask_4: 3.246  loss_ce_5: 1.851  loss_mask_5: 3.309  loss_ce_6: 1.947  loss_mask_6: 3.641  loss_ce_7: 1.886  loss_mask_7: 3.196  loss_ce_8: 1.866  loss_mask_8: 3.185  time: 2.4377  data_time: 0.3626  lr: 8.7248e-05  max_mem: 18490M
[01/24 07:36:31] d2.utils.events INFO:  eta: 1 day, 9:59:54  iter: 8459  total_loss: 52.46  loss_ce: 1.792  loss_mask: 3.394  loss_ce_0: 0.9587  loss_mask_0: 3.923  loss_ce_1: 1.141  loss_mask_1: 4.017  loss_ce_2: 1.55  loss_mask_2: 3.855  loss_ce_3: 1.736  loss_mask_3: 3.529  loss_ce_4: 1.83  loss_mask_4: 3.425  loss_ce_5: 1.856  loss_mask_5: 3.35  loss_ce_6: 1.927  loss_mask_6: 3.843  loss_ce_7: 1.89  loss_mask_7: 3.431  loss_ce_8: 1.886  loss_mask_8: 3.314  time: 2.4372  data_time: 0.3630  lr: 8.7217e-05  max_mem: 18490M
[01/24 07:37:18] d2.utils.events INFO:  eta: 1 day, 9:59:07  iter: 8479  total_loss: 54.5  loss_ce: 1.808  loss_mask: 3.518  loss_ce_0: 0.9868  loss_mask_0: 4.541  loss_ce_1: 0.9933  loss_mask_1: 4.414  loss_ce_2: 1.518  loss_mask_2: 3.78  loss_ce_3: 1.759  loss_mask_3: 3.617  loss_ce_4: 1.881  loss_mask_4: 3.514  loss_ce_5: 1.864  loss_mask_5: 3.465  loss_ce_6: 1.936  loss_mask_6: 3.763  loss_ce_7: 1.946  loss_mask_7: 3.691  loss_ce_8: 1.893  loss_mask_8: 3.489  time: 2.4370  data_time: 0.4158  lr: 8.7187e-05  max_mem: 18490M
[01/24 07:38:05] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 07:38:05] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 07:38:05] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 07:41:32] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 11.585803353544971, 'error_1pix': 0.9054496685973332, 'error_3pix': 0.7958713869850559, 'mIoU': 0.36691573162860225, 'fwIoU': 1.408609955753169, 'IoU-0': nan, 'IoU-1': 7.805151482025736, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.025652602911641363, 'IoU-13': 0.724692230839394, 'IoU-14': 0.1856327541656494, 'IoU-15': 0.00029297190431176273, 'IoU-16': 0.00012072943388221728, 'IoU-17': 0.0251485860523631, 'IoU-18': 0.00012279738964734047, 'IoU-19': 0.023649584828770713, 'IoU-20': 0.0017060604641336026, 'IoU-21': 0.000797228118709462, 'IoU-22': 0.016573686189210235, 'IoU-23': 0.3226459412677474, 'IoU-24': 4.979700561890738e-05, 'IoU-25': 0.1454020672382858, 'IoU-26': 1.9238819674993672, 'IoU-27': 0.007661529937836494, 'IoU-28': 0.12496346764497333, 'IoU-29': 0.0001278147950587502, 'IoU-30': 0.1157861965666679, 'IoU-31': 2.5584510305215975, 'IoU-32': 0.10538682037710678, 'IoU-33': 3.6910702483884816, 'IoU-34': 9.500640847014951e-05, 'IoU-35': 0.6973483064338022, 'IoU-36': 0.0, 'IoU-37': 0.12358175026149938, 'IoU-38': 3.26738027274752, 'IoU-39': 5.207433758669571, 'IoU-40': 1.9575617156211547, 'IoU-41': 0.0004129799321880181, 'IoU-42': 0.8068709885365452, 'IoU-43': 3.458883838962606, 'IoU-44': 1.8546524673094196, 'IoU-45': 2.35889194798236, 'IoU-46': 4.5266163394718643e-05, 'IoU-47': 4.317013809444207, 'IoU-48': 0.0, 'IoU-49': 0.0004070937563314822, 'IoU-50': 1.7487839688605031, 'IoU-51': 0.03836408720768043, 'IoU-52': 5.226045544882403e-06, 'IoU-53': 0.0035185676388972227, 'IoU-54': 0.3293882331604031, 'IoU-55': 0.0, 'IoU-56': 0.14967371060212112, 'IoU-57': 2.0838310937006947, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 2.3116721028941147, 'IoU-62': 0.4073837104858721, 'IoU-63': 0.006080590919368789, 'IoU-64': 0.3561053729450982, 'IoU-65': 1.532899081691554, 'IoU-66': 0.0, 'IoU-67': 4.231862475472389e-05, 'IoU-68': 2.1578475357254963, 'IoU-69': 0.0, 'IoU-70': 0.6498730123720419, 'IoU-71': 0.0, 'IoU-72': 0.017031584963720512, 'IoU-73': 0.025178876536756985, 'IoU-74': 0.3127486790282662, 'IoU-75': 0.010489889837638726, 'IoU-76': 0.42123201421315637, 'IoU-77': 0.0, 'IoU-78': 0.0037325595600763216, 'IoU-79': 1.693272615798875, 'IoU-80': 3.316867665161767e-05, 'IoU-81': 0.7908975672290801, 'IoU-82': 0.0, 'IoU-83': 2.5015559552391946, 'IoU-84': 0.0736911375060282, 'IoU-85': 2.495030363266081, 'IoU-86': 1.2192606706594002, 'IoU-87': 0.000977857397100066, 'IoU-88': 0.000640767030802425, 'IoU-89': 0.05620872350739382, 'IoU-90': 0.09750573039082093, 'IoU-91': 0.05710982221458288, 'IoU-92': 0.00017062657776263627, 'IoU-93': 2.3337861481879587, 'IoU-94': 0.006548927461532631, 'IoU-95': 0.0, 'IoU-96': 0.9156551622213823, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.005019732742505019, 'IoU-100': 0.0, 'IoU-101': 0.024460561803049164, 'IoU-102': 0.6703035575507438, 'IoU-103': 0.05472053300399638, 'IoU-104': 2.4593403409777012e-05, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.001902248678488545, 'IoU-109': 0.0003270898588808545, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.007392386902281595, 'IoU-113': 0.0, 'IoU-114': 0.637193184213438, 'IoU-115': 0.0, 'IoU-116': 0.011898240591849116, 'IoU-117': 0.0007223429917279689, 'IoU-118': 0.7261576783182762, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.00036882372750849074, 'IoU-122': 0.001650579023121311, 'IoU-123': 0.5001764578322474, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.2885892840657775, 'IoU-128': 0.007782133777274133, 'IoU-129': 0.0, 'IoU-130': 0.00019346825379423492, 'IoU-131': 0.001394701992032931, 'IoU-132': 0.3434696621700055, 'IoU-133': 0.10475452479538297, 'IoU-134': 0.00034466713771175487, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.00530256030336705, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.00016536319131115647, 'IoU-141': 0.000168286140290058, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.008635224952061147, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.027094025261524796, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.09230467465486705, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0003498087420702731, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.15684605084589687, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.2257336343115124, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.24526053424416117, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0002553306659789761, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.689686818270925, 'pACC': 3.657591668507228, 'ACC-0': nan, 'ACC-1': 7.869517297719819, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.03472161178600939, 'ACC-13': 2.464060485041807, 'ACC-14': 0.23039372165761357, 'ACC-15': 0.0002933596144433259, 'ACC-16': 0.00012446641974117923, 'ACC-17': 0.025918277573720436, 'ACC-18': 0.0001283438229535764, 'ACC-19': 0.03294166763874066, 'ACC-20': 0.0017889975603123116, 'ACC-21': 0.0008260951237759874, 'ACC-22': 0.0197985013787526, 'ACC-23': 0.5991733496833007, 'ACC-24': 4.988903275985163e-05, 'ACC-25': 0.1970269458570537, 'ACC-26': 22.87993443684795, 'ACC-27': 0.00939170456759391, 'ACC-28': 0.1460211583125213, 'ACC-29': 0.00013710331239989777, 'ACC-30': 0.11758111950359595, 'ACC-31': 4.927553238246358, 'ACC-32': 0.1495854122092901, 'ACC-33': 26.903170019746764, 'ACC-34': 9.502970455783197e-05, 'ACC-35': 1.9940867707054863, 'ACC-36': 0.0, 'ACC-37': 0.12550362020269087, 'ACC-38': 20.984470758352632, 'ACC-39': 15.375366253180742, 'ACC-40': 4.3268825526270485, 'ACC-41': 0.00041310072421636056, 'ACC-42': 0.9284605091160328, 'ACC-43': 9.476811664220772, 'ACC-44': 5.473641430761827, 'ACC-45': 7.271161848893586, 'ACC-46': 4.5267396569142866e-05, 'ACC-47': 31.89085338992123, 'ACC-48': 0.0, 'ACC-49': 0.0004131641733268202, 'ACC-50': 3.7361775281832292, 'ACC-51': 0.03851241909878123, 'ACC-52': 5.226113005286736e-06, 'ACC-53': 0.003526239877365213, 'ACC-54': 0.3576991813519613, 'ACC-55': 0.0, 'ACC-56': 0.1611031481008443, 'ACC-57': 6.948781240317933, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 14.485670127462713, 'ACC-62': 0.45644199217257625, 'ACC-63': 0.006096283277775073, 'ACC-64': 0.4596091577217391, 'ACC-65': 2.292996591797662, 'ACC-66': 0.0, 'ACC-67': 4.232138734586287e-05, 'ACC-68': 37.30027169618699, 'ACC-69': 0.0, 'ACC-70': 0.8350104780063533, 'ACC-71': 0.0, 'ACC-72': 0.01715003024641698, 'ACC-73': 0.02533624388913664, 'ACC-74': 0.3326802310210999, 'ACC-75': 0.010516096835452023, 'ACC-76': 0.5537247745131556, 'ACC-77': 0.0, 'ACC-78': 0.003737987693701524, 'ACC-79': 10.377335688834192, 'ACC-80': 3.317398394445525e-05, 'ACC-81': 1.0376757446120128, 'ACC-82': 0.0, 'ACC-83': 34.50415961840736, 'ACC-84': 0.07568322741499871, 'ACC-85': 11.704273024751965, 'ACC-86': 4.236899727081971, 'ACC-87': 0.000978771426529991, 'ACC-88': 0.0006409897082189711, 'ACC-89': 0.056620258726009585, 'ACC-90': 0.10123108251473067, 'ACC-91': 0.05873066113361062, 'ACC-92': 0.00017063878201450174, 'ACC-93': 10.053932645846416, 'ACC-94': 0.006568527992876797, 'ACC-95': 0.0, 'ACC-96': 9.658412198500917, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.005033141598278936, 'ACC-100': 0.0, 'ACC-101': 0.02476051935189341, 'ACC-102': 3.390620752152243, 'ACC-103': 0.05863322943232266, 'ACC-104': 2.45935909102088e-05, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0019069059566491184, 'ACC-109': 0.00036854183587698076, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.007440580458700107, 'ACC-113': 0.0, 'ACC-114': 0.8626102725330967, 'ACC-115': 0.0, 'ACC-116': 0.011908673444522875, 'ACC-117': 0.0007232825455045176, 'ACC-118': 1.651931374981788, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0005904724097224462, 'ACC-122': 0.0016511458952513042, 'ACC-123': 1.2188924129954666, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.5879178386864656, 'ACC-128': 0.007927883096655531, 'ACC-129': 0.0, 'ACC-130': 0.00019347698784706545, 'ACC-131': 0.0013956149777399412, 'ACC-132': 1.1759541306846553, 'ACC-133': 0.10927623207931032, 'ACC-134': 0.00034467901766479966, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.005342626450427677, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0001656487550667813, 'ACC-141': 0.0001683107824936589, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.008754512635379063, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.028297444893367947, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.11290648097314097, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0003509430717696129, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.1924287883838945, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.31735852628203765, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.27695580789833424, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.00025672556806950075, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 07:41:32] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 07:41:32] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 07:41:32] d2.evaluation.testing INFO: copypaste: 11.5858,0.9054,0.7959,0.3669,1.4086,1.6897,3.6576
[01/24 07:41:32] d2.utils.events INFO:  eta: 1 day, 9:59:16  iter: 8499  total_loss: 56.7  loss_ce: 1.842  loss_mask: 3.659  loss_ce_0: 1.069  loss_mask_0: 4.441  loss_ce_1: 1.258  loss_mask_1: 4.542  loss_ce_2: 1.593  loss_mask_2: 4.005  loss_ce_3: 1.786  loss_mask_3: 3.89  loss_ce_4: 1.891  loss_mask_4: 3.713  loss_ce_5: 1.922  loss_mask_5: 3.591  loss_ce_6: 1.901  loss_mask_6: 3.779  loss_ce_7: 1.97  loss_mask_7: 3.816  loss_ce_8: 1.954  loss_mask_8: 3.789  time: 2.4367  data_time: 0.3866  lr: 8.7156e-05  max_mem: 18490M
[01/24 07:42:21] d2.utils.events INFO:  eta: 1 day, 10:02:15  iter: 8519  total_loss: 57.84  loss_ce: 1.871  loss_mask: 3.837  loss_ce_0: 1.143  loss_mask_0: 5.098  loss_ce_1: 1.156  loss_mask_1: 4.617  loss_ce_2: 1.63  loss_mask_2: 4.084  loss_ce_3: 1.804  loss_mask_3: 3.782  loss_ce_4: 1.936  loss_mask_4: 3.85  loss_ce_5: 1.931  loss_mask_5: 3.909  loss_ce_6: 1.938  loss_mask_6: 3.785  loss_ce_7: 1.965  loss_mask_7: 3.95  loss_ce_8: 2.013  loss_mask_8: 3.912  time: 2.4367  data_time: 0.3861  lr: 8.7126e-05  max_mem: 18490M
[01/24 07:43:11] d2.utils.events INFO:  eta: 1 day, 10:01:27  iter: 8539  total_loss: 54.39  loss_ce: 1.893  loss_mask: 3.537  loss_ce_0: 1.111  loss_mask_0: 4.391  loss_ce_1: 1.169  loss_mask_1: 4.337  loss_ce_2: 1.629  loss_mask_2: 3.642  loss_ce_3: 1.747  loss_mask_3: 3.452  loss_ce_4: 1.889  loss_mask_4: 3.542  loss_ce_5: 1.888  loss_mask_5: 3.638  loss_ce_6: 1.917  loss_mask_6: 3.612  loss_ce_7: 1.937  loss_mask_7: 3.609  loss_ce_8: 2  loss_mask_8: 3.743  time: 2.4368  data_time: 0.4043  lr: 8.7095e-05  max_mem: 18490M
[01/24 07:43:59] d2.utils.events INFO:  eta: 1 day, 10:03:05  iter: 8559  total_loss: 54.98  loss_ce: 1.834  loss_mask: 3.62  loss_ce_0: 1.072  loss_mask_0: 4.264  loss_ce_1: 1.226  loss_mask_1: 4.117  loss_ce_2: 1.624  loss_mask_2: 3.726  loss_ce_3: 1.773  loss_mask_3: 3.48  loss_ce_4: 1.882  loss_mask_4: 3.503  loss_ce_5: 1.861  loss_mask_5: 3.525  loss_ce_6: 1.995  loss_mask_6: 3.932  loss_ce_7: 1.928  loss_mask_7: 3.7  loss_ce_8: 1.949  loss_mask_8: 3.641  time: 2.4368  data_time: 0.4027  lr: 8.7065e-05  max_mem: 18490M
[01/24 07:44:46] d2.utils.events INFO:  eta: 1 day, 10:02:25  iter: 8579  total_loss: 56.97  loss_ce: 1.847  loss_mask: 3.779  loss_ce_0: 1.241  loss_mask_0: 4.439  loss_ce_1: 1.404  loss_mask_1: 4.253  loss_ce_2: 1.694  loss_mask_2: 3.793  loss_ce_3: 1.779  loss_mask_3: 3.572  loss_ce_4: 1.858  loss_mask_4: 3.632  loss_ce_5: 1.901  loss_mask_5: 3.781  loss_ce_6: 2.018  loss_mask_6: 4.125  loss_ce_7: 1.943  loss_mask_7: 3.976  loss_ce_8: 1.968  loss_mask_8: 3.886  time: 2.4366  data_time: 0.3775  lr: 8.7034e-05  max_mem: 18490M
[01/24 07:45:37] d2.utils.events INFO:  eta: 1 day, 10:02:45  iter: 8599  total_loss: 54.47  loss_ce: 1.856  loss_mask: 3.637  loss_ce_0: 1.17  loss_mask_0: 4.315  loss_ce_1: 1.326  loss_mask_1: 4.167  loss_ce_2: 1.583  loss_mask_2: 3.685  loss_ce_3: 1.748  loss_mask_3: 3.413  loss_ce_4: 1.854  loss_mask_4: 3.403  loss_ce_5: 1.921  loss_mask_5: 3.378  loss_ce_6: 1.922  loss_mask_6: 3.741  loss_ce_7: 1.944  loss_mask_7: 3.726  loss_ce_8: 1.939  loss_mask_8: 3.67  time: 2.4368  data_time: 0.3995  lr: 8.7004e-05  max_mem: 18490M
[01/24 07:46:23] d2.utils.events INFO:  eta: 1 day, 10:00:19  iter: 8619  total_loss: 56.68  loss_ce: 1.937  loss_mask: 4.132  loss_ce_0: 1.076  loss_mask_0: 4.226  loss_ce_1: 1.246  loss_mask_1: 4.216  loss_ce_2: 1.566  loss_mask_2: 3.9  loss_ce_3: 1.761  loss_mask_3: 3.59  loss_ce_4: 1.885  loss_mask_4: 3.702  loss_ce_5: 1.955  loss_mask_5: 3.52  loss_ce_6: 1.962  loss_mask_6: 4.041  loss_ce_7: 1.968  loss_mask_7: 4.026  loss_ce_8: 1.976  loss_mask_8: 3.942  time: 2.4365  data_time: 0.3333  lr: 8.6973e-05  max_mem: 18490M
[01/24 07:47:10] d2.utils.events INFO:  eta: 1 day, 9:55:23  iter: 8639  total_loss: 57.47  loss_ce: 1.918  loss_mask: 3.978  loss_ce_0: 1.133  loss_mask_0: 4.878  loss_ce_1: 1.168  loss_mask_1: 4.514  loss_ce_2: 1.531  loss_mask_2: 3.832  loss_ce_3: 1.754  loss_mask_3: 3.595  loss_ce_4: 1.894  loss_mask_4: 3.68  loss_ce_5: 1.906  loss_mask_5: 3.488  loss_ce_6: 1.93  loss_mask_6: 3.652  loss_ce_7: 1.982  loss_mask_7: 3.941  loss_ce_8: 2.019  loss_mask_8: 4.131  time: 2.4362  data_time: 0.3656  lr: 8.6943e-05  max_mem: 18490M
[01/24 07:48:00] d2.utils.events INFO:  eta: 1 day, 9:56:42  iter: 8659  total_loss: 53.5  loss_ce: 1.822  loss_mask: 3.328  loss_ce_0: 1.186  loss_mask_0: 4.541  loss_ce_1: 1.184  loss_mask_1: 4.47  loss_ce_2: 1.482  loss_mask_2: 3.657  loss_ce_3: 1.706  loss_mask_3: 3.389  loss_ce_4: 1.864  loss_mask_4: 3.43  loss_ce_5: 1.87  loss_mask_5: 3.3  loss_ce_6: 1.874  loss_mask_6: 3.574  loss_ce_7: 1.908  loss_mask_7: 3.569  loss_ce_8: 1.909  loss_mask_8: 3.414  time: 2.4364  data_time: 0.4267  lr: 8.6912e-05  max_mem: 18490M
[01/24 07:48:47] d2.utils.events INFO:  eta: 1 day, 9:57:56  iter: 8679  total_loss: 54.73  loss_ce: 1.965  loss_mask: 3.676  loss_ce_0: 1.136  loss_mask_0: 4.538  loss_ce_1: 1.14  loss_mask_1: 4.531  loss_ce_2: 1.533  loss_mask_2: 3.827  loss_ce_3: 1.728  loss_mask_3: 3.531  loss_ce_4: 1.906  loss_mask_4: 3.61  loss_ce_5: 1.905  loss_mask_5: 3.611  loss_ce_6: 1.906  loss_mask_6: 3.467  loss_ce_7: 1.912  loss_mask_7: 3.585  loss_ce_8: 2.021  loss_mask_8: 3.64  time: 2.4363  data_time: 0.3781  lr: 8.6882e-05  max_mem: 18490M
[01/24 07:49:35] d2.utils.events INFO:  eta: 1 day, 9:52:41  iter: 8699  total_loss: 55.06  loss_ce: 1.895  loss_mask: 3.549  loss_ce_0: 1.225  loss_mask_0: 4.538  loss_ce_1: 1.149  loss_mask_1: 4.299  loss_ce_2: 1.534  loss_mask_2: 3.748  loss_ce_3: 1.729  loss_mask_3: 3.395  loss_ce_4: 1.892  loss_mask_4: 3.414  loss_ce_5: 1.916  loss_mask_5: 3.644  loss_ce_6: 1.952  loss_mask_6: 3.78  loss_ce_7: 1.9  loss_mask_7: 3.592  loss_ce_8: 1.979  loss_mask_8: 3.665  time: 2.4361  data_time: 0.3368  lr: 8.6851e-05  max_mem: 18490M
[01/24 07:50:26] d2.utils.events INFO:  eta: 1 day, 9:53:51  iter: 8719  total_loss: 53.14  loss_ce: 1.823  loss_mask: 3.299  loss_ce_0: 1.195  loss_mask_0: 4.417  loss_ce_1: 1.156  loss_mask_1: 4.348  loss_ce_2: 1.482  loss_mask_2: 3.663  loss_ce_3: 1.652  loss_mask_3: 3.256  loss_ce_4: 1.834  loss_mask_4: 3.246  loss_ce_5: 1.883  loss_mask_5: 3.406  loss_ce_6: 1.905  loss_mask_6: 3.762  loss_ce_7: 1.889  loss_mask_7: 3.445  loss_ce_8: 1.88  loss_mask_8: 3.439  time: 2.4364  data_time: 0.4393  lr: 8.6821e-05  max_mem: 18490M
[01/24 07:51:14] d2.utils.events INFO:  eta: 1 day, 9:51:53  iter: 8739  total_loss: 56.59  loss_ce: 1.858  loss_mask: 3.602  loss_ce_0: 1.112  loss_mask_0: 4.473  loss_ce_1: 1.162  loss_mask_1: 4.426  loss_ce_2: 1.517  loss_mask_2: 4.057  loss_ce_3: 1.676  loss_mask_3: 3.706  loss_ce_4: 1.872  loss_mask_4: 3.528  loss_ce_5: 1.943  loss_mask_5: 3.715  loss_ce_6: 1.942  loss_mask_6: 3.991  loss_ce_7: 1.925  loss_mask_7: 3.748  loss_ce_8: 1.941  loss_mask_8: 3.659  time: 2.4363  data_time: 0.3950  lr: 8.6791e-05  max_mem: 18490M
[01/24 07:52:03] d2.utils.events INFO:  eta: 1 day, 9:50:08  iter: 8759  total_loss: 62.96  loss_ce: 2.036  loss_mask: 4.677  loss_ce_0: 1.254  loss_mask_0: 5.434  loss_ce_1: 1.266  loss_mask_1: 4.732  loss_ce_2: 1.634  loss_mask_2: 4.37  loss_ce_3: 1.85  loss_mask_3: 4.06  loss_ce_4: 1.951  loss_mask_4: 4.009  loss_ce_5: 2.033  loss_mask_5: 4.319  loss_ce_6: 2.026  loss_mask_6: 4.592  loss_ce_7: 2.046  loss_mask_7: 4.578  loss_ce_8: 2.051  loss_mask_8: 4.188  time: 2.4363  data_time: 0.3676  lr: 8.676e-05  max_mem: 18490M
[01/24 07:52:54] d2.utils.events INFO:  eta: 1 day, 9:50:56  iter: 8779  total_loss: 56.68  loss_ce: 1.869  loss_mask: 3.686  loss_ce_0: 1.327  loss_mask_0: 4.767  loss_ce_1: 1.241  loss_mask_1: 4.56  loss_ce_2: 1.627  loss_mask_2: 3.788  loss_ce_3: 1.758  loss_mask_3: 3.718  loss_ce_4: 1.902  loss_mask_4: 3.7  loss_ce_5: 1.953  loss_mask_5: 3.674  loss_ce_6: 1.908  loss_mask_6: 3.758  loss_ce_7: 1.958  loss_mask_7: 3.705  loss_ce_8: 1.983  loss_mask_8: 3.659  time: 2.4366  data_time: 0.4169  lr: 8.673e-05  max_mem: 18490M
[01/24 07:53:42] d2.utils.events INFO:  eta: 1 day, 9:48:33  iter: 8799  total_loss: 54.74  loss_ce: 1.961  loss_mask: 3.535  loss_ce_0: 1.217  loss_mask_0: 4.314  loss_ce_1: 1.2  loss_mask_1: 4.25  loss_ce_2: 1.585  loss_mask_2: 3.624  loss_ce_3: 1.732  loss_mask_3: 3.553  loss_ce_4: 1.873  loss_mask_4: 3.474  loss_ce_5: 1.93  loss_mask_5: 3.54  loss_ce_6: 1.92  loss_mask_6: 3.603  loss_ce_7: 1.93  loss_mask_7: 3.458  loss_ce_8: 2.087  loss_mask_8: 4.002  time: 2.4365  data_time: 0.3978  lr: 8.6699e-05  max_mem: 18490M
[01/24 07:54:31] d2.utils.events INFO:  eta: 1 day, 9:47:56  iter: 8819  total_loss: 55.4  loss_ce: 1.925  loss_mask: 3.638  loss_ce_0: 1.157  loss_mask_0: 4.444  loss_ce_1: 1.128  loss_mask_1: 4.26  loss_ce_2: 1.53  loss_mask_2: 3.665  loss_ce_3: 1.742  loss_mask_3: 3.52  loss_ce_4: 1.906  loss_mask_4: 3.539  loss_ce_5: 1.954  loss_mask_5: 3.613  loss_ce_6: 1.946  loss_mask_6: 3.667  loss_ce_7: 1.933  loss_mask_7: 3.468  loss_ce_8: 2.072  loss_mask_8: 3.907  time: 2.4366  data_time: 0.4038  lr: 8.6669e-05  max_mem: 18490M
[01/24 07:55:21] d2.utils.events INFO:  eta: 1 day, 9:48:34  iter: 8839  total_loss: 57.22  loss_ce: 2.057  loss_mask: 4.085  loss_ce_0: 1.201  loss_mask_0: 4.483  loss_ce_1: 1.112  loss_mask_1: 4.537  loss_ce_2: 1.573  loss_mask_2: 3.719  loss_ce_3: 1.784  loss_mask_3: 3.722  loss_ce_4: 1.936  loss_mask_4: 3.763  loss_ce_5: 1.971  loss_mask_5: 3.684  loss_ce_6: 1.966  loss_mask_6: 3.754  loss_ce_7: 1.962  loss_mask_7: 3.827  loss_ce_8: 2.075  loss_mask_8: 4.006  time: 2.4366  data_time: 0.3725  lr: 8.6638e-05  max_mem: 18490M
[01/24 07:56:09] d2.utils.events INFO:  eta: 1 day, 9:47:46  iter: 8859  total_loss: 57.18  loss_ce: 1.954  loss_mask: 3.767  loss_ce_0: 1.27  loss_mask_0: 4.822  loss_ce_1: 1.19  loss_mask_1: 4.563  loss_ce_2: 1.542  loss_mask_2: 3.776  loss_ce_3: 1.789  loss_mask_3: 3.61  loss_ce_4: 1.991  loss_mask_4: 3.703  loss_ce_5: 1.97  loss_mask_5: 4.059  loss_ce_6: 1.987  loss_mask_6: 3.793  loss_ce_7: 1.963  loss_mask_7: 3.672  loss_ce_8: 2.046  loss_mask_8: 3.814  time: 2.4366  data_time: 0.3774  lr: 8.6608e-05  max_mem: 18490M
[01/24 07:57:03] d2.utils.events INFO:  eta: 1 day, 9:49:59  iter: 8879  total_loss: 57.54  loss_ce: 1.951  loss_mask: 3.726  loss_ce_0: 1.283  loss_mask_0: 4.848  loss_ce_1: 1.148  loss_mask_1: 4.524  loss_ce_2: 1.583  loss_mask_2: 3.878  loss_ce_3: 1.791  loss_mask_3: 3.825  loss_ce_4: 1.972  loss_mask_4: 3.877  loss_ce_5: 1.983  loss_mask_5: 3.931  loss_ce_6: 1.989  loss_mask_6: 3.976  loss_ce_7: 1.988  loss_mask_7: 3.836  loss_ce_8: 2.023  loss_mask_8: 3.873  time: 2.4371  data_time: 0.4060  lr: 8.6577e-05  max_mem: 18490M
[01/24 07:57:50] d2.utils.events INFO:  eta: 1 day, 9:48:34  iter: 8899  total_loss: 58.39  loss_ce: 2  loss_mask: 3.837  loss_ce_0: 1.299  loss_mask_0: 4.639  loss_ce_1: 1.115  loss_mask_1: 4.446  loss_ce_2: 1.518  loss_mask_2: 4.057  loss_ce_3: 1.757  loss_mask_3: 3.68  loss_ce_4: 2.009  loss_mask_4: 3.794  loss_ce_5: 1.988  loss_mask_5: 3.936  loss_ce_6: 2.09  loss_mask_6: 4.126  loss_ce_7: 2.035  loss_mask_7: 3.924  loss_ce_8: 2.028  loss_mask_8: 3.856  time: 2.4369  data_time: 0.3584  lr: 8.6547e-05  max_mem: 18490M
[01/24 07:58:37] d2.utils.events INFO:  eta: 1 day, 9:49:27  iter: 8919  total_loss: 54.58  loss_ce: 1.855  loss_mask: 3.509  loss_ce_0: 1.318  loss_mask_0: 4.46  loss_ce_1: 1.161  loss_mask_1: 4.313  loss_ce_2: 1.51  loss_mask_2: 3.755  loss_ce_3: 1.743  loss_mask_3: 3.6  loss_ce_4: 1.907  loss_mask_4: 3.632  loss_ce_5: 1.936  loss_mask_5: 3.658  loss_ce_6: 1.914  loss_mask_6: 3.645  loss_ce_7: 1.95  loss_mask_7: 3.548  loss_ce_8: 1.91  loss_mask_8: 3.352  time: 2.4368  data_time: 0.3532  lr: 8.6516e-05  max_mem: 18490M
[01/24 07:59:28] d2.utils.events INFO:  eta: 1 day, 9:51:03  iter: 8939  total_loss: 55.75  loss_ce: 1.934  loss_mask: 3.603  loss_ce_0: 1.275  loss_mask_0: 4.735  loss_ce_1: 1.144  loss_mask_1: 4.451  loss_ce_2: 1.458  loss_mask_2: 4.134  loss_ce_3: 1.722  loss_mask_3: 3.727  loss_ce_4: 1.961  loss_mask_4: 3.693  loss_ce_5: 1.975  loss_mask_5: 3.624  loss_ce_6: 1.974  loss_mask_6: 3.665  loss_ce_7: 1.977  loss_mask_7: 3.573  loss_ce_8: 1.958  loss_mask_8: 3.675  time: 2.4370  data_time: 0.3998  lr: 8.6486e-05  max_mem: 18490M
[01/24 08:00:16] d2.utils.events INFO:  eta: 1 day, 9:50:54  iter: 8959  total_loss: 54.88  loss_ce: 1.874  loss_mask: 3.412  loss_ce_0: 1.229  loss_mask_0: 4.631  loss_ce_1: 1.091  loss_mask_1: 4.569  loss_ce_2: 1.426  loss_mask_2: 4.006  loss_ce_3: 1.744  loss_mask_3: 3.674  loss_ce_4: 1.973  loss_mask_4: 3.602  loss_ce_5: 1.92  loss_mask_5: 3.434  loss_ce_6: 1.933  loss_mask_6: 3.561  loss_ce_7: 1.919  loss_mask_7: 3.279  loss_ce_8: 1.972  loss_mask_8: 3.512  time: 2.4370  data_time: 0.3916  lr: 8.6455e-05  max_mem: 18490M
[01/24 08:01:03] d2.utils.events INFO:  eta: 1 day, 9:48:56  iter: 8979  total_loss: 54.51  loss_ce: 1.923  loss_mask: 3.509  loss_ce_0: 1.272  loss_mask_0: 4.497  loss_ce_1: 1.185  loss_mask_1: 4.163  loss_ce_2: 1.403  loss_mask_2: 3.786  loss_ce_3: 1.668  loss_mask_3: 3.607  loss_ce_4: 1.951  loss_mask_4: 3.548  loss_ce_5: 1.946  loss_mask_5: 3.511  loss_ce_6: 1.946  loss_mask_6: 3.431  loss_ce_7: 1.939  loss_mask_7: 3.414  loss_ce_8: 1.977  loss_mask_8: 3.596  time: 2.4367  data_time: 0.3439  lr: 8.6425e-05  max_mem: 18490M
[01/24 08:01:54] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 08:01:55] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 08:01:55] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 08:06:03] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 11.434239433951756, 'error_1pix': 0.8629584203064193, 'error_3pix': 0.7524806781433114, 'mIoU': 0.5542753128052994, 'fwIoU': 5.725913979532064, 'IoU-0': nan, 'IoU-1': 50.06605867011395, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0004607634829580973, 'IoU-13': 0.4164938521370327, 'IoU-14': 0.10721223629266226, 'IoU-15': 7.3339745834754695e-06, 'IoU-16': 0.005400543071006935, 'IoU-17': 0.596647683034791, 'IoU-18': 0.0, 'IoU-19': 0.9589396027894506, 'IoU-20': 3.0790692355505516e-05, 'IoU-21': 0.0, 'IoU-22': 0.0030166129942385753, 'IoU-23': 1.8102416530675312, 'IoU-24': 2.499889476565596, 'IoU-25': 1.2183302815988806, 'IoU-26': 3.6637355709233175, 'IoU-27': 0.0002450995445036258, 'IoU-28': 8.356935432242025e-05, 'IoU-29': 0.20578402849294264, 'IoU-30': 5.465932333233516e-05, 'IoU-31': 0.0027632262833478696, 'IoU-32': 1.8696459479112728, 'IoU-33': 1.1794449799474054, 'IoU-34': 4.379293570520142, 'IoU-35': 0.0, 'IoU-36': 3.650916950832015, 'IoU-37': 1.4216218504643174e-05, 'IoU-38': 1.4482061062058178, 'IoU-39': 2.559302435501029, 'IoU-40': 4.78945395572981, 'IoU-41': 0.006629045566701673, 'IoU-42': 0.0, 'IoU-43': 0.12127281111313892, 'IoU-44': 0.009816729945727354, 'IoU-45': 0.9587055216147331, 'IoU-46': 0.0, 'IoU-47': 0.775835185723194, 'IoU-48': 0.380463021876881, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.00020101528801671483, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.011307210500581187, 'IoU-55': 0.028837301253401455, 'IoU-56': 0.11843896050828817, 'IoU-57': 0.10894063082564685, 'IoU-58': 0.0, 'IoU-59': 0.001086574133715748, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.015321936076360352, 'IoU-63': 9.2209844894742e-06, 'IoU-64': 0.0, 'IoU-65': 2.9674412347720806e-05, 'IoU-66': 0.004356179608039733, 'IoU-67': 1.0448915295754664, 'IoU-68': 0.48093210091477484, 'IoU-69': 0.49379827270436083, 'IoU-70': 0.0014570902751894481, 'IoU-71': 0.0, 'IoU-72': 0.0024113602850072287, 'IoU-73': 1.3030069310142198, 'IoU-74': 1.7819746742983391, 'IoU-75': 0.00020747384109753224, 'IoU-76': 1.1579520293166004, 'IoU-77': 0.2525394108209022, 'IoU-78': 0.0020392784988338985, 'IoU-79': 0.008040313510036621, 'IoU-80': 0.1280571154275888, 'IoU-81': 0.19343184756140103, 'IoU-82': 0.058987709955343554, 'IoU-83': 0.8081584756650181, 'IoU-84': 7.938753649700226e-05, 'IoU-85': 0.35189817764169723, 'IoU-86': 1.8542642445699629, 'IoU-87': 1.8204106874355106, 'IoU-88': 0.7607286580665271, 'IoU-89': 3.8432398819664164e-05, 'IoU-90': 0.00629095525366753, 'IoU-91': 0.00161899783761751, 'IoU-92': 0.0014486578610992758, 'IoU-93': 0.004721245738193245, 'IoU-94': 0.9164977932021651, 'IoU-95': 4.721838835141247e-05, 'IoU-96': 0.6186694000781575, 'IoU-97': 1.039660543705581, 'IoU-98': 1.6141197956652724, 'IoU-99': 0.08161537285524444, 'IoU-100': 0.0, 'IoU-101': 0.08979013815026289, 'IoU-102': 0.0, 'IoU-103': 0.23656198680548332, 'IoU-104': 0.00022124274508165086, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.015978887389801587, 'IoU-108': 0.11318591179917861, 'IoU-109': 0.2019198606989689, 'IoU-110': 0.0, 'IoU-111': 0.000242856969387879, 'IoU-112': 0.027710027545673883, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.5046488914182002, 'IoU-120': 0.0, 'IoU-121': 0.01794947236746139, 'IoU-122': 0.09364175199943563, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 1.3777427029086777, 'IoU-126': 0.7132309403261203, 'IoU-127': 1.1352819179129001, 'IoU-128': 0.011181479622354542, 'IoU-129': 0.005387978292712572, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.06379058843472171, 'IoU-133': 0.004883968441423921, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.04204954241300255, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.41601670057627127, 'IoU-149': 0.006444220239281952, 'IoU-150': 0.41790016799772894, 'IoU-151': 0.0, 'IoU-152': 0.00031608792723234467, 'IoU-153': 0.00022882928648740178, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.04156220610058586, 'IoU-161': 0.021460321207357674, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.00033568536881751473, 'IoU-167': 0.0, 'IoU-168': 0.09514215357062905, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0001931184182829069, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0011782226746597294, 'IoU-187': 0.0, 'IoU-188': 0.0017621810766926377, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.8361762631990926, 'pACC': 8.101242307341963, 'ACC-0': nan, 'ACC-1': 51.896707567270774, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.00046084970786395646, 'ACC-13': 0.6941352336268725, 'ACC-14': 0.155166570430208, 'ACC-15': 7.333990361083149e-06, 'ACC-16': 0.005717510643004382, 'ACC-17': 0.7794516470044981, 'ACC-18': 0.0, 'ACC-19': 3.912575142226671, 'ACC-20': 3.0791696390917585e-05, 'ACC-21': 0.0, 'ACC-22': 0.003018505695438512, 'ACC-23': 11.859037857741386, 'ACC-24': 13.611589621422377, 'ACC-25': 1.6914871749615499, 'ACC-26': 19.190736011762443, 'ACC-27': 0.00024529519585129696, 'ACC-28': 8.357570046307566e-05, 'ACC-29': 0.21410967286450705, 'ACC-30': 5.4678720007252584e-05, 'ACC-31': 0.002765963354128698, 'ACC-32': 3.3216179477808265, 'ACC-33': 1.6064893949379169, 'ACC-34': 54.70984781885518, 'ACC-35': 0.0, 'ACC-36': 10.66247709412678, 'ACC-37': 1.4216218504643174e-05, 'ACC-38': 2.0344568070067655, 'ACC-39': 3.997832309541585, 'ACC-40': 16.54443315165434, 'ACC-41': 0.006646858374071442, 'ACC-42': 0.0, 'ACC-43': 0.12430140531363568, 'ACC-44': 0.009844704624444237, 'ACC-45': 1.311859297809679, 'ACC-46': 0.0, 'ACC-47': 1.1781226760232717, 'ACC-48': 0.5234128043781363, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.00020110923811374014, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.011365754807114907, 'ACC-55': 0.02924388751269435, 'ACC-56': 0.13238036592493907, 'ACC-57': 0.11087526082865731, 'ACC-58': 0.0, 'ACC-59': 0.0010870227207106567, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.015422113768933274, 'ACC-63': 9.222818877118113e-06, 'ACC-64': 0.0, 'ACC-65': 2.967524891351495e-05, 'ACC-66': 0.004364212882011716, 'ACC-67': 29.793304460272175, 'ACC-68': 0.5395089965449806, 'ACC-69': 1.791794314163939, 'ACC-70': 0.0014614563136818998, 'ACC-71': 0.0, 'ACC-72': 0.002416595171086029, 'ACC-73': 2.061771375812185, 'ACC-74': 4.813182855830107, 'ACC-75': 0.00020748269976488933, 'ACC-76': 1.8550373026050184, 'ACC-77': 0.3004253615289174, 'ACC-78': 0.0020409190968578056, 'ACC-79': 0.008064037367234368, 'ACC-80': 0.1347858967663217, 'ACC-81': 0.23315904298755594, 'ACC-82': 0.06011491027543048, 'ACC-83': 1.8795828061166742, 'ACC-84': 7.939196641765188e-05, 'ACC-85': 0.38846942030011944, 'ACC-86': 68.33582851047709, 'ACC-87': 4.082590201127741, 'ACC-88': 1.1398053854698442, 'ACC-89': 3.843873640598071e-05, 'ACC-90': 0.006317986748120496, 'ACC-91': 0.0016193115558154922, 'ACC-92': 0.0014504296471232647, 'ACC-93': 0.00472899541552622, 'ACC-94': 2.9278453281952848, 'ACC-95': 4.721896061623891e-05, 'ACC-96': 2.6153276616026093, 'ACC-97': 2.2590457621683497, 'ACC-98': 10.219239279903105, 'ACC-99': 0.10706514235112893, 'ACC-100': 0.0, 'ACC-101': 0.09607597352687806, 'ACC-102': 0.0, 'ACC-103': 0.24811089071502787, 'ACC-104': 0.00022134231819187917, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.016127523291080855, 'ACC-108': 0.1330135995558291, 'ACC-109': 0.39173162216524, 'ACC-110': 0.0, 'ACC-111': 0.0002507144578566233, 'ACC-112': 0.028127396083785606, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.8443357321801027, 'ACC-120': 0.0, 'ACC-121': 0.030840828169349306, 'ACC-122': 0.09831394416296338, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 3.7911575732327707, 'ACC-126': 5.066986038124209, 'ACC-127': 4.217051836761394, 'ACC-128': 0.01134297119983022, 'ACC-129': 0.005396725191850443, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.07667226293760661, 'ACC-133': 0.00489905897242238, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.04473690890169302, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.6864686217683363, 'ACC-149': 0.006490418013343894, 'ACC-150': 0.6551950211015323, 'ACC-151': 0.0, 'ACC-152': 0.00031610358082136353, 'ACC-153': 0.00022902581578995585, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.044111659050807585, 'ACC-161': 0.022467050666007633, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.00033576483031284886, 'ACC-167': 0.0, 'ACC-168': 0.1016245868204515, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.00019315795878395477, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0011803226057746103, 'ACC-187': 0.0, 'ACC-188': 0.0017654654775836327, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 08:06:03] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 08:06:03] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 08:06:03] d2.evaluation.testing INFO: copypaste: 11.4342,0.8630,0.7525,0.5543,5.7259,1.8362,8.1012
[01/24 08:06:03] d2.utils.events INFO:  eta: 1 day, 9:50:41  iter: 8999  total_loss: 51.15  loss_ce: 1.884  loss_mask: 3.151  loss_ce_0: 1.211  loss_mask_0: 4.183  loss_ce_1: 1.186  loss_mask_1: 4.018  loss_ce_2: 1.444  loss_mask_2: 3.641  loss_ce_3: 1.699  loss_mask_3: 3.302  loss_ce_4: 1.946  loss_mask_4: 3.465  loss_ce_5: 1.921  loss_mask_5: 3.374  loss_ce_6: 1.924  loss_mask_6: 3.218  loss_ce_7: 1.924  loss_mask_7: 3.14  loss_ce_8: 1.987  loss_mask_8: 3.386  time: 2.4370  data_time: 0.4167  lr: 8.6394e-05  max_mem: 18490M
[01/24 08:06:54] d2.utils.events INFO:  eta: 1 day, 9:49:32  iter: 9019  total_loss: 53.75  loss_ce: 1.99  loss_mask: 3.413  loss_ce_0: 1.206  loss_mask_0: 4.264  loss_ce_1: 1.056  loss_mask_1: 4.139  loss_ce_2: 1.353  loss_mask_2: 3.704  loss_ce_3: 1.677  loss_mask_3: 3.573  loss_ce_4: 1.941  loss_mask_4: 3.483  loss_ce_5: 1.893  loss_mask_5: 3.311  loss_ce_6: 1.909  loss_mask_6: 3.449  loss_ce_7: 1.933  loss_mask_7: 3.331  loss_ce_8: 2.037  loss_mask_8: 3.606  time: 2.4372  data_time: 0.4211  lr: 8.6364e-05  max_mem: 18490M
[01/24 08:07:41] d2.utils.events INFO:  eta: 1 day, 9:49:45  iter: 9039  total_loss: 56.18  loss_ce: 2.041  loss_mask: 3.872  loss_ce_0: 1.178  loss_mask_0: 4.58  loss_ce_1: 1.03  loss_mask_1: 4.474  loss_ce_2: 1.308  loss_mask_2: 3.957  loss_ce_3: 1.742  loss_mask_3: 3.788  loss_ce_4: 1.985  loss_mask_4: 3.696  loss_ce_5: 1.973  loss_mask_5: 3.579  loss_ce_6: 1.986  loss_mask_6: 3.581  loss_ce_7: 1.98  loss_mask_7: 3.633  loss_ce_8: 2.036  loss_mask_8: 3.73  time: 2.4371  data_time: 0.3317  lr: 8.6333e-05  max_mem: 18490M
[01/24 08:08:33] d2.utils.events INFO:  eta: 1 day, 9:53:15  iter: 9059  total_loss: 55.04  loss_ce: 1.982  loss_mask: 3.67  loss_ce_0: 1.314  loss_mask_0: 4.489  loss_ce_1: 1.094  loss_mask_1: 4.132  loss_ce_2: 1.353  loss_mask_2: 3.706  loss_ce_3: 1.768  loss_mask_3: 3.506  loss_ce_4: 2.008  loss_mask_4: 3.62  loss_ce_5: 1.981  loss_mask_5: 3.354  loss_ce_6: 1.987  loss_mask_6: 3.564  loss_ce_7: 1.96  loss_mask_7: 3.519  loss_ce_8: 2.002  loss_mask_8: 3.945  time: 2.4374  data_time: 0.4028  lr: 8.6303e-05  max_mem: 18490M
[01/24 08:09:23] d2.utils.events INFO:  eta: 1 day, 9:52:27  iter: 9079  total_loss: 54.72  loss_ce: 2.034  loss_mask: 3.747  loss_ce_0: 1.223  loss_mask_0: 4.553  loss_ce_1: 1.06  loss_mask_1: 4.277  loss_ce_2: 1.363  loss_mask_2: 3.775  loss_ce_3: 1.802  loss_mask_3: 3.667  loss_ce_4: 1.955  loss_mask_4: 3.502  loss_ce_5: 1.953  loss_mask_5: 3.457  loss_ce_6: 1.971  loss_mask_6: 3.585  loss_ce_7: 1.964  loss_mask_7: 3.668  loss_ce_8: 2.019  loss_mask_8: 3.675  time: 2.4375  data_time: 0.3717  lr: 8.6272e-05  max_mem: 18490M
[01/24 08:10:10] d2.utils.events INFO:  eta: 1 day, 9:53:57  iter: 9099  total_loss: 54.72  loss_ce: 1.971  loss_mask: 3.506  loss_ce_0: 1.257  loss_mask_0: 4.55  loss_ce_1: 1.057  loss_mask_1: 4.12  loss_ce_2: 1.348  loss_mask_2: 3.79  loss_ce_3: 1.782  loss_mask_3: 3.479  loss_ce_4: 1.998  loss_mask_4: 3.734  loss_ce_5: 1.974  loss_mask_5: 3.528  loss_ce_6: 2.019  loss_mask_6: 3.551  loss_ce_7: 2.026  loss_mask_7: 3.706  loss_ce_8: 2.008  loss_mask_8: 3.619  time: 2.4374  data_time: 0.3615  lr: 8.6242e-05  max_mem: 18490M
[01/24 08:11:03] d2.utils.events INFO:  eta: 1 day, 9:55:56  iter: 9119  total_loss: 58.32  loss_ce: 1.964  loss_mask: 3.764  loss_ce_0: 1.377  loss_mask_0: 4.755  loss_ce_1: 1.086  loss_mask_1: 4.326  loss_ce_2: 1.35  loss_mask_2: 4.073  loss_ce_3: 1.751  loss_mask_3: 3.669  loss_ce_4: 2.019  loss_mask_4: 3.901  loss_ce_5: 2.059  loss_mask_5: 4.01  loss_ce_6: 2.048  loss_mask_6: 3.914  loss_ce_7: 2.061  loss_mask_7: 3.871  loss_ce_8: 2.069  loss_mask_8: 3.967  time: 2.4379  data_time: 0.4214  lr: 8.6211e-05  max_mem: 18490M
[01/24 08:11:52] d2.utils.events INFO:  eta: 1 day, 9:53:49  iter: 9139  total_loss: 57.07  loss_ce: 1.962  loss_mask: 3.757  loss_ce_0: 1.32  loss_mask_0: 4.793  loss_ce_1: 1.091  loss_mask_1: 4.287  loss_ce_2: 1.383  loss_mask_2: 3.944  loss_ce_3: 1.754  loss_mask_3: 3.765  loss_ce_4: 2.014  loss_mask_4: 3.916  loss_ce_5: 2.061  loss_mask_5: 3.729  loss_ce_6: 1.995  loss_mask_6: 3.858  loss_ce_7: 1.986  loss_mask_7: 3.848  loss_ce_8: 1.989  loss_mask_8: 3.626  time: 2.4379  data_time: 0.3713  lr: 8.6181e-05  max_mem: 18490M
[01/24 08:12:42] d2.utils.events INFO:  eta: 1 day, 9:53:40  iter: 9159  total_loss: 54.77  loss_ce: 1.932  loss_mask: 3.514  loss_ce_0: 1.271  loss_mask_0: 4.496  loss_ce_1: 1.064  loss_mask_1: 4.11  loss_ce_2: 1.343  loss_mask_2: 3.634  loss_ce_3: 1.741  loss_mask_3: 3.711  loss_ce_4: 1.974  loss_mask_4: 3.618  loss_ce_5: 1.97  loss_mask_5: 3.553  loss_ce_6: 1.949  loss_mask_6: 3.482  loss_ce_7: 1.952  loss_mask_7: 3.732  loss_ce_8: 1.963  loss_mask_8: 3.607  time: 2.4380  data_time: 0.3721  lr: 8.615e-05  max_mem: 18490M
[01/24 08:13:35] d2.utils.events INFO:  eta: 1 day, 9:53:52  iter: 9179  total_loss: 57.36  loss_ce: 1.915  loss_mask: 3.621  loss_ce_0: 1.178  loss_mask_0: 4.885  loss_ce_1: 1.144  loss_mask_1: 4.279  loss_ce_2: 1.353  loss_mask_2: 3.984  loss_ce_3: 1.802  loss_mask_3: 3.612  loss_ce_4: 2.183  loss_mask_4: 3.654  loss_ce_5: 2.051  loss_mask_5: 3.891  loss_ce_6: 1.997  loss_mask_6: 3.69  loss_ce_7: 1.977  loss_mask_7: 3.857  loss_ce_8: 1.955  loss_mask_8: 3.769  time: 2.4384  data_time: 0.4340  lr: 8.612e-05  max_mem: 18490M
[01/24 08:14:23] d2.utils.events INFO:  eta: 1 day, 9:52:20  iter: 9199  total_loss: 54.76  loss_ce: 1.873  loss_mask: 3.514  loss_ce_0: 1.252  loss_mask_0: 4.587  loss_ce_1: 1.109  loss_mask_1: 4.129  loss_ce_2: 1.276  loss_mask_2: 3.748  loss_ce_3: 1.702  loss_mask_3: 3.517  loss_ce_4: 2.043  loss_mask_4: 3.364  loss_ce_5: 2.002  loss_mask_5: 3.502  loss_ce_6: 1.949  loss_mask_6: 3.49  loss_ce_7: 1.978  loss_mask_7: 3.681  loss_ce_8: 1.938  loss_mask_8: 3.644  time: 2.4384  data_time: 0.3820  lr: 8.6089e-05  max_mem: 18490M
[01/24 08:15:12] d2.utils.events INFO:  eta: 1 day, 9:56:05  iter: 9219  total_loss: 54.93  loss_ce: 1.872  loss_mask: 3.667  loss_ce_0: 1.24  loss_mask_0: 4.451  loss_ce_1: 1.155  loss_mask_1: 4.158  loss_ce_2: 1.265  loss_mask_2: 3.728  loss_ce_3: 1.697  loss_mask_3: 3.586  loss_ce_4: 1.985  loss_mask_4: 3.561  loss_ce_5: 1.979  loss_mask_5: 3.475  loss_ce_6: 1.949  loss_mask_6: 3.687  loss_ce_7: 1.953  loss_mask_7: 3.801  loss_ce_8: 1.931  loss_mask_8: 3.721  time: 2.4384  data_time: 0.3593  lr: 8.6059e-05  max_mem: 18490M
[01/24 08:16:03] d2.utils.events INFO:  eta: 1 day, 9:56:43  iter: 9239  total_loss: 55.09  loss_ce: 1.949  loss_mask: 3.75  loss_ce_0: 1.23  loss_mask_0: 4.592  loss_ce_1: 1.061  loss_mask_1: 4.171  loss_ce_2: 1.267  loss_mask_2: 3.733  loss_ce_3: 1.652  loss_mask_3: 3.59  loss_ce_4: 1.935  loss_mask_4: 3.497  loss_ce_5: 1.971  loss_mask_5: 3.697  loss_ce_6: 2.023  loss_mask_6: 3.743  loss_ce_7: 2.028  loss_mask_7: 3.662  loss_ce_8: 1.984  loss_mask_8: 3.751  time: 2.4387  data_time: 0.4160  lr: 8.6028e-05  max_mem: 18490M
[01/24 08:16:52] d2.utils.events INFO:  eta: 1 day, 9:57:37  iter: 9259  total_loss: 54.28  loss_ce: 1.896  loss_mask: 3.613  loss_ce_0: 1.274  loss_mask_0: 4.603  loss_ce_1: 1.105  loss_mask_1: 4.163  loss_ce_2: 1.299  loss_mask_2: 3.791  loss_ce_3: 1.657  loss_mask_3: 3.607  loss_ce_4: 1.941  loss_mask_4: 3.454  loss_ce_5: 1.968  loss_mask_5: 3.471  loss_ce_6: 1.991  loss_mask_6: 3.606  loss_ce_7: 1.958  loss_mask_7: 3.563  loss_ce_8: 1.984  loss_mask_8: 3.452  time: 2.4386  data_time: 0.3594  lr: 8.5998e-05  max_mem: 18490M
[01/24 08:17:45] d2.utils.events INFO:  eta: 1 day, 10:00:28  iter: 9279  total_loss: 53.83  loss_ce: 1.988  loss_mask: 3.839  loss_ce_0: 1.241  loss_mask_0: 4.546  loss_ce_1: 1.049  loss_mask_1: 4.002  loss_ce_2: 1.249  loss_mask_2: 3.587  loss_ce_3: 1.689  loss_mask_3: 3.492  loss_ce_4: 1.938  loss_mask_4: 3.37  loss_ce_5: 1.921  loss_mask_5: 3.255  loss_ce_6: 1.998  loss_mask_6: 3.445  loss_ce_7: 1.97  loss_mask_7: 3.453  loss_ce_8: 2.027  loss_mask_8: 3.872  time: 2.4391  data_time: 0.4083  lr: 8.5967e-05  max_mem: 18490M
[01/24 08:18:33] d2.utils.events INFO:  eta: 1 day, 9:58:39  iter: 9299  total_loss: 54.95  loss_ce: 1.948  loss_mask: 3.736  loss_ce_0: 1.289  loss_mask_0: 4.567  loss_ce_1: 1.058  loss_mask_1: 4.065  loss_ce_2: 1.235  loss_mask_2: 3.59  loss_ce_3: 1.742  loss_mask_3: 3.664  loss_ce_4: 1.961  loss_mask_4: 3.457  loss_ce_5: 1.963  loss_mask_5: 3.409  loss_ce_6: 1.935  loss_mask_6: 3.352  loss_ce_7: 1.925  loss_mask_7: 3.471  loss_ce_8: 2.032  loss_mask_8: 4.528  time: 2.4391  data_time: 0.3487  lr: 8.5937e-05  max_mem: 18490M
[01/24 08:19:22] d2.utils.events INFO:  eta: 1 day, 10:00:30  iter: 9319  total_loss: 59.59  loss_ce: 1.991  loss_mask: 4.23  loss_ce_0: 1.317  loss_mask_0: 5.214  loss_ce_1: 1.046  loss_mask_1: 4.465  loss_ce_2: 1.235  loss_mask_2: 4.005  loss_ce_3: 1.654  loss_mask_3: 3.967  loss_ce_4: 1.998  loss_mask_4: 4.246  loss_ce_5: 2.031  loss_mask_5: 3.9  loss_ce_6: 1.922  loss_mask_6: 4.045  loss_ce_7: 1.978  loss_mask_7: 4.235  loss_ce_8: 2.001  loss_mask_8: 4.357  time: 2.4391  data_time: 0.3756  lr: 8.5906e-05  max_mem: 18490M
[01/24 08:20:15] d2.utils.events INFO:  eta: 1 day, 10:05:09  iter: 9339  total_loss: 58.97  loss_ce: 2.045  loss_mask: 4.498  loss_ce_0: 1.272  loss_mask_0: 4.837  loss_ce_1: 1.115  loss_mask_1: 4.305  loss_ce_2: 1.396  loss_mask_2: 3.983  loss_ce_3: 1.769  loss_mask_3: 4.059  loss_ce_4: 1.999  loss_mask_4: 3.904  loss_ce_5: 1.995  loss_mask_5: 3.801  loss_ce_6: 1.974  loss_mask_6: 3.796  loss_ce_7: 1.962  loss_mask_7: 3.909  loss_ce_8: 2.139  loss_mask_8: 4.787  time: 2.4395  data_time: 0.4246  lr: 8.5876e-05  max_mem: 18490M
[01/24 08:21:03] d2.utils.events INFO:  eta: 1 day, 10:01:17  iter: 9359  total_loss: 57.97  loss_ce: 1.967  loss_mask: 4.328  loss_ce_0: 1.317  loss_mask_0: 5.031  loss_ce_1: 1.102  loss_mask_1: 4.332  loss_ce_2: 1.377  loss_mask_2: 4.076  loss_ce_3: 1.688  loss_mask_3: 3.825  loss_ce_4: 1.945  loss_mask_4: 3.888  loss_ce_5: 1.952  loss_mask_5: 3.922  loss_ce_6: 1.957  loss_mask_6: 3.657  loss_ce_7: 1.935  loss_mask_7: 3.882  loss_ce_8: 2.005  loss_mask_8: 4.258  time: 2.4393  data_time: 0.3570  lr: 8.5845e-05  max_mem: 18490M
[01/24 08:21:52] d2.utils.events INFO:  eta: 1 day, 10:02:20  iter: 9379  total_loss: 56.09  loss_ce: 1.931  loss_mask: 4.052  loss_ce_0: 1.239  loss_mask_0: 4.935  loss_ce_1: 1.127  loss_mask_1: 4.236  loss_ce_2: 1.497  loss_mask_2: 4.012  loss_ce_3: 1.82  loss_mask_3: 3.53  loss_ce_4: 1.992  loss_mask_4: 3.646  loss_ce_5: 2.02  loss_mask_5: 3.591  loss_ce_6: 2.011  loss_mask_6: 3.666  loss_ce_7: 1.945  loss_mask_7: 3.617  loss_ce_8: 1.954  loss_mask_8: 3.728  time: 2.4394  data_time: 0.3507  lr: 8.5815e-05  max_mem: 18490M
[01/24 08:22:44] d2.utils.events INFO:  eta: 1 day, 10:08:43  iter: 9399  total_loss: 56.3  loss_ce: 1.983  loss_mask: 3.67  loss_ce_0: 1.18  loss_mask_0: 4.713  loss_ce_1: 1.131  loss_mask_1: 4.297  loss_ce_2: 1.399  loss_mask_2: 3.919  loss_ce_3: 1.698  loss_mask_3: 3.622  loss_ce_4: 1.972  loss_mask_4: 3.602  loss_ce_5: 2.002  loss_mask_5: 3.622  loss_ce_6: 1.979  loss_mask_6: 3.837  loss_ce_7: 1.912  loss_mask_7: 3.675  loss_ce_8: 1.919  loss_mask_8: 4.038  time: 2.4397  data_time: 0.4336  lr: 8.5784e-05  max_mem: 18490M
[01/24 08:23:33] d2.utils.events INFO:  eta: 1 day, 10:09:44  iter: 9419  total_loss: 56.25  loss_ce: 1.905  loss_mask: 3.718  loss_ce_0: 1.122  loss_mask_0: 4.681  loss_ce_1: 1.093  loss_mask_1: 4.49  loss_ce_2: 1.401  loss_mask_2: 4.084  loss_ce_3: 1.719  loss_mask_3: 3.819  loss_ce_4: 1.97  loss_mask_4: 3.701  loss_ce_5: 1.968  loss_mask_5: 3.692  loss_ce_6: 1.954  loss_mask_6: 3.757  loss_ce_7: 1.927  loss_mask_7: 3.905  loss_ce_8: 1.931  loss_mask_8: 3.855  time: 2.4397  data_time: 0.3774  lr: 8.5754e-05  max_mem: 18490M
[01/24 08:24:24] d2.utils.events INFO:  eta: 1 day, 10:13:44  iter: 9439  total_loss: 54.95  loss_ce: 1.906  loss_mask: 3.656  loss_ce_0: 1.195  loss_mask_0: 4.607  loss_ce_1: 1.042  loss_mask_1: 4.489  loss_ce_2: 1.4  loss_mask_2: 4.04  loss_ce_3: 1.735  loss_mask_3: 3.636  loss_ce_4: 1.968  loss_mask_4: 3.596  loss_ce_5: 1.978  loss_mask_5: 3.672  loss_ce_6: 1.92  loss_mask_6: 3.739  loss_ce_7: 1.906  loss_mask_7: 3.621  loss_ce_8: 1.869  loss_mask_8: 3.725  time: 2.4400  data_time: 0.3804  lr: 8.5723e-05  max_mem: 18490M
[01/24 08:25:13] d2.utils.events INFO:  eta: 1 day, 10:14:15  iter: 9459  total_loss: 54.84  loss_ce: 1.882  loss_mask: 3.664  loss_ce_0: 1.164  loss_mask_0: 4.372  loss_ce_1: 1.039  loss_mask_1: 4.123  loss_ce_2: 1.347  loss_mask_2: 3.802  loss_ce_3: 1.691  loss_mask_3: 3.545  loss_ce_4: 1.94  loss_mask_4: 3.499  loss_ce_5: 1.995  loss_mask_5: 3.756  loss_ce_6: 1.925  loss_mask_6: 3.603  loss_ce_7: 1.908  loss_mask_7: 3.603  loss_ce_8: 1.871  loss_mask_8: 3.714  time: 2.4400  data_time: 0.3780  lr: 8.5693e-05  max_mem: 18490M
[01/24 08:26:00] d2.utils.events INFO:  eta: 1 day, 10:13:32  iter: 9479  total_loss: 55.81  loss_ce: 1.866  loss_mask: 3.675  loss_ce_0: 1.184  loss_mask_0: 4.565  loss_ce_1: 1.048  loss_mask_1: 4.212  loss_ce_2: 1.325  loss_mask_2: 4.136  loss_ce_3: 1.645  loss_mask_3: 3.773  loss_ce_4: 1.926  loss_mask_4: 3.722  loss_ce_5: 1.963  loss_mask_5: 3.724  loss_ce_6: 2.007  loss_mask_6: 3.828  loss_ce_7: 1.94  loss_mask_7: 3.603  loss_ce_8: 1.871  loss_mask_8: 3.629  time: 2.4398  data_time: 0.3408  lr: 8.5662e-05  max_mem: 18490M
[01/24 08:26:53] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 08:26:53] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 08:26:53] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 08:30:53] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 16.643516045900768, 'error_1pix': 0.8863271822908513, 'error_3pix': 0.761879299286047, 'mIoU': 0.2881883583362881, 'fwIoU': 1.3228842558759863, 'IoU-0': nan, 'IoU-1': 8.420779545922432, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 1.4934142564738441e-05, 'IoU-13': 1.2173019214819183, 'IoU-14': 0.10519800583984946, 'IoU-15': 4.2839374273241715, 'IoU-16': 0.0, 'IoU-17': 6.250436944607658e-05, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 1.927441854859606, 'IoU-22': 0.29012617274664354, 'IoU-23': 2.4383421748128578e-05, 'IoU-24': 0.15795895678265842, 'IoU-25': 0.8601790468433, 'IoU-26': 0.00011859660080855513, 'IoU-27': 0.001113228901030268, 'IoU-28': 0.7370374405345534, 'IoU-29': 0.0004327516676058632, 'IoU-30': 3.2805889356998557e-05, 'IoU-31': 3.704843559892256, 'IoU-32': 0.0006062217403240515, 'IoU-33': 3.4682843816223072, 'IoU-34': 0.23862998656507028, 'IoU-35': 0.00019122295504647632, 'IoU-36': 0.0, 'IoU-37': 2.4149215082964908, 'IoU-38': 0.22651117352626504, 'IoU-39': 7.726384935926724e-05, 'IoU-40': 0.13358458490164582, 'IoU-41': 0.19686918122898295, 'IoU-42': 0.3600428415743946, 'IoU-43': 1.0015491075471792, 'IoU-44': 0.004986715447284766, 'IoU-45': 0.34393432886126285, 'IoU-46': 0.25187924461398126, 'IoU-47': 8.093026528685391e-05, 'IoU-48': 0.0, 'IoU-49': 0.0004836920512624973, 'IoU-50': 0.0, 'IoU-51': 0.0005959414384874506, 'IoU-52': 1.0451377214555382e-05, 'IoU-53': 0.07044292075185025, 'IoU-54': 0.0007053475532892875, 'IoU-55': 0.0, 'IoU-56': 2.7810957243751173, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.002642884367142909, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 1.583843255277683, 'IoU-64': 3.803573933156943e-05, 'IoU-65': 0.0, 'IoU-66': 0.008020999402329072, 'IoU-67': 0.05631781934583196, 'IoU-68': 0.009969544545439798, 'IoU-69': 3.0319910081746215, 'IoU-70': 0.0019138986686878566, 'IoU-71': 0.36501757206199714, 'IoU-72': 0.005839325302595836, 'IoU-73': 0.05217007837151035, 'IoU-74': 0.000522614851146225, 'IoU-75': 0.006854382759578838, 'IoU-76': 0.0, 'IoU-77': 0.3449887694588099, 'IoU-78': 1.0590913501423067, 'IoU-79': 0.0, 'IoU-80': 0.05713732822668008, 'IoU-81': 0.0990390965081333, 'IoU-82': 2.084810620512172, 'IoU-83': 2.8171596533260894, 'IoU-84': 0.0998260329983268, 'IoU-85': 1.0907936988575027, 'IoU-86': 1.3987734094506208, 'IoU-87': 0.6601204281811026, 'IoU-88': 0.0, 'IoU-89': 0.9364478854395222, 'IoU-90': 0.18980326856083501, 'IoU-91': 0.08852768708387013, 'IoU-92': 0.1932826496441624, 'IoU-93': 0.0001473186025534144, 'IoU-94': 0.0, 'IoU-95': 0.06358291057782665, 'IoU-96': 2.865948931125388, 'IoU-97': 0.0, 'IoU-98': 0.2031287715591598, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 1.7575601504541905, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.056564395170997595, 'IoU-105': 0.0, 'IoU-106': 2.622045741063544e-05, 'IoU-107': 0.011077456486618918, 'IoU-108': 0.0, 'IoU-109': 0.0002517902285248114, 'IoU-110': 0.0, 'IoU-111': 0.1582075719688579, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.01066650973410966, 'IoU-116': 0.0073743193259947, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.018370154687508442, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.00030209381221244446, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.3740826840637498, 'IoU-138': 0.0003963786843398709, 'IoU-139': 0.0, 'IoU-140': 0.35744793860779056, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.5267991238579697, 'pACC': 4.66961170860765, 'ACC-0': nan, 'ACC-1': 13.881948473259706, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 1.4934944236331923e-05, 'ACC-13': 3.2453892029992595, 'ACC-14': 0.10581086228081049, 'ACC-15': 89.29091460873676, 'ACC-16': 0.0, 'ACC-17': 6.250639713908221e-05, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 6.548393191108487, 'ACC-22': 0.3140944528859574, 'ACC-23': 2.4383526538237822e-05, 'ACC-24': 0.16259459389345143, 'ACC-25': 1.5062154720811425, 'ACC-26': 0.00011859753849288378, 'ACC-27': 0.001116516063874869, 'ACC-28': 0.8773632938578403, 'ACC-29': 0.00043281633914477534, 'ACC-30': 3.2807232004351555e-05, 'ACC-31': 12.269365541439946, 'ACC-32': 0.000606332241592432, 'ACC-33': 23.734272881132107, 'ACC-34': 0.367785114454928, 'ACC-35': 0.0001912984543389858, 'ACC-36': 0.0, 'ACC-37': 18.854279694488916, 'ACC-38': 0.3954251079972103, 'ACC-39': 7.726468512664618e-05, 'ACC-40': 0.19827398071095992, 'ACC-41': 0.2187571499016228, 'ACC-42': 0.5049636803488909, 'ACC-43': 1.6362043516268385, 'ACC-44': 0.0049976395653588005, 'ACC-45': 0.5407471901500475, 'ACC-46': 0.26519286997351854, 'ACC-47': 8.09404737769692e-05, 'ACC-48': 0.0, 'ACC-49': 0.00048580842358208527, 'ACC-50': 0.0, 'ACC-51': 0.000598299983388377, 'ACC-52': 1.0452226010573472e-05, 'ACC-53': 0.08449915557982567, 'ACC-54': 0.0007058083320337497, 'ACC-55': 0.0, 'ACC-56': 8.699213982438543, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.002660190011767986, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 4.171628543222556, 'ACC-64': 3.803688227271132e-05, 'ACC-65': 0.0, 'ACC-66': 0.008084525502743016, 'ACC-67': 0.06084757465651433, 'ACC-68': 0.010010484040343546, 'ACC-69': 51.09100809773162, 'ACC-70': 0.001916837628814666, 'ACC-71': 0.43547987851637376, 'ACC-72': 0.005857737603646319, 'ACC-73': 0.05299285900231109, 'ACC-74': 0.0005228594705154642, 'ACC-75': 0.0069015298027057925, 'ACC-76': 0.0, 'ACC-77': 0.3739133719141749, 'ACC-78': 1.3123775309892491, 'ACC-79': 0.0, 'ACC-80': 0.05792177596701886, 'ACC-81': 0.10178201629442991, 'ACC-82': 4.322152912619721, 'ACC-83': 7.077745226280148, 'ACC-84': 0.10217746077951796, 'ACC-85': 1.5207915851376193, 'ACC-86': 6.620636824545666, 'ACC-87': 0.9888650068660816, 'ACC-88': 0.0, 'ACC-89': 1.31381038453215, 'ACC-90': 0.1970690794341585, 'ACC-91': 0.09083113138712949, 'ACC-92': 0.21453560868773233, 'ACC-93': 0.00014732072945564548, 'ACC-94': 0.0, 'ACC-95': 0.06638985862643192, 'ACC-96': 21.480801662783986, 'ACC-97': 0.0, 'ACC-98': 0.2816652732642391, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 5.952820034011324, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.05801628095718255, 'ACC-105': 0.0, 'ACC-106': 2.6222375710528048e-05, 'ACC-107': 0.01117776066211506, 'ACC-108': 0.0, 'ACC-109': 0.0002551443479148328, 'ACC-110': 0.0, 'ACC-111': 0.31649566373675486, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0109001247876355, 'ACC-116': 0.007742602866570978, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.018453862383528495, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.00030491858064059734, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.4528257532912487, 'ACC-138': 0.00039660380231997357, 'ACC-139': 0.0, 'ACC-140': 0.6331923662427715, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 08:30:53] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 08:30:53] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 08:30:53] d2.evaluation.testing INFO: copypaste: 16.6435,0.8863,0.7619,0.2882,1.3229,1.5268,4.6696
[01/24 08:30:53] d2.utils.events INFO:  eta: 1 day, 10:17:32  iter: 9499  total_loss: 54.86  loss_ce: 1.942  loss_mask: 3.65  loss_ce_0: 1.255  loss_mask_0: 4.438  loss_ce_1: 1.057  loss_mask_1: 4.216  loss_ce_2: 1.304  loss_mask_2: 3.873  loss_ce_3: 1.656  loss_mask_3: 3.758  loss_ce_4: 1.968  loss_mask_4: 3.624  loss_ce_5: 1.995  loss_mask_5: 3.476  loss_ce_6: 1.941  loss_mask_6: 3.407  loss_ce_7: 1.905  loss_mask_7: 3.513  loss_ce_8: 1.922  loss_mask_8: 3.66  time: 2.4402  data_time: 0.4123  lr: 8.5632e-05  max_mem: 18490M
[01/24 08:31:46] d2.utils.events INFO:  eta: 1 day, 10:19:31  iter: 9519  total_loss: 58.35  loss_ce: 1.912  loss_mask: 3.951  loss_ce_0: 1.278  loss_mask_0: 4.986  loss_ce_1: 1.112  loss_mask_1: 4.474  loss_ce_2: 1.359  loss_mask_2: 4.1  loss_ce_3: 1.713  loss_mask_3: 4.045  loss_ce_4: 1.921  loss_mask_4: 3.863  loss_ce_5: 2.002  loss_mask_5: 3.974  loss_ce_6: 2.004  loss_mask_6: 3.933  loss_ce_7: 1.925  loss_mask_7: 4.002  loss_ce_8: 1.934  loss_mask_8: 4.18  time: 2.4406  data_time: 0.4276  lr: 8.5601e-05  max_mem: 18490M
[01/24 08:32:34] d2.utils.events INFO:  eta: 1 day, 10:17:07  iter: 9539  total_loss: 56.96  loss_ce: 1.9  loss_mask: 3.741  loss_ce_0: 1.264  loss_mask_0: 4.682  loss_ce_1: 1.039  loss_mask_1: 4.143  loss_ce_2: 1.291  loss_mask_2: 3.846  loss_ce_3: 1.82  loss_mask_3: 4.23  loss_ce_4: 1.91  loss_mask_4: 3.933  loss_ce_5: 1.942  loss_mask_5: 3.852  loss_ce_6: 1.919  loss_mask_6: 3.649  loss_ce_7: 1.848  loss_mask_7: 3.593  loss_ce_8: 1.853  loss_mask_8: 3.916  time: 2.4406  data_time: 0.3721  lr: 8.5571e-05  max_mem: 18490M
[01/24 08:33:23] d2.utils.events INFO:  eta: 1 day, 10:17:53  iter: 9559  total_loss: 59.25  loss_ce: 1.861  loss_mask: 3.879  loss_ce_0: 1.331  loss_mask_0: 4.81  loss_ce_1: 1.093  loss_mask_1: 4.4  loss_ce_2: 1.532  loss_mask_2: 4.153  loss_ce_3: 2.025  loss_mask_3: 4.485  loss_ce_4: 2.03  loss_mask_4: 4.521  loss_ce_5: 1.984  loss_mask_5: 3.982  loss_ce_6: 1.934  loss_mask_6: 3.811  loss_ce_7: 1.908  loss_mask_7: 3.827  loss_ce_8: 1.935  loss_mask_8: 3.884  time: 2.4406  data_time: 0.3847  lr: 8.554e-05  max_mem: 18490M
[01/24 08:34:16] d2.utils.events INFO:  eta: 1 day, 10:19:31  iter: 9579  total_loss: 58.34  loss_ce: 1.871  loss_mask: 3.848  loss_ce_0: 1.365  loss_mask_0: 4.995  loss_ce_1: 1.086  loss_mask_1: 4.412  loss_ce_2: 1.482  loss_mask_2: 3.976  loss_ce_3: 1.976  loss_mask_3: 4.159  loss_ce_4: 1.963  loss_mask_4: 3.918  loss_ce_5: 2.015  loss_mask_5: 4.129  loss_ce_6: 1.983  loss_mask_6: 3.866  loss_ce_7: 1.934  loss_mask_7: 3.709  loss_ce_8: 1.948  loss_mask_8: 3.987  time: 2.4410  data_time: 0.4361  lr: 8.5509e-05  max_mem: 18490M
[01/24 08:35:06] d2.utils.events INFO:  eta: 1 day, 10:18:42  iter: 9599  total_loss: 57.19  loss_ce: 1.896  loss_mask: 3.654  loss_ce_0: 1.269  loss_mask_0: 5.164  loss_ce_1: 1.142  loss_mask_1: 4.277  loss_ce_2: 1.471  loss_mask_2: 3.811  loss_ce_3: 1.797  loss_mask_3: 3.785  loss_ce_4: 1.946  loss_mask_4: 3.789  loss_ce_5: 2.003  loss_mask_5: 3.807  loss_ce_6: 2.036  loss_mask_6: 3.814  loss_ce_7: 1.975  loss_mask_7: 3.75  loss_ce_8: 1.937  loss_mask_8: 3.822  time: 2.4411  data_time: 0.3750  lr: 8.5479e-05  max_mem: 18490M
[01/24 08:35:56] d2.utils.events INFO:  eta: 1 day, 10:23:04  iter: 9619  total_loss: 54.61  loss_ce: 1.845  loss_mask: 3.553  loss_ce_0: 1.288  loss_mask_0: 4.424  loss_ce_1: 1.127  loss_mask_1: 4.079  loss_ce_2: 1.396  loss_mask_2: 3.645  loss_ce_3: 1.777  loss_mask_3: 3.809  loss_ce_4: 1.938  loss_mask_4: 3.739  loss_ce_5: 1.984  loss_mask_5: 3.685  loss_ce_6: 1.99  loss_mask_6: 3.503  loss_ce_7: 1.977  loss_mask_7: 3.478  loss_ce_8: 1.879  loss_mask_8: 3.56  time: 2.4412  data_time: 0.3818  lr: 8.5448e-05  max_mem: 18490M
[01/24 08:36:45] d2.utils.events INFO:  eta: 1 day, 10:25:21  iter: 9639  total_loss: 56.22  loss_ce: 1.867  loss_mask: 3.861  loss_ce_0: 1.321  loss_mask_0: 4.38  loss_ce_1: 1.113  loss_mask_1: 4.16  loss_ce_2: 1.37  loss_mask_2: 3.781  loss_ce_3: 1.741  loss_mask_3: 3.746  loss_ce_4: 1.91  loss_mask_4: 3.75  loss_ce_5: 1.987  loss_mask_5: 3.78  loss_ce_6: 2.037  loss_mask_6: 3.78  loss_ce_7: 1.973  loss_mask_7: 3.88  loss_ce_8: 1.897  loss_mask_8: 3.643  time: 2.4413  data_time: 0.3892  lr: 8.5418e-05  max_mem: 18490M
[01/24 08:37:33] d2.utils.events INFO:  eta: 1 day, 10:21:31  iter: 9659  total_loss: 56.76  loss_ce: 1.877  loss_mask: 3.728  loss_ce_0: 1.205  loss_mask_0: 4.762  loss_ce_1: 1.086  loss_mask_1: 4.543  loss_ce_2: 1.369  loss_mask_2: 3.819  loss_ce_3: 1.712  loss_mask_3: 3.703  loss_ce_4: 1.856  loss_mask_4: 3.661  loss_ce_5: 1.927  loss_mask_5: 3.754  loss_ce_6: 1.992  loss_mask_6: 3.788  loss_ce_7: 1.974  loss_mask_7: 3.881  loss_ce_8: 1.888  loss_mask_8: 3.787  time: 2.4412  data_time: 0.3601  lr: 8.5387e-05  max_mem: 18490M
[01/24 08:38:21] d2.utils.events INFO:  eta: 1 day, 10:21:04  iter: 9679  total_loss: 55.13  loss_ce: 1.875  loss_mask: 3.562  loss_ce_0: 1.266  loss_mask_0: 4.128  loss_ce_1: 1.099  loss_mask_1: 3.965  loss_ce_2: 1.324  loss_mask_2: 3.669  loss_ce_3: 1.697  loss_mask_3: 3.729  loss_ce_4: 1.87  loss_mask_4: 3.727  loss_ce_5: 1.933  loss_mask_5: 3.84  loss_ce_6: 1.978  loss_mask_6: 3.603  loss_ce_7: 1.971  loss_mask_7: 3.535  loss_ce_8: 1.872  loss_mask_8: 3.819  time: 2.4411  data_time: 0.3750  lr: 8.5357e-05  max_mem: 18490M
[01/24 08:39:09] d2.utils.events INFO:  eta: 1 day, 10:20:26  iter: 9699  total_loss: 57.38  loss_ce: 1.931  loss_mask: 3.704  loss_ce_0: 1.136  loss_mask_0: 4.567  loss_ce_1: 1.047  loss_mask_1: 4.22  loss_ce_2: 1.316  loss_mask_2: 3.798  loss_ce_3: 1.786  loss_mask_3: 3.913  loss_ce_4: 1.914  loss_mask_4: 3.815  loss_ce_5: 2.007  loss_mask_5: 3.956  loss_ce_6: 2.023  loss_mask_6: 3.751  loss_ce_7: 2.058  loss_mask_7: 3.962  loss_ce_8: 1.902  loss_mask_8: 4.208  time: 2.4410  data_time: 0.3812  lr: 8.5326e-05  max_mem: 18490M
[01/24 08:39:56] d2.utils.events INFO:  eta: 1 day, 10:15:25  iter: 9719  total_loss: 55.77  loss_ce: 1.879  loss_mask: 3.682  loss_ce_0: 1.243  loss_mask_0: 4.247  loss_ce_1: 1.064  loss_mask_1: 4.032  loss_ce_2: 1.287  loss_mask_2: 3.651  loss_ce_3: 1.626  loss_mask_3: 3.573  loss_ce_4: 1.839  loss_mask_4: 3.463  loss_ce_5: 1.921  loss_mask_5: 3.504  loss_ce_6: 2.041  loss_mask_6: 3.989  loss_ce_7: 2.12  loss_mask_7: 4.163  loss_ce_8: 1.902  loss_mask_8: 4.277  time: 2.4408  data_time: 0.3746  lr: 8.5296e-05  max_mem: 18490M
[01/24 08:40:44] d2.utils.events INFO:  eta: 1 day, 10:15:46  iter: 9739  total_loss: 56.85  loss_ce: 1.892  loss_mask: 3.732  loss_ce_0: 1.23  loss_mask_0: 4.701  loss_ce_1: 1.058  loss_mask_1: 4.362  loss_ce_2: 1.299  loss_mask_2: 3.885  loss_ce_3: 1.645  loss_mask_3: 3.847  loss_ce_4: 1.893  loss_mask_4: 3.671  loss_ce_5: 1.944  loss_mask_5: 3.749  loss_ce_6: 1.934  loss_mask_6: 3.816  loss_ce_7: 2.052  loss_mask_7: 3.914  loss_ce_8: 1.899  loss_mask_8: 4.068  time: 2.4407  data_time: 0.3832  lr: 8.5265e-05  max_mem: 18490M
[01/24 08:41:32] d2.utils.events INFO:  eta: 1 day, 10:13:16  iter: 9759  total_loss: 55.5  loss_ce: 1.889  loss_mask: 3.636  loss_ce_0: 1.217  loss_mask_0: 4.455  loss_ce_1: 1.084  loss_mask_1: 4.204  loss_ce_2: 1.419  loss_mask_2: 3.823  loss_ce_3: 1.746  loss_mask_3: 3.652  loss_ce_4: 1.918  loss_mask_4: 3.665  loss_ce_5: 1.991  loss_mask_5: 3.616  loss_ce_6: 1.952  loss_mask_6: 3.53  loss_ce_7: 2.049  loss_mask_7: 3.909  loss_ce_8: 1.847  loss_mask_8: 3.776  time: 2.4406  data_time: 0.3852  lr: 8.5235e-05  max_mem: 18490M
[01/24 08:42:19] d2.utils.events INFO:  eta: 1 day, 10:10:25  iter: 9779  total_loss: 54.85  loss_ce: 1.855  loss_mask: 3.531  loss_ce_0: 1.225  loss_mask_0: 4.572  loss_ce_1: 1.076  loss_mask_1: 4.121  loss_ce_2: 1.407  loss_mask_2: 3.863  loss_ce_3: 1.739  loss_mask_3: 3.729  loss_ce_4: 1.901  loss_mask_4: 3.711  loss_ce_5: 1.922  loss_mask_5: 3.615  loss_ce_6: 1.926  loss_mask_6: 3.637  loss_ce_7: 1.981  loss_mask_7: 3.635  loss_ce_8: 1.831  loss_mask_8: 3.575  time: 2.4405  data_time: 0.3826  lr: 8.5204e-05  max_mem: 18490M
[01/24 08:43:07] d2.utils.events INFO:  eta: 1 day, 10:09:36  iter: 9799  total_loss: 53.73  loss_ce: 1.902  loss_mask: 3.682  loss_ce_0: 1.167  loss_mask_0: 4.559  loss_ce_1: 1.052  loss_mask_1: 4.014  loss_ce_2: 1.308  loss_mask_2: 3.71  loss_ce_3: 1.691  loss_mask_3: 3.743  loss_ce_4: 1.866  loss_mask_4: 3.448  loss_ce_5: 1.89  loss_mask_5: 3.472  loss_ce_6: 1.883  loss_mask_6: 3.438  loss_ce_7: 1.979  loss_mask_7: 3.525  loss_ce_8: 1.832  loss_mask_8: 3.618  time: 2.4403  data_time: 0.3809  lr: 8.5174e-05  max_mem: 18490M
[01/24 08:43:54] d2.utils.events INFO:  eta: 1 day, 10:07:41  iter: 9819  total_loss: 56.3  loss_ce: 1.88  loss_mask: 3.851  loss_ce_0: 1.304  loss_mask_0: 4.623  loss_ce_1: 1.071  loss_mask_1: 4.128  loss_ce_2: 1.286  loss_mask_2: 3.77  loss_ce_3: 1.614  loss_mask_3: 3.508  loss_ce_4: 1.833  loss_mask_4: 3.488  loss_ce_5: 1.906  loss_mask_5: 3.518  loss_ce_6: 1.904  loss_mask_6: 3.663  loss_ce_7: 2.061  loss_mask_7: 4.249  loss_ce_8: 1.943  loss_mask_8: 4.1  time: 2.4401  data_time: 0.3929  lr: 8.5143e-05  max_mem: 18490M
[01/24 08:44:41] d2.utils.events INFO:  eta: 1 day, 10:06:11  iter: 9839  total_loss: 58.11  loss_ce: 1.868  loss_mask: 3.991  loss_ce_0: 1.351  loss_mask_0: 4.835  loss_ce_1: 1.031  loss_mask_1: 4.453  loss_ce_2: 1.232  loss_mask_2: 3.912  loss_ce_3: 1.548  loss_mask_3: 3.709  loss_ce_4: 1.844  loss_mask_4: 3.649  loss_ce_5: 1.884  loss_mask_5: 3.839  loss_ce_6: 1.931  loss_mask_6: 3.983  loss_ce_7: 2.145  loss_mask_7: 4.118  loss_ce_8: 1.979  loss_mask_8: 4.054  time: 2.4400  data_time: 0.3465  lr: 8.5113e-05  max_mem: 18490M
[01/24 08:45:30] d2.utils.events INFO:  eta: 1 day, 10:07:09  iter: 9859  total_loss: 54.25  loss_ce: 1.848  loss_mask: 3.711  loss_ce_0: 1.324  loss_mask_0: 4.422  loss_ce_1: 1.09  loss_mask_1: 4.133  loss_ce_2: 1.274  loss_mask_2: 3.641  loss_ce_3: 1.569  loss_mask_3: 3.543  loss_ce_4: 1.836  loss_mask_4: 3.497  loss_ce_5: 1.924  loss_mask_5: 3.712  loss_ce_6: 1.906  loss_mask_6: 3.827  loss_ce_7: 2.008  loss_mask_7: 3.658  loss_ce_8: 1.872  loss_mask_8: 3.608  time: 2.4400  data_time: 0.3725  lr: 8.5082e-05  max_mem: 18490M
[01/24 08:46:23] d2.utils.events INFO:  eta: 1 day, 10:05:40  iter: 9879  total_loss: 54.46  loss_ce: 1.828  loss_mask: 3.632  loss_ce_0: 1.26  loss_mask_0: 4.475  loss_ce_1: 1.039  loss_mask_1: 4.256  loss_ce_2: 1.248  loss_mask_2: 3.788  loss_ce_3: 1.552  loss_mask_3: 3.563  loss_ce_4: 1.838  loss_mask_4: 3.542  loss_ce_5: 1.928  loss_mask_5: 3.652  loss_ce_6: 1.896  loss_mask_6: 3.767  loss_ce_7: 1.949  loss_mask_7: 3.687  loss_ce_8: 1.846  loss_mask_8: 3.65  time: 2.4404  data_time: 0.4321  lr: 8.5051e-05  max_mem: 18490M
[01/24 08:47:12] d2.utils.events INFO:  eta: 1 day, 10:05:46  iter: 9899  total_loss: 54.94  loss_ce: 1.824  loss_mask: 3.634  loss_ce_0: 1.25  loss_mask_0: 4.422  loss_ce_1: 1.088  loss_mask_1: 4.168  loss_ce_2: 1.322  loss_mask_2: 3.761  loss_ce_3: 1.607  loss_mask_3: 3.642  loss_ce_4: 1.889  loss_mask_4: 3.66  loss_ce_5: 1.989  loss_mask_5: 3.858  loss_ce_6: 1.922  loss_mask_6: 3.72  loss_ce_7: 1.939  loss_mask_7: 3.615  loss_ce_8: 1.85  loss_mask_8: 3.794  time: 2.4404  data_time: 0.3878  lr: 8.5021e-05  max_mem: 18490M
[01/24 08:48:00] d2.utils.events INFO:  eta: 1 day, 10:04:57  iter: 9919  total_loss: 53.68  loss_ce: 1.829  loss_mask: 3.577  loss_ce_0: 1.299  loss_mask_0: 4.406  loss_ce_1: 1.088  loss_mask_1: 4.016  loss_ce_2: 1.277  loss_mask_2: 3.62  loss_ce_3: 1.581  loss_mask_3: 3.574  loss_ce_4: 1.867  loss_mask_4: 3.462  loss_ce_5: 1.875  loss_mask_5: 3.471  loss_ce_6: 1.903  loss_mask_6: 3.693  loss_ce_7: 1.925  loss_mask_7: 3.543  loss_ce_8: 1.837  loss_mask_8: 3.88  time: 2.4404  data_time: 0.3566  lr: 8.499e-05  max_mem: 18490M
[01/24 08:48:51] d2.utils.events INFO:  eta: 1 day, 10:03:31  iter: 9939  total_loss: 52.32  loss_ce: 1.796  loss_mask: 3.412  loss_ce_0: 1.292  loss_mask_0: 4.131  loss_ce_1: 1.198  loss_mask_1: 3.795  loss_ce_2: 1.332  loss_mask_2: 3.65  loss_ce_3: 1.61  loss_mask_3: 3.4  loss_ce_4: 1.844  loss_mask_4: 3.32  loss_ce_5: 1.883  loss_mask_5: 3.466  loss_ce_6: 1.937  loss_mask_6: 3.712  loss_ce_7: 1.933  loss_mask_7: 3.493  loss_ce_8: 1.813  loss_mask_8: 3.467  time: 2.4406  data_time: 0.3975  lr: 8.496e-05  max_mem: 18490M
[01/24 08:49:40] d2.utils.events INFO:  eta: 1 day, 10:01:58  iter: 9959  total_loss: 53.61  loss_ce: 1.874  loss_mask: 3.551  loss_ce_0: 1.187  loss_mask_0: 4.314  loss_ce_1: 1.213  loss_mask_1: 4.073  loss_ce_2: 1.297  loss_mask_2: 3.768  loss_ce_3: 1.581  loss_mask_3: 3.537  loss_ce_4: 1.863  loss_mask_4: 3.434  loss_ce_5: 1.92  loss_mask_5: 3.659  loss_ce_6: 1.934  loss_mask_6: 3.616  loss_ce_7: 1.937  loss_mask_7: 3.454  loss_ce_8: 1.857  loss_mask_8: 3.542  time: 2.4406  data_time: 0.3519  lr: 8.4929e-05  max_mem: 18490M
[01/24 08:50:29] d2.utils.events INFO:  eta: 1 day, 10:02:55  iter: 9979  total_loss: 51.96  loss_ce: 1.825  loss_mask: 3.433  loss_ce_0: 1.2  loss_mask_0: 3.956  loss_ce_1: 1.311  loss_mask_1: 3.716  loss_ce_2: 1.359  loss_mask_2: 3.482  loss_ce_3: 1.569  loss_mask_3: 3.411  loss_ce_4: 1.852  loss_mask_4: 3.523  loss_ce_5: 1.883  loss_mask_5: 3.378  loss_ce_6: 2.051  loss_mask_6: 3.399  loss_ce_7: 1.982  loss_mask_7: 3.409  loss_ce_8: 1.818  loss_mask_8: 3.266  time: 2.4406  data_time: 0.4135  lr: 8.4899e-05  max_mem: 18490M
[01/24 08:51:20] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/model_0009999.pth
[01/24 08:51:20] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 08:51:21] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 08:51:21] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 08:55:14] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 14.064551869934036, 'error_1pix': 0.9243752972572868, 'error_3pix': 0.8240402005154158, 'mIoU': 0.13041298219539962, 'fwIoU': 0.25185405763687574, 'IoU-0': nan, 'IoU-1': 0.05144716611600026, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0021020927345090875, 'IoU-12': 1.706807252966479e-05, 'IoU-13': 0.00041876965233379315, 'IoU-14': 9.631833234524993e-05, 'IoU-15': 0.0955226652174178, 'IoU-16': 2.1185548034774277e-05, 'IoU-17': 1.8751210625035978e-05, 'IoU-18': 0.0, 'IoU-19': 0.04013045010744377, 'IoU-20': 0.01860047584146454, 'IoU-21': 1.3464107610200948, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 1.8787511675338184, 'IoU-26': 0.0004224597215808078, 'IoU-27': 0.0014728708487253685, 'IoU-28': 0.03939740361092733, 'IoU-29': 0.0, 'IoU-30': 4.254977737230472, 'IoU-31': 0.038898633533725004, 'IoU-32': 0.002018811644115873, 'IoU-33': 0.011462901283932824, 'IoU-34': 3.0777485679428667, 'IoU-35': 0.18049112663996789, 'IoU-36': 0.11209478534765874, 'IoU-37': 0.08922480562243769, 'IoU-38': 0.0, 'IoU-39': 0.2623228760365858, 'IoU-40': 0.9580890175037226, 'IoU-41': 0.0, 'IoU-42': 8.129426693743078e-05, 'IoU-43': 1.0294846145012242, 'IoU-44': 0.0, 'IoU-45': 0.020318550648994117, 'IoU-46': 0.0, 'IoU-47': 0.008096012241465058, 'IoU-48': 0.19986044094429592, 'IoU-49': 3.6290565310383906e-05, 'IoU-50': 0.002797256509899057, 'IoU-51': 0.012408600157960139, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.7240967152899793, 'IoU-55': 0.004139202379834703, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.09458806621939335, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0008136182363757512, 'IoU-68': 0.0009485212715056989, 'IoU-69': 4.2363775836740176e-05, 'IoU-70': 0.0, 'IoU-71': 9.918006736310175e-05, 'IoU-72': 0.4520531455083858, 'IoU-73': 0.0024248046048362067, 'IoU-74': 0.0, 'IoU-75': 0.10561599745728556, 'IoU-76': 0.029598814719924066, 'IoU-77': 1.4072462108196846, 'IoU-78': 0.00014418174530449966, 'IoU-79': 0.016542865700169006, 'IoU-80': 0.018532854584285385, 'IoU-81': 2.334442361946273, 'IoU-82': 0.0037297271687775466, 'IoU-83': 0.6327285237568904, 'IoU-84': 0.7990643330384293, 'IoU-85': 0.006762812659526025, 'IoU-86': 0.0008030857767887331, 'IoU-87': 0.0008168673600041747, 'IoU-88': 0.0, 'IoU-89': 0.03495819378082931, 'IoU-90': 0.0030809546175384834, 'IoU-91': 1.0404143995644182, 'IoU-92': 0.3510742914227339, 'IoU-93': 0.022273569234453276, 'IoU-94': 0.006019675912688213, 'IoU-95': 0.0008418304949355321, 'IoU-96': 0.0, 'IoU-97': 1.7106073220493693e-05, 'IoU-98': 0.3490231723734284, 'IoU-99': 0.005674295441649328, 'IoU-100': 0.0002229674741129695, 'IoU-101': 0.542548040609373, 'IoU-102': 0.0004287466989324884, 'IoU-103': 0.0, 'IoU-104': 0.0007834005262493035, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.004667387579050486, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.6562275178554831, 'IoU-111': 0.03371693068109723, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0006013100290620653, 'IoU-116': 0.0011770009310077365, 'IoU-117': 0.0, 'IoU-118': 0.00046106823642237877, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.03564361937536343, 'IoU-122': 0.7739508732051525, 'IoU-123': 0.0, 'IoU-124': 0.0021949406151811433, 'IoU-125': 0.00010860581627588485, 'IoU-126': 0.0, 'IoU-127': 0.18977957892655925, 'IoU-128': 0.00624487544364636, 'IoU-129': 6.135195160558057e-05, 'IoU-130': 0.38096901518758647, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.17060997915998274, 'IoU-134': 0.0, 'IoU-135': 0.0001425222156503645, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.01186006393018418, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0001826854394224217, 'IoU-147': 0.0, 'IoU-148': 0.00018055821377370277, 'IoU-149': 0.0, 'IoU-150': 0.04146808824251953, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.001207781980859071, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.0993420155252869, 'pACC': 2.4883850618766834, 'ACC-0': nan, 'ACC-1': 0.051500310528058514, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0021075859594084354, 'ACC-12': 1.7068507698665057e-05, 'ACC-13': 0.0004192383920939821, 'ACC-14': 9.634350699357518e-05, 'ACC-15': 0.18621734925826222, 'ACC-16': 2.1185773572966678e-05, 'ACC-17': 1.875191914172466e-05, 'ACC-18': 0.0, 'ACC-19': 0.04037659748946698, 'ACC-20': 0.04862932611017613, 'ACC-21': 10.146692943675038, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 24.927500789664585, 'ACC-26': 0.00042269379103873953, 'ACC-27': 0.001488688085166492, 'ACC-28': 0.04068983844269535, 'ACC-29': 0.0, 'ACC-30': 73.20857271563038, 'ACC-31': 0.04078224377252256, 'ACC-32': 0.002019302911731939, 'ACC-33': 0.011923069748843992, 'ACC-34': 22.67121069916982, 'ACC-35': 0.20134023697109893, 'ACC-36': 0.117540917085507, 'ACC-37': 0.10764804976085902, 'ACC-38': 0.0, 'ACC-39': 0.6985351596367145, 'ACC-40': 4.830673775709035, 'ACC-41': 0.0, 'ACC-42': 8.13077711599144e-05, 'ACC-43': 6.343005107891414, 'ACC-44': 0.0, 'ACC-45': 0.022113942276783233, 'ACC-46': 0.0, 'ACC-47': 0.008430589347611688, 'ACC-48': 0.25140732002840566, 'ACC-49': 3.632212512763254e-05, 'ACC-50': 0.002853902513892524, 'ACC-51': 0.012564299651155915, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 1.6346633002970221, 'ACC-55': 0.0041481111182514645, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.09641154284235554, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0008146867064078601, 'ACC-68': 0.0009492700383084395, 'ACC-69': 4.2368218159039483e-05, 'ACC-70': 0.0, 'ACC-71': 9.923331240245502e-05, 'ACC-72': 0.5302811624958684, 'ACC-73': 0.002430865091849133, 'ACC-74': 0.0, 'ACC-75': 0.1116912133260678, 'ACC-76': 0.030225891409619503, 'ACC-77': 6.800086194493464, 'ACC-78': 0.00014419537097364927, 'ACC-79': 0.016573601660835276, 'ACC-80': 0.018787532907209824, 'ACC-81': 41.033299095751104, 'ACC-82': 0.0037466339363126234, 'ACC-83': 4.069224099198237, 'ACC-84': 1.0689334358472649, 'ACC-85': 0.006816268129074427, 'ACC-86': 0.000830078732967822, 'ACC-87': 0.0008197210697188674, 'ACC-88': 0.0, 'ACC-89': 0.03649117376141102, 'ACC-90': 0.0030873461016588818, 'ACC-91': 1.8981597272589463, 'ACC-92': 0.5125278016790572, 'ACC-93': 0.026090501186594815, 'ACC-94': 0.006081970363774811, 'ACC-95': 0.0008499412910923004, 'ACC-96': 0.0, 'ACC-97': 1.712085733035499e-05, 'ACC-98': 0.773830295679935, 'ACC-99': 0.005727368025627754, 'ACC-100': 0.0002230066650610187, 'ACC-101': 0.7526381129733085, 'ACC-102': 0.0004304485727231536, 'ACC-103': 0.0, 'ACC-104': 0.0007869949091266816, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.004677797649352288, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 4.642642394891678, 'ACC-111': 0.03469261310591025, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0006013861951798897, 'ACC-116': 0.001179076578665631, 'ACC-117': 0.0, 'ACC-118': 0.0004618555592923869, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.04078801722544282, 'ACC-122': 1.99434836347854, 'ACC-123': 0.0, 'ACC-124': 0.0025038610069463498, 'ACC-125': 0.00010877096424372092, 'ACC-126': 0.0, 'ACC-127': 0.20745918567597119, 'ACC-128': 0.006586241341836902, 'ACC-129': 6.275261850988887e-05, 'ACC-130': 0.4417079632548505, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.20950281355678488, 'ACC-134': 0.0, 'ACC-135': 0.00014252323128669973, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.015737058163157104, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0001827694135386443, 'ACC-147': 0.0, 'ACC-148': 0.00019010485233130332, 'ACC-149': 0.0, 'ACC-150': 0.043985411852505034, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0012080358545041618, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 08:55:14] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 08:55:14] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 08:55:14] d2.evaluation.testing INFO: copypaste: 14.0646,0.9244,0.8240,0.1304,0.2519,1.0993,2.4884
[01/24 08:55:14] d2.utils.events INFO:  eta: 1 day, 10:01:08  iter: 9999  total_loss: 52.15  loss_ce: 1.818  loss_mask: 3.368  loss_ce_0: 1.114  loss_mask_0: 4.061  loss_ce_1: 1.159  loss_mask_1: 3.77  loss_ce_2: 1.368  loss_mask_2: 3.573  loss_ce_3: 1.629  loss_mask_3: 3.455  loss_ce_4: 1.856  loss_mask_4: 3.436  loss_ce_5: 1.941  loss_mask_5: 3.486  loss_ce_6: 2.048  loss_mask_6: 3.584  loss_ce_7: 1.963  loss_mask_7: 3.301  loss_ce_8: 1.84  loss_mask_8: 3.496  time: 2.4408  data_time: 0.4061  lr: 8.4868e-05  max_mem: 18490M
[01/24 08:56:06] d2.utils.events INFO:  eta: 1 day, 10:00:52  iter: 10019  total_loss: 55.83  loss_ce: 1.815  loss_mask: 3.642  loss_ce_0: 1.091  loss_mask_0: 4.45  loss_ce_1: 1.135  loss_mask_1: 4.092  loss_ce_2: 1.299  loss_mask_2: 3.812  loss_ce_3: 1.702  loss_mask_3: 3.696  loss_ce_4: 1.91  loss_mask_4: 3.769  loss_ce_5: 2.011  loss_mask_5: 3.664  loss_ce_6: 2  loss_mask_6: 3.998  loss_ce_7: 1.907  loss_mask_7: 3.531  loss_ce_8: 1.867  loss_mask_8: 3.796  time: 2.4411  data_time: 0.4129  lr: 8.4838e-05  max_mem: 18490M
[01/24 08:56:56] d2.utils.events INFO:  eta: 1 day, 10:01:31  iter: 10039  total_loss: 54.34  loss_ce: 1.875  loss_mask: 3.516  loss_ce_0: 1.144  loss_mask_0: 4.159  loss_ce_1: 1.05  loss_mask_1: 3.931  loss_ce_2: 1.254  loss_mask_2: 3.838  loss_ce_3: 1.662  loss_mask_3: 3.609  loss_ce_4: 1.933  loss_mask_4: 3.464  loss_ce_5: 1.925  loss_mask_5: 3.622  loss_ce_6: 1.997  loss_mask_6: 3.876  loss_ce_7: 1.954  loss_mask_7: 3.673  loss_ce_8: 1.913  loss_mask_8: 3.815  time: 2.4412  data_time: 0.3853  lr: 8.4807e-05  max_mem: 18490M
[01/24 08:57:45] d2.utils.events INFO:  eta: 1 day, 9:58:15  iter: 10059  total_loss: 52.8  loss_ce: 1.809  loss_mask: 3.542  loss_ce_0: 1.138  loss_mask_0: 4.225  loss_ce_1: 1.098  loss_mask_1: 4.116  loss_ce_2: 1.226  loss_mask_2: 3.811  loss_ce_3: 1.604  loss_mask_3: 3.409  loss_ce_4: 1.903  loss_mask_4: 3.514  loss_ce_5: 1.906  loss_mask_5: 3.451  loss_ce_6: 1.893  loss_mask_6: 3.557  loss_ce_7: 2.008  loss_mask_7: 3.585  loss_ce_8: 1.858  loss_mask_8: 3.673  time: 2.4412  data_time: 0.3929  lr: 8.4776e-05  max_mem: 18490M
[01/24 08:58:35] d2.utils.events INFO:  eta: 1 day, 9:57:52  iter: 10079  total_loss: 53.01  loss_ce: 1.767  loss_mask: 3.357  loss_ce_0: 1.226  loss_mask_0: 4.056  loss_ce_1: 1.149  loss_mask_1: 3.913  loss_ce_2: 1.234  loss_mask_2: 3.518  loss_ce_3: 1.576  loss_mask_3: 3.307  loss_ce_4: 1.857  loss_mask_4: 3.318  loss_ce_5: 2.05  loss_mask_5: 4.099  loss_ce_6: 1.907  loss_mask_6: 3.541  loss_ce_7: 1.978  loss_mask_7: 3.585  loss_ce_8: 1.861  loss_mask_8: 3.483  time: 2.4413  data_time: 0.3874  lr: 8.4746e-05  max_mem: 18490M
[01/24 08:59:24] d2.utils.events INFO:  eta: 1 day, 9:59:04  iter: 10099  total_loss: 53.54  loss_ce: 1.832  loss_mask: 3.561  loss_ce_0: 1.166  loss_mask_0: 4.311  loss_ce_1: 1.135  loss_mask_1: 3.854  loss_ce_2: 1.207  loss_mask_2: 3.595  loss_ce_3: 1.541  loss_mask_3: 3.31  loss_ce_4: 1.885  loss_mask_4: 3.5  loss_ce_5: 2.103  loss_mask_5: 3.801  loss_ce_6: 1.973  loss_mask_6: 3.623  loss_ce_7: 1.987  loss_mask_7: 3.541  loss_ce_8: 1.871  loss_mask_8: 3.527  time: 2.4414  data_time: 0.3706  lr: 8.4715e-05  max_mem: 18490M
[01/24 09:00:16] d2.utils.events INFO:  eta: 1 day, 9:59:00  iter: 10119  total_loss: 53.15  loss_ce: 1.851  loss_mask: 3.498  loss_ce_0: 1.217  loss_mask_0: 4.112  loss_ce_1: 1.232  loss_mask_1: 3.781  loss_ce_2: 1.301  loss_mask_2: 3.531  loss_ce_3: 1.589  loss_mask_3: 3.293  loss_ce_4: 1.842  loss_mask_4: 3.339  loss_ce_5: 2.045  loss_mask_5: 3.491  loss_ce_6: 1.963  loss_mask_6: 3.574  loss_ce_7: 1.978  loss_mask_7: 3.873  loss_ce_8: 1.921  loss_mask_8: 3.665  time: 2.4416  data_time: 0.4002  lr: 8.4685e-05  max_mem: 18490M
[01/24 09:01:05] d2.utils.events INFO:  eta: 1 day, 9:59:25  iter: 10139  total_loss: 54.72  loss_ce: 1.934  loss_mask: 3.78  loss_ce_0: 1.133  loss_mask_0: 4.182  loss_ce_1: 1.242  loss_mask_1: 3.978  loss_ce_2: 1.264  loss_mask_2: 3.623  loss_ce_3: 1.563  loss_mask_3: 3.426  loss_ce_4: 1.85  loss_mask_4: 3.466  loss_ce_5: 2.074  loss_mask_5: 3.56  loss_ce_6: 1.992  loss_mask_6: 3.476  loss_ce_7: 1.947  loss_mask_7: 3.905  loss_ce_8: 1.898  loss_mask_8: 3.707  time: 2.4416  data_time: 0.4237  lr: 8.4654e-05  max_mem: 18490M
[01/24 09:01:53] d2.utils.events INFO:  eta: 1 day, 9:57:41  iter: 10159  total_loss: 55.28  loss_ce: 1.876  loss_mask: 3.733  loss_ce_0: 1.155  loss_mask_0: 4.353  loss_ce_1: 1.189  loss_mask_1: 4.086  loss_ce_2: 1.264  loss_mask_2: 3.823  loss_ce_3: 1.596  loss_mask_3: 3.675  loss_ce_4: 1.905  loss_mask_4: 3.675  loss_ce_5: 2.029  loss_mask_5: 3.812  loss_ce_6: 1.928  loss_mask_6: 3.594  loss_ce_7: 1.916  loss_mask_7: 3.599  loss_ce_8: 1.859  loss_mask_8: 3.692  time: 2.4416  data_time: 0.3857  lr: 8.4624e-05  max_mem: 18490M
[01/24 09:02:45] d2.utils.events INFO:  eta: 1 day, 9:55:48  iter: 10179  total_loss: 54.21  loss_ce: 1.857  loss_mask: 3.609  loss_ce_0: 1.126  loss_mask_0: 4.27  loss_ce_1: 1.231  loss_mask_1: 4.033  loss_ce_2: 1.277  loss_mask_2: 3.783  loss_ce_3: 1.563  loss_mask_3: 3.57  loss_ce_4: 1.923  loss_mask_4: 3.558  loss_ce_5: 2.05  loss_mask_5: 3.599  loss_ce_6: 2.012  loss_mask_6: 3.713  loss_ce_7: 2.006  loss_mask_7: 3.68  loss_ce_8: 1.881  loss_mask_8: 3.595  time: 2.4419  data_time: 0.4188  lr: 8.4593e-05  max_mem: 18490M
[01/24 09:03:33] d2.utils.events INFO:  eta: 1 day, 9:54:22  iter: 10199  total_loss: 53.51  loss_ce: 1.844  loss_mask: 3.465  loss_ce_0: 1.154  loss_mask_0: 4.126  loss_ce_1: 1.15  loss_mask_1: 3.97  loss_ce_2: 1.211  loss_mask_2: 3.661  loss_ce_3: 1.505  loss_mask_3: 3.462  loss_ce_4: 1.832  loss_mask_4: 3.647  loss_ce_5: 1.975  loss_mask_5: 3.746  loss_ce_6: 1.94  loss_mask_6: 3.92  loss_ce_7: 1.933  loss_mask_7: 3.754  loss_ce_8: 1.859  loss_mask_8: 3.47  time: 2.4418  data_time: 0.3872  lr: 8.4563e-05  max_mem: 18490M
[01/24 09:04:22] d2.utils.events INFO:  eta: 1 day, 9:52:27  iter: 10219  total_loss: 51.45  loss_ce: 1.835  loss_mask: 3.371  loss_ce_0: 1.227  loss_mask_0: 3.98  loss_ce_1: 1.214  loss_mask_1: 3.881  loss_ce_2: 1.18  loss_mask_2: 3.528  loss_ce_3: 1.473  loss_mask_3: 3.321  loss_ce_4: 1.826  loss_mask_4: 3.163  loss_ce_5: 1.909  loss_mask_5: 3.397  loss_ce_6: 1.875  loss_mask_6: 3.287  loss_ce_7: 1.906  loss_mask_7: 3.33  loss_ce_8: 1.84  loss_mask_8: 3.421  time: 2.4418  data_time: 0.3883  lr: 8.4532e-05  max_mem: 18490M
[01/24 09:05:14] d2.utils.events INFO:  eta: 1 day, 9:52:32  iter: 10239  total_loss: 52.39  loss_ce: 1.853  loss_mask: 3.459  loss_ce_0: 1.106  loss_mask_0: 4.042  loss_ce_1: 1.217  loss_mask_1: 4  loss_ce_2: 1.182  loss_mask_2: 3.731  loss_ce_3: 1.496  loss_mask_3: 3.479  loss_ce_4: 1.854  loss_mask_4: 3.398  loss_ce_5: 1.922  loss_mask_5: 3.576  loss_ce_6: 1.89  loss_mask_6: 3.358  loss_ce_7: 1.913  loss_mask_7: 3.53  loss_ce_8: 1.839  loss_mask_8: 3.462  time: 2.4421  data_time: 0.4321  lr: 8.4501e-05  max_mem: 18490M
[01/24 09:06:01] d2.utils.events INFO:  eta: 1 day, 9:50:29  iter: 10259  total_loss: 52.7  loss_ce: 1.841  loss_mask: 3.411  loss_ce_0: 1.135  loss_mask_0: 4.073  loss_ce_1: 1.173  loss_mask_1: 3.901  loss_ce_2: 1.191  loss_mask_2: 3.695  loss_ce_3: 1.473  loss_mask_3: 3.449  loss_ce_4: 1.859  loss_mask_4: 3.516  loss_ce_5: 1.905  loss_mask_5: 3.438  loss_ce_6: 1.879  loss_mask_6: 3.465  loss_ce_7: 1.906  loss_mask_7: 3.504  loss_ce_8: 1.842  loss_mask_8: 3.522  time: 2.4419  data_time: 0.3815  lr: 8.4471e-05  max_mem: 18490M
[01/24 09:06:50] d2.utils.events INFO:  eta: 1 day, 9:47:54  iter: 10279  total_loss: 54.62  loss_ce: 1.89  loss_mask: 3.599  loss_ce_0: 1.244  loss_mask_0: 4.159  loss_ce_1: 1.256  loss_mask_1: 4.021  loss_ce_2: 1.283  loss_mask_2: 3.757  loss_ce_3: 1.614  loss_mask_3: 3.575  loss_ce_4: 1.939  loss_mask_4: 3.944  loss_ce_5: 1.93  loss_mask_5: 3.677  loss_ce_6: 1.888  loss_mask_6: 3.602  loss_ce_7: 1.952  loss_mask_7: 3.555  loss_ce_8: 1.885  loss_mask_8: 3.679  time: 2.4420  data_time: 0.3860  lr: 8.444e-05  max_mem: 18490M
[01/24 09:07:42] d2.utils.events INFO:  eta: 1 day, 9:49:46  iter: 10299  total_loss: 54.56  loss_ce: 1.921  loss_mask: 3.566  loss_ce_0: 1.245  loss_mask_0: 4.185  loss_ce_1: 1.318  loss_mask_1: 3.915  loss_ce_2: 1.286  loss_mask_2: 3.723  loss_ce_3: 1.702  loss_mask_3: 3.491  loss_ce_4: 1.943  loss_mask_4: 3.835  loss_ce_5: 1.955  loss_mask_5: 3.573  loss_ce_6: 1.885  loss_mask_6: 3.57  loss_ce_7: 1.948  loss_mask_7: 3.642  loss_ce_8: 1.946  loss_mask_8: 3.464  time: 2.4422  data_time: 0.4319  lr: 8.441e-05  max_mem: 18490M
[01/24 09:08:30] d2.utils.events INFO:  eta: 1 day, 9:47:15  iter: 10319  total_loss: 54.12  loss_ce: 1.874  loss_mask: 3.445  loss_ce_0: 1.167  loss_mask_0: 4.008  loss_ce_1: 1.272  loss_mask_1: 3.81  loss_ce_2: 1.253  loss_mask_2: 3.652  loss_ce_3: 1.667  loss_mask_3: 3.664  loss_ce_4: 1.927  loss_mask_4: 3.612  loss_ce_5: 2.041  loss_mask_5: 3.584  loss_ce_6: 1.929  loss_mask_6: 3.394  loss_ce_7: 1.992  loss_mask_7: 3.963  loss_ce_8: 1.84  loss_mask_8: 3.552  time: 2.4421  data_time: 0.3707  lr: 8.4379e-05  max_mem: 18490M
[01/24 09:09:19] d2.utils.events INFO:  eta: 1 day, 9:44:19  iter: 10339  total_loss: 54.56  loss_ce: 1.888  loss_mask: 3.49  loss_ce_0: 1.213  loss_mask_0: 4.264  loss_ce_1: 1.215  loss_mask_1: 4.017  loss_ce_2: 1.237  loss_mask_2: 3.785  loss_ce_3: 1.54  loss_mask_3: 3.633  loss_ce_4: 1.862  loss_mask_4: 3.583  loss_ce_5: 1.991  loss_mask_5: 3.63  loss_ce_6: 1.878  loss_mask_6: 3.597  loss_ce_7: 1.923  loss_mask_7: 3.619  loss_ce_8: 1.887  loss_mask_8: 3.677  time: 2.4422  data_time: 0.3794  lr: 8.4349e-05  max_mem: 18490M
[01/24 09:10:09] d2.utils.events INFO:  eta: 1 day, 9:46:59  iter: 10359  total_loss: 54.91  loss_ce: 1.911  loss_mask: 3.786  loss_ce_0: 1.256  loss_mask_0: 4.297  loss_ce_1: 1.314  loss_mask_1: 4.017  loss_ce_2: 1.287  loss_mask_2: 3.902  loss_ce_3: 1.627  loss_mask_3: 3.65  loss_ce_4: 1.855  loss_mask_4: 3.656  loss_ce_5: 1.914  loss_mask_5: 3.588  loss_ce_6: 1.852  loss_mask_6: 3.59  loss_ce_7: 1.92  loss_mask_7: 3.602  loss_ce_8: 1.872  loss_mask_8: 3.678  time: 2.4423  data_time: 0.4007  lr: 8.4318e-05  max_mem: 18490M
[01/24 09:10:56] d2.utils.events INFO:  eta: 1 day, 9:44:37  iter: 10379  total_loss: 52.85  loss_ce: 1.908  loss_mask: 3.348  loss_ce_0: 1.236  loss_mask_0: 4.095  loss_ce_1: 1.337  loss_mask_1: 3.893  loss_ce_2: 1.322  loss_mask_2: 3.809  loss_ce_3: 1.59  loss_mask_3: 3.432  loss_ce_4: 1.818  loss_mask_4: 3.475  loss_ce_5: 1.926  loss_mask_5: 3.504  loss_ce_6: 1.869  loss_mask_6: 3.52  loss_ce_7: 1.912  loss_mask_7: 3.508  loss_ce_8: 1.845  loss_mask_8: 3.458  time: 2.4421  data_time: 0.3605  lr: 8.4287e-05  max_mem: 18490M
[01/24 09:11:47] d2.utils.events INFO:  eta: 1 day, 9:42:23  iter: 10399  total_loss: 51.74  loss_ce: 1.89  loss_mask: 3.32  loss_ce_0: 1.219  loss_mask_0: 4.1  loss_ce_1: 1.347  loss_mask_1: 3.894  loss_ce_2: 1.307  loss_mask_2: 3.651  loss_ce_3: 1.595  loss_mask_3: 3.413  loss_ce_4: 1.828  loss_mask_4: 3.504  loss_ce_5: 1.902  loss_mask_5: 3.397  loss_ce_6: 1.827  loss_mask_6: 3.477  loss_ce_7: 1.86  loss_mask_7: 3.412  loss_ce_8: 1.82  loss_mask_8: 3.249  time: 2.4423  data_time: 0.3984  lr: 8.4257e-05  max_mem: 18490M
[01/24 09:12:37] d2.utils.events INFO:  eta: 1 day, 9:42:11  iter: 10419  total_loss: 57.99  loss_ce: 1.924  loss_mask: 3.839  loss_ce_0: 1.206  loss_mask_0: 4.603  loss_ce_1: 1.299  loss_mask_1: 4.26  loss_ce_2: 1.338  loss_mask_2: 4.154  loss_ce_3: 1.677  loss_mask_3: 3.866  loss_ce_4: 1.828  loss_mask_4: 3.835  loss_ce_5: 1.915  loss_mask_5: 3.846  loss_ce_6: 1.888  loss_mask_6: 3.71  loss_ce_7: 1.946  loss_mask_7: 4.152  loss_ce_8: 2.111  loss_mask_8: 4.265  time: 2.4424  data_time: 0.3633  lr: 8.4226e-05  max_mem: 18490M
[01/24 09:13:27] d2.utils.events INFO:  eta: 1 day, 9:40:47  iter: 10439  total_loss: 54.88  loss_ce: 1.9  loss_mask: 3.566  loss_ce_0: 1.211  loss_mask_0: 4.245  loss_ce_1: 1.271  loss_mask_1: 4.228  loss_ce_2: 1.272  loss_mask_2: 3.95  loss_ce_3: 1.59  loss_mask_3: 3.759  loss_ce_4: 1.782  loss_mask_4: 3.552  loss_ce_5: 1.877  loss_mask_5: 3.582  loss_ce_6: 1.836  loss_mask_6: 3.734  loss_ce_7: 1.942  loss_mask_7: 3.944  loss_ce_8: 1.93  loss_mask_8: 3.644  time: 2.4425  data_time: 0.3770  lr: 8.4196e-05  max_mem: 18490M
[01/24 09:14:18] d2.utils.events INFO:  eta: 1 day, 9:42:19  iter: 10459  total_loss: 54.83  loss_ce: 1.882  loss_mask: 3.403  loss_ce_0: 1.237  loss_mask_0: 4.178  loss_ce_1: 1.24  loss_mask_1: 3.874  loss_ce_2: 1.335  loss_mask_2: 3.758  loss_ce_3: 1.703  loss_mask_3: 3.703  loss_ce_4: 1.858  loss_mask_4: 3.762  loss_ce_5: 1.932  loss_mask_5: 3.63  loss_ce_6: 1.874  loss_mask_6: 3.707  loss_ce_7: 1.919  loss_mask_7: 3.709  loss_ce_8: 1.899  loss_mask_8: 3.491  time: 2.4427  data_time: 0.4260  lr: 8.4165e-05  max_mem: 18490M
[01/24 09:15:06] d2.utils.events INFO:  eta: 1 day, 9:42:39  iter: 10479  total_loss: 54.81  loss_ce: 1.914  loss_mask: 3.411  loss_ce_0: 1.221  loss_mask_0: 4.186  loss_ce_1: 1.243  loss_mask_1: 3.956  loss_ce_2: 1.322  loss_mask_2: 3.902  loss_ce_3: 1.71  loss_mask_3: 3.725  loss_ce_4: 1.892  loss_mask_4: 3.893  loss_ce_5: 1.951  loss_mask_5: 3.837  loss_ce_6: 1.921  loss_mask_6: 3.687  loss_ce_7: 1.959  loss_mask_7: 3.66  loss_ce_8: 1.96  loss_mask_8: 3.675  time: 2.4426  data_time: 0.3493  lr: 8.4135e-05  max_mem: 18490M
[01/24 09:15:53] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 09:15:54] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 09:15:54] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 09:20:01] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 13.834227811493587, 'error_1pix': 0.8906282578675557, 'error_3pix': 0.7525396098739277, 'mIoU': 0.31061546853418215, 'fwIoU': 0.7724600641821536, 'IoU-0': nan, 'IoU-1': 2.0324819451617007, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.4072397405511121, 'IoU-13': 0.0033255502278461886, 'IoU-14': 0.011676396790398622, 'IoU-15': 0.10262762243760574, 'IoU-16': 0.6024942555022019, 'IoU-17': 0.0, 'IoU-18': 0.00039209742629267536, 'IoU-19': 0.0005828326609518062, 'IoU-20': 3.078994814110614e-06, 'IoU-21': 0.15834542575505606, 'IoU-22': 3.341115533881863e-05, 'IoU-23': 0.0025087415098188144, 'IoU-24': 2.1389964290526673, 'IoU-25': 2.3284589275611456, 'IoU-26': 3.0409452328196324e-06, 'IoU-27': 5.715121835319067, 'IoU-28': 0.01237889906246853, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 4.501310042625857, 'IoU-32': 1.1413558471606018, 'IoU-33': 0.017461533055837617, 'IoU-34': 0.9726649788902604, 'IoU-35': 0.009037533424544861, 'IoU-36': 0.05987492703970459, 'IoU-37': 6.041754600662046, 'IoU-38': 0.00016091213734678472, 'IoU-39': 0.005398407205450484, 'IoU-40': 0.00561760384101395, 'IoU-41': 0.029807421778820654, 'IoU-42': 2.6198363961595077, 'IoU-43': 0.0, 'IoU-44': 0.15930691995516374, 'IoU-45': 0.0001323394264295825, 'IoU-46': 3.29190498344213e-05, 'IoU-47': 3.243618007816287, 'IoU-48': 0.0802904217404572, 'IoU-49': 1.3616981719746721e-05, 'IoU-50': 0.01150000584388052, 'IoU-51': 3.295536993491098, 'IoU-52': 5.224858581365208e-06, 'IoU-53': 0.00020678225105226315, 'IoU-54': 0.12048428437912571, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.05000994500893726, 'IoU-59': 0.0, 'IoU-60': 0.0007081470906484928, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 9.222202230537164e-06, 'IoU-64': 0.06897761885360308, 'IoU-65': 0.6535726730925788, 'IoU-66': 0.0032515137320569786, 'IoU-67': 0.09564233627633681, 'IoU-68': 0.0034192096325973767, 'IoU-69': 0.39076454355644896, 'IoU-70': 0.0612000016857846, 'IoU-71': 0.03728288291831138, 'IoU-72': 2.3944850888291036, 'IoU-73': 0.30396168693597025, 'IoU-74': 0.00032669414600026725, 'IoU-75': 0.37159306587299884, 'IoU-76': 3.948032847633293, 'IoU-77': 0.24042798024863282, 'IoU-78': 0.688301114852808, 'IoU-79': 0.6333295456821751, 'IoU-80': 0.48170212435831306, 'IoU-81': 2.087418139110029, 'IoU-82': 0.30532222198512543, 'IoU-83': 0.25005780223063084, 'IoU-84': 2.1236524984079095, 'IoU-85': 0.003842423368100362, 'IoU-86': 0.0, 'IoU-87': 0.9691972603433217, 'IoU-88': 0.00400972849777036, 'IoU-89': 0.6493211703158086, 'IoU-90': 0.0, 'IoU-91': 1.5861068834354317, 'IoU-92': 0.04224409060802472, 'IoU-93': 4.418983244983128e-05, 'IoU-94': 0.05970417984699467, 'IoU-95': 0.159635885701516, 'IoU-96': 0.0031009267815813174, 'IoU-97': 0.07553494100174081, 'IoU-98': 0.00018045854154489474, 'IoU-99': 0.0001155884511725485, 'IoU-100': 0.0029643264485675245, 'IoU-101': 0.0005151775602392828, 'IoU-102': 0.00013569159291074748, 'IoU-103': 0.08552012317124202, 'IoU-104': 9.833484687051807e-05, 'IoU-105': 0.003586880868747634, 'IoU-106': 0.0, 'IoU-107': 0.0005708664039412617, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 6.0178610114820785e-05, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0005462675902716297, 'IoU-115': 7.517095755020856e-05, 'IoU-116': 3.930250628152307e-05, 'IoU-117': 0.20321127007608047, 'IoU-118': 0.00730148459323807, 'IoU-119': 0.0, 'IoU-120': 0.0016239316614444829, 'IoU-121': 0.02157701175985398, 'IoU-122': 0.003436943850695393, 'IoU-123': 0.010899503630713034, 'IoU-124': 1.3458877020093807, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.11649096268971938, 'IoU-129': 1.3744565288561126, 'IoU-130': 0.0, 'IoU-131': 0.00674214341993242, 'IoU-132': 0.0, 'IoU-133': 0.002115229786665856, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.16230314205023721, 'IoU-151': 0.001367797624872032, 'IoU-152': 0.0, 'IoU-153': 0.002981594048992031, 'IoU-154': 0.0, 'IoU-155': 0.001724297194937956, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.022975488692576727, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0011005781703988496, 'IoU-175': 0.0, 'IoU-176': 1.4649293065039728, 'IoU-177': 0.0, 'IoU-178': 0.21436814043008398, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.773396048834559, 'pACC': 3.844956886325104, 'ACC-0': nan, 'ACC-1': 2.744045889740596, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.42596167812788516, 'ACC-13': 0.0034409953051578535, 'ACC-14': 0.026175460366743338, 'ACC-15': 0.11312191199280017, 'ACC-16': 1.8149481468923023, 'ACC-17': 0.0, 'ACC-18': 0.0004059246493415439, 'ACC-19': 0.0005835467511956813, 'ACC-20': 3.079169639091758e-06, 'ACC-21': 0.26836717749276295, 'ACC-22': 3.341519220042633e-05, 'ACC-23': 0.0025236949967076144, 'ACC-24': 31.092360595309614, 'ACC-25': 12.36672691371114, 'ACC-26': 3.040962525458558e-06, 'ACC-27': 43.94449900147938, 'ACC-28': 0.012423960161942041, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 23.513362798526284, 'ACC-32': 1.769131311587047, 'ACC-33': 0.01748183681430887, 'ACC-34': 1.0726089144083002, 'ACC-35': 0.009049248622644198, 'ACC-36': 0.06141755431149971, 'ACC-37': 49.11706620922288, 'ACC-38': 0.00016092180608290175, 'ACC-39': 0.0053996128028890806, 'ACC-40': 0.005684639397592215, 'ACC-41': 0.02999382143531576, 'ACC-42': 7.85473723290353, 'ACC-43': 0.0, 'ACC-44': 0.16783321277812546, 'ACC-45': 0.00013244147496362305, 'ACC-46': 3.292174295937662e-05, 'ACC-47': 28.142035706591805, 'ACC-48': 0.08775455057512942, 'ACC-49': 1.3620796922862204e-05, 'ACC-50': 0.011538054717882317, 'ACC-51': 26.059071414292674, 'ACC-52': 5.226113005286736e-06, 'ACC-53': 0.00020678567182079953, 'ACC-54': 0.18114626858180474, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.05228208386910694, 'ACC-59': 0.0, 'ACC-60': 0.000710436501659106, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 9.222818877118113e-06, 'ACC-64': 0.07199430892167435, 'ACC-65': 1.0229948557956008, 'ACC-66': 0.003270604501741801, 'ACC-67': 0.0974873157511951, 'ACC-68': 0.003451891048394326, 'ACC-69': 0.42521802949866006, 'ACC-70': 0.0645900149068544, 'ACC-71': 0.037631477247731006, 'ACC-72': 6.551088826465748, 'ACC-73': 0.32349289679121385, 'ACC-74': 0.00032678716907216516, 'ACC-75': 0.43010071647052267, 'ACC-76': 40.94104404931205, 'ACC-77': 0.29883159303274276, 'ACC-78': 0.8715279141163497, 'ACC-79': 0.7958670249148682, 'ACC-80': 0.6316768862810206, 'ACC-81': 5.48015162041269, 'ACC-82': 0.3461192185669227, 'ACC-83': 0.27817228985966624, 'ACC-84': 9.383415902868693, 'ACC-85': 0.0038652522158079093, 'ACC-86': 0.0, 'ACC-87': 1.4662730047989163, 'ACC-88': 0.004160148890597636, 'ACC-89': 1.4294469165534753, 'ACC-90': 0.0, 'ACC-91': 12.22103956536045, 'ACC-92': 0.04492065936531758, 'ACC-93': 4.419621883669364e-05, 'ACC-94': 0.06877187988838368, 'ACC-95': 0.2977312863389251, 'ACC-96': 0.003264017916127729, 'ACC-97': 0.0801427331633917, 'ACC-98': 0.00018053151728255294, 'ACC-99': 0.00011570440455813645, 'ACC-100': 0.0029801799785427042, 'ACC-101': 0.000515844153164446, 'ACC-102': 0.00013593112822836428, 'ACC-103': 0.2031737035987532, 'ACC-104': 9.83743636408352e-05, 'ACC-105': 0.0036010257560174803, 'ACC-106': 0.0, 'ACC-107': 0.0005711264571883608, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 6.021975997005873e-05, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0005466478279677419, 'ACC-115': 7.517327439748621e-05, 'ACC-116': 3.930255262218771e-05, 'ACC-117': 0.5064986936713581, 'ACC-118': 0.007305715210625029, 'ACC-119': 0.0, 'ACC-120': 0.0016252191849657563, 'ACC-121': 0.025617418391035353, 'ACC-122': 0.0034438185815241495, 'ACC-123': 0.010953896922843119, 'ACC-124': 5.538327452811543, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.12849268988194773, 'ACC-129': 5.861910352864249, 'ACC-130': 0.0, 'ACC-131': 0.006778701320451143, 'ACC-132': 0.0, 'ACC-133': 0.002177359543298836, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.24900746188538989, 'ACC-151': 0.0013855094891413358, 'ACC-152': 0.0, 'ACC-153': 0.005382106671063962, 'ACC-154': 0.0, 'ACC-155': 0.0017255702393365923, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.07176785817688584, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0011183993468547814, 'ACC-175': 0.0, 'ACC-176': 12.417285813791503, 'ACC-177': 0.0, 'ACC-178': 0.7865392081682637, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 09:20:01] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 09:20:01] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 09:20:01] d2.evaluation.testing INFO: copypaste: 13.8342,0.8906,0.7525,0.3106,0.7725,1.7734,3.8450
[01/24 09:20:01] d2.utils.events INFO:  eta: 1 day, 9:38:20  iter: 10499  total_loss: 52.07  loss_ce: 1.839  loss_mask: 3.359  loss_ce_0: 1.281  loss_mask_0: 4.071  loss_ce_1: 1.283  loss_mask_1: 3.713  loss_ce_2: 1.381  loss_mask_2: 3.614  loss_ce_3: 1.685  loss_mask_3: 3.503  loss_ce_4: 1.856  loss_mask_4: 3.512  loss_ce_5: 1.887  loss_mask_5: 3.324  loss_ce_6: 1.847  loss_mask_6: 3.307  loss_ce_7: 1.904  loss_mask_7: 3.439  loss_ce_8: 1.847  loss_mask_8: 3.294  time: 2.4425  data_time: 0.3920  lr: 8.4104e-05  max_mem: 18490M
[01/24 09:20:51] d2.utils.events INFO:  eta: 1 day, 9:37:31  iter: 10519  total_loss: 52.48  loss_ce: 1.831  loss_mask: 3.389  loss_ce_0: 1.259  loss_mask_0: 4.187  loss_ce_1: 1.236  loss_mask_1: 3.947  loss_ce_2: 1.327  loss_mask_2: 3.765  loss_ce_3: 1.691  loss_mask_3: 3.614  loss_ce_4: 1.873  loss_mask_4: 3.426  loss_ce_5: 1.915  loss_mask_5: 3.387  loss_ce_6: 1.868  loss_mask_6: 3.319  loss_ce_7: 1.907  loss_mask_7: 3.391  loss_ce_8: 1.875  loss_mask_8: 3.328  time: 2.4426  data_time: 0.3984  lr: 8.4073e-05  max_mem: 18490M
[01/24 09:21:43] d2.utils.events INFO:  eta: 1 day, 9:40:12  iter: 10539  total_loss: 53.16  loss_ce: 2.007  loss_mask: 3.512  loss_ce_0: 1.292  loss_mask_0: 4.026  loss_ce_1: 1.305  loss_mask_1: 3.79  loss_ce_2: 1.379  loss_mask_2: 3.681  loss_ce_3: 1.761  loss_mask_3: 3.579  loss_ce_4: 1.852  loss_mask_4: 3.402  loss_ce_5: 1.905  loss_mask_5: 3.338  loss_ce_6: 1.856  loss_mask_6: 3.472  loss_ce_7: 1.893  loss_mask_7: 3.359  loss_ce_8: 1.886  loss_mask_8: 3.491  time: 2.4429  data_time: 0.4161  lr: 8.4043e-05  max_mem: 18490M
[01/24 09:22:30] d2.utils.events INFO:  eta: 1 day, 9:35:53  iter: 10559  total_loss: 55.92  loss_ce: 2.168  loss_mask: 3.751  loss_ce_0: 1.281  loss_mask_0: 4.358  loss_ce_1: 1.273  loss_mask_1: 4.167  loss_ce_2: 1.424  loss_mask_2: 3.864  loss_ce_3: 1.81  loss_mask_3: 3.69  loss_ce_4: 1.968  loss_mask_4: 3.612  loss_ce_5: 1.96  loss_mask_5: 3.599  loss_ce_6: 1.943  loss_mask_6: 3.676  loss_ce_7: 2.026  loss_mask_7: 3.742  loss_ce_8: 2.039  loss_mask_8: 3.807  time: 2.4427  data_time: 0.3352  lr: 8.4012e-05  max_mem: 18490M
[01/24 09:23:18] d2.utils.events INFO:  eta: 1 day, 9:30:17  iter: 10579  total_loss: 58.64  loss_ce: 2.106  loss_mask: 3.793  loss_ce_0: 1.284  loss_mask_0: 4.425  loss_ce_1: 1.288  loss_mask_1: 4.137  loss_ce_2: 1.473  loss_mask_2: 3.761  loss_ce_3: 1.792  loss_mask_3: 4.033  loss_ce_4: 2.059  loss_mask_4: 4.249  loss_ce_5: 2.058  loss_mask_5: 3.897  loss_ce_6: 1.998  loss_mask_6: 3.658  loss_ce_7: 2.074  loss_mask_7: 4.152  loss_ce_8: 1.966  loss_mask_8: 3.755  time: 2.4426  data_time: 0.3732  lr: 8.3982e-05  max_mem: 18490M
[01/24 09:24:08] d2.utils.events INFO:  eta: 1 day, 9:28:47  iter: 10599  total_loss: 59.85  loss_ce: 2.082  loss_mask: 4.423  loss_ce_0: 1.287  loss_mask_0: 4.555  loss_ce_1: 1.344  loss_mask_1: 4.191  loss_ce_2: 1.437  loss_mask_2: 3.828  loss_ce_3: 1.731  loss_mask_3: 3.749  loss_ce_4: 1.994  loss_mask_4: 4.376  loss_ce_5: 2.087  loss_mask_5: 4.194  loss_ce_6: 2.041  loss_mask_6: 4.183  loss_ce_7: 2.058  loss_mask_7: 4.395  loss_ce_8: 2.028  loss_mask_8: 3.932  time: 2.4427  data_time: 0.3799  lr: 8.3951e-05  max_mem: 18490M
[01/24 09:24:55] d2.utils.events INFO:  eta: 1 day, 9:26:01  iter: 10619  total_loss: 56.31  loss_ce: 1.989  loss_mask: 4.338  loss_ce_0: 1.334  loss_mask_0: 4.139  loss_ce_1: 1.3  loss_mask_1: 3.838  loss_ce_2: 1.435  loss_mask_2: 3.582  loss_ce_3: 1.614  loss_mask_3: 3.474  loss_ce_4: 1.895  loss_mask_4: 3.736  loss_ce_5: 1.984  loss_mask_5: 3.804  loss_ce_6: 2.015  loss_mask_6: 3.892  loss_ce_7: 1.944  loss_mask_7: 3.951  loss_ce_8: 1.95  loss_mask_8: 3.879  time: 2.4425  data_time: 0.3899  lr: 8.392e-05  max_mem: 18490M
[01/24 09:25:45] d2.utils.events INFO:  eta: 1 day, 9:23:43  iter: 10639  total_loss: 60.14  loss_ce: 1.976  loss_mask: 4.062  loss_ce_0: 1.357  loss_mask_0: 4.61  loss_ce_1: 1.281  loss_mask_1: 4.408  loss_ce_2: 1.43  loss_mask_2: 4.066  loss_ce_3: 1.595  loss_mask_3: 3.86  loss_ce_4: 1.924  loss_mask_4: 4.063  loss_ce_5: 2.104  loss_mask_5: 3.998  loss_ce_6: 2.095  loss_mask_6: 4.349  loss_ce_7: 1.963  loss_mask_7: 4.021  loss_ce_8: 1.981  loss_mask_8: 4.274  time: 2.4426  data_time: 0.4114  lr: 8.389e-05  max_mem: 18490M
[01/24 09:26:34] d2.utils.events INFO:  eta: 1 day, 9:23:44  iter: 10659  total_loss: 60.08  loss_ce: 1.96  loss_mask: 4.038  loss_ce_0: 1.336  loss_mask_0: 4.57  loss_ce_1: 1.271  loss_mask_1: 4.173  loss_ce_2: 1.386  loss_mask_2: 3.967  loss_ce_3: 1.61  loss_mask_3: 3.857  loss_ce_4: 1.991  loss_mask_4: 4.403  loss_ce_5: 2.061  loss_mask_5: 4.429  loss_ce_6: 2.08  loss_mask_6: 4.375  loss_ce_7: 1.966  loss_mask_7: 4.281  loss_ce_8: 1.954  loss_mask_8: 4.198  time: 2.4426  data_time: 0.3698  lr: 8.3859e-05  max_mem: 18490M
[01/24 09:27:21] d2.utils.events INFO:  eta: 1 day, 9:20:51  iter: 10679  total_loss: 62.33  loss_ce: 2  loss_mask: 4.264  loss_ce_0: 1.451  loss_mask_0: 4.96  loss_ce_1: 1.294  loss_mask_1: 4.684  loss_ce_2: 1.44  loss_mask_2: 4.423  loss_ce_3: 1.771  loss_mask_3: 4.612  loss_ce_4: 2.061  loss_mask_4: 4.505  loss_ce_5: 2.066  loss_mask_5: 4.577  loss_ce_6: 2.067  loss_mask_6: 4.365  loss_ce_7: 2.024  loss_mask_7: 4.41  loss_ce_8: 1.962  loss_mask_8: 4.151  time: 2.4424  data_time: 0.3712  lr: 8.3829e-05  max_mem: 18490M
[01/24 09:28:12] d2.utils.events INFO:  eta: 1 day, 9:24:23  iter: 10699  total_loss: 61.64  loss_ce: 1.941  loss_mask: 4.071  loss_ce_0: 1.473  loss_mask_0: 4.815  loss_ce_1: 1.346  loss_mask_1: 4.699  loss_ce_2: 1.48  loss_mask_2: 4.343  loss_ce_3: 1.684  loss_mask_3: 4.256  loss_ce_4: 1.982  loss_mask_4: 4.511  loss_ce_5: 2.002  loss_mask_5: 4.381  loss_ce_6: 2.008  loss_mask_6: 4.365  loss_ce_7: 1.985  loss_mask_7: 4.256  loss_ce_8: 1.924  loss_mask_8: 4.134  time: 2.4427  data_time: 0.4172  lr: 8.3798e-05  max_mem: 18490M
[01/24 09:29:00] d2.utils.events INFO:  eta: 1 day, 9:25:17  iter: 10719  total_loss: 58.08  loss_ce: 1.938  loss_mask: 3.923  loss_ce_0: 1.439  loss_mask_0: 4.449  loss_ce_1: 1.553  loss_mask_1: 4.455  loss_ce_2: 1.594  loss_mask_2: 3.841  loss_ce_3: 1.726  loss_mask_3: 3.657  loss_ce_4: 1.971  loss_mask_4: 3.876  loss_ce_5: 1.952  loss_mask_5: 3.898  loss_ce_6: 1.969  loss_mask_6: 3.755  loss_ce_7: 1.989  loss_mask_7: 3.847  loss_ce_8: 1.942  loss_mask_8: 3.773  time: 2.4426  data_time: 0.3676  lr: 8.3767e-05  max_mem: 18490M
[01/24 09:29:48] d2.utils.events INFO:  eta: 1 day, 9:22:10  iter: 10739  total_loss: 58.38  loss_ce: 1.904  loss_mask: 3.886  loss_ce_0: 1.419  loss_mask_0: 4.481  loss_ce_1: 1.474  loss_mask_1: 4.35  loss_ce_2: 1.62  loss_mask_2: 4.169  loss_ce_3: 1.686  loss_mask_3: 3.861  loss_ce_4: 1.956  loss_mask_4: 3.859  loss_ce_5: 1.957  loss_mask_5: 3.796  loss_ce_6: 1.986  loss_mask_6: 3.874  loss_ce_7: 1.987  loss_mask_7: 3.781  loss_ce_8: 1.925  loss_mask_8: 3.99  time: 2.4425  data_time: 0.3500  lr: 8.3737e-05  max_mem: 18490M
[01/24 09:30:39] d2.utils.events INFO:  eta: 1 day, 9:26:51  iter: 10759  total_loss: 57.46  loss_ce: 1.937  loss_mask: 3.829  loss_ce_0: 1.414  loss_mask_0: 4.64  loss_ce_1: 1.454  loss_mask_1: 4.267  loss_ce_2: 1.552  loss_mask_2: 3.967  loss_ce_3: 1.63  loss_mask_3: 3.84  loss_ce_4: 1.93  loss_mask_4: 3.862  loss_ce_5: 1.959  loss_mask_5: 3.753  loss_ce_6: 1.967  loss_mask_6: 3.963  loss_ce_7: 1.987  loss_mask_7: 3.989  loss_ce_8: 1.94  loss_mask_8: 3.929  time: 2.4427  data_time: 0.4307  lr: 8.3706e-05  max_mem: 18490M
[01/24 09:31:28] d2.utils.events INFO:  eta: 1 day, 9:27:16  iter: 10779  total_loss: 55.76  loss_ce: 1.93  loss_mask: 3.709  loss_ce_0: 1.257  loss_mask_0: 4.303  loss_ce_1: 1.428  loss_mask_1: 4.058  loss_ce_2: 1.516  loss_mask_2: 3.84  loss_ce_3: 1.565  loss_mask_3: 3.742  loss_ce_4: 1.91  loss_mask_4: 3.718  loss_ce_5: 1.938  loss_mask_5: 3.684  loss_ce_6: 1.924  loss_mask_6: 3.677  loss_ce_7: 1.956  loss_mask_7: 3.652  loss_ce_8: 1.926  loss_mask_8: 3.681  time: 2.4427  data_time: 0.3731  lr: 8.3676e-05  max_mem: 18490M
[01/24 09:32:16] d2.utils.events INFO:  eta: 1 day, 9:26:27  iter: 10799  total_loss: 56.21  loss_ce: 1.913  loss_mask: 3.674  loss_ce_0: 1.377  loss_mask_0: 4.419  loss_ce_1: 1.386  loss_mask_1: 4.323  loss_ce_2: 1.501  loss_mask_2: 3.948  loss_ce_3: 1.556  loss_mask_3: 3.789  loss_ce_4: 1.925  loss_mask_4: 3.718  loss_ce_5: 1.952  loss_mask_5: 3.668  loss_ce_6: 1.955  loss_mask_6: 3.812  loss_ce_7: 1.943  loss_mask_7: 3.644  loss_ce_8: 1.945  loss_mask_8: 3.678  time: 2.4426  data_time: 0.3521  lr: 8.3645e-05  max_mem: 18490M
[01/24 09:33:07] d2.utils.events INFO:  eta: 1 day, 9:29:56  iter: 10819  total_loss: 55.03  loss_ce: 1.871  loss_mask: 3.623  loss_ce_0: 1.396  loss_mask_0: 4.302  loss_ce_1: 1.303  loss_mask_1: 4.277  loss_ce_2: 1.481  loss_mask_2: 3.92  loss_ce_3: 1.604  loss_mask_3: 3.75  loss_ce_4: 1.875  loss_mask_4: 3.551  loss_ce_5: 1.917  loss_mask_5: 3.588  loss_ce_6: 1.951  loss_mask_6: 3.758  loss_ce_7: 1.908  loss_mask_7: 3.531  loss_ce_8: 1.913  loss_mask_8: 3.658  time: 2.4428  data_time: 0.4259  lr: 8.3614e-05  max_mem: 18490M
[01/24 09:33:55] d2.utils.events INFO:  eta: 1 day, 9:31:00  iter: 10839  total_loss: 54.16  loss_ce: 1.896  loss_mask: 3.539  loss_ce_0: 1.426  loss_mask_0: 4.284  loss_ce_1: 1.35  loss_mask_1: 4.202  loss_ce_2: 1.462  loss_mask_2: 3.819  loss_ce_3: 1.536  loss_mask_3: 3.546  loss_ce_4: 1.878  loss_mask_4: 3.524  loss_ce_5: 1.939  loss_mask_5: 3.606  loss_ce_6: 1.954  loss_mask_6: 3.57  loss_ce_7: 1.904  loss_mask_7: 3.418  loss_ce_8: 1.923  loss_mask_8: 3.635  time: 2.4427  data_time: 0.3710  lr: 8.3584e-05  max_mem: 18490M
[01/24 09:34:44] d2.utils.events INFO:  eta: 1 day, 9:29:21  iter: 10859  total_loss: 55.51  loss_ce: 1.87  loss_mask: 3.549  loss_ce_0: 1.36  loss_mask_0: 4.329  loss_ce_1: 1.278  loss_mask_1: 4.344  loss_ce_2: 1.46  loss_mask_2: 3.965  loss_ce_3: 1.519  loss_mask_3: 3.677  loss_ce_4: 1.878  loss_mask_4: 3.672  loss_ce_5: 1.942  loss_mask_5: 3.606  loss_ce_6: 1.957  loss_mask_6: 3.705  loss_ce_7: 1.901  loss_mask_7: 3.446  loss_ce_8: 1.896  loss_mask_8: 3.827  time: 2.4427  data_time: 0.3693  lr: 8.3553e-05  max_mem: 18490M
[01/24 09:35:34] d2.utils.events INFO:  eta: 1 day, 9:27:12  iter: 10879  total_loss: 54.1  loss_ce: 1.89  loss_mask: 3.534  loss_ce_0: 1.438  loss_mask_0: 4.105  loss_ce_1: 1.285  loss_mask_1: 4.329  loss_ce_2: 1.47  loss_mask_2: 3.982  loss_ce_3: 1.491  loss_mask_3: 3.592  loss_ce_4: 1.833  loss_mask_4: 3.471  loss_ce_5: 1.919  loss_mask_5: 3.388  loss_ce_6: 1.945  loss_mask_6: 3.66  loss_ce_7: 1.906  loss_mask_7: 3.54  loss_ce_8: 1.922  loss_mask_8: 3.629  time: 2.4429  data_time: 0.3859  lr: 8.3523e-05  max_mem: 18490M
[01/24 09:36:23] d2.utils.events INFO:  eta: 1 day, 9:25:17  iter: 10899  total_loss: 55.26  loss_ce: 1.883  loss_mask: 3.638  loss_ce_0: 1.415  loss_mask_0: 4.356  loss_ce_1: 1.247  loss_mask_1: 4.338  loss_ce_2: 1.489  loss_mask_2: 4.195  loss_ce_3: 1.572  loss_mask_3: 3.755  loss_ce_4: 1.862  loss_mask_4: 3.587  loss_ce_5: 1.931  loss_mask_5: 3.55  loss_ce_6: 1.917  loss_mask_6: 3.787  loss_ce_7: 1.899  loss_mask_7: 3.572  loss_ce_8: 1.931  loss_mask_8: 3.702  time: 2.4428  data_time: 0.3583  lr: 8.3492e-05  max_mem: 18490M
[01/24 09:37:12] d2.utils.events INFO:  eta: 1 day, 9:25:34  iter: 10919  total_loss: 52.69  loss_ce: 1.846  loss_mask: 3.341  loss_ce_0: 1.378  loss_mask_0: 3.995  loss_ce_1: 1.225  loss_mask_1: 4.379  loss_ce_2: 1.502  loss_mask_2: 3.847  loss_ce_3: 1.531  loss_mask_3: 3.415  loss_ce_4: 1.813  loss_mask_4: 3.284  loss_ce_5: 1.897  loss_mask_5: 3.26  loss_ce_6: 1.892  loss_mask_6: 3.444  loss_ce_7: 1.873  loss_mask_7: 3.319  loss_ce_8: 1.889  loss_mask_8: 3.621  time: 2.4429  data_time: 0.3816  lr: 8.3461e-05  max_mem: 18490M
[01/24 09:38:01] d2.utils.events INFO:  eta: 1 day, 9:20:47  iter: 10939  total_loss: 53.91  loss_ce: 1.884  loss_mask: 3.476  loss_ce_0: 1.392  loss_mask_0: 4.104  loss_ce_1: 1.242  loss_mask_1: 4.302  loss_ce_2: 1.502  loss_mask_2: 3.967  loss_ce_3: 1.555  loss_mask_3: 3.628  loss_ce_4: 1.811  loss_mask_4: 3.491  loss_ce_5: 1.929  loss_mask_5: 3.451  loss_ce_6: 1.931  loss_mask_6: 3.777  loss_ce_7: 1.932  loss_mask_7: 3.5  loss_ce_8: 1.909  loss_mask_8: 3.67  time: 2.4429  data_time: 0.3924  lr: 8.3431e-05  max_mem: 18490M
[01/24 09:38:49] d2.utils.events INFO:  eta: 1 day, 9:19:07  iter: 10959  total_loss: 53.73  loss_ce: 1.844  loss_mask: 3.504  loss_ce_0: 1.305  loss_mask_0: 4.125  loss_ce_1: 1.278  loss_mask_1: 4.313  loss_ce_2: 1.487  loss_mask_2: 3.893  loss_ce_3: 1.538  loss_mask_3: 3.578  loss_ce_4: 1.831  loss_mask_4: 3.467  loss_ce_5: 1.898  loss_mask_5: 3.475  loss_ce_6: 1.909  loss_mask_6: 3.508  loss_ce_7: 1.888  loss_mask_7: 3.392  loss_ce_8: 1.869  loss_mask_8: 3.498  time: 2.4428  data_time: 0.3678  lr: 8.34e-05  max_mem: 18490M
[01/24 09:39:40] d2.utils.events INFO:  eta: 1 day, 9:21:21  iter: 10979  total_loss: 54.92  loss_ce: 1.873  loss_mask: 3.584  loss_ce_0: 1.319  loss_mask_0: 4.167  loss_ce_1: 1.361  loss_mask_1: 4.246  loss_ce_2: 1.483  loss_mask_2: 3.993  loss_ce_3: 1.51  loss_mask_3: 3.698  loss_ce_4: 1.813  loss_mask_4: 3.507  loss_ce_5: 1.896  loss_mask_5: 3.527  loss_ce_6: 1.913  loss_mask_6: 3.617  loss_ce_7: 1.906  loss_mask_7: 3.559  loss_ce_8: 1.887  loss_mask_8: 3.631  time: 2.4430  data_time: 0.4477  lr: 8.337e-05  max_mem: 18490M
[01/24 09:40:28] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 09:40:28] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 09:40:28] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 09:43:54] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 14.675576056661289, 'error_1pix': 0.8235599748593873, 'error_3pix': 0.7166162622147223, 'mIoU': 0.3976706866687013, 'fwIoU': 5.21461708268239, 'IoU-0': nan, 'IoU-1': 46.4041465938417, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.009760987449711047, 'IoU-12': 0.0012524581082482135, 'IoU-13': 7.794553597148074, 'IoU-14': 1.5546214619815923, 'IoU-15': 0.5136444936950326, 'IoU-16': 0.9298999846698017, 'IoU-17': 2.5002418984036707e-05, 'IoU-18': 0.0, 'IoU-19': 0.00013906407519351748, 'IoU-20': 0.051381556648318234, 'IoU-21': 1.3974361090798062, 'IoU-22': 0.000658788061792986, 'IoU-23': 0.013788269872072649, 'IoU-24': 0.00012097326903304235, 'IoU-25': 0.044102625222991104, 'IoU-26': 0.001477170152919937, 'IoU-27': 5.3566191771364605e-05, 'IoU-28': 0.014303310814190826, 'IoU-29': 3.42854818048631, 'IoU-30': 0.0, 'IoU-31': 1.0353842459794294, 'IoU-32': 1.623924390296911e-05, 'IoU-33': 3.2155970014363113, 'IoU-34': 0.08728661191385871, 'IoU-35': 0.00032158157812167416, 'IoU-36': 0.1783093526382159, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 7.638903296709274e-05, 'IoU-41': 0.0331841251352026, 'IoU-42': 0.005719280381324827, 'IoU-43': 0.8388099018199655, 'IoU-44': 0.0, 'IoU-45': 1.4393887420519154, 'IoU-46': 4.1127784726317e-05, 'IoU-47': 0.004603971156583626, 'IoU-48': 0.06443274292326334, 'IoU-49': 2.268913950303978e-05, 'IoU-50': 0.004872683310181828, 'IoU-51': 0.0, 'IoU-52': 0.1740460039367897, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.310903318623474, 'IoU-57': 0.0, 'IoU-58': 0.00048442598150932187, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 1.183519285092051, 'IoU-66': 0.0, 'IoU-67': 1.058015541613497e-05, 'IoU-68': 0.0001939964354232749, 'IoU-69': 0.0, 'IoU-70': 2.1148185760588154e-05, 'IoU-71': 0.0016533251305202298, 'IoU-72': 0.0023652864372928303, 'IoU-73': 4.4197166210294094e-05, 'IoU-74': 0.059524999875013127, 'IoU-75': 0.010158829264265335, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.8842709308140604, 'IoU-79': 0.0, 'IoU-80': 0.11920903493728265, 'IoU-81': 0.21042829671505145, 'IoU-82': 0.00020769283323085334, 'IoU-83': 0.0, 'IoU-84': 0.11852009291820706, 'IoU-85': 0.0, 'IoU-86': 0.06820155020124138, 'IoU-87': 0.021406989757517498, 'IoU-88': 0.955031560644149, 'IoU-89': 0.47142524770702343, 'IoU-90': 0.98422776221844, 'IoU-91': 0.0, 'IoU-92': 0.4883105822845764, 'IoU-93': 0.03568591866091385, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.14137854395854296, 'IoU-100': 0.0, 'IoU-101': 0.3435134307848905, 'IoU-102': 0.0, 'IoU-103': 0.4873423988311942, 'IoU-104': 0.0, 'IoU-105': 0.14721232848884755, 'IoU-106': 0.01937406674073921, 'IoU-107': 0.0, 'IoU-108': 7.3961105333927e-05, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0016484790719961994, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.04318260247399086, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0012140942466675282, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.4348794490125973, 'pACC': 11.417182465059746, 'ACC-0': nan, 'ACC-1': 82.0506862789578, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0097695672649857, 'ACC-12': 0.001258802442776548, 'ACC-13': 49.66104373468577, 'ACC-14': 2.4624394133151437, 'ACC-15': 0.549090969007388, 'ACC-16': 1.1997900807625523, 'ACC-17': 2.500255885563288e-05, 'ACC-18': 0.0, 'ACC-19': 0.0001390836816321313, 'ACC-20': 0.05203180856137253, 'ACC-21': 1.6874339797348092, 'ACC-22': 0.00065995004595842, 'ACC-23': 0.013941281298237473, 'ACC-24': 0.00012160451735213834, 'ACC-25': 0.04528083548921216, 'ACC-26': 0.0014779077873728593, 'ACC-27': 5.357021518591543e-05, 'ACC-28': 0.014346201272592781, 'ACC-29': 15.230911818214127, 'ACC-30': 0.0, 'ACC-31': 1.4801466170120368, 'ACC-32': 1.624104218551157e-05, 'ACC-33': 73.37037787875792, 'ACC-34': 0.09494043422930795, 'ACC-35': 0.00032160319859887465, 'ACC-36': 0.2514412148536381, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 7.648868941862507e-05, 'ACC-41': 0.033762519025912555, 'ACC-42': 0.005737500547501785, 'ACC-43': 1.2692563508781614, 'ACC-44': 0.0, 'ACC-45': 17.937914993536666, 'ACC-46': 4.115217869922078e-05, 'ACC-47': 0.004660467279579175, 'ACC-48': 0.06847473955443906, 'ACC-49': 2.270132820477034e-05, 'ACC-50': 0.004888367672310958, 'ACC-51': 0.0, 'ACC-52': 0.21748469271500753, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.7566463233758055, 'ACC-57': 0.0, 'ACC-58': 0.00048486299295674164, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 2.4676651069026114, 'ACC-66': 0.0, 'ACC-67': 1.0580346836465717e-05, 'ACC-68': 0.00019416887147218084, 'ACC-69': 0.0, 'ACC-70': 2.1180526285244924e-05, 'ACC-71': 0.0016759403872414627, 'ACC-72': 0.0023831860212553467, 'ACC-73': 4.4197547124529686e-05, 'ACC-74': 0.062252955708247466, 'ACC-75': 0.010319534277780023, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 14.410242041912936, 'ACC-79': 0.0, 'ACC-80': 0.13568159433282198, 'ACC-81': 0.22995688723868912, 'ACC-82': 0.00021377190627609564, 'ACC-83': 0.0, 'ACC-84': 0.12522381445961348, 'ACC-85': 0.0, 'ACC-86': 0.0699756371891874, 'ACC-87': 0.02302559780911804, 'ACC-88': 1.8760009179978097, 'ACC-89': 0.6560595400651433, 'ACC-90': 1.5618975115729885, 'ACC-91': 0.0, 'ACC-92': 2.7917073533512533, 'ACC-93': 0.038568566971487986, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.1453633002598721, 'ACC-100': 0.0, 'ACC-101': 0.42404538740755643, 'ACC-102': 0.0, 'ACC-103': 1.624822896004534, 'ACC-104': 0.0, 'ACC-105': 0.28872054022537313, 'ACC-106': 0.020873011065580326, 'ACC-107': 0.0, 'ACC-108': 8.29089546369182e-05, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0016538120367446966, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.04975258809960983, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0012226422871794602, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 09:43:54] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 09:43:54] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 09:43:54] d2.evaluation.testing INFO: copypaste: 14.6756,0.8236,0.7166,0.3977,5.2146,1.4349,11.4172
[01/24 09:43:54] d2.utils.events INFO:  eta: 1 day, 9:16:07  iter: 10999  total_loss: 54.52  loss_ce: 1.912  loss_mask: 3.636  loss_ce_0: 1.278  loss_mask_0: 4.221  loss_ce_1: 1.354  loss_mask_1: 4.34  loss_ce_2: 1.447  loss_mask_2: 3.936  loss_ce_3: 1.478  loss_mask_3: 3.733  loss_ce_4: 1.792  loss_mask_4: 3.467  loss_ce_5: 1.867  loss_mask_5: 3.525  loss_ce_6: 1.897  loss_mask_6: 3.648  loss_ce_7: 1.906  loss_mask_7: 3.503  loss_ce_8: 1.884  loss_mask_8: 3.539  time: 2.4429  data_time: 0.3825  lr: 8.3339e-05  max_mem: 18490M
[01/24 09:44:40] d2.utils.events INFO:  eta: 1 day, 9:08:53  iter: 11019  total_loss: 50.57  loss_ce: 1.863  loss_mask: 3.359  loss_ce_0: 1.233  loss_mask_0: 3.687  loss_ce_1: 1.368  loss_mask_1: 3.99  loss_ce_2: 1.371  loss_mask_2: 3.68  loss_ce_3: 1.457  loss_mask_3: 3.359  loss_ce_4: 1.741  loss_mask_4: 3.093  loss_ce_5: 1.818  loss_mask_5: 3.124  loss_ce_6: 1.858  loss_mask_6: 3.227  loss_ce_7: 1.86  loss_mask_7: 3.265  loss_ce_8: 1.829  loss_mask_8: 3.207  time: 2.4427  data_time: 0.3558  lr: 8.3308e-05  max_mem: 18490M
[01/24 09:45:27] d2.utils.events INFO:  eta: 1 day, 9:05:37  iter: 11039  total_loss: 52.08  loss_ce: 1.875  loss_mask: 3.426  loss_ce_0: 1.195  loss_mask_0: 3.839  loss_ce_1: 1.278  loss_mask_1: 4.057  loss_ce_2: 1.36  loss_mask_2: 3.837  loss_ce_3: 1.42  loss_mask_3: 3.514  loss_ce_4: 1.745  loss_mask_4: 3.316  loss_ce_5: 1.829  loss_mask_5: 3.313  loss_ce_6: 1.885  loss_mask_6: 3.423  loss_ce_7: 1.878  loss_mask_7: 3.366  loss_ce_8: 1.876  loss_mask_8: 3.418  time: 2.4425  data_time: 0.3595  lr: 8.3278e-05  max_mem: 18490M
[01/24 09:46:14] d2.utils.events INFO:  eta: 1 day, 9:03:38  iter: 11059  total_loss: 50.97  loss_ce: 1.883  loss_mask: 3.421  loss_ce_0: 1.195  loss_mask_0: 3.804  loss_ce_1: 1.279  loss_mask_1: 3.97  loss_ce_2: 1.381  loss_mask_2: 3.677  loss_ce_3: 1.381  loss_mask_3: 3.505  loss_ce_4: 1.741  loss_mask_4: 3.216  loss_ce_5: 1.837  loss_mask_5: 3.253  loss_ce_6: 1.881  loss_mask_6: 3.349  loss_ce_7: 1.877  loss_mask_7: 3.34  loss_ce_8: 1.893  loss_mask_8: 3.456  time: 2.4423  data_time: 0.3771  lr: 8.3247e-05  max_mem: 18490M
[01/24 09:47:01] d2.utils.events INFO:  eta: 1 day, 8:56:32  iter: 11079  total_loss: 51.13  loss_ce: 1.867  loss_mask: 3.437  loss_ce_0: 1.179  loss_mask_0: 3.886  loss_ce_1: 1.297  loss_mask_1: 3.955  loss_ce_2: 1.358  loss_mask_2: 3.694  loss_ce_3: 1.384  loss_mask_3: 3.47  loss_ce_4: 1.735  loss_mask_4: 3.243  loss_ce_5: 1.825  loss_mask_5: 3.219  loss_ce_6: 1.854  loss_mask_6: 3.314  loss_ce_7: 1.857  loss_mask_7: 3.358  loss_ce_8: 1.879  loss_mask_8: 3.404  time: 2.4421  data_time: 0.4042  lr: 8.3217e-05  max_mem: 18490M
[01/24 09:47:50] d2.utils.events INFO:  eta: 1 day, 8:55:09  iter: 11099  total_loss: 49.56  loss_ce: 1.882  loss_mask: 3.224  loss_ce_0: 1.076  loss_mask_0: 3.688  loss_ce_1: 1.284  loss_mask_1: 3.865  loss_ce_2: 1.323  loss_mask_2: 3.699  loss_ce_3: 1.354  loss_mask_3: 3.447  loss_ce_4: 1.722  loss_mask_4: 3.134  loss_ce_5: 1.823  loss_mask_5: 3.126  loss_ce_6: 1.863  loss_mask_6: 3.236  loss_ce_7: 1.867  loss_mask_7: 3.197  loss_ce_8: 1.883  loss_mask_8: 3.301  time: 2.4421  data_time: 0.3507  lr: 8.3186e-05  max_mem: 18490M
[01/24 09:48:40] d2.utils.events INFO:  eta: 1 day, 8:54:20  iter: 11119  total_loss: 50.18  loss_ce: 1.812  loss_mask: 3.181  loss_ce_0: 1.118  loss_mask_0: 3.717  loss_ce_1: 1.337  loss_mask_1: 3.74  loss_ce_2: 1.369  loss_mask_2: 3.59  loss_ce_3: 1.409  loss_mask_3: 3.43  loss_ce_4: 1.728  loss_mask_4: 3.117  loss_ce_5: 1.823  loss_mask_5: 3.161  loss_ce_6: 1.838  loss_mask_6: 3.21  loss_ce_7: 1.838  loss_mask_7: 3.247  loss_ce_8: 1.836  loss_mask_8: 3.326  time: 2.4422  data_time: 0.4384  lr: 8.3155e-05  max_mem: 18490M
[01/24 09:49:27] d2.utils.events INFO:  eta: 1 day, 8:50:48  iter: 11139  total_loss: 50.88  loss_ce: 1.823  loss_mask: 3.266  loss_ce_0: 1.171  loss_mask_0: 3.824  loss_ce_1: 1.359  loss_mask_1: 3.933  loss_ce_2: 1.373  loss_mask_2: 3.839  loss_ce_3: 1.46  loss_mask_3: 3.493  loss_ce_4: 1.749  loss_mask_4: 3.226  loss_ce_5: 1.832  loss_mask_5: 3.154  loss_ce_6: 1.835  loss_mask_6: 3.229  loss_ce_7: 1.83  loss_mask_7: 3.19  loss_ce_8: 1.859  loss_mask_8: 3.305  time: 2.4420  data_time: 0.3500  lr: 8.3125e-05  max_mem: 18490M
[01/24 09:50:14] d2.utils.events INFO:  eta: 1 day, 8:48:35  iter: 11159  total_loss: 51.55  loss_ce: 1.844  loss_mask: 3.316  loss_ce_0: 1.121  loss_mask_0: 3.965  loss_ce_1: 1.33  loss_mask_1: 3.986  loss_ce_2: 1.369  loss_mask_2: 3.834  loss_ce_3: 1.419  loss_mask_3: 3.688  loss_ce_4: 1.768  loss_mask_4: 3.338  loss_ce_5: 1.897  loss_mask_5: 3.266  loss_ce_6: 1.868  loss_mask_6: 3.382  loss_ce_7: 1.883  loss_mask_7: 3.261  loss_ce_8: 1.894  loss_mask_8: 3.411  time: 2.4419  data_time: 0.3465  lr: 8.3094e-05  max_mem: 18490M
[01/24 09:51:06] d2.utils.events INFO:  eta: 1 day, 8:49:20  iter: 11179  total_loss: 50.18  loss_ce: 1.836  loss_mask: 3.195  loss_ce_0: 1.041  loss_mask_0: 3.636  loss_ce_1: 1.303  loss_mask_1: 3.827  loss_ce_2: 1.321  loss_mask_2: 3.599  loss_ce_3: 1.432  loss_mask_3: 3.513  loss_ce_4: 1.764  loss_mask_4: 3.272  loss_ce_5: 1.837  loss_mask_5: 3.163  loss_ce_6: 1.867  loss_mask_6: 3.274  loss_ce_7: 1.843  loss_mask_7: 3.194  loss_ce_8: 1.873  loss_mask_8: 3.231  time: 2.4421  data_time: 0.4066  lr: 8.3063e-05  max_mem: 18490M
[01/24 09:51:53] d2.utils.events INFO:  eta: 1 day, 8:48:32  iter: 11199  total_loss: 49.21  loss_ce: 1.827  loss_mask: 3.119  loss_ce_0: 1.068  loss_mask_0: 3.567  loss_ce_1: 1.256  loss_mask_1: 3.677  loss_ce_2: 1.287  loss_mask_2: 3.444  loss_ce_3: 1.435  loss_mask_3: 3.345  loss_ce_4: 1.756  loss_mask_4: 3.114  loss_ce_5: 1.85  loss_mask_5: 3.14  loss_ce_6: 1.841  loss_mask_6: 3.166  loss_ce_7: 1.863  loss_mask_7: 3.157  loss_ce_8: 1.855  loss_mask_8: 3.277  time: 2.4420  data_time: 0.3911  lr: 8.3033e-05  max_mem: 18490M
[01/24 09:52:41] d2.utils.events INFO:  eta: 1 day, 8:47:05  iter: 11219  total_loss: 50.58  loss_ce: 1.818  loss_mask: 3.208  loss_ce_0: 1.136  loss_mask_0: 3.835  loss_ce_1: 1.27  loss_mask_1: 3.886  loss_ce_2: 1.308  loss_mask_2: 3.622  loss_ce_3: 1.436  loss_mask_3: 3.51  loss_ce_4: 1.769  loss_mask_4: 3.207  loss_ce_5: 1.869  loss_mask_5: 3.183  loss_ce_6: 1.844  loss_mask_6: 3.221  loss_ce_7: 1.854  loss_mask_7: 3.243  loss_ce_8: 1.864  loss_mask_8: 3.283  time: 2.4419  data_time: 0.3783  lr: 8.3002e-05  max_mem: 18490M
[01/24 09:53:33] d2.utils.events INFO:  eta: 1 day, 8:44:50  iter: 11239  total_loss: 50.13  loss_ce: 1.836  loss_mask: 3.164  loss_ce_0: 1.125  loss_mask_0: 3.841  loss_ce_1: 1.282  loss_mask_1: 3.777  loss_ce_2: 1.315  loss_mask_2: 3.663  loss_ce_3: 1.447  loss_mask_3: 3.555  loss_ce_4: 1.814  loss_mask_4: 3.196  loss_ce_5: 1.885  loss_mask_5: 3.164  loss_ce_6: 1.879  loss_mask_6: 3.238  loss_ce_7: 1.9  loss_mask_7: 3.161  loss_ce_8: 1.871  loss_mask_8: 3.238  time: 2.4422  data_time: 0.3976  lr: 8.2972e-05  max_mem: 18490M
[01/24 09:54:20] d2.utils.events INFO:  eta: 1 day, 8:42:42  iter: 11259  total_loss: 49.85  loss_ce: 1.791  loss_mask: 3.204  loss_ce_0: 1.127  loss_mask_0: 3.745  loss_ce_1: 1.29  loss_mask_1: 3.653  loss_ce_2: 1.304  loss_mask_2: 3.534  loss_ce_3: 1.465  loss_mask_3: 3.447  loss_ce_4: 1.778  loss_mask_4: 3.229  loss_ce_5: 1.851  loss_mask_5: 3.143  loss_ce_6: 1.841  loss_mask_6: 3.237  loss_ce_7: 1.843  loss_mask_7: 3.184  loss_ce_8: 1.819  loss_mask_8: 3.146  time: 2.4420  data_time: 0.3573  lr: 8.2941e-05  max_mem: 18490M
[01/24 09:55:09] d2.utils.events INFO:  eta: 1 day, 8:41:03  iter: 11279  total_loss: 49.4  loss_ce: 1.809  loss_mask: 3.183  loss_ce_0: 1.125  loss_mask_0: 3.757  loss_ce_1: 1.17  loss_mask_1: 3.671  loss_ce_2: 1.283  loss_mask_2: 3.477  loss_ce_3: 1.443  loss_mask_3: 3.441  loss_ce_4: 1.778  loss_mask_4: 3.167  loss_ce_5: 1.854  loss_mask_5: 3.134  loss_ce_6: 1.859  loss_mask_6: 3.161  loss_ce_7: 1.879  loss_mask_7: 3.109  loss_ce_8: 1.84  loss_mask_8: 3.108  time: 2.4420  data_time: 0.3762  lr: 8.291e-05  max_mem: 18490M
[01/24 09:55:57] d2.utils.events INFO:  eta: 1 day, 8:36:57  iter: 11299  total_loss: 49.16  loss_ce: 1.807  loss_mask: 3.093  loss_ce_0: 1.082  loss_mask_0: 3.54  loss_ce_1: 1.192  loss_mask_1: 3.614  loss_ce_2: 1.245  loss_mask_2: 3.474  loss_ce_3: 1.483  loss_mask_3: 3.495  loss_ce_4: 1.793  loss_mask_4: 3.212  loss_ce_5: 1.862  loss_mask_5: 3.099  loss_ce_6: 1.828  loss_mask_6: 3.076  loss_ce_7: 1.853  loss_mask_7: 3.063  loss_ce_8: 1.852  loss_mask_8: 3.165  time: 2.4419  data_time: 0.3747  lr: 8.288e-05  max_mem: 18490M
[01/24 09:56:44] d2.utils.events INFO:  eta: 1 day, 8:35:58  iter: 11319  total_loss: 50.71  loss_ce: 1.851  loss_mask: 3.357  loss_ce_0: 1.078  loss_mask_0: 3.899  loss_ce_1: 1.17  loss_mask_1: 3.67  loss_ce_2: 1.241  loss_mask_2: 3.626  loss_ce_3: 1.498  loss_mask_3: 3.567  loss_ce_4: 1.795  loss_mask_4: 3.296  loss_ce_5: 1.854  loss_mask_5: 3.294  loss_ce_6: 1.853  loss_mask_6: 3.273  loss_ce_7: 1.881  loss_mask_7: 3.321  loss_ce_8: 1.858  loss_mask_8: 3.311  time: 2.4418  data_time: 0.3875  lr: 8.2849e-05  max_mem: 18490M
[01/24 09:57:35] d2.utils.events INFO:  eta: 1 day, 8:35:27  iter: 11339  total_loss: 50.4  loss_ce: 1.808  loss_mask: 3.299  loss_ce_0: 1.068  loss_mask_0: 3.657  loss_ce_1: 1.161  loss_mask_1: 3.727  loss_ce_2: 1.244  loss_mask_2: 3.551  loss_ce_3: 1.45  loss_mask_3: 3.699  loss_ce_4: 1.756  loss_mask_4: 3.453  loss_ce_5: 1.847  loss_mask_5: 3.288  loss_ce_6: 1.833  loss_mask_6: 3.368  loss_ce_7: 1.837  loss_mask_7: 3.288  loss_ce_8: 1.849  loss_mask_8: 3.418  time: 2.4420  data_time: 0.4221  lr: 8.2818e-05  max_mem: 18490M
[01/24 09:58:23] d2.utils.events INFO:  eta: 1 day, 8:33:25  iter: 11359  total_loss: 48.3  loss_ce: 1.789  loss_mask: 3.122  loss_ce_0: 1.052  loss_mask_0: 3.377  loss_ce_1: 1.18  loss_mask_1: 3.528  loss_ce_2: 1.242  loss_mask_2: 3.372  loss_ce_3: 1.416  loss_mask_3: 3.444  loss_ce_4: 1.784  loss_mask_4: 3.416  loss_ce_5: 1.867  loss_mask_5: 3.113  loss_ce_6: 1.842  loss_mask_6: 3.101  loss_ce_7: 1.859  loss_mask_7: 3.063  loss_ce_8: 1.852  loss_mask_8: 3.14  time: 2.4419  data_time: 0.3892  lr: 8.2788e-05  max_mem: 18490M
[01/24 09:59:10] d2.utils.events INFO:  eta: 1 day, 8:32:37  iter: 11379  total_loss: 50.78  loss_ce: 1.81  loss_mask: 3.209  loss_ce_0: 1.121  loss_mask_0: 3.769  loss_ce_1: 1.223  loss_mask_1: 3.645  loss_ce_2: 1.31  loss_mask_2: 3.646  loss_ce_3: 1.386  loss_mask_3: 3.605  loss_ce_4: 1.826  loss_mask_4: 3.572  loss_ce_5: 1.864  loss_mask_5: 3.291  loss_ce_6: 1.866  loss_mask_6: 3.386  loss_ce_7: 1.868  loss_mask_7: 3.178  loss_ce_8: 1.862  loss_mask_8: 3.369  time: 2.4418  data_time: 0.3798  lr: 8.2757e-05  max_mem: 18490M
[01/24 10:00:02] d2.utils.events INFO:  eta: 1 day, 8:33:13  iter: 11399  total_loss: 50.47  loss_ce: 1.808  loss_mask: 3.142  loss_ce_0: 1.104  loss_mask_0: 3.654  loss_ce_1: 1.268  loss_mask_1: 3.631  loss_ce_2: 1.279  loss_mask_2: 3.623  loss_ce_3: 1.354  loss_mask_3: 3.637  loss_ce_4: 1.81  loss_mask_4: 3.499  loss_ce_5: 1.894  loss_mask_5: 3.25  loss_ce_6: 1.897  loss_mask_6: 3.277  loss_ce_7: 1.88  loss_mask_7: 3.129  loss_ce_8: 1.872  loss_mask_8: 3.308  time: 2.4420  data_time: 0.4273  lr: 8.2726e-05  max_mem: 18490M
[01/24 10:00:49] d2.utils.events INFO:  eta: 1 day, 8:30:23  iter: 11419  total_loss: 48.51  loss_ce: 1.795  loss_mask: 2.968  loss_ce_0: 1.128  loss_mask_0: 3.596  loss_ce_1: 1.345  loss_mask_1: 3.586  loss_ce_2: 1.288  loss_mask_2: 3.467  loss_ce_3: 1.396  loss_mask_3: 3.322  loss_ce_4: 1.779  loss_mask_4: 3.198  loss_ce_5: 1.822  loss_mask_5: 3.106  loss_ce_6: 1.875  loss_mask_6: 3.151  loss_ce_7: 1.84  loss_mask_7: 3.066  loss_ce_8: 1.85  loss_mask_8: 3.1  time: 2.4419  data_time: 0.3823  lr: 8.2696e-05  max_mem: 18490M
[01/24 10:01:37] d2.utils.events INFO:  eta: 1 day, 8:26:38  iter: 11439  total_loss: 50.76  loss_ce: 1.811  loss_mask: 3.11  loss_ce_0: 1.128  loss_mask_0: 3.937  loss_ce_1: 1.31  loss_mask_1: 3.719  loss_ce_2: 1.235  loss_mask_2: 3.726  loss_ce_3: 1.402  loss_mask_3: 3.545  loss_ce_4: 1.806  loss_mask_4: 3.365  loss_ce_5: 1.854  loss_mask_5: 3.275  loss_ce_6: 1.864  loss_mask_6: 3.208  loss_ce_7: 1.837  loss_mask_7: 3.182  loss_ce_8: 1.851  loss_mask_8: 3.266  time: 2.4417  data_time: 0.3643  lr: 8.2665e-05  max_mem: 18490M
[01/24 10:02:29] d2.utils.events INFO:  eta: 1 day, 8:27:11  iter: 11459  total_loss: 50.59  loss_ce: 1.823  loss_mask: 3.194  loss_ce_0: 1.14  loss_mask_0: 4.046  loss_ce_1: 1.247  loss_mask_1: 3.815  loss_ce_2: 1.246  loss_mask_2: 3.675  loss_ce_3: 1.433  loss_mask_3: 3.368  loss_ce_4: 1.78  loss_mask_4: 3.45  loss_ce_5: 1.893  loss_mask_5: 3.548  loss_ce_6: 1.909  loss_mask_6: 3.45  loss_ce_7: 1.864  loss_mask_7: 3.23  loss_ce_8: 1.864  loss_mask_8: 3.253  time: 2.4420  data_time: 0.4111  lr: 8.2635e-05  max_mem: 18490M
[01/24 10:03:17] d2.utils.events INFO:  eta: 1 day, 8:25:52  iter: 11479  total_loss: 51.5  loss_ce: 1.846  loss_mask: 3.25  loss_ce_0: 1.187  loss_mask_0: 4.018  loss_ce_1: 1.226  loss_mask_1: 3.841  loss_ce_2: 1.24  loss_mask_2: 3.668  loss_ce_3: 1.451  loss_mask_3: 3.518  loss_ce_4: 1.77  loss_mask_4: 3.377  loss_ce_5: 1.873  loss_mask_5: 3.46  loss_ce_6: 1.912  loss_mask_6: 3.545  loss_ce_7: 1.882  loss_mask_7: 3.393  loss_ce_8: 1.88  loss_mask_8: 3.486  time: 2.4419  data_time: 0.3780  lr: 8.2604e-05  max_mem: 18490M
[01/24 10:04:05] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 10:04:06] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 10:04:06] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 10:08:26] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 10.250888276878861, 'error_1pix': 0.8171755982126007, 'error_3pix': 0.7144674778793519, 'mIoU': 0.5464888976076339, 'fwIoU': 5.172673248670047, 'IoU-0': nan, 'IoU-1': 44.49282537089148, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.9747337782837617, 'IoU-12': 0.00045655057268295787, 'IoU-13': 0.5607241676966415, 'IoU-14': 0.4589450714323743, 'IoU-15': 1.2603142297077403, 'IoU-16': 0.010787697479346924, 'IoU-17': 0.0001781392177363156, 'IoU-18': 0.0, 'IoU-19': 0.005719809709137274, 'IoU-20': 0.004819164390702566, 'IoU-21': 0.1659510508232842, 'IoU-22': 0.3850841101588326, 'IoU-23': 0.00024379993155926422, 'IoU-24': 0.9386940056435686, 'IoU-25': 0.021364766056424556, 'IoU-26': 1.8821595986878648, 'IoU-27': 0.9739156096361031, 'IoU-28': 2.6815584341170005, 'IoU-29': 1.7007138584024404, 'IoU-30': 0.0004100482263186283, 'IoU-31': 0.0010659036996077003, 'IoU-32': 0.0006846404540297355, 'IoU-33': 3.9188056895431056, 'IoU-34': 0.07819652543787121, 'IoU-35': 3.0925916052269886, 'IoU-36': 3.288259245701279e-05, 'IoU-37': 0.28068185957038877, 'IoU-38': 3.403898403499708, 'IoU-39': 2.9588776109626904, 'IoU-40': 0.12364864453168059, 'IoU-41': 3.120062123440383, 'IoU-42': 0.0008049924217730961, 'IoU-43': 1.7503176462569765, 'IoU-44': 1.192964436672194, 'IoU-45': 0.021112937030777608, 'IoU-46': 1.0797098908647411, 'IoU-47': 0.022441643195148964, 'IoU-48': 0.006640434451967281, 'IoU-49': 0.0008306602414416122, 'IoU-50': 0.0, 'IoU-51': 2.066518342264816, 'IoU-52': 0.04424518094037497, 'IoU-53': 0.0016251542130030383, 'IoU-54': 0.004750700952216174, 'IoU-55': 0.0, 'IoU-56': 0.1285501000168687, 'IoU-57': 0.0, 'IoU-58': 0.32662337312994977, 'IoU-59': 0.009475415896186246, 'IoU-60': 0.0, 'IoU-61': 0.0016570891355740397, 'IoU-62': 0.021168183018185995, 'IoU-63': 8.299109496329812e-05, 'IoU-64': 0.0, 'IoU-65': 0.3309683151762383, 'IoU-66': 1.770416382313073, 'IoU-67': 0.08409955476706299, 'IoU-68': 0.016250926165071695, 'IoU-69': 0.03336399693176344, 'IoU-70': 0.001807695263595269, 'IoU-71': 0.00020941344286611613, 'IoU-72': 0.029857177662207208, 'IoU-73': 0.007183339683582163, 'IoU-74': 0.0, 'IoU-75': 0.0349553954699763, 'IoU-76': 1.1290306999748836, 'IoU-77': 0.6031848017398909, 'IoU-78': 0.020047042995250113, 'IoU-79': 0.20832463262334933, 'IoU-80': 0.00173210741316598, 'IoU-81': 0.5638614148731665, 'IoU-82': 2.4203008042475127, 'IoU-83': 1.9264894000200803, 'IoU-84': 0.07049471119653886, 'IoU-85': 0.00790037784766298, 'IoU-86': 0.004157746803614027, 'IoU-87': 0.006627591946853304, 'IoU-88': 1.6734831138925284, 'IoU-89': 1.80848876540524, 'IoU-90': 0.03642272054473924, 'IoU-91': 0.06459052681109956, 'IoU-92': 0.06293657263757581, 'IoU-93': 0.006310325138042014, 'IoU-94': 0.12104547424421298, 'IoU-95': 0.2438478665145674, 'IoU-96': 0.0, 'IoU-97': 0.0008729313239253018, 'IoU-98': 0.0, 'IoU-99': 0.0009059854992201778, 'IoU-100': 2.1480365831452257, 'IoU-101': 0.02277118483857772, 'IoU-102': 0.12105913491446874, 'IoU-103': 2.8285808788165134, 'IoU-104': 0.0, 'IoU-105': 0.002625812089748728, 'IoU-106': 0.0001048736626313903, 'IoU-107': 0.001032242081412933, 'IoU-108': 2.7635714850272457e-05, 'IoU-109': 0.033014030124883534, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.30464331823626767, 'IoU-113': 1.5515401553281742, 'IoU-114': 0.4030358330006899, 'IoU-115': 0.0014277394751178825, 'IoU-116': 0.0, 'IoU-117': 0.03104842535088249, 'IoU-118': 0.07028799764268627, 'IoU-119': 0.12034224824533504, 'IoU-120': 0.0, 'IoU-121': 0.04145411587821511, 'IoU-122': 0.0027751933463093224, 'IoU-123': 0.0031039008643624884, 'IoU-124': 1.2927315178459824, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.00023362166140044504, 'IoU-128': 6.095293823638769e-05, 'IoU-129': 0.0, 'IoU-130': 0.0005804107502389358, 'IoU-131': 0.0, 'IoU-132': 0.00013377568493150684, 'IoU-133': 6.802711833045125e-05, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.006288336533139146, 'IoU-139': 1.0433530607805634, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.09120922883239341, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0001827455323285984, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.1994192485243356, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.6708809069833992, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.46421818106434054, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0017648912700913963, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.127880691088542, 'pACC': 12.834836359082402, 'ACC-0': nan, 'ACC-1': 99.624833513404, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 1.028553352726912, 'ACC-12': 0.00045658258093929024, 'ACC-13': 0.5781054390226974, 'ACC-14': 0.4900009356025013, 'ACC-15': 1.4182935046318794, 'ACC-16': 0.010810040965606248, 'ACC-17': 0.00017814323184638429, 'ACC-18': 0.0, 'ACC-19': 0.00573569008817724, 'ACC-20': 0.0048281379940958765, 'ACC-21': 0.17547038634553358, 'ACC-22': 0.4083726330801102, 'ACC-23': 0.00024383526538237818, 'ACC-24': 1.5778404390958276, 'ACC-25': 0.021664698396293387, 'ACC-26': 7.643991476182041, 'ACC-27': 1.12253848385577, 'ACC-28': 5.308558460092935, 'ACC-29': 2.209067711992502, 'ACC-30': 0.00041009040005439445, 'ACC-31': 0.0010660483760704356, 'ACC-32': 0.000684830612155738, 'ACC-33': 53.397476439725665, 'ACC-34': 0.0802194690868947, 'ACC-35': 10.233951633041436, 'ACC-36': 3.2883177251505665e-05, 'ACC-37': 0.3597812146718085, 'ACC-38': 9.539915935597945, 'ACC-39': 12.32468011454549, 'ACC-40': 0.27318700312756133, 'ACC-41': 24.310920056917155, 'ACC-42': 0.0008060074706287166, 'ACC-43': 6.477409506578177, 'ACC-44': 1.7973576898830568, 'ACC-45': 0.0213419976798524, 'ACC-46': 1.8768726813319314, 'ACC-47': 0.022688892807165156, 'ACC-48': 0.006662550573005894, 'ACC-49': 0.0008308686122945944, 'ACC-50': 0.0, 'ACC-51': 5.28170175419544, 'ACC-52': 0.044667587856185735, 'ACC-53': 0.0016270767335373436, 'ACC-54': 0.004755803761084552, 'ACC-55': 0.0, 'ACC-56': 0.13434480587455278, 'ACC-57': 0.0, 'ACC-58': 0.34903901540118815, 'ACC-59': 0.009507726125667866, 'ACC-60': 0.0, 'ACC-61': 0.001661061904354887, 'ACC-62': 0.02159095927650658, 'ACC-63': 8.300536989406302e-05, 'ACC-64': 0.0, 'ACC-65': 0.3739872703073911, 'ACC-66': 9.674877382993103, 'ACC-67': 0.08867388683641916, 'ACC-68': 0.016547502713240302, 'ACC-69': 0.033894574527231595, 'ACC-70': 0.001810934997388441, 'ACC-71': 0.00020949254840518284, 'ACC-72': 0.030201871446936916, 'ACC-73': 0.007193150794517206, 'ACC-74': 0.0, 'ACC-75': 0.03591634734351163, 'ACC-76': 1.6833936368461877, 'ACC-77': 0.7518002488462098, 'ACC-78': 0.02024281169437769, 'ACC-79': 0.25446270399424914, 'ACC-80': 0.0017361051597598249, 'ACC-81': 0.7243963271605964, 'ACC-82': 23.68142675420664, 'ACC-83': 19.774895690956086, 'ACC-84': 0.07289316688089266, 'ACC-85': 0.00793881143725816, 'ACC-86': 0.004174110200066763, 'ACC-87': 0.006643411057572315, 'ACC-88': 4.064754539903872, 'ACC-89': 10.936550843493226, 'ACC-90': 0.03673551057670062, 'ACC-91': 0.06631012782763776, 'ACC-92': 0.06509869533853241, 'ACC-93': 0.006364255512483885, 'ACC-94': 0.12808629586109754, 'ACC-95': 0.2615930418139636, 'ACC-96': 0.0, 'ACC-97': 0.0008731637238481044, 'ACC-98': 0.0, 'ACC-99': 0.0009063511690387355, 'ACC-100': 8.93956681563512, 'ACC-101': 0.02291207780305414, 'ACC-102': 0.1314227458087902, 'ACC-103': 19.531737035987533, 'ACC-104': 0.0, 'ACC-105': 0.00263053654517589, 'ACC-106': 0.00010488950284211219, 'ACC-107': 0.0010334669225313194, 'ACC-108': 2.7636318212306068e-05, 'ACC-109': 0.03350895769281471, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.3272854426878446, 'ACC-113': 5.004742163293402, 'ACC-114': 0.6082368165854408, 'ACC-115': 0.0014282922135522378, 'ACC-116': 0.0, 'ACC-117': 0.031824432002198776, 'ACC-118': 0.07251132280890474, 'ACC-119': 0.12528216365427614, 'ACC-120': 0.0, 'ACC-121': 0.04383122118324312, 'ACC-122': 0.0027833602234236276, 'ACC-123': 0.0031085383159419663, 'ACC-124': 44.62796620959661, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.00023362520909456214, 'ACC-128': 6.0983716128119473e-05, 'ACC-129': 0.0, 'ACC-130': 0.0005804309635411964, 'ACC-131': 0.0, 'ACC-132': 0.00013404241772308848, 'ACC-133': 6.804248572808862e-05, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.006424981597583573, 'ACC-139': 5.61539918327727, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.11483996538626397, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0001827694135386443, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.26570148742126565, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 1.1359228454418135, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.8804275479741741, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0017654654775836327, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 10:08:26] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 10:08:26] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 10:08:26] d2.evaluation.testing INFO: copypaste: 10.2509,0.8172,0.7145,0.5465,5.1727,2.1279,12.8348
[01/24 10:08:26] d2.utils.events INFO:  eta: 1 day, 8:24:14  iter: 11499  total_loss: 50.36  loss_ce: 1.816  loss_mask: 3.245  loss_ce_0: 1.139  loss_mask_0: 3.948  loss_ce_1: 1.184  loss_mask_1: 3.777  loss_ce_2: 1.29  loss_mask_2: 3.632  loss_ce_3: 1.525  loss_mask_3: 3.396  loss_ce_4: 1.794  loss_mask_4: 3.247  loss_ce_5: 1.871  loss_mask_5: 3.345  loss_ce_6: 1.88  loss_mask_6: 3.392  loss_ce_7: 1.852  loss_mask_7: 3.161  loss_ce_8: 1.863  loss_mask_8: 3.301  time: 2.4419  data_time: 0.4049  lr: 8.2573e-05  max_mem: 18490M
[01/24 10:09:16] d2.utils.events INFO:  eta: 1 day, 8:20:15  iter: 11519  total_loss: 50.65  loss_ce: 1.817  loss_mask: 3.238  loss_ce_0: 1.103  loss_mask_0: 3.952  loss_ce_1: 1.22  loss_mask_1: 3.673  loss_ce_2: 1.36  loss_mask_2: 3.782  loss_ce_3: 1.539  loss_mask_3: 3.371  loss_ce_4: 1.779  loss_mask_4: 3.229  loss_ce_5: 1.829  loss_mask_5: 3.255  loss_ce_6: 1.881  loss_mask_6: 3.312  loss_ce_7: 1.871  loss_mask_7: 3.265  loss_ce_8: 1.86  loss_mask_8: 3.278  time: 2.4420  data_time: 0.4287  lr: 8.2543e-05  max_mem: 18490M
[01/24 10:10:06] d2.utils.events INFO:  eta: 1 day, 8:18:15  iter: 11539  total_loss: 50.62  loss_ce: 1.817  loss_mask: 3.204  loss_ce_0: 1.127  loss_mask_0: 3.858  loss_ce_1: 1.194  loss_mask_1: 3.818  loss_ce_2: 1.24  loss_mask_2: 3.788  loss_ce_3: 1.491  loss_mask_3: 3.392  loss_ce_4: 1.762  loss_mask_4: 3.211  loss_ce_5: 1.851  loss_mask_5: 3.206  loss_ce_6: 1.895  loss_mask_6: 3.496  loss_ce_7: 1.862  loss_mask_7: 3.187  loss_ce_8: 1.865  loss_mask_8: 3.256  time: 2.4421  data_time: 0.3991  lr: 8.2512e-05  max_mem: 18490M
[01/24 10:10:54] d2.utils.events INFO:  eta: 1 day, 8:23:02  iter: 11559  total_loss: 51.2  loss_ce: 1.811  loss_mask: 3.244  loss_ce_0: 1.191  loss_mask_0: 3.93  loss_ce_1: 1.262  loss_mask_1: 3.906  loss_ce_2: 1.308  loss_mask_2: 3.751  loss_ce_3: 1.519  loss_mask_3: 3.488  loss_ce_4: 1.773  loss_mask_4: 3.397  loss_ce_5: 1.855  loss_mask_5: 3.265  loss_ce_6: 1.882  loss_mask_6: 3.419  loss_ce_7: 1.857  loss_mask_7: 3.229  loss_ce_8: 1.861  loss_mask_8: 3.312  time: 2.4421  data_time: 0.4044  lr: 8.2481e-05  max_mem: 18490M
[01/24 10:11:47] d2.utils.events INFO:  eta: 1 day, 8:25:41  iter: 11579  total_loss: 52.19  loss_ce: 1.837  loss_mask: 3.329  loss_ce_0: 1.201  loss_mask_0: 3.919  loss_ce_1: 1.158  loss_mask_1: 3.695  loss_ce_2: 1.241  loss_mask_2: 3.792  loss_ce_3: 1.472  loss_mask_3: 3.65  loss_ce_4: 1.822  loss_mask_4: 3.713  loss_ce_5: 1.882  loss_mask_5: 3.542  loss_ce_6: 1.873  loss_mask_6: 3.428  loss_ce_7: 1.851  loss_mask_7: 3.442  loss_ce_8: 1.852  loss_mask_8: 3.358  time: 2.4424  data_time: 0.4264  lr: 8.2451e-05  max_mem: 18490M
[01/24 10:12:36] d2.utils.events INFO:  eta: 1 day, 8:24:53  iter: 11599  total_loss: 52.09  loss_ce: 1.849  loss_mask: 3.446  loss_ce_0: 1.209  loss_mask_0: 4.02  loss_ce_1: 1.157  loss_mask_1: 3.773  loss_ce_2: 1.248  loss_mask_2: 3.812  loss_ce_3: 1.446  loss_mask_3: 3.534  loss_ce_4: 1.808  loss_mask_4: 3.387  loss_ce_5: 1.916  loss_mask_5: 3.465  loss_ce_6: 1.881  loss_mask_6: 3.48  loss_ce_7: 1.876  loss_mask_7: 3.399  loss_ce_8: 1.875  loss_mask_8: 3.369  time: 2.4424  data_time: 0.4227  lr: 8.242e-05  max_mem: 18490M
[01/24 10:13:24] d2.utils.events INFO:  eta: 1 day, 8:24:39  iter: 11619  total_loss: 50.98  loss_ce: 1.815  loss_mask: 3.328  loss_ce_0: 1.165  loss_mask_0: 4.141  loss_ce_1: 1.125  loss_mask_1: 3.928  loss_ce_2: 1.182  loss_mask_2: 3.871  loss_ce_3: 1.37  loss_mask_3: 3.608  loss_ce_4: 1.748  loss_mask_4: 3.327  loss_ce_5: 1.878  loss_mask_5: 3.394  loss_ce_6: 1.852  loss_mask_6: 3.366  loss_ce_7: 1.856  loss_mask_7: 3.538  loss_ce_8: 1.825  loss_mask_8: 3.299  time: 2.4423  data_time: 0.3830  lr: 8.2389e-05  max_mem: 18490M
[01/24 10:14:17] d2.utils.events INFO:  eta: 1 day, 8:26:34  iter: 11639  total_loss: 52.05  loss_ce: 1.84  loss_mask: 3.312  loss_ce_0: 1.115  loss_mask_0: 3.84  loss_ce_1: 1.072  loss_mask_1: 3.848  loss_ce_2: 1.17  loss_mask_2: 3.728  loss_ce_3: 1.374  loss_mask_3: 3.54  loss_ce_4: 1.763  loss_mask_4: 3.583  loss_ce_5: 1.884  loss_mask_5: 3.672  loss_ce_6: 1.879  loss_mask_6: 3.78  loss_ce_7: 1.853  loss_mask_7: 3.475  loss_ce_8: 1.841  loss_mask_8: 3.402  time: 2.4426  data_time: 0.4347  lr: 8.2359e-05  max_mem: 18490M
[01/24 10:15:03] d2.utils.events INFO:  eta: 1 day, 8:25:25  iter: 11659  total_loss: 51.36  loss_ce: 1.825  loss_mask: 3.269  loss_ce_0: 1.171  loss_mask_0: 3.88  loss_ce_1: 1.095  loss_mask_1: 3.709  loss_ce_2: 1.136  loss_mask_2: 3.676  loss_ce_3: 1.393  loss_mask_3: 3.504  loss_ce_4: 1.744  loss_mask_4: 3.378  loss_ce_5: 1.857  loss_mask_5: 3.57  loss_ce_6: 1.86  loss_mask_6: 3.503  loss_ce_7: 1.86  loss_mask_7: 3.573  loss_ce_8: 1.844  loss_mask_8: 3.421  time: 2.4424  data_time: 0.3399  lr: 8.2328e-05  max_mem: 18490M
[01/24 10:15:51] d2.utils.events INFO:  eta: 1 day, 8:24:48  iter: 11679  total_loss: 50.14  loss_ce: 1.826  loss_mask: 3.286  loss_ce_0: 1.181  loss_mask_0: 3.76  loss_ce_1: 1.126  loss_mask_1: 3.532  loss_ce_2: 1.165  loss_mask_2: 3.521  loss_ce_3: 1.594  loss_mask_3: 3.545  loss_ce_4: 1.79  loss_mask_4: 3.272  loss_ce_5: 1.837  loss_mask_5: 3.419  loss_ce_6: 1.814  loss_mask_6: 3.368  loss_ce_7: 1.86  loss_mask_7: 3.464  loss_ce_8: 1.839  loss_mask_8: 3.449  time: 2.4424  data_time: 0.3742  lr: 8.2297e-05  max_mem: 18490M
[01/24 10:16:43] d2.utils.events INFO:  eta: 1 day, 8:21:26  iter: 11699  total_loss: 53.29  loss_ce: 1.88  loss_mask: 3.412  loss_ce_0: 1.239  loss_mask_0: 3.901  loss_ce_1: 1.13  loss_mask_1: 3.784  loss_ce_2: 1.187  loss_mask_2: 3.7  loss_ce_3: 1.481  loss_mask_3: 3.419  loss_ce_4: 1.763  loss_mask_4: 3.563  loss_ce_5: 1.938  loss_mask_5: 4.198  loss_ce_6: 1.87  loss_mask_6: 3.602  loss_ce_7: 1.891  loss_mask_7: 3.701  loss_ce_8: 1.932  loss_mask_8: 3.586  time: 2.4426  data_time: 0.4061  lr: 8.2267e-05  max_mem: 18490M
[01/24 10:17:31] d2.utils.events INFO:  eta: 1 day, 8:20:38  iter: 11719  total_loss: 51.23  loss_ce: 1.816  loss_mask: 3.279  loss_ce_0: 1.205  loss_mask_0: 4.022  loss_ce_1: 1.185  loss_mask_1: 3.743  loss_ce_2: 1.234  loss_mask_2: 3.6  loss_ce_3: 1.513  loss_mask_3: 3.605  loss_ce_4: 1.825  loss_mask_4: 3.291  loss_ce_5: 1.904  loss_mask_5: 3.288  loss_ce_6: 1.892  loss_mask_6: 3.474  loss_ce_7: 1.874  loss_mask_7: 3.402  loss_ce_8: 1.868  loss_mask_8: 3.295  time: 2.4425  data_time: 0.3389  lr: 8.2236e-05  max_mem: 18490M
[01/24 10:18:23] d2.utils.events INFO:  eta: 1 day, 8:22:54  iter: 11739  total_loss: 54.58  loss_ce: 1.817  loss_mask: 3.618  loss_ce_0: 1.233  loss_mask_0: 4.534  loss_ce_1: 1.153  loss_mask_1: 4.131  loss_ce_2: 1.219  loss_mask_2: 3.99  loss_ce_3: 1.503  loss_mask_3: 4.005  loss_ce_4: 1.812  loss_mask_4: 3.593  loss_ce_5: 1.918  loss_mask_5: 3.666  loss_ce_6: 1.962  loss_mask_6: 3.802  loss_ce_7: 1.889  loss_mask_7: 3.556  loss_ce_8: 1.844  loss_mask_8: 3.562  time: 2.4428  data_time: 0.4083  lr: 8.2205e-05  max_mem: 18490M
[01/24 10:19:11] d2.utils.events INFO:  eta: 1 day, 8:19:40  iter: 11759  total_loss: 50.81  loss_ce: 1.781  loss_mask: 3.372  loss_ce_0: 1.159  loss_mask_0: 3.914  loss_ce_1: 1.125  loss_mask_1: 3.701  loss_ce_2: 1.206  loss_mask_2: 3.579  loss_ce_3: 1.401  loss_mask_3: 3.47  loss_ce_4: 1.771  loss_mask_4: 3.4  loss_ce_5: 1.867  loss_mask_5: 3.473  loss_ce_6: 1.873  loss_mask_6: 3.39  loss_ce_7: 1.897  loss_mask_7: 3.358  loss_ce_8: 1.846  loss_mask_8: 3.356  time: 2.4428  data_time: 0.3841  lr: 8.2175e-05  max_mem: 18490M
[01/24 10:19:59] d2.utils.events INFO:  eta: 1 day, 8:16:48  iter: 11779  total_loss: 51.57  loss_ce: 1.803  loss_mask: 3.348  loss_ce_0: 1.243  loss_mask_0: 3.798  loss_ce_1: 1.132  loss_mask_1: 3.753  loss_ce_2: 1.219  loss_mask_2: 3.468  loss_ce_3: 1.443  loss_mask_3: 3.458  loss_ce_4: 1.803  loss_mask_4: 3.226  loss_ce_5: 1.867  loss_mask_5: 3.392  loss_ce_6: 1.886  loss_mask_6: 3.831  loss_ce_7: 1.901  loss_mask_7: 3.509  loss_ce_8: 1.907  loss_mask_8: 3.531  time: 2.4426  data_time: 0.3588  lr: 8.2144e-05  max_mem: 18490M
[01/24 10:20:51] d2.utils.events INFO:  eta: 1 day, 8:20:08  iter: 11799  total_loss: 52.4  loss_ce: 1.812  loss_mask: 3.433  loss_ce_0: 1.241  loss_mask_0: 4.05  loss_ce_1: 1.168  loss_mask_1: 3.829  loss_ce_2: 1.208  loss_mask_2: 3.738  loss_ce_3: 1.418  loss_mask_3: 3.661  loss_ce_4: 1.767  loss_mask_4: 3.54  loss_ce_5: 1.841  loss_mask_5: 3.518  loss_ce_6: 1.837  loss_mask_6: 3.563  loss_ce_7: 1.86  loss_mask_7: 3.476  loss_ce_8: 1.842  loss_mask_8: 3.389  time: 2.4429  data_time: 0.4459  lr: 8.2113e-05  max_mem: 18490M
[01/24 10:21:39] d2.utils.events INFO:  eta: 1 day, 8:15:11  iter: 11819  total_loss: 51.42  loss_ce: 1.797  loss_mask: 3.337  loss_ce_0: 1.217  loss_mask_0: 3.835  loss_ce_1: 1.096  loss_mask_1: 3.78  loss_ce_2: 1.142  loss_mask_2: 3.587  loss_ce_3: 1.398  loss_mask_3: 3.522  loss_ce_4: 1.736  loss_mask_4: 3.441  loss_ce_5: 1.868  loss_mask_5: 3.444  loss_ce_6: 1.864  loss_mask_6: 3.54  loss_ce_7: 1.859  loss_mask_7: 3.376  loss_ce_8: 1.839  loss_mask_8: 3.404  time: 2.4428  data_time: 0.3611  lr: 8.2083e-05  max_mem: 18490M
[01/24 10:22:27] d2.utils.events INFO:  eta: 1 day, 8:13:05  iter: 11839  total_loss: 53.75  loss_ce: 1.825  loss_mask: 3.449  loss_ce_0: 1.29  loss_mask_0: 4.107  loss_ce_1: 1.157  loss_mask_1: 3.67  loss_ce_2: 1.174  loss_mask_2: 3.638  loss_ce_3: 1.327  loss_mask_3: 3.457  loss_ce_4: 1.73  loss_mask_4: 3.568  loss_ce_5: 2.06  loss_mask_5: 4.017  loss_ce_6: 1.965  loss_mask_6: 3.929  loss_ce_7: 1.933  loss_mask_7: 3.57  loss_ce_8: 1.919  loss_mask_8: 3.581  time: 2.4428  data_time: 0.3838  lr: 8.2052e-05  max_mem: 18490M
[01/24 10:23:20] d2.utils.events INFO:  eta: 1 day, 8:14:16  iter: 11859  total_loss: 53.51  loss_ce: 1.801  loss_mask: 3.432  loss_ce_0: 1.287  loss_mask_0: 4.28  loss_ce_1: 1.219  loss_mask_1: 3.862  loss_ce_2: 1.301  loss_mask_2: 3.843  loss_ce_3: 1.428  loss_mask_3: 3.634  loss_ce_4: 1.791  loss_mask_4: 3.499  loss_ce_5: 1.944  loss_mask_5: 4.063  loss_ce_6: 1.887  loss_mask_6: 3.772  loss_ce_7: 1.872  loss_mask_7: 3.454  loss_ce_8: 1.842  loss_mask_8: 3.512  time: 2.4431  data_time: 0.4313  lr: 8.2021e-05  max_mem: 18490M
[01/24 10:24:07] d2.utils.events INFO:  eta: 1 day, 8:10:44  iter: 11879  total_loss: 52.25  loss_ce: 1.799  loss_mask: 3.359  loss_ce_0: 1.184  loss_mask_0: 4.058  loss_ce_1: 1.234  loss_mask_1: 3.806  loss_ce_2: 1.443  loss_mask_2: 3.652  loss_ce_3: 1.556  loss_mask_3: 3.607  loss_ce_4: 1.861  loss_mask_4: 3.363  loss_ce_5: 1.963  loss_mask_5: 3.563  loss_ce_6: 1.9  loss_mask_6: 3.47  loss_ce_7: 1.869  loss_mask_7: 3.305  loss_ce_8: 1.838  loss_mask_8: 3.373  time: 2.4429  data_time: 0.3714  lr: 8.1991e-05  max_mem: 18490M
[01/24 10:24:55] d2.utils.events INFO:  eta: 1 day, 8:08:12  iter: 11899  total_loss: 51.56  loss_ce: 1.791  loss_mask: 3.109  loss_ce_0: 1.223  loss_mask_0: 3.978  loss_ce_1: 1.305  loss_mask_1: 3.91  loss_ce_2: 1.443  loss_mask_2: 3.751  loss_ce_3: 1.536  loss_mask_3: 3.45  loss_ce_4: 1.824  loss_mask_4: 3.282  loss_ce_5: 1.945  loss_mask_5: 3.308  loss_ce_6: 1.874  loss_mask_6: 3.231  loss_ce_7: 1.831  loss_mask_7: 3.155  loss_ce_8: 1.824  loss_mask_8: 3.25  time: 2.4429  data_time: 0.3801  lr: 8.196e-05  max_mem: 18490M
[01/24 10:25:46] d2.utils.events INFO:  eta: 1 day, 8:08:42  iter: 11919  total_loss: 52.59  loss_ce: 1.776  loss_mask: 3.436  loss_ce_0: 1.258  loss_mask_0: 4.174  loss_ce_1: 1.185  loss_mask_1: 3.95  loss_ce_2: 1.184  loss_mask_2: 3.777  loss_ce_3: 1.433  loss_mask_3: 3.72  loss_ce_4: 1.829  loss_mask_4: 3.416  loss_ce_5: 1.938  loss_mask_5: 3.562  loss_ce_6: 1.918  loss_mask_6: 3.488  loss_ce_7: 1.853  loss_mask_7: 3.438  loss_ce_8: 1.79  loss_mask_8: 3.427  time: 2.4430  data_time: 0.4174  lr: 8.1929e-05  max_mem: 18490M
[01/24 10:26:33] d2.utils.events INFO:  eta: 1 day, 8:06:01  iter: 11939  total_loss: 51.38  loss_ce: 1.787  loss_mask: 3.457  loss_ce_0: 1.171  loss_mask_0: 3.888  loss_ce_1: 1.156  loss_mask_1: 3.783  loss_ce_2: 1.226  loss_mask_2: 3.641  loss_ce_3: 1.405  loss_mask_3: 3.544  loss_ce_4: 1.787  loss_mask_4: 3.384  loss_ce_5: 1.944  loss_mask_5: 3.466  loss_ce_6: 1.901  loss_mask_6: 3.429  loss_ce_7: 1.845  loss_mask_7: 3.353  loss_ce_8: 1.824  loss_mask_8: 3.401  time: 2.4429  data_time: 0.3734  lr: 8.1899e-05  max_mem: 18490M
[01/24 10:27:22] d2.utils.events INFO:  eta: 1 day, 8:07:31  iter: 11959  total_loss: 51.25  loss_ce: 1.768  loss_mask: 3.358  loss_ce_0: 1.189  loss_mask_0: 3.953  loss_ce_1: 1.223  loss_mask_1: 3.614  loss_ce_2: 1.319  loss_mask_2: 3.597  loss_ce_3: 1.481  loss_mask_3: 3.497  loss_ce_4: 1.831  loss_mask_4: 3.438  loss_ce_5: 1.945  loss_mask_5: 3.503  loss_ce_6: 1.921  loss_mask_6: 3.372  loss_ce_7: 1.816  loss_mask_7: 3.25  loss_ce_8: 1.822  loss_mask_8: 3.33  time: 2.4429  data_time: 0.3846  lr: 8.1868e-05  max_mem: 18490M
[01/24 10:28:12] d2.utils.events INFO:  eta: 1 day, 8:06:50  iter: 11979  total_loss: 51.99  loss_ce: 1.783  loss_mask: 3.46  loss_ce_0: 1.172  loss_mask_0: 4.031  loss_ce_1: 1.148  loss_mask_1: 3.889  loss_ce_2: 1.228  loss_mask_2: 3.681  loss_ce_3: 1.43  loss_mask_3: 3.628  loss_ce_4: 1.79  loss_mask_4: 3.376  loss_ce_5: 1.942  loss_mask_5: 3.452  loss_ce_6: 1.947  loss_mask_6: 3.55  loss_ce_7: 1.834  loss_mask_7: 3.321  loss_ce_8: 1.808  loss_mask_8: 3.362  time: 2.4430  data_time: 0.4005  lr: 8.1837e-05  max_mem: 18490M
[01/24 10:28:59] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 10:29:00] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 10:29:00] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 10:33:16] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 10.76420661935516, 'error_1pix': 0.8901835852986524, 'error_3pix': 0.7495259341604583, 'mIoU': 0.484821528684681, 'fwIoU': 0.8752840684350616, 'IoU-0': nan, 'IoU-1': 0.0031759817193162732, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0001243395912098072, 'IoU-12': 0.0, 'IoU-13': 0.0037323724027079103, 'IoU-14': 0.0011616300607993758, 'IoU-15': 3.9427026291781844, 'IoU-16': 0.8140506451602032, 'IoU-17': 0.0, 'IoU-18': 0.3338979052638925, 'IoU-19': 0.0, 'IoU-20': 0.032514301655645866, 'IoU-21': 0.0, 'IoU-22': 1.1648610883989903, 'IoU-23': 3.4699019107525255, 'IoU-24': 3.5555798055994794, 'IoU-25': 9.321767753935908e-06, 'IoU-26': 1.3062711842909434, 'IoU-27': 1.3383937174134384, 'IoU-28': 0.09984156659217527, 'IoU-29': 0.03355756369119313, 'IoU-30': 0.44019665420322274, 'IoU-31': 4.698852363982589, 'IoU-32': 0.29953015141421674, 'IoU-33': 4.0421179148577595, 'IoU-34': 0.2122954493000621, 'IoU-35': 5.389849800149907, 'IoU-36': 0.009541709189451512, 'IoU-37': 2.464360127967746, 'IoU-38': 0.7699683845038977, 'IoU-39': 0.0, 'IoU-40': 1.8734017458676409, 'IoU-41': 5.327316045771841, 'IoU-42': 3.8862299948212686, 'IoU-43': 1.2017424769548934, 'IoU-44': 0.03673487800975415, 'IoU-45': 3.1644183861003023, 'IoU-46': 1.833160840905215, 'IoU-47': 0.0023112008539951, 'IoU-48': 0.4374675702494329, 'IoU-49': 0.028537361553950414, 'IoU-50': 0.0252883083329511, 'IoU-51': 0.002190494549863669, 'IoU-52': 0.0948979874887118, 'IoU-53': 0.0, 'IoU-54': 0.7587867387284748, 'IoU-55': 0.4769059613655659, 'IoU-56': 0.046932367166172766, 'IoU-57': 0.148228026653547, 'IoU-58': 0.0008864507184994717, 'IoU-59': 0.0, 'IoU-60': 1.173094110393676, 'IoU-61': 0.0, 'IoU-62': 0.08120407791591502, 'IoU-63': 0.016635925214026893, 'IoU-64': 0.015666523780253648, 'IoU-65': 0.027146223364741158, 'IoU-66': 0.0, 'IoU-67': 0.33994976245625963, 'IoU-68': 0.001118739530946288, 'IoU-69': 0.025186223146231708, 'IoU-70': 0.00979443019628491, 'IoU-71': 1.5802750227886224, 'IoU-72': 0.14932545187043286, 'IoU-73': 0.4385517787783769, 'IoU-74': 0.0, 'IoU-75': 1.762271805796833, 'IoU-76': 0.0025949542938333648, 'IoU-77': 1.034534400208775, 'IoU-78': 0.09353688494210709, 'IoU-79': 0.020851386481802424, 'IoU-80': 1.2444078658296978, 'IoU-81': 1.5425081965017429, 'IoU-82': 0.10372925337775905, 'IoU-83': 1.2972103743682775, 'IoU-84': 0.011618865755821987, 'IoU-85': 0.028548775916684425, 'IoU-86': 0.3892413670856675, 'IoU-87': 0.5049797696856521, 'IoU-88': 0.0, 'IoU-89': 0.020342456158163026, 'IoU-90': 0.6883570753437598, 'IoU-91': 2.6528920376196967, 'IoU-92': 0.018530134666973327, 'IoU-93': 0.06398302476887799, 'IoU-94': 1.5204694723180288e-05, 'IoU-95': 1.713788444408364, 'IoU-96': 0.0, 'IoU-97': 0.10249053256725842, 'IoU-98': 0.0, 'IoU-99': 0.005462388421060763, 'IoU-100': 1.3981198690879675, 'IoU-101': 0.012110858157371583, 'IoU-102': 1.6778878802279324, 'IoU-103': 0.003482369459898426, 'IoU-104': 2.4283545871977146, 'IoU-105': 0.0, 'IoU-106': 0.05635676071372209, 'IoU-107': 1.0690274727861853, 'IoU-108': 0.0, 'IoU-109': 0.002799958112626635, 'IoU-110': 0.0, 'IoU-111': 0.6096009228797451, 'IoU-112': 0.0, 'IoU-113': 0.24258809800348463, 'IoU-114': 0.05267427942037445, 'IoU-115': 0.0, 'IoU-116': 0.00011745489340576907, 'IoU-117': 0.0, 'IoU-118': 2.0023038070379324, 'IoU-119': 0.002693336685041208, 'IoU-120': 0.6017392590823792, 'IoU-121': 0.05638534219350893, 'IoU-122': 0.0022573894231899734, 'IoU-123': 2.010375857176081, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.003798575704196406, 'IoU-127': 0.11227467848368496, 'IoU-128': 0.06506034007947695, 'IoU-129': 0.0, 'IoU-130': 6.447590438739186e-05, 'IoU-131': 0.11993404534722583, 'IoU-132': 1.5208188183335114, 'IoU-133': 0.0, 'IoU-134': 0.00013787008639628962, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.01233995239942464, 'IoU-139': 0.0, 'IoU-140': 0.034304366921464186, 'IoU-141': 0.0, 'IoU-142': 0.010068642973471643, 'IoU-143': 0.08052416733511551, 'IoU-144': 0.010488673577238324, 'IoU-145': 0.0009836270801477228, 'IoU-146': 0.36164372947063445, 'IoU-147': 0.0, 'IoU-148': 0.5950230842659993, 'IoU-149': 0.6181181209480525, 'IoU-150': 0.3617561235255539, 'IoU-151': 0.017387773375883053, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.004640021344098183, 'IoU-155': 0.12644328743172473, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.009376307610063158, 'IoU-160': 0.0, 'IoU-161': 0.6361917571922688, 'IoU-162': 0.0008887690696513507, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.5544303453338136, 'IoU-166': 0.5628087860406866, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0001771755384364613, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0016552119866773826, 'IoU-178': 0.8414471794144923, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.21393636632048296, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 1.9498193695254118, 'IoU-189': 1.0985475387718255, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.2663389162653815, 'pACC': 3.637214115641724, 'ACC-0': nan, 'ACC-1': 0.0031772967083401266, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.00012445308617816178, 'ACC-12': 0.0, 'ACC-13': 0.003821752878653837, 'ACC-14': 0.0011646859512112198, 'ACC-15': 21.510659734970123, 'ACC-16': 2.130041509021339, 'ACC-17': 0.0, 'ACC-18': 0.3755817818032635, 'ACC-19': 0.0, 'ACC-20': 0.03476074605570686, 'ACC-21': 0.0, 'ACC-22': 1.9500437864324796, 'ACC-23': 61.00040549804633, 'ACC-24': 19.617911123124667, 'ACC-25': 9.322159378783728e-06, 'ACC-26': 1.8478195918572144, 'ACC-27': 1.7671347857628412, 'ACC-28': 0.10119288173655089, 'ACC-29': 0.034039257678578544, 'ACC-30': 0.5081402807713997, 'ACC-31': 20.60852503432571, 'ACC-32': 0.3261526091694434, 'ACC-33': 9.28002740420746, 'ACC-34': 0.22501882164087847, 'ACC-35': 11.710412510719298, 'ACC-36': 0.009552562991562397, 'ACC-37': 5.049654834479573, 'ACC-38': 0.851322331837431, 'ACC-39': 0.0, 'ACC-40': 3.9883742087359813, 'ACC-41': 22.391867414713072, 'ACC-42': 8.035420776023287, 'ACC-43': 1.375055625625225, 'ACC-44': 0.03736757330683987, 'ACC-45': 5.658736083759319, 'ACC-46': 3.015779802922216, 'ACC-47': 0.0023131935400470672, 'ACC-48': 0.49424976760705075, 'ACC-49': 0.029021377976978402, 'ACC-50': 0.025341335688540717, 'ACC-51': 0.0021920906954397677, 'ACC-52': 0.09654721165966715, 'ACC-53': 0.0, 'ACC-54': 1.3579976374466498, 'ACC-55': 0.6531115153103172, 'ACC-56': 0.04829725015280037, 'ACC-57': 0.1550685731708692, 'ACC-58': 0.0008866066156923275, 'ACC-59': 0.0, 'ACC-60': 3.4100320580524506, 'ACC-61': 0.0, 'ACC-62': 0.0939259303915885, 'ACC-63': 0.0173112310323507, 'ACC-64': 0.01801997297669699, 'ACC-65': 0.03232623781645562, 'ACC-66': 0.0, 'ACC-67': 0.5193257441210831, 'ACC-68': 0.0011434389097806205, 'ACC-69': 0.025918757458792407, 'ACC-70': 0.010992693142042115, 'ACC-71': 33.83069804571017, 'ACC-72': 0.15576459289391836, 'ACC-73': 1.2182722383273175, 'ACC-74': 0.0, 'ACC-75': 39.40823749998635, 'ACC-76': 0.0027112222147381193, 'ACC-77': 2.2848745474952836, 'ACC-78': 0.10203486289127692, 'ACC-79': 0.02144098333138972, 'ACC-80': 2.596240215471661, 'ACC-81': 7.311840109382982, 'ACC-82': 0.1512605004197805, 'ACC-83': 3.972252219485215, 'ACC-84': 0.012044895476506614, 'ACC-85': 0.028769512001492404, 'ACC-86': 0.48329555486909365, 'ACC-87': 1.15134106367006, 'ACC-88': 0.0, 'ACC-89': 0.021359124529589945, 'ACC-90': 0.9260344823992614, 'ACC-91': 13.780314124669571, 'ACC-92': 0.018571187442578272, 'ACC-93': 0.06999207856437717, 'ACC-94': 1.520492590943703e-05, 'ACC-95': 3.2695824899502313, 'ACC-96': 0.0, 'ACC-97': 0.1111828475033253, 'ACC-98': 0.0, 'ACC-99': 0.005727368025627754, 'ACC-100': 3.41696894206449, 'ACC-101': 0.01212233759936448, 'ACC-102': 6.35444041685546, 'ACC-103': 0.0035420799093227543, 'ACC-104': 7.998524384545387, 'ACC-105': 0.0, 'ACC-106': 0.06657861192903071, 'ACC-107': 1.5992356696212942, 'ACC-108': 0.0, 'ACC-109': 0.002834937199053698, 'ACC-110': 0.0, 'ACC-111': 0.7041628941975586, 'ACC-112': 0.0, 'ACC-113': 0.35135355384826117, 'ACC-114': 0.05524787381327312, 'ACC-115': 0.0, 'ACC-116': 0.00011790765786656311, 'ACC-117': 0.0, 'ACC-118': 13.14440921746133, 'ACC-119': 0.002702080215754672, 'ACC-120': 0.814674060096213, 'ACC-121': 0.06449775552352874, 'ACC-122': 0.002264428656344646, 'ACC-123': 18.762742540001458, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.003813787010810663, 'ACC-127': 0.12101785831098318, 'ACC-128': 0.07909587981817096, 'ACC-129': 0.0, 'ACC-130': 6.449232928235516e-05, 'ACC-131': 0.17571457148306688, 'ACC-132': 14.430604564814537, 'ACC-133': 0.0, 'ACC-134': 0.00013787160706591985, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.01546754829047897, 'ACC-139': 0.0, 'ACC-140': 0.03486906294155746, 'ACC-141': 0.0, 'ACC-142': 0.010479791032966803, 'ACC-143': 0.13991066205509622, 'ACC-144': 0.01055956678700361, 'ACC-145': 0.0009839218229387955, 'ACC-146': 0.5459322382399305, 'ACC-147': 0.0, 'ACC-148': 2.348650398127087, 'ACC-149': 1.1086445269043037, 'ACC-150': 0.7934051066854699, 'ACC-151': 0.01779846805281562, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.00469667135159634, 'ACC-155': 0.13299216344601306, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.009498507174917136, 'ACC-160': 0.0, 'ACC-161': 4.420673056670327, 'ACC-162': 0.0008925888349037938, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 1.5546633547948556, 'ACC-166': 1.2327605744936248, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.00017746354898703806, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0016609180447672777, 'ACC-178': 12.797101085354571, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.7215992428505171, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 7.452786408942334, 'ACC-189': 12.236824202032754, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 10:33:16] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 10:33:16] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 10:33:16] d2.evaluation.testing INFO: copypaste: 10.7642,0.8902,0.7495,0.4848,0.8753,2.2663,3.6372
[01/24 10:33:16] d2.utils.events INFO:  eta: 1 day, 8:05:55  iter: 11999  total_loss: 52.33  loss_ce: 1.777  loss_mask: 3.408  loss_ce_0: 1.163  loss_mask_0: 3.83  loss_ce_1: 1.063  loss_mask_1: 3.734  loss_ce_2: 1.255  loss_mask_2: 3.738  loss_ce_3: 1.558  loss_mask_3: 3.909  loss_ce_4: 1.873  loss_mask_4: 3.585  loss_ce_5: 1.957  loss_mask_5: 3.69  loss_ce_6: 1.861  loss_mask_6: 3.364  loss_ce_7: 1.852  loss_mask_7: 3.554  loss_ce_8: 1.823  loss_mask_8: 3.53  time: 2.4429  data_time: 0.3589  lr: 8.1807e-05  max_mem: 18490M
[01/24 10:34:04] d2.utils.events INFO:  eta: 1 day, 8:06:53  iter: 12019  total_loss: 51.4  loss_ce: 1.761  loss_mask: 3.53  loss_ce_0: 1.175  loss_mask_0: 3.933  loss_ce_1: 1.13  loss_mask_1: 3.739  loss_ce_2: 1.192  loss_mask_2: 3.69  loss_ce_3: 1.494  loss_mask_3: 3.687  loss_ce_4: 1.75  loss_mask_4: 3.502  loss_ce_5: 1.872  loss_mask_5: 3.409  loss_ce_6: 1.913  loss_mask_6: 3.465  loss_ce_7: 1.823  loss_mask_7: 3.339  loss_ce_8: 1.816  loss_mask_8: 3.335  time: 2.4428  data_time: 0.3551  lr: 8.1776e-05  max_mem: 18490M
[01/24 10:34:56] d2.utils.events INFO:  eta: 1 day, 8:10:43  iter: 12039  total_loss: 51.54  loss_ce: 1.83  loss_mask: 3.477  loss_ce_0: 1.163  loss_mask_0: 3.776  loss_ce_1: 1.214  loss_mask_1: 3.767  loss_ce_2: 1.23  loss_mask_2: 3.701  loss_ce_3: 1.451  loss_mask_3: 3.567  loss_ce_4: 1.826  loss_mask_4: 3.329  loss_ce_5: 1.901  loss_mask_5: 3.341  loss_ce_6: 1.936  loss_mask_6: 3.485  loss_ce_7: 1.83  loss_mask_7: 3.31  loss_ce_8: 1.862  loss_mask_8: 3.447  time: 2.4430  data_time: 0.4472  lr: 8.1745e-05  max_mem: 18490M
[01/24 10:35:44] d2.utils.events INFO:  eta: 1 day, 8:10:35  iter: 12059  total_loss: 51.38  loss_ce: 1.781  loss_mask: 3.474  loss_ce_0: 1.098  loss_mask_0: 3.845  loss_ce_1: 1.192  loss_mask_1: 3.717  loss_ce_2: 1.191  loss_mask_2: 3.598  loss_ce_3: 1.437  loss_mask_3: 3.553  loss_ce_4: 1.844  loss_mask_4: 3.43  loss_ce_5: 1.91  loss_mask_5: 3.26  loss_ce_6: 1.882  loss_mask_6: 3.426  loss_ce_7: 1.835  loss_mask_7: 3.511  loss_ce_8: 1.839  loss_mask_8: 3.601  time: 2.4429  data_time: 0.3798  lr: 8.1715e-05  max_mem: 18490M
[01/24 10:36:32] d2.utils.events INFO:  eta: 1 day, 8:09:47  iter: 12079  total_loss: 52.18  loss_ce: 1.773  loss_mask: 3.509  loss_ce_0: 1.152  loss_mask_0: 3.891  loss_ce_1: 1.159  loss_mask_1: 3.759  loss_ce_2: 1.194  loss_mask_2: 3.733  loss_ce_3: 1.508  loss_mask_3: 3.609  loss_ce_4: 1.874  loss_mask_4: 3.617  loss_ce_5: 1.9  loss_mask_5: 3.321  loss_ce_6: 1.863  loss_mask_6: 3.47  loss_ce_7: 1.837  loss_mask_7: 3.535  loss_ce_8: 1.842  loss_mask_8: 3.497  time: 2.4429  data_time: 0.3849  lr: 8.1684e-05  max_mem: 18490M
[01/24 10:37:24] d2.utils.events INFO:  eta: 1 day, 8:12:43  iter: 12099  total_loss: 51.65  loss_ce: 1.838  loss_mask: 3.595  loss_ce_0: 1.163  loss_mask_0: 3.797  loss_ce_1: 1.131  loss_mask_1: 3.646  loss_ce_2: 1.237  loss_mask_2: 3.574  loss_ce_3: 1.569  loss_mask_3: 3.453  loss_ce_4: 1.879  loss_mask_4: 3.472  loss_ce_5: 1.929  loss_mask_5: 3.442  loss_ce_6: 1.904  loss_mask_6: 3.549  loss_ce_7: 1.837  loss_mask_7: 3.61  loss_ce_8: 1.861  loss_mask_8: 3.673  time: 2.4432  data_time: 0.4193  lr: 8.1653e-05  max_mem: 18490M
[01/24 10:38:12] d2.utils.events INFO:  eta: 1 day, 8:06:57  iter: 12119  total_loss: 53.52  loss_ce: 1.881  loss_mask: 3.657  loss_ce_0: 1.132  loss_mask_0: 4.134  loss_ce_1: 1.149  loss_mask_1: 3.872  loss_ce_2: 1.282  loss_mask_2: 3.777  loss_ce_3: 1.661  loss_mask_3: 3.677  loss_ce_4: 1.857  loss_mask_4: 3.522  loss_ce_5: 1.925  loss_mask_5: 3.43  loss_ce_6: 1.874  loss_mask_6: 3.592  loss_ce_7: 1.889  loss_mask_7: 3.761  loss_ce_8: 1.907  loss_mask_8: 3.651  time: 2.4431  data_time: 0.4027  lr: 8.1623e-05  max_mem: 18490M
[01/24 10:39:01] d2.utils.events INFO:  eta: 1 day, 8:09:45  iter: 12139  total_loss: 50.82  loss_ce: 1.847  loss_mask: 3.299  loss_ce_0: 1.225  loss_mask_0: 3.69  loss_ce_1: 1.128  loss_mask_1: 3.515  loss_ce_2: 1.256  loss_mask_2: 3.469  loss_ce_3: 1.587  loss_mask_3: 3.398  loss_ce_4: 1.806  loss_mask_4: 3.348  loss_ce_5: 1.872  loss_mask_5: 3.398  loss_ce_6: 1.883  loss_mask_6: 3.484  loss_ce_7: 1.836  loss_mask_7: 3.455  loss_ce_8: 1.933  loss_mask_8: 3.806  time: 2.4431  data_time: 0.4094  lr: 8.1592e-05  max_mem: 18490M
[01/24 10:39:50] d2.utils.events INFO:  eta: 1 day, 8:11:54  iter: 12159  total_loss: 50.45  loss_ce: 1.837  loss_mask: 3.394  loss_ce_0: 1.306  loss_mask_0: 3.805  loss_ce_1: 1.203  loss_mask_1: 3.49  loss_ce_2: 1.317  loss_mask_2: 3.362  loss_ce_3: 1.568  loss_mask_3: 3.3  loss_ce_4: 1.783  loss_mask_4: 3.222  loss_ce_5: 1.829  loss_mask_5: 3.345  loss_ce_6: 1.82  loss_mask_6: 3.351  loss_ce_7: 1.772  loss_mask_7: 3.287  loss_ce_8: 1.887  loss_mask_8: 3.44  time: 2.4431  data_time: 0.4109  lr: 8.1561e-05  max_mem: 18490M
[01/24 10:40:35] d2.utils.events INFO:  eta: 1 day, 8:02:46  iter: 12179  total_loss: 53.4  loss_ce: 1.924  loss_mask: 3.94  loss_ce_0: 1.209  loss_mask_0: 3.914  loss_ce_1: 1.165  loss_mask_1: 3.61  loss_ce_2: 1.331  loss_mask_2: 3.609  loss_ce_3: 1.576  loss_mask_3: 3.437  loss_ce_4: 1.791  loss_mask_4: 3.307  loss_ce_5: 1.873  loss_mask_5: 3.369  loss_ce_6: 1.84  loss_mask_6: 3.581  loss_ce_7: 1.86  loss_mask_7: 3.783  loss_ce_8: 2.005  loss_mask_8: 3.802  time: 2.4428  data_time: 0.3616  lr: 8.1531e-05  max_mem: 18490M
[01/24 10:41:24] d2.utils.events INFO:  eta: 1 day, 8:03:44  iter: 12199  total_loss: 53.57  loss_ce: 1.985  loss_mask: 3.605  loss_ce_0: 1.231  loss_mask_0: 3.974  loss_ce_1: 1.232  loss_mask_1: 3.626  loss_ce_2: 1.435  loss_mask_2: 3.679  loss_ce_3: 1.652  loss_mask_3: 3.52  loss_ce_4: 1.808  loss_mask_4: 3.372  loss_ce_5: 1.898  loss_mask_5: 3.428  loss_ce_6: 1.892  loss_mask_6: 3.553  loss_ce_7: 1.835  loss_mask_7: 3.549  loss_ce_8: 1.938  loss_mask_8: 3.675  time: 2.4428  data_time: 0.4158  lr: 8.15e-05  max_mem: 18490M
[01/24 10:42:13] d2.utils.events INFO:  eta: 1 day, 8:05:49  iter: 12219  total_loss: 52.97  loss_ce: 2.007  loss_mask: 3.682  loss_ce_0: 1.295  loss_mask_0: 3.837  loss_ce_1: 1.242  loss_mask_1: 3.56  loss_ce_2: 1.376  loss_mask_2: 3.589  loss_ce_3: 1.632  loss_mask_3: 3.44  loss_ce_4: 1.812  loss_mask_4: 3.38  loss_ce_5: 1.942  loss_mask_5: 3.452  loss_ce_6: 1.867  loss_mask_6: 3.534  loss_ce_7: 1.824  loss_mask_7: 3.4  loss_ce_8: 1.975  loss_mask_8: 3.798  time: 2.4428  data_time: 0.3751  lr: 8.1469e-05  max_mem: 18490M
[01/24 10:43:00] d2.utils.events INFO:  eta: 1 day, 8:02:07  iter: 12239  total_loss: 53.97  loss_ce: 1.905  loss_mask: 3.495  loss_ce_0: 1.273  loss_mask_0: 4.106  loss_ce_1: 1.188  loss_mask_1: 3.77  loss_ce_2: 1.343  loss_mask_2: 3.746  loss_ce_3: 1.601  loss_mask_3: 3.519  loss_ce_4: 1.817  loss_mask_4: 3.59  loss_ce_5: 1.939  loss_mask_5: 3.496  loss_ce_6: 1.865  loss_mask_6: 3.597  loss_ce_7: 1.815  loss_mask_7: 3.545  loss_ce_8: 1.918  loss_mask_8: 3.981  time: 2.4427  data_time: 0.3517  lr: 8.1439e-05  max_mem: 18490M
[01/24 10:43:50] d2.utils.events INFO:  eta: 1 day, 8:04:05  iter: 12259  total_loss: 53.71  loss_ce: 1.939  loss_mask: 3.755  loss_ce_0: 1.262  loss_mask_0: 4.114  loss_ce_1: 1.169  loss_mask_1: 3.867  loss_ce_2: 1.372  loss_mask_2: 3.787  loss_ce_3: 1.606  loss_mask_3: 3.551  loss_ce_4: 1.805  loss_mask_4: 3.461  loss_ce_5: 1.925  loss_mask_5: 3.421  loss_ce_6: 1.872  loss_mask_6: 3.581  loss_ce_7: 1.857  loss_mask_7: 3.473  loss_ce_8: 1.961  loss_mask_8: 3.696  time: 2.4427  data_time: 0.3991  lr: 8.1408e-05  max_mem: 18490M
[01/24 10:44:37] d2.utils.events INFO:  eta: 1 day, 8:01:58  iter: 12279  total_loss: 52.8  loss_ce: 1.906  loss_mask: 3.416  loss_ce_0: 1.269  loss_mask_0: 4.091  loss_ce_1: 1.151  loss_mask_1: 3.767  loss_ce_2: 1.296  loss_mask_2: 3.643  loss_ce_3: 1.588  loss_mask_3: 3.5  loss_ce_4: 1.836  loss_mask_4: 3.377  loss_ce_5: 1.941  loss_mask_5: 3.49  loss_ce_6: 1.852  loss_mask_6: 3.45  loss_ce_7: 1.984  loss_mask_7: 3.546  loss_ce_8: 1.955  loss_mask_8: 3.57  time: 2.4426  data_time: 0.3763  lr: 8.1377e-05  max_mem: 18490M
[01/24 10:45:24] d2.utils.events INFO:  eta: 1 day, 8:00:42  iter: 12299  total_loss: 52.87  loss_ce: 1.849  loss_mask: 3.356  loss_ce_0: 1.273  loss_mask_0: 4.083  loss_ce_1: 1.229  loss_mask_1: 3.602  loss_ce_2: 1.318  loss_mask_2: 3.679  loss_ce_3: 1.552  loss_mask_3: 3.497  loss_ce_4: 1.769  loss_mask_4: 3.382  loss_ce_5: 1.966  loss_mask_5: 3.366  loss_ce_6: 1.91  loss_mask_6: 3.574  loss_ce_7: 1.948  loss_mask_7: 3.478  loss_ce_8: 1.92  loss_mask_8: 3.74  time: 2.4424  data_time: 0.3881  lr: 8.1346e-05  max_mem: 18490M
[01/24 10:46:12] d2.utils.events INFO:  eta: 1 day, 7:59:26  iter: 12319  total_loss: 51.99  loss_ce: 1.848  loss_mask: 3.598  loss_ce_0: 1.293  loss_mask_0: 3.881  loss_ce_1: 1.18  loss_mask_1: 3.589  loss_ce_2: 1.342  loss_mask_2: 3.603  loss_ce_3: 1.588  loss_mask_3: 3.447  loss_ce_4: 1.775  loss_mask_4: 3.389  loss_ce_5: 2.018  loss_mask_5: 3.187  loss_ce_6: 1.957  loss_mask_6: 3.516  loss_ce_7: 1.999  loss_mask_7: 3.436  loss_ce_8: 1.954  loss_mask_8: 3.494  time: 2.4424  data_time: 0.3886  lr: 8.1316e-05  max_mem: 18490M
[01/24 10:46:58] d2.utils.events INFO:  eta: 1 day, 7:53:51  iter: 12339  total_loss: 53.1  loss_ce: 1.82  loss_mask: 3.61  loss_ce_0: 1.315  loss_mask_0: 3.822  loss_ce_1: 1.202  loss_mask_1: 3.71  loss_ce_2: 1.339  loss_mask_2: 3.589  loss_ce_3: 1.625  loss_mask_3: 3.472  loss_ce_4: 1.785  loss_mask_4: 3.517  loss_ce_5: 2.021  loss_mask_5: 3.336  loss_ce_6: 2  loss_mask_6: 3.638  loss_ce_7: 2.064  loss_mask_7: 3.691  loss_ce_8: 1.924  loss_mask_8: 3.486  time: 2.4422  data_time: 0.3709  lr: 8.1285e-05  max_mem: 18490M
[01/24 10:47:44] d2.utils.events INFO:  eta: 1 day, 7:51:35  iter: 12359  total_loss: 51.9  loss_ce: 1.902  loss_mask: 3.456  loss_ce_0: 1.264  loss_mask_0: 3.908  loss_ce_1: 1.163  loss_mask_1: 3.615  loss_ce_2: 1.288  loss_mask_2: 3.494  loss_ce_3: 1.584  loss_mask_3: 3.34  loss_ce_4: 1.788  loss_mask_4: 3.416  loss_ce_5: 2.004  loss_mask_5: 3.352  loss_ce_6: 1.943  loss_mask_6: 3.652  loss_ce_7: 1.912  loss_mask_7: 3.555  loss_ce_8: 1.894  loss_mask_8: 3.345  time: 2.4419  data_time: 0.3753  lr: 8.1254e-05  max_mem: 18490M
[01/24 10:48:31] d2.utils.events INFO:  eta: 1 day, 7:50:29  iter: 12379  total_loss: 54.34  loss_ce: 1.837  loss_mask: 3.475  loss_ce_0: 1.213  loss_mask_0: 4.23  loss_ce_1: 1.13  loss_mask_1: 3.831  loss_ce_2: 1.275  loss_mask_2: 3.699  loss_ce_3: 1.542  loss_mask_3: 3.563  loss_ce_4: 1.783  loss_mask_4: 3.507  loss_ce_5: 2.048  loss_mask_5: 3.499  loss_ce_6: 2.014  loss_mask_6: 3.739  loss_ce_7: 2.001  loss_mask_7: 3.717  loss_ce_8: 1.931  loss_mask_8: 3.66  time: 2.4417  data_time: 0.3523  lr: 8.1224e-05  max_mem: 18490M
[01/24 10:49:19] d2.utils.events INFO:  eta: 1 day, 7:45:13  iter: 12399  total_loss: 54.56  loss_ce: 1.994  loss_mask: 3.953  loss_ce_0: 1.277  loss_mask_0: 4.15  loss_ce_1: 1.178  loss_mask_1: 3.989  loss_ce_2: 1.335  loss_mask_2: 3.692  loss_ce_3: 1.589  loss_mask_3: 3.481  loss_ce_4: 1.848  loss_mask_4: 3.501  loss_ce_5: 2.122  loss_mask_5: 3.636  loss_ce_6: 2.077  loss_mask_6: 3.636  loss_ce_7: 2.095  loss_mask_7: 3.487  loss_ce_8: 1.953  loss_mask_8: 3.689  time: 2.4416  data_time: 0.4098  lr: 8.1193e-05  max_mem: 18490M
[01/24 10:50:06] d2.utils.events INFO:  eta: 1 day, 7:44:38  iter: 12419  total_loss: 54.65  loss_ce: 2.035  loss_mask: 4.163  loss_ce_0: 1.315  loss_mask_0: 3.725  loss_ce_1: 1.223  loss_mask_1: 3.734  loss_ce_2: 1.445  loss_mask_2: 3.568  loss_ce_3: 1.635  loss_mask_3: 3.344  loss_ce_4: 1.896  loss_mask_4: 3.322  loss_ce_5: 2.065  loss_mask_5: 3.555  loss_ce_6: 2.099  loss_mask_6: 3.651  loss_ce_7: 2.031  loss_mask_7: 3.451  loss_ce_8: 1.956  loss_mask_8: 3.632  time: 2.4415  data_time: 0.3839  lr: 8.1162e-05  max_mem: 18490M
[01/24 10:50:54] d2.utils.events INFO:  eta: 1 day, 7:45:36  iter: 12439  total_loss: 55.57  loss_ce: 1.994  loss_mask: 3.81  loss_ce_0: 1.303  loss_mask_0: 4.038  loss_ce_1: 1.214  loss_mask_1: 3.903  loss_ce_2: 1.411  loss_mask_2: 3.756  loss_ce_3: 1.63  loss_mask_3: 3.433  loss_ce_4: 1.899  loss_mask_4: 3.434  loss_ce_5: 2.031  loss_mask_5: 4.014  loss_ce_6: 2.166  loss_mask_6: 4.156  loss_ce_7: 2  loss_mask_7: 3.577  loss_ce_8: 1.925  loss_mask_8: 3.525  time: 2.4415  data_time: 0.3718  lr: 8.1132e-05  max_mem: 18490M
[01/24 10:51:43] d2.utils.events INFO:  eta: 1 day, 7:42:20  iter: 12459  total_loss: 52.11  loss_ce: 1.894  loss_mask: 3.365  loss_ce_0: 1.277  loss_mask_0: 3.948  loss_ce_1: 1.139  loss_mask_1: 3.769  loss_ce_2: 1.368  loss_mask_2: 3.53  loss_ce_3: 1.575  loss_mask_3: 3.395  loss_ce_4: 1.844  loss_mask_4: 3.242  loss_ce_5: 1.959  loss_mask_5: 3.409  loss_ce_6: 2.061  loss_mask_6: 3.518  loss_ce_7: 1.996  loss_mask_7: 3.381  loss_ce_8: 1.913  loss_mask_8: 3.379  time: 2.4414  data_time: 0.3535  lr: 8.1101e-05  max_mem: 18490M
[01/24 10:52:33] d2.utils.events INFO:  eta: 1 day, 7:42:52  iter: 12479  total_loss: 51.56  loss_ce: 1.927  loss_mask: 3.376  loss_ce_0: 1.285  loss_mask_0: 3.828  loss_ce_1: 1.154  loss_mask_1: 3.548  loss_ce_2: 1.323  loss_mask_2: 3.392  loss_ce_3: 1.565  loss_mask_3: 3.369  loss_ce_4: 1.815  loss_mask_4: 3.382  loss_ce_5: 1.984  loss_mask_5: 3.376  loss_ce_6: 2.07  loss_mask_6: 3.428  loss_ce_7: 1.988  loss_mask_7: 3.243  loss_ce_8: 1.905  loss_mask_8: 3.324  time: 2.4416  data_time: 0.4144  lr: 8.107e-05  max_mem: 18490M
[01/24 10:53:21] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 10:53:22] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 10:53:22] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 10:57:36] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 12.283690751889417, 'error_1pix': 0.868382770731082, 'error_3pix': 0.7288148743220745, 'mIoU': 0.4423425465157273, 'fwIoU': 2.157673502396826, 'IoU-0': nan, 'IoU-1': 12.497429134556794, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 2.5783072432119676, 'IoU-12': 0.0, 'IoU-13': 4.813934178082243, 'IoU-14': 1.9132005891032846, 'IoU-15': 1.4751391380612984, 'IoU-16': 0.368210312460225, 'IoU-17': 0.0027623781100658937, 'IoU-18': 0.26806297375849114, 'IoU-19': 0.12714820383397638, 'IoU-20': 3.334643810081603, 'IoU-21': 0.3931181609957226, 'IoU-22': 0.0, 'IoU-23': 0.29996356368010996, 'IoU-24': 0.28461190065150954, 'IoU-25': 0.015075751843350905, 'IoU-26': 0.924555520259732, 'IoU-27': 0.05750348467492911, 'IoU-28': 2.881912898505512e-06, 'IoU-29': 5.234091830703144, 'IoU-30': 0.0005578662988522103, 'IoU-31': 0.3950431020359529, 'IoU-32': 2.917484817670542, 'IoU-33': 2.753011343680678, 'IoU-34': 0.5941604034065591, 'IoU-35': 0.0, 'IoU-36': 0.00018073535300161168, 'IoU-37': 0.10279134026881447, 'IoU-38': 6.447905545846794, 'IoU-39': 0.0, 'IoU-40': 0.04882162961753929, 'IoU-41': 1.7177233518995267, 'IoU-42': 0.03323162181565378, 'IoU-43': 5.757394460873212, 'IoU-44': 0.0, 'IoU-45': 0.015259888980634895, 'IoU-46': 0.05852323963798932, 'IoU-47': 3.949001142219824, 'IoU-48': 0.0, 'IoU-49': 0.033419081880273156, 'IoU-50': 0.16518169138520397, 'IoU-51': 6.230302596427736, 'IoU-52': 0.0, 'IoU-53': 0.07793248955585257, 'IoU-54': 4.173414953371805, 'IoU-55': 0.0, 'IoU-56': 0.00017160849340009624, 'IoU-57': 0.0, 'IoU-58': 0.4588117800312635, 'IoU-59': 0.015659689184903267, 'IoU-60': 0.002422655732518671, 'IoU-61': 0.0002169594172403296, 'IoU-62': 0.06361512864359259, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.17228184949632547, 'IoU-66': 0.007296757843864954, 'IoU-67': 2.115980487697531e-05, 'IoU-68': 2.1571980413504664e-05, 'IoU-69': 0.000497809532141655, 'IoU-70': 0.0003600096228454483, 'IoU-71': 6.61415979170688e-05, 'IoU-72': 1.7045206139344196, 'IoU-73': 0.0, 'IoU-74': 4.356982380145406e-05, 'IoU-75': 0.0015869656640413255, 'IoU-76': 0.20447593511341958, 'IoU-77': 0.09129930466019599, 'IoU-78': 1.1091503797176324e-05, 'IoU-79': 2.17822222230819, 'IoU-80': 0.016834516700830835, 'IoU-81': 0.09472170090583622, 'IoU-82': 0.008257836936650642, 'IoU-83': 0.07213934756636062, 'IoU-84': 0.00011341175680708705, 'IoU-85': 0.0034702962814449484, 'IoU-86': 0.0014208942018754383, 'IoU-87': 0.02620854043288838, 'IoU-88': 1.5055734385266126, 'IoU-89': 1.681985841551303, 'IoU-90': 0.009444196716010543, 'IoU-91': 0.0013867932147199125, 'IoU-92': 0.9373201733106163, 'IoU-93': 5.8927571238277465e-05, 'IoU-94': 0.003973990459098647, 'IoU-95': 0.0, 'IoU-96': 0.01739023893793068, 'IoU-97': 0.00041085161837020297, 'IoU-98': 0.0, 'IoU-99': 0.0011364490013695172, 'IoU-100': 0.002525684697967511, 'IoU-101': 0.21511365469257127, 'IoU-102': 0.0431726694198745, 'IoU-103': 0.2258352245455589, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 1.480292792699705, 'IoU-107': 0.02445929626539203, 'IoU-108': 0.23571459504624875, 'IoU-109': 0.0012188332987524816, 'IoU-110': 0.0, 'IoU-111': 0.0444612376725752, 'IoU-112': 0.0004972480634674168, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0003369245749415717, 'IoU-116': 0.0, 'IoU-117': 1.2304831485547063, 'IoU-118': 0.0, 'IoU-119': 0.00012863616931778666, 'IoU-120': 0.003231668252658811, 'IoU-121': 0.002357423481207255, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.00010642447294610079, 'IoU-125': 0.03984792083405089, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.001885829451667712, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0010585160927524726, 'IoU-132': 0.004544749744692, 'IoU-133': 0.18219427244345276, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0007948488016931725, 'IoU-137': 0.0, 'IoU-138': 0.0016009539477316141, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.006118771216629647, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0002674101858322518, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0011392560088634117, 'IoU-149': 0.0, 'IoU-150': 0.7448749273748586, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 1.0540069275800907, 'IoU-154': 0.0, 'IoU-155': 0.00036787788416261185, 'IoU-156': 0.009891069777001335, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.019827165150613914, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0034590799939557128, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.005401264336774343, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.1829437031705274, 'pACC': 5.332818564804155, 'ACC-0': nan, 'ACC-1': 13.909502392789364, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 3.357379022333891, 'ACC-12': 0.0, 'ACC-13': 12.789841323129329, 'ACC-14': 2.2327543516756383, 'ACC-15': 1.770483945088361, 'ACC-16': 0.4823418033791256, 'ACC-17': 0.0027627827535474333, 'ACC-18': 0.27512438531143746, 'ACC-19': 0.1354281996518433, 'ACC-20': 12.734919089275227, 'ACC-21': 0.41186828116782076, 'ACC-22': 0.0, 'ACC-23': 0.3428110475419028, 'ACC-24': 0.5122044632163016, 'ACC-25': 0.01783018350515368, 'ACC-26': 4.300118673562555, 'ACC-27': 0.0679975199809854, 'ACC-28': 2.881920705623299e-06, 'ACC-29': 21.226479993965302, 'ACC-30': 0.0005659247520750643, 'ACC-31': 0.6742219025532251, 'ACC-32': 18.347104744598514, 'ACC-33': 6.745818063267853, 'ACC-34': 2.454430089007701, 'ACC-35': 0.0, 'ACC-36': 0.00018085747488328117, 'ACC-37': 0.11927123001025529, 'ACC-38': 56.281157407101425, 'ACC-39': 0.0, 'ACC-40': 0.06109610556002097, 'ACC-41': 2.0980166797205366, 'ACC-42': 0.03403967515212242, 'ACC-43': 50.207377136587404, 'ACC-44': 0.0, 'ACC-45': 0.015329154716503915, 'ACC-46': 0.05866243073573923, 'ACC-47': 9.532828199456583, 'ACC-48': 0.0, 'ACC-49': 0.03359796574306011, 'ACC-50': 0.16980249016651627, 'ACC-51': 24.87060631619762, 'ACC-52': 0.0, 'ACC-53': 0.07886152515860598, 'ACC-54': 12.7826538303658, 'ACC-55': 0.0, 'ACC-56': 0.00017165009268469263, 'ACC-57': 0.0, 'ACC-58': 0.4769735793999169, 'ACC-59': 0.01588095522791665, 'ACC-60': 0.0024312715834556072, 'ACC-61': 0.00021702316338305055, 'ACC-62': 0.06486050347593415, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.24551322601114703, 'ACC-66': 0.007471287158666427, 'ACC-67': 2.1160693672931433e-05, 'ACC-68': 2.157431905246454e-05, 'ACC-69': 0.000497826563368714, 'ACC-70': 0.00036006894684916375, 'ACC-71': 6.615554160163669e-05, 'ACC-72': 48.92359060160524, 'ACC-73': 0.0, 'ACC-74': 4.357162254295536e-05, 'ACC-75': 0.0015943407455617812, 'ACC-76': 0.29539613286513916, 'ACC-77': 0.1001345096945881, 'ACC-78': 1.1091951613357637e-05, 'ACC-79': 11.288616464024313, 'ACC-80': 0.017106717720690758, 'ACC-81': 0.14768696877731943, 'ACC-82': 0.00838210895661533, 'ACC-83': 0.13908614492983312, 'ACC-84': 0.00011341709488235982, 'ACC-85': 0.0034833560387969482, 'ACC-86': 0.0014229921136591234, 'ACC-87': 0.0270874992292175, 'ACC-88': 3.40591766725998, 'ACC-89': 16.21017891053602, 'ACC-90': 0.009496520287381117, 'ACC-91': 0.0013879813335561362, 'ACC-92': 1.5120302474304999, 'ACC-93': 5.8928291782258195e-05, 'ACC-94': 0.003998895514181939, 'ACC-95': 0.0, 'ACC-96': 0.017585729180769807, 'ACC-97': 0.0004109005759285197, 'ACC-98': 0.0, 'ACC-99': 0.0011377599781550083, 'ACC-100': 0.0025341666484206666, 'ACC-101': 0.5976699319601562, 'ACC-102': 0.05061169007702764, 'ACC-103': 0.26898554831397, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 65.74180347535633, 'ACC-107': 0.029943344255446914, 'ACC-108': 0.5114377048369361, 'ACC-109': 0.0012190229955930901, 'ACC-110': 0.0, 'ACC-111': 0.047792443528918815, 'ACC-112': 0.0005004874748004557, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.00033827973478868793, 'ACC-116': 0.0, 'ACC-117': 5.492286191652195, 'ACC-118': 0.0, 'ACC-119': 0.0001286704864645082, 'ACC-120': 0.0032504383699315125, 'ACC-121': 0.0023618896388897847, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.00010654727689133403, 'ACC-125': 0.040897882555639066, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0018904951999717035, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0010633256973256694, 'ACC-132': 0.004557442202585008, 'ACC-133': 0.20263052249824792, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0008007594111069698, 'ACC-137': 0.0, 'ACC-138': 0.002300302053455847, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.006143343561018549, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0002683423153469443, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0011406291139878198, 'ACC-149': 0.0, 'ACC-150': 1.183958040835556, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 2.816559482584877, 'ACC-154': 0.0, 'ACC-155': 0.00036976505128641265, 'ACC-156': 0.009954300710375095, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.020649537064240206, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0035128004599919763, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.011606396308692243, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 10:57:36] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 10:57:36] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 10:57:36] d2.evaluation.testing INFO: copypaste: 12.2837,0.8684,0.7288,0.4423,2.1577,2.1829,5.3328
[01/24 10:57:36] d2.utils.events INFO:  eta: 1 day, 7:43:45  iter: 12499  total_loss: 52.36  loss_ce: 1.986  loss_mask: 3.352  loss_ce_0: 1.274  loss_mask_0: 3.848  loss_ce_1: 1.229  loss_mask_1: 3.532  loss_ce_2: 1.393  loss_mask_2: 3.422  loss_ce_3: 1.618  loss_mask_3: 3.358  loss_ce_4: 1.911  loss_mask_4: 3.561  loss_ce_5: 2.013  loss_mask_5: 3.225  loss_ce_6: 2.127  loss_mask_6: 3.541  loss_ce_7: 1.995  loss_mask_7: 3.495  loss_ce_8: 1.935  loss_mask_8: 3.387  time: 2.4415  data_time: 0.3798  lr: 8.1039e-05  max_mem: 18490M
[01/24 10:58:25] d2.utils.events INFO:  eta: 1 day, 7:42:07  iter: 12519  total_loss: 52.96  loss_ce: 1.983  loss_mask: 3.351  loss_ce_0: 1.271  loss_mask_0: 4.142  loss_ce_1: 1.191  loss_mask_1: 3.721  loss_ce_2: 1.353  loss_mask_2: 3.606  loss_ce_3: 1.636  loss_mask_3: 3.451  loss_ce_4: 1.915  loss_mask_4: 3.707  loss_ce_5: 1.986  loss_mask_5: 3.328  loss_ce_6: 2.045  loss_mask_6: 3.481  loss_ce_7: 1.979  loss_mask_7: 3.473  loss_ce_8: 1.951  loss_mask_8: 3.359  time: 2.4415  data_time: 0.3979  lr: 8.1009e-05  max_mem: 18490M
[01/24 10:59:16] d2.utils.events INFO:  eta: 1 day, 7:42:09  iter: 12539  total_loss: 54.53  loss_ce: 2.008  loss_mask: 3.575  loss_ce_0: 1.271  loss_mask_0: 4.043  loss_ce_1: 1.208  loss_mask_1: 3.894  loss_ce_2: 1.32  loss_mask_2: 3.834  loss_ce_3: 1.61  loss_mask_3: 3.628  loss_ce_4: 1.924  loss_mask_4: 3.709  loss_ce_5: 1.98  loss_mask_5: 3.413  loss_ce_6: 1.995  loss_mask_6: 3.509  loss_ce_7: 1.996  loss_mask_7: 3.69  loss_ce_8: 1.956  loss_mask_8: 3.521  time: 2.4416  data_time: 0.4389  lr: 8.0978e-05  max_mem: 18490M
[01/24 11:00:06] d2.utils.events INFO:  eta: 1 day, 7:42:00  iter: 12559  total_loss: 54.49  loss_ce: 2.008  loss_mask: 3.542  loss_ce_0: 1.339  loss_mask_0: 4.346  loss_ce_1: 1.25  loss_mask_1: 3.738  loss_ce_2: 1.417  loss_mask_2: 3.74  loss_ce_3: 1.689  loss_mask_3: 3.594  loss_ce_4: 1.962  loss_mask_4: 3.777  loss_ce_5: 1.976  loss_mask_5: 3.531  loss_ce_6: 1.996  loss_mask_6: 3.695  loss_ce_7: 1.973  loss_mask_7: 3.812  loss_ce_8: 2.005  loss_mask_8: 3.488  time: 2.4418  data_time: 0.4325  lr: 8.0947e-05  max_mem: 18490M
[01/24 11:00:54] d2.utils.events INFO:  eta: 1 day, 7:38:00  iter: 12579  total_loss: 52.34  loss_ce: 1.972  loss_mask: 3.298  loss_ce_0: 1.327  loss_mask_0: 4.17  loss_ce_1: 1.209  loss_mask_1: 3.629  loss_ce_2: 1.309  loss_mask_2: 3.542  loss_ce_3: 1.591  loss_mask_3: 3.269  loss_ce_4: 1.914  loss_mask_4: 3.504  loss_ce_5: 1.955  loss_mask_5: 3.403  loss_ce_6: 2.001  loss_mask_6: 3.717  loss_ce_7: 1.932  loss_mask_7: 3.406  loss_ce_8: 1.978  loss_mask_8: 3.312  time: 2.4417  data_time: 0.3888  lr: 8.0917e-05  max_mem: 18490M
[01/24 11:01:45] d2.utils.events INFO:  eta: 1 day, 7:38:55  iter: 12599  total_loss: 51.94  loss_ce: 1.929  loss_mask: 3.257  loss_ce_0: 1.265  loss_mask_0: 4.007  loss_ce_1: 1.213  loss_mask_1: 3.648  loss_ce_2: 1.327  loss_mask_2: 3.487  loss_ce_3: 1.585  loss_mask_3: 3.263  loss_ce_4: 1.897  loss_mask_4: 3.331  loss_ce_5: 1.942  loss_mask_5: 3.428  loss_ce_6: 1.958  loss_mask_6: 3.689  loss_ce_7: 1.945  loss_mask_7: 3.413  loss_ce_8: 1.935  loss_mask_8: 3.331  time: 2.4419  data_time: 0.4506  lr: 8.0886e-05  max_mem: 18490M
[01/24 11:02:33] d2.utils.events INFO:  eta: 1 day, 7:38:57  iter: 12619  total_loss: 51.27  loss_ce: 1.88  loss_mask: 3.211  loss_ce_0: 1.236  loss_mask_0: 3.923  loss_ce_1: 1.237  loss_mask_1: 3.548  loss_ce_2: 1.328  loss_mask_2: 3.547  loss_ce_3: 1.536  loss_mask_3: 3.31  loss_ce_4: 1.873  loss_mask_4: 3.426  loss_ce_5: 1.912  loss_mask_5: 3.336  loss_ce_6: 1.981  loss_mask_6: 3.592  loss_ce_7: 1.94  loss_mask_7: 3.536  loss_ce_8: 1.916  loss_mask_8: 3.249  time: 2.4418  data_time: 0.4123  lr: 8.0855e-05  max_mem: 18490M
[01/24 11:03:21] d2.utils.events INFO:  eta: 1 day, 7:35:08  iter: 12639  total_loss: 51.58  loss_ce: 1.941  loss_mask: 3.284  loss_ce_0: 1.253  loss_mask_0: 3.787  loss_ce_1: 1.222  loss_mask_1: 3.353  loss_ce_2: 1.33  loss_mask_2: 3.685  loss_ce_3: 1.576  loss_mask_3: 3.385  loss_ce_4: 1.943  loss_mask_4: 3.657  loss_ce_5: 1.997  loss_mask_5: 3.291  loss_ce_6: 1.972  loss_mask_6: 3.409  loss_ce_7: 1.944  loss_mask_7: 3.485  loss_ce_8: 1.927  loss_mask_8: 3.309  time: 2.4417  data_time: 0.4441  lr: 8.0824e-05  max_mem: 18490M
[01/24 11:04:15] d2.utils.events INFO:  eta: 1 day, 7:38:34  iter: 12659  total_loss: 54.89  loss_ce: 1.997  loss_mask: 3.36  loss_ce_0: 1.35  loss_mask_0: 4.269  loss_ce_1: 1.209  loss_mask_1: 3.898  loss_ce_2: 1.301  loss_mask_2: 3.889  loss_ce_3: 1.622  loss_mask_3: 3.86  loss_ce_4: 2.021  loss_mask_4: 4.092  loss_ce_5: 2.036  loss_mask_5: 3.358  loss_ce_6: 1.999  loss_mask_6: 3.658  loss_ce_7: 1.98  loss_mask_7: 3.635  loss_ce_8: 1.958  loss_mask_8: 3.647  time: 2.4421  data_time: 0.4668  lr: 8.0794e-05  max_mem: 18490M
[01/24 11:05:04] d2.utils.events INFO:  eta: 1 day, 7:39:06  iter: 12679  total_loss: 52.7  loss_ce: 1.9  loss_mask: 3.296  loss_ce_0: 1.313  loss_mask_0: 4.052  loss_ce_1: 1.241  loss_mask_1: 3.743  loss_ce_2: 1.292  loss_mask_2: 3.672  loss_ce_3: 1.648  loss_mask_3: 3.399  loss_ce_4: 1.986  loss_mask_4: 3.581  loss_ce_5: 2.08  loss_mask_5: 3.308  loss_ce_6: 2.039  loss_mask_6: 3.441  loss_ce_7: 1.97  loss_mask_7: 3.512  loss_ce_8: 1.973  loss_mask_8: 3.531  time: 2.4421  data_time: 0.3837  lr: 8.0763e-05  max_mem: 18490M
[01/24 11:05:55] d2.utils.events INFO:  eta: 1 day, 7:38:18  iter: 12699  total_loss: 53.03  loss_ce: 1.938  loss_mask: 3.286  loss_ce_0: 1.283  loss_mask_0: 4.142  loss_ce_1: 1.193  loss_mask_1: 3.823  loss_ce_2: 1.289  loss_mask_2: 3.592  loss_ce_3: 1.674  loss_mask_3: 3.491  loss_ce_4: 2.006  loss_mask_4: 3.612  loss_ce_5: 2.021  loss_mask_5: 3.148  loss_ce_6: 2.12  loss_mask_6: 3.546  loss_ce_7: 2.019  loss_mask_7: 3.321  loss_ce_8: 1.964  loss_mask_8: 3.312  time: 2.4423  data_time: 0.4245  lr: 8.0732e-05  max_mem: 18490M
[01/24 11:06:47] d2.utils.events INFO:  eta: 1 day, 7:39:32  iter: 12719  total_loss: 52.37  loss_ce: 1.942  loss_mask: 3.232  loss_ce_0: 1.283  loss_mask_0: 3.826  loss_ce_1: 1.229  loss_mask_1: 3.451  loss_ce_2: 1.429  loss_mask_2: 3.568  loss_ce_3: 1.719  loss_mask_3: 3.589  loss_ce_4: 1.922  loss_mask_4: 3.287  loss_ce_5: 1.952  loss_mask_5: 3.159  loss_ce_6: 2.111  loss_mask_6: 3.602  loss_ce_7: 2.026  loss_mask_7: 3.469  loss_ce_8: 1.977  loss_mask_8: 3.45  time: 2.4425  data_time: 0.4605  lr: 8.0702e-05  max_mem: 18490M
[01/24 11:07:36] d2.utils.events INFO:  eta: 1 day, 7:37:48  iter: 12739  total_loss: 55.78  loss_ce: 2.096  loss_mask: 3.858  loss_ce_0: 1.313  loss_mask_0: 4.164  loss_ce_1: 1.231  loss_mask_1: 4.127  loss_ce_2: 1.393  loss_mask_2: 3.673  loss_ce_3: 1.678  loss_mask_3: 3.574  loss_ce_4: 1.911  loss_mask_4: 3.677  loss_ce_5: 1.985  loss_mask_5: 3.489  loss_ce_6: 2.102  loss_mask_6: 3.769  loss_ce_7: 2.038  loss_mask_7: 3.879  loss_ce_8: 1.958  loss_mask_8: 3.754  time: 2.4425  data_time: 0.4055  lr: 8.0671e-05  max_mem: 18490M
[01/24 11:08:26] d2.utils.events INFO:  eta: 1 day, 7:37:50  iter: 12759  total_loss: 53.54  loss_ce: 1.99  loss_mask: 3.699  loss_ce_0: 1.335  loss_mask_0: 4.192  loss_ce_1: 1.236  loss_mask_1: 3.757  loss_ce_2: 1.375  loss_mask_2: 3.589  loss_ce_3: 1.609  loss_mask_3: 3.438  loss_ce_4: 1.858  loss_mask_4: 3.354  loss_ce_5: 1.993  loss_mask_5: 3.41  loss_ce_6: 2.075  loss_mask_6: 3.499  loss_ce_7: 1.973  loss_mask_7: 3.534  loss_ce_8: 1.949  loss_mask_8: 3.382  time: 2.4427  data_time: 0.4150  lr: 8.064e-05  max_mem: 18490M
[01/24 11:09:16] d2.utils.events INFO:  eta: 1 day, 7:41:43  iter: 12779  total_loss: 51.93  loss_ce: 1.949  loss_mask: 3.561  loss_ce_0: 1.243  loss_mask_0: 4.061  loss_ce_1: 1.198  loss_mask_1: 3.619  loss_ce_2: 1.319  loss_mask_2: 3.526  loss_ce_3: 1.538  loss_mask_3: 3.356  loss_ce_4: 1.84  loss_mask_4: 3.271  loss_ce_5: 1.986  loss_mask_5: 3.294  loss_ce_6: 2.022  loss_mask_6: 3.624  loss_ce_7: 1.955  loss_mask_7: 3.408  loss_ce_8: 1.927  loss_mask_8: 3.276  time: 2.4427  data_time: 0.4205  lr: 8.0609e-05  max_mem: 18490M
[01/24 11:10:02] d2.utils.events INFO:  eta: 1 day, 7:35:26  iter: 12799  total_loss: 52.45  loss_ce: 1.977  loss_mask: 3.642  loss_ce_0: 1.189  loss_mask_0: 3.955  loss_ce_1: 1.16  loss_mask_1: 3.754  loss_ce_2: 1.34  loss_mask_2: 3.475  loss_ce_3: 1.528  loss_mask_3: 3.499  loss_ce_4: 1.818  loss_mask_4: 3.304  loss_ce_5: 1.932  loss_mask_5: 3.3  loss_ce_6: 1.961  loss_mask_6: 3.558  loss_ce_7: 1.913  loss_mask_7: 3.421  loss_ce_8: 1.935  loss_mask_8: 3.314  time: 2.4425  data_time: 0.3300  lr: 8.0579e-05  max_mem: 18490M
[01/24 11:10:54] d2.utils.events INFO:  eta: 1 day, 7:40:06  iter: 12819  total_loss: 52.16  loss_ce: 1.962  loss_mask: 3.521  loss_ce_0: 1.265  loss_mask_0: 4.251  loss_ce_1: 1.235  loss_mask_1: 3.6  loss_ce_2: 1.388  loss_mask_2: 3.456  loss_ce_3: 1.52  loss_mask_3: 3.404  loss_ce_4: 1.81  loss_mask_4: 3.361  loss_ce_5: 1.89  loss_mask_5: 3.276  loss_ce_6: 1.948  loss_mask_6: 3.388  loss_ce_7: 1.944  loss_mask_7: 3.479  loss_ce_8: 1.967  loss_mask_8: 3.446  time: 2.4428  data_time: 0.4236  lr: 8.0548e-05  max_mem: 18490M
[01/24 11:11:40] d2.utils.events INFO:  eta: 1 day, 7:35:44  iter: 12839  total_loss: 50.75  loss_ce: 1.912  loss_mask: 3.354  loss_ce_0: 1.189  loss_mask_0: 3.979  loss_ce_1: 1.206  loss_mask_1: 3.66  loss_ce_2: 1.325  loss_mask_2: 3.45  loss_ce_3: 1.478  loss_mask_3: 3.405  loss_ce_4: 1.766  loss_mask_4: 3.296  loss_ce_5: 1.906  loss_mask_5: 3.209  loss_ce_6: 1.91  loss_mask_6: 3.285  loss_ce_7: 1.873  loss_mask_7: 3.245  loss_ce_8: 1.886  loss_mask_8: 3.181  time: 2.4425  data_time: 0.3757  lr: 8.0517e-05  max_mem: 18490M
[01/24 11:12:28] d2.utils.events INFO:  eta: 1 day, 7:33:07  iter: 12859  total_loss: 52.18  loss_ce: 1.909  loss_mask: 3.571  loss_ce_0: 1.261  loss_mask_0: 4.082  loss_ce_1: 1.233  loss_mask_1: 3.718  loss_ce_2: 1.356  loss_mask_2: 3.575  loss_ce_3: 1.538  loss_mask_3: 3.358  loss_ce_4: 1.779  loss_mask_4: 3.386  loss_ce_5: 1.892  loss_mask_5: 3.461  loss_ce_6: 1.943  loss_mask_6: 3.479  loss_ce_7: 1.891  loss_mask_7: 3.296  loss_ce_8: 1.906  loss_mask_8: 3.279  time: 2.4425  data_time: 0.3461  lr: 8.0486e-05  max_mem: 18490M
[01/24 11:13:19] d2.utils.events INFO:  eta: 1 day, 7:37:32  iter: 12879  total_loss: 52.59  loss_ce: 1.92  loss_mask: 3.668  loss_ce_0: 1.239  loss_mask_0: 4.246  loss_ce_1: 1.197  loss_mask_1: 3.9  loss_ce_2: 1.31  loss_mask_2: 3.685  loss_ce_3: 1.476  loss_mask_3: 3.54  loss_ce_4: 1.761  loss_mask_4: 3.366  loss_ce_5: 1.869  loss_mask_5: 3.354  loss_ce_6: 1.897  loss_mask_6: 3.455  loss_ce_7: 1.885  loss_mask_7: 3.401  loss_ce_8: 1.915  loss_mask_8: 3.498  time: 2.4426  data_time: 0.4038  lr: 8.0456e-05  max_mem: 18490M
[01/24 11:14:06] d2.utils.events INFO:  eta: 1 day, 7:36:07  iter: 12899  total_loss: 51.56  loss_ce: 1.923  loss_mask: 3.642  loss_ce_0: 1.28  loss_mask_0: 3.872  loss_ce_1: 1.274  loss_mask_1: 3.666  loss_ce_2: 1.338  loss_mask_2: 3.485  loss_ce_3: 1.477  loss_mask_3: 3.385  loss_ce_4: 1.779  loss_mask_4: 3.108  loss_ce_5: 1.882  loss_mask_5: 3.228  loss_ce_6: 1.895  loss_mask_6: 3.459  loss_ce_7: 1.923  loss_mask_7: 3.306  loss_ce_8: 1.98  loss_mask_8: 3.489  time: 2.4425  data_time: 0.3779  lr: 8.0425e-05  max_mem: 18490M
[01/24 11:14:54] d2.utils.events INFO:  eta: 1 day, 7:32:47  iter: 12919  total_loss: 51.13  loss_ce: 1.971  loss_mask: 3.357  loss_ce_0: 1.221  loss_mask_0: 3.89  loss_ce_1: 1.245  loss_mask_1: 3.426  loss_ce_2: 1.343  loss_mask_2: 3.408  loss_ce_3: 1.483  loss_mask_3: 3.577  loss_ce_4: 1.779  loss_mask_4: 3.209  loss_ce_5: 1.892  loss_mask_5: 3.267  loss_ce_6: 1.91  loss_mask_6: 3.606  loss_ce_7: 2.022  loss_mask_7: 3.203  loss_ce_8: 2.049  loss_mask_8: 3.435  time: 2.4424  data_time: 0.3606  lr: 8.0394e-05  max_mem: 18490M
[01/24 11:15:44] d2.utils.events INFO:  eta: 1 day, 7:36:53  iter: 12939  total_loss: 51.64  loss_ce: 1.958  loss_mask: 3.738  loss_ce_0: 1.166  loss_mask_0: 4.033  loss_ce_1: 1.239  loss_mask_1: 3.495  loss_ce_2: 1.379  loss_mask_2: 3.634  loss_ce_3: 1.524  loss_mask_3: 3.669  loss_ce_4: 1.784  loss_mask_4: 3.18  loss_ce_5: 1.863  loss_mask_5: 3.278  loss_ce_6: 1.901  loss_mask_6: 3.561  loss_ce_7: 1.893  loss_mask_7: 3.284  loss_ce_8: 1.922  loss_mask_8: 3.401  time: 2.4425  data_time: 0.3951  lr: 8.0364e-05  max_mem: 18490M
[01/24 11:16:32] d2.utils.events INFO:  eta: 1 day, 7:33:54  iter: 12959  total_loss: 50.82  loss_ce: 1.879  loss_mask: 3.546  loss_ce_0: 1.222  loss_mask_0: 3.951  loss_ce_1: 1.271  loss_mask_1: 3.581  loss_ce_2: 1.327  loss_mask_2: 3.611  loss_ce_3: 1.486  loss_mask_3: 3.409  loss_ce_4: 1.801  loss_mask_4: 3.179  loss_ce_5: 1.861  loss_mask_5: 3.219  loss_ce_6: 1.838  loss_mask_6: 3.36  loss_ce_7: 1.879  loss_mask_7: 3.167  loss_ce_8: 1.934  loss_mask_8: 3.393  time: 2.4424  data_time: 0.3695  lr: 8.0333e-05  max_mem: 18490M
[01/24 11:17:20] d2.utils.events INFO:  eta: 1 day, 7:30:07  iter: 12979  total_loss: 50.97  loss_ce: 1.87  loss_mask: 3.542  loss_ce_0: 1.201  loss_mask_0: 3.924  loss_ce_1: 1.201  loss_mask_1: 3.611  loss_ce_2: 1.286  loss_mask_2: 3.59  loss_ce_3: 1.431  loss_mask_3: 3.635  loss_ce_4: 1.737  loss_mask_4: 3.294  loss_ce_5: 1.874  loss_mask_5: 3.193  loss_ce_6: 1.858  loss_mask_6: 3.297  loss_ce_7: 1.871  loss_mask_7: 3.338  loss_ce_8: 1.873  loss_mask_8: 3.241  time: 2.4424  data_time: 0.3986  lr: 8.0302e-05  max_mem: 18490M
[01/24 11:18:09] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 11:18:09] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 11:18:09] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 11:22:10] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 13.779323076489465, 'error_1pix': 0.9441545267178688, 'error_3pix': 0.8684879445955366, 'mIoU': 0.16985025422427116, 'fwIoU': 0.5867627910124494, 'IoU-0': nan, 'IoU-1': 2.401415989742207, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 2.1335597751441354e-05, 'IoU-13': 2.6400641843698827, 'IoU-14': 0.1381485265990448, 'IoU-15': 0.08467482935298329, 'IoU-16': 0.0, 'IoU-17': 0.03857020449124626, 'IoU-18': 3.71529489216402, 'IoU-19': 0.0012567555799503144, 'IoU-20': 0.7323633731573551, 'IoU-21': 0.0, 'IoU-22': 0.7263648935781413, 'IoU-23': 0.0, 'IoU-24': 0.01213576223641877, 'IoU-25': 0.26059889475232817, 'IoU-26': 0.0, 'IoU-27': 7.59768683640537e-05, 'IoU-28': 0.005820476027115267, 'IoU-29': 0.6772960873567233, 'IoU-30': 0.0, 'IoU-31': 0.7364762912572913, 'IoU-32': 0.0312276455300948, 'IoU-33': 0.5314942555304488, 'IoU-34': 0.6654724774856626, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.8030655310188168, 'IoU-38': 2.8442316252802313, 'IoU-39': 0.00031455872752092116, 'IoU-40': 1.5085983772781573, 'IoU-41': 0.7269100429851653, 'IoU-42': 0.21037088192579204, 'IoU-43': 0.0016094957931803706, 'IoU-44': 0.0, 'IoU-45': 0.5390500481025273, 'IoU-46': 0.002366043689140241, 'IoU-47': 0.08423272392316929, 'IoU-48': 0.00010174227002044576, 'IoU-49': 0.09807910702465035, 'IoU-50': 0.002367003017952377, 'IoU-51': 1.327100003062679, 'IoU-52': 0.0, 'IoU-53': 0.0024924944760091176, 'IoU-54': 0.0005355211454708047, 'IoU-55': 0.03892486578700619, 'IoU-56': 0.0004956509173799485, 'IoU-57': 0.0, 'IoU-58': 0.40762969271203, 'IoU-59': 0.15189397461086812, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.7237496573049471, 'IoU-63': 0.007144434429358194, 'IoU-64': 0.0, 'IoU-65': 0.019708522242847196, 'IoU-66': 0.00083695606021511, 'IoU-67': 0.0925580950448898, 'IoU-68': 0.12599604385691066, 'IoU-69': 0.00034922959422378487, 'IoU-70': 0.0, 'IoU-71': 0.00022040338006215597, 'IoU-72': 1.5392887381031557, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.033973316895606336, 'IoU-77': 0.014585455907115009, 'IoU-78': 3.327551527689998e-05, 'IoU-79': 0.0, 'IoU-80': 0.5441595784970052, 'IoU-81': 1.1333256960218063, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.2479313155098963, 'IoU-85': 6.940609436406319e-05, 'IoU-86': 0.0005448896047738015, 'IoU-87': 1.3146900512508404, 'IoU-88': 0.0657661629920189, 'IoU-89': 0.20627301516176677, 'IoU-90': 0.0, 'IoU-91': 0.00014965308374464124, 'IoU-92': 2.9358147380847157, 'IoU-93': 0.0014875282538318211, 'IoU-94': 0.0, 'IoU-95': 0.00018882739759654195, 'IoU-96': 0.007653748622625985, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.05829434737524163, 'IoU-100': 0.003086938477316147, 'IoU-101': 0.0, 'IoU-102': 4.5296204336613305e-05, 'IoU-103': 1.3129837294452742, 'IoU-104': 0.0, 'IoU-105': 0.0004337347676176684, 'IoU-106': 0.0008362003682417372, 'IoU-107': 0.0, 'IoU-108': 0.0006145867625493273, 'IoU-109': 2.832648540548656e-05, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.00019860046254047728, 'IoU-113': 0.0, 'IoU-114': 3.63906845670018e-05, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0019130967815733707, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.064762824202647, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.00030481369406001933, 'IoU-138': 0.0004745510154205352, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0001010078563910701, 'IoU-150': 0.0012469255491927716, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0002464665933017774, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.3320849383193154, 'pACC': 1.9496711812229772, 'ACC-0': nan, 'ACC-1': 2.4442241848339754, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 2.1335634623331318e-05, 'ACC-13': 7.175506092131302, 'ACC-14': 0.14331846003682033, 'ACC-15': 0.08675866130815996, 'ACC-16': 0.0, 'ACC-17': 0.03973844198117151, 'ACC-18': 12.310739497707047, 'ACC-19': 0.0012819887176526883, 'ACC-20': 5.4486799722924, 'ACC-21': 0.0, 'ACC-22': 0.9424922036091249, 'ACC-23': 0.0, 'ACC-24': 0.012219694961616156, 'ACC-25': 0.3388729229646269, 'ACC-26': 0.0, 'ACC-27': 7.612609526419562e-05, 'ACC-28': 0.00584453519100405, 'ACC-29': 1.0479021230743637, 'ACC-30': 0.0, 'ACC-31': 7.015884382731798, 'ACC-32': 0.03334015276649101, 'ACC-33': 1.1139557817504648, 'ACC-34': 1.3242994064617435, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 1.227217905657023, 'ACC-38': 16.315149265032755, 'ACC-39': 0.00031500217782401906, 'ACC-40': 4.594700049757422, 'ACC-41': 2.2511551498304474, 'ACC-42': 0.2673222759713724, 'ACC-43': 0.0016164789397004934, 'ACC-44': 0.0, 'ACC-45': 0.5908289878970061, 'ACC-46': 0.002374480710945039, 'ACC-47': 0.10140989359267115, 'ACC-48': 0.00010175210038455215, 'ACC-49': 0.10852142935008414, 'ACC-50': 0.002368833274732574, 'ACC-51': 21.851192437005547, 'ACC-52': 0.0, 'ACC-53': 0.002503194974672836, 'ACC-54': 0.0005377587291685713, 'ACC-55': 0.040711846638473714, 'ACC-56': 0.0004958780455335566, 'ACC-57': 0.0, 'ACC-58': 1.299398188053142, 'ACC-59': 0.17588921064430516, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 2.9015042168966083, 'ACC-63': 0.007618048392499561, 'ACC-64': 0.0, 'ACC-65': 0.020208844510103678, 'ACC-66': 0.0008380924035713365, 'ACC-67': 0.19994739451552906, 'ACC-68': 0.33187774998406194, 'ACC-69': 0.00034953779981207575, 'ACC-70': 0.0, 'ACC-71': 0.0002205184720054556, 'ACC-72': 39.860968936617944, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.03572247082152998, 'ACC-77': 0.014835146481515887, 'ACC-78': 3.327585484007292e-05, 'ACC-79': 0.0, 'ACC-80': 0.708950152882305, 'ACC-81': 8.920419227560258, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.4523413995193157, 'ACC-85': 6.943566854744748e-05, 'ACC-86': 0.0005454803102359974, 'ACC-87': 4.2602739189714285, 'ACC-88': 0.06776895111209201, 'ACC-89': 0.5492511045050583, 'ACC-90': 0.0, 'ACC-91': 0.00014968426146193625, 'ACC-92': 38.6009667540195, 'ACC-93': 0.0014879393675020195, 'ACC-94': 0.0, 'ACC-95': 0.00018887584246495565, 'ACC-96': 0.008476454690352114, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.06242252625911462, 'ACC-100': 0.0031018199776668962, 'ACC-101': 0.0, 'ACC-102': 4.531037607612143e-05, 'ACC-103': 70.25108623783886, 'ACC-104': 0.0, 'ACC-105': 0.00043416622590281673, 'ACC-106': 0.0008391160227368975, 'ACC-107': 0.0, 'ACC-108': 0.0006356353188830395, 'ACC-109': 2.834937199053698e-05, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.00020019498992018226, 'ACC-113': 0.0, 'ACC-114': 3.6443188531182795e-05, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0019287534546787138, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.17319009986705286, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0003052929400244387, 'ACC-138': 0.0004759245627839683, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.00010141278145849835, 'ACC-150': 0.0012507700052845033, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.00024651003419094177, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 11:22:10] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 11:22:10] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 11:22:10] d2.evaluation.testing INFO: copypaste: 13.7793,0.9442,0.8685,0.1699,0.5868,1.3321,1.9497
[01/24 11:22:10] d2.utils.events INFO:  eta: 1 day, 7:34:28  iter: 12999  total_loss: 50.42  loss_ce: 1.839  loss_mask: 3.359  loss_ce_0: 1.252  loss_mask_0: 4.066  loss_ce_1: 1.214  loss_mask_1: 3.664  loss_ce_2: 1.266  loss_mask_2: 3.638  loss_ce_3: 1.433  loss_mask_3: 3.494  loss_ce_4: 1.749  loss_mask_4: 3.145  loss_ce_5: 1.869  loss_mask_5: 3.145  loss_ce_6: 1.858  loss_mask_6: 3.375  loss_ce_7: 1.9  loss_mask_7: 3.226  loss_ce_8: 1.86  loss_mask_8: 3.179  time: 2.4423  data_time: 0.3965  lr: 8.0271e-05  max_mem: 18490M
[01/24 11:23:00] d2.utils.events INFO:  eta: 1 day, 7:34:10  iter: 13019  total_loss: 49.21  loss_ce: 1.813  loss_mask: 3.27  loss_ce_0: 1.172  loss_mask_0: 4.039  loss_ce_1: 1.172  loss_mask_1: 3.493  loss_ce_2: 1.298  loss_mask_2: 3.55  loss_ce_3: 1.452  loss_mask_3: 3.321  loss_ce_4: 1.781  loss_mask_4: 3.017  loss_ce_5: 1.841  loss_mask_5: 2.975  loss_ce_6: 1.811  loss_mask_6: 3.103  loss_ce_7: 1.917  loss_mask_7: 3.056  loss_ce_8: 1.828  loss_mask_8: 3.183  time: 2.4424  data_time: 0.4202  lr: 8.0241e-05  max_mem: 18490M
[01/24 11:23:46] d2.utils.events INFO:  eta: 1 day, 7:27:42  iter: 13039  total_loss: 49.38  loss_ce: 1.818  loss_mask: 3.235  loss_ce_0: 1.214  loss_mask_0: 3.898  loss_ce_1: 1.171  loss_mask_1: 3.469  loss_ce_2: 1.268  loss_mask_2: 3.526  loss_ce_3: 1.444  loss_mask_3: 3.46  loss_ce_4: 1.728  loss_mask_4: 3.034  loss_ce_5: 1.812  loss_mask_5: 2.933  loss_ce_6: 1.821  loss_mask_6: 3.21  loss_ce_7: 1.893  loss_mask_7: 3.085  loss_ce_8: 1.842  loss_mask_8: 3.206  time: 2.4422  data_time: 0.3692  lr: 8.021e-05  max_mem: 18490M
[01/24 11:24:35] d2.utils.events INFO:  eta: 1 day, 7:27:16  iter: 13059  total_loss: 48.85  loss_ce: 1.745  loss_mask: 3.201  loss_ce_0: 1.163  loss_mask_0: 3.945  loss_ce_1: 1.108  loss_mask_1: 3.58  loss_ce_2: 1.197  loss_mask_2: 3.52  loss_ce_3: 1.441  loss_mask_3: 3.36  loss_ce_4: 1.748  loss_mask_4: 3.126  loss_ce_5: 1.794  loss_mask_5: 3.03  loss_ce_6: 1.779  loss_mask_6: 3.164  loss_ce_7: 1.833  loss_mask_7: 3.114  loss_ce_8: 1.784  loss_mask_8: 3.15  time: 2.4422  data_time: 0.3788  lr: 8.0179e-05  max_mem: 18490M
[01/24 11:25:23] d2.utils.events INFO:  eta: 1 day, 7:28:26  iter: 13079  total_loss: 48.43  loss_ce: 1.746  loss_mask: 3.113  loss_ce_0: 1.203  loss_mask_0: 3.722  loss_ce_1: 1.118  loss_mask_1: 3.611  loss_ce_2: 1.204  loss_mask_2: 3.383  loss_ce_3: 1.372  loss_mask_3: 3.319  loss_ce_4: 1.672  loss_mask_4: 3.001  loss_ce_5: 1.785  loss_mask_5: 2.949  loss_ce_6: 1.799  loss_mask_6: 3.127  loss_ce_7: 1.843  loss_mask_7: 3.137  loss_ce_8: 1.821  loss_mask_8: 3.099  time: 2.4421  data_time: 0.4249  lr: 8.0148e-05  max_mem: 18490M
[01/24 11:26:10] d2.utils.events INFO:  eta: 1 day, 7:23:45  iter: 13099  total_loss: 46.35  loss_ce: 1.735  loss_mask: 3.038  loss_ce_0: 1.187  loss_mask_0: 3.631  loss_ce_1: 1.106  loss_mask_1: 3.414  loss_ce_2: 1.225  loss_mask_2: 3.201  loss_ce_3: 1.389  loss_mask_3: 3.221  loss_ce_4: 1.681  loss_mask_4: 3.035  loss_ce_5: 1.765  loss_mask_5: 2.842  loss_ce_6: 1.764  loss_mask_6: 2.939  loss_ce_7: 1.774  loss_mask_7: 2.979  loss_ce_8: 1.773  loss_mask_8: 2.893  time: 2.4420  data_time: 0.3755  lr: 8.0118e-05  max_mem: 18490M
[01/24 11:26:59] d2.utils.events INFO:  eta: 1 day, 7:24:21  iter: 13119  total_loss: 46.33  loss_ce: 1.724  loss_mask: 2.925  loss_ce_0: 1.19  loss_mask_0: 3.687  loss_ce_1: 1.041  loss_mask_1: 3.438  loss_ce_2: 1.18  loss_mask_2: 3.26  loss_ce_3: 1.381  loss_mask_3: 3.12  loss_ce_4: 1.651  loss_mask_4: 3.069  loss_ce_5: 1.748  loss_mask_5: 2.851  loss_ce_6: 1.78  loss_mask_6: 2.987  loss_ce_7: 1.781  loss_mask_7: 2.891  loss_ce_8: 1.757  loss_mask_8: 2.894  time: 2.4420  data_time: 0.4537  lr: 8.0087e-05  max_mem: 18490M
[01/24 11:27:47] d2.utils.events INFO:  eta: 1 day, 7:22:23  iter: 13139  total_loss: 47.87  loss_ce: 1.732  loss_mask: 3.056  loss_ce_0: 1.226  loss_mask_0: 3.924  loss_ce_1: 1.12  loss_mask_1: 3.416  loss_ce_2: 1.24  loss_mask_2: 3.371  loss_ce_3: 1.347  loss_mask_3: 3.206  loss_ce_4: 1.677  loss_mask_4: 2.996  loss_ce_5: 1.77  loss_mask_5: 2.979  loss_ce_6: 1.808  loss_mask_6: 3.158  loss_ce_7: 1.807  loss_mask_7: 3.075  loss_ce_8: 1.763  loss_mask_8: 2.98  time: 2.4420  data_time: 0.3852  lr: 8.0056e-05  max_mem: 18490M
[01/24 11:28:34] d2.utils.events INFO:  eta: 1 day, 7:18:17  iter: 13159  total_loss: 47.67  loss_ce: 1.763  loss_mask: 3.144  loss_ce_0: 1.223  loss_mask_0: 3.787  loss_ce_1: 1.095  loss_mask_1: 3.519  loss_ce_2: 1.192  loss_mask_2: 3.42  loss_ce_3: 1.34  loss_mask_3: 3.174  loss_ce_4: 1.642  loss_mask_4: 3.039  loss_ce_5: 1.748  loss_mask_5: 3.006  loss_ce_6: 1.778  loss_mask_6: 3.114  loss_ce_7: 1.775  loss_mask_7: 3.135  loss_ce_8: 1.788  loss_mask_8: 3.101  time: 2.4418  data_time: 0.3327  lr: 8.0025e-05  max_mem: 18490M
[01/24 11:29:24] d2.utils.events INFO:  eta: 1 day, 7:21:54  iter: 13179  total_loss: 46.95  loss_ce: 1.708  loss_mask: 2.995  loss_ce_0: 1.197  loss_mask_0: 3.948  loss_ce_1: 1.112  loss_mask_1: 3.478  loss_ce_2: 1.208  loss_mask_2: 3.359  loss_ce_3: 1.329  loss_mask_3: 3.27  loss_ce_4: 1.611  loss_mask_4: 2.984  loss_ce_5: 1.729  loss_mask_5: 3.007  loss_ce_6: 1.768  loss_mask_6: 3.006  loss_ce_7: 1.77  loss_mask_7: 3.02  loss_ce_8: 1.767  loss_mask_8: 2.942  time: 2.4419  data_time: 0.4175  lr: 7.9995e-05  max_mem: 18490M
[01/24 11:30:10] d2.utils.events INFO:  eta: 1 day, 7:19:36  iter: 13199  total_loss: 45.99  loss_ce: 1.706  loss_mask: 2.958  loss_ce_0: 1.155  loss_mask_0: 3.744  loss_ce_1: 1.092  loss_mask_1: 3.478  loss_ce_2: 1.192  loss_mask_2: 3.339  loss_ce_3: 1.294  loss_mask_3: 3.14  loss_ce_4: 1.586  loss_mask_4: 2.897  loss_ce_5: 1.711  loss_mask_5: 2.868  loss_ce_6: 1.737  loss_mask_6: 2.881  loss_ce_7: 1.744  loss_mask_7: 2.965  loss_ce_8: 1.748  loss_mask_8: 2.837  time: 2.4417  data_time: 0.3928  lr: 7.9964e-05  max_mem: 18490M
[01/24 11:30:56] d2.utils.events INFO:  eta: 1 day, 7:14:04  iter: 13219  total_loss: 47.35  loss_ce: 1.698  loss_mask: 3.105  loss_ce_0: 1.143  loss_mask_0: 3.844  loss_ce_1: 1.049  loss_mask_1: 3.558  loss_ce_2: 1.195  loss_mask_2: 3.383  loss_ce_3: 1.254  loss_mask_3: 3.326  loss_ce_4: 1.567  loss_mask_4: 2.988  loss_ce_5: 1.72  loss_mask_5: 3.051  loss_ce_6: 1.744  loss_mask_6: 3.095  loss_ce_7: 1.747  loss_mask_7: 3.046  loss_ce_8: 1.727  loss_mask_8: 3.02  time: 2.4415  data_time: 0.3591  lr: 7.9933e-05  max_mem: 18490M
[01/24 11:31:49] d2.utils.events INFO:  eta: 1 day, 7:18:00  iter: 13239  total_loss: 48.08  loss_ce: 1.704  loss_mask: 3.03  loss_ce_0: 1.145  loss_mask_0: 3.973  loss_ce_1: 1.027  loss_mask_1: 3.716  loss_ce_2: 1.127  loss_mask_2: 3.471  loss_ce_3: 1.269  loss_mask_3: 3.268  loss_ce_4: 1.587  loss_mask_4: 3.127  loss_ce_5: 1.72  loss_mask_5: 3.071  loss_ce_6: 1.765  loss_mask_6: 3.13  loss_ce_7: 1.768  loss_mask_7: 3.027  loss_ce_8: 1.731  loss_mask_8: 3.082  time: 2.4417  data_time: 0.4489  lr: 7.9902e-05  max_mem: 18490M
[01/24 11:32:35] d2.utils.events INFO:  eta: 1 day, 7:13:50  iter: 13259  total_loss: 46.69  loss_ce: 1.675  loss_mask: 3.054  loss_ce_0: 1.178  loss_mask_0: 3.727  loss_ce_1: 1.055  loss_mask_1: 3.585  loss_ce_2: 1.158  loss_mask_2: 3.359  loss_ce_3: 1.262  loss_mask_3: 3.254  loss_ce_4: 1.547  loss_mask_4: 3.019  loss_ce_5: 1.69  loss_mask_5: 2.91  loss_ce_6: 1.75  loss_mask_6: 3.012  loss_ce_7: 1.738  loss_mask_7: 2.986  loss_ce_8: 1.694  loss_mask_8: 2.917  time: 2.4415  data_time: 0.3843  lr: 7.9872e-05  max_mem: 18490M
[01/24 11:33:23] d2.utils.events INFO:  eta: 1 day, 7:13:02  iter: 13279  total_loss: 45.8  loss_ce: 1.656  loss_mask: 2.959  loss_ce_0: 1.18  loss_mask_0: 3.846  loss_ce_1: 1.045  loss_mask_1: 3.488  loss_ce_2: 1.129  loss_mask_2: 3.276  loss_ce_3: 1.246  loss_mask_3: 3.253  loss_ce_4: 1.551  loss_mask_4: 3.006  loss_ce_5: 1.693  loss_mask_5: 2.862  loss_ce_6: 1.738  loss_mask_6: 3.011  loss_ce_7: 1.721  loss_mask_7: 2.859  loss_ce_8: 1.683  loss_mask_8: 2.844  time: 2.4414  data_time: 0.3754  lr: 7.9841e-05  max_mem: 18490M
[01/24 11:34:13] d2.utils.events INFO:  eta: 1 day, 7:15:35  iter: 13299  total_loss: 45.32  loss_ce: 1.655  loss_mask: 2.946  loss_ce_0: 1.167  loss_mask_0: 3.599  loss_ce_1: 1.03  loss_mask_1: 3.432  loss_ce_2: 1.1  loss_mask_2: 3.339  loss_ce_3: 1.223  loss_mask_3: 3.122  loss_ce_4: 1.507  loss_mask_4: 2.957  loss_ce_5: 1.699  loss_mask_5: 2.952  loss_ce_6: 1.753  loss_mask_6: 2.964  loss_ce_7: 1.743  loss_mask_7: 2.933  loss_ce_8: 1.72  loss_mask_8: 2.827  time: 2.4416  data_time: 0.4299  lr: 7.981e-05  max_mem: 18490M
[01/24 11:35:00] d2.utils.events INFO:  eta: 1 day, 7:14:55  iter: 13319  total_loss: 49.13  loss_ce: 1.672  loss_mask: 3.234  loss_ce_0: 1.107  loss_mask_0: 3.95  loss_ce_1: 1.037  loss_mask_1: 3.753  loss_ce_2: 1.197  loss_mask_2: 3.749  loss_ce_3: 1.278  loss_mask_3: 3.535  loss_ce_4: 1.542  loss_mask_4: 3.235  loss_ce_5: 1.703  loss_mask_5: 3.194  loss_ce_6: 1.74  loss_mask_6: 3.216  loss_ce_7: 1.735  loss_mask_7: 3.22  loss_ce_8: 1.745  loss_mask_8: 3.202  time: 2.4415  data_time: 0.3607  lr: 7.9779e-05  max_mem: 18490M
[01/24 11:35:47] d2.utils.events INFO:  eta: 1 day, 7:14:21  iter: 13339  total_loss: 46.17  loss_ce: 1.647  loss_mask: 2.946  loss_ce_0: 1.173  loss_mask_0: 3.675  loss_ce_1: 1.062  loss_mask_1: 3.456  loss_ce_2: 1.208  loss_mask_2: 3.335  loss_ce_3: 1.272  loss_mask_3: 3.163  loss_ce_4: 1.532  loss_mask_4: 2.952  loss_ce_5: 1.703  loss_mask_5: 2.899  loss_ce_6: 1.729  loss_mask_6: 2.863  loss_ce_7: 1.728  loss_mask_7: 2.978  loss_ce_8: 1.748  loss_mask_8: 2.915  time: 2.4413  data_time: 0.3932  lr: 7.9748e-05  max_mem: 18490M
[01/24 11:36:37] d2.utils.events INFO:  eta: 1 day, 7:17:10  iter: 13359  total_loss: 47.07  loss_ce: 1.679  loss_mask: 3.01  loss_ce_0: 1.16  loss_mask_0: 3.816  loss_ce_1: 1.082  loss_mask_1: 3.46  loss_ce_2: 1.261  loss_mask_2: 3.315  loss_ce_3: 1.322  loss_mask_3: 3.265  loss_ce_4: 1.548  loss_mask_4: 2.985  loss_ce_5: 1.716  loss_mask_5: 2.922  loss_ce_6: 1.747  loss_mask_6: 2.989  loss_ce_7: 1.734  loss_mask_7: 2.943  loss_ce_8: 1.722  loss_mask_8: 2.901  time: 2.4414  data_time: 0.4334  lr: 7.9718e-05  max_mem: 18490M
[01/24 11:37:24] d2.utils.events INFO:  eta: 1 day, 7:17:07  iter: 13379  total_loss: 47.24  loss_ce: 1.69  loss_mask: 3.103  loss_ce_0: 1.179  loss_mask_0: 3.849  loss_ce_1: 1.062  loss_mask_1: 3.517  loss_ce_2: 1.179  loss_mask_2: 3.377  loss_ce_3: 1.291  loss_mask_3: 3.391  loss_ce_4: 1.557  loss_mask_4: 3.078  loss_ce_5: 1.706  loss_mask_5: 3.101  loss_ce_6: 1.724  loss_mask_6: 3.061  loss_ce_7: 1.748  loss_mask_7: 3.152  loss_ce_8: 1.744  loss_mask_8: 3.1  time: 2.4412  data_time: 0.3778  lr: 7.9687e-05  max_mem: 18490M
[01/24 11:38:10] d2.utils.events INFO:  eta: 1 day, 7:15:05  iter: 13399  total_loss: 46.05  loss_ce: 1.722  loss_mask: 2.866  loss_ce_0: 1.156  loss_mask_0: 3.557  loss_ce_1: 1.058  loss_mask_1: 3.507  loss_ce_2: 1.222  loss_mask_2: 3.416  loss_ce_3: 1.334  loss_mask_3: 3.05  loss_ce_4: 1.544  loss_mask_4: 2.886  loss_ce_5: 1.717  loss_mask_5: 2.85  loss_ce_6: 1.745  loss_mask_6: 2.867  loss_ce_7: 1.743  loss_mask_7: 2.803  loss_ce_8: 1.768  loss_mask_8: 2.846  time: 2.4410  data_time: 0.3657  lr: 7.9656e-05  max_mem: 18490M
[01/24 11:38:59] d2.utils.events INFO:  eta: 1 day, 7:15:30  iter: 13419  total_loss: 49.94  loss_ce: 1.725  loss_mask: 3.182  loss_ce_0: 1.15  loss_mask_0: 3.892  loss_ce_1: 1.189  loss_mask_1: 3.756  loss_ce_2: 1.448  loss_mask_2: 3.834  loss_ce_3: 1.427  loss_mask_3: 3.485  loss_ce_4: 1.582  loss_mask_4: 3.287  loss_ce_5: 1.732  loss_mask_5: 3.088  loss_ce_6: 1.764  loss_mask_6: 3.115  loss_ce_7: 1.794  loss_mask_7: 3.214  loss_ce_8: 1.743  loss_mask_8: 3.156  time: 2.4410  data_time: 0.4115  lr: 7.9625e-05  max_mem: 18490M
[01/24 11:39:47] d2.utils.events INFO:  eta: 1 day, 7:14:42  iter: 13439  total_loss: 47.18  loss_ce: 1.716  loss_mask: 3.008  loss_ce_0: 1.133  loss_mask_0: 3.693  loss_ce_1: 1.113  loss_mask_1: 3.57  loss_ce_2: 1.331  loss_mask_2: 3.543  loss_ce_3: 1.382  loss_mask_3: 3.33  loss_ce_4: 1.587  loss_mask_4: 3.022  loss_ce_5: 1.732  loss_mask_5: 2.942  loss_ce_6: 1.753  loss_mask_6: 3.058  loss_ce_7: 1.782  loss_mask_7: 2.989  loss_ce_8: 1.722  loss_mask_8: 2.963  time: 2.4409  data_time: 0.3664  lr: 7.9595e-05  max_mem: 18490M
[01/24 11:40:34] d2.utils.events INFO:  eta: 1 day, 7:13:09  iter: 13459  total_loss: 45.74  loss_ce: 1.715  loss_mask: 2.851  loss_ce_0: 1.147  loss_mask_0: 3.7  loss_ce_1: 1.089  loss_mask_1: 3.36  loss_ce_2: 1.321  loss_mask_2: 3.292  loss_ce_3: 1.35  loss_mask_3: 3.153  loss_ce_4: 1.549  loss_mask_4: 2.908  loss_ce_5: 1.698  loss_mask_5: 2.806  loss_ce_6: 1.722  loss_mask_6: 2.874  loss_ce_7: 1.74  loss_mask_7: 2.837  loss_ce_8: 1.687  loss_mask_8: 2.794  time: 2.4408  data_time: 0.4152  lr: 7.9564e-05  max_mem: 18490M
[01/24 11:41:23] d2.utils.events INFO:  eta: 1 day, 7:10:23  iter: 13479  total_loss: 47.09  loss_ce: 1.704  loss_mask: 3.138  loss_ce_0: 1.169  loss_mask_0: 3.846  loss_ce_1: 1.026  loss_mask_1: 3.554  loss_ce_2: 1.2  loss_mask_2: 3.466  loss_ce_3: 1.286  loss_mask_3: 3.326  loss_ce_4: 1.496  loss_mask_4: 3.054  loss_ce_5: 1.693  loss_mask_5: 2.98  loss_ce_6: 1.701  loss_mask_6: 2.995  loss_ce_7: 1.746  loss_mask_7: 3.062  loss_ce_8: 1.712  loss_mask_8: 3.006  time: 2.4408  data_time: 0.3949  lr: 7.9533e-05  max_mem: 18490M
[01/24 11:42:10] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 11:42:10] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 11:42:10] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 11:46:32] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 9.869863152407508, 'error_1pix': 0.8482781538446671, 'error_3pix': 0.7248368090327768, 'mIoU': 0.6437429077527298, 'fwIoU': 6.1123462828230855, 'IoU-0': nan, 'IoU-1': 52.626322973442896, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 1.2467850090061515e-05, 'IoU-11': 0.00034353598232396464, 'IoU-12': 0.00033064927892325236, 'IoU-13': 0.8092482184363496, 'IoU-14': 0.10162000167593843, 'IoU-15': 1.9552542986632367e-05, 'IoU-16': 2.289350106328534, 'IoU-17': 0.06884962869640647, 'IoU-18': 0.06212509141042679, 'IoU-19': 0.0021664778376266863, 'IoU-20': 0.2747974365206295, 'IoU-21': 0.1337148998038137, 'IoU-22': 0.9357802829274284, 'IoU-23': 0.001031622840141782, 'IoU-24': 1.2750498638166, 'IoU-25': 0.006698920888305571, 'IoU-26': 0.2142545439073789, 'IoU-27': 1.3675516068623323, 'IoU-28': 3.5429275908519235, 'IoU-29': 1.8897575682836871, 'IoU-30': 0.03158704499367111, 'IoU-31': 0.0071006191180602455, 'IoU-32': 1.317823146395066, 'IoU-33': 3.837245355579747, 'IoU-34': 0.0069813445401704305, 'IoU-35': 1.0263192512238075, 'IoU-36': 0.00039703497565983926, 'IoU-37': 3.4880423932599776, 'IoU-38': 0.03322663469658696, 'IoU-39': 3.2321652187974816, 'IoU-40': 1.2136371073605179, 'IoU-41': 0.09368204706390454, 'IoU-42': 4.791063932020623, 'IoU-43': 4.132429219627031, 'IoU-44': 0.32385945804898353, 'IoU-45': 0.0, 'IoU-46': 0.1997180772100733, 'IoU-47': 0.009162196818443097, 'IoU-48': 1.4982164834423322, 'IoU-49': 2.723275157722242, 'IoU-50': 1.6108949055433759, 'IoU-51': 0.8366561259271383, 'IoU-52': 0.061070159141161366, 'IoU-53': 0.0, 'IoU-54': 0.029773466311840233, 'IoU-55': 0.9300186606480335, 'IoU-56': 0.0010930862738042573, 'IoU-57': 0.010702476378957668, 'IoU-58': 0.002069555188911282, 'IoU-59': 0.008125476756471305, 'IoU-60': 0.07934688269750412, 'IoU-61': 0.00044139645846800785, 'IoU-62': 0.0008320454874888824, 'IoU-63': 0.0, 'IoU-64': 1.7337321986094705, 'IoU-65': 0.029472677250170786, 'IoU-66': 4.088136126756749e-05, 'IoU-67': 0.00023273628366067515, 'IoU-68': 0.42938444532765, 'IoU-69': 0.02716296962474137, 'IoU-70': 0.44692612940352616, 'IoU-71': 0.00014283880926052567, 'IoU-72': 1.766095979531564, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0036982545323139596, 'IoU-76': 0.0, 'IoU-77': 0.03095977530776021, 'IoU-78': 0.31756148976881143, 'IoU-79': 0.08890573337576632, 'IoU-80': 0.0, 'IoU-81': 0.28783611060004977, 'IoU-82': 0.000584621749727926, 'IoU-83': 2.7254989769163394, 'IoU-84': 0.20550759262275795, 'IoU-85': 0.0016397770180400877, 'IoU-86': 2.4726703775285777, 'IoU-87': 1.2604124826398158, 'IoU-88': 0.004515268380027061, 'IoU-89': 0.7351962076492822, 'IoU-90': 0.0035538036764294297, 'IoU-91': 0.38664222705922785, 'IoU-92': 0.00019905873654576216, 'IoU-93': 1.0352536157302183, 'IoU-94': 0.00010640744596743902, 'IoU-95': 3.147814771246727e-05, 'IoU-96': 0.06723462621477617, 'IoU-97': 0.0001540732340896275, 'IoU-98': 0.32522567484971926, 'IoU-99': 0.05603917060551818, 'IoU-100': 0.5657612358590076, 'IoU-101': 0.03886100987743835, 'IoU-102': 1.0578312543530397, 'IoU-103': 1.4951995716961486, 'IoU-104': 0.00036882857585451433, 'IoU-105': 0.0, 'IoU-106': 0.4656295319453142, 'IoU-107': 0.0, 'IoU-108': 0.011429510669992472, 'IoU-109': 0.0005385287564435674, 'IoU-110': 0.5890196827745741, 'IoU-111': 0.00018801044836731727, 'IoU-112': 0.0007006022844305154, 'IoU-113': 0.0, 'IoU-114': 1.6618231619734778, 'IoU-115': 1.8575557087915264, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.5432080719535938, 'IoU-119': 0.0, 'IoU-120': 0.00021960636876037915, 'IoU-121': 0.004955504783366196, 'IoU-122': 0.0, 'IoU-123': 0.41322710932730733, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.12285076507274333, 'IoU-128': 1.02889347923119, 'IoU-129': 0.0, 'IoU-130': 0.007465661122253365, 'IoU-131': 0.001587879188858381, 'IoU-132': 0.0, 'IoU-133': 6.804225423988297e-05, 'IoU-134': 0.0015936350217232373, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.003166292912174159, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.00033653914917855, 'IoU-142': 0.500348167714159, 'IoU-143': 0.002506467581527334, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.989994809696734, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0012147851500613972, 'IoU-150': 1.247028482009469, 'IoU-151': 0.0, 'IoU-152': 0.04703688058754268, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0002457192632845048, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.3285384917534726, 'pACC': 8.94870849222182, 'ACC-0': nan, 'ACC-1': 57.61183250622349, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 1.2468345986626452e-05, 'ACC-11': 0.0003435987379266641, 'ACC-12': 0.0003307023366616354, 'ACC-13': 0.9798289827358644, 'ACC-14': 0.10554110046122847, 'ACC-15': 1.9557307629555062e-05, 'ACC-16': 11.49087757803389, 'ACC-17': 0.07391693993682166, 'ACC-18': 0.06299293914965651, 'ACC-19': 0.0021678912984834375, 'ACC-20': 0.3915225779497953, 'ACC-21': 0.14298629077183503, 'ACC-22': 3.3008417927373133, 'ACC-23': 0.001039347818692387, 'ACC-24': 3.8832344693804033, 'ACC-25': 0.0068269280517292835, 'ACC-26': 0.2346011359515514, 'ACC-27': 5.14722645849845, 'ACC-28': 14.47651884498036, 'ACC-29': 5.390474803825322, 'ACC-30': 0.032719746052339946, 'ACC-31': 0.007116593213226962, 'ACC-32': 2.790211047470888, 'ACC-33': 20.53872451090348, 'ACC-34': 0.007043716889347181, 'ACC-35': 1.3754802457591837, 'ACC-36': 0.0003973383917890268, 'ACC-37': 10.533231306376369, 'ACC-38': 0.03342863161004278, 'ACC-39': 9.097218319777788, 'ACC-40': 1.683442624962096, 'ACC-41': 0.09601205766520414, 'ACC-42': 65.79630232760464, 'ACC-43': 9.430326972549384, 'ACC-44': 0.33781390482429247, 'ACC-45': 0.0, 'ACC-46': 0.20455924987808666, 'ACC-47': 0.00918035373628256, 'ACC-48': 2.054901363283489, 'ACC-49': 4.497864100133198, 'ACC-50': 1.9793320945073114, 'ACC-51': 0.9243634188731367, 'ACC-52': 0.06147476728118787, 'ACC-53': 0.0, 'ACC-54': 0.029980049151147846, 'ACC-55': 1.2106862916703205, 'ACC-56': 0.0010934746645098938, 'ACC-57': 0.010755152981684751, 'ACC-58': 0.0020710576413437965, 'ACC-59': 0.008234569377438264, 'ACC-60': 0.08556023601647834, 'ACC-61': 0.0004423933715116031, 'ACC-62': 0.0008324436409367392, 'ACC-63': 0.0, 'ACC-64': 2.8621422619335726, 'ACC-65': 0.029744491160979818, 'ACC-66': 4.0882556271772514e-05, 'ACC-67': 0.00023276763040224575, 'ACC-68': 1.555357383449326, 'ACC-69': 0.027391053039819032, 'ACC-70': 0.6839297840137012, 'ACC-71': 0.00014333700680354617, 'ACC-72': 11.198446340896275, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0037237684536751193, 'ACC-76': 0.0, 'ACC-77': 0.03186445370091603, 'ACC-78': 0.3642929668375049, 'ACC-79': 0.09437374117759227, 'ACC-80': 0.0, 'ACC-81': 4.751766448720633, 'ACC-82': 0.000585059954018788, 'ACC-83': 65.91298752075524, 'ACC-84': 0.25755888076835093, 'ACC-85': 0.0016433108222895902, 'ACC-86': 9.092848456676116, 'ACC-87': 3.5067055630431567, 'ACC-88': 0.004524633234486855, 'ACC-89': 1.3483668085611267, 'ACC-90': 0.0035563100664678256, 'ACC-91': 0.4721177683110798, 'ACC-92': 0.0001990785790169187, 'ACC-93': 1.8204275218104657, 'ACC-94': 0.0001064344813660592, 'ACC-95': 3.1479307077492606e-05, 'ACC-96': 0.07322391212864093, 'ACC-97': 0.00015408771597319492, 'ACC-98': 0.36445702709001787, 'ACC-99': 0.05858499684126975, 'ACC-100': 0.7077826082372985, 'ACC-101': 0.039397597197934564, 'ACC-102': 1.8639329406434073, 'ACC-103': 4.249055445357515, 'ACC-104': 0.000368903863653132, 'ACC-105': 0.0, 'ACC-106': 0.6268196689844624, 'ACC-107': 0.0, 'ACC-108': 0.011607253649168548, 'ACC-109': 0.0005386380678202026, 'ACC-110': 0.872493992326196, 'ACC-111': 0.00018803584339246746, 'ACC-112': 0.0007006824647206379, 'ACC-113': 0.0, 'ACC-114': 38.14654316313028, 'ACC-115': 4.6859260595673025, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.8363364441404595, 'ACC-119': 0.0, 'ACC-120': 0.00021962421418456163, 'ACC-121': 0.005177988823719912, 'ACC-122': 0.0, 'ACC-123': 0.5307212400995522, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.13725481034305526, 'ACC-128': 3.4455189775226223, 'ACC-129': 0.0, 'ACC-130': 0.007610094855317908, 'ACC-131': 0.0015949885459885038, 'ACC-132': 0.0, 'ACC-133': 6.804248572808862e-05, 'ACC-134': 0.0016544592847910385, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0031728304185597886, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0003366215649873178, 'ACC-142': 0.9745332344739713, 'ACC-143': 0.002516055579667755, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 4.031710493248955, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0012169533775019802, 'ACC-150': 45.18010566921928, 'ACC-151': 0.0, 'ACC-152': 0.0485745835862162, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.00024651003419094177, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 11:46:32] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 11:46:32] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 11:46:32] d2.evaluation.testing INFO: copypaste: 9.8699,0.8483,0.7248,0.6437,6.1123,2.3285,8.9487
[01/24 11:46:32] d2.utils.events INFO:  eta: 1 day, 7:09:07  iter: 13499  total_loss: 46.59  loss_ce: 1.725  loss_mask: 3.084  loss_ce_0: 1.157  loss_mask_0: 3.658  loss_ce_1: 1.001  loss_mask_1: 3.589  loss_ce_2: 1.137  loss_mask_2: 3.398  loss_ce_3: 1.258  loss_mask_3: 3.419  loss_ce_4: 1.476  loss_mask_4: 3.031  loss_ce_5: 1.666  loss_mask_5: 2.948  loss_ce_6: 1.712  loss_mask_6: 3.023  loss_ce_7: 1.765  loss_mask_7: 3.093  loss_ce_8: 1.761  loss_mask_8: 3.046  time: 2.4407  data_time: 0.3850  lr: 7.9502e-05  max_mem: 18490M
[01/24 11:47:17] d2.utils.events INFO:  eta: 1 day, 7:06:25  iter: 13519  total_loss: 46.52  loss_ce: 1.66  loss_mask: 3.054  loss_ce_0: 1.175  loss_mask_0: 3.644  loss_ce_1: 1.026  loss_mask_1: 3.622  loss_ce_2: 1.143  loss_mask_2: 3.387  loss_ce_3: 1.309  loss_mask_3: 3.223  loss_ce_4: 1.478  loss_mask_4: 3.008  loss_ce_5: 1.67  loss_mask_5: 2.941  loss_ce_6: 1.694  loss_mask_6: 2.957  loss_ce_7: 1.731  loss_mask_7: 2.933  loss_ce_8: 1.726  loss_mask_8: 2.922  time: 2.4404  data_time: 0.3381  lr: 7.9472e-05  max_mem: 18490M
[01/24 11:48:04] d2.utils.events INFO:  eta: 1 day, 7:01:45  iter: 13539  total_loss: 47.69  loss_ce: 1.728  loss_mask: 3.166  loss_ce_0: 1.148  loss_mask_0: 3.79  loss_ce_1: 1.006  loss_mask_1: 3.666  loss_ce_2: 1.123  loss_mask_2: 3.525  loss_ce_3: 1.305  loss_mask_3: 3.384  loss_ce_4: 1.533  loss_mask_4: 3.119  loss_ce_5: 1.703  loss_mask_5: 3.019  loss_ce_6: 1.71  loss_mask_6: 3.064  loss_ce_7: 1.738  loss_mask_7: 3.09  loss_ce_8: 1.744  loss_mask_8: 3.063  time: 2.4403  data_time: 0.3912  lr: 7.9441e-05  max_mem: 18490M
[01/24 11:48:49] d2.utils.events INFO:  eta: 1 day, 6:52:58  iter: 13559  total_loss: 46.53  loss_ce: 1.678  loss_mask: 3.026  loss_ce_0: 1.147  loss_mask_0: 3.697  loss_ce_1: 1.02  loss_mask_1: 3.54  loss_ce_2: 1.207  loss_mask_2: 3.452  loss_ce_3: 1.354  loss_mask_3: 3.22  loss_ce_4: 1.535  loss_mask_4: 2.999  loss_ce_5: 1.692  loss_mask_5: 2.971  loss_ce_6: 1.686  loss_mask_6: 2.964  loss_ce_7: 1.717  loss_mask_7: 3.042  loss_ce_8: 1.723  loss_mask_8: 3.052  time: 2.4400  data_time: 0.3665  lr: 7.941e-05  max_mem: 18490M
[01/24 11:49:33] d2.utils.events INFO:  eta: 1 day, 6:49:24  iter: 13579  total_loss: 46.29  loss_ce: 1.674  loss_mask: 3.027  loss_ce_0: 1.22  loss_mask_0: 3.694  loss_ce_1: 1.085  loss_mask_1: 3.58  loss_ce_2: 1.303  loss_mask_2: 3.46  loss_ce_3: 1.436  loss_mask_3: 3.324  loss_ce_4: 1.562  loss_mask_4: 3.049  loss_ce_5: 1.723  loss_mask_5: 2.935  loss_ce_6: 1.69  loss_mask_6: 2.989  loss_ce_7: 1.723  loss_mask_7: 2.97  loss_ce_8: 1.723  loss_mask_8: 3.033  time: 2.4396  data_time: 0.3707  lr: 7.9379e-05  max_mem: 18490M
[01/24 11:50:19] d2.utils.events INFO:  eta: 1 day, 6:43:56  iter: 13599  total_loss: 46.74  loss_ce: 1.662  loss_mask: 2.951  loss_ce_0: 1.128  loss_mask_0: 3.612  loss_ce_1: 1.018  loss_mask_1: 3.503  loss_ce_2: 1.248  loss_mask_2: 3.361  loss_ce_3: 1.372  loss_mask_3: 3.282  loss_ce_4: 1.519  loss_mask_4: 3.094  loss_ce_5: 1.696  loss_mask_5: 2.926  loss_ce_6: 1.713  loss_mask_6: 3.062  loss_ce_7: 1.74  loss_mask_7: 2.975  loss_ce_8: 1.762  loss_mask_8: 2.97  time: 2.4394  data_time: 0.3721  lr: 7.9348e-05  max_mem: 18490M
[01/24 11:51:05] d2.utils.events INFO:  eta: 1 day, 6:40:30  iter: 13619  total_loss: 47.96  loss_ce: 1.685  loss_mask: 3.175  loss_ce_0: 1.153  loss_mask_0: 3.813  loss_ce_1: 1.02  loss_mask_1: 3.559  loss_ce_2: 1.209  loss_mask_2: 3.538  loss_ce_3: 1.299  loss_mask_3: 3.258  loss_ce_4: 1.525  loss_mask_4: 3.137  loss_ce_5: 1.699  loss_mask_5: 3.011  loss_ce_6: 1.721  loss_mask_6: 3.062  loss_ce_7: 1.734  loss_mask_7: 3.033  loss_ce_8: 1.802  loss_mask_8: 3.274  time: 2.4392  data_time: 0.3917  lr: 7.9318e-05  max_mem: 18490M
[01/24 11:51:51] d2.utils.events INFO:  eta: 1 day, 6:39:38  iter: 13639  total_loss: 47.2  loss_ce: 1.688  loss_mask: 3.119  loss_ce_0: 1.138  loss_mask_0: 3.718  loss_ce_1: 1.016  loss_mask_1: 3.551  loss_ce_2: 1.215  loss_mask_2: 3.567  loss_ce_3: 1.32  loss_mask_3: 3.364  loss_ce_4: 1.537  loss_mask_4: 3.096  loss_ce_5: 1.68  loss_mask_5: 3.025  loss_ce_6: 1.682  loss_mask_6: 3.024  loss_ce_7: 1.71  loss_mask_7: 2.98  loss_ce_8: 1.796  loss_mask_8: 3.148  time: 2.4390  data_time: 0.3961  lr: 7.9287e-05  max_mem: 18490M
[01/24 11:52:36] d2.utils.events INFO:  eta: 1 day, 6:34:15  iter: 13659  total_loss: 46.44  loss_ce: 1.717  loss_mask: 3.112  loss_ce_0: 1.141  loss_mask_0: 3.667  loss_ce_1: 1.022  loss_mask_1: 3.54  loss_ce_2: 1.166  loss_mask_2: 3.458  loss_ce_3: 1.292  loss_mask_3: 3.337  loss_ce_4: 1.574  loss_mask_4: 2.993  loss_ce_5: 1.685  loss_mask_5: 2.919  loss_ce_6: 1.693  loss_mask_6: 2.953  loss_ce_7: 1.724  loss_mask_7: 2.893  loss_ce_8: 1.815  loss_mask_8: 3.087  time: 2.4387  data_time: 0.4013  lr: 7.9256e-05  max_mem: 18490M
[01/24 11:53:20] d2.utils.events INFO:  eta: 1 day, 6:29:18  iter: 13679  total_loss: 46.35  loss_ce: 1.656  loss_mask: 3.043  loss_ce_0: 1.196  loss_mask_0: 3.709  loss_ce_1: 1.035  loss_mask_1: 3.519  loss_ce_2: 1.169  loss_mask_2: 3.434  loss_ce_3: 1.309  loss_mask_3: 3.193  loss_ce_4: 1.55  loss_mask_4: 3.022  loss_ce_5: 1.679  loss_mask_5: 2.867  loss_ce_6: 1.694  loss_mask_6: 2.92  loss_ce_7: 1.688  loss_mask_7: 2.915  loss_ce_8: 1.807  loss_mask_8: 3.114  time: 2.4384  data_time: 0.3782  lr: 7.9225e-05  max_mem: 18490M
[01/24 11:54:06] d2.utils.events INFO:  eta: 1 day, 6:25:23  iter: 13699  total_loss: 45.47  loss_ce: 1.658  loss_mask: 2.969  loss_ce_0: 1.147  loss_mask_0: 3.447  loss_ce_1: 1.009  loss_mask_1: 3.42  loss_ce_2: 1.155  loss_mask_2: 3.248  loss_ce_3: 1.3  loss_mask_3: 3.11  loss_ce_4: 1.593  loss_mask_4: 2.879  loss_ce_5: 1.698  loss_mask_5: 2.786  loss_ce_6: 1.706  loss_mask_6: 2.84  loss_ce_7: 1.708  loss_mask_7: 2.759  loss_ce_8: 1.77  loss_mask_8: 2.884  time: 2.4382  data_time: 0.3879  lr: 7.9195e-05  max_mem: 18490M
[01/24 11:54:52] d2.utils.events INFO:  eta: 1 day, 6:20:59  iter: 13719  total_loss: 44.98  loss_ce: 1.665  loss_mask: 2.949  loss_ce_0: 1.196  loss_mask_0: 3.521  loss_ce_1: 1.035  loss_mask_1: 3.431  loss_ce_2: 1.088  loss_mask_2: 3.257  loss_ce_3: 1.227  loss_mask_3: 3.098  loss_ce_4: 1.544  loss_mask_4: 2.881  loss_ce_5: 1.694  loss_mask_5: 2.765  loss_ce_6: 1.689  loss_mask_6: 2.801  loss_ce_7: 1.703  loss_mask_7: 2.81  loss_ce_8: 1.742  loss_mask_8: 2.921  time: 2.4380  data_time: 0.3751  lr: 7.9164e-05  max_mem: 18490M
[01/24 11:55:39] d2.utils.events INFO:  eta: 1 day, 6:17:50  iter: 13739  total_loss: 45.24  loss_ce: 1.649  loss_mask: 3.049  loss_ce_0: 1.187  loss_mask_0: 3.653  loss_ce_1: 1.04  loss_mask_1: 3.48  loss_ce_2: 1.114  loss_mask_2: 3.216  loss_ce_3: 1.208  loss_mask_3: 3.066  loss_ce_4: 1.477  loss_mask_4: 2.831  loss_ce_5: 1.645  loss_mask_5: 2.749  loss_ce_6: 1.672  loss_mask_6: 2.954  loss_ce_7: 1.723  loss_mask_7: 2.906  loss_ce_8: 1.728  loss_mask_8: 2.987  time: 2.4379  data_time: 0.4079  lr: 7.9133e-05  max_mem: 18490M
[01/24 11:56:30] d2.utils.events INFO:  eta: 1 day, 6:18:34  iter: 13759  total_loss: 47.75  loss_ce: 1.699  loss_mask: 3.152  loss_ce_0: 1.184  loss_mask_0: 3.696  loss_ce_1: 1.06  loss_mask_1: 3.584  loss_ce_2: 1.092  loss_mask_2: 3.487  loss_ce_3: 1.231  loss_mask_3: 3.075  loss_ce_4: 1.476  loss_mask_4: 2.998  loss_ce_5: 1.701  loss_mask_5: 2.89  loss_ce_6: 1.76  loss_mask_6: 3.275  loss_ce_7: 1.799  loss_mask_7: 3.171  loss_ce_8: 1.798  loss_mask_8: 3.222  time: 2.4380  data_time: 0.4576  lr: 7.9102e-05  max_mem: 18490M
[01/24 11:57:17] d2.utils.events INFO:  eta: 1 day, 6:13:19  iter: 13779  total_loss: 47.49  loss_ce: 1.706  loss_mask: 3.214  loss_ce_0: 1.178  loss_mask_0: 3.864  loss_ce_1: 1.09  loss_mask_1: 3.699  loss_ce_2: 1.149  loss_mask_2: 3.52  loss_ce_3: 1.275  loss_mask_3: 3.246  loss_ce_4: 1.494  loss_mask_4: 2.997  loss_ce_5: 1.713  loss_mask_5: 3.001  loss_ce_6: 1.769  loss_mask_6: 3.153  loss_ce_7: 1.742  loss_mask_7: 3.099  loss_ce_8: 1.768  loss_mask_8: 3.155  time: 2.4378  data_time: 0.4014  lr: 7.9071e-05  max_mem: 18490M
[01/24 11:58:03] d2.utils.events INFO:  eta: 1 day, 6:14:02  iter: 13799  total_loss: 47.02  loss_ce: 1.697  loss_mask: 3.086  loss_ce_0: 1.12  loss_mask_0: 3.802  loss_ce_1: 1.004  loss_mask_1: 3.662  loss_ce_2: 1.099  loss_mask_2: 3.522  loss_ce_3: 1.209  loss_mask_3: 3.282  loss_ce_4: 1.492  loss_mask_4: 3.113  loss_ce_5: 1.697  loss_mask_5: 2.976  loss_ce_6: 1.727  loss_mask_6: 3.035  loss_ce_7: 1.744  loss_mask_7: 3.002  loss_ce_8: 1.76  loss_mask_8: 3.069  time: 2.4377  data_time: 0.3573  lr: 7.9041e-05  max_mem: 18490M
[01/24 11:58:54] d2.utils.events INFO:  eta: 1 day, 6:13:44  iter: 13819  total_loss: 46.02  loss_ce: 1.659  loss_mask: 3.096  loss_ce_0: 1.128  loss_mask_0: 3.605  loss_ce_1: 1.031  loss_mask_1: 3.513  loss_ce_2: 1.127  loss_mask_2: 3.274  loss_ce_3: 1.228  loss_mask_3: 3.171  loss_ce_4: 1.449  loss_mask_4: 2.958  loss_ce_5: 1.655  loss_mask_5: 2.849  loss_ce_6: 1.681  loss_mask_6: 2.993  loss_ce_7: 1.698  loss_mask_7: 2.991  loss_ce_8: 1.787  loss_mask_8: 3.124  time: 2.4378  data_time: 0.4489  lr: 7.901e-05  max_mem: 18490M
[01/24 11:59:39] d2.utils.events INFO:  eta: 1 day, 6:11:08  iter: 13839  total_loss: 46.42  loss_ce: 1.691  loss_mask: 3.207  loss_ce_0: 1.099  loss_mask_0: 3.717  loss_ce_1: 1.005  loss_mask_1: 3.487  loss_ce_2: 1.124  loss_mask_2: 3.385  loss_ce_3: 1.269  loss_mask_3: 3.265  loss_ce_4: 1.478  loss_mask_4: 2.991  loss_ce_5: 1.666  loss_mask_5: 2.918  loss_ce_6: 1.687  loss_mask_6: 3.005  loss_ce_7: 1.699  loss_mask_7: 3.039  loss_ce_8: 1.806  loss_mask_8: 3.43  time: 2.4376  data_time: 0.3722  lr: 7.8979e-05  max_mem: 18490M
[01/24 12:00:26] d2.utils.events INFO:  eta: 1 day, 6:09:14  iter: 13859  total_loss: 48  loss_ce: 1.738  loss_mask: 3.286  loss_ce_0: 1.168  loss_mask_0: 3.805  loss_ce_1: 1.037  loss_mask_1: 3.553  loss_ce_2: 1.127  loss_mask_2: 3.383  loss_ce_3: 1.255  loss_mask_3: 3.362  loss_ce_4: 1.521  loss_mask_4: 3.202  loss_ce_5: 1.697  loss_mask_5: 3.056  loss_ce_6: 1.716  loss_mask_6: 3.084  loss_ce_7: 1.753  loss_mask_7: 3.167  loss_ce_8: 1.837  loss_mask_8: 3.429  time: 2.4374  data_time: 0.3587  lr: 7.8948e-05  max_mem: 18490M
[01/24 12:01:16] d2.utils.events INFO:  eta: 1 day, 6:08:27  iter: 13879  total_loss: 47.36  loss_ce: 1.699  loss_mask: 3.239  loss_ce_0: 1.086  loss_mask_0: 3.715  loss_ce_1: 0.9622  loss_mask_1: 3.732  loss_ce_2: 1.095  loss_mask_2: 3.563  loss_ce_3: 1.243  loss_mask_3: 3.307  loss_ce_4: 1.522  loss_mask_4: 2.937  loss_ce_5: 1.701  loss_mask_5: 2.982  loss_ce_6: 1.698  loss_mask_6: 3.014  loss_ce_7: 1.72  loss_mask_7: 3.055  loss_ce_8: 1.757  loss_mask_8: 3.182  time: 2.4375  data_time: 0.4298  lr: 7.8917e-05  max_mem: 18490M
[01/24 12:02:03] d2.utils.events INFO:  eta: 1 day, 6:07:29  iter: 13899  total_loss: 48.21  loss_ce: 1.776  loss_mask: 3.415  loss_ce_0: 1.229  loss_mask_0: 3.69  loss_ce_1: 1.021  loss_mask_1: 3.701  loss_ce_2: 1.121  loss_mask_2: 3.533  loss_ce_3: 1.226  loss_mask_3: 3.374  loss_ce_4: 1.481  loss_mask_4: 3.14  loss_ce_5: 1.673  loss_mask_5: 2.993  loss_ce_6: 1.715  loss_mask_6: 3.035  loss_ce_7: 1.745  loss_mask_7: 3.187  loss_ce_8: 1.901  loss_mask_8: 3.472  time: 2.4373  data_time: 0.3861  lr: 7.8887e-05  max_mem: 18490M
[01/24 12:02:49] d2.utils.events INFO:  eta: 1 day, 6:03:19  iter: 13919  total_loss: 47.65  loss_ce: 1.762  loss_mask: 3.302  loss_ce_0: 1.21  loss_mask_0: 3.775  loss_ce_1: 1.033  loss_mask_1: 3.551  loss_ce_2: 1.126  loss_mask_2: 3.384  loss_ce_3: 1.285  loss_mask_3: 3.239  loss_ce_4: 1.503  loss_mask_4: 2.995  loss_ce_5: 1.672  loss_mask_5: 3.008  loss_ce_6: 1.712  loss_mask_6: 3.046  loss_ce_7: 1.731  loss_mask_7: 3.016  loss_ce_8: 1.846  loss_mask_8: 3.302  time: 2.4371  data_time: 0.3823  lr: 7.8856e-05  max_mem: 18490M
[01/24 12:03:40] d2.utils.events INFO:  eta: 1 day, 6:03:51  iter: 13939  total_loss: 46.66  loss_ce: 1.775  loss_mask: 3.506  loss_ce_0: 1.126  loss_mask_0: 3.529  loss_ce_1: 0.9878  loss_mask_1: 3.438  loss_ce_2: 1.067  loss_mask_2: 3.238  loss_ce_3: 1.208  loss_mask_3: 3.116  loss_ce_4: 1.487  loss_mask_4: 2.958  loss_ce_5: 1.68  loss_mask_5: 2.973  loss_ce_6: 1.709  loss_mask_6: 2.969  loss_ce_7: 1.752  loss_mask_7: 2.955  loss_ce_8: 1.871  loss_mask_8: 3.35  time: 2.4373  data_time: 0.4266  lr: 7.8825e-05  max_mem: 18490M
[01/24 12:04:27] d2.utils.events INFO:  eta: 1 day, 6:03:04  iter: 13959  total_loss: 47.75  loss_ce: 1.788  loss_mask: 3.37  loss_ce_0: 1.201  loss_mask_0: 3.776  loss_ce_1: 1.003  loss_mask_1: 3.649  loss_ce_2: 1.067  loss_mask_2: 3.414  loss_ce_3: 1.219  loss_mask_3: 3.359  loss_ce_4: 1.502  loss_mask_4: 3.078  loss_ce_5: 1.688  loss_mask_5: 2.967  loss_ce_6: 1.74  loss_mask_6: 3.15  loss_ce_7: 1.768  loss_mask_7: 3.067  loss_ce_8: 1.79  loss_mask_8: 3.267  time: 2.4372  data_time: 0.3692  lr: 7.8794e-05  max_mem: 18490M
[01/24 12:05:13] d2.utils.events INFO:  eta: 1 day, 6:00:43  iter: 13979  total_loss: 46.65  loss_ce: 1.768  loss_mask: 3.232  loss_ce_0: 1.176  loss_mask_0: 3.563  loss_ce_1: 0.9869  loss_mask_1: 3.693  loss_ce_2: 1.056  loss_mask_2: 3.376  loss_ce_3: 1.218  loss_mask_3: 3.25  loss_ce_4: 1.464  loss_mask_4: 2.956  loss_ce_5: 1.661  loss_mask_5: 2.912  loss_ce_6: 1.762  loss_mask_6: 3.172  loss_ce_7: 1.742  loss_mask_7: 3.069  loss_ce_8: 1.751  loss_mask_8: 3.157  time: 2.4370  data_time: 0.3640  lr: 7.8763e-05  max_mem: 18490M
[01/24 12:06:04] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 12:06:04] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 12:06:04] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 12:10:18] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 12.905760608107505, 'error_1pix': 0.8963948861342141, 'error_3pix': 0.7992415590243185, 'mIoU': 0.42458808896549344, 'fwIoU': 3.0176636580045506, 'IoU-0': nan, 'IoU-1': 23.927879820721703, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.001957702312092314, 'IoU-10': 0.0017323555229027926, 'IoU-11': 0.0, 'IoU-12': 0.8038308540645663, 'IoU-13': 0.11804877233274527, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.7872745736729343, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.27786534062230384, 'IoU-20': 0.0, 'IoU-21': 0.023686267287058305, 'IoU-22': 0.00034484095406813045, 'IoU-23': 0.04482570332593239, 'IoU-24': 0.17341160415058288, 'IoU-25': 0.9015906808992032, 'IoU-26': 0.1981291792148768, 'IoU-27': 0.09637388821522629, 'IoU-28': 0.12276085464398957, 'IoU-29': 0.6036277216945967, 'IoU-30': 2.829309076240922, 'IoU-31': 1.7304401690182387, 'IoU-32': 0.03430057592796431, 'IoU-33': 2.1189648207179554, 'IoU-34': 0.5982998060626017, 'IoU-35': 4.602057990590177, 'IoU-36': 0.3209869835889375, 'IoU-37': 1.3186562877995915, 'IoU-38': 0.128581455002151, 'IoU-39': 0.30687399164636614, 'IoU-40': 3.495492868227649, 'IoU-41': 0.32557272646784485, 'IoU-42': 3.889699606410699, 'IoU-43': 0.6438168052986826, 'IoU-44': 0.06639851350609145, 'IoU-45': 2.2703629992584995e-05, 'IoU-46': 1.0176524296000498, 'IoU-47': 0.19930040579587277, 'IoU-48': 0.0007997254507756816, 'IoU-49': 0.1650910395635765, 'IoU-50': 3.1885536240633545, 'IoU-51': 0.0, 'IoU-52': 0.9383428475892615, 'IoU-53': 0.000690274511634735, 'IoU-54': 2.126650627845451, 'IoU-55': 0.17597749323116657, 'IoU-56': 0.00186763024529354, 'IoU-57': 0.0, 'IoU-58': 0.02919846750067557, 'IoU-59': 0.0013552243788721556, 'IoU-60': 0.0, 'IoU-61': 0.0001752518807656304, 'IoU-62': 0.00011389226282549532, 'IoU-63': 0.009472280954385714, 'IoU-64': 0.5246943896689252, 'IoU-65': 0.4628878640265251, 'IoU-66': 0.005089322611160455, 'IoU-67': 1.8043340979806377, 'IoU-68': 0.1024953899652709, 'IoU-69': 0.44493206939044516, 'IoU-70': 4.915818573260346e-05, 'IoU-71': 0.1502129103665748, 'IoU-72': 0.16153181704640626, 'IoU-73': 0.012921880102914373, 'IoU-74': 0.021199050491374195, 'IoU-75': 0.06361325803544107, 'IoU-76': 2.9784676931029814, 'IoU-77': 2.1923887275789706, 'IoU-78': 0.006663114483837013, 'IoU-79': 0.06203562165665764, 'IoU-80': 0.8277358001597497, 'IoU-81': 0.36016946500452646, 'IoU-82': 0.00038248063213699014, 'IoU-83': 0.2177729983182319, 'IoU-84': 0.029421294942012483, 'IoU-85': 0.0005322832079922092, 'IoU-86': 0.055790900782495996, 'IoU-87': 0.05088452668749412, 'IoU-88': 0.07158981104853092, 'IoU-89': 1.556494977261515, 'IoU-90': 2.95847595404052, 'IoU-91': 0.0036036861102692725, 'IoU-92': 0.0019168474419457905, 'IoU-93': 0.0010306770723823894, 'IoU-94': 0.5556440643426136, 'IoU-95': 0.0032931717964612833, 'IoU-96': 0.0032721295617140246, 'IoU-97': 1.0437404494412972, 'IoU-98': 0.09430002953352573, 'IoU-99': 1.0356618115554672, 'IoU-100': 0.006537133533322687, 'IoU-101': 0.0026006898649623767, 'IoU-102': 0.002120987920071247, 'IoU-103': 1.9853465307100238, 'IoU-104': 0.003947460042387384, 'IoU-105': 0.0, 'IoU-106': 0.36877108617701115, 'IoU-107': 0.004634089828172827, 'IoU-108': 0.00019338752788579085, 'IoU-109': 0.053023579288182354, 'IoU-110': 0.0013225342401109006, 'IoU-111': 0.0, 'IoU-112': 0.009593859929645027, 'IoU-113': 0.00010399489454397719, 'IoU-114': 0.00040044063030811355, 'IoU-115': 1.4981267040745685, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.7910020953911051, 'IoU-119': 0.000600275869638947, 'IoU-120': 0.0009211209076462248, 'IoU-121': 0.003986893992113199, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.005297326313282869, 'IoU-125': 0.0037335298576875817, 'IoU-126': 0.0028438709178365876, 'IoU-127': 0.005189549729573134, 'IoU-128': 0.0, 'IoU-129': 0.001863858784117935, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0006600716705819918, 'IoU-133': 0.0002641268231353967, 'IoU-134': 0.00020652239012492536, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.009809543387394015, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0011681853075665033, 'IoU-142': 0.0, 'IoU-143': 0.00829611115376842, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0003042226098243621, 'IoU-150': 0.95923937185777, 'IoU-151': 0.0001065364365266565, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.9529938770294815, 'pACC': 5.04336907578583, 'ACC-0': nan, 'ACC-1': 25.362366764588213, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0019767765816220318, 'ACC-10': 0.0017954418220742089, 'ACC-11': 0.0, 'ACC-12': 1.4064002295372917, 'ACC-13': 0.11841358005100897, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 1.8312479514350037, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.2893877881020199, 'ACC-20': 0.0, 'ACC-21': 0.02371132453099048, 'ACC-22': 0.00034529031940440537, 'ACC-23': 0.055948001641986676, 'ACC-24': 0.23398268170825165, 'ACC-25': 9.91407610331252, 'ACC-26': 0.27918772849982476, 'ACC-27': 0.12283932290631386, 'ACC-28': 0.13442719131379877, 'ACC-29': 1.1335271741184647, 'ACC-30': 19.579558371461033, 'ACC-31': 3.221008853702017, 'ACC-32': 0.03440123418927776, 'ACC-33': 3.427037026044766, 'ACC-34': 0.7932417408243926, 'ACC-35': 31.00482729173538, 'ACC-36': 0.3406368331483472, 'ACC-37': 1.7536416336402585, 'ACC-38': 0.17918930467699115, 'ACC-39': 0.3203512714097099, 'ACC-40': 21.049907615431145, 'ACC-41': 0.3600951607992876, 'ACC-42': 12.356727311305079, 'ACC-43': 1.060180819188566, 'ACC-44': 0.08781003290841687, 'ACC-45': 2.2704252850906813e-05, 'ACC-46': 2.5729905905543404, 'ACC-47': 0.24355414561983596, 'ACC-48': 0.0008140168030764172, 'ACC-49': 0.2225274995944408, 'ACC-50': 11.319208431049669, 'ACC-51': 0.0, 'ACC-52': 2.001000278029212, 'ACC-53': 0.0007128663949611773, 'ACC-54': 4.2415215614362465, 'ACC-55': 0.26512406639392094, 'ACC-56': 0.0018690787870110975, 'ACC-57': 0.0, 'ACC-58': 0.029839853909394903, 'ACC-59': 0.0013625010814386999, 'ACC-60': 0.0, 'ACC-61': 0.00017528793965554084, 'ACC-62': 0.00011391334033871167, 'ACC-63': 0.009896084655147734, 'ACC-64': 0.646123009945979, 'ACC-65': 0.9374114379290237, 'ACC-66': 0.005202305285583053, 'ACC-67': 27.591269774932748, 'ACC-68': 0.11507741782584584, 'ACC-69': 1.0699457972793036, 'ACC-70': 5.2951315713112305e-05, 'ACC-71': 0.4061509217396482, 'ACC-72': 0.6572136590859079, 'ACC-73': 0.0270268000666499, 'ACC-74': 0.021230273084055, 'ACC-75': 0.06674390847173703, 'ACC-76': 12.338454577919892, 'ACC-77': 14.972494393973895, 'ACC-78': 0.006666262919627941, 'ACC-79': 0.06559270173431381, 'ACC-80': 2.4077124647153214, 'ACC-81': 2.614177904682128, 'ACC-82': 0.0003825392007045922, 'ACC-83': 0.23901848831824404, 'ACC-84': 0.029658570311737093, 'ACC-85': 0.0005323401255304306, 'ACC-86': 0.11619916434788126, 'ACC-87': 0.05187488560608952, 'ACC-88': 0.07532257492855478, 'ACC-89': 3.1717467087152276, 'ACC-90': 28.749145443441904, 'ACC-91': 0.0036196375953522764, 'ACC-92': 0.0019196862976631447, 'ACC-93': 0.0010312451061895184, 'ACC-94': 0.8055265648301548, 'ACC-95': 0.0033053272431367246, 'ACC-96': 0.0032806710687610335, 'ACC-97': 2.335558873577706, 'ACC-98': 0.09528453482173145, 'ACC-99': 3.998088563236699, 'ACC-100': 0.006588833285893735, 'ACC-101': 0.0026222077785859337, 'ACC-102': 0.002129587675577707, 'ACC-103': 16.00831208085388, 'ACC-104': 0.003959568136543617, 'ACC-105': 0.0, 'ACC-106': 1.1551480948001815, 'ACC-107': 0.004650601151390938, 'ACC-108': 0.00019345422748614247, 'ACC-109': 0.05658534649311181, 'ACC-110': 0.001324834719341292, 'ACC-111': 0.0, 'ACC-112': 0.009709457011128839, 'ACC-113': 0.00010403283276201968, 'ACC-114': 0.0004008750738430108, 'ACC-115': 79.49017485303625, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 5.778232915438026, 'ACC-119': 0.0006004622701677048, 'ACC-120': 0.000922421699575159, 'ACC-121': 0.00399704400427502, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.005593732036795036, 'ACC-125': 0.003752598266408372, 'ACC-126': 0.002846109709560196, 'ACC-127': 0.005314973506901289, 'ACC-128': 0.0, 'ACC-129': 0.001882578555296666, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0006702120886154423, 'ACC-133': 0.0002721699429123545, 'ACC-134': 0.0002068074105988798, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.010787623423103283, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0011781754774556122, 'ACC-142': 0.0, 'ACC-143': 0.008446758017456035, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.00030423834437549505, 'ACC-150': 11.388782052284272, 'ACC-151': 0.00010657765301087199, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 12:10:18] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 12:10:18] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 12:10:18] d2.evaluation.testing INFO: copypaste: 12.9058,0.8964,0.7992,0.4246,3.0177,1.9530,5.0434
[01/24 12:10:18] d2.utils.events INFO:  eta: 1 day, 5:59:50  iter: 13999  total_loss: 46.25  loss_ce: 1.81  loss_mask: 3.313  loss_ce_0: 1.198  loss_mask_0: 3.617  loss_ce_1: 0.9752  loss_mask_1: 3.46  loss_ce_2: 1.033  loss_mask_2: 3.253  loss_ce_3: 1.156  loss_mask_3: 3.132  loss_ce_4: 1.487  loss_mask_4: 2.803  loss_ce_5: 1.661  loss_mask_5: 2.82  loss_ce_6: 1.689  loss_mask_6: 2.939  loss_ce_7: 1.749  loss_mask_7: 2.95  loss_ce_8: 1.769  loss_mask_8: 3.068  time: 2.4371  data_time: 0.4209  lr: 7.8733e-05  max_mem: 18490M
[01/24 12:11:08] d2.utils.events INFO:  eta: 1 day, 5:59:00  iter: 14019  total_loss: 47.25  loss_ce: 1.754  loss_mask: 3.279  loss_ce_0: 1.196  loss_mask_0: 3.779  loss_ce_1: 0.983  loss_mask_1: 3.511  loss_ce_2: 1.05  loss_mask_2: 3.37  loss_ce_3: 1.18  loss_mask_3: 3.227  loss_ce_4: 1.466  loss_mask_4: 2.91  loss_ce_5: 1.666  loss_mask_5: 2.928  loss_ce_6: 1.723  loss_mask_6: 3.042  loss_ce_7: 1.761  loss_mask_7: 3.111  loss_ce_8: 1.805  loss_mask_8: 3.235  time: 2.4372  data_time: 0.4376  lr: 7.8702e-05  max_mem: 18490M
[01/24 12:11:57] d2.utils.events INFO:  eta: 1 day, 5:58:34  iter: 14039  total_loss: 46.44  loss_ce: 1.763  loss_mask: 3.318  loss_ce_0: 1.164  loss_mask_0: 3.626  loss_ce_1: 0.9477  loss_mask_1: 3.548  loss_ce_2: 1.027  loss_mask_2: 3.322  loss_ce_3: 1.187  loss_mask_3: 3.203  loss_ce_4: 1.461  loss_mask_4: 2.961  loss_ce_5: 1.689  loss_mask_5: 2.927  loss_ce_6: 1.719  loss_mask_6: 2.964  loss_ce_7: 1.751  loss_mask_7: 3.076  loss_ce_8: 1.805  loss_mask_8: 3.272  time: 2.4372  data_time: 0.4197  lr: 7.8671e-05  max_mem: 18490M
[01/24 12:12:48] d2.utils.events INFO:  eta: 1 day, 6:00:27  iter: 14059  total_loss: 45.84  loss_ce: 1.753  loss_mask: 3.173  loss_ce_0: 1.218  loss_mask_0: 3.646  loss_ce_1: 1.005  loss_mask_1: 3.432  loss_ce_2: 1.111  loss_mask_2: 3.254  loss_ce_3: 1.205  loss_mask_3: 3.182  loss_ce_4: 1.436  loss_mask_4: 2.936  loss_ce_5: 1.688  loss_mask_5: 2.973  loss_ce_6: 1.698  loss_mask_6: 2.86  loss_ce_7: 1.692  loss_mask_7: 2.933  loss_ce_8: 1.784  loss_mask_8: 2.984  time: 2.4374  data_time: 0.5012  lr: 7.864e-05  max_mem: 18490M
[01/24 12:13:36] d2.utils.events INFO:  eta: 1 day, 5:57:20  iter: 14079  total_loss: 48.95  loss_ce: 1.845  loss_mask: 3.525  loss_ce_0: 1.188  loss_mask_0: 3.958  loss_ce_1: 1.016  loss_mask_1: 3.775  loss_ce_2: 1.144  loss_mask_2: 3.807  loss_ce_3: 1.272  loss_mask_3: 3.511  loss_ce_4: 1.492  loss_mask_4: 3.122  loss_ce_5: 1.726  loss_mask_5: 3.105  loss_ce_6: 1.732  loss_mask_6: 3.018  loss_ce_7: 1.771  loss_mask_7: 3.066  loss_ce_8: 1.81  loss_mask_8: 3.249  time: 2.4373  data_time: 0.3858  lr: 7.8609e-05  max_mem: 18490M
[01/24 12:14:23] d2.utils.events INFO:  eta: 1 day, 5:57:15  iter: 14099  total_loss: 52.27  loss_ce: 1.934  loss_mask: 3.897  loss_ce_0: 1.214  loss_mask_0: 3.888  loss_ce_1: 1.065  loss_mask_1: 3.942  loss_ce_2: 1.272  loss_mask_2: 3.786  loss_ce_3: 1.384  loss_mask_3: 3.514  loss_ce_4: 1.538  loss_mask_4: 3.245  loss_ce_5: 1.75  loss_mask_5: 3.122  loss_ce_6: 1.72  loss_mask_6: 3.162  loss_ce_7: 1.909  loss_mask_7: 3.513  loss_ce_8: 2.004  loss_mask_8: 4.397  time: 2.4372  data_time: 0.4243  lr: 7.8579e-05  max_mem: 18490M
[01/24 12:15:14] d2.utils.events INFO:  eta: 1 day, 5:55:46  iter: 14119  total_loss: 49.66  loss_ce: 1.857  loss_mask: 3.53  loss_ce_0: 1.273  loss_mask_0: 3.809  loss_ce_1: 1.062  loss_mask_1: 3.738  loss_ce_2: 1.2  loss_mask_2: 3.527  loss_ce_3: 1.303  loss_mask_3: 3.351  loss_ce_4: 1.537  loss_mask_4: 3.144  loss_ce_5: 1.786  loss_mask_5: 3.004  loss_ce_6: 1.733  loss_mask_6: 3.083  loss_ce_7: 1.858  loss_mask_7: 3.241  loss_ce_8: 1.94  loss_mask_8: 3.949  time: 2.4374  data_time: 0.4514  lr: 7.8548e-05  max_mem: 18490M
[01/24 12:16:04] d2.utils.events INFO:  eta: 1 day, 5:54:42  iter: 14139  total_loss: 52.05  loss_ce: 1.975  loss_mask: 3.729  loss_ce_0: 1.259  loss_mask_0: 4.063  loss_ce_1: 1.069  loss_mask_1: 3.955  loss_ce_2: 1.203  loss_mask_2: 3.809  loss_ce_3: 1.331  loss_mask_3: 3.618  loss_ce_4: 1.542  loss_mask_4: 3.313  loss_ce_5: 1.757  loss_mask_5: 3.197  loss_ce_6: 1.75  loss_mask_6: 3.19  loss_ce_7: 1.829  loss_mask_7: 3.385  loss_ce_8: 1.951  loss_mask_8: 4.049  time: 2.4374  data_time: 0.4673  lr: 7.8517e-05  max_mem: 18490M
[01/24 12:16:53] d2.utils.events INFO:  eta: 1 day, 5:57:28  iter: 14159  total_loss: 51.79  loss_ce: 1.894  loss_mask: 3.655  loss_ce_0: 1.297  loss_mask_0: 4.074  loss_ce_1: 1.113  loss_mask_1: 4.109  loss_ce_2: 1.25  loss_mask_2: 3.889  loss_ce_3: 1.376  loss_mask_3: 3.639  loss_ce_4: 1.555  loss_mask_4: 3.281  loss_ce_5: 1.77  loss_mask_5: 3.266  loss_ce_6: 1.737  loss_mask_6: 3.144  loss_ce_7: 1.803  loss_mask_7: 3.334  loss_ce_8: 1.951  loss_mask_8: 3.721  time: 2.4374  data_time: 0.4414  lr: 7.8486e-05  max_mem: 18490M
[01/24 12:17:44] d2.utils.events INFO:  eta: 1 day, 5:57:06  iter: 14179  total_loss: 51.97  loss_ce: 1.874  loss_mask: 3.444  loss_ce_0: 1.303  loss_mask_0: 3.905  loss_ce_1: 1.345  loss_mask_1: 4.039  loss_ce_2: 1.403  loss_mask_2: 3.738  loss_ce_3: 1.462  loss_mask_3: 3.617  loss_ce_4: 1.639  loss_mask_4: 3.285  loss_ce_5: 1.868  loss_mask_5: 3.14  loss_ce_6: 1.831  loss_mask_6: 3.148  loss_ce_7: 1.84  loss_mask_7: 3.347  loss_ce_8: 1.891  loss_mask_8: 3.446  time: 2.4376  data_time: 0.4997  lr: 7.8455e-05  max_mem: 18490M
[01/24 12:18:34] d2.utils.events INFO:  eta: 1 day, 6:01:55  iter: 14199  total_loss: 50.5  loss_ce: 1.945  loss_mask: 3.846  loss_ce_0: 1.224  loss_mask_0: 3.791  loss_ce_1: 1.241  loss_mask_1: 3.749  loss_ce_2: 1.325  loss_mask_2: 3.629  loss_ce_3: 1.371  loss_mask_3: 3.509  loss_ce_4: 1.558  loss_mask_4: 3.189  loss_ce_5: 1.815  loss_mask_5: 3.137  loss_ce_6: 1.761  loss_mask_6: 3.164  loss_ce_7: 1.819  loss_mask_7: 3.322  loss_ce_8: 1.922  loss_mask_8: 3.511  time: 2.4377  data_time: 0.4511  lr: 7.8424e-05  max_mem: 18490M
[01/24 12:19:25] d2.utils.events INFO:  eta: 1 day, 6:08:51  iter: 14219  total_loss: 51.86  loss_ce: 1.882  loss_mask: 3.725  loss_ce_0: 1.237  loss_mask_0: 4.221  loss_ce_1: 1.181  loss_mask_1: 3.922  loss_ce_2: 1.279  loss_mask_2: 3.784  loss_ce_3: 1.329  loss_mask_3: 3.655  loss_ce_4: 1.535  loss_mask_4: 3.279  loss_ce_5: 1.821  loss_mask_5: 3.364  loss_ce_6: 1.767  loss_mask_6: 3.259  loss_ce_7: 1.822  loss_mask_7: 3.359  loss_ce_8: 1.944  loss_mask_8: 3.69  time: 2.4378  data_time: 0.5172  lr: 7.8394e-05  max_mem: 18490M
[01/24 12:20:17] d2.utils.events INFO:  eta: 1 day, 6:07:22  iter: 14239  total_loss: 50.06  loss_ce: 1.835  loss_mask: 3.414  loss_ce_0: 1.26  loss_mask_0: 3.89  loss_ce_1: 1.273  loss_mask_1: 3.812  loss_ce_2: 1.33  loss_mask_2: 3.682  loss_ce_3: 1.356  loss_mask_3: 3.511  loss_ce_4: 1.548  loss_mask_4: 3.235  loss_ce_5: 1.799  loss_mask_5: 3.091  loss_ce_6: 1.778  loss_mask_6: 3.106  loss_ce_7: 1.781  loss_mask_7: 3.214  loss_ce_8: 1.913  loss_mask_8: 3.663  time: 2.4380  data_time: 0.4939  lr: 7.8363e-05  max_mem: 18490M
[01/24 12:21:05] d2.utils.events INFO:  eta: 1 day, 6:10:22  iter: 14259  total_loss: 49.76  loss_ce: 1.851  loss_mask: 3.485  loss_ce_0: 1.216  loss_mask_0: 3.851  loss_ce_1: 1.273  loss_mask_1: 3.697  loss_ce_2: 1.347  loss_mask_2: 3.642  loss_ce_3: 1.411  loss_mask_3: 3.286  loss_ce_4: 1.585  loss_mask_4: 3.15  loss_ce_5: 1.774  loss_mask_5: 3.07  loss_ce_6: 1.795  loss_mask_6: 3.101  loss_ce_7: 1.811  loss_mask_7: 3.194  loss_ce_8: 1.864  loss_mask_8: 3.388  time: 2.4380  data_time: 0.4315  lr: 7.8332e-05  max_mem: 18490M
[01/24 12:21:56] d2.utils.events INFO:  eta: 1 day, 6:13:38  iter: 14279  total_loss: 51.26  loss_ce: 1.792  loss_mask: 3.396  loss_ce_0: 1.27  loss_mask_0: 3.896  loss_ce_1: 1.197  loss_mask_1: 3.776  loss_ce_2: 1.267  loss_mask_2: 3.61  loss_ce_3: 1.306  loss_mask_3: 3.44  loss_ce_4: 1.505  loss_mask_4: 3.24  loss_ce_5: 1.793  loss_mask_5: 3.199  loss_ce_6: 1.844  loss_mask_6: 3.585  loss_ce_7: 1.807  loss_mask_7: 3.537  loss_ce_8: 1.869  loss_mask_8: 3.542  time: 2.4381  data_time: 0.4595  lr: 7.8301e-05  max_mem: 18490M
[01/24 12:22:44] d2.utils.events INFO:  eta: 1 day, 6:10:25  iter: 14299  total_loss: 49  loss_ce: 1.767  loss_mask: 3.258  loss_ce_0: 1.208  loss_mask_0: 3.733  loss_ce_1: 1.127  loss_mask_1: 3.61  loss_ce_2: 1.19  loss_mask_2: 3.45  loss_ce_3: 1.257  loss_mask_3: 3.258  loss_ce_4: 1.447  loss_mask_4: 3.066  loss_ce_5: 1.824  loss_mask_5: 3.033  loss_ce_6: 1.918  loss_mask_6: 3.728  loss_ce_7: 1.801  loss_mask_7: 3.123  loss_ce_8: 1.821  loss_mask_8: 3.283  time: 2.4381  data_time: 0.4293  lr: 7.827e-05  max_mem: 18490M
[01/24 12:23:32] d2.utils.events INFO:  eta: 1 day, 6:10:23  iter: 14319  total_loss: 48.93  loss_ce: 1.779  loss_mask: 3.182  loss_ce_0: 1.219  loss_mask_0: 3.719  loss_ce_1: 1.08  loss_mask_1: 3.791  loss_ce_2: 1.123  loss_mask_2: 3.443  loss_ce_3: 1.227  loss_mask_3: 3.407  loss_ce_4: 1.437  loss_mask_4: 3.2  loss_ce_5: 1.76  loss_mask_5: 3.107  loss_ce_6: 1.828  loss_mask_6: 3.57  loss_ce_7: 1.796  loss_mask_7: 3.202  loss_ce_8: 1.813  loss_mask_8: 3.231  time: 2.4381  data_time: 0.4730  lr: 7.8239e-05  max_mem: 18490M
[01/24 12:24:24] d2.utils.events INFO:  eta: 1 day, 6:13:42  iter: 14339  total_loss: 48.75  loss_ce: 1.751  loss_mask: 3.213  loss_ce_0: 1.2  loss_mask_0: 3.872  loss_ce_1: 1.098  loss_mask_1: 3.764  loss_ce_2: 1.12  loss_mask_2: 3.426  loss_ce_3: 1.265  loss_mask_3: 3.359  loss_ce_4: 1.487  loss_mask_4: 3.187  loss_ce_5: 1.775  loss_mask_5: 3.099  loss_ce_6: 1.825  loss_mask_6: 3.444  loss_ce_7: 1.755  loss_mask_7: 3.129  loss_ce_8: 1.788  loss_mask_8: 3.366  time: 2.4382  data_time: 0.4846  lr: 7.8209e-05  max_mem: 18490M
[01/24 12:25:10] d2.utils.events INFO:  eta: 1 day, 6:11:42  iter: 14359  total_loss: 49.28  loss_ce: 1.807  loss_mask: 3.186  loss_ce_0: 1.204  loss_mask_0: 3.619  loss_ce_1: 1.215  loss_mask_1: 3.555  loss_ce_2: 1.301  loss_mask_2: 3.381  loss_ce_3: 1.427  loss_mask_3: 3.433  loss_ce_4: 1.544  loss_mask_4: 3.188  loss_ce_5: 1.852  loss_mask_5: 3.071  loss_ce_6: 1.852  loss_mask_6: 3.203  loss_ce_7: 1.807  loss_mask_7: 3.096  loss_ce_8: 1.833  loss_mask_8: 3.26  time: 2.4381  data_time: 0.4307  lr: 7.8178e-05  max_mem: 18490M
[01/24 12:25:59] d2.utils.events INFO:  eta: 1 day, 6:11:38  iter: 14379  total_loss: 50.6  loss_ce: 1.803  loss_mask: 3.368  loss_ce_0: 1.164  loss_mask_0: 3.855  loss_ce_1: 1.202  loss_mask_1: 3.688  loss_ce_2: 1.363  loss_mask_2: 3.656  loss_ce_3: 1.561  loss_mask_3: 3.747  loss_ce_4: 1.619  loss_mask_4: 3.229  loss_ce_5: 1.853  loss_mask_5: 3.24  loss_ce_6: 1.863  loss_mask_6: 3.329  loss_ce_7: 1.807  loss_mask_7: 3.246  loss_ce_8: 1.907  loss_mask_8: 3.423  time: 2.4381  data_time: 0.4580  lr: 7.8147e-05  max_mem: 18490M
[01/24 12:26:51] d2.utils.events INFO:  eta: 1 day, 6:15:03  iter: 14399  total_loss: 49.97  loss_ce: 1.783  loss_mask: 3.209  loss_ce_0: 1.14  loss_mask_0: 3.921  loss_ce_1: 1.166  loss_mask_1: 3.59  loss_ce_2: 1.325  loss_mask_2: 3.443  loss_ce_3: 1.446  loss_mask_3: 3.471  loss_ce_4: 1.572  loss_mask_4: 3.081  loss_ce_5: 1.895  loss_mask_5: 3.134  loss_ce_6: 1.885  loss_mask_6: 3.245  loss_ce_7: 1.807  loss_mask_7: 3.151  loss_ce_8: 1.858  loss_mask_8: 3.223  time: 2.4383  data_time: 0.5184  lr: 7.8116e-05  max_mem: 18490M
[01/24 12:27:38] d2.utils.events INFO:  eta: 1 day, 6:12:43  iter: 14419  total_loss: 48.19  loss_ce: 1.79  loss_mask: 3.18  loss_ce_0: 1.117  loss_mask_0: 3.838  loss_ce_1: 1.132  loss_mask_1: 3.606  loss_ce_2: 1.255  loss_mask_2: 3.403  loss_ce_3: 1.343  loss_mask_3: 3.347  loss_ce_4: 1.552  loss_mask_4: 3.074  loss_ce_5: 1.828  loss_mask_5: 3.035  loss_ce_6: 1.849  loss_mask_6: 3.112  loss_ce_7: 1.777  loss_mask_7: 2.942  loss_ce_8: 1.768  loss_mask_8: 3.17  time: 2.4382  data_time: 0.3594  lr: 7.8085e-05  max_mem: 18490M
[01/24 12:28:26] d2.utils.events INFO:  eta: 1 day, 6:12:07  iter: 14439  total_loss: 46.12  loss_ce: 1.729  loss_mask: 3.049  loss_ce_0: 1.097  loss_mask_0: 3.73  loss_ce_1: 1.084  loss_mask_1: 3.336  loss_ce_2: 1.184  loss_mask_2: 3.29  loss_ce_3: 1.244  loss_mask_3: 3.016  loss_ce_4: 1.499  loss_mask_4: 2.895  loss_ce_5: 1.751  loss_mask_5: 3  loss_ce_6: 1.8  loss_mask_6: 3.014  loss_ce_7: 1.758  loss_mask_7: 2.944  loss_ce_8: 1.743  loss_mask_8: 3.012  time: 2.4381  data_time: 0.3663  lr: 7.8054e-05  max_mem: 18490M
[01/24 12:29:17] d2.utils.events INFO:  eta: 1 day, 6:12:56  iter: 14459  total_loss: 46.74  loss_ce: 1.725  loss_mask: 3.004  loss_ce_0: 1.084  loss_mask_0: 3.566  loss_ce_1: 1.039  loss_mask_1: 3.367  loss_ce_2: 1.167  loss_mask_2: 3.387  loss_ce_3: 1.268  loss_mask_3: 3.189  loss_ce_4: 1.487  loss_mask_4: 2.981  loss_ce_5: 1.74  loss_mask_5: 2.997  loss_ce_6: 1.756  loss_mask_6: 2.976  loss_ce_7: 1.741  loss_mask_7: 3.048  loss_ce_8: 1.723  loss_mask_8: 2.977  time: 2.4383  data_time: 0.4189  lr: 7.8024e-05  max_mem: 18490M
[01/24 12:30:06] d2.utils.events INFO:  eta: 1 day, 6:12:13  iter: 14479  total_loss: 45.88  loss_ce: 1.743  loss_mask: 3.038  loss_ce_0: 1.159  loss_mask_0: 3.553  loss_ce_1: 1.095  loss_mask_1: 3.401  loss_ce_2: 1.149  loss_mask_2: 3.265  loss_ce_3: 1.262  loss_mask_3: 3.286  loss_ce_4: 1.478  loss_mask_4: 2.975  loss_ce_5: 1.782  loss_mask_5: 2.962  loss_ce_6: 1.778  loss_mask_6: 2.954  loss_ce_7: 1.765  loss_mask_7: 2.872  loss_ce_8: 1.738  loss_mask_8: 2.951  time: 2.4383  data_time: 0.3969  lr: 7.7993e-05  max_mem: 18490M
[01/24 12:30:56] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 12:30:57] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 12:30:57] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 12:35:20] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 8.852759953330068, 'error_1pix': 0.7839521769817206, 'error_3pix': 0.6445971336338164, 'mIoU': 0.814617559534634, 'fwIoU': 6.200887285217918, 'IoU-0': nan, 'IoU-1': 48.05001142097399, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.00011787634473644276, 'IoU-11': 0.0, 'IoU-12': 2.633502916765425, 'IoU-13': 6.781237399794583, 'IoU-14': 0.5809125034628823, 'IoU-15': 2.3596637819988406, 'IoU-16': 0.5016238606138342, 'IoU-17': 0.8853475141657919, 'IoU-18': 2.806515808979113, 'IoU-19': 2.5318850999809457, 'IoU-20': 0.6334881803993198, 'IoU-21': 0.09506699609773941, 'IoU-22': 1.9565356045830193, 'IoU-23': 0.24520287043720873, 'IoU-24': 4.38516928052832, 'IoU-25': 2.970617389488139, 'IoU-26': 2.983086330133547, 'IoU-27': 5.074317270455193, 'IoU-28': 0.055556948288982014, 'IoU-29': 3.054169769811194, 'IoU-30': 0.9237896051587483, 'IoU-31': 0.5476234439238179, 'IoU-32': 2.092043637498627, 'IoU-33': 5.8853986497262385, 'IoU-34': 2.1141228953498246, 'IoU-35': 0.0740309086476426, 'IoU-36': 0.04226361768685051, 'IoU-37': 1.072071711481532, 'IoU-38': 0.0, 'IoU-39': 2.1688911466024416, 'IoU-40': 4.5992718435650035, 'IoU-41': 0.15692168884723734, 'IoU-42': 2.681911223390065, 'IoU-43': 1.8266446654069581, 'IoU-44': 0.42072184784132843, 'IoU-45': 0.04207509277724262, 'IoU-46': 0.42668207857416657, 'IoU-47': 4.653469569081064, 'IoU-48': 1.8209785835709587, 'IoU-49': 0.05154633834731799, 'IoU-50': 1.1889455399777529, 'IoU-51': 0.11620745542949758, 'IoU-52': 0.7386624136892762, 'IoU-53': 0.007170859971901094, 'IoU-54': 2.3865648841685703, 'IoU-55': 0.10021360176254204, 'IoU-56': 0.0068507792916579656, 'IoU-57': 0.0, 'IoU-58': 0.033251694767628674, 'IoU-59': 1.687024038465062, 'IoU-60': 0.011793303019831393, 'IoU-61': 0.00023169234963046667, 'IoU-62': 0.0016431364573261291, 'IoU-63': 0.038919474751668834, 'IoU-64': 2.0786256483531376, 'IoU-65': 0.2361076248412722, 'IoU-66': 2.077491242336852, 'IoU-67': 0.3863891071946337, 'IoU-68': 0.49916076167368223, 'IoU-69': 0.1917924334646711, 'IoU-70': 0.0007702892879456375, 'IoU-71': 0.024319533899506862, 'IoU-72': 0.06042199057066275, 'IoU-73': 0.005409633453173275, 'IoU-74': 0.001437614813269509, 'IoU-75': 0.05157507028482984, 'IoU-76': 0.002487398152953394, 'IoU-77': 0.37467503639013244, 'IoU-78': 0.07138241893699904, 'IoU-79': 0.2624472558325671, 'IoU-80': 1.7445306330093113, 'IoU-81': 0.00017660578255898688, 'IoU-82': 0.0023348749494858786, 'IoU-83': 1.3611454930347238, 'IoU-84': 0.0, 'IoU-85': 0.20995276282544215, 'IoU-86': 0.001906833308895863, 'IoU-87': 0.015996397490557597, 'IoU-88': 3.2163804436740273, 'IoU-89': 0.17352681091622552, 'IoU-90': 0.4568582703991945, 'IoU-91': 0.003584902022183482, 'IoU-92': 0.0015903804701278268, 'IoU-93': 0.022023610011880464, 'IoU-94': 0.402589537888557, 'IoU-95': 0.14523130393049008, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.006129913418578794, 'IoU-99': 1.0960191781611663, 'IoU-100': 0.06805097807699895, 'IoU-101': 0.0, 'IoU-102': 2.492726897545891, 'IoU-103': 1.6322421782810874, 'IoU-104': 0.3613110154534619, 'IoU-105': 1.372718902458693, 'IoU-106': 0.10621453022816268, 'IoU-107': 0.7883260757483859, 'IoU-108': 0.0, 'IoU-109': 0.059675702279499476, 'IoU-110': 0.0009823013116996848, 'IoU-111': 0.0, 'IoU-112': 1.9861719318679356, 'IoU-113': 0.010695044640706296, 'IoU-114': 3.6388168605307e-05, 'IoU-115': 1.1653201566021365, 'IoU-116': 0.0, 'IoU-117': 0.002847981182465742, 'IoU-118': 0.8132058102997433, 'IoU-119': 0.15265538493636727, 'IoU-120': 1.358175551933939, 'IoU-121': 0.00688342297427343, 'IoU-122': 0.004022396328581137, 'IoU-123': 9.86578584930604e-05, 'IoU-124': 0.007993438252726042, 'IoU-125': 0.007339900460075835, 'IoU-126': 0.032405700210557234, 'IoU-127': 0.00023361729515559496, 'IoU-128': 0.12275993350695535, 'IoU-129': 0.09595257107277282, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.04703711061410985, 'IoU-133': 0.0, 'IoU-134': 0.11676173783447645, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 7.60045906772769e-05, 'IoU-138': 0.005448795145044558, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.020631775662689224, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.003440348406106821, 'IoU-150': 0.0, 'IoU-151': 1.2018620212743085, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.00036925849202217026, 'IoU-176': 0.0, 'IoU-177': 0.6754606539930301, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.7347742132505153, 'pACC': 13.906240320747223, 'ACC-0': nan, 'ACC-1': 99.0469376283168, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.00011844928687295129, 'ACC-11': 0.0, 'ACC-12': 4.315878849780576, 'ACC-13': 24.944052434044433, 'ACC-14': 0.6658749371358617, 'ACC-15': 2.775751559218574, 'ACC-16': 0.5389157634840365, 'ACC-17': 1.1228211637284753, 'ACC-18': 5.082406434741419, 'ACC-19': 4.779380928857669, 'ACC-20': 0.7043477382636834, 'ACC-21': 0.09815267171734042, 'ACC-22': 2.5412392898391722, 'ACC-23': 0.25016888640068546, 'ACC-24': 17.913355658883365, 'ACC-25': 5.196510342858146, 'ACC-26': 6.06543695210408, 'ACC-27': 11.984175922331081, 'ACC-28': 0.05696980850876137, 'ACC-29': 5.991799178810301, 'ACC-30': 1.0899765403685746, 'ACC-31': 0.5818476320891562, 'ACC-32': 2.7112849961300305, 'ACC-33': 40.771825380559164, 'ACC-34': 2.9121852961747607, 'ACC-35': 0.07593716904847567, 'ACC-36': 0.04231516859314587, 'ACC-37': 1.1933548731789627, 'ACC-38': 0.0, 'ACC-39': 2.8811971366539773, 'ACC-40': 10.229003770617028, 'ACC-41': 0.160726656363754, 'ACC-42': 3.663699887501861, 'ACC-43': 2.6743551841844866, 'ACC-44': 0.5181555569449838, 'ACC-45': 0.042123957122715765, 'ACC-46': 0.46009781872876804, 'ACC-47': 10.7421981583827, 'ACC-48': 2.444005819158381, 'ACC-49': 0.0519542597294374, 'ACC-50': 1.3472162347305618, 'ACC-51': 0.1261709082616077, 'ACC-52': 0.9830997957635038, 'ACC-53': 0.0071830812316698795, 'ACC-54': 29.025437780418773, 'ACC-55': 0.1036613560192998, 'ACC-56': 0.0070185815675518765, 'ACC-57': 0.0, 'ACC-58': 0.033940409506971914, 'ACC-59': 2.913444252337583, 'ACC-60': 0.011982695661316921, 'ACC-61': 0.0002420642976195564, 'ACC-62': 0.0016473621525905997, 'ACC-63': 0.03904019230684097, 'ACC-64': 16.74402576085889, 'ACC-65': 0.5567769118650053, 'ACC-66': 3.442965358983594, 'ACC-67': 1.016855973759047, 'ACC-68': 0.5983853132391563, 'ACC-69': 0.20356869619964496, 'ACC-70': 0.0007730892094114397, 'ACC-71': 0.024676017017410484, 'ACC-72': 0.06831057502046867, 'ACC-73': 0.005414199522754886, 'ACC-74': 0.0014487564495532655, 'ACC-75': 0.05255864389307434, 'ACC-76': 0.002488817267435383, 'ACC-77': 0.48725651092637473, 'ACC-78': 0.07439371947078968, 'ACC-79': 0.30211180876915056, 'ACC-80': 32.17594463748632, 'ACC-81': 0.00017728197917601552, 'ACC-82': 0.002340239816075152, 'ACC-83': 5.880649463404829, 'ACC-84': 0.0, 'ACC-85': 0.22117574954646935, 'ACC-86': 0.0019091810858259904, 'ACC-87': 0.016210901751902977, 'ACC-88': 60.12796416892668, 'ACC-89': 0.1802264220955082, 'ACC-90': 0.555839539289801, 'ACC-91': 0.00359242227508647, 'ACC-92': 0.0015926286321353495, 'ACC-93': 0.02218650185602021, 'ACC-94': 0.5280518719088386, 'ACC-95': 0.17184553733603217, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0061380715876068, 'ACC-99': 4.641308632242806, 'ACC-100': 0.07636964611680522, 'ACC-101': 0.0, 'ACC-102': 12.435885817852288, 'ACC-103': 3.6952158307358083, 'ACC-104': 0.48228031774919455, 'ACC-105': 3.717024755902809, 'ACC-106': 0.11081575975269153, 'ACC-107': 1.3481576004421063, 'ACC-108': 0.0, 'ACC-109': 0.063247448910888, 'ACC-110': 0.000993626039505969, 'ACC-111': 0.0, 'ACC-112': 11.674304105532121, 'ACC-113': 0.010854092218170722, 'ACC-114': 3.6443188531182795e-05, 'ACC-115': 4.14862508081127, 'ACC-116': 0.0, 'ACC-117': 0.002852947818378931, 'ACC-118': 2.97842252813855, 'ACC-119': 0.15753556559471285, 'ACC-120': 32.12900199243087, 'ACC-121': 0.006994827007481286, 'ACC-122': 0.00405710134261749, 'ACC-123': 9.868375606164972e-05, 'ACC-124': 0.00836396123596972, 'ACC-125': 0.007342040086451162, 'ACC-126': 0.03466561626244319, 'ACC-127': 0.00023362520909456214, 'ACC-128': 0.1300172827851507, 'ACC-129': 0.10956607191826596, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.049193567304373464, 'ACC-133': 0.0, 'ACC-134': 0.12270573028866869, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 7.632323500610967e-05, 'ACC-138': 0.005473132472015636, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.021646280104653505, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0034480345695889437, 'ACC-150': 0.0, 'ACC-151': 10.545219299507718, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0003697684694728396, 'ACC-176': 0.0, 'ACC-177': 0.955766061538859, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 12:35:20] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 12:35:20] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 12:35:20] d2.evaluation.testing INFO: copypaste: 8.8528,0.7840,0.6446,0.8146,6.2009,2.7348,13.9062
[01/24 12:35:20] d2.utils.events INFO:  eta: 1 day, 6:12:25  iter: 14499  total_loss: 47.34  loss_ce: 1.713  loss_mask: 3.181  loss_ce_0: 1.14  loss_mask_0: 3.957  loss_ce_1: 1.082  loss_mask_1: 3.532  loss_ce_2: 1.189  loss_mask_2: 3.378  loss_ce_3: 1.341  loss_mask_3: 3.314  loss_ce_4: 1.501  loss_mask_4: 3.138  loss_ce_5: 1.791  loss_mask_5: 3.056  loss_ce_6: 1.759  loss_mask_6: 3.09  loss_ce_7: 1.754  loss_mask_7: 3.113  loss_ce_8: 1.737  loss_mask_8: 3.118  time: 2.4384  data_time: 0.4247  lr: 7.7962e-05  max_mem: 18490M
[01/24 12:36:10] d2.utils.events INFO:  eta: 1 day, 6:13:57  iter: 14519  total_loss: 46.5  loss_ce: 1.731  loss_mask: 3.128  loss_ce_0: 1.067  loss_mask_0: 3.538  loss_ce_1: 0.9818  loss_mask_1: 3.403  loss_ce_2: 1.108  loss_mask_2: 3.232  loss_ce_3: 1.284  loss_mask_3: 3.121  loss_ce_4: 1.496  loss_mask_4: 3.18  loss_ce_5: 1.764  loss_mask_5: 3.008  loss_ce_6: 1.736  loss_mask_6: 3.046  loss_ce_7: 1.745  loss_mask_7: 2.981  loss_ce_8: 1.732  loss_mask_8: 3.059  time: 2.4385  data_time: 0.4388  lr: 7.7931e-05  max_mem: 18490M
[01/24 12:36:58] d2.utils.events INFO:  eta: 1 day, 6:13:09  iter: 14539  total_loss: 46.42  loss_ce: 1.707  loss_mask: 3.044  loss_ce_0: 1.121  loss_mask_0: 3.711  loss_ce_1: 1.036  loss_mask_1: 3.457  loss_ce_2: 1.126  loss_mask_2: 3.34  loss_ce_3: 1.289  loss_mask_3: 3.186  loss_ce_4: 1.491  loss_mask_4: 3.147  loss_ce_5: 1.776  loss_mask_5: 2.927  loss_ce_6: 1.731  loss_mask_6: 2.988  loss_ce_7: 1.746  loss_mask_7: 2.883  loss_ce_8: 1.725  loss_mask_8: 2.961  time: 2.4384  data_time: 0.3731  lr: 7.79e-05  max_mem: 18490M
[01/24 12:37:45] d2.utils.events INFO:  eta: 1 day, 6:14:09  iter: 14559  total_loss: 45.53  loss_ce: 1.696  loss_mask: 2.97  loss_ce_0: 1.073  loss_mask_0: 3.527  loss_ce_1: 0.9895  loss_mask_1: 3.365  loss_ce_2: 1.114  loss_mask_2: 3.224  loss_ce_3: 1.267  loss_mask_3: 3.158  loss_ce_4: 1.473  loss_mask_4: 3.138  loss_ce_5: 1.766  loss_mask_5: 2.955  loss_ce_6: 1.73  loss_mask_6: 2.959  loss_ce_7: 1.727  loss_mask_7: 2.945  loss_ce_8: 1.726  loss_mask_8: 2.929  time: 2.4383  data_time: 0.3893  lr: 7.7869e-05  max_mem: 18490M
[01/24 12:38:35] d2.utils.events INFO:  eta: 1 day, 6:18:55  iter: 14579  total_loss: 47.48  loss_ce: 1.732  loss_mask: 3.094  loss_ce_0: 1.052  loss_mask_0: 3.833  loss_ce_1: 0.9414  loss_mask_1: 3.657  loss_ce_2: 1.065  loss_mask_2: 3.434  loss_ce_3: 1.244  loss_mask_3: 3.399  loss_ce_4: 1.503  loss_mask_4: 3.243  loss_ce_5: 1.769  loss_mask_5: 3.108  loss_ce_6: 1.746  loss_mask_6: 3.066  loss_ce_7: 1.739  loss_mask_7: 3.034  loss_ce_8: 1.749  loss_mask_8: 3.046  time: 2.4384  data_time: 0.4872  lr: 7.7839e-05  max_mem: 18490M
[01/24 12:39:22] d2.utils.events INFO:  eta: 1 day, 6:17:59  iter: 14599  total_loss: 44.54  loss_ce: 1.68  loss_mask: 2.86  loss_ce_0: 1.08  loss_mask_0: 3.532  loss_ce_1: 0.9897  loss_mask_1: 3.328  loss_ce_2: 1.101  loss_mask_2: 3.08  loss_ce_3: 1.266  loss_mask_3: 3.083  loss_ce_4: 1.509  loss_mask_4: 2.991  loss_ce_5: 1.741  loss_mask_5: 2.863  loss_ce_6: 1.716  loss_mask_6: 2.912  loss_ce_7: 1.712  loss_mask_7: 2.779  loss_ce_8: 1.733  loss_mask_8: 2.83  time: 2.4382  data_time: 0.3729  lr: 7.7808e-05  max_mem: 18490M
[01/24 12:40:10] d2.utils.events INFO:  eta: 1 day, 6:18:24  iter: 14619  total_loss: 44.03  loss_ce: 1.699  loss_mask: 2.83  loss_ce_0: 1.066  loss_mask_0: 3.436  loss_ce_1: 0.9765  loss_mask_1: 3.224  loss_ce_2: 1.107  loss_mask_2: 3.043  loss_ce_3: 1.269  loss_mask_3: 2.979  loss_ce_4: 1.516  loss_mask_4: 2.922  loss_ce_5: 1.761  loss_mask_5: 2.807  loss_ce_6: 1.722  loss_mask_6: 2.781  loss_ce_7: 1.739  loss_mask_7: 2.709  loss_ce_8: 1.69  loss_mask_8: 2.771  time: 2.4382  data_time: 0.4143  lr: 7.7777e-05  max_mem: 18490M
[01/24 12:41:00] d2.utils.events INFO:  eta: 1 day, 6:19:04  iter: 14639  total_loss: 44.64  loss_ce: 1.659  loss_mask: 2.905  loss_ce_0: 1.06  loss_mask_0: 3.593  loss_ce_1: 0.9677  loss_mask_1: 3.357  loss_ce_2: 1.08  loss_mask_2: 3.15  loss_ce_3: 1.249  loss_mask_3: 3.012  loss_ce_4: 1.49  loss_mask_4: 2.98  loss_ce_5: 1.749  loss_mask_5: 2.879  loss_ce_6: 1.71  loss_mask_6: 2.855  loss_ce_7: 1.712  loss_mask_7: 2.747  loss_ce_8: 1.683  loss_mask_8: 2.828  time: 2.4383  data_time: 0.4746  lr: 7.7746e-05  max_mem: 18490M
[01/24 12:41:48] d2.utils.events INFO:  eta: 1 day, 6:19:52  iter: 14659  total_loss: 46.23  loss_ce: 1.682  loss_mask: 2.971  loss_ce_0: 1.125  loss_mask_0: 3.644  loss_ce_1: 1.016  loss_mask_1: 3.508  loss_ce_2: 1.095  loss_mask_2: 3.239  loss_ce_3: 1.254  loss_mask_3: 3.091  loss_ce_4: 1.478  loss_mask_4: 3.073  loss_ce_5: 1.738  loss_mask_5: 2.977  loss_ce_6: 1.713  loss_mask_6: 2.949  loss_ce_7: 1.73  loss_mask_7: 2.933  loss_ce_8: 1.703  loss_mask_8: 2.908  time: 2.4382  data_time: 0.4552  lr: 7.7715e-05  max_mem: 18490M
[01/24 12:42:38] d2.utils.events INFO:  eta: 1 day, 6:25:31  iter: 14679  total_loss: 47.37  loss_ce: 1.702  loss_mask: 3.19  loss_ce_0: 1.113  loss_mask_0: 3.735  loss_ce_1: 1.033  loss_mask_1: 3.575  loss_ce_2: 1.116  loss_mask_2: 3.34  loss_ce_3: 1.271  loss_mask_3: 3.209  loss_ce_4: 1.504  loss_mask_4: 3.096  loss_ce_5: 1.774  loss_mask_5: 3.116  loss_ce_6: 1.769  loss_mask_6: 3.169  loss_ce_7: 1.747  loss_mask_7: 3.069  loss_ce_8: 1.717  loss_mask_8: 3.11  time: 2.4383  data_time: 0.4407  lr: 7.7684e-05  max_mem: 18490M
[01/24 12:43:27] d2.utils.events INFO:  eta: 1 day, 6:27:19  iter: 14699  total_loss: 45.4  loss_ce: 1.689  loss_mask: 2.913  loss_ce_0: 1.187  loss_mask_0: 3.634  loss_ce_1: 1.129  loss_mask_1: 3.346  loss_ce_2: 1.173  loss_mask_2: 3.239  loss_ce_3: 1.276  loss_mask_3: 3.142  loss_ce_4: 1.478  loss_mask_4: 2.967  loss_ce_5: 1.752  loss_mask_5: 2.851  loss_ce_6: 1.766  loss_mask_6: 2.866  loss_ce_7: 1.734  loss_mask_7: 2.853  loss_ce_8: 1.686  loss_mask_8: 2.856  time: 2.4383  data_time: 0.4195  lr: 7.7653e-05  max_mem: 18490M
[01/24 12:44:15] d2.utils.events INFO:  eta: 1 day, 6:28:31  iter: 14719  total_loss: 44.35  loss_ce: 1.695  loss_mask: 2.827  loss_ce_0: 1.08  loss_mask_0: 3.51  loss_ce_1: 1.074  loss_mask_1: 3.343  loss_ce_2: 1.179  loss_mask_2: 3.054  loss_ce_3: 1.26  loss_mask_3: 2.997  loss_ce_4: 1.452  loss_mask_4: 2.884  loss_ce_5: 1.736  loss_mask_5: 2.816  loss_ce_6: 1.756  loss_mask_6: 2.778  loss_ce_7: 1.724  loss_mask_7: 2.714  loss_ce_8: 1.686  loss_mask_8: 2.755  time: 2.4383  data_time: 0.4017  lr: 7.7623e-05  max_mem: 18490M
[01/24 12:45:06] d2.utils.events INFO:  eta: 1 day, 6:28:53  iter: 14739  total_loss: 46.61  loss_ce: 1.698  loss_mask: 3.018  loss_ce_0: 1.068  loss_mask_0: 3.791  loss_ce_1: 1.027  loss_mask_1: 3.572  loss_ce_2: 1.163  loss_mask_2: 3.417  loss_ce_3: 1.247  loss_mask_3: 3.172  loss_ce_4: 1.46  loss_mask_4: 3.077  loss_ce_5: 1.717  loss_mask_5: 2.985  loss_ce_6: 1.718  loss_mask_6: 2.913  loss_ce_7: 1.731  loss_mask_7: 2.963  loss_ce_8: 1.703  loss_mask_8: 3.009  time: 2.4384  data_time: 0.4146  lr: 7.7592e-05  max_mem: 18490M
[01/24 12:45:52] d2.utils.events INFO:  eta: 1 day, 6:23:36  iter: 14759  total_loss: 44.77  loss_ce: 1.698  loss_mask: 2.928  loss_ce_0: 1.139  loss_mask_0: 3.462  loss_ce_1: 1.081  loss_mask_1: 3.254  loss_ce_2: 1.153  loss_mask_2: 3.16  loss_ce_3: 1.25  loss_mask_3: 3.119  loss_ce_4: 1.437  loss_mask_4: 3.009  loss_ce_5: 1.719  loss_mask_5: 2.872  loss_ce_6: 1.709  loss_mask_6: 2.863  loss_ce_7: 1.731  loss_mask_7: 2.846  loss_ce_8: 1.686  loss_mask_8: 2.866  time: 2.4382  data_time: 0.3802  lr: 7.7561e-05  max_mem: 18490M
[01/24 12:46:38] d2.utils.events INFO:  eta: 1 day, 6:22:01  iter: 14779  total_loss: 45.28  loss_ce: 1.7  loss_mask: 2.894  loss_ce_0: 1.166  loss_mask_0: 3.607  loss_ce_1: 1.127  loss_mask_1: 3.42  loss_ce_2: 1.164  loss_mask_2: 3.185  loss_ce_3: 1.247  loss_mask_3: 3.041  loss_ce_4: 1.482  loss_mask_4: 2.888  loss_ce_5: 1.735  loss_mask_5: 2.862  loss_ce_6: 1.727  loss_mask_6: 2.906  loss_ce_7: 1.703  loss_mask_7: 2.858  loss_ce_8: 1.661  loss_mask_8: 2.86  time: 2.4380  data_time: 0.3977  lr: 7.753e-05  max_mem: 18490M
[01/24 12:47:31] d2.utils.events INFO:  eta: 1 day, 6:26:53  iter: 14799  total_loss: 46.18  loss_ce: 1.703  loss_mask: 2.984  loss_ce_0: 1.069  loss_mask_0: 3.572  loss_ce_1: 1.074  loss_mask_1: 3.48  loss_ce_2: 1.163  loss_mask_2: 3.409  loss_ce_3: 1.264  loss_mask_3: 3.217  loss_ce_4: 1.488  loss_mask_4: 3.011  loss_ce_5: 1.739  loss_mask_5: 2.892  loss_ce_6: 1.679  loss_mask_6: 2.859  loss_ce_7: 1.718  loss_mask_7: 2.914  loss_ce_8: 1.691  loss_mask_8: 2.924  time: 2.4383  data_time: 0.4971  lr: 7.7499e-05  max_mem: 18490M
[01/24 12:48:18] d2.utils.events INFO:  eta: 1 day, 6:20:46  iter: 14819  total_loss: 45.93  loss_ce: 1.697  loss_mask: 3.068  loss_ce_0: 1.058  loss_mask_0: 3.701  loss_ce_1: 1.007  loss_mask_1: 3.494  loss_ce_2: 1.102  loss_mask_2: 3.344  loss_ce_3: 1.195  loss_mask_3: 3.165  loss_ce_4: 1.455  loss_mask_4: 3.117  loss_ce_5: 1.707  loss_mask_5: 2.913  loss_ce_6: 1.71  loss_mask_6: 2.997  loss_ce_7: 1.692  loss_mask_7: 2.933  loss_ce_8: 1.664  loss_mask_8: 2.979  time: 2.4382  data_time: 0.3610  lr: 7.7468e-05  max_mem: 18490M
[01/24 12:49:04] d2.utils.events INFO:  eta: 1 day, 6:20:59  iter: 14839  total_loss: 45.09  loss_ce: 1.669  loss_mask: 2.936  loss_ce_0: 1.077  loss_mask_0: 3.583  loss_ce_1: 0.9803  loss_mask_1: 3.405  loss_ce_2: 1.084  loss_mask_2: 3.283  loss_ce_3: 1.178  loss_mask_3: 3.188  loss_ce_4: 1.457  loss_mask_4: 3.031  loss_ce_5: 1.701  loss_mask_5: 2.85  loss_ce_6: 1.708  loss_mask_6: 2.934  loss_ce_7: 1.681  loss_mask_7: 2.845  loss_ce_8: 1.659  loss_mask_8: 2.852  time: 2.4380  data_time: 0.3805  lr: 7.7437e-05  max_mem: 18490M
[01/24 12:49:56] d2.utils.events INFO:  eta: 1 day, 6:24:53  iter: 14859  total_loss: 44.59  loss_ce: 1.619  loss_mask: 2.821  loss_ce_0: 1.107  loss_mask_0: 3.553  loss_ce_1: 1.006  loss_mask_1: 3.312  loss_ce_2: 1.088  loss_mask_2: 3.144  loss_ce_3: 1.222  loss_mask_3: 3.1  loss_ce_4: 1.462  loss_mask_4: 2.902  loss_ce_5: 1.679  loss_mask_5: 2.851  loss_ce_6: 1.687  loss_mask_6: 2.843  loss_ce_7: 1.684  loss_mask_7: 2.839  loss_ce_8: 1.633  loss_mask_8: 2.838  time: 2.4382  data_time: 0.4629  lr: 7.7407e-05  max_mem: 18490M
[01/24 12:50:42] d2.utils.events INFO:  eta: 1 day, 6:20:39  iter: 14879  total_loss: 44.68  loss_ce: 1.647  loss_mask: 2.905  loss_ce_0: 1.131  loss_mask_0: 3.626  loss_ce_1: 0.984  loss_mask_1: 3.399  loss_ce_2: 1.068  loss_mask_2: 3.303  loss_ce_3: 1.185  loss_mask_3: 3.103  loss_ce_4: 1.441  loss_mask_4: 2.922  loss_ce_5: 1.686  loss_mask_5: 2.861  loss_ce_6: 1.683  loss_mask_6: 2.83  loss_ce_7: 1.699  loss_mask_7: 2.861  loss_ce_8: 1.657  loss_mask_8: 2.857  time: 2.4380  data_time: 0.4213  lr: 7.7376e-05  max_mem: 18490M
[01/24 12:51:29] d2.utils.events INFO:  eta: 1 day, 6:19:27  iter: 14899  total_loss: 44.61  loss_ce: 1.654  loss_mask: 2.83  loss_ce_0: 1.122  loss_mask_0: 3.556  loss_ce_1: 1.013  loss_mask_1: 3.359  loss_ce_2: 1.084  loss_mask_2: 3.23  loss_ce_3: 1.19  loss_mask_3: 3.107  loss_ce_4: 1.428  loss_mask_4: 2.954  loss_ce_5: 1.689  loss_mask_5: 2.853  loss_ce_6: 1.685  loss_mask_6: 2.809  loss_ce_7: 1.72  loss_mask_7: 2.777  loss_ce_8: 1.658  loss_mask_8: 2.794  time: 2.4379  data_time: 0.3708  lr: 7.7345e-05  max_mem: 18490M
[01/24 12:52:14] d2.utils.events INFO:  eta: 1 day, 6:15:54  iter: 14919  total_loss: 44.75  loss_ce: 1.601  loss_mask: 2.84  loss_ce_0: 1.104  loss_mask_0: 3.605  loss_ce_1: 1.04  loss_mask_1: 3.315  loss_ce_2: 1.101  loss_mask_2: 3.239  loss_ce_3: 1.225  loss_mask_3: 3.171  loss_ce_4: 1.439  loss_mask_4: 2.982  loss_ce_5: 1.667  loss_mask_5: 2.821  loss_ce_6: 1.67  loss_mask_6: 2.859  loss_ce_7: 1.704  loss_mask_7: 2.81  loss_ce_8: 1.636  loss_mask_8: 2.809  time: 2.4376  data_time: 0.3779  lr: 7.7314e-05  max_mem: 18490M
[01/24 12:52:59] d2.utils.events INFO:  eta: 1 day, 6:13:00  iter: 14939  total_loss: 42.77  loss_ce: 1.584  loss_mask: 2.806  loss_ce_0: 0.9805  loss_mask_0: 3.274  loss_ce_1: 0.9045  loss_mask_1: 3.2  loss_ce_2: 1.009  loss_mask_2: 2.926  loss_ce_3: 1.183  loss_mask_3: 2.94  loss_ce_4: 1.411  loss_mask_4: 2.813  loss_ce_5: 1.663  loss_mask_5: 2.745  loss_ce_6: 1.678  loss_mask_6: 2.748  loss_ce_7: 1.69  loss_mask_7: 2.804  loss_ce_8: 1.636  loss_mask_8: 2.81  time: 2.4374  data_time: 0.4192  lr: 7.7283e-05  max_mem: 18490M
[01/24 12:53:45] d2.utils.events INFO:  eta: 1 day, 6:10:11  iter: 14959  total_loss: 44.48  loss_ce: 1.618  loss_mask: 2.902  loss_ce_0: 1.078  loss_mask_0: 3.497  loss_ce_1: 0.9673  loss_mask_1: 3.461  loss_ce_2: 1.038  loss_mask_2: 3.248  loss_ce_3: 1.159  loss_mask_3: 3.207  loss_ce_4: 1.412  loss_mask_4: 2.943  loss_ce_5: 1.719  loss_mask_5: 2.862  loss_ce_6: 1.703  loss_mask_6: 2.877  loss_ce_7: 1.723  loss_mask_7: 2.849  loss_ce_8: 1.651  loss_mask_8: 2.848  time: 2.4372  data_time: 0.4024  lr: 7.7252e-05  max_mem: 18490M
[01/24 12:54:29] d2.utils.events INFO:  eta: 1 day, 6:07:02  iter: 14979  total_loss: 44.81  loss_ce: 1.612  loss_mask: 2.885  loss_ce_0: 1.084  loss_mask_0: 3.436  loss_ce_1: 1.021  loss_mask_1: 3.295  loss_ce_2: 1.184  loss_mask_2: 3.181  loss_ce_3: 1.281  loss_mask_3: 3.186  loss_ce_4: 1.455  loss_mask_4: 2.99  loss_ce_5: 1.732  loss_mask_5: 2.911  loss_ce_6: 1.688  loss_mask_6: 2.869  loss_ce_7: 1.705  loss_mask_7: 2.779  loss_ce_8: 1.638  loss_mask_8: 2.816  time: 2.4369  data_time: 0.3672  lr: 7.7221e-05  max_mem: 18490M
[01/24 12:55:15] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1/model_0014999.pth
[01/24 12:55:15] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 12:55:16] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 12:55:16] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 12:59:29] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 7.542303399984461, 'error_1pix': 0.7642870606782899, 'error_3pix': 0.6022321380254558, 'mIoU': 0.9976043216405325, 'fwIoU': 6.114607645429112, 'IoU-0': nan, 'IoU-1': 44.994814519483434, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 3.0780281262875313, 'IoU-13': 0.07324545286241779, 'IoU-14': 2.416365996019875, 'IoU-15': 0.22162286183417024, 'IoU-16': 0.2806127954161784, 'IoU-17': 1.649572129464116, 'IoU-18': 2.722334398736143, 'IoU-19': 0.062401433621858834, 'IoU-20': 0.4181699190444256, 'IoU-21': 2.680948975355785, 'IoU-22': 5.516407949716666, 'IoU-23': 1.5299537549486695, 'IoU-24': 1.8242523628525509, 'IoU-25': 2.275246113143407, 'IoU-26': 0.4741124300890325, 'IoU-27': 3.992228417770206, 'IoU-28': 5.692616146454613, 'IoU-29': 0.2803628954172449, 'IoU-30': 1.0563384509018157, 'IoU-31': 1.1870610634994343, 'IoU-32': 0.49288406776035465, 'IoU-33': 4.7327846616868285, 'IoU-34': 0.1490319643389582, 'IoU-35': 2.3841495729145104, 'IoU-36': 5.0114480977874, 'IoU-37': 6.315705928081688, 'IoU-38': 7.17859629728003e-05, 'IoU-39': 5.297378416049601, 'IoU-40': 2.674709066425562, 'IoU-41': 0.004041380902008509, 'IoU-42': 0.32635724697888546, 'IoU-43': 6.257438787284118, 'IoU-44': 0.3843728142863658, 'IoU-45': 0.04538303850845208, 'IoU-46': 1.1714988743226618, 'IoU-47': 5.835217254307606, 'IoU-48': 1.5174641460922467, 'IoU-49': 0.03473541936098351, 'IoU-50': 4.054695881810648, 'IoU-51': 4.05165426470501, 'IoU-52': 0.04925128372245853, 'IoU-53': 1.2838093077178874, 'IoU-54': 1.6952190896566564, 'IoU-55': 0.0016414417030465455, 'IoU-56': 0.00036233572286326337, 'IoU-57': 0.001068644198152541, 'IoU-58': 0.02344067537323612, 'IoU-59': 3.9988166306411568, 'IoU-60': 0.004423694187659405, 'IoU-61': 1.4060847589656542, 'IoU-62': 0.019651309674273434, 'IoU-63': 1.0996261634393294, 'IoU-64': 0.024548570987393187, 'IoU-65': 1.9015751001404735, 'IoU-66': 2.9408066915761495, 'IoU-67': 0.06489661902519185, 'IoU-68': 0.008601471516581, 'IoU-69': 1.2238572292106449, 'IoU-70': 0.024674584364656568, 'IoU-71': 0.7734597277011018, 'IoU-72': 0.9632493916188006, 'IoU-73': 0.013662746560238278, 'IoU-74': 2.759472381660811, 'IoU-75': 0.0006217649135223178, 'IoU-76': 2.8831945987316705, 'IoU-77': 0.39573904498459, 'IoU-78': 0.014810247015966635, 'IoU-79': 2.9959579010193664, 'IoU-80': 0.7724447518369857, 'IoU-81': 0.106774620119304, 'IoU-82': 0.03740071889862845, 'IoU-83': 0.014740844495548792, 'IoU-84': 0.09004968204776016, 'IoU-85': 0.027690438656452075, 'IoU-86': 0.2795846294687169, 'IoU-87': 1.0079497151795276, 'IoU-88': 0.05852362022281331, 'IoU-89': 1.7994968563692881, 'IoU-90': 3.367254946247956, 'IoU-91': 0.0, 'IoU-92': 0.00028434860000966784, 'IoU-93': 2.86506944855534, 'IoU-94': 0.0049389682480226, 'IoU-95': 2.5597726212336944, 'IoU-96': 2.0834685720476878, 'IoU-97': 0.00011981933298631372, 'IoU-98': 0.0, 'IoU-99': 0.033804153086677044, 'IoU-100': 1.3599682683281864, 'IoU-101': 0.0, 'IoU-102': 2.5422710686993795, 'IoU-103': 0.7090669911556376, 'IoU-104': 0.0, 'IoU-105': 0.0025753835154035984, 'IoU-106': 0.29401819118198674, 'IoU-107': 0.5980945838090138, 'IoU-108': 0.025351317866977058, 'IoU-109': 2.412887080716124, 'IoU-110': 0.0, 'IoU-111': 0.0005315835686893526, 'IoU-112': 1.3935753481362534, 'IoU-113': 0.0011433358590661857, 'IoU-114': 0.21249890072991534, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 1.4852279897838958, 'IoU-118': 0.00045973129959351396, 'IoU-119': 0.36421491690137814, 'IoU-120': 0.006915572529444131, 'IoU-121': 0.6889619943671602, 'IoU-122': 0.0001414387812880264, 'IoU-123': 0.0, 'IoU-124': 0.003692491344142722, 'IoU-125': 0.17273431523216629, 'IoU-126': 0.7662603458392843, 'IoU-127': 0.0002918169280665436, 'IoU-128': 0.0, 'IoU-129': 0.00012545209799816087, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.00034014091357767695, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0008177009964801689, 'IoU-138': 0.00039643871176447737, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.018784211950130324, 'IoU-142': 0.0, 'IoU-143': 0.0013450598641310196, 'IoU-144': 0.0, 'IoU-145': 1.5263312329963183, 'IoU-146': 9.117282903818135e-05, 'IoU-147': 0.0004630384210760272, 'IoU-148': 0.0, 'IoU-149': 0.0006084112860293558, 'IoU-150': 0.2314319577842078, 'IoU-151': 0.07589143357270312, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0003510430659633324, 'IoU-155': 0.0, 'IoU-156': 0.126251431411506, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.006999256125569911, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 1.6593080832193223, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 3.2033261429034248, 'pACC': 14.587961821435592, 'ACC-0': nan, 'ACC-1': 99.56233323339552, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 5.341911652380041, 'ACC-13': 0.07379000762102486, 'ACC-14': 3.2194702948346823, 'ACC-15': 0.22617292874544317, 'ACC-16': 0.2920114618212896, 'ACC-17': 2.033279968496776, 'ACC-18': 3.3599994985636683, 'ACC-19': 0.0628869890057978, 'ACC-20': 0.429636539742473, 'ACC-21': 3.583702412281568, 'ACC-22': 12.333553010376058, 'ACC-23': 2.0150241537118005, 'ACC-24': 3.0425606144732384, 'ACC-25': 2.9479837489902936, 'ACC-26': 0.5024764838566703, 'ACC-27': 18.59586545079195, 'ACC-28': 15.512442534140892, 'ACC-29': 0.2950543931853094, 'ACC-30': 1.226810037186724, 'ACC-31': 1.5711064743972898, 'ACC-32': 0.5239143661816893, 'ACC-33': 23.06772643541948, 'ACC-34': 0.15133336466433897, 'ACC-35': 3.4182205900182185, 'ACC-36': 12.708451941126835, 'ACC-37': 19.96883406849664, 'ACC-38': 7.184009200129542e-05, 'ACC-39': 18.959425371838527, 'ACC-40': 4.411191445651834, 'ACC-41': 0.004049741525924322, 'ACC-42': 0.39018892355545876, 'ACC-43': 33.02986004314178, 'ACC-44': 0.40972398689170053, 'ACC-45': 0.04548418654464998, 'ACC-46': 1.5547169656029516, 'ACC-47': 40.905326015235296, 'ACC-48': 2.06794332815017, 'ACC-49': 0.035037229951242546, 'ACC-50': 7.609102197118764, 'ACC-51': 7.858177564172952, 'ACC-52': 0.04947561182104953, 'ACC-53': 1.548122698999239, 'ACC-54': 2.1962458614984466, 'ACC-55': 0.0016450426403336763, 'ACC-56': 0.0003623724178899067, 'ACC-57': 0.0010690362903481832, 'ACC-58': 0.02350892854421687, 'ACC-59': 15.918732990141896, 'ACC-60': 0.004436281265915751, 'ACC-61': 2.1638962268686694, 'ACC-62': 0.019733295572521438, 'ACC-63': 1.4737326740124574, 'ACC-64': 0.024914157888625915, 'ACC-65': 5.99687321793948, 'ACC-66': 12.567859933091608, 'ACC-67': 0.06962926253078087, 'ACC-68': 0.00865130194003828, 'ACC-69': 2.068617659560563, 'ACC-70': 0.025056562595444747, 'ACC-71': 1.1527492864849191, 'ACC-72': 3.2813130597703055, 'ACC-73': 0.013701239608604202, 'ACC-74': 11.627425155662346, 'ACC-75': 0.000622448099294668, 'ACC-76': 24.151694577428483, 'ACC-77': 0.45658192548630133, 'ACC-78': 0.014907582968352666, 'ACC-79': 11.280463321271805, 'ACC-80': 1.0354263868743374, 'ACC-81': 0.1131391430853934, 'ACC-82': 0.0391090076955636, 'ACC-83': 0.01589301552050906, 'ACC-84': 0.09208333933498794, 'ACC-85': 0.027785840030403564, 'ACC-86': 0.39894769733194907, 'ACC-87': 1.7830401423525162, 'ACC-88': 0.05904646371005346, 'ACC-89': 3.9675694943525164, 'ACC-90': 28.387235530377403, 'ACC-91': 0.0, 'ACC-92': 0.0002843979700241696, 'ACC-93': 16.09280086318162, 'ACC-94': 0.004972010772385908, 'ACC-95': 11.596362880860267, 'ACC-96': 5.991654439089346, 'ACC-97': 0.00011984600131248491, 'ACC-98': 0.0, 'ACC-99': 0.03716039793058816, 'ACC-100': 3.89120275198334, 'ACC-101': 0.0, 'ACC-102': 8.428001812415042, 'ACC-103': 0.964036081987343, 'ACC-104': 0.0, 'ACC-105': 0.002579458165657911, 'ACC-106': 0.37141372956391927, 'ACC-107': 0.8372169932422142, 'ACC-108': 0.026171593347053844, 'ACC-109': 12.982708300554371, 'ACC-110': 0.0, 'ACC-111': 0.0005327682229453245, 'ACC-112': 4.873913858765104, 'ACC-113': 0.0011443611603822166, 'ACC-114': 0.3874639804635355, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 35.22671291388839, 'ACC-118': 0.0004618555592923869, 'ACC-119': 0.5449195101771921, 'ACC-120': 0.007027974853905972, 'ACC-121': 1.9807624088912426, 'ACC-122': 0.00014152679102154037, 'ACC-123': 0.0, 'ACC-124': 0.0038889756065336924, 'ACC-125': 0.19475441147838232, 'ACC-126': 2.2061904024626817, 'ACC-127': 0.00029203151136820266, 'ACC-128': 0.0, 'ACC-129': 0.00012550523701977773, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0003402124286404431, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0008395555850672065, 'ACC-138': 0.00039660380231997357, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.019692361551758093, 'ACC-142': 0.0, 'ACC-143': 0.0013478869176791544, 'ACC-144': 0.0, 'ACC-145': 4.0060824258145304, 'ACC-146': 9.138470676932215e-05, 'ACC-147': 0.0004642598815394486, 'ACC-148': 0.0, 'ACC-149': 0.0006084766887509901, 'ACC-150': 0.29653672208620097, 'ACC-151': 0.08345030230751277, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0003522503513697255, 'ACC-155': 0.0, 'ACC-156': 0.13069867556089898, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.007218943851726251, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 18.42733206734469, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 12:59:29] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 12:59:29] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 12:59:29] d2.evaluation.testing INFO: copypaste: 7.5423,0.7643,0.6022,0.9976,6.1146,3.2033,14.5880
[01/24 12:59:29] d2.utils.events INFO:  eta: 1 day, 6:02:47  iter: 14999  total_loss: 45.27  loss_ce: 1.657  loss_mask: 2.938  loss_ce_0: 1.041  loss_mask_0: 3.652  loss_ce_1: 0.9657  loss_mask_1: 3.469  loss_ce_2: 1.101  loss_mask_2: 3.275  loss_ce_3: 1.198  loss_mask_3: 3.254  loss_ce_4: 1.411  loss_mask_4: 3.014  loss_ce_5: 1.684  loss_mask_5: 2.951  loss_ce_6: 1.667  loss_mask_6: 2.909  loss_ce_7: 1.673  loss_mask_7: 2.909  loss_ce_8: 1.629  loss_mask_8: 2.895  time: 2.4367  data_time: 0.3694  lr: 7.719e-05  max_mem: 18490M
[01/24 13:00:16] d2.utils.events INFO:  eta: 1 day, 6:00:05  iter: 15019  total_loss: 44.33  loss_ce: 1.613  loss_mask: 2.921  loss_ce_0: 1.05  loss_mask_0: 3.55  loss_ce_1: 0.9556  loss_mask_1: 3.325  loss_ce_2: 1.069  loss_mask_2: 3.204  loss_ce_3: 1.155  loss_mask_3: 3.119  loss_ce_4: 1.388  loss_mask_4: 2.938  loss_ce_5: 1.704  loss_mask_5: 2.814  loss_ce_6: 1.648  loss_mask_6: 2.806  loss_ce_7: 1.701  loss_mask_7: 2.759  loss_ce_8: 1.638  loss_mask_8: 2.858  time: 2.4366  data_time: 0.4224  lr: 7.716e-05  max_mem: 18490M
[01/24 13:01:06] d2.utils.events INFO:  eta: 1 day, 5:59:49  iter: 15039  total_loss: 42.97  loss_ce: 1.562  loss_mask: 2.732  loss_ce_0: 1.114  loss_mask_0: 3.339  loss_ce_1: 1.009  loss_mask_1: 3.173  loss_ce_2: 1.104  loss_mask_2: 3.082  loss_ce_3: 1.174  loss_mask_3: 3.004  loss_ce_4: 1.376  loss_mask_4: 2.837  loss_ce_5: 1.659  loss_mask_5: 2.74  loss_ce_6: 1.617  loss_mask_6: 2.683  loss_ce_7: 1.649  loss_mask_7: 2.616  loss_ce_8: 1.602  loss_mask_8: 2.758  time: 2.4367  data_time: 0.4487  lr: 7.7129e-05  max_mem: 18490M
[01/24 13:01:53] d2.utils.events INFO:  eta: 1 day, 5:54:11  iter: 15059  total_loss: 45.22  loss_ce: 1.619  loss_mask: 2.865  loss_ce_0: 1.07  loss_mask_0: 3.694  loss_ce_1: 0.9749  loss_mask_1: 3.522  loss_ce_2: 1.078  loss_mask_2: 3.382  loss_ce_3: 1.16  loss_mask_3: 3.319  loss_ce_4: 1.381  loss_mask_4: 3.007  loss_ce_5: 1.695  loss_mask_5: 2.901  loss_ce_6: 1.659  loss_mask_6: 2.866  loss_ce_7: 1.702  loss_mask_7: 2.854  loss_ce_8: 1.674  loss_mask_8: 2.847  time: 2.4365  data_time: 0.3985  lr: 7.7098e-05  max_mem: 18490M
[01/24 13:02:40] d2.utils.events INFO:  eta: 1 day, 5:52:29  iter: 15079  total_loss: 44.76  loss_ce: 1.592  loss_mask: 2.896  loss_ce_0: 1.077  loss_mask_0: 3.502  loss_ce_1: 0.955  loss_mask_1: 3.314  loss_ce_2: 1.06  loss_mask_2: 3.191  loss_ce_3: 1.137  loss_mask_3: 3.169  loss_ce_4: 1.374  loss_mask_4: 3.053  loss_ce_5: 1.726  loss_mask_5: 2.872  loss_ce_6: 1.673  loss_mask_6: 2.885  loss_ce_7: 1.682  loss_mask_7: 2.9  loss_ce_8: 1.643  loss_mask_8: 2.872  time: 2.4364  data_time: 0.3831  lr: 7.7067e-05  max_mem: 18490M
[01/24 13:03:31] d2.utils.events INFO:  eta: 1 day, 5:55:11  iter: 15099  total_loss: 43.96  loss_ce: 1.623  loss_mask: 2.874  loss_ce_0: 1.041  loss_mask_0: 3.487  loss_ce_1: 0.8947  loss_mask_1: 3.344  loss_ce_2: 0.9859  loss_mask_2: 3.246  loss_ce_3: 1.085  loss_mask_3: 3.217  loss_ce_4: 1.335  loss_mask_4: 2.99  loss_ce_5: 1.684  loss_mask_5: 2.815  loss_ce_6: 1.643  loss_mask_6: 2.782  loss_ce_7: 1.679  loss_mask_7: 2.82  loss_ce_8: 1.623  loss_mask_8: 2.861  time: 2.4366  data_time: 0.4801  lr: 7.7036e-05  max_mem: 18490M
[01/24 13:04:19] d2.utils.events INFO:  eta: 1 day, 5:51:08  iter: 15119  total_loss: 42.13  loss_ce: 1.55  loss_mask: 2.706  loss_ce_0: 1.034  loss_mask_0: 3.249  loss_ce_1: 0.9098  loss_mask_1: 3.165  loss_ce_2: 1  loss_mask_2: 3.036  loss_ce_3: 1.091  loss_mask_3: 2.969  loss_ce_4: 1.329  loss_mask_4: 2.803  loss_ce_5: 1.641  loss_mask_5: 2.712  loss_ce_6: 1.615  loss_mask_6: 2.677  loss_ce_7: 1.636  loss_mask_7: 2.657  loss_ce_8: 1.584  loss_mask_8: 2.623  time: 2.4365  data_time: 0.4263  lr: 7.7005e-05  max_mem: 18490M
[01/24 13:05:06] d2.utils.events INFO:  eta: 1 day, 5:50:05  iter: 15139  total_loss: 42.77  loss_ce: 1.558  loss_mask: 2.808  loss_ce_0: 1.073  loss_mask_0: 3.391  loss_ce_1: 0.8886  loss_mask_1: 3.238  loss_ce_2: 1.01  loss_mask_2: 3.09  loss_ce_3: 1.126  loss_mask_3: 2.983  loss_ce_4: 1.32  loss_mask_4: 2.882  loss_ce_5: 1.653  loss_mask_5: 2.751  loss_ce_6: 1.617  loss_mask_6: 2.758  loss_ce_7: 1.631  loss_mask_7: 2.751  loss_ce_8: 1.596  loss_mask_8: 2.769  time: 2.4364  data_time: 0.4032  lr: 7.6974e-05  max_mem: 18490M
[01/24 13:05:56] d2.utils.events INFO:  eta: 1 day, 5:49:17  iter: 15159  total_loss: 43.62  loss_ce: 1.596  loss_mask: 2.798  loss_ce_0: 1.072  loss_mask_0: 3.437  loss_ce_1: 0.9194  loss_mask_1: 3.292  loss_ce_2: 1.035  loss_mask_2: 3.242  loss_ce_3: 1.141  loss_mask_3: 3.131  loss_ce_4: 1.329  loss_mask_4: 2.967  loss_ce_5: 1.675  loss_mask_5: 2.852  loss_ce_6: 1.651  loss_mask_6: 2.879  loss_ce_7: 1.678  loss_mask_7: 2.778  loss_ce_8: 1.608  loss_mask_8: 2.77  time: 2.4364  data_time: 0.4481  lr: 7.6943e-05  max_mem: 18490M
[01/24 13:06:42] d2.utils.events INFO:  eta: 1 day, 5:44:21  iter: 15179  total_loss: 42.71  loss_ce: 1.581  loss_mask: 2.739  loss_ce_0: 1.036  loss_mask_0: 3.386  loss_ce_1: 0.8965  loss_mask_1: 3.284  loss_ce_2: 1.006  loss_mask_2: 3.136  loss_ce_3: 1.082  loss_mask_3: 2.987  loss_ce_4: 1.283  loss_mask_4: 2.898  loss_ce_5: 1.658  loss_mask_5: 2.805  loss_ce_6: 1.63  loss_mask_6: 2.775  loss_ce_7: 1.626  loss_mask_7: 2.705  loss_ce_8: 1.579  loss_mask_8: 2.697  time: 2.4363  data_time: 0.3964  lr: 7.6913e-05  max_mem: 18490M
[01/24 13:07:31] d2.utils.events INFO:  eta: 1 day, 5:41:49  iter: 15199  total_loss: 44.03  loss_ce: 1.591  loss_mask: 2.849  loss_ce_0: 1.034  loss_mask_0: 3.479  loss_ce_1: 0.896  loss_mask_1: 3.445  loss_ce_2: 1.033  loss_mask_2: 3.248  loss_ce_3: 1.098  loss_mask_3: 3.195  loss_ce_4: 1.317  loss_mask_4: 2.931  loss_ce_5: 1.686  loss_mask_5: 2.867  loss_ce_6: 1.636  loss_mask_6: 2.924  loss_ce_7: 1.639  loss_mask_7: 2.805  loss_ce_8: 1.599  loss_mask_8: 2.853  time: 2.4363  data_time: 0.4229  lr: 7.6882e-05  max_mem: 18490M
[01/24 13:08:21] d2.utils.events INFO:  eta: 1 day, 5:40:14  iter: 15219  total_loss: 44.75  loss_ce: 1.594  loss_mask: 2.908  loss_ce_0: 1.059  loss_mask_0: 3.606  loss_ce_1: 0.9262  loss_mask_1: 3.351  loss_ce_2: 1.004  loss_mask_2: 3.266  loss_ce_3: 1.087  loss_mask_3: 3.203  loss_ce_4: 1.331  loss_mask_4: 3.059  loss_ce_5: 1.655  loss_mask_5: 2.98  loss_ce_6: 1.645  loss_mask_6: 2.941  loss_ce_7: 1.655  loss_mask_7: 2.842  loss_ce_8: 1.613  loss_mask_8: 2.879  time: 2.4364  data_time: 0.4376  lr: 7.6851e-05  max_mem: 18490M
[01/24 13:09:07] d2.utils.events INFO:  eta: 1 day, 5:36:12  iter: 15239  total_loss: 44.33  loss_ce: 1.593  loss_mask: 2.858  loss_ce_0: 1.168  loss_mask_0: 3.463  loss_ce_1: 0.9971  loss_mask_1: 3.356  loss_ce_2: 1.045  loss_mask_2: 3.155  loss_ce_3: 1.122  loss_mask_3: 3.081  loss_ce_4: 1.335  loss_mask_4: 3.051  loss_ce_5: 1.641  loss_mask_5: 2.861  loss_ce_6: 1.629  loss_mask_6: 2.855  loss_ce_7: 1.647  loss_mask_7: 2.784  loss_ce_8: 1.613  loss_mask_8: 2.822  time: 2.4362  data_time: 0.3854  lr: 7.682e-05  max_mem: 18490M
[01/24 13:09:56] d2.utils.events INFO:  eta: 1 day, 5:35:25  iter: 15259  total_loss: 44.57  loss_ce: 1.589  loss_mask: 2.923  loss_ce_0: 1.102  loss_mask_0: 3.536  loss_ce_1: 0.9319  loss_mask_1: 3.353  loss_ce_2: 0.9743  loss_mask_2: 3.27  loss_ce_3: 1.095  loss_mask_3: 3.181  loss_ce_4: 1.316  loss_mask_4: 3.039  loss_ce_5: 1.647  loss_mask_5: 2.912  loss_ce_6: 1.635  loss_mask_6: 2.828  loss_ce_7: 1.637  loss_mask_7: 2.803  loss_ce_8: 1.604  loss_mask_8: 2.787  time: 2.4363  data_time: 0.4113  lr: 7.6789e-05  max_mem: 18490M
[01/24 13:10:43] d2.utils.events INFO:  eta: 1 day, 5:32:33  iter: 15279  total_loss: 42.8  loss_ce: 1.596  loss_mask: 2.852  loss_ce_0: 1.12  loss_mask_0: 3.327  loss_ce_1: 0.9389  loss_mask_1: 3.337  loss_ce_2: 1.021  loss_mask_2: 3.111  loss_ce_3: 1.129  loss_mask_3: 2.965  loss_ce_4: 1.332  loss_mask_4: 2.879  loss_ce_5: 1.631  loss_mask_5: 2.742  loss_ce_6: 1.615  loss_mask_6: 2.682  loss_ce_7: 1.629  loss_mask_7: 2.684  loss_ce_8: 1.579  loss_mask_8: 2.74  time: 2.4361  data_time: 0.3835  lr: 7.6758e-05  max_mem: 18490M
[01/24 13:11:31] d2.utils.events INFO:  eta: 1 day, 5:30:53  iter: 15299  total_loss: 41.8  loss_ce: 1.636  loss_mask: 2.718  loss_ce_0: 1.056  loss_mask_0: 3.285  loss_ce_1: 0.9494  loss_mask_1: 3.119  loss_ce_2: 1.035  loss_mask_2: 3.051  loss_ce_3: 1.133  loss_mask_3: 2.919  loss_ce_4: 1.315  loss_mask_4: 2.749  loss_ce_5: 1.648  loss_mask_5: 2.627  loss_ce_6: 1.62  loss_mask_6: 2.59  loss_ce_7: 1.616  loss_mask_7: 2.615  loss_ce_8: 1.593  loss_mask_8: 2.597  time: 2.4360  data_time: 0.4186  lr: 7.6727e-05  max_mem: 18490M
[01/24 13:12:21] d2.utils.events INFO:  eta: 1 day, 5:31:49  iter: 15319  total_loss: 42.39  loss_ce: 1.681  loss_mask: 2.878  loss_ce_0: 1.008  loss_mask_0: 3.186  loss_ce_1: 0.8898  loss_mask_1: 3.179  loss_ce_2: 1.001  loss_mask_2: 3.059  loss_ce_3: 1.119  loss_mask_3: 2.993  loss_ce_4: 1.285  loss_mask_4: 2.86  loss_ce_5: 1.675  loss_mask_5: 2.729  loss_ce_6: 1.642  loss_mask_6: 2.682  loss_ce_7: 1.653  loss_mask_7: 2.707  loss_ce_8: 1.616  loss_mask_8: 2.725  time: 2.4361  data_time: 0.4764  lr: 7.6696e-05  max_mem: 18490M
[01/24 13:13:08] d2.utils.events INFO:  eta: 1 day, 5:27:22  iter: 15339  total_loss: 43.4  loss_ce: 1.707  loss_mask: 2.987  loss_ce_0: 1.054  loss_mask_0: 3.379  loss_ce_1: 0.9012  loss_mask_1: 3.321  loss_ce_2: 0.9845  loss_mask_2: 3.212  loss_ce_3: 1.112  loss_mask_3: 3.087  loss_ce_4: 1.3  loss_mask_4: 3.015  loss_ce_5: 1.696  loss_mask_5: 2.815  loss_ce_6: 1.666  loss_mask_6: 2.811  loss_ce_7: 1.696  loss_mask_7: 2.763  loss_ce_8: 1.634  loss_mask_8: 2.889  time: 2.4360  data_time: 0.4034  lr: 7.6665e-05  max_mem: 18490M
[01/24 13:13:54] d2.utils.events INFO:  eta: 1 day, 5:26:23  iter: 15359  total_loss: 42.59  loss_ce: 1.733  loss_mask: 2.956  loss_ce_0: 1.048  loss_mask_0: 3.355  loss_ce_1: 0.9082  loss_mask_1: 3.059  loss_ce_2: 1.015  loss_mask_2: 2.971  loss_ce_3: 1.102  loss_mask_3: 2.939  loss_ce_4: 1.328  loss_mask_4: 2.865  loss_ce_5: 1.667  loss_mask_5: 2.691  loss_ce_6: 1.657  loss_mask_6: 2.653  loss_ce_7: 1.7  loss_mask_7: 2.66  loss_ce_8: 1.661  loss_mask_8: 2.755  time: 2.4358  data_time: 0.3896  lr: 7.6635e-05  max_mem: 18490M
[01/24 13:14:46] d2.utils.events INFO:  eta: 1 day, 5:27:20  iter: 15379  total_loss: 44.76  loss_ce: 1.705  loss_mask: 2.933  loss_ce_0: 1.043  loss_mask_0: 3.554  loss_ce_1: 0.8765  loss_mask_1: 3.296  loss_ce_2: 0.9541  loss_mask_2: 3.182  loss_ce_3: 1.058  loss_mask_3: 3.167  loss_ce_4: 1.303  loss_mask_4: 3.081  loss_ce_5: 1.665  loss_mask_5: 2.868  loss_ce_6: 1.642  loss_mask_6: 2.852  loss_ce_7: 1.679  loss_mask_7: 2.854  loss_ce_8: 1.669  loss_mask_8: 2.96  time: 2.4361  data_time: 0.4528  lr: 7.6604e-05  max_mem: 18490M
[01/24 13:15:34] d2.utils.events INFO:  eta: 1 day, 5:24:48  iter: 15399  total_loss: 44.35  loss_ce: 1.68  loss_mask: 2.885  loss_ce_0: 1.128  loss_mask_0: 3.546  loss_ce_1: 0.949  loss_mask_1: 3.284  loss_ce_2: 1.034  loss_mask_2: 3.199  loss_ce_3: 1.158  loss_mask_3: 3.158  loss_ce_4: 1.446  loss_mask_4: 3.1  loss_ce_5: 1.729  loss_mask_5: 2.927  loss_ce_6: 1.671  loss_mask_6: 2.813  loss_ce_7: 1.664  loss_mask_7: 2.835  loss_ce_8: 1.648  loss_mask_8: 2.807  time: 2.4360  data_time: 0.4332  lr: 7.6573e-05  max_mem: 18490M
[01/24 13:16:21] d2.utils.events INFO:  eta: 1 day, 5:23:12  iter: 15419  total_loss: 44.31  loss_ce: 1.679  loss_mask: 3.004  loss_ce_0: 1.077  loss_mask_0: 3.482  loss_ce_1: 0.8933  loss_mask_1: 3.16  loss_ce_2: 0.991  loss_mask_2: 3.093  loss_ce_3: 1.156  loss_mask_3: 3.062  loss_ce_4: 1.426  loss_mask_4: 3.08  loss_ce_5: 1.717  loss_mask_5: 2.848  loss_ce_6: 1.69  loss_mask_6: 2.779  loss_ce_7: 1.641  loss_mask_7: 2.832  loss_ce_8: 1.652  loss_mask_8: 2.849  time: 2.4359  data_time: 0.3970  lr: 7.6542e-05  max_mem: 18490M
[01/24 13:17:14] d2.utils.events INFO:  eta: 1 day, 5:24:57  iter: 15439  total_loss: 43.51  loss_ce: 1.638  loss_mask: 2.777  loss_ce_0: 1.099  loss_mask_0: 3.42  loss_ce_1: 0.9207  loss_mask_1: 3.104  loss_ce_2: 1.001  loss_mask_2: 3.083  loss_ce_3: 1.091  loss_mask_3: 3.019  loss_ce_4: 1.297  loss_mask_4: 2.96  loss_ce_5: 1.675  loss_mask_5: 2.845  loss_ce_6: 1.686  loss_mask_6: 2.77  loss_ce_7: 1.649  loss_mask_7: 2.79  loss_ce_8: 1.632  loss_mask_8: 2.779  time: 2.4361  data_time: 0.4733  lr: 7.6511e-05  max_mem: 18490M
[01/24 13:18:02] d2.utils.events INFO:  eta: 1 day, 5:23:52  iter: 15459  total_loss: 44.7  loss_ce: 1.672  loss_mask: 3.004  loss_ce_0: 1.061  loss_mask_0: 3.48  loss_ce_1: 0.9012  loss_mask_1: 3.402  loss_ce_2: 0.9875  loss_mask_2: 3.196  loss_ce_3: 1.109  loss_mask_3: 3.171  loss_ce_4: 1.34  loss_mask_4: 3.082  loss_ce_5: 1.667  loss_mask_5: 2.935  loss_ce_6: 1.64  loss_mask_6: 2.88  loss_ce_7: 1.654  loss_mask_7: 2.962  loss_ce_8: 1.674  loss_mask_8: 2.961  time: 2.4361  data_time: 0.4450  lr: 7.648e-05  max_mem: 18490M
[01/24 13:18:52] d2.utils.events INFO:  eta: 1 day, 5:24:03  iter: 15479  total_loss: 43.65  loss_ce: 1.665  loss_mask: 2.863  loss_ce_0: 1.131  loss_mask_0: 3.366  loss_ce_1: 0.9451  loss_mask_1: 3.161  loss_ce_2: 1.023  loss_mask_2: 3.097  loss_ce_3: 1.169  loss_mask_3: 3.058  loss_ce_4: 1.305  loss_mask_4: 2.89  loss_ce_5: 1.658  loss_mask_5: 2.747  loss_ce_6: 1.673  loss_mask_6: 2.741  loss_ce_7: 1.666  loss_mask_7: 2.826  loss_ce_8: 1.62  loss_mask_8: 2.805  time: 2.4362  data_time: 0.4256  lr: 7.6449e-05  max_mem: 18490M
[01/24 13:19:44] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 13:19:45] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 13:19:45] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 13:24:22] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 6.704800109713121, 'error_1pix': 0.7688524961404997, 'error_3pix': 0.5776019805422713, 'mIoU': 1.0407481189451635, 'fwIoU': 8.125595025629796, 'IoU-0': nan, 'IoU-1': 67.46571808758631, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 3.079308830657106e-05, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 1.0503090006878997, 'IoU-13': 2.687021247469613, 'IoU-14': 0.08095854853779423, 'IoU-15': 0.12263626265714446, 'IoU-16': 0.02934352308946499, 'IoU-17': 4.039036281377505, 'IoU-18': 0.019350097198998183, 'IoU-19': 0.0011388149238161513, 'IoU-20': 0.6211282328649138, 'IoU-21': 2.9930830449447933e-05, 'IoU-22': 2.176292669700581, 'IoU-23': 0.3434407608901619, 'IoU-24': 2.507197804603909, 'IoU-25': 1.494526186838311, 'IoU-26': 0.009408759901467825, 'IoU-27': 1.5243271093350492, 'IoU-28': 4.949462994737069, 'IoU-29': 0.16536705479404615, 'IoU-30': 0.027256982073141908, 'IoU-31': 0.07537557216988335, 'IoU-32': 0.05407081140307656, 'IoU-33': 6.448472239927745, 'IoU-34': 0.22999525933558992, 'IoU-35': 0.003977543704019994, 'IoU-36': 3.2411907929921617, 'IoU-37': 7.390585539064267, 'IoU-38': 0.6980521638798926, 'IoU-39': 0.07588838528438538, 'IoU-40': 5.21295262260962, 'IoU-41': 0.028186050225157692, 'IoU-42': 2.955775519923562, 'IoU-43': 6.303784753804339, 'IoU-44': 0.008756878096344919, 'IoU-45': 1.891989712873533e-05, 'IoU-46': 5.607230370390229, 'IoU-47': 2.1399192810160317, 'IoU-48': 0.0014814938641167638, 'IoU-49': 0.01595580500023696, 'IoU-50': 5.15105894732887, 'IoU-51': 0.0544642004537753, 'IoU-52': 0.6609971160115042, 'IoU-53': 0.17847054600670598, 'IoU-54': 0.822726945248612, 'IoU-55': 0.2686525878706784, 'IoU-56': 0.2120242400054973, 'IoU-57': 5.830535863820449e-05, 'IoU-58': 0.4802926771540053, 'IoU-59': 4.6825261515792675, 'IoU-60': 1.8101906016147022, 'IoU-61': 1.6611415927019666, 'IoU-62': 0.9561770665966446, 'IoU-63': 0.008086853166461875, 'IoU-64': 0.20768720535305116, 'IoU-65': 0.2663625082109533, 'IoU-66': 2.9421373367238024, 'IoU-67': 2.944721638812263, 'IoU-68': 0.06444128989858759, 'IoU-69': 3.938740526364019, 'IoU-70': 0.0004652676631995061, 'IoU-71': 0.9735452684081667, 'IoU-72': 0.5632127953588328, 'IoU-73': 0.0019108190908278587, 'IoU-74': 2.1785517010077215e-05, 'IoU-75': 0.0022145407838776196, 'IoU-76': 0.0009928162352070382, 'IoU-77': 2.3792497942672295, 'IoU-78': 2.3468553324440733, 'IoU-79': 0.5159882510771173, 'IoU-80': 0.23032639677579544, 'IoU-81': 0.7135136818532876, 'IoU-82': 0.8927647282626022, 'IoU-83': 0.05480479540312008, 'IoU-84': 0.060944572802650185, 'IoU-85': 0.18329434837267403, 'IoU-86': 0.7428444081287584, 'IoU-87': 3.381667171261795, 'IoU-88': 0.08734118471383294, 'IoU-89': 3.11186432886841, 'IoU-90': 2.7468194481366788, 'IoU-91': 0.0032842433944636883, 'IoU-92': 2.8438652565266e-05, 'IoU-93': 1.1073203596502856, 'IoU-94': 0.00458954543960499, 'IoU-95': 0.036119669105695126, 'IoU-96': 0.011114686594123924, 'IoU-97': 0.01744862609217023, 'IoU-98': 0.0029400008946260394, 'IoU-99': 1.723804254197664, 'IoU-100': 0.02069581487466085, 'IoU-101': 0.0, 'IoU-102': 0.018678065006409207, 'IoU-103': 2.955111677824284, 'IoU-104': 0.0035593270336495364, 'IoU-105': 0.05655262055602376, 'IoU-106': 0.19302095816110043, 'IoU-107': 1.6170025737305367, 'IoU-108': 0.882897588448164, 'IoU-109': 0.08020885713316156, 'IoU-110': 0.0, 'IoU-111': 0.002058457061677299, 'IoU-112': 1.4523416057394436, 'IoU-113': 0.0, 'IoU-114': 0.4419499139028225, 'IoU-115': 0.0023843752258278458, 'IoU-116': 0.0, 'IoU-117': 0.00016067683510017597, 'IoU-118': 0.0, 'IoU-119': 0.05357389523784332, 'IoU-120': 0.0, 'IoU-121': 0.008699772199811013, 'IoU-122': 0.6158032161309259, 'IoU-123': 0.268351776251329, 'IoU-124': 0.06426485008588546, 'IoU-125': 0.0037253197566124428, 'IoU-126': 0.0, 'IoU-127': 0.011952968452056756, 'IoU-128': 1.8543960740730183, 'IoU-129': 0.001630866021220076, 'IoU-130': 0.0018025847778153318, 'IoU-131': 0.0, 'IoU-132': 0.001271829446332479, 'IoU-133': 0.006099813050784631, 'IoU-134': 0.0011666577451662624, 'IoU-135': 0.0, 'IoU-136': 0.0016469363689664486, 'IoU-137': 0.00038156026095669367, 'IoU-138': 0.20910432333051898, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 1.6525288216300296, 'IoU-142': 0.00017464777909151718, 'IoU-143': 0.0019681584761204974, 'IoU-144': 0.00027074321720555096, 'IoU-145': 0.03869076697606253, 'IoU-146': 0.00036485664326415347, 'IoU-147': 0.0266837616294016, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 1.0175395655820791, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.00022900011679005957, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0001413437550795412, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.536345489520391, 'IoU-163': 1.315520933366005, 'IoU-164': 0.00015853965948851934, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.8928231679938305, 'IoU-168': 0.11376342310838292, 'IoU-169': 0.34439718309096473, 'IoU-170': 0.0, 'IoU-171': 0.43760105054614734, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0001844511379712957, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 2.587170099509645, 'IoU-181': 0.0, 'IoU-182': 1.0126868373312639, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 3.5223101390661453, 'pACC': 13.057895279975549, 'ACC-0': nan, 'ACC-1': 79.60666463269368, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 3.0887134087844246e-05, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 1.1321455813986037, 'ACC-13': 3.3981742552832492, 'ACC-14': 0.08194122318144673, 'ACC-15': 0.12804902704105806, 'ACC-16': 0.030722019902498305, 'ACC-17': 32.55407858147982, 'ACC-18': 0.019379917265990036, 'ACC-19': 0.0011398814777242065, 'ACC-20': 0.8554549091324724, 'ACC-21': 2.993098274550679e-05, 'ACC-22': 3.2779412476826217, 'ACC-23': 0.5096126567083531, 'ACC-24': 10.711212750314713, 'ACC-25': 1.6185909960059208, 'ACC-26': 0.00942698382892153, 'ACC-27': 2.8288034077423623, 'ACC-28': 29.76632147692903, 'ACC-29': 0.1803607516121871, 'ACC-30': 0.02777678976368431, 'ACC-31': 0.0760194644193913, 'ACC-32': 0.05495427307504265, 'ACC-33': 64.13820271806571, 'ACC-34': 0.24938098226388633, 'ACC-35': 0.00399786045154808, 'ACC-36': 4.6993650039251555, 'ACC-37': 23.646402044269475, 'ACC-38': 0.74533808090976, 'ACC-39': 0.07718147700420211, 'ACC-40': 13.68064460751221, 'ACC-41': 0.028426070326199565, 'ACC-42': 4.932769255368231, 'ACC-43': 28.594616826591896, 'ACC-44': 0.008769172436777349, 'ACC-45': 1.8920210709089007e-05, 'ACC-46': 30.504077152104625, 'ACC-47': 5.948268557595175, 'ACC-48': 0.001482041462122825, 'ACC-49': 0.01600443638436309, 'ACC-50': 16.15362039197174, 'ACC-51': 0.05494304385267381, 'ACC-52': 0.7847635810998668, 'ACC-53': 0.1872607510183514, 'ACC-54': 0.9083529167137205, 'ACC-55': 0.2875865910799161, 'ACC-56': 0.22048136534806761, 'ACC-57': 5.831107038262818e-05, 'ACC-58': 0.5301838295698268, 'ACC-59': 40.31880440604557, 'ACC-60': 3.2581959901700848, 'ACC-61': 2.2755629914739948, 'ACC-62': 1.1027512349958606, 'ACC-63': 0.00820830880063512, 'ACC-64': 0.219615449022067, 'ACC-65': 0.29032285187055457, 'ACC-66': 7.936101382198345, 'ACC-67': 6.0006331279546945, 'ACC-68': 0.06583403458859553, 'ACC-69': 13.061634423923044, 'ACC-70': 0.0004659715782753883, 'ACC-71': 1.2019138798185354, 'ACC-72': 0.6867362111529541, 'ACC-73': 0.0019115439131359088, 'ACC-74': 2.178581127147768e-05, 'ACC-75': 0.0022167888448564495, 'ACC-76': 0.0009955269069741532, 'ACC-77': 7.701798927983278, 'ACC-78': 3.7623456194444573, 'ACC-79': 0.5556723207375074, 'ACC-80': 0.25121552241671147, 'ACC-81': 0.9240379959601869, 'ACC-82': 1.200453016422858, 'ACC-83': 0.055525388257576816, 'ACC-84': 0.06193707551525669, 'ACC-85': 0.19189704264229568, 'ACC-86': 1.393714050920587, 'ACC-87': 56.69709667031748, 'ACC-88': 0.09024129617671005, 'ACC-89': 8.812720966677844, 'ACC-90': 9.2281817120728, 'ACC-91': 0.0032930537521625976, 'ACC-92': 2.8439797002416958e-05, 'ACC-93': 1.4632042170264166, 'ACC-94': 0.004607092550559419, 'ACC-95': 0.03637433932804272, 'ACC-96': 0.011124305959047566, 'ACC-97': 0.017857054195560253, 'ACC-98': 0.002942663731705613, 'ACC-99': 2.7774263792157865, 'ACC-100': 0.02138836651267043, 'ACC-101': 0.0, 'ACC-102': 0.018826461259628453, 'ACC-103': 37.36594408236517, 'ACC-104': 0.0035906642728904844, 'ACC-105': 0.057514255337243726, 'ACC-106': 0.20789099463306634, 'ACC-107': 6.869916974531024, 'ACC-108': 1.2284343445370045, 'ACC-109': 0.08107920389293577, 'ACC-110': 0.0, 'ACC-111': 0.002068394277317142, 'ACC-112': 4.033428559416872, 'ACC-113': 0.0, 'ACC-114': 0.4818882819478301, 'ACC-115': 0.0024431314179183014, 'ACC-116': 0.0, 'ACC-117': 0.0001607294545565595, 'ACC-118': 0.0, 'ACC-119': 0.05472784690957081, 'ACC-120': 0.0, 'ACC-121': 0.008857086145836692, 'ACC-122': 0.7061715116004793, 'ACC-123': 0.33014650590424915, 'ACC-124': 0.06595276439573576, 'ACC-125': 0.003752598266408372, 'ACC-126': 0.0, 'ACC-127': 0.012382136082011793, 'ACC-128': 13.725665972671978, 'ACC-129': 0.0016315680812571105, 'ACC-130': 0.0018057852199059444, 'ACC-131': 0.0, 'ACC-132': 0.0012734029683693405, 'ACC-133': 0.006191866201256064, 'ACC-134': 0.0011719086600603188, 'ACC-135': 0.0, 'ACC-136': 0.0018199077525158404, 'ACC-137': 0.00038161617503054836, 'ACC-138': 0.2732600197984618, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 42.59356817175779, 'ACC-142': 0.00017466318388278005, 'ACC-143': 0.002156619068286647, 'ACC-144': 0.0002707581227436823, 'ACC-145': 0.0442764820322458, 'ACC-146': 0.0003655388270772886, 'ACC-147': 0.030455448228987828, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 10.20023785476267, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.00022902581578995585, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.00014176876380473337, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 1.0340641652360452, 'ACC-163': 3.1432340671418766, 'ACC-164': 0.000158549462675871, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 1.222755516644171, 'ACC-168': 0.1332723820240523, 'ACC-169': 0.4463995872909476, 'ACC-170': 0.0, 'ACC-171': 0.8471571924784491, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.00018454644941858642, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 4.0726912526668695, 'ACC-181': 0.0, 'ACC-182': 11.99533747621947, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 13:24:22] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 13:24:22] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 13:24:22] d2.evaluation.testing INFO: copypaste: 6.7048,0.7689,0.5776,1.0407,8.1256,3.5223,13.0579
[01/24 13:24:22] d2.utils.events INFO:  eta: 1 day, 5:24:54  iter: 15499  total_loss: 43.31  loss_ce: 1.63  loss_mask: 2.779  loss_ce_0: 1.122  loss_mask_0: 3.403  loss_ce_1: 0.9358  loss_mask_1: 3.19  loss_ce_2: 1.037  loss_mask_2: 3.065  loss_ce_3: 1.154  loss_mask_3: 2.992  loss_ce_4: 1.3  loss_mask_4: 3.033  loss_ce_5: 1.66  loss_mask_5: 2.735  loss_ce_6: 1.68  loss_mask_6: 2.78  loss_ce_7: 1.668  loss_mask_7: 2.752  loss_ce_8: 1.616  loss_mask_8: 2.778  time: 2.4364  data_time: 0.5366  lr: 7.6418e-05  max_mem: 18490M
[01/24 13:25:12] d2.utils.events INFO:  eta: 1 day, 5:24:00  iter: 15519  total_loss: 44.15  loss_ce: 1.633  loss_mask: 2.875  loss_ce_0: 1.059  loss_mask_0: 3.441  loss_ce_1: 0.9359  loss_mask_1: 3.374  loss_ce_2: 1.02  loss_mask_2: 3.262  loss_ce_3: 1.113  loss_mask_3: 3.122  loss_ce_4: 1.286  loss_mask_4: 3.004  loss_ce_5: 1.645  loss_mask_5: 2.946  loss_ce_6: 1.648  loss_mask_6: 2.813  loss_ce_7: 1.679  loss_mask_7: 2.941  loss_ce_8: 1.629  loss_mask_8: 2.812  time: 2.4365  data_time: 0.5428  lr: 7.6387e-05  max_mem: 18490M
[01/24 13:26:00] d2.utils.events INFO:  eta: 1 day, 5:23:40  iter: 15539  total_loss: 44.16  loss_ce: 1.642  loss_mask: 2.829  loss_ce_0: 1.075  loss_mask_0: 3.564  loss_ce_1: 0.937  loss_mask_1: 3.392  loss_ce_2: 1.014  loss_mask_2: 3.223  loss_ce_3: 1.114  loss_mask_3: 3.067  loss_ce_4: 1.265  loss_mask_4: 2.896  loss_ce_5: 1.647  loss_mask_5: 2.766  loss_ce_6: 1.649  loss_mask_6: 2.735  loss_ce_7: 1.645  loss_mask_7: 2.83  loss_ce_8: 1.654  loss_mask_8: 2.842  time: 2.4365  data_time: 0.4465  lr: 7.6356e-05  max_mem: 18490M
[01/24 13:26:52] d2.utils.events INFO:  eta: 1 day, 5:26:55  iter: 15559  total_loss: 43.37  loss_ce: 1.59  loss_mask: 2.84  loss_ce_0: 1.102  loss_mask_0: 3.403  loss_ce_1: 0.9257  loss_mask_1: 3.273  loss_ce_2: 0.9909  loss_mask_2: 3.231  loss_ce_3: 1.075  loss_mask_3: 3.065  loss_ce_4: 1.239  loss_mask_4: 2.965  loss_ce_5: 1.641  loss_mask_5: 2.795  loss_ce_6: 1.637  loss_mask_6: 2.782  loss_ce_7: 1.621  loss_mask_7: 2.726  loss_ce_8: 1.598  loss_mask_8: 2.804  time: 2.4366  data_time: 0.5055  lr: 7.6325e-05  max_mem: 18490M
[01/24 13:27:39] d2.utils.events INFO:  eta: 1 day, 5:22:35  iter: 15579  total_loss: 41.88  loss_ce: 1.57  loss_mask: 2.764  loss_ce_0: 1.036  loss_mask_0: 3.305  loss_ce_1: 0.9264  loss_mask_1: 3.117  loss_ce_2: 1.008  loss_mask_2: 3.055  loss_ce_3: 1.11  loss_mask_3: 2.902  loss_ce_4: 1.261  loss_mask_4: 2.851  loss_ce_5: 1.615  loss_mask_5: 2.676  loss_ce_6: 1.626  loss_mask_6: 2.658  loss_ce_7: 1.634  loss_mask_7: 2.663  loss_ce_8: 1.596  loss_mask_8: 2.741  time: 2.4365  data_time: 0.4385  lr: 7.6295e-05  max_mem: 18490M
[01/24 13:28:27] d2.utils.events INFO:  eta: 1 day, 5:23:51  iter: 15599  total_loss: 44.1  loss_ce: 1.614  loss_mask: 2.84  loss_ce_0: 1.129  loss_mask_0: 3.395  loss_ce_1: 0.9846  loss_mask_1: 3.308  loss_ce_2: 1.02  loss_mask_2: 3.247  loss_ce_3: 1.142  loss_mask_3: 3.18  loss_ce_4: 1.283  loss_mask_4: 3.073  loss_ce_5: 1.623  loss_mask_5: 2.785  loss_ce_6: 1.636  loss_mask_6: 2.794  loss_ce_7: 1.648  loss_mask_7: 2.811  loss_ce_8: 1.618  loss_mask_8: 2.778  time: 2.4365  data_time: 0.4147  lr: 7.6264e-05  max_mem: 18490M
[01/24 13:29:18] d2.utils.events INFO:  eta: 1 day, 5:24:31  iter: 15619  total_loss: 43.22  loss_ce: 1.608  loss_mask: 2.886  loss_ce_0: 1.181  loss_mask_0: 3.331  loss_ce_1: 0.9966  loss_mask_1: 3.294  loss_ce_2: 1.013  loss_mask_2: 3.21  loss_ce_3: 1.097  loss_mask_3: 3.065  loss_ce_4: 1.283  loss_mask_4: 3.048  loss_ce_5: 1.614  loss_mask_5: 2.715  loss_ce_6: 1.631  loss_mask_6: 2.72  loss_ce_7: 1.649  loss_mask_7: 2.777  loss_ce_8: 1.626  loss_mask_8: 2.722  time: 2.4366  data_time: 0.4530  lr: 7.6233e-05  max_mem: 18490M
[01/24 13:30:04] d2.utils.events INFO:  eta: 1 day, 5:22:07  iter: 15639  total_loss: 43.02  loss_ce: 1.602  loss_mask: 2.793  loss_ce_0: 1.116  loss_mask_0: 3.355  loss_ce_1: 0.9248  loss_mask_1: 3.177  loss_ce_2: 0.9858  loss_mask_2: 3.203  loss_ce_3: 1.116  loss_mask_3: 3.05  loss_ce_4: 1.23  loss_mask_4: 2.904  loss_ce_5: 1.601  loss_mask_5: 2.755  loss_ce_6: 1.606  loss_mask_6: 2.728  loss_ce_7: 1.623  loss_mask_7: 2.705  loss_ce_8: 1.617  loss_mask_8: 2.713  time: 2.4365  data_time: 0.4204  lr: 7.6202e-05  max_mem: 18490M
[01/24 13:30:53] d2.utils.events INFO:  eta: 1 day, 5:21:03  iter: 15659  total_loss: 44.21  loss_ce: 1.588  loss_mask: 2.814  loss_ce_0: 1.141  loss_mask_0: 3.445  loss_ce_1: 0.9738  loss_mask_1: 3.291  loss_ce_2: 1.024  loss_mask_2: 3.24  loss_ce_3: 1.142  loss_mask_3: 3.166  loss_ce_4: 1.285  loss_mask_4: 3.055  loss_ce_5: 1.635  loss_mask_5: 2.825  loss_ce_6: 1.653  loss_mask_6: 2.808  loss_ce_7: 1.649  loss_mask_7: 2.759  loss_ce_8: 1.627  loss_mask_8: 2.812  time: 2.4364  data_time: 0.4311  lr: 7.6171e-05  max_mem: 18490M
[01/24 13:31:42] d2.utils.events INFO:  eta: 1 day, 5:18:26  iter: 15679  total_loss: 42.61  loss_ce: 1.587  loss_mask: 2.817  loss_ce_0: 1.138  loss_mask_0: 3.211  loss_ce_1: 0.9944  loss_mask_1: 3.156  loss_ce_2: 1.046  loss_mask_2: 3.03  loss_ce_3: 1.132  loss_mask_3: 3.014  loss_ce_4: 1.241  loss_mask_4: 3.06  loss_ce_5: 1.609  loss_mask_5: 2.778  loss_ce_6: 1.638  loss_mask_6: 2.737  loss_ce_7: 1.624  loss_mask_7: 2.672  loss_ce_8: 1.613  loss_mask_8: 2.773  time: 2.4364  data_time: 0.4030  lr: 7.614e-05  max_mem: 18490M
[01/24 13:32:31] d2.utils.events INFO:  eta: 1 day, 5:17:18  iter: 15699  total_loss: 44.98  loss_ce: 1.605  loss_mask: 2.962  loss_ce_0: 1.122  loss_mask_0: 3.505  loss_ce_1: 0.9608  loss_mask_1: 3.405  loss_ce_2: 1.031  loss_mask_2: 3.243  loss_ce_3: 1.149  loss_mask_3: 3.228  loss_ce_4: 1.25  loss_mask_4: 3.169  loss_ce_5: 1.641  loss_mask_5: 2.934  loss_ce_6: 1.65  loss_mask_6: 2.848  loss_ce_7: 1.63  loss_mask_7: 2.882  loss_ce_8: 1.633  loss_mask_8: 2.912  time: 2.4365  data_time: 0.4009  lr: 7.6109e-05  max_mem: 18490M
[01/24 13:33:20] d2.utils.events INFO:  eta: 1 day, 5:17:09  iter: 15719  total_loss: 44.76  loss_ce: 1.601  loss_mask: 2.93  loss_ce_0: 1.108  loss_mask_0: 3.356  loss_ce_1: 0.9834  loss_mask_1: 3.265  loss_ce_2: 1.088  loss_mask_2: 3.29  loss_ce_3: 1.199  loss_mask_3: 3.225  loss_ce_4: 1.32  loss_mask_4: 3.038  loss_ce_5: 1.622  loss_mask_5: 2.92  loss_ce_6: 1.625  loss_mask_6: 2.87  loss_ce_7: 1.636  loss_mask_7: 2.863  loss_ce_8: 1.614  loss_mask_8: 2.853  time: 2.4365  data_time: 0.4344  lr: 7.6078e-05  max_mem: 18490M
[01/24 13:34:09] d2.utils.events INFO:  eta: 1 day, 5:12:29  iter: 15739  total_loss: 43.96  loss_ce: 1.641  loss_mask: 2.905  loss_ce_0: 1.128  loss_mask_0: 3.337  loss_ce_1: 0.973  loss_mask_1: 3.313  loss_ce_2: 1.086  loss_mask_2: 3.208  loss_ce_3: 1.171  loss_mask_3: 3.245  loss_ce_4: 1.326  loss_mask_4: 3.066  loss_ce_5: 1.64  loss_mask_5: 2.925  loss_ce_6: 1.672  loss_mask_6: 2.92  loss_ce_7: 1.645  loss_mask_7: 2.943  loss_ce_8: 1.635  loss_mask_8: 2.875  time: 2.4365  data_time: 0.4007  lr: 7.6047e-05  max_mem: 18490M
[01/24 13:34:55] d2.utils.events INFO:  eta: 1 day, 5:11:42  iter: 15759  total_loss: 44.83  loss_ce: 1.646  loss_mask: 2.937  loss_ce_0: 1.14  loss_mask_0: 3.48  loss_ce_1: 0.9848  loss_mask_1: 3.36  loss_ce_2: 1.076  loss_mask_2: 3.302  loss_ce_3: 1.168  loss_mask_3: 3.176  loss_ce_4: 1.327  loss_mask_4: 3.037  loss_ce_5: 1.629  loss_mask_5: 2.83  loss_ce_6: 1.646  loss_mask_6: 2.825  loss_ce_7: 1.627  loss_mask_7: 2.851  loss_ce_8: 1.627  loss_mask_8: 2.909  time: 2.4364  data_time: 0.3813  lr: 7.6016e-05  max_mem: 18490M
[01/24 13:35:46] d2.utils.events INFO:  eta: 1 day, 5:15:52  iter: 15779  total_loss: 44.39  loss_ce: 1.63  loss_mask: 2.762  loss_ce_0: 1.168  loss_mask_0: 3.325  loss_ce_1: 1.065  loss_mask_1: 3.323  loss_ce_2: 1.146  loss_mask_2: 3.241  loss_ce_3: 1.25  loss_mask_3: 3.106  loss_ce_4: 1.341  loss_mask_4: 3.08  loss_ce_5: 1.667  loss_mask_5: 2.8  loss_ce_6: 1.672  loss_mask_6: 2.809  loss_ce_7: 1.666  loss_mask_7: 2.765  loss_ce_8: 1.64  loss_mask_8: 2.752  time: 2.4365  data_time: 0.4529  lr: 7.5985e-05  max_mem: 18490M
[01/24 13:36:34] d2.utils.events INFO:  eta: 1 day, 5:10:07  iter: 15799  total_loss: 46.39  loss_ce: 1.665  loss_mask: 3.001  loss_ce_0: 1.161  loss_mask_0: 3.616  loss_ce_1: 1.042  loss_mask_1: 3.431  loss_ce_2: 1.112  loss_mask_2: 3.336  loss_ce_3: 1.242  loss_mask_3: 3.332  loss_ce_4: 1.352  loss_mask_4: 3.202  loss_ce_5: 1.693  loss_mask_5: 3.039  loss_ce_6: 1.708  loss_mask_6: 3.026  loss_ce_7: 1.7  loss_mask_7: 3.013  loss_ce_8: 1.66  loss_mask_8: 3.017  time: 2.4364  data_time: 0.4171  lr: 7.5954e-05  max_mem: 18490M
[01/24 13:37:21] d2.utils.events INFO:  eta: 1 day, 5:11:25  iter: 15819  total_loss: 45.52  loss_ce: 1.631  loss_mask: 2.967  loss_ce_0: 1.012  loss_mask_0: 3.64  loss_ce_1: 0.9353  loss_mask_1: 3.356  loss_ce_2: 1.072  loss_mask_2: 3.322  loss_ce_3: 1.19  loss_mask_3: 3.258  loss_ce_4: 1.336  loss_mask_4: 3.186  loss_ce_5: 1.695  loss_mask_5: 2.938  loss_ce_6: 1.698  loss_mask_6: 2.914  loss_ce_7: 1.682  loss_mask_7: 2.925  loss_ce_8: 1.679  loss_mask_8: 2.921  time: 2.4363  data_time: 0.4155  lr: 7.5923e-05  max_mem: 18490M
[01/24 13:38:11] d2.utils.events INFO:  eta: 1 day, 5:14:44  iter: 15839  total_loss: 44.45  loss_ce: 1.662  loss_mask: 2.897  loss_ce_0: 1.132  loss_mask_0: 3.47  loss_ce_1: 0.9955  loss_mask_1: 3.278  loss_ce_2: 1.053  loss_mask_2: 3.222  loss_ce_3: 1.164  loss_mask_3: 3.152  loss_ce_4: 1.286  loss_mask_4: 3.077  loss_ce_5: 1.663  loss_mask_5: 2.927  loss_ce_6: 1.688  loss_mask_6: 2.941  loss_ce_7: 1.69  loss_mask_7: 2.83  loss_ce_8: 1.642  loss_mask_8: 2.84  time: 2.4364  data_time: 0.4235  lr: 7.5893e-05  max_mem: 18490M
[01/24 13:38:59] d2.utils.events INFO:  eta: 1 day, 5:10:17  iter: 15859  total_loss: 46.13  loss_ce: 1.651  loss_mask: 2.948  loss_ce_0: 1.176  loss_mask_0: 3.531  loss_ce_1: 1.004  loss_mask_1: 3.443  loss_ce_2: 1.071  loss_mask_2: 3.335  loss_ce_3: 1.259  loss_mask_3: 3.34  loss_ce_4: 1.358  loss_mask_4: 3.121  loss_ce_5: 1.696  loss_mask_5: 2.964  loss_ce_6: 1.713  loss_mask_6: 3.026  loss_ce_7: 1.677  loss_mask_7: 3.021  loss_ce_8: 1.659  loss_mask_8: 2.987  time: 2.4363  data_time: 0.4168  lr: 7.5862e-05  max_mem: 18490M
[01/24 13:39:46] d2.utils.events INFO:  eta: 1 day, 5:09:47  iter: 15879  total_loss: 46.01  loss_ce: 1.699  loss_mask: 2.948  loss_ce_0: 1.181  loss_mask_0: 3.527  loss_ce_1: 1.064  loss_mask_1: 3.406  loss_ce_2: 1.108  loss_mask_2: 3.245  loss_ce_3: 1.302  loss_mask_3: 3.272  loss_ce_4: 1.349  loss_mask_4: 3.137  loss_ce_5: 1.736  loss_mask_5: 2.907  loss_ce_6: 1.72  loss_mask_6: 2.923  loss_ce_7: 1.705  loss_mask_7: 2.947  loss_ce_8: 1.704  loss_mask_8: 2.988  time: 2.4362  data_time: 0.4105  lr: 7.5831e-05  max_mem: 18490M
[01/24 13:40:35] d2.utils.events INFO:  eta: 1 day, 5:13:39  iter: 15899  total_loss: 44.34  loss_ce: 1.713  loss_mask: 2.895  loss_ce_0: 1.119  loss_mask_0: 3.31  loss_ce_1: 1.09  loss_mask_1: 3.269  loss_ce_2: 1.181  loss_mask_2: 3.116  loss_ce_3: 1.339  loss_mask_3: 3.124  loss_ce_4: 1.397  loss_mask_4: 2.952  loss_ce_5: 1.721  loss_mask_5: 2.58  loss_ce_6: 1.758  loss_mask_6: 2.705  loss_ce_7: 1.749  loss_mask_7: 2.803  loss_ce_8: 1.765  loss_mask_8: 2.843  time: 2.4363  data_time: 0.4458  lr: 7.58e-05  max_mem: 18490M
[01/24 13:41:22] d2.utils.events INFO:  eta: 1 day, 5:13:53  iter: 15919  total_loss: 45.02  loss_ce: 1.736  loss_mask: 2.946  loss_ce_0: 1.106  loss_mask_0: 3.494  loss_ce_1: 1.01  loss_mask_1: 3.251  loss_ce_2: 1.115  loss_mask_2: 3.189  loss_ce_3: 1.28  loss_mask_3: 3.19  loss_ce_4: 1.396  loss_mask_4: 3.042  loss_ce_5: 1.704  loss_mask_5: 2.829  loss_ce_6: 1.744  loss_mask_6: 2.815  loss_ce_7: 1.714  loss_mask_7: 2.923  loss_ce_8: 1.807  loss_mask_8: 3.102  time: 2.4362  data_time: 0.3826  lr: 7.5769e-05  max_mem: 18490M
[01/24 13:42:12] d2.utils.events INFO:  eta: 1 day, 5:14:27  iter: 15939  total_loss: 44.99  loss_ce: 1.776  loss_mask: 3  loss_ce_0: 1.077  loss_mask_0: 3.333  loss_ce_1: 0.9245  loss_mask_1: 3.286  loss_ce_2: 0.9997  loss_mask_2: 3.133  loss_ce_3: 1.17  loss_mask_3: 3.047  loss_ce_4: 1.316  loss_mask_4: 3.034  loss_ce_5: 1.686  loss_mask_5: 2.835  loss_ce_6: 1.688  loss_mask_6: 2.849  loss_ce_7: 1.677  loss_mask_7: 2.884  loss_ce_8: 1.826  loss_mask_8: 3.126  time: 2.4362  data_time: 0.4902  lr: 7.5738e-05  max_mem: 18490M
[01/24 13:43:09] d2.utils.events INFO:  eta: 1 day, 5:19:25  iter: 15959  total_loss: 44.51  loss_ce: 1.782  loss_mask: 2.989  loss_ce_0: 1.1  loss_mask_0: 3.437  loss_ce_1: 0.9352  loss_mask_1: 3.262  loss_ce_2: 0.9931  loss_mask_2: 3.037  loss_ce_3: 1.125  loss_mask_3: 3.039  loss_ce_4: 1.374  loss_mask_4: 2.907  loss_ce_5: 1.716  loss_mask_5: 2.717  loss_ce_6: 1.731  loss_mask_6: 2.832  loss_ce_7: 1.744  loss_mask_7: 2.808  loss_ce_8: 1.802  loss_mask_8: 2.99  time: 2.4367  data_time: 0.5664  lr: 7.5707e-05  max_mem: 18490M
[01/24 13:44:00] d2.utils.events INFO:  eta: 1 day, 5:23:06  iter: 15979  total_loss: 46.49  loss_ce: 1.727  loss_mask: 2.984  loss_ce_0: 1.174  loss_mask_0: 3.711  loss_ce_1: 1.011  loss_mask_1: 3.448  loss_ce_2: 1.086  loss_mask_2: 3.303  loss_ce_3: 1.206  loss_mask_3: 3.282  loss_ce_4: 1.436  loss_mask_4: 3.068  loss_ce_5: 1.743  loss_mask_5: 3.066  loss_ce_6: 1.771  loss_mask_6: 3.123  loss_ce_7: 1.752  loss_mask_7: 3.059  loss_ce_8: 1.71  loss_mask_8: 3.039  time: 2.4369  data_time: 0.4953  lr: 7.5676e-05  max_mem: 18490M
[01/24 13:44:52] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 13:44:53] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 13:44:53] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 13:49:55] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 8.839438843811758, 'error_1pix': 0.8663333715779795, 'error_3pix': 0.6965802508297967, 'mIoU': 0.5533869987152642, 'fwIoU': 0.949613295743943, 'IoU-0': nan, 'IoU-1': 0.7011118553240369, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 6.234162888452248e-06, 'IoU-11': 0.0, 'IoU-12': 0.8420594668336733, 'IoU-13': 0.0039024763125181513, 'IoU-14': 0.0, 'IoU-15': 1.9465531531094284, 'IoU-16': 0.21613631486025348, 'IoU-17': 0.0, 'IoU-18': 0.014247855615497407, 'IoU-19': 4.5352588712157916e-05, 'IoU-20': 3.55491978828096, 'IoU-21': 0.0, 'IoU-22': 0.0031529778210214357, 'IoU-23': 1.5267641296615369, 'IoU-24': 9.346990574370078e-06, 'IoU-25': 0.008453794349745558, 'IoU-26': 0.5911264053763413, 'IoU-27': 5.1864253880076, 'IoU-28': 0.06016481755584342, 'IoU-29': 0.1548965468531121, 'IoU-30': 0.06220129467935932, 'IoU-31': 5.555222390939414, 'IoU-32': 0.0015916622193354315, 'IoU-33': 6.391102079190151, 'IoU-34': 0.03505255090916302, 'IoU-35': 0.006989548533341726, 'IoU-36': 2.332506733713003, 'IoU-37': 3.02127234091084, 'IoU-38': 0.1097922388877884, 'IoU-39': 0.776224923743104, 'IoU-40': 3.2388554797021163, 'IoU-41': 0.33794160744621565, 'IoU-42': 3.161528312348848, 'IoU-43': 0.32946039536348853, 'IoU-44': 7.528421943815602e-05, 'IoU-45': 0.004374186686386271, 'IoU-46': 2.2076124730882265, 'IoU-47': 0.40143127713549703, 'IoU-48': 0.0006591404039398193, 'IoU-49': 0.42817802642532204, 'IoU-50': 0.34006553640473414, 'IoU-51': 0.203007599849081, 'IoU-52': 0.000427647382412094, 'IoU-53': 0.19116813270225774, 'IoU-54': 4.025153601591288, 'IoU-55': 0.0008799864966367389, 'IoU-56': 0.0, 'IoU-57': 4.535113309158156e-05, 'IoU-58': 0.6537303909945305, 'IoU-59': 1.3848965614106548, 'IoU-60': 3.151880828665549, 'IoU-61': 0.22016770711808117, 'IoU-62': 0.3635073597747922, 'IoU-63': 1.0395799268813968, 'IoU-64': 0.00019010828567952304, 'IoU-65': 1.5239815512806876, 'IoU-66': 3.282522891199271, 'IoU-67': 0.0891177027528351, 'IoU-68': 1.328822182171291, 'IoU-69': 0.8451525029542316, 'IoU-70': 0.8067182460439141, 'IoU-71': 2.826318914530978, 'IoU-72': 0.791871328980575, 'IoU-73': 0.45206474652350875, 'IoU-74': 0.0, 'IoU-75': 0.16002351428818523, 'IoU-76': 0.18943399630989133, 'IoU-77': 0.2584875021573735, 'IoU-78': 0.0009866085077579578, 'IoU-79': 1.6415084242575237, 'IoU-80': 0.00021006614872462207, 'IoU-81': 3.138944428229371, 'IoU-82': 0.09413983355824233, 'IoU-83': 2.5923218688237717, 'IoU-84': 0.01173812116246677, 'IoU-85': 1.7027269551818984, 'IoU-86': 0.19315533869292287, 'IoU-87': 3.4004721886380174, 'IoU-88': 0.013572188860382292, 'IoU-89': 2.099685975585206, 'IoU-90': 2.8046295210244465, 'IoU-91': 0.07751292930109131, 'IoU-92': 3.1916569128547243, 'IoU-93': 0.00020622413912469638, 'IoU-94': 0.037703371958574816, 'IoU-95': 0.0, 'IoU-96': 0.13789521623901138, 'IoU-97': 0.002564767650004283, 'IoU-98': 2.8059258390141206, 'IoU-99': 0.7613029853591244, 'IoU-100': 0.0, 'IoU-101': 6.44657348502837e-05, 'IoU-102': 0.0, 'IoU-103': 0.009080970579767174, 'IoU-104': 0.0033413591469706647, 'IoU-105': 1.0424111800908211, 'IoU-106': 0.0011529911866925949, 'IoU-107': 0.0, 'IoU-108': 1.4494366877867106, 'IoU-109': 0.00025512250557513546, 'IoU-110': 0.003095796569496726, 'IoU-111': 0.3187589872754157, 'IoU-112': 0.011572199718875355, 'IoU-113': 0.03658143101899837, 'IoU-114': 0.0005460188310974469, 'IoU-115': 0.08415085065533814, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 1.2097254608275323, 'IoU-119': 0.0017124467910673638, 'IoU-120': 1.105118391696912, 'IoU-121': 0.0, 'IoU-122': 1.9732838457461666, 'IoU-123': 0.011252358805641119, 'IoU-124': 0.5213511908581445, 'IoU-125': 0.0, 'IoU-126': 0.00011384438838240786, 'IoU-127': 0.014869288579464244, 'IoU-128': 0.0015216512716135348, 'IoU-129': 0.0, 'IoU-130': 0.022422994474508545, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.013250676294132398, 'IoU-134': 1.5359487159385006, 'IoU-135': 0.0, 'IoU-136': 0.24293872242334857, 'IoU-137': 0.0, 'IoU-138': 0.0010302007306500565, 'IoU-139': 0.0, 'IoU-140': 0.009429676750680986, 'IoU-141': 0.0010078367707566083, 'IoU-142': 0.0, 'IoU-143': 0.00017967143484709514, 'IoU-144': 0.0, 'IoU-145': 0.0016935495372153054, 'IoU-146': 0.0012769435080192053, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.016077559697625653, 'IoU-151': 0.00018311597467139838, 'IoU-152': 1.2679273748196034, 'IoU-153': 0.0, 'IoU-154': 1.094744775549106, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.005358803410720759, 'IoU-168': 0.0003516267130813928, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.016178361269691563, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.00018483331731444585, 'IoU-176': 0.0, 'IoU-177': 1.4070225480708825, 'IoU-178': 1.225964245425971, 'IoU-179': 0.0, 'IoU-180': 0.09099854655099258, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.7817805769541875, 'pACC': 4.5051023699406665, 'ACC-0': nan, 'ACC-1': 0.7018876555677829, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 6.234172993313226e-06, 'ACC-11': 0.0, 'ACC-12': 1.0545009398773766, 'ACC-13': 0.004028334115337828, 'ACC-14': 0.0, 'ACC-15': 3.8258078524839223, 'ACC-16': 0.2516843418251475, 'ACC-17': 0.0, 'ACC-18': 0.014738646459180469, 'ACC-19': 4.5353374445260196e-05, 'ACC-20': 81.1869540016396, 'ACC-21': 0.0, 'ACC-22': 0.0031633048616403585, 'ACC-23': 2.4712887022953067, 'ACC-24': 9.35419364247218e-06, 'ACC-25': 0.008672715608728461, 'ACC-26': 0.6735731993890706, 'ACC-27': 14.326933948206625, 'ACC-28': 0.060811408809357224, 'ACC-29': 0.1591823222967676, 'ACC-30': 0.06326327904839124, 'ACC-31': 22.628094748912865, 'ACC-32': 0.001594328974544386, 'ACC-33': 54.346260285183035, 'ACC-34': 0.03525314070293876, 'ACC-35': 0.006994869569525525, 'ACC-36': 3.080887902783298, 'ACC-37': 4.521545062981686, 'ACC-38': 0.11137800503512836, 'ACC-39': 0.866205469798854, 'ACC-40': 4.8582250016376225, 'ACC-41': 0.3546232692391758, 'ACC-42': 4.950360014902653, 'ACC-43': 0.34848955880209737, 'ACC-44': 7.528725313668208e-05, 'ACC-45': 0.004412193137359556, 'ACC-46': 6.502204727973811, 'ACC-47': 0.41701810097375225, 'ACC-48': 0.0006591766503173162, 'ACC-49': 0.46510481225933475, 'ACC-50': 0.36120704441096163, 'ACC-51': 0.21303501593388494, 'ACC-52': 0.00042854126643351235, 'ACC-53': 0.19887339900955106, 'ACC-54': 66.75052341849639, 'ACC-55': 0.0008816955158622941, 'ACC-56': 0.0, 'ACC-57': 4.5353054742044134e-05, 'ACC-58': 0.7751366136115726, 'ACC-59': 1.8954995919197581, 'ACC-60': 9.211835430068263, 'ACC-61': 0.2278910156416941, 'ACC-62': 0.3907490450557054, 'ACC-63': 1.3265641531902839, 'ACC-64': 0.00019018441136355662, 'ACC-65': 2.2817298889601645, 'ACC-66': 11.318069967224455, 'ACC-67': 0.09137187527971792, 'ACC-68': 3.163992547798713, 'ACC-69': 0.9311792907539095, 'ACC-70': 0.9785614949046009, 'ACC-71': 25.881293803927104, 'ACC-72': 0.9013565896652581, 'ACC-73': 0.514426300369182, 'ACC-74': 0.0, 'ACC-75': 0.1814490810154422, 'ACC-76': 0.19701901117489545, 'ACC-77': 0.2911793210065892, 'ACC-78': 0.0009871836935888298, 'ACC-79': 2.579489521930673, 'ACC-80': 0.00021010189831488323, 'ACC-81': 18.153098501191668, 'ACC-82': 0.09705244544934742, 'ACC-83': 13.664031223320352, 'ACC-84': 0.011795377867765421, 'ACC-85': 5.905295302954765, 'ACC-86': 0.20581209270556455, 'ACC-87': 14.858521037223657, 'ACC-88': 0.01364931025736868, 'ACC-89': 3.3075379515254224, 'ACC-90': 6.569234192266888, 'ACC-91': 0.07884278281004169, 'ACC-92': 30.92847831870746, 'ACC-93': 0.0002062490212379037, 'ACC-94': 0.03851407732860399, 'ACC-95': 0.0, 'ACC-96': 0.15767204913212926, 'ACC-97': 0.0025681285995532484, 'ACC-98': 29.098900400581385, 'ACC-99': 1.276219582276245, 'ACC-100': 0.0, 'ACC-101': 6.448051914555575e-05, 'ACC-102': 0.0, 'ACC-103': 0.009138566166052705, 'ACC-104': 0.0033447283637883965, 'ACC-105': 4.346463626702858, 'ACC-106': 0.001153784531263234, 'ACC-107': 0.0, 'ACC-108': 3.9080241220839884, 'ACC-109': 0.0002551443479148328, 'ACC-110': 0.003101317638458025, 'ACC-111': 0.5503495743025202, 'ACC-112': 0.011611309415370571, 'ACC-113': 0.03703568846327901, 'ACC-114': 0.0005466478279677419, 'ACC-115': 0.08558477290153804, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 2.3873733728513744, 'ACC-119': 0.0017156064861934424, 'ACC-120': 3.4309694739912224, 'ACC-121': 0.0, 'ACC-122': 13.814760300791606, 'ACC-123': 0.011595341337243843, 'ACC-124': 1.2941764987605888, 'ACC-125': 0.0, 'ACC-126': 0.00011384438838240786, 'ACC-127': 0.015068825986599258, 'ACC-128': 0.0015245929032029868, 'ACC-129': 0.0, 'ACC-130': 0.023604192517341988, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.01326828471697728, 'ACC-134': 10.723446790176649, 'ACC-135': 0.0, 'ACC-136': 0.3045797614610511, 'ACC-137': 0.0, 'ACC-138': 0.0010311698860319314, 'ACC-139': 0.0, 'ACC-140': 0.009524803416339924, 'ACC-141': 0.0010098646949619533, 'ACC-142': 0.0, 'ACC-143': 0.00017971825569055392, 'ACC-144': 0.0, 'ACC-145': 0.0016995013305306469, 'ACC-146': 0.0012793858947705101, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.01730231840643563, 'ACC-151': 0.00021315530602174397, 'ACC-152': 13.935004889068717, 'ACC-153': 0.0, 'ACC-154': 2.6879050145185857, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.00590619229519844, 'ACC-168': 0.00035164216892889793, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.01726643020229276, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0001848842347364198, 'ACC-176': 0.0, 'ACC-177': 10.601639879749532, 'ACC-178': 2.397283426467663, 'ACC-179': 0.0, 'ACC-180': 0.10667479427003963, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 13:49:55] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 13:49:55] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 13:49:55] d2.evaluation.testing INFO: copypaste: 8.8394,0.8663,0.6966,0.5534,0.9496,2.7818,4.5051
[01/24 13:49:55] d2.utils.events INFO:  eta: 1 day, 5:27:43  iter: 15999  total_loss: 46.25  loss_ce: 1.714  loss_mask: 3.061  loss_ce_0: 1.146  loss_mask_0: 3.628  loss_ce_1: 1.032  loss_mask_1: 3.417  loss_ce_2: 1.087  loss_mask_2: 3.288  loss_ce_3: 1.206  loss_mask_3: 3.219  loss_ce_4: 1.334  loss_mask_4: 3.127  loss_ce_5: 1.709  loss_mask_5: 3.016  loss_ce_6: 1.725  loss_mask_6: 3.108  loss_ce_7: 1.72  loss_mask_7: 3.046  loss_ce_8: 1.717  loss_mask_8: 2.994  time: 2.4371  data_time: 0.4683  lr: 7.5645e-05  max_mem: 18490M
[01/24 13:50:49] d2.utils.events INFO:  eta: 1 day, 5:31:01  iter: 16019  total_loss: 45.91  loss_ce: 1.895  loss_mask: 3.272  loss_ce_0: 1.08  loss_mask_0: 3.521  loss_ce_1: 0.9249  loss_mask_1: 3.393  loss_ce_2: 0.9883  loss_mask_2: 3.283  loss_ce_3: 1.111  loss_mask_3: 3.312  loss_ce_4: 1.315  loss_mask_4: 2.937  loss_ce_5: 1.693  loss_mask_5: 2.797  loss_ce_6: 1.726  loss_mask_6: 2.984  loss_ce_7: 1.756  loss_mask_7: 3.041  loss_ce_8: 1.755  loss_mask_8: 2.917  time: 2.4374  data_time: 0.6525  lr: 7.5614e-05  max_mem: 18490M
[01/24 13:51:42] d2.utils.events INFO:  eta: 1 day, 5:32:24  iter: 16039  total_loss: 45.91  loss_ce: 1.815  loss_mask: 3.122  loss_ce_0: 1.136  loss_mask_0: 3.552  loss_ce_1: 0.9639  loss_mask_1: 3.392  loss_ce_2: 1.034  loss_mask_2: 3.367  loss_ce_3: 1.164  loss_mask_3: 3.244  loss_ce_4: 1.326  loss_mask_4: 3.037  loss_ce_5: 1.664  loss_mask_5: 2.884  loss_ce_6: 1.701  loss_mask_6: 2.979  loss_ce_7: 1.765  loss_mask_7: 3.122  loss_ce_8: 1.739  loss_mask_8: 2.935  time: 2.4377  data_time: 0.6222  lr: 7.5583e-05  max_mem: 18490M
[01/24 13:52:33] d2.utils.events INFO:  eta: 1 day, 5:38:19  iter: 16059  total_loss: 46.13  loss_ce: 1.823  loss_mask: 3.214  loss_ce_0: 1.053  loss_mask_0: 3.746  loss_ce_1: 0.9557  loss_mask_1: 3.477  loss_ce_2: 1.036  loss_mask_2: 3.346  loss_ce_3: 1.225  loss_mask_3: 3.213  loss_ce_4: 1.324  loss_mask_4: 3.066  loss_ce_5: 1.679  loss_mask_5: 2.941  loss_ce_6: 1.676  loss_mask_6: 2.92  loss_ce_7: 1.743  loss_mask_7: 3.015  loss_ce_8: 1.762  loss_mask_8: 3.003  time: 2.4378  data_time: 0.5983  lr: 7.5552e-05  max_mem: 18490M
[01/24 13:53:23] d2.utils.events INFO:  eta: 1 day, 5:42:00  iter: 16079  total_loss: 45.7  loss_ce: 1.791  loss_mask: 3.064  loss_ce_0: 1.114  loss_mask_0: 3.511  loss_ce_1: 0.9561  loss_mask_1: 3.348  loss_ce_2: 1.052  loss_mask_2: 3.306  loss_ce_3: 1.213  loss_mask_3: 3.247  loss_ce_4: 1.382  loss_mask_4: 3.148  loss_ce_5: 1.673  loss_mask_5: 2.993  loss_ce_6: 1.656  loss_mask_6: 2.819  loss_ce_7: 1.728  loss_mask_7: 2.997  loss_ce_8: 1.733  loss_mask_8: 2.949  time: 2.4379  data_time: 0.4739  lr: 7.5521e-05  max_mem: 18490M
[01/24 13:54:11] d2.utils.events INFO:  eta: 1 day, 5:37:24  iter: 16099  total_loss: 46.08  loss_ce: 1.778  loss_mask: 3.125  loss_ce_0: 1.099  loss_mask_0: 3.563  loss_ce_1: 0.9083  loss_mask_1: 3.49  loss_ce_2: 1.001  loss_mask_2: 3.363  loss_ce_3: 1.184  loss_mask_3: 3.357  loss_ce_4: 1.363  loss_mask_4: 3.123  loss_ce_5: 1.693  loss_mask_5: 2.962  loss_ce_6: 1.701  loss_mask_6: 2.963  loss_ce_7: 1.707  loss_mask_7: 3.107  loss_ce_8: 1.676  loss_mask_8: 2.974  time: 2.4379  data_time: 0.3991  lr: 7.549e-05  max_mem: 18490M
[01/24 13:54:59] d2.utils.events INFO:  eta: 1 day, 5:36:13  iter: 16119  total_loss: 45.11  loss_ce: 1.825  loss_mask: 3.136  loss_ce_0: 1.121  loss_mask_0: 3.552  loss_ce_1: 0.9559  loss_mask_1: 3.339  loss_ce_2: 1.042  loss_mask_2: 3.254  loss_ce_3: 1.138  loss_mask_3: 3.2  loss_ce_4: 1.35  loss_mask_4: 2.994  loss_ce_5: 1.711  loss_mask_5: 2.895  loss_ce_6: 1.71  loss_mask_6: 2.818  loss_ce_7: 1.718  loss_mask_7: 2.977  loss_ce_8: 1.693  loss_mask_8: 2.905  time: 2.4378  data_time: 0.3790  lr: 7.5459e-05  max_mem: 18490M
[01/24 13:55:44] d2.utils.events INFO:  eta: 1 day, 5:32:16  iter: 16139  total_loss: 44.52  loss_ce: 1.732  loss_mask: 3.027  loss_ce_0: 1.08  loss_mask_0: 3.471  loss_ce_1: 0.9433  loss_mask_1: 3.274  loss_ce_2: 1.026  loss_mask_2: 3.143  loss_ce_3: 1.145  loss_mask_3: 3.143  loss_ce_4: 1.334  loss_mask_4: 3.002  loss_ce_5: 1.698  loss_mask_5: 2.933  loss_ce_6: 1.697  loss_mask_6: 2.843  loss_ce_7: 1.667  loss_mask_7: 2.908  loss_ce_8: 1.656  loss_mask_8: 2.877  time: 2.4376  data_time: 0.3932  lr: 7.5428e-05  max_mem: 18490M
[01/24 13:56:30] d2.utils.events INFO:  eta: 1 day, 5:28:21  iter: 16159  total_loss: 45  loss_ce: 1.741  loss_mask: 3.074  loss_ce_0: 1.117  loss_mask_0: 3.534  loss_ce_1: 0.9529  loss_mask_1: 3.361  loss_ce_2: 1.073  loss_mask_2: 3.266  loss_ce_3: 1.149  loss_mask_3: 3.195  loss_ce_4: 1.343  loss_mask_4: 2.988  loss_ce_5: 1.709  loss_mask_5: 2.897  loss_ce_6: 1.715  loss_mask_6: 2.834  loss_ce_7: 1.695  loss_mask_7: 2.965  loss_ce_8: 1.668  loss_mask_8: 2.907  time: 2.4374  data_time: 0.4258  lr: 7.5397e-05  max_mem: 18490M
[01/24 13:57:16] d2.utils.events INFO:  eta: 1 day, 5:25:51  iter: 16179  total_loss: 44.55  loss_ce: 1.677  loss_mask: 2.927  loss_ce_0: 1.07  loss_mask_0: 3.451  loss_ce_1: 0.9456  loss_mask_1: 3.314  loss_ce_2: 1.031  loss_mask_2: 3.204  loss_ce_3: 1.119  loss_mask_3: 3.04  loss_ce_4: 1.347  loss_mask_4: 3.044  loss_ce_5: 1.662  loss_mask_5: 2.828  loss_ce_6: 1.702  loss_mask_6: 2.891  loss_ce_7: 1.69  loss_mask_7: 2.92  loss_ce_8: 1.676  loss_mask_8: 2.877  time: 2.4372  data_time: 0.4062  lr: 7.5366e-05  max_mem: 18490M
[01/24 13:58:03] d2.utils.events INFO:  eta: 1 day, 5:24:16  iter: 16199  total_loss: 46.47  loss_ce: 1.719  loss_mask: 3.147  loss_ce_0: 1.083  loss_mask_0: 3.717  loss_ce_1: 0.914  loss_mask_1: 3.485  loss_ce_2: 0.9888  loss_mask_2: 3.483  loss_ce_3: 1.082  loss_mask_3: 3.329  loss_ce_4: 1.253  loss_mask_4: 3.176  loss_ce_5: 1.654  loss_mask_5: 3.088  loss_ce_6: 1.686  loss_mask_6: 3.017  loss_ce_7: 1.686  loss_mask_7: 3.018  loss_ce_8: 1.644  loss_mask_8: 2.979  time: 2.4371  data_time: 0.4159  lr: 7.5335e-05  max_mem: 18490M
[01/24 13:58:49] d2.utils.events INFO:  eta: 1 day, 5:17:42  iter: 16219  total_loss: 44.08  loss_ce: 1.683  loss_mask: 2.881  loss_ce_0: 1.113  loss_mask_0: 3.441  loss_ce_1: 0.9239  loss_mask_1: 3.319  loss_ce_2: 0.997  loss_mask_2: 3.272  loss_ce_3: 1.109  loss_mask_3: 3.203  loss_ce_4: 1.266  loss_mask_4: 2.892  loss_ce_5: 1.643  loss_mask_5: 2.817  loss_ce_6: 1.693  loss_mask_6: 2.805  loss_ce_7: 1.696  loss_mask_7: 2.814  loss_ce_8: 1.652  loss_mask_8: 2.821  time: 2.4369  data_time: 0.4435  lr: 7.5305e-05  max_mem: 18490M
[01/24 13:59:35] d2.utils.events INFO:  eta: 1 day, 5:16:54  iter: 16239  total_loss: 44.71  loss_ce: 1.677  loss_mask: 2.905  loss_ce_0: 1.069  loss_mask_0: 3.524  loss_ce_1: 0.922  loss_mask_1: 3.474  loss_ce_2: 1.024  loss_mask_2: 3.373  loss_ce_3: 1.109  loss_mask_3: 3.276  loss_ce_4: 1.288  loss_mask_4: 3.037  loss_ce_5: 1.662  loss_mask_5: 2.83  loss_ce_6: 1.699  loss_mask_6: 2.828  loss_ce_7: 1.687  loss_mask_7: 2.864  loss_ce_8: 1.662  loss_mask_8: 2.957  time: 2.4368  data_time: 0.4086  lr: 7.5274e-05  max_mem: 18490M
[01/24 14:00:22] d2.utils.events INFO:  eta: 1 day, 5:13:09  iter: 16259  total_loss: 42.96  loss_ce: 1.639  loss_mask: 2.793  loss_ce_0: 1.132  loss_mask_0: 3.382  loss_ce_1: 0.9287  loss_mask_1: 3.227  loss_ce_2: 1.006  loss_mask_2: 3.15  loss_ce_3: 1.078  loss_mask_3: 2.989  loss_ce_4: 1.316  loss_mask_4: 2.857  loss_ce_5: 1.634  loss_mask_5: 2.613  loss_ce_6: 1.681  loss_mask_6: 2.667  loss_ce_7: 1.682  loss_mask_7: 2.74  loss_ce_8: 1.657  loss_mask_8: 2.683  time: 2.4366  data_time: 0.4253  lr: 7.5243e-05  max_mem: 18490M
[01/24 14:01:07] d2.utils.events INFO:  eta: 1 day, 5:10:14  iter: 16279  total_loss: 45.13  loss_ce: 1.649  loss_mask: 3.073  loss_ce_0: 1.16  loss_mask_0: 3.46  loss_ce_1: 0.9318  loss_mask_1: 3.464  loss_ce_2: 0.982  loss_mask_2: 3.332  loss_ce_3: 1.049  loss_mask_3: 3.171  loss_ce_4: 1.273  loss_mask_4: 3.058  loss_ce_5: 1.61  loss_mask_5: 2.897  loss_ce_6: 1.651  loss_mask_6: 2.896  loss_ce_7: 1.673  loss_mask_7: 3.013  loss_ce_8: 1.66  loss_mask_8: 2.964  time: 2.4365  data_time: 0.4205  lr: 7.5212e-05  max_mem: 18490M
[01/24 14:01:53] d2.utils.events INFO:  eta: 1 day, 5:08:31  iter: 16299  total_loss: 41.26  loss_ce: 1.606  loss_mask: 2.747  loss_ce_0: 1.081  loss_mask_0: 3.141  loss_ce_1: 0.9153  loss_mask_1: 3.062  loss_ce_2: 0.9666  loss_mask_2: 3.027  loss_ce_3: 1.027  loss_mask_3: 2.901  loss_ce_4: 1.22  loss_mask_4: 2.824  loss_ce_5: 1.577  loss_mask_5: 2.727  loss_ce_6: 1.623  loss_mask_6: 2.597  loss_ce_7: 1.638  loss_mask_7: 2.744  loss_ce_8: 1.63  loss_mask_8: 2.715  time: 2.4363  data_time: 0.4217  lr: 7.5181e-05  max_mem: 18490M
[01/24 14:02:39] d2.utils.events INFO:  eta: 1 day, 5:04:54  iter: 16319  total_loss: 43.14  loss_ce: 1.602  loss_mask: 2.764  loss_ce_0: 1.092  loss_mask_0: 3.227  loss_ce_1: 0.9094  loss_mask_1: 3.258  loss_ce_2: 0.9669  loss_mask_2: 3.189  loss_ce_3: 1.032  loss_mask_3: 3.142  loss_ce_4: 1.252  loss_mask_4: 2.95  loss_ce_5: 1.599  loss_mask_5: 2.736  loss_ce_6: 1.632  loss_mask_6: 2.772  loss_ce_7: 1.64  loss_mask_7: 2.877  loss_ce_8: 1.638  loss_mask_8: 2.738  time: 2.4361  data_time: 0.4016  lr: 7.515e-05  max_mem: 18490M
[01/24 14:03:25] d2.utils.events INFO:  eta: 1 day, 5:03:52  iter: 16339  total_loss: 41.06  loss_ce: 1.634  loss_mask: 2.661  loss_ce_0: 1.073  loss_mask_0: 3.19  loss_ce_1: 0.9299  loss_mask_1: 3.047  loss_ce_2: 0.9688  loss_mask_2: 2.927  loss_ce_3: 1.062  loss_mask_3: 2.768  loss_ce_4: 1.243  loss_mask_4: 2.673  loss_ce_5: 1.611  loss_mask_5: 2.596  loss_ce_6: 1.651  loss_mask_6: 2.588  loss_ce_7: 1.656  loss_mask_7: 2.655  loss_ce_8: 1.702  loss_mask_8: 2.629  time: 2.4359  data_time: 0.3922  lr: 7.5119e-05  max_mem: 18490M
[01/24 14:04:11] d2.utils.events INFO:  eta: 1 day, 5:03:08  iter: 16359  total_loss: 42.13  loss_ce: 1.613  loss_mask: 2.735  loss_ce_0: 1.11  loss_mask_0: 3.24  loss_ce_1: 0.9641  loss_mask_1: 3.104  loss_ce_2: 1.009  loss_mask_2: 3.068  loss_ce_3: 1.068  loss_mask_3: 2.972  loss_ce_4: 1.238  loss_mask_4: 2.829  loss_ce_5: 1.594  loss_mask_5: 2.663  loss_ce_6: 1.638  loss_mask_6: 2.642  loss_ce_7: 1.635  loss_mask_7: 2.63  loss_ce_8: 1.627  loss_mask_8: 2.621  time: 2.4357  data_time: 0.3997  lr: 7.5088e-05  max_mem: 18490M
[01/24 14:04:59] d2.utils.events INFO:  eta: 1 day, 5:00:01  iter: 16379  total_loss: 44.3  loss_ce: 1.66  loss_mask: 3.019  loss_ce_0: 1.14  loss_mask_0: 3.439  loss_ce_1: 0.9837  loss_mask_1: 3.257  loss_ce_2: 1.029  loss_mask_2: 3.318  loss_ce_3: 1.133  loss_mask_3: 3.134  loss_ce_4: 1.296  loss_mask_4: 2.956  loss_ce_5: 1.637  loss_mask_5: 2.785  loss_ce_6: 1.698  loss_mask_6: 2.841  loss_ce_7: 1.687  loss_mask_7: 2.918  loss_ce_8: 1.654  loss_mask_8: 2.815  time: 2.4357  data_time: 0.4160  lr: 7.5057e-05  max_mem: 18490M
[01/24 14:05:48] d2.utils.events INFO:  eta: 1 day, 4:59:13  iter: 16399  total_loss: 44.52  loss_ce: 1.681  loss_mask: 2.904  loss_ce_0: 1.112  loss_mask_0: 3.485  loss_ce_1: 0.976  loss_mask_1: 3.373  loss_ce_2: 1.042  loss_mask_2: 3.289  loss_ce_3: 1.148  loss_mask_3: 3.231  loss_ce_4: 1.306  loss_mask_4: 3.037  loss_ce_5: 1.675  loss_mask_5: 2.706  loss_ce_6: 1.689  loss_mask_6: 2.743  loss_ce_7: 1.713  loss_mask_7: 2.93  loss_ce_8: 1.655  loss_mask_8: 2.71  time: 2.4357  data_time: 0.4160  lr: 7.5026e-05  max_mem: 18490M
[01/24 14:06:34] d2.utils.events INFO:  eta: 1 day, 4:58:07  iter: 16419  total_loss: 44.29  loss_ce: 1.68  loss_mask: 2.83  loss_ce_0: 1.123  loss_mask_0: 3.228  loss_ce_1: 1.038  loss_mask_1: 3.205  loss_ce_2: 1.12  loss_mask_2: 3.126  loss_ce_3: 1.247  loss_mask_3: 3.065  loss_ce_4: 1.355  loss_mask_4: 2.954  loss_ce_5: 1.715  loss_mask_5: 2.877  loss_ce_6: 1.726  loss_mask_6: 2.82  loss_ce_7: 1.73  loss_mask_7: 2.895  loss_ce_8: 1.674  loss_mask_8: 2.747  time: 2.4355  data_time: 0.3775  lr: 7.4995e-05  max_mem: 18490M
[01/24 14:07:24] d2.utils.events INFO:  eta: 1 day, 4:56:59  iter: 16439  total_loss: 43.51  loss_ce: 1.675  loss_mask: 2.841  loss_ce_0: 1.153  loss_mask_0: 3.453  loss_ce_1: 0.9938  loss_mask_1: 3.332  loss_ce_2: 1.058  loss_mask_2: 3.174  loss_ce_3: 1.168  loss_mask_3: 3.049  loss_ce_4: 1.284  loss_mask_4: 2.988  loss_ce_5: 1.679  loss_mask_5: 2.799  loss_ce_6: 1.698  loss_mask_6: 2.831  loss_ce_7: 1.693  loss_mask_7: 2.797  loss_ce_8: 1.696  loss_mask_8: 2.759  time: 2.4356  data_time: 0.4465  lr: 7.4964e-05  max_mem: 18490M
[01/24 14:08:12] d2.utils.events INFO:  eta: 1 day, 4:53:55  iter: 16459  total_loss: 44.64  loss_ce: 1.66  loss_mask: 3.008  loss_ce_0: 1.087  loss_mask_0: 3.457  loss_ce_1: 0.9947  loss_mask_1: 3.285  loss_ce_2: 1.075  loss_mask_2: 3.207  loss_ce_3: 1.149  loss_mask_3: 3.291  loss_ce_4: 1.294  loss_mask_4: 3.049  loss_ce_5: 1.672  loss_mask_5: 2.946  loss_ce_6: 1.69  loss_mask_6: 2.933  loss_ce_7: 1.688  loss_mask_7: 2.902  loss_ce_8: 1.692  loss_mask_8: 2.839  time: 2.4356  data_time: 0.4184  lr: 7.4933e-05  max_mem: 18490M
[01/24 14:08:58] d2.utils.events INFO:  eta: 1 day, 4:50:55  iter: 16479  total_loss: 44.39  loss_ce: 1.616  loss_mask: 2.809  loss_ce_0: 1.131  loss_mask_0: 3.32  loss_ce_1: 1.026  loss_mask_1: 3.308  loss_ce_2: 1.072  loss_mask_2: 3.119  loss_ce_3: 1.162  loss_mask_3: 3.091  loss_ce_4: 1.263  loss_mask_4: 3.088  loss_ce_5: 1.62  loss_mask_5: 2.809  loss_ce_6: 1.666  loss_mask_6: 2.798  loss_ce_7: 1.679  loss_mask_7: 2.787  loss_ce_8: 1.647  loss_mask_8: 2.77  time: 2.4354  data_time: 0.4162  lr: 7.4902e-05  max_mem: 18490M
[01/24 14:09:49] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 14:09:50] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 14:09:50] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 14:14:39] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 7.140849740184564, 'error_1pix': 0.7625367265111767, 'error_3pix': 0.5796306783338143, 'mIoU': 1.069275953694069, 'fwIoU': 6.472773361465109, 'IoU-0': nan, 'IoU-1': 48.1713022213808, 'IoU-2': 0.0, 'IoU-3': 0.009495852789509972, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0018707774681765788, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 4.246479288999663, 'IoU-13': 1.9753520633607284, 'IoU-14': 0.7573598982995169, 'IoU-15': 5.674586499956691, 'IoU-16': 0.2542267987357367, 'IoU-17': 0.8097191859705049, 'IoU-18': 0.46264246087931077, 'IoU-19': 0.0, 'IoU-20': 0.04552585037656408, 'IoU-21': 3.1018150078929825, 'IoU-22': 0.2366442224977237, 'IoU-23': 1.3495167842713358, 'IoU-24': 0.5744491260730323, 'IoU-25': 0.9526549506509678, 'IoU-26': 3.2807699209355548, 'IoU-27': 6.712214968675366, 'IoU-28': 0.07097074157718335, 'IoU-29': 0.002014357101950346, 'IoU-30': 0.902806875322435, 'IoU-31': 1.0280445187235896, 'IoU-32': 1.236066346354449, 'IoU-33': 6.32901702930124, 'IoU-34': 0.5968038429048214, 'IoU-35': 0.13136080439744446, 'IoU-36': 5.849054054956517, 'IoU-37': 8.11965068063591, 'IoU-38': 0.018126321621337958, 'IoU-39': 0.7518489807989147, 'IoU-40': 3.713792656710772, 'IoU-41': 3.3933825053574935, 'IoU-42': 1.303927571408213, 'IoU-43': 7.2409846008689565, 'IoU-44': 1.5221942902804688, 'IoU-45': 0.03157401499590425, 'IoU-46': 1.027358560333455, 'IoU-47': 5.732363573855778, 'IoU-48': 0.08564628033628985, 'IoU-49': 0.10691724521522818, 'IoU-50': 0.38775079899795317, 'IoU-51': 1.3557512216205831, 'IoU-52': 1.5633276515159462, 'IoU-53': 0.15949486180030203, 'IoU-54': 6.271618076991819, 'IoU-55': 0.023810386322638825, 'IoU-56': 0.018312923652869427, 'IoU-57': 0.002561730259895298, 'IoU-58': 2.873750734172787, 'IoU-59': 0.08732539195845397, 'IoU-60': 2.432504768454682, 'IoU-61': 1.9159774921996018, 'IoU-62': 0.16205915765801707, 'IoU-63': 0.007363385359976012, 'IoU-64': 2.7984969900491152, 'IoU-65': 3.0337584807542495, 'IoU-66': 0.44478809315891976, 'IoU-67': 2.818429619584548, 'IoU-68': 0.0013579652421252025, 'IoU-69': 0.014766310998971525, 'IoU-70': 0.6624751157866654, 'IoU-71': 3.9579005624998804, 'IoU-72': 0.2096106972874169, 'IoU-73': 0.0016418379990732982, 'IoU-74': 2.724681603155826, 'IoU-75': 0.016571941363576426, 'IoU-76': 1.287055762224875, 'IoU-77': 0.619668316299587, 'IoU-78': 2.811249606165311, 'IoU-79': 0.2181767446435732, 'IoU-80': 2.6837024574342063, 'IoU-81': 0.001709709428815862, 'IoU-82': 0.015494100598806687, 'IoU-83': 2.730917296054568, 'IoU-84': 1.353738631475312, 'IoU-85': 0.029594295221534356, 'IoU-86': 0.0930864228328275, 'IoU-87': 0.009195946925358526, 'IoU-88': 0.27022372093662617, 'IoU-89': 2.018207980019653, 'IoU-90': 0.9305012968588303, 'IoU-91': 0.01013378767384594, 'IoU-92': 2.142205111123577, 'IoU-93': 0.00010308907897860519, 'IoU-94': 0.001534495924166123, 'IoU-95': 3.121801575293699, 'IoU-96': 0.829651508083076, 'IoU-97': 0.02230327447822681, 'IoU-98': 0.0032701258728945193, 'IoU-99': 1.1443106393469908, 'IoU-100': 0.6887169929836257, 'IoU-101': 0.8873434545484113, 'IoU-102': 0.004457041809314629, 'IoU-103': 0.04418383663840933, 'IoU-104': 0.001670622931068624, 'IoU-105': 1.58150300150345, 'IoU-106': 0.17617050187637906, 'IoU-107': 0.015761305491715647, 'IoU-108': 0.05336013927282813, 'IoU-109': 0.2305376884065968, 'IoU-110': 0.004540651574712614, 'IoU-111': 1.3372156376377984, 'IoU-112': 1.2101493525843672, 'IoU-113': 0.0, 'IoU-114': 0.0018522049410290634, 'IoU-115': 1.031636427634823, 'IoU-116': 1.4738867111012501, 'IoU-117': 0.2791341711075583, 'IoU-118': 0.09257693822959003, 'IoU-119': 1.0520631351122827, 'IoU-120': 0.0024070864625457345, 'IoU-121': 0.0005845378935682397, 'IoU-122': 0.047594332431420035, 'IoU-123': 1.9212899378497923, 'IoU-124': 0.45673972195708673, 'IoU-125': 0.0, 'IoU-126': 0.6471497862303426, 'IoU-127': 0.0006995053331452441, 'IoU-128': 0.02064134966905036, 'IoU-129': 6.270925293839882e-05, 'IoU-130': 0.0008101813622140138, 'IoU-131': 0.06300745115867387, 'IoU-132': 0.010064005752373815, 'IoU-133': 0.007505882989370047, 'IoU-134': 1.4407255250306197, 'IoU-135': 0.00028454035351293524, 'IoU-136': 0.0, 'IoU-137': 0.001217420572259282, 'IoU-138': 0.00047579473580704304, 'IoU-139': 0.11897729160534556, 'IoU-140': 0.021885639118054658, 'IoU-141': 0.1410012594774423, 'IoU-142': 0.16170492879936915, 'IoU-143': 0.0, 'IoU-144': 0.0004510844069142218, 'IoU-145': 0.010752922769080204, 'IoU-146': 0.012196044742569983, 'IoU-147': 1.6078406609764648, 'IoU-148': 0.0, 'IoU-149': 0.0002028210378149684, 'IoU-150': 0.0, 'IoU-151': 0.0023160771548466023, 'IoU-152': 0.0, 'IoU-153': 0.002385580190142101, 'IoU-154': 0.0296144527303977, 'IoU-155': 0.0, 'IoU-156': 0.9244306664030073, 'IoU-157': 0.0, 'IoU-158': 1.3811885067299774, 'IoU-159': 0.0, 'IoU-160': 0.013156181506477724, 'IoU-161': 0.0, 'IoU-162': 0.003543774474192462, 'IoU-163': 0.0, 'IoU-164': 0.2522010546807915, 'IoU-165': 0.0, 'IoU-166': 0.00016634312928021666, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.00017495884093267057, 'IoU-170': 0.3099090056975486, 'IoU-171': 0.001813026230863508, 'IoU-172': 0.0, 'IoU-173': 0.00018784740028590373, 'IoU-174': 0.0, 'IoU-175': 0.004364199742148532, 'IoU-176': 0.0, 'IoU-177': 0.005329051144680186, 'IoU-178': 1.400158947374689, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0025557733642411528, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 3.501220815357991, 'pACC': 13.470004796651953, 'ACC-0': nan, 'ACC-1': 80.95642589978746, 'ACC-2': 0.0, 'ACC-3': 0.010629669255530317, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0019304458804902654, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 7.706904877035909, 'ACC-13': 2.43945503950775, 'ACC-14': 0.7975551015278581, 'ACC-15': 16.638648378823877, 'ACC-16': 0.264078019365333, 'ACC-17': 0.9109619812652702, 'ACC-18': 0.4884706206811744, 'ACC-19': 0.0, 'ACC-20': 0.04654472826451102, 'ACC-21': 5.671708720296044, 'ACC-22': 0.25193662619446433, 'ACC-23': 2.3099490030734215, 'ACC-24': 0.6918642243781699, 'ACC-25': 1.1327697673670665, 'ACC-26': 18.290653677702064, 'ACC-27': 39.160413753786216, 'ACC-28': 0.07197308770223626, 'ACC-29': 0.002016225182351438, 'ACC-30': 1.007244903061601, 'ACC-31': 1.2685975675238186, 'ACC-32': 1.3675092862218956, 'ACC-33': 39.763397621264744, 'ACC-34': 0.6151618338590492, 'ACC-35': 0.1331603588681375, 'ACC-36': 14.736190326076162, 'ACC-37': 34.58814776235157, 'ACC-38': 0.018164048861607534, 'ACC-39': 0.834529920615588, 'ACC-40': 6.006916841588651, 'ACC-41': 5.4489407674172154, 'ACC-42': 1.6366830120032543, 'ACC-43': 39.6576676240421, 'ACC-44': 1.8969268747099648, 'ACC-45': 0.03203570077262951, 'ACC-46': 1.151944131802198, 'ACC-47': 20.43422774970871, 'ACC-48': 0.08645389329195297, 'ACC-49': 0.11483693885665124, 'ACC-50': 0.41951896013211215, 'ACC-51': 1.6350935218290001, 'ACC-52': 1.9474535241770439, 'ACC-53': 0.1630831525999353, 'ACC-54': 42.42168552407277, 'ACC-55': 0.024036558291494217, 'ACC-56': 0.018353845095581765, 'ACC-57': 0.00256568709683564, 'ACC-58': 6.156263861886638, 'ACC-59': 0.08936666929239735, 'ACC-60': 3.570653857338667, 'ACC-61': 3.6594362339202533, 'ACC-62': 0.16622585124810466, 'ACC-63': 0.007405923558325845, 'ACC-64': 9.68065279658094, 'ACC-65': 10.374140592426778, 'ACC-66': 0.49575209799058145, 'ACC-67': 11.84630649614251, 'ACC-68': 0.0013591821003052658, 'ACC-69': 0.014828876355663819, 'ACC-70': 0.9088246121104319, 'ACC-71': 14.855667903591529, 'ACC-72': 0.25428817574460083, 'ACC-73': 0.0016463586303887307, 'ACC-74': 7.7958455982912085, 'ACC-75': 0.01678425839677026, 'ACC-76': 4.11495751641878, 'ACC-77': 0.9144410490140576, 'ACC-78': 8.093763816412228, 'ACC-79': 0.24209933178757767, 'ACC-80': 16.89534415299134, 'ACC-81': 0.0017174191732676504, 'ACC-82': 0.015571595699269284, 'ACC-83': 13.231313825955231, 'ACC-84': 2.3885073096750564, 'ACC-85': 0.030088789703893906, 'ACC-86': 0.09823388891293482, 'ACC-87': 0.009383971051856288, 'ACC-88': 0.2940131812620861, 'ACC-89': 6.819441851609308, 'ACC-90': 1.3405595469599672, 'ACC-91': 0.010178529779411666, 'ACC-92': 6.80955389476621, 'ACC-93': 0.00010312451061895185, 'ACC-94': 0.0015356975168531399, 'ACC-95': 35.33394822913158, 'ACC-96': 1.6312429130427324, 'ACC-97': 0.022428323102765036, 'ACC-98': 0.003285673614542464, 'ACC-99': 4.165589972902028, 'ACC-100': 1.3346137970574472, 'ACC-101': 1.161036227734877, 'ACC-102': 0.004463072043497961, 'ACC-103': 0.044512137527155944, 'ACC-104': 0.0016723641818941982, 'ACC-105': 4.865266727466964, 'ACC-106': 0.2193501728185671, 'ACC-107': 0.016181916287003554, 'ACC-108': 0.05662681601701513, 'ACC-109': 0.2582060800898108, 'ACC-110': 0.004667031397679552, 'ACC-111': 5.722651518499123, 'ACC-112': 6.550013046040176, 'ACC-113': 0.0, 'ACC-114': 0.0018586026150903224, 'ACC-115': 2.4455745493362198, 'ACC-116': 5.85611964325859, 'ACC-117': 0.3520376878425044, 'ACC-118': 0.09955086646202267, 'ACC-119': 1.9126438911327592, 'ACC-120': 0.002415866356030178, 'ACC-121': 0.0005904724097224462, 'ACC-122': 0.053166897827092004, 'ACC-123': 7.751461013008493, 'ACC-124': 0.9564749046535056, 'ACC-125': 0.0, 'ACC-126': 1.7785339575041668, 'ACC-127': 0.0007008756272836864, 'ACC-128': 0.02195413780612301, 'ACC-129': 6.275261850988887e-05, 'ACC-130': 0.000838400280670617, 'ACC-131': 0.06944845960658279, 'ACC-132': 0.010187223746954724, 'ACC-133': 0.007552715915817836, 'ACC-134': 3.268728996122361, 'ACC-135': 0.00028504646257339946, 'ACC-136': 0.0, 'ACC-137': 0.0012974949951038645, 'ACC-138': 0.0004759245627839683, 'ACC-139': 0.14150405860858714, 'ACC-140': 0.023687771974549725, 'ACC-141': 0.1891813195228726, 'ACC-142': 0.18750092789816436, 'ACC-143': 0.0, 'ACC-144': 0.0004512635379061372, 'ACC-145': 0.012343746505959435, 'ACC-146': 0.012519704827397135, 'ACC-147': 26.1959566678397, 'ACC-148': 0.0, 'ACC-149': 0.0002028255629169967, 'ACC-150': 0.0, 'ACC-151': 0.002344708366239184, 'ACC-152': 0.0, 'ACC-153': 0.0024047710657945365, 'ACC-154': 0.0317025316232753, 'ACC-155': 0.0, 'ACC-156': 5.989127835198149, 'ACC-157': 0.0, 'ACC-158': 18.43353548297864, 'ACC-159': 0.0, 'ACC-160': 0.013714201692077998, 'ACC-161': 0.0, 'ACC-162': 0.0035703553396151753, 'ACC-163': 0.0, 'ACC-164': 0.3329538716193291, 'ACC-165': 0.0, 'ACC-166': 0.00016788241515642443, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.00017547153588480646, 'ACC-170': 0.4559038573477008, 'ACC-171': 0.0018368542768396553, 'ACC-172': 0.0, 'ACC-173': 0.000188144630540389, 'ACC-174': 0.0, 'ACC-175': 0.004437221633674075, 'ACC-176': 0.0, 'ACC-177': 0.0055363934825575925, 'ACC-178': 7.721489402388591, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.002567255680695008, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 14:14:39] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 14:14:39] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 14:14:39] d2.evaluation.testing INFO: copypaste: 7.1408,0.7625,0.5796,1.0693,6.4728,3.5012,13.4700
[01/24 14:14:39] d2.utils.events INFO:  eta: 1 day, 4:49:07  iter: 16499  total_loss: 45.01  loss_ce: 1.626  loss_mask: 2.992  loss_ce_0: 1.037  loss_mask_0: 3.496  loss_ce_1: 0.9171  loss_mask_1: 3.363  loss_ce_2: 0.9996  loss_mask_2: 3.231  loss_ce_3: 1.11  loss_mask_3: 3.192  loss_ce_4: 1.244  loss_mask_4: 3.156  loss_ce_5: 1.621  loss_mask_5: 2.931  loss_ce_6: 1.667  loss_mask_6: 2.887  loss_ce_7: 1.69  loss_mask_7: 2.989  loss_ce_8: 1.67  loss_mask_8: 2.956  time: 2.4355  data_time: 0.4572  lr: 7.4871e-05  max_mem: 18490M
[01/24 14:15:36] d2.utils.events INFO:  eta: 1 day, 4:49:35  iter: 16519  total_loss: 45.17  loss_ce: 1.611  loss_mask: 2.882  loss_ce_0: 1.072  loss_mask_0: 3.542  loss_ce_1: 0.9852  loss_mask_1: 3.473  loss_ce_2: 1.088  loss_mask_2: 3.231  loss_ce_3: 1.156  loss_mask_3: 3.214  loss_ce_4: 1.296  loss_mask_4: 3  loss_ce_5: 1.694  loss_mask_5: 2.966  loss_ce_6: 1.716  loss_mask_6: 2.846  loss_ce_7: 1.689  loss_mask_7: 2.957  loss_ce_8: 1.685  loss_mask_8: 2.859  time: 2.4360  data_time: 0.6447  lr: 7.484e-05  max_mem: 18490M
[01/24 14:16:29] d2.utils.events INFO:  eta: 1 day, 4:50:31  iter: 16539  total_loss: 43.73  loss_ce: 1.71  loss_mask: 2.908  loss_ce_0: 1.042  loss_mask_0: 3.331  loss_ce_1: 0.9574  loss_mask_1: 3.081  loss_ce_2: 1.042  loss_mask_2: 3.022  loss_ce_3: 1.135  loss_mask_3: 2.963  loss_ce_4: 1.31  loss_mask_4: 2.906  loss_ce_5: 1.659  loss_mask_5: 2.821  loss_ce_6: 1.701  loss_mask_6: 2.789  loss_ce_7: 1.679  loss_mask_7: 2.981  loss_ce_8: 1.799  loss_mask_8: 2.967  time: 2.4363  data_time: 0.6286  lr: 7.4809e-05  max_mem: 18490M
[01/24 14:17:23] d2.utils.events INFO:  eta: 1 day, 4:51:40  iter: 16559  total_loss: 44.14  loss_ce: 1.683  loss_mask: 2.943  loss_ce_0: 1.101  loss_mask_0: 3.315  loss_ce_1: 0.9855  loss_mask_1: 3.284  loss_ce_2: 1.079  loss_mask_2: 3.152  loss_ce_3: 1.159  loss_mask_3: 3.019  loss_ce_4: 1.324  loss_mask_4: 2.937  loss_ce_5: 1.654  loss_mask_5: 2.847  loss_ce_6: 1.689  loss_mask_6: 2.788  loss_ce_7: 1.72  loss_mask_7: 2.944  loss_ce_8: 1.754  loss_mask_8: 2.878  time: 2.4366  data_time: 0.6331  lr: 7.4778e-05  max_mem: 18490M
[01/24 14:18:18] d2.utils.events INFO:  eta: 1 day, 4:54:56  iter: 16579  total_loss: 43.36  loss_ce: 1.67  loss_mask: 2.816  loss_ce_0: 1.096  loss_mask_0: 3.366  loss_ce_1: 0.953  loss_mask_1: 3.284  loss_ce_2: 1.065  loss_mask_2: 3.108  loss_ce_3: 1.143  loss_mask_3: 2.962  loss_ce_4: 1.276  loss_mask_4: 2.852  loss_ce_5: 1.664  loss_mask_5: 2.728  loss_ce_6: 1.698  loss_mask_6: 2.773  loss_ce_7: 1.741  loss_mask_7: 2.929  loss_ce_8: 1.743  loss_mask_8: 2.757  time: 2.4370  data_time: 0.6385  lr: 7.4747e-05  max_mem: 18490M
[01/24 14:19:11] d2.utils.events INFO:  eta: 1 day, 4:58:36  iter: 16599  total_loss: 43.94  loss_ce: 1.686  loss_mask: 2.769  loss_ce_0: 1.063  loss_mask_0: 3.319  loss_ce_1: 0.9683  loss_mask_1: 3.247  loss_ce_2: 1.047  loss_mask_2: 3.101  loss_ce_3: 1.121  loss_mask_3: 2.992  loss_ce_4: 1.257  loss_mask_4: 2.878  loss_ce_5: 1.67  loss_mask_5: 2.868  loss_ce_6: 1.689  loss_mask_6: 2.803  loss_ce_7: 1.72  loss_mask_7: 2.952  loss_ce_8: 1.737  loss_mask_8: 2.841  time: 2.4373  data_time: 0.5549  lr: 7.4716e-05  max_mem: 18490M
[01/24 14:20:06] d2.utils.events INFO:  eta: 1 day, 5:01:39  iter: 16619  total_loss: 44.18  loss_ce: 1.651  loss_mask: 2.897  loss_ce_0: 1.166  loss_mask_0: 3.471  loss_ce_1: 0.974  loss_mask_1: 3.249  loss_ce_2: 1.07  loss_mask_2: 3.177  loss_ce_3: 1.18  loss_mask_3: 3.11  loss_ce_4: 1.257  loss_mask_4: 2.92  loss_ce_5: 1.662  loss_mask_5: 2.744  loss_ce_6: 1.701  loss_mask_6: 2.81  loss_ce_7: 1.702  loss_mask_7: 2.89  loss_ce_8: 1.708  loss_mask_8: 2.873  time: 2.4376  data_time: 0.5872  lr: 7.4685e-05  max_mem: 18490M
[01/24 14:20:53] d2.utils.events INFO:  eta: 1 day, 5:01:41  iter: 16639  total_loss: 44.96  loss_ce: 1.686  loss_mask: 2.968  loss_ce_0: 1.158  loss_mask_0: 3.519  loss_ce_1: 0.9198  loss_mask_1: 3.361  loss_ce_2: 1.038  loss_mask_2: 3.173  loss_ce_3: 1.117  loss_mask_3: 3.117  loss_ce_4: 1.219  loss_mask_4: 2.996  loss_ce_5: 1.63  loss_mask_5: 2.793  loss_ce_6: 1.667  loss_mask_6: 2.874  loss_ce_7: 1.687  loss_mask_7: 3.011  loss_ce_8: 1.697  loss_mask_8: 2.926  time: 2.4375  data_time: 0.4076  lr: 7.4654e-05  max_mem: 18490M
[01/24 14:21:39] d2.utils.events INFO:  eta: 1 day, 5:00:08  iter: 16659  total_loss: 44.17  loss_ce: 1.649  loss_mask: 2.896  loss_ce_0: 1.119  loss_mask_0: 3.41  loss_ce_1: 0.9437  loss_mask_1: 3.249  loss_ce_2: 1.047  loss_mask_2: 3.163  loss_ce_3: 1.101  loss_mask_3: 3.098  loss_ce_4: 1.223  loss_mask_4: 2.928  loss_ce_5: 1.605  loss_mask_5: 2.818  loss_ce_6: 1.636  loss_mask_6: 2.806  loss_ce_7: 1.65  loss_mask_7: 2.896  loss_ce_8: 1.657  loss_mask_8: 2.872  time: 2.4373  data_time: 0.3950  lr: 7.4623e-05  max_mem: 18490M
[01/24 14:22:30] d2.utils.events INFO:  eta: 1 day, 5:03:11  iter: 16679  total_loss: 42.95  loss_ce: 1.623  loss_mask: 2.813  loss_ce_0: 1.201  loss_mask_0: 3.193  loss_ce_1: 1.038  loss_mask_1: 3.212  loss_ce_2: 1.114  loss_mask_2: 3.02  loss_ce_3: 1.153  loss_mask_3: 3.015  loss_ce_4: 1.252  loss_mask_4: 2.881  loss_ce_5: 1.636  loss_mask_5: 2.739  loss_ce_6: 1.651  loss_mask_6: 2.687  loss_ce_7: 1.677  loss_mask_7: 2.696  loss_ce_8: 1.668  loss_mask_8: 2.739  time: 2.4375  data_time: 0.4577  lr: 7.4592e-05  max_mem: 18490M
[01/24 14:23:18] d2.utils.events INFO:  eta: 1 day, 4:58:26  iter: 16699  total_loss: 46.47  loss_ce: 1.628  loss_mask: 2.984  loss_ce_0: 1.172  loss_mask_0: 3.674  loss_ce_1: 1.069  loss_mask_1: 3.525  loss_ce_2: 1.169  loss_mask_2: 3.428  loss_ce_3: 1.29  loss_mask_3: 3.313  loss_ce_4: 1.367  loss_mask_4: 3.19  loss_ce_5: 1.695  loss_mask_5: 2.934  loss_ce_6: 1.68  loss_mask_6: 2.884  loss_ce_7: 1.719  loss_mask_7: 3.016  loss_ce_8: 1.686  loss_mask_8: 2.964  time: 2.4374  data_time: 0.3804  lr: 7.4561e-05  max_mem: 18490M
[01/24 14:24:07] d2.utils.events INFO:  eta: 1 day, 5:01:25  iter: 16719  total_loss: 46.2  loss_ce: 1.67  loss_mask: 3.082  loss_ce_0: 1.174  loss_mask_0: 3.546  loss_ce_1: 1  loss_mask_1: 3.355  loss_ce_2: 1.114  loss_mask_2: 3.371  loss_ce_3: 1.22  loss_mask_3: 3.368  loss_ce_4: 1.335  loss_mask_4: 3.183  loss_ce_5: 1.679  loss_mask_5: 3.038  loss_ce_6: 1.707  loss_mask_6: 2.911  loss_ce_7: 1.714  loss_mask_7: 2.995  loss_ce_8: 1.709  loss_mask_8: 3.073  time: 2.4374  data_time: 0.4440  lr: 7.453e-05  max_mem: 18490M
[01/24 14:24:57] d2.utils.events INFO:  eta: 1 day, 5:01:33  iter: 16739  total_loss: 43.99  loss_ce: 1.633  loss_mask: 2.86  loss_ce_0: 1.142  loss_mask_0: 3.472  loss_ce_1: 0.9709  loss_mask_1: 3.278  loss_ce_2: 1.091  loss_mask_2: 3.199  loss_ce_3: 1.223  loss_mask_3: 3.066  loss_ce_4: 1.3  loss_mask_4: 2.885  loss_ce_5: 1.651  loss_mask_5: 2.783  loss_ce_6: 1.674  loss_mask_6: 2.824  loss_ce_7: 1.678  loss_mask_7: 2.822  loss_ce_8: 1.659  loss_mask_8: 2.805  time: 2.4375  data_time: 0.4154  lr: 7.4499e-05  max_mem: 18490M
[01/24 14:25:44] d2.utils.events INFO:  eta: 1 day, 5:00:09  iter: 16759  total_loss: 46.84  loss_ce: 1.659  loss_mask: 3.106  loss_ce_0: 1.134  loss_mask_0: 3.63  loss_ce_1: 0.933  loss_mask_1: 3.403  loss_ce_2: 1.073  loss_mask_2: 3.335  loss_ce_3: 1.227  loss_mask_3: 3.329  loss_ce_4: 1.285  loss_mask_4: 3.201  loss_ce_5: 1.663  loss_mask_5: 3.003  loss_ce_6: 1.729  loss_mask_6: 3.171  loss_ce_7: 1.76  loss_mask_7: 3.105  loss_ce_8: 1.685  loss_mask_8: 3.016  time: 2.4374  data_time: 0.3650  lr: 7.4468e-05  max_mem: 18490M
[01/24 14:26:30] d2.utils.events INFO:  eta: 1 day, 4:52:52  iter: 16779  total_loss: 43.28  loss_ce: 1.605  loss_mask: 2.803  loss_ce_0: 1.136  loss_mask_0: 3.276  loss_ce_1: 0.9547  loss_mask_1: 3.056  loss_ce_2: 1.087  loss_mask_2: 3.06  loss_ce_3: 1.221  loss_mask_3: 2.922  loss_ce_4: 1.304  loss_mask_4: 2.824  loss_ce_5: 1.621  loss_mask_5: 2.767  loss_ce_6: 1.659  loss_mask_6: 2.725  loss_ce_7: 1.689  loss_mask_7: 2.823  loss_ce_8: 1.639  loss_mask_8: 2.768  time: 2.4372  data_time: 0.3980  lr: 7.4437e-05  max_mem: 18490M
[01/24 14:27:19] d2.utils.events INFO:  eta: 1 day, 4:54:31  iter: 16799  total_loss: 46.1  loss_ce: 1.656  loss_mask: 2.827  loss_ce_0: 1.156  loss_mask_0: 3.576  loss_ce_1: 0.9743  loss_mask_1: 3.363  loss_ce_2: 1.131  loss_mask_2: 3.2  loss_ce_3: 1.26  loss_mask_3: 3.26  loss_ce_4: 1.387  loss_mask_4: 3.159  loss_ce_5: 1.664  loss_mask_5: 3.015  loss_ce_6: 1.71  loss_mask_6: 2.977  loss_ce_7: 1.754  loss_mask_7: 2.898  loss_ce_8: 1.718  loss_mask_8: 2.802  time: 2.4372  data_time: 0.4447  lr: 7.4406e-05  max_mem: 18490M
[01/24 14:28:06] d2.utils.events INFO:  eta: 1 day, 4:52:40  iter: 16819  total_loss: 45.43  loss_ce: 1.646  loss_mask: 2.904  loss_ce_0: 1.19  loss_mask_0: 3.444  loss_ce_1: 1.04  loss_mask_1: 3.341  loss_ce_2: 1.158  loss_mask_2: 3.263  loss_ce_3: 1.304  loss_mask_3: 3.205  loss_ce_4: 1.418  loss_mask_4: 3.129  loss_ce_5: 1.672  loss_mask_5: 2.853  loss_ce_6: 1.682  loss_mask_6: 2.825  loss_ce_7: 1.712  loss_mask_7: 2.906  loss_ce_8: 1.684  loss_mask_8: 2.847  time: 2.4371  data_time: 0.4072  lr: 7.4375e-05  max_mem: 18490M
[01/24 14:28:54] d2.utils.events INFO:  eta: 1 day, 4:48:15  iter: 16839  total_loss: 45.33  loss_ce: 1.637  loss_mask: 2.869  loss_ce_0: 1.191  loss_mask_0: 3.395  loss_ce_1: 1.038  loss_mask_1: 3.338  loss_ce_2: 1.091  loss_mask_2: 3.2  loss_ce_3: 1.204  loss_mask_3: 3.191  loss_ce_4: 1.402  loss_mask_4: 3.091  loss_ce_5: 1.677  loss_mask_5: 2.867  loss_ce_6: 1.684  loss_mask_6: 2.941  loss_ce_7: 1.685  loss_mask_7: 2.907  loss_ce_8: 1.698  loss_mask_8: 2.934  time: 2.4371  data_time: 0.4213  lr: 7.4344e-05  max_mem: 18490M
[01/24 14:29:43] d2.utils.events INFO:  eta: 1 day, 4:48:17  iter: 16859  total_loss: 45.71  loss_ce: 1.639  loss_mask: 2.868  loss_ce_0: 1.145  loss_mask_0: 3.483  loss_ce_1: 1.041  loss_mask_1: 3.319  loss_ce_2: 1.105  loss_mask_2: 3.212  loss_ce_3: 1.268  loss_mask_3: 3.267  loss_ce_4: 1.398  loss_mask_4: 3.185  loss_ce_5: 1.728  loss_mask_5: 2.929  loss_ce_6: 1.696  loss_mask_6: 2.931  loss_ce_7: 1.701  loss_mask_7: 2.895  loss_ce_8: 1.696  loss_mask_8: 2.942  time: 2.4371  data_time: 0.4398  lr: 7.4313e-05  max_mem: 18490M
[01/24 14:30:30] d2.utils.events INFO:  eta: 1 day, 4:46:59  iter: 16879  total_loss: 46.54  loss_ce: 1.691  loss_mask: 2.851  loss_ce_0: 1.224  loss_mask_0: 3.377  loss_ce_1: 1.118  loss_mask_1: 3.299  loss_ce_2: 1.206  loss_mask_2: 3.262  loss_ce_3: 1.316  loss_mask_3: 3.362  loss_ce_4: 1.427  loss_mask_4: 3.313  loss_ce_5: 1.817  loss_mask_5: 3.123  loss_ce_6: 1.829  loss_mask_6: 3.082  loss_ce_7: 1.87  loss_mask_7: 3.014  loss_ce_8: 1.778  loss_mask_8: 2.876  time: 2.4370  data_time: 0.3876  lr: 7.4282e-05  max_mem: 18490M
[01/24 14:31:21] d2.utils.events INFO:  eta: 1 day, 4:46:11  iter: 16899  total_loss: 48.24  loss_ce: 1.763  loss_mask: 3.143  loss_ce_0: 1.422  loss_mask_0: 3.746  loss_ce_1: 1.242  loss_mask_1: 3.498  loss_ce_2: 1.357  loss_mask_2: 3.336  loss_ce_3: 1.424  loss_mask_3: 3.429  loss_ce_4: 1.518  loss_mask_4: 3.318  loss_ce_5: 1.875  loss_mask_5: 3.097  loss_ce_6: 1.89  loss_mask_6: 3.197  loss_ce_7: 1.935  loss_mask_7: 3.121  loss_ce_8: 1.835  loss_mask_8: 3.209  time: 2.4371  data_time: 0.4217  lr: 7.4251e-05  max_mem: 18490M
[01/24 14:32:10] d2.utils.events INFO:  eta: 1 day, 4:47:36  iter: 16919  total_loss: 48.63  loss_ce: 1.776  loss_mask: 3.172  loss_ce_0: 1.35  loss_mask_0: 3.768  loss_ce_1: 1.118  loss_mask_1: 3.575  loss_ce_2: 1.193  loss_mask_2: 3.426  loss_ce_3: 1.269  loss_mask_3: 3.494  loss_ce_4: 1.327  loss_mask_4: 3.333  loss_ce_5: 1.805  loss_mask_5: 3.075  loss_ce_6: 1.826  loss_mask_6: 3.089  loss_ce_7: 1.824  loss_mask_7: 3.025  loss_ce_8: 1.826  loss_mask_8: 3.064  time: 2.4372  data_time: 0.4067  lr: 7.422e-05  max_mem: 18490M
[01/24 14:33:00] d2.utils.events INFO:  eta: 1 day, 4:48:57  iter: 16939  total_loss: 51  loss_ce: 1.742  loss_mask: 3.31  loss_ce_0: 1.394  loss_mask_0: 3.727  loss_ce_1: 1.116  loss_mask_1: 3.638  loss_ce_2: 1.18  loss_mask_2: 3.597  loss_ce_3: 1.29  loss_mask_3: 3.629  loss_ce_4: 1.403  loss_mask_4: 3.513  loss_ce_5: 1.837  loss_mask_5: 3.24  loss_ce_6: 1.824  loss_mask_6: 3.147  loss_ce_7: 1.847  loss_mask_7: 3.316  loss_ce_8: 1.827  loss_mask_8: 3.294  time: 2.4372  data_time: 0.4021  lr: 7.4189e-05  max_mem: 18490M
[01/24 14:33:52] d2.utils.events INFO:  eta: 1 day, 4:44:59  iter: 16959  total_loss: 46.49  loss_ce: 1.706  loss_mask: 3.054  loss_ce_0: 1.281  loss_mask_0: 3.545  loss_ce_1: 1.123  loss_mask_1: 3.297  loss_ce_2: 1.162  loss_mask_2: 3.254  loss_ce_3: 1.323  loss_mask_3: 3.126  loss_ce_4: 1.342  loss_mask_4: 3.133  loss_ce_5: 1.811  loss_mask_5: 2.958  loss_ce_6: 1.778  loss_mask_6: 3.009  loss_ce_7: 1.819  loss_mask_7: 3.019  loss_ce_8: 1.82  loss_mask_8: 2.962  time: 2.4374  data_time: 0.4473  lr: 7.4158e-05  max_mem: 18490M
[01/24 14:34:42] d2.utils.events INFO:  eta: 1 day, 4:42:58  iter: 16979  total_loss: 46.71  loss_ce: 1.706  loss_mask: 3.009  loss_ce_0: 1.24  loss_mask_0: 3.549  loss_ce_1: 1.072  loss_mask_1: 3.375  loss_ce_2: 1.161  loss_mask_2: 3.316  loss_ce_3: 1.235  loss_mask_3: 3.297  loss_ce_4: 1.388  loss_mask_4: 3.295  loss_ce_5: 1.855  loss_mask_5: 3.14  loss_ce_6: 1.819  loss_mask_6: 2.999  loss_ce_7: 1.811  loss_mask_7: 3.061  loss_ce_8: 1.853  loss_mask_8: 2.961  time: 2.4374  data_time: 0.4313  lr: 7.4127e-05  max_mem: 18490M
[01/24 14:35:30] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 14:35:30] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 14:35:30] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 14:39:54] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 9.774998224268465, 'error_1pix': 0.8791532916907743, 'error_3pix': 0.7274289241921419, 'mIoU': 0.720098730769208, 'fwIoU': 1.1284039616709336, 'IoU-0': nan, 'IoU-1': 0.011688828116810084, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 6.233170051288393e-05, 'IoU-11': 0.0, 'IoU-12': 0.030653348148296906, 'IoU-13': 0.046303541918640334, 'IoU-14': 1.1892745159752562, 'IoU-15': 0.6706370567336613, 'IoU-16': 0.09118804334120449, 'IoU-17': 0.0738120068786653, 'IoU-18': 8.947211719272643e-06, 'IoU-19': 0.0, 'IoU-20': 2.1539852018754935e-05, 'IoU-21': 0.9717631269039397, 'IoU-22': 0.0, 'IoU-23': 0.7233368400130685, 'IoU-24': 0.001989648814303661, 'IoU-25': 0.03183693479912849, 'IoU-26': 2.7653311244065018, 'IoU-27': 3.2236667904792604, 'IoU-28': 0.015449846997966218, 'IoU-29': 3.2229685995916393, 'IoU-30': 3.6516379146968565, 'IoU-31': 0.27007394871692936, 'IoU-32': 1.0759200305915113, 'IoU-33': 5.4634813992112115, 'IoU-34': 5.524658171480043, 'IoU-35': 0.22982075797911578, 'IoU-36': 4.364052677934008, 'IoU-37': 0.03950477306179413, 'IoU-38': 5.685529783333104, 'IoU-39': 0.3453848756806113, 'IoU-40': 3.142254961565379, 'IoU-41': 0.28897926456594714, 'IoU-42': 3.6938438881571263, 'IoU-43': 1.7028233211043975, 'IoU-44': 0.01480487792675963, 'IoU-45': 0.23624222469796227, 'IoU-46': 5.017631375435451, 'IoU-47': 0.019031114981309, 'IoU-48': 0.3751551990827541, 'IoU-49': 2.951936999579234, 'IoU-50': 3.417090618513744, 'IoU-51': 1.4954660683688923, 'IoU-52': 0.022768364738279288, 'IoU-53': 3.5647121065576113, 'IoU-54': 0.10751917346463302, 'IoU-55': 2.522896505915607, 'IoU-56': 0.558602234989375, 'IoU-57': 0.000123080470983617, 'IoU-58': 0.6962635036104249, 'IoU-59': 3.0925760128423723, 'IoU-60': 2.163545192642067, 'IoU-61': 0.3093082678029204, 'IoU-62': 0.06609252025944726, 'IoU-63': 1.8312731616900546, 'IoU-64': 1.940745948984737, 'IoU-65': 0.0167007803899202, 'IoU-66': 0.16677005125026112, 'IoU-67': 0.0280951705758679, 'IoU-68': 0.32880156582598835, 'IoU-69': 0.4275423048610698, 'IoU-70': 0.05399169246202118, 'IoU-71': 0.7368082482461565, 'IoU-72': 2.7510714660101514, 'IoU-73': 0.3721134732448617, 'IoU-74': 0.030902582228844153, 'IoU-75': 1.7100484637306042, 'IoU-76': 0.02247495440794963, 'IoU-77': 2.7724199538648118, 'IoU-78': 0.5536613699450825, 'IoU-79': 0.41667491968444714, 'IoU-80': 1.773285591547225, 'IoU-81': 0.17331119958425956, 'IoU-82': 0.0574589644538832, 'IoU-83': 0.07057907656256868, 'IoU-84': 0.27860057422320444, 'IoU-85': 2.969893901285465, 'IoU-86': 2.371389886354798, 'IoU-87': 0.49606980074788193, 'IoU-88': 0.4145686201415397, 'IoU-89': 1.178609636901895, 'IoU-90': 0.0027976890827925986, 'IoU-91': 1.0278480667883263, 'IoU-92': 0.2286532786749744, 'IoU-93': 0.04421389463322951, 'IoU-94': 0.24939417916694526, 'IoU-95': 3.766084148601042, 'IoU-96': 0.0008477857249839626, 'IoU-97': 0.015807683384000074, 'IoU-98': 7.221110772922424e-05, 'IoU-99': 1.2411029448574, 'IoU-100': 0.177141491987931, 'IoU-101': 0.13353425932865995, 'IoU-102': 2.798065313444327, 'IoU-103': 0.2696427263725312, 'IoU-104': 0.14978934951702172, 'IoU-105': 0.6540210212594847, 'IoU-106': 2.3785792200709026, 'IoU-107': 0.09183149344140108, 'IoU-108': 0.118837565227844, 'IoU-109': 0.20556014717439935, 'IoU-110': 0.3295972567093679, 'IoU-111': 2.185035647100964, 'IoU-112': 1.5250578965023218, 'IoU-113': 0.0, 'IoU-114': 0.8634298906430024, 'IoU-115': 0.009868637093077753, 'IoU-116': 0.0, 'IoU-117': 0.49162913991722307, 'IoU-118': 0.12778037219940355, 'IoU-119': 0.8610364330844356, 'IoU-120': 1.9299574256775884, 'IoU-121': 0.0058690585939722055, 'IoU-122': 1.0897828488143442, 'IoU-123': 2.1403981540045156, 'IoU-124': 0.00021288666871747492, 'IoU-125': 0.05924980175255727, 'IoU-126': 0.7476017630955862, 'IoU-127': 0.02982835439178328, 'IoU-128': 1.7870912102789491, 'IoU-129': 0.0, 'IoU-130': 0.12277447834900557, 'IoU-131': 0.394141387293749, 'IoU-132': 0.05205287130458393, 'IoU-133': 0.0425174715111081, 'IoU-134': 0.05667003959683658, 'IoU-135': 0.0035830307662908464, 'IoU-136': 0.0013894755563460127, 'IoU-137': 0.0015159255559277995, 'IoU-138': 0.005449343808183097, 'IoU-139': 0.6080963586234516, 'IoU-140': 0.2746733695245241, 'IoU-141': 1.4687762829857347, 'IoU-142': 1.0446865141505774, 'IoU-143': 0.5728138146100543, 'IoU-144': 0.0, 'IoU-145': 0.012190672492828254, 'IoU-146': 0.7816910098443769, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.00020837066641106531, 'IoU-151': 0.6266376218726551, 'IoU-152': 0.0012458445891931288, 'IoU-153': 0.016787094329051767, 'IoU-154': 1.1646735513436175, 'IoU-155': 0.009102043120641244, 'IoU-156': 0.0, 'IoU-157': 0.7850136111537067, 'IoU-158': 0.6273695784767841, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.004296302661189128, 'IoU-163': 0.6263985664880084, 'IoU-164': 0.05028256233404421, 'IoU-165': 0.0007937503274220102, 'IoU-166': 0.7035987533172362, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0003504738406325352, 'IoU-170': 1.092906668409935, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.06679080310880829, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.01654944145635085, 'IoU-178': 0.0003863121866042386, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.8818027553815562, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.6502131777829963, 'pACC': 4.080751336835453, 'ACC-0': nan, 'ACC-1': 0.01169259067115067, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 6.234172993313227e-05, 'ACC-11': 0.0, 'ACC-12': 0.04246644715427866, 'ACC-13': 0.04963215476644989, 'ACC-14': 3.7181956702371575, 'ACC-15': 1.5965168043965612, 'ACC-16': 0.10671274148703316, 'ACC-17': 0.07472327245991582, 'ACC-18': 8.95422020606347e-06, 'ACC-19': 0.0, 'ACC-20': 2.1554187473642307e-05, 'ACC-21': 1.925717526470063, 'ACC-22': 0.0, 'ACC-23': 2.0535165982932266, 'ACC-24': 0.002054804536796389, 'ACC-25': 0.03582195110620627, 'ACC-26': 5.125064905543903, 'ACC-27': 34.42928125406182, 'ACC-28': 0.015591191017422047, 'ACC-29': 24.89229728320915, 'ACC-30': 10.74683449169746, 'ACC-31': 0.279721140603661, 'ACC-32': 1.3871934293507355, 'ACC-33': 17.72001827137598, 'ACC-34': 31.01519023910165, 'ACC-35': 0.24335935833286224, 'ACC-36': 11.996322893509145, 'ACC-37': 0.040553184906345116, 'ACC-38': 23.283701408439374, 'ACC-39': 0.39574080206270557, 'ACC-40': 7.589210823663557, 'ACC-41': 0.30875215849360993, 'ACC-42': 7.2979451511209215, 'ACC-43': 3.4588244040408043, 'ACC-44': 0.014853099511679705, 'ACC-45': 0.24250412470053564, 'ACC-46': 16.98707615827951, 'ACC-47': 0.019093431761493473, 'ACC-48': 0.40044760306558724, 'ACC-49': 5.412750328113647, 'ACC-50': 6.994128590065725, 'ACC-51': 2.007769050977572, 'ACC-52': 0.022874696624140045, 'ACC-53': 9.330289230575003, 'ACC-54': 0.10955713776123871, 'ACC-55': 5.31915069880583, 'ACC-56': 0.5873548301128174, 'ACC-57': 0.00012310114858554835, 'ACC-58': 0.7577369587786108, 'ACC-59': 5.51416100236003, 'ACC-60': 4.064951893976351, 'ACC-61': 0.33923224550194453, 'ACC-62': 0.06748051030372451, 'ACC-63': 3.497652608139396, 'ACC-64': 3.996449637408665, 'ACC-65': 0.016895108381427843, 'ACC-66': 0.1706948930737182, 'ACC-67': 0.02826010640019993, 'ACC-68': 0.5249355440250408, 'ACC-69': 0.5419212864177343, 'ACC-70': 0.056361380445036746, 'ACC-71': 1.0512336078972075, 'ACC-72': 26.633506971821387, 'ACC-73': 0.3983745910069483, 'ACC-74': 0.03116460302384882, 'ACC-75': 3.6846852651246693, 'ACC-76': 0.022981844554616087, 'ACC-77': 12.306163364764048, 'ACC-78': 0.6035574550892425, 'ACC-79': 0.4943900920157899, 'ACC-80': 4.850611468401062, 'ACC-81': 0.20837280627400925, 'ACC-82': 0.06008115681654478, 'ACC-83': 0.10437303890149437, 'ACC-84': 0.3029484021402713, 'ACC-85': 8.56366301851664, 'ACC-86': 6.413840495628154, 'ACC-87': 0.7238626431330865, 'ACC-88': 0.4622289901797863, 'ACC-89': 2.012895683547721, 'ACC-90': 0.002800757012053416, 'ACC-91': 1.684315348270371, 'ACC-92': 0.26158925282823114, 'ACC-93': 0.045315856380556546, 'ACC-94': 0.48997873743160825, 'ACC-95': 40.41796649972141, 'ACC-96': 0.0008493107842985418, 'ACC-97': 0.01592239731723014, 'ACC-98': 7.221260691302117e-05, 'ACC-99': 5.670152197573755, 'ACC-100': 0.1826424586849743, 'ACC-101': 0.16006214202565122, 'ACC-102': 17.922519256909833, 'ACC-103': 0.31996788514215546, 'ACC-104': 0.16248985514374953, 'ACC-105': 1.5817952569127565, 'ACC-106': 8.233852195481518, 'ACC-107': 0.09442624092180898, 'ACC-108': 0.12240125336230358, 'ACC-109': 0.24128150501146023, 'ACC-110': 0.40250887563987264, 'ACC-111': 4.949510809083761, 'ACC-112': 4.136729174215686, 'ACC-113': 0.0, 'ACC-114': 1.0888860301232106, 'ACC-115': 0.01078736487603927, 'ACC-116': 0.0, 'ACC-117': 0.7622996205981225, 'ACC-118': 0.17508524384084123, 'ACC-119': 1.6048640875096558, 'ACC-120': 9.932197612596942, 'ACC-121': 0.005904724097224462, 'ACC-122': 3.8236764886259635, 'ACC-123': 17.363998981583638, 'ACC-124': 0.00021309455378266807, 'ACC-125': 0.06460995276077024, 'ACC-126': 8.193892931629614, 'ACC-127': 0.03153940322776589, 'ACC-128': 7.517828589410056, 'ACC-129': 0.0, 'ACC-130': 0.2112768707289955, 'ACC-131': 0.44938802283226104, 'ACC-132': 0.05422015796898928, 'ACC-133': 0.05293705389645294, 'ACC-134': 0.06493752692804826, 'ACC-135': 0.0036343423978108433, 'ACC-136': 0.0014559262020126724, 'ACC-137': 0.0015264647001221935, 'ACC-138': 0.00571109475340762, 'ACC-139': 0.8514838659958205, 'ACC-140': 0.5863965929364058, 'ACC-141': 8.875195871673126, 'ACC-142': 4.796076366237257, 'ACC-143': 2.0810475417687693, 'ACC-144': 0.0, 'ACC-145': 0.01261208882130638, 'ACC-146': 2.3676863676863675, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0002084616675474172, 'ACC-151': 1.9287357865377504, 'ACC-152': 0.0012644143232854541, 'ACC-153': 0.0186656039868814, 'ACC-154': 8.806845868162087, 'ACC-155': 0.0097371463505422, 'ACC-156': 0.0, 'ACC-157': 1.4074500532846626, 'ACC-158': 1.1627956209221353, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.00431417936870167, 'ACC-163': 1.4433623218535938, 'ACC-164': 0.0683348184133004, 'ACC-165': 0.0007940869112242596, 'ACC-166': 2.5874037823908136, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0003509430717696129, 'ACC-170': 4.746972471854281, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.06829650088616121, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.016609180447672775, 'ACC-178': 0.00038631591756790954, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 2.68149626076313, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 14:39:54] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 14:39:54] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 14:39:54] d2.evaluation.testing INFO: copypaste: 9.7750,0.8792,0.7274,0.7201,1.1284,2.6502,4.0808
[01/24 14:39:54] d2.utils.events INFO:  eta: 1 day, 4:39:23  iter: 16999  total_loss: 47.63  loss_ce: 1.75  loss_mask: 3.16  loss_ce_0: 1.241  loss_mask_0: 3.652  loss_ce_1: 1.044  loss_mask_1: 3.472  loss_ce_2: 1.1  loss_mask_2: 3.394  loss_ce_3: 1.168  loss_mask_3: 3.328  loss_ce_4: 1.282  loss_mask_4: 3.301  loss_ce_5: 1.858  loss_mask_5: 3.185  loss_ce_6: 1.811  loss_mask_6: 3.091  loss_ce_7: 1.808  loss_mask_7: 3.086  loss_ce_8: 1.803  loss_mask_8: 3.005  time: 2.4374  data_time: 0.3699  lr: 7.4096e-05  max_mem: 18490M
[01/24 14:40:45] d2.utils.events INFO:  eta: 1 day, 4:37:31  iter: 17019  total_loss: 48.99  loss_ce: 1.744  loss_mask: 3.231  loss_ce_0: 1.226  loss_mask_0: 3.621  loss_ce_1: 1.017  loss_mask_1: 3.457  loss_ce_2: 1.121  loss_mask_2: 3.41  loss_ce_3: 1.194  loss_mask_3: 3.483  loss_ce_4: 1.379  loss_mask_4: 3.319  loss_ce_5: 1.803  loss_mask_5: 3.166  loss_ce_6: 1.84  loss_mask_6: 3.357  loss_ce_7: 1.851  loss_mask_7: 3.38  loss_ce_8: 1.836  loss_mask_8: 3.251  time: 2.4375  data_time: 0.4102  lr: 7.4065e-05  max_mem: 18490M
[01/24 14:41:35] d2.utils.events INFO:  eta: 1 day, 4:35:38  iter: 17039  total_loss: 45.79  loss_ce: 1.659  loss_mask: 2.906  loss_ce_0: 1.216  loss_mask_0: 3.499  loss_ce_1: 1.005  loss_mask_1: 3.466  loss_ce_2: 1.087  loss_mask_2: 3.318  loss_ce_3: 1.135  loss_mask_3: 3.202  loss_ce_4: 1.283  loss_mask_4: 3.16  loss_ce_5: 1.732  loss_mask_5: 2.863  loss_ce_6: 1.765  loss_mask_6: 2.975  loss_ce_7: 1.759  loss_mask_7: 3.012  loss_ce_8: 1.742  loss_mask_8: 2.938  time: 2.4376  data_time: 0.4402  lr: 7.4034e-05  max_mem: 18490M
[01/24 14:42:22] d2.utils.events INFO:  eta: 1 day, 4:31:19  iter: 17059  total_loss: 46.19  loss_ce: 1.676  loss_mask: 3.039  loss_ce_0: 1.21  loss_mask_0: 3.383  loss_ce_1: 0.9967  loss_mask_1: 3.443  loss_ce_2: 1.088  loss_mask_2: 3.266  loss_ce_3: 1.184  loss_mask_3: 3.218  loss_ce_4: 1.311  loss_mask_4: 3.243  loss_ce_5: 1.767  loss_mask_5: 3.035  loss_ce_6: 1.748  loss_mask_6: 2.982  loss_ce_7: 1.762  loss_mask_7: 2.982  loss_ce_8: 1.76  loss_mask_8: 3.058  time: 2.4375  data_time: 0.4021  lr: 7.4003e-05  max_mem: 18490M
[01/24 14:43:13] d2.utils.events INFO:  eta: 1 day, 4:29:15  iter: 17079  total_loss: 47.34  loss_ce: 1.693  loss_mask: 3.115  loss_ce_0: 1.276  loss_mask_0: 3.563  loss_ce_1: 0.9695  loss_mask_1: 3.53  loss_ce_2: 1.015  loss_mask_2: 3.543  loss_ce_3: 1.092  loss_mask_3: 3.336  loss_ce_4: 1.267  loss_mask_4: 3.251  loss_ce_5: 1.771  loss_mask_5: 3.171  loss_ce_6: 1.811  loss_mask_6: 3.109  loss_ce_7: 1.778  loss_mask_7: 3.172  loss_ce_8: 1.756  loss_mask_8: 3.027  time: 2.4377  data_time: 0.4190  lr: 7.3972e-05  max_mem: 18490M
[01/24 14:44:06] d2.utils.events INFO:  eta: 1 day, 4:31:10  iter: 17099  total_loss: 47.73  loss_ce: 1.663  loss_mask: 3.119  loss_ce_0: 1.306  loss_mask_0: 3.763  loss_ce_1: 1.045  loss_mask_1: 3.5  loss_ce_2: 1.092  loss_mask_2: 3.533  loss_ce_3: 1.141  loss_mask_3: 3.336  loss_ce_4: 1.272  loss_mask_4: 3.272  loss_ce_5: 1.735  loss_mask_5: 3.163  loss_ce_6: 1.77  loss_mask_6: 3.201  loss_ce_7: 1.796  loss_mask_7: 3.336  loss_ce_8: 1.794  loss_mask_8: 3.139  time: 2.4379  data_time: 0.4622  lr: 7.3941e-05  max_mem: 18490M
[01/24 14:44:57] d2.utils.events INFO:  eta: 1 day, 4:33:36  iter: 17119  total_loss: 47.19  loss_ce: 1.661  loss_mask: 3.056  loss_ce_0: 1.332  loss_mask_0: 3.579  loss_ce_1: 1.038  loss_mask_1: 3.393  loss_ce_2: 1.074  loss_mask_2: 3.368  loss_ce_3: 1.117  loss_mask_3: 3.323  loss_ce_4: 1.247  loss_mask_4: 3.201  loss_ce_5: 1.704  loss_mask_5: 3.056  loss_ce_6: 1.83  loss_mask_6: 3.248  loss_ce_7: 1.815  loss_mask_7: 3.279  loss_ce_8: 1.756  loss_mask_8: 3.082  time: 2.4380  data_time: 0.4427  lr: 7.391e-05  max_mem: 18490M
[01/24 14:45:53] d2.utils.events INFO:  eta: 1 day, 4:39:02  iter: 17139  total_loss: 46.32  loss_ce: 1.689  loss_mask: 3.094  loss_ce_0: 1.294  loss_mask_0: 3.531  loss_ce_1: 1.002  loss_mask_1: 3.344  loss_ce_2: 1.028  loss_mask_2: 3.3  loss_ce_3: 1.116  loss_mask_3: 3.264  loss_ce_4: 1.203  loss_mask_4: 3.19  loss_ce_5: 1.678  loss_mask_5: 3.034  loss_ce_6: 1.767  loss_mask_6: 3.04  loss_ce_7: 1.812  loss_mask_7: 3.183  loss_ce_8: 1.759  loss_mask_8: 3.093  time: 2.4384  data_time: 0.4802  lr: 7.3879e-05  max_mem: 18490M
[01/24 14:46:47] d2.utils.events INFO:  eta: 1 day, 4:48:09  iter: 17159  total_loss: 45.86  loss_ce: 1.816  loss_mask: 3.189  loss_ce_0: 1.288  loss_mask_0: 3.548  loss_ce_1: 1.009  loss_mask_1: 3.306  loss_ce_2: 1.037  loss_mask_2: 3.187  loss_ce_3: 1.142  loss_mask_3: 3.181  loss_ce_4: 1.233  loss_mask_4: 3.138  loss_ce_5: 1.644  loss_mask_5: 2.938  loss_ce_6: 1.722  loss_mask_6: 2.88  loss_ce_7: 1.756  loss_mask_7: 3.034  loss_ce_8: 1.79  loss_mask_8: 3.077  time: 2.4387  data_time: 0.5151  lr: 7.3848e-05  max_mem: 18490M
[01/24 14:47:39] d2.utils.events INFO:  eta: 1 day, 4:54:16  iter: 17179  total_loss: 47.31  loss_ce: 1.747  loss_mask: 3.195  loss_ce_0: 1.284  loss_mask_0: 3.556  loss_ce_1: 0.9835  loss_mask_1: 3.456  loss_ce_2: 1.02  loss_mask_2: 3.401  loss_ce_3: 1.076  loss_mask_3: 3.29  loss_ce_4: 1.197  loss_mask_4: 3.247  loss_ce_5: 1.631  loss_mask_5: 3.06  loss_ce_6: 1.747  loss_mask_6: 3.031  loss_ce_7: 1.801  loss_mask_7: 3.187  loss_ce_8: 1.796  loss_mask_8: 3.058  time: 2.4389  data_time: 0.4628  lr: 7.3817e-05  max_mem: 18490M
[01/24 14:48:36] d2.utils.events INFO:  eta: 1 day, 5:02:04  iter: 17199  total_loss: 45.15  loss_ce: 1.706  loss_mask: 3.042  loss_ce_0: 1.212  loss_mask_0: 3.494  loss_ce_1: 0.9679  loss_mask_1: 3.401  loss_ce_2: 1.013  loss_mask_2: 3.351  loss_ce_3: 1.069  loss_mask_3: 3.228  loss_ce_4: 1.188  loss_mask_4: 3.104  loss_ce_5: 1.598  loss_mask_5: 2.931  loss_ce_6: 1.712  loss_mask_6: 2.904  loss_ce_7: 1.745  loss_mask_7: 3.011  loss_ce_8: 1.706  loss_mask_8: 2.888  time: 2.4394  data_time: 0.5165  lr: 7.3786e-05  max_mem: 18490M
[01/24 14:49:27] d2.utils.events INFO:  eta: 1 day, 5:05:56  iter: 17219  total_loss: 44.69  loss_ce: 1.716  loss_mask: 2.902  loss_ce_0: 1.221  loss_mask_0: 3.464  loss_ce_1: 0.9942  loss_mask_1: 3.271  loss_ce_2: 1.006  loss_mask_2: 3.199  loss_ce_3: 1.05  loss_mask_3: 3.036  loss_ce_4: 1.171  loss_mask_4: 3  loss_ce_5: 1.658  loss_mask_5: 2.855  loss_ce_6: 1.721  loss_mask_6: 2.936  loss_ce_7: 1.769  loss_mask_7: 3.008  loss_ce_8: 1.759  loss_mask_8: 2.94  time: 2.4395  data_time: 0.3968  lr: 7.3755e-05  max_mem: 18490M
[01/24 14:50:18] d2.utils.events INFO:  eta: 1 day, 5:11:52  iter: 17239  total_loss: 44.45  loss_ce: 1.678  loss_mask: 2.903  loss_ce_0: 1.282  loss_mask_0: 3.447  loss_ce_1: 1.056  loss_mask_1: 3.209  loss_ce_2: 1.058  loss_mask_2: 3.131  loss_ce_3: 1.079  loss_mask_3: 3.085  loss_ce_4: 1.184  loss_mask_4: 2.872  loss_ce_5: 1.608  loss_mask_5: 2.791  loss_ce_6: 1.697  loss_mask_6: 3.001  loss_ce_7: 1.763  loss_mask_7: 3.027  loss_ce_8: 1.722  loss_mask_8: 2.849  time: 2.4396  data_time: 0.4016  lr: 7.3724e-05  max_mem: 18490M
[01/24 14:51:09] d2.utils.events INFO:  eta: 1 day, 5:14:53  iter: 17259  total_loss: 45.54  loss_ce: 1.682  loss_mask: 2.976  loss_ce_0: 1.241  loss_mask_0: 3.578  loss_ce_1: 1.025  loss_mask_1: 3.344  loss_ce_2: 0.9959  loss_mask_2: 3.203  loss_ce_3: 1.068  loss_mask_3: 3.156  loss_ce_4: 1.186  loss_mask_4: 3.084  loss_ce_5: 1.589  loss_mask_5: 2.957  loss_ce_6: 1.703  loss_mask_6: 3.112  loss_ce_7: 1.768  loss_mask_7: 3.126  loss_ce_8: 1.742  loss_mask_8: 3.023  time: 2.4398  data_time: 0.4467  lr: 7.3693e-05  max_mem: 18490M
[01/24 14:51:57] d2.utils.events INFO:  eta: 1 day, 5:18:36  iter: 17279  total_loss: 47.47  loss_ce: 1.68  loss_mask: 3.168  loss_ce_0: 1.241  loss_mask_0: 3.671  loss_ce_1: 1.03  loss_mask_1: 3.534  loss_ce_2: 1.054  loss_mask_2: 3.355  loss_ce_3: 1.107  loss_mask_3: 3.316  loss_ce_4: 1.234  loss_mask_4: 3.302  loss_ce_5: 1.63  loss_mask_5: 3.163  loss_ce_6: 1.716  loss_mask_6: 3.239  loss_ce_7: 1.77  loss_mask_7: 3.287  loss_ce_8: 1.743  loss_mask_8: 3.241  time: 2.4397  data_time: 0.3525  lr: 7.3662e-05  max_mem: 18490M
[01/24 14:52:46] d2.utils.events INFO:  eta: 1 day, 5:20:22  iter: 17299  total_loss: 43.64  loss_ce: 1.64  loss_mask: 2.89  loss_ce_0: 1.211  loss_mask_0: 3.332  loss_ce_1: 1.05  loss_mask_1: 3.199  loss_ce_2: 1.07  loss_mask_2: 3.162  loss_ce_3: 1.103  loss_mask_3: 2.976  loss_ce_4: 1.231  loss_mask_4: 2.917  loss_ce_5: 1.617  loss_mask_5: 2.837  loss_ce_6: 1.673  loss_mask_6: 2.891  loss_ce_7: 1.751  loss_mask_7: 3.014  loss_ce_8: 1.731  loss_mask_8: 2.763  time: 2.4397  data_time: 0.4215  lr: 7.3631e-05  max_mem: 18490M
[01/24 14:53:36] d2.utils.events INFO:  eta: 1 day, 5:25:31  iter: 17319  total_loss: 44.13  loss_ce: 1.651  loss_mask: 2.918  loss_ce_0: 1.203  loss_mask_0: 3.203  loss_ce_1: 1.004  loss_mask_1: 3.2  loss_ce_2: 1.046  loss_mask_2: 3.075  loss_ce_3: 1.06  loss_mask_3: 3.046  loss_ce_4: 1.164  loss_mask_4: 2.969  loss_ce_5: 1.569  loss_mask_5: 2.869  loss_ce_6: 1.668  loss_mask_6: 2.878  loss_ce_7: 1.76  loss_mask_7: 2.97  loss_ce_8: 1.772  loss_mask_8: 2.948  time: 2.4398  data_time: 0.4435  lr: 7.36e-05  max_mem: 18490M
[01/24 14:54:22] d2.utils.events INFO:  eta: 1 day, 5:24:03  iter: 17339  total_loss: 43.87  loss_ce: 1.646  loss_mask: 2.847  loss_ce_0: 1.184  loss_mask_0: 3.286  loss_ce_1: 1.026  loss_mask_1: 3.266  loss_ce_2: 1.03  loss_mask_2: 3.099  loss_ce_3: 1.028  loss_mask_3: 3.055  loss_ce_4: 1.134  loss_mask_4: 3.028  loss_ce_5: 1.569  loss_mask_5: 2.819  loss_ce_6: 1.668  loss_mask_6: 2.813  loss_ce_7: 1.714  loss_mask_7: 2.842  loss_ce_8: 1.707  loss_mask_8: 2.776  time: 2.4397  data_time: 0.3785  lr: 7.3568e-05  max_mem: 18490M
[01/24 14:55:12] d2.utils.events INFO:  eta: 1 day, 5:25:28  iter: 17359  total_loss: 45.12  loss_ce: 1.716  loss_mask: 2.967  loss_ce_0: 1.183  loss_mask_0: 3.386  loss_ce_1: 1.034  loss_mask_1: 3.365  loss_ce_2: 1.035  loss_mask_2: 3.236  loss_ce_3: 1.05  loss_mask_3: 3.134  loss_ce_4: 1.185  loss_mask_4: 3.062  loss_ce_5: 1.591  loss_mask_5: 2.886  loss_ce_6: 1.731  loss_mask_6: 2.935  loss_ce_7: 1.78  loss_mask_7: 3.007  loss_ce_8: 1.76  loss_mask_8: 2.905  time: 2.4397  data_time: 0.4119  lr: 7.3537e-05  max_mem: 18490M
[01/24 14:56:00] d2.utils.events INFO:  eta: 1 day, 5:23:02  iter: 17379  total_loss: 44.17  loss_ce: 1.696  loss_mask: 2.958  loss_ce_0: 1.198  loss_mask_0: 3.307  loss_ce_1: 1.04  loss_mask_1: 3.236  loss_ce_2: 1.051  loss_mask_2: 3.078  loss_ce_3: 1.098  loss_mask_3: 3.035  loss_ce_4: 1.203  loss_mask_4: 3.064  loss_ce_5: 1.581  loss_mask_5: 2.839  loss_ce_6: 1.704  loss_mask_6: 2.85  loss_ce_7: 1.747  loss_mask_7: 2.877  loss_ce_8: 1.722  loss_mask_8: 2.888  time: 2.4397  data_time: 0.3927  lr: 7.3506e-05  max_mem: 18490M
[01/24 14:56:49] d2.utils.events INFO:  eta: 1 day, 5:24:13  iter: 17399  total_loss: 47.32  loss_ce: 1.715  loss_mask: 3.192  loss_ce_0: 1.233  loss_mask_0: 3.503  loss_ce_1: 1.036  loss_mask_1: 3.459  loss_ce_2: 1.059  loss_mask_2: 3.424  loss_ce_3: 1.087  loss_mask_3: 3.333  loss_ce_4: 1.203  loss_mask_4: 3.218  loss_ce_5: 1.6  loss_mask_5: 3.029  loss_ce_6: 1.734  loss_mask_6: 3.221  loss_ce_7: 1.802  loss_mask_7: 3.226  loss_ce_8: 1.742  loss_mask_8: 3.115  time: 2.4397  data_time: 0.3986  lr: 7.3475e-05  max_mem: 18490M
[01/24 14:57:40] d2.utils.events INFO:  eta: 1 day, 5:25:08  iter: 17419  total_loss: 45.92  loss_ce: 1.726  loss_mask: 3.012  loss_ce_0: 1.255  loss_mask_0: 3.466  loss_ce_1: 1.046  loss_mask_1: 3.316  loss_ce_2: 1.04  loss_mask_2: 3.306  loss_ce_3: 1.064  loss_mask_3: 3.28  loss_ce_4: 1.209  loss_mask_4: 3.225  loss_ce_5: 1.552  loss_mask_5: 3.006  loss_ce_6: 1.695  loss_mask_6: 3.056  loss_ce_7: 1.729  loss_mask_7: 3.03  loss_ce_8: 1.705  loss_mask_8: 3.001  time: 2.4398  data_time: 0.4341  lr: 7.3444e-05  max_mem: 18490M
[01/24 14:58:29] d2.utils.events INFO:  eta: 1 day, 5:23:48  iter: 17439  total_loss: 45.04  loss_ce: 1.748  loss_mask: 3.069  loss_ce_0: 1.299  loss_mask_0: 3.438  loss_ce_1: 1.064  loss_mask_1: 3.313  loss_ce_2: 1.061  loss_mask_2: 3.235  loss_ce_3: 1.073  loss_mask_3: 3.068  loss_ce_4: 1.191  loss_mask_4: 3.109  loss_ce_5: 1.551  loss_mask_5: 2.879  loss_ce_6: 1.685  loss_mask_6: 2.835  loss_ce_7: 1.721  loss_mask_7: 2.861  loss_ce_8: 1.708  loss_mask_8: 2.881  time: 2.4398  data_time: 0.4044  lr: 7.3413e-05  max_mem: 18490M
[01/24 14:59:15] d2.utils.events INFO:  eta: 1 day, 5:22:49  iter: 17459  total_loss: 45.02  loss_ce: 1.719  loss_mask: 2.959  loss_ce_0: 1.236  loss_mask_0: 3.417  loss_ce_1: 1.037  loss_mask_1: 3.25  loss_ce_2: 1.055  loss_mask_2: 3.136  loss_ce_3: 1.094  loss_mask_3: 3.102  loss_ce_4: 1.225  loss_mask_4: 3.107  loss_ce_5: 1.554  loss_mask_5: 2.885  loss_ce_6: 1.664  loss_mask_6: 2.841  loss_ce_7: 1.706  loss_mask_7: 3.012  loss_ce_8: 1.697  loss_mask_8: 2.94  time: 2.4396  data_time: 0.3400  lr: 7.3382e-05  max_mem: 18490M
[01/24 15:00:07] d2.utils.events INFO:  eta: 1 day, 5:24:22  iter: 17479  total_loss: 46.41  loss_ce: 1.784  loss_mask: 3.31  loss_ce_0: 1.167  loss_mask_0: 3.443  loss_ce_1: 1.004  loss_mask_1: 3.425  loss_ce_2: 1.055  loss_mask_2: 3.341  loss_ce_3: 1.113  loss_mask_3: 3.148  loss_ce_4: 1.251  loss_mask_4: 3.21  loss_ce_5: 1.615  loss_mask_5: 3.035  loss_ce_6: 1.697  loss_mask_6: 2.981  loss_ce_7: 1.745  loss_mask_7: 3.049  loss_ce_8: 1.697  loss_mask_8: 3.042  time: 2.4398  data_time: 0.4466  lr: 7.3351e-05  max_mem: 18490M
[01/24 15:00:54] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 15:00:54] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 15:00:54] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 15:04:34] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 8.383239531317482, 'error_1pix': 0.8131432078436185, 'error_3pix': 0.6607812954963547, 'mIoU': 0.9768110691246622, 'fwIoU': 7.263441800975842, 'IoU-0': nan, 'IoU-1': 61.217645910247754, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 9.172834135469236e-05, 'IoU-13': 0.008538625389168664, 'IoU-14': 5.034784088158776, 'IoU-15': 4.324248235855107, 'IoU-16': 1.7886378699049785, 'IoU-17': 0.6465925480034359, 'IoU-18': 0.006661288380650251, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 5.984951736601078e-06, 'IoU-22': 0.016531415375892936, 'IoU-23': 0.08266872147312201, 'IoU-24': 0.02408522448716536, 'IoU-25': 0.8089755700986124, 'IoU-26': 0.6188236218048004, 'IoU-27': 0.0010432220057474241, 'IoU-28': 5.763478651282597e-06, 'IoU-29': 4.75799864189376, 'IoU-30': 3.805853380989975, 'IoU-31': 0.299747908690087, 'IoU-32': 0.00010015046660237728, 'IoU-33': 3.7126076156434434e-05, 'IoU-34': 4.6693060385206, 'IoU-35': 0.0, 'IoU-36': 0.6449554906850427, 'IoU-37': 0.025478519417131747, 'IoU-38': 5.36463214028127, 'IoU-39': 2.33271487667972, 'IoU-40': 2.226570646809796, 'IoU-41': 0.0, 'IoU-42': 0.0034424283893605637, 'IoU-43': 0.47307836025300054, 'IoU-44': 0.0, 'IoU-45': 2.509375248013258, 'IoU-46': 4.363737441452904, 'IoU-47': 0.4579012287833157, 'IoU-48': 0.08019644944297952, 'IoU-49': 1.2544513649214013, 'IoU-50': 2.730070806551767, 'IoU-51': 0.0063117899613191805, 'IoU-52': 0.000146326904652396, 'IoU-53': 0.0004186012477361556, 'IoU-54': 0.0014387937421989527, 'IoU-55': 3.650845007609223, 'IoU-56': 0.0009532765481322358, 'IoU-57': 0.0004534404143668061, 'IoU-58': 0.09833134222437087, 'IoU-59': 0.8544989809608968, 'IoU-60': 1.6119189806160266, 'IoU-61': 0.014058746917001704, 'IoU-62': 2.1761010890056967, 'IoU-63': 1.1941254098904641, 'IoU-64': 0.0, 'IoU-65': 2.7778981113304173, 'IoU-66': 0.0678257556142862, 'IoU-67': 0.0012891703037295804, 'IoU-68': 1.7879418453269176, 'IoU-69': 0.008989955307682276, 'IoU-70': 0.03877793426292168, 'IoU-71': 3.2485484430965745, 'IoU-72': 0.08196622982606713, 'IoU-73': 0.35796804229520807, 'IoU-74': 0.013823062009395596, 'IoU-75': 2.286300810006687, 'IoU-76': 0.42172029172070297, 'IoU-77': 0.001318615405874181, 'IoU-78': 2.1962210904082493, 'IoU-79': 0.09648073524522278, 'IoU-80': 2.7581405889613846, 'IoU-81': 0.45325694682637263, 'IoU-82': 0.004816644166538672, 'IoU-83': 0.017868571492665387, 'IoU-84': 0.81439996519492, 'IoU-85': 0.39845518287044623, 'IoU-86': 1.2952545743932242, 'IoU-87': 0.06479134215961077, 'IoU-88': 1.4789023133140997, 'IoU-89': 1.490536681125466, 'IoU-90': 1.6971378680376867, 'IoU-91': 1.5046215847076478, 'IoU-92': 1.9923016378016147, 'IoU-93': 0.00011782851473622319, 'IoU-94': 0.872905255651458, 'IoU-95': 0.7226215235021949, 'IoU-96': 0.06426742481026096, 'IoU-97': 0.0038748488680917805, 'IoU-98': 0.021167332529442286, 'IoU-99': 1.4359832904041814, 'IoU-100': 0.1831076784997836, 'IoU-101': 1.5040117970419251, 'IoU-102': 6.796422453839266e-05, 'IoU-103': 1.698804922110933, 'IoU-104': 0.014018914524990001, 'IoU-105': 0.7016777184879571, 'IoU-106': 1.8323445239104494, 'IoU-107': 0.0055975037837232705, 'IoU-108': 0.34232681632522033, 'IoU-109': 0.005601283735420126, 'IoU-110': 0.0004504146066454171, 'IoU-111': 3.108932522951757, 'IoU-112': 1.7755531609170487, 'IoU-113': 0.0, 'IoU-114': 0.0028254092677770766, 'IoU-115': 2.4383211770398985, 'IoU-116': 0.0, 'IoU-117': 0.09693819270905868, 'IoU-118': 0.0381733555737007, 'IoU-119': 0.0007702703049671307, 'IoU-120': 3.716452227234775, 'IoU-121': 0.06142282563197263, 'IoU-122': 0.7477156734953275, 'IoU-123': 0.6752902630409261, 'IoU-124': 0.00015969976444284745, 'IoU-125': 0.059718796132770015, 'IoU-126': 0.0011946384625799412, 'IoU-127': 0.0038687400033490583, 'IoU-128': 1.8185867844279244, 'IoU-129': 0.0008154764891855271, 'IoU-130': 0.008334429968855552, 'IoU-131': 1.1848294093961849, 'IoU-132': 0.05618518830769972, 'IoU-133': 0.09590407295600856, 'IoU-134': 1.9342111722682889, 'IoU-135': 0.0, 'IoU-136': 0.15757114435886063, 'IoU-137': 0.002364706375934917, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.5164450541201683, 'IoU-141': 0.019939643371636867, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.07876398471408069, 'IoU-146': 9.128118621727113e-05, 'IoU-147': 0.007121213089520039, 'IoU-148': 1.0266346532278536, 'IoU-149': 0.0, 'IoU-150': 0.11675861564077392, 'IoU-151': 0.2900720243105352, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.897405177866696, 'IoU-155': 0.0, 'IoU-156': 0.44993342177698803, 'IoU-157': 0.0, 'IoU-158': 1.0467391735661462, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.00014875086461440057, 'IoU-163': 0.00522306205743876, 'IoU-164': 0.1892052970242591, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.6502749667473029, 'IoU-170': 0.0010323521972756225, 'IoU-171': 0.00018365843938077721, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 1.3438611566682146, 'IoU-176': 0.0, 'IoU-177': 0.18621902169986274, 'IoU-178': 0.37300618503418936, 'IoU-179': 0.003029874563193084, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 2.2484702708111737, 'IoU-184': 0.8725176009966337, 'IoU-185': 0.0, 'IoU-186': 0.902518805978447, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.833696039251375, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.547203762591161, 'mACC': 2.9365388168672815, 'pACC': 10.674894518829998, 'ACC-0': nan, 'ACC-1': 64.87364908888198, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 9.174322888032467e-05, 'ACC-13': 0.0117366496723895, 'ACC-14': 6.747430358095969, 'ACC-15': 15.067284716702375, 'ACC-16': 2.87979809110354, 'ACC-17': 0.7006904612893976, 'ACC-18': 0.006727604114822354, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 5.986196549101358e-06, 'ACC-22': 0.017242239175419987, 'ACC-23': 0.11814123401857951, 'ACC-24': 0.02712716156316932, 'ACC-25': 5.180358148041173, 'ACC-26': 0.9057567701328824, 'ACC-27': 0.0010488484236400285, 'ACC-28': 5.763841411246598e-06, 'ACC-29': 75.8614160793582, 'ACC-30': 14.160621091206266, 'ACC-31': 0.313462750383856, 'ACC-32': 0.00010015309347732137, 'ACC-33': 3.713462068398943e-05, 'ACC-34': 10.286642993327417, 'ACC-35': 0.0, 'ACC-36': 0.6905631638702447, 'ACC-37': 0.025557917627647496, 'ACC-38': 34.767038386460044, 'ACC-39': 4.377008751800601, 'ACC-40': 3.7141959121935546, 'ACC-41': 0.0, 'ACC-42': 0.003443207352598114, 'ACC-43': 0.7014462789983671, 'ACC-44': 0.0, 'ACC-45': 4.2773298754251705, 'ACC-46': 22.22912298534365, 'ACC-47': 0.5428805376969393, 'ACC-48': 0.08241035330275816, 'ACC-49': 1.9467024572780298, 'ACC-50': 8.709427607937089, 'ACC-51': 0.00631483007677144, 'ACC-52': 0.00014633116414802862, 'ACC-53': 0.0004190130718474096, 'ACC-54': 0.0014396249312116959, 'ACC-55': 19.21666028177095, 'ACC-56': 0.0009536116260260702, 'ACC-57': 0.00045353054742044134, 'ACC-58': 0.10989073404655293, 'ACC-59': 0.9769653929192532, 'ACC-60': 2.703566107063728, 'ACC-61': 0.014098158575152783, 'ACC-62': 3.7431660758361414, 'ACC-63': 1.8154473362285606, 'ACC-64': 0.0, 'ACC-65': 7.040818799468021, 'ACC-66': 0.0709516764096612, 'ACC-67': 0.0012908023140488173, 'ACC-68': 3.074459123730985, 'ACC-69': 0.00902443046787541, 'ACC-70': 0.03946991073255392, 'ACC-71': 22.090404855375716, 'ACC-72': 0.08370105670913638, 'ACC-73': 0.41913638876869613, 'ACC-74': 0.013997383741924408, 'ACC-75': 7.92261768910137, 'ACC-76': 0.4659277738874563, 'ACC-77': 0.0013208629317611644, 'ACC-78': 6.211626006899638, 'ACC-79': 0.09841689803436861, 'ACC-80': 20.86937732763876, 'ACC-81': 0.5363333876259394, 'ACC-82': 0.004826744620655002, 'ACC-83': 0.01790746636729627, 'ACC-84': 1.0445487604475576, 'ACC-85': 0.45204934746673225, 'ACC-86': 2.0633029900028874, 'ACC-87': 0.06721712771694713, 'ACC-88': 2.4339133326613416, 'ACC-89': 3.1801135403395957, 'ACC-90': 6.5595943774347045, 'ACC-91': 3.4817103522451687, 'ACC-92': 4.776037309600892, 'ACC-93': 0.00011785658356451639, 'ACC-94': 1.6077080459602335, 'ACC-95': 0.9001193065738237, 'ACC-96': 0.06629620063318617, 'ACC-97': 0.0038864346139905826, 'ACC-98': 0.021248559584156484, 'ACC-99': 5.048511000017742, 'ACC-100': 0.19050851196167207, 'ACC-101': 2.794585699768386, 'ACC-102': 6.796556411418214e-05, 'ACC-103': 3.0508170397657506, 'ACC-104': 0.014092127591549642, 'ACC-105': 1.0300976797390713, 'ACC-106': 5.1813054390189475, 'ACC-107': 0.005629675077999556, 'ACC-108': 0.37427865754926104, 'ACC-109': 0.005641525026116858, 'ACC-110': 0.0004516481997754405, 'ACC-111': 10.2523723072092, 'ACC-112': 17.08143731994963, 'ACC-113': 0.0, 'ACC-114': 0.002842568705432258, 'ACC-115': 10.922112970396764, 'ACC-116': 0.0, 'ACC-117': 0.0995718970977886, 'ACC-118': 0.03896381445666682, 'ACC-119': 0.000772022918787049, 'ACC-120': 5.937716329850972, 'ACC-121': 0.06745011757214096, 'ACC-122': 1.414230047081246, 'ACC-123': 0.8943215393087005, 'ACC-124': 0.00015982091533700104, 'ACC-125': 0.06118366738709302, 'ACC-126': 0.0011953660780152824, 'ACC-127': 0.003913222252333915, 'ACC-128': 4.685500877555675, 'ACC-129': 0.0008157840406285553, 'ACC-130': 0.008577479794553236, 'ACC-131': 3.443779644357429, 'ACC-132': 0.06253078786782078, 'ACC-133': 0.10226785604931721, 'ACC-134': 13.797432141318398, 'ACC-135': 0.0, 'ACC-136': 0.2730589591874767, 'ACC-137': 0.0023660202851894, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.7265354397229027, 'ACC-141': 0.02246948946290346, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.08148661642702207, 'ACC-146': 9.138470676932215e-05, 'ACC-147': 0.007242454152015399, 'ACC-148': 2.095145577543294, 'ACC-149': 0.0, 'ACC-150': 0.1296631572144935, 'ACC-151': 0.4477327202986732, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 8.30254078178443, 'ACC-155': 0.0, 'ACC-156': 1.658619196287175, 'ACC-157': 0.0, 'ACC-158': 2.122077309890184, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.00014876480581729897, 'ACC-163': 0.00535031574506204, 'ACC-164': 0.6628953034478166, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 1.9070246519960765, 'ACC-170': 0.0010647812939222282, 'ACC-171': 0.00018368542768396553, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 13.728393966118116, 'ACC-176': 0.0, 'ACC-177': 0.3567282867261275, 'ACC-178': 0.42378856157199674, 'ACC-179': 0.00304333094600928, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 7.141595899715362, 'ACC-184': 19.54685779107913, 'ACC-185': 0.0, 'ACC-186': 12.416285619185436, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 1.081841543844876, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.6505910219004954})])
[01/24 15:04:34] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 15:04:34] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 15:04:34] d2.evaluation.testing INFO: copypaste: 8.3832,0.8131,0.6608,0.9768,7.2634,2.9365,10.6749
[01/24 15:04:34] d2.utils.events INFO:  eta: 1 day, 5:21:16  iter: 17499  total_loss: 43.73  loss_ce: 1.677  loss_mask: 2.999  loss_ce_0: 1.261  loss_mask_0: 3.421  loss_ce_1: 1.018  loss_mask_1: 3.18  loss_ce_2: 1.004  loss_mask_2: 3.03  loss_ce_3: 1.059  loss_mask_3: 2.932  loss_ce_4: 1.177  loss_mask_4: 2.905  loss_ce_5: 1.554  loss_mask_5: 2.862  loss_ce_6: 1.652  loss_mask_6: 2.87  loss_ce_7: 1.695  loss_mask_7: 2.917  loss_ce_8: 1.661  loss_mask_8: 2.965  time: 2.4397  data_time: 0.3801  lr: 7.332e-05  max_mem: 18490M
[01/24 15:05:21] d2.utils.events INFO:  eta: 1 day, 5:13:17  iter: 17519  total_loss: 44.94  loss_ce: 1.704  loss_mask: 3.061  loss_ce_0: 1.215  loss_mask_0: 3.478  loss_ce_1: 0.9952  loss_mask_1: 3.232  loss_ce_2: 0.9912  loss_mask_2: 3.141  loss_ce_3: 1.09  loss_mask_3: 3.124  loss_ce_4: 1.237  loss_mask_4: 3.056  loss_ce_5: 1.611  loss_mask_5: 2.897  loss_ce_6: 1.707  loss_mask_6: 2.841  loss_ce_7: 1.695  loss_mask_7: 2.884  loss_ce_8: 1.692  loss_mask_8: 2.891  time: 2.4396  data_time: 0.3859  lr: 7.3289e-05  max_mem: 18490M
[01/24 15:06:08] d2.utils.events INFO:  eta: 1 day, 5:02:43  iter: 17539  total_loss: 45.66  loss_ce: 1.856  loss_mask: 3.265  loss_ce_0: 1.259  loss_mask_0: 3.404  loss_ce_1: 1.004  loss_mask_1: 3.267  loss_ce_2: 1.001  loss_mask_2: 3.109  loss_ce_3: 1.08  loss_mask_3: 3.111  loss_ce_4: 1.187  loss_mask_4: 3.173  loss_ce_5: 1.587  loss_mask_5: 2.912  loss_ce_6: 1.698  loss_mask_6: 2.899  loss_ce_7: 1.819  loss_mask_7: 3.011  loss_ce_8: 1.8  loss_mask_8: 3.169  time: 2.4395  data_time: 0.3950  lr: 7.3258e-05  max_mem: 18490M
[01/24 15:06:54] d2.utils.events INFO:  eta: 1 day, 4:54:57  iter: 17559  total_loss: 45.17  loss_ce: 1.702  loss_mask: 2.94  loss_ce_0: 1.322  loss_mask_0: 3.608  loss_ce_1: 1.015  loss_mask_1: 3.425  loss_ce_2: 1.006  loss_mask_2: 3.279  loss_ce_3: 1.051  loss_mask_3: 3.206  loss_ce_4: 1.141  loss_mask_4: 3.138  loss_ce_5: 1.53  loss_mask_5: 2.932  loss_ce_6: 1.665  loss_mask_6: 3.015  loss_ce_7: 1.707  loss_mask_7: 2.97  loss_ce_8: 1.7  loss_mask_8: 2.954  time: 2.4393  data_time: 0.3976  lr: 7.3227e-05  max_mem: 18490M
[01/24 15:07:42] d2.utils.events INFO:  eta: 1 day, 4:48:08  iter: 17579  total_loss: 45.76  loss_ce: 1.703  loss_mask: 3.031  loss_ce_0: 1.199  loss_mask_0: 3.478  loss_ce_1: 0.981  loss_mask_1: 3.447  loss_ce_2: 0.9972  loss_mask_2: 3.38  loss_ce_3: 1.093  loss_mask_3: 3.301  loss_ce_4: 1.218  loss_mask_4: 3.216  loss_ce_5: 1.537  loss_mask_5: 3.061  loss_ce_6: 1.672  loss_mask_6: 3.009  loss_ce_7: 1.72  loss_mask_7: 2.988  loss_ce_8: 1.694  loss_mask_8: 3.03  time: 2.4393  data_time: 0.4171  lr: 7.3196e-05  max_mem: 18490M
[01/24 15:08:31] d2.utils.events INFO:  eta: 1 day, 4:45:03  iter: 17599  total_loss: 42.62  loss_ce: 1.65  loss_mask: 2.776  loss_ce_0: 1.085  loss_mask_0: 3.263  loss_ce_1: 0.9343  loss_mask_1: 3.276  loss_ce_2: 0.9493  loss_mask_2: 3.135  loss_ce_3: 1.011  loss_mask_3: 3.01  loss_ce_4: 1.121  loss_mask_4: 2.969  loss_ce_5: 1.475  loss_mask_5: 2.834  loss_ce_6: 1.655  loss_mask_6: 2.751  loss_ce_7: 1.704  loss_mask_7: 2.772  loss_ce_8: 1.649  loss_mask_8: 2.804  time: 2.4393  data_time: 0.4161  lr: 7.3165e-05  max_mem: 18490M
[01/24 15:09:22] d2.utils.events INFO:  eta: 1 day, 4:41:49  iter: 17619  total_loss: 43  loss_ce: 1.631  loss_mask: 2.783  loss_ce_0: 1.185  loss_mask_0: 3.281  loss_ce_1: 1.057  loss_mask_1: 3.137  loss_ce_2: 1.033  loss_mask_2: 3.009  loss_ce_3: 1.078  loss_mask_3: 2.873  loss_ce_4: 1.187  loss_mask_4: 2.895  loss_ce_5: 1.535  loss_mask_5: 2.791  loss_ce_6: 1.637  loss_mask_6: 2.764  loss_ce_7: 1.67  loss_mask_7: 2.731  loss_ce_8: 1.643  loss_mask_8: 2.793  time: 2.4394  data_time: 0.4581  lr: 7.3134e-05  max_mem: 18490M
[01/24 15:10:11] d2.utils.events INFO:  eta: 1 day, 4:42:21  iter: 17639  total_loss: 44.81  loss_ce: 1.718  loss_mask: 3.055  loss_ce_0: 1.229  loss_mask_0: 3.319  loss_ce_1: 1.061  loss_mask_1: 3.194  loss_ce_2: 1.062  loss_mask_2: 3.165  loss_ce_3: 1.101  loss_mask_3: 3.013  loss_ce_4: 1.196  loss_mask_4: 3.025  loss_ce_5: 1.566  loss_mask_5: 2.866  loss_ce_6: 1.701  loss_mask_6: 2.804  loss_ce_7: 1.766  loss_mask_7: 2.975  loss_ce_8: 1.749  loss_mask_8: 2.95  time: 2.4394  data_time: 0.3822  lr: 7.3103e-05  max_mem: 18490M
[01/24 15:10:59] d2.utils.events INFO:  eta: 1 day, 4:42:55  iter: 17659  total_loss: 42.97  loss_ce: 1.704  loss_mask: 2.88  loss_ce_0: 1.163  loss_mask_0: 3.124  loss_ce_1: 1.047  loss_mask_1: 3.026  loss_ce_2: 1.057  loss_mask_2: 2.927  loss_ce_3: 1.088  loss_mask_3: 2.908  loss_ce_4: 1.163  loss_mask_4: 2.857  loss_ce_5: 1.549  loss_mask_5: 2.783  loss_ce_6: 1.721  loss_mask_6: 2.818  loss_ce_7: 1.719  loss_mask_7: 2.775  loss_ce_8: 1.713  loss_mask_8: 2.796  time: 2.4394  data_time: 0.3993  lr: 7.3072e-05  max_mem: 18490M
[01/24 15:11:52] d2.utils.events INFO:  eta: 1 day, 4:42:07  iter: 17679  total_loss: 42.93  loss_ce: 1.712  loss_mask: 2.888  loss_ce_0: 1.168  loss_mask_0: 3.148  loss_ce_1: 1.003  loss_mask_1: 3.156  loss_ce_2: 1.014  loss_mask_2: 3.137  loss_ce_3: 1.036  loss_mask_3: 2.923  loss_ce_4: 1.105  loss_mask_4: 2.937  loss_ce_5: 1.471  loss_mask_5: 2.761  loss_ce_6: 1.676  loss_mask_6: 2.877  loss_ce_7: 1.728  loss_mask_7: 2.856  loss_ce_8: 1.709  loss_mask_8: 2.912  time: 2.4396  data_time: 0.4588  lr: 7.3041e-05  max_mem: 18490M
[01/24 15:12:40] d2.utils.events INFO:  eta: 1 day, 4:42:06  iter: 17699  total_loss: 43.02  loss_ce: 1.702  loss_mask: 2.906  loss_ce_0: 1.161  loss_mask_0: 3.151  loss_ce_1: 0.9941  loss_mask_1: 3.109  loss_ce_2: 1.006  loss_mask_2: 3.006  loss_ce_3: 1.01  loss_mask_3: 2.942  loss_ce_4: 1.092  loss_mask_4: 2.909  loss_ce_5: 1.463  loss_mask_5: 2.807  loss_ce_6: 1.664  loss_mask_6: 2.747  loss_ce_7: 1.687  loss_mask_7: 2.797  loss_ce_8: 1.717  loss_mask_8: 2.898  time: 2.4396  data_time: 0.4042  lr: 7.301e-05  max_mem: 18490M
[01/24 15:13:28] d2.utils.events INFO:  eta: 1 day, 4:40:09  iter: 17719  total_loss: 43.07  loss_ce: 1.667  loss_mask: 2.743  loss_ce_0: 1.1  loss_mask_0: 3.275  loss_ce_1: 0.9722  loss_mask_1: 3.216  loss_ce_2: 0.9859  loss_mask_2: 3.04  loss_ce_3: 1.01  loss_mask_3: 3.073  loss_ce_4: 1.106  loss_mask_4: 2.997  loss_ce_5: 1.449  loss_mask_5: 2.873  loss_ce_6: 1.639  loss_mask_6: 2.711  loss_ce_7: 1.682  loss_mask_7: 2.729  loss_ce_8: 1.722  loss_mask_8: 2.86  time: 2.4395  data_time: 0.4208  lr: 7.2978e-05  max_mem: 18490M
[01/24 15:14:25] d2.utils.events INFO:  eta: 1 day, 4:41:52  iter: 17739  total_loss: 42.94  loss_ce: 1.651  loss_mask: 2.757  loss_ce_0: 1.147  loss_mask_0: 3.264  loss_ce_1: 1.013  loss_mask_1: 3.261  loss_ce_2: 1.019  loss_mask_2: 3.062  loss_ce_3: 1.06  loss_mask_3: 3.077  loss_ce_4: 1.143  loss_mask_4: 3.023  loss_ce_5: 1.462  loss_mask_5: 2.757  loss_ce_6: 1.669  loss_mask_6: 2.719  loss_ce_7: 1.708  loss_mask_7: 2.785  loss_ce_8: 1.71  loss_mask_8: 2.804  time: 2.4400  data_time: 0.5352  lr: 7.2947e-05  max_mem: 18490M
[01/24 15:15:16] d2.utils.events INFO:  eta: 1 day, 4:47:16  iter: 17759  total_loss: 43.65  loss_ce: 1.717  loss_mask: 2.841  loss_ce_0: 1.154  loss_mask_0: 3.242  loss_ce_1: 1.02  loss_mask_1: 3.18  loss_ce_2: 1.031  loss_mask_2: 3.071  loss_ce_3: 1.043  loss_mask_3: 3  loss_ce_4: 1.117  loss_mask_4: 2.97  loss_ce_5: 1.437  loss_mask_5: 2.86  loss_ce_6: 1.632  loss_mask_6: 2.771  loss_ce_7: 1.692  loss_mask_7: 2.765  loss_ce_8: 1.76  loss_mask_8: 2.981  time: 2.4401  data_time: 0.4328  lr: 7.2916e-05  max_mem: 18490M
[01/24 15:16:08] d2.utils.events INFO:  eta: 1 day, 4:50:22  iter: 17779  total_loss: 42.75  loss_ce: 1.665  loss_mask: 2.828  loss_ce_0: 1.14  loss_mask_0: 3.269  loss_ce_1: 1.01  loss_mask_1: 3.121  loss_ce_2: 1.008  loss_mask_2: 3.053  loss_ce_3: 1.042  loss_mask_3: 2.965  loss_ce_4: 1.124  loss_mask_4: 2.902  loss_ce_5: 1.456  loss_mask_5: 2.85  loss_ce_6: 1.63  loss_mask_6: 2.803  loss_ce_7: 1.657  loss_mask_7: 2.796  loss_ce_8: 1.657  loss_mask_8: 2.818  time: 2.4403  data_time: 0.4791  lr: 7.2885e-05  max_mem: 18490M
[01/24 15:17:03] d2.utils.events INFO:  eta: 1 day, 4:56:23  iter: 17799  total_loss: 46.45  loss_ce: 1.72  loss_mask: 3.062  loss_ce_0: 1.131  loss_mask_0: 3.511  loss_ce_1: 1.065  loss_mask_1: 3.424  loss_ce_2: 1.106  loss_mask_2: 3.34  loss_ce_3: 1.121  loss_mask_3: 3.27  loss_ce_4: 1.225  loss_mask_4: 3.244  loss_ce_5: 1.571  loss_mask_5: 3.191  loss_ce_6: 1.747  loss_mask_6: 3.091  loss_ce_7: 1.823  loss_mask_7: 3.086  loss_ce_8: 1.781  loss_mask_8: 3.066  time: 2.4406  data_time: 0.5017  lr: 7.2854e-05  max_mem: 18490M
[01/24 15:17:53] d2.utils.events INFO:  eta: 1 day, 5:01:10  iter: 17819  total_loss: 44.76  loss_ce: 1.707  loss_mask: 2.938  loss_ce_0: 1.168  loss_mask_0: 3.355  loss_ce_1: 1.019  loss_mask_1: 3.337  loss_ce_2: 1.046  loss_mask_2: 3.147  loss_ce_3: 1.109  loss_mask_3: 3.143  loss_ce_4: 1.183  loss_mask_4: 3.111  loss_ce_5: 1.503  loss_mask_5: 2.964  loss_ce_6: 1.665  loss_mask_6: 2.925  loss_ce_7: 1.741  loss_mask_7: 2.91  loss_ce_8: 1.732  loss_mask_8: 2.931  time: 2.4407  data_time: 0.4220  lr: 7.2823e-05  max_mem: 18490M
[01/24 15:18:46] d2.utils.events INFO:  eta: 1 day, 5:03:33  iter: 17839  total_loss: 45.81  loss_ce: 1.689  loss_mask: 2.879  loss_ce_0: 1.282  loss_mask_0: 3.426  loss_ce_1: 1.057  loss_mask_1: 3.476  loss_ce_2: 1.045  loss_mask_2: 3.316  loss_ce_3: 1.053  loss_mask_3: 3.224  loss_ce_4: 1.157  loss_mask_4: 3.163  loss_ce_5: 1.511  loss_mask_5: 2.985  loss_ce_6: 1.669  loss_mask_6: 2.94  loss_ce_7: 1.797  loss_mask_7: 3.044  loss_ce_8: 1.755  loss_mask_8: 3.068  time: 2.4409  data_time: 0.4469  lr: 7.2792e-05  max_mem: 18490M
[01/24 15:19:39] d2.utils.events INFO:  eta: 1 day, 5:05:04  iter: 17859  total_loss: 44.32  loss_ce: 1.693  loss_mask: 2.803  loss_ce_0: 1.333  loss_mask_0: 3.304  loss_ce_1: 1.026  loss_mask_1: 3.333  loss_ce_2: 1.005  loss_mask_2: 3.245  loss_ce_3: 1.04  loss_mask_3: 3.122  loss_ce_4: 1.136  loss_mask_4: 3.051  loss_ce_5: 1.464  loss_mask_5: 2.934  loss_ce_6: 1.687  loss_mask_6: 2.879  loss_ce_7: 1.797  loss_mask_7: 2.904  loss_ce_8: 1.72  loss_mask_8: 2.885  time: 2.4411  data_time: 0.4466  lr: 7.2761e-05  max_mem: 18490M
[01/24 15:20:31] d2.utils.events INFO:  eta: 1 day, 5:07:50  iter: 17879  total_loss: 45.89  loss_ce: 1.684  loss_mask: 2.998  loss_ce_0: 1.259  loss_mask_0: 3.564  loss_ce_1: 0.9938  loss_mask_1: 3.439  loss_ce_2: 1.017  loss_mask_2: 3.351  loss_ce_3: 1.045  loss_mask_3: 3.193  loss_ce_4: 1.139  loss_mask_4: 3.174  loss_ce_5: 1.468  loss_mask_5: 3.046  loss_ce_6: 1.678  loss_mask_6: 3.072  loss_ce_7: 1.739  loss_mask_7: 3.094  loss_ce_8: 1.732  loss_mask_8: 3.084  time: 2.4413  data_time: 0.4308  lr: 7.273e-05  max_mem: 18490M
[01/24 15:21:27] d2.utils.events INFO:  eta: 1 day, 5:10:42  iter: 17899  total_loss: 45.06  loss_ce: 1.733  loss_mask: 2.994  loss_ce_0: 1.338  loss_mask_0: 3.337  loss_ce_1: 1.036  loss_mask_1: 3.34  loss_ce_2: 1.045  loss_mask_2: 3.272  loss_ce_3: 1.075  loss_mask_3: 3.159  loss_ce_4: 1.174  loss_mask_4: 3.122  loss_ce_5: 1.511  loss_mask_5: 2.928  loss_ce_6: 1.691  loss_mask_6: 2.939  loss_ce_7: 1.731  loss_mask_7: 2.978  loss_ce_8: 1.737  loss_mask_8: 2.984  time: 2.4417  data_time: 0.4519  lr: 7.2699e-05  max_mem: 18490M
[01/24 15:22:15] d2.utils.events INFO:  eta: 1 day, 5:08:16  iter: 17919  total_loss: 44.09  loss_ce: 1.706  loss_mask: 2.83  loss_ce_0: 1.269  loss_mask_0: 3.314  loss_ce_1: 1.042  loss_mask_1: 3.158  loss_ce_2: 1.042  loss_mask_2: 3.109  loss_ce_3: 1.053  loss_mask_3: 3.005  loss_ce_4: 1.151  loss_mask_4: 2.947  loss_ce_5: 1.544  loss_mask_5: 2.871  loss_ce_6: 1.683  loss_mask_6: 2.857  loss_ce_7: 1.731  loss_mask_7: 2.843  loss_ce_8: 1.706  loss_mask_8: 2.865  time: 2.4417  data_time: 0.3721  lr: 7.2668e-05  max_mem: 18490M
[01/24 15:23:04] d2.utils.events INFO:  eta: 1 day, 5:05:33  iter: 17939  total_loss: 42.98  loss_ce: 1.679  loss_mask: 2.877  loss_ce_0: 1.232  loss_mask_0: 3.242  loss_ce_1: 1.029  loss_mask_1: 3.126  loss_ce_2: 1.047  loss_mask_2: 3.069  loss_ce_3: 1.073  loss_mask_3: 2.974  loss_ce_4: 1.16  loss_mask_4: 3.014  loss_ce_5: 1.629  loss_mask_5: 2.906  loss_ce_6: 1.695  loss_mask_6: 2.785  loss_ce_7: 1.729  loss_mask_7: 2.77  loss_ce_8: 1.683  loss_mask_8: 2.824  time: 2.4417  data_time: 0.3734  lr: 7.2637e-05  max_mem: 18490M
[01/24 15:23:56] d2.utils.events INFO:  eta: 1 day, 5:04:31  iter: 17959  total_loss: 43.92  loss_ce: 1.671  loss_mask: 2.851  loss_ce_0: 1.224  loss_mask_0: 3.273  loss_ce_1: 1.065  loss_mask_1: 3.252  loss_ce_2: 1.082  loss_mask_2: 3.1  loss_ce_3: 1.089  loss_mask_3: 3.017  loss_ce_4: 1.196  loss_mask_4: 2.974  loss_ce_5: 1.634  loss_mask_5: 2.93  loss_ce_6: 1.697  loss_mask_6: 2.835  loss_ce_7: 1.749  loss_mask_7: 2.887  loss_ce_8: 1.693  loss_mask_8: 2.857  time: 2.4418  data_time: 0.4462  lr: 7.2606e-05  max_mem: 18490M
[01/24 15:24:44] d2.utils.events INFO:  eta: 1 day, 5:02:22  iter: 17979  total_loss: 42.54  loss_ce: 1.625  loss_mask: 2.661  loss_ce_0: 1.165  loss_mask_0: 3.15  loss_ce_1: 1.029  loss_mask_1: 2.969  loss_ce_2: 1.029  loss_mask_2: 2.979  loss_ce_3: 1.074  loss_mask_3: 2.852  loss_ce_4: 1.178  loss_mask_4: 2.827  loss_ce_5: 1.505  loss_mask_5: 2.73  loss_ce_6: 1.665  loss_mask_6: 2.713  loss_ce_7: 1.725  loss_mask_7: 2.782  loss_ce_8: 1.658  loss_mask_8: 2.8  time: 2.4418  data_time: 0.4053  lr: 7.2574e-05  max_mem: 18490M
[01/24 15:25:33] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 15:25:33] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 15:25:33] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 15:30:11] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 6.7000550232230465, 'error_1pix': 0.7516744360495133, 'error_3pix': 0.5599692390587452, 'mIoU': 1.3278575514103184, 'fwIoU': 10.903854200937399, 'IoU-0': nan, 'IoU-1': 91.80806529788372, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.00014960748605938743, 'IoU-11': 0.00385063110711307, 'IoU-12': 0.0012733083954000082, 'IoU-13': 0.19686376955745563, 'IoU-14': 0.04344778991218523, 'IoU-15': 2.7993171525060334, 'IoU-16': 2.9737367502890932, 'IoU-17': 0.8961872354939859, 'IoU-18': 2.920444912908355, 'IoU-19': 0.0014732707115951767, 'IoU-20': 1.0348397038010348, 'IoU-21': 0.8583845839354941, 'IoU-22': 3.1534544703839167, 'IoU-23': 0.140547684334268, 'IoU-24': 4.86236109165828, 'IoU-25': 0.021944934782291276, 'IoU-26': 5.491322073660552, 'IoU-27': 0.00501497452809681, 'IoU-28': 5.814352246074081, 'IoU-29': 2.4043963094693743, 'IoU-30': 0.31289772867511007, 'IoU-31': 5.7559348178328085, 'IoU-32': 0.6260267197673072, 'IoU-33': 6.560544485010368, 'IoU-34': 1.938634105382559, 'IoU-35': 2.7445414565685753, 'IoU-36': 2.9293089389600233, 'IoU-37': 0.13743873839920007, 'IoU-38': 0.4851408979348457, 'IoU-39': 0.9010655536625584, 'IoU-40': 7.693264874196634, 'IoU-41': 4.593314495784351, 'IoU-42': 0.02866611251153198, 'IoU-43': 2.529893853271343, 'IoU-44': 0.006758985288717682, 'IoU-45': 0.2615290359476533, 'IoU-46': 0.8004009928878588, 'IoU-47': 2.110086206696597, 'IoU-48': 1.2426028249103493, 'IoU-49': 0.5182104697287088, 'IoU-50': 0.9117265319573622, 'IoU-51': 0.003072574356927006, 'IoU-52': 1.473303410203758, 'IoU-53': 2.0675212369827856, 'IoU-54': 0.265435253118553, 'IoU-55': 2.4557569774452728, 'IoU-56': 0.020452250305610525, 'IoU-57': 0.2183271177477345, 'IoU-58': 0.40600555895397417, 'IoU-59': 0.14287775270963415, 'IoU-60': 0.7069002613188267, 'IoU-61': 4.388940637712751, 'IoU-62': 3.468697595137914, 'IoU-63': 2.3672996820612138, 'IoU-64': 3.1984544179811722, 'IoU-65': 0.09228904285915313, 'IoU-66': 0.014117589142963679, 'IoU-67': 0.004526689742584354, 'IoU-68': 0.7338397782998659, 'IoU-69': 0.0743599120325833, 'IoU-70': 3.6732679157827146, 'IoU-71': 4.536237842111484, 'IoU-72': 0.01550060796829031, 'IoU-73': 0.0011417942023605127, 'IoU-74': 2.2988024369920566, 'IoU-75': 0.576822492389286, 'IoU-76': 3.677232129380189, 'IoU-77': 0.2767147915025956, 'IoU-78': 1.6958875332668104, 'IoU-79': 2.0927594262832288, 'IoU-80': 3.1901121129801244, 'IoU-81': 0.019519528739112772, 'IoU-82': 1.741269445617516, 'IoU-83': 0.008041156563862268, 'IoU-84': 1.81586339995892, 'IoU-85': 0.005539812807196699, 'IoU-86': 0.022593376226411725, 'IoU-87': 2.2600334895081007, 'IoU-88': 0.5188721274977816, 'IoU-89': 3.645401299813617, 'IoU-90': 1.4396274781446308, 'IoU-91': 0.015474069591184803, 'IoU-92': 1.3829921984579017, 'IoU-93': 0.011062366599270058, 'IoU-94': 0.07186231418600426, 'IoU-95': 0.015554540450004099, 'IoU-96': 0.03341272085808487, 'IoU-97': 0.5163750466363698, 'IoU-98': 2.6433702519485758, 'IoU-99': 1.688625194834046, 'IoU-100': 0.12758824475395455, 'IoU-101': 0.00015043052140723025, 'IoU-102': 0.000747420380477742, 'IoU-103': 0.29538218347466527, 'IoU-104': 0.0013769877802170133, 'IoU-105': 2.4831764994811993, 'IoU-106': 1.8140007587408982, 'IoU-107': 0.012299717823752217, 'IoU-108': 0.31666203079804495, 'IoU-109': 0.015723836548609437, 'IoU-110': 0.029004198148804068, 'IoU-111': 0.546551091335022, 'IoU-112': 2.346225398982774, 'IoU-113': 0.003795850280721937, 'IoU-114': 0.0008343354427509855, 'IoU-115': 1.788205998329281, 'IoU-116': 0.0, 'IoU-117': 0.0033103853168856374, 'IoU-118': 0.024818830891004385, 'IoU-119': 0.007295315213078665, 'IoU-120': 0.0005705132424900709, 'IoU-121': 0.029232350642045955, 'IoU-122': 2.0958562267636007, 'IoU-123': 0.004225608168198859, 'IoU-124': 0.09812973827929296, 'IoU-125': 0.0, 'IoU-126': 0.00011371783988414426, 'IoU-127': 0.012253981098812173, 'IoU-128': 0.007277826161844299, 'IoU-129': 0.0, 'IoU-130': 0.014182193085009297, 'IoU-131': 0.016233215897859823, 'IoU-132': 0.03335095834394888, 'IoU-133': 0.8816716779299764, 'IoU-134': 2.0779017130950974, 'IoU-135': 0.00042639286559457285, 'IoU-136': 0.0009437050878044991, 'IoU-137': 0.0926799410040603, 'IoU-138': 0.2620752589642937, 'IoU-139': 0.3389979333983524, 'IoU-140': 0.4381031928943021, 'IoU-141': 0.03836957831516328, 'IoU-142': 0.0, 'IoU-143': 0.06325820659938848, 'IoU-144': 0.00027065235336732127, 'IoU-145': 0.16347173648180774, 'IoU-146': 0.07553593021660546, 'IoU-147': 0.0, 'IoU-148': 1.4114609712299486, 'IoU-149': 0.007821906089601418, 'IoU-150': 0.00010404549701493469, 'IoU-151': 0.0011694538650450239, 'IoU-152': 0.001988158943889969, 'IoU-153': 0.0, 'IoU-154': 0.6532030364798055, 'IoU-155': 0.0007368481810288611, 'IoU-156': 0.0, 'IoU-157': 1.242008035344839, 'IoU-158': 0.0004227108446467194, 'IoU-159': 0.0, 'IoU-160': 0.002259816785354127, 'IoU-161': 0.0, 'IoU-162': 0.6801411714962317, 'IoU-163': 0.0003057243833539188, 'IoU-164': 0.0016760780991445907, 'IoU-165': 0.0, 'IoU-166': 0.00016783761375194271, 'IoU-167': 0.0, 'IoU-168': 0.00017568548082480821, 'IoU-169': 0.1939411648959422, 'IoU-170': 0.23349426190385678, 'IoU-171': 0.0, 'IoU-172': 0.22147917525373786, 'IoU-173': 0.00425617747149749, 'IoU-174': 0.0012693784216548704, 'IoU-175': 0.003497526880334879, 'IoU-176': 0.0, 'IoU-177': 0.0068228093415759, 'IoU-178': 0.0, 'IoU-179': 0.0018162994714568538, 'IoU-180': 0.8948702753689762, 'IoU-181': 0.008329534911163197, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.9402585625300756, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 1.3542955652211461, 'IoU-190': 0.006267693175526747, 'IoU-191': 0.0, 'IoU-192': 0.0005659389634827884, 'mACC': 3.7295569500997017, 'pACC': 14.82497759721185, 'ACC-0': nan, 'ACC-1': 96.17261520060988, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.00014962015183951743, 'ACC-11': 0.003863456675269892, 'ACC-12': 0.0012737373870128797, 'ACC-13': 0.2021437907077694, 'ACC-14': 0.04362648093351292, 'ACC-15': 4.7004033156872636, 'ACC-16': 7.496247006417091, 'ACC-17': 1.194625387441996, 'ACC-18': 10.560828181796339, 'ACC-19': 0.0014785200069154824, 'ACC-20': 1.1632487062560843, 'ACC-21': 1.0339418541573357, 'ACC-22': 11.174797682845773, 'ACC-23': 0.1520465276699992, 'ACC-24': 17.744977055254317, 'ACC-25': 0.02218363193504568, 'ACC-26': 45.26438356268526, 'ACC-27': 0.005021502802427125, 'ACC-28': 14.39392011563649, 'ACC-29': 2.83284745890839, 'ACC-30': 0.32371169212293716, 'ACC-31': 33.809037994802296, 'ACC-32': 0.7198354717462438, 'ACC-33': 20.91273298439549, 'ACC-34': 2.2678838992726598, 'ACC-35': 3.582731715867012, 'ACC-36': 4.019727275696723, 'ACC-37': 0.14106184973417235, 'ACC-38': 0.5237113970857635, 'ACC-39': 1.204179032854757, 'ACC-40': 36.92598871804069, 'ACC-41': 26.065941236963752, 'ACC-42': 0.028761740267698413, 'ACC-43': 10.97523667126647, 'ACC-44': 0.006768682567716941, 'ACC-45': 0.26550731688064605, 'ACC-46': 0.9228129160228065, 'ACC-47': 4.418020740442602, 'ACC-48': 2.1569365999473717, 'ACC-49': 0.6647766146172127, 'ACC-50': 1.1801499118257148, 'ACC-51': 0.003076971343140224, 'ACC-52': 2.097437741315768, 'ACC-53': 3.1005661301938914, 'ACC-54': 0.27828454069130676, 'ACC-55': 4.439532197212446, 'ACC-56': 0.02050264995956051, 'ACC-57': 0.22637005423318288, 'ACC-58': 0.49554383203016017, 'ACC-59': 0.15292771700956775, 'ACC-60': 0.7502998831410892, 'ACC-61': 16.31706182689431, 'ACC-62': 6.215760278663575, 'ACC-63': 3.684405467582161, 'ACC-64': 13.451467648347881, 'ACC-65': 0.09607856423232357, 'ACC-66': 0.014186247026305061, 'ACC-67': 0.0045389687928437915, 'ACC-68': 0.867686750811545, 'ACC-69': 0.07673943514056027, 'ACC-70': 9.409067552746924, 'ACC-71': 20.901644902412304, 'ACC-72': 0.01553525467126733, 'ACC-73': 0.001160185612018904, 'ACC-74': 3.6353329694376657, 'ACC-75': 0.6644142053576401, 'ACC-76': 12.448979246017574, 'ACC-77': 0.30055635619983584, 'ACC-78': 2.4859281955857138, 'ACC-79': 3.2667148058510604, 'ACC-80': 17.919137529495817, 'ACC-81': 0.020077184141683756, 'ACC-82': 2.357139047823926, 'ACC-83': 0.008091192075217146, 'ACC-84': 3.2005396839042883, 'ACC-85': 0.005577998706644947, 'ACC-86': 0.02340822026969258, 'ACC-87': 6.962894285834535, 'ACC-88': 0.6411405293267873, 'ACC-89': 25.82874236014098, 'ACC-90': 2.6493077049737277, 'ACC-91': 0.015594378512307175, 'ACC-92': 2.5400435896768654, 'ACC-93': 0.011211107511574621, 'ACC-94': 0.08263877231779025, 'ACC-95': 0.01567669492459132, 'ACC-96': 0.033722634082442096, 'ACC-97': 0.6594611826506135, 'ACC-98': 7.588191000178907, 'ACC-99': 5.986353051163716, 'ACC-100': 0.13108737238950427, 'ACC-101': 0.0001504545446729634, 'ACC-102': 0.0007476212052560036, 'ACC-103': 0.3325304618872202, 'ACC-104': 0.0013772410909716928, 'ACC-105': 26.600087701577635, 'ACC-106': 4.663072627851782, 'ACC-107': 0.012591978556105287, 'ACC-108': 0.3895062688842417, 'ACC-109': 0.015847298942710173, 'ACC-110': 0.029266803345448542, 'ACC-111': 0.7560294476666476, 'ACC-112': 16.574310044650158, 'ACC-113': 0.0038492148121947287, 'ACC-114': 0.0008381933362172042, 'ACC-115': 3.331829867845384, 'ACC-116': 0.0, 'ACC-117': 0.0033351361820486095, 'ACC-118': 0.02494020020178889, 'ACC-119': 0.007334217728476966, 'ACC-120': 0.0005710229568798603, 'ACC-121': 0.03052288148719106, 'ACC-122': 10.240170964363553, 'ACC-123': 0.004243401510650938, 'ACC-124': 0.10100681849298467, 'ACC-125': 0.0, 'ACC-126': 0.00011384438838240786, 'ACC-127': 0.012382136082011793, 'ACC-128': 0.007318045935374336, 'ACC-129': 0.0, 'ACC-130': 0.014833235734941686, 'ACC-131': 0.01654800616463073, 'ACC-132': 0.03491804981686455, 'ACC-133': 6.398239060469358, 'ACC-134': 17.48398104265403, 'ACC-135': 0.0004275696938600992, 'ACC-136': 0.0009463520313082371, 'ACC-137': 0.09395390229252101, 'ACC-138': 0.7166630707921923, 'ACC-139': 0.44312250103094647, 'ACC-140': 0.4926393975686076, 'ACC-141': 0.04073120936346545, 'ACC-142': 0.0, 'ACC-143': 0.06532758594351634, 'ACC-144': 0.0002707581227436823, 'ACC-145': 0.2001833672488204, 'ACC-146': 0.08654131731054808, 'ACC-147': 0.0, 'ACC-148': 7.419697334064604, 'ACC-149': 0.008011609735221368, 'ACC-150': 0.0001042308337737086, 'ACC-151': 0.001172354183119592, 'ACC-152': 0.002001989345201969, 'ACC-153': 0.0, 'ACC-154': 2.8856348784207912, 'ACC-155': 0.0007395301025728253, 'ACC-156': 0.0, 'ACC-157': 4.812496512338496, 'ACC-158': 0.0004233993036492786, 'ACC-159': 0.0, 'ACC-160': 0.0022621363615798764, 'ACC-161': 0.0, 'ACC-162': 1.2826501557567518, 'ACC-163': 0.00030573232828925946, 'ACC-164': 0.0017440440894345808, 'ACC-165': 0.0, 'ACC-166': 0.00016788241515642443, 'ACC-167': 0.0, 'ACC-168': 0.00017582108446444897, 'ACC-169': 0.2888261480663914, 'ACC-170': 0.49050924940017315, 'ACC-171': 0.0, 'ACC-172': 0.38115346149572177, 'ACC-173': 0.004327326502428947, 'ACC-174': 0.001304799237997245, 'ACC-175': 0.0035128004599919763, 'ACC-176': 0.0, 'ACC-177': 0.01642463399825419, 'ACC-178': 0.0, 'ACC-179': 0.0018259985676055681, 'ACC-180': 1.6204409224829828, 'ACC-181': 0.008527148308426954, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 19.39592044658587, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 40.82244602986746, 'ACC-190': 0.006288187639519163, 'ACC-191': 0.0, 'ACC-192': 0.0005659774005223972})])
[01/24 15:30:11] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 15:30:11] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 15:30:11] d2.evaluation.testing INFO: copypaste: 6.7001,0.7517,0.5600,1.3279,10.9039,3.7296,14.8250
[01/24 15:30:11] d2.utils.events INFO:  eta: 1 day, 5:00:53  iter: 17999  total_loss: 45.21  loss_ce: 1.645  loss_mask: 2.882  loss_ce_0: 1.227  loss_mask_0: 3.461  loss_ce_1: 1.064  loss_mask_1: 3.33  loss_ce_2: 1.063  loss_mask_2: 3.269  loss_ce_3: 1.12  loss_mask_3: 3.155  loss_ce_4: 1.226  loss_mask_4: 3.066  loss_ce_5: 1.494  loss_mask_5: 2.985  loss_ce_6: 1.681  loss_mask_6: 2.978  loss_ce_7: 1.746  loss_mask_7: 2.957  loss_ce_8: 1.694  loss_mask_8: 2.92  time: 2.4418  data_time: 0.4124  lr: 7.2543e-05  max_mem: 18490M
[01/24 15:31:02] d2.utils.events INFO:  eta: 1 day, 5:00:03  iter: 18019  total_loss: 44.87  loss_ce: 1.632  loss_mask: 2.939  loss_ce_0: 1.191  loss_mask_0: 3.394  loss_ce_1: 1.077  loss_mask_1: 3.303  loss_ce_2: 1.064  loss_mask_2: 3.187  loss_ce_3: 1.104  loss_mask_3: 3.181  loss_ce_4: 1.208  loss_mask_4: 3.121  loss_ce_5: 1.464  loss_mask_5: 3.026  loss_ce_6: 1.659  loss_mask_6: 2.96  loss_ce_7: 1.708  loss_mask_7: 2.984  loss_ce_8: 1.686  loss_mask_8: 2.889  time: 2.4419  data_time: 0.4350  lr: 7.2512e-05  max_mem: 18490M
[01/24 15:31:52] d2.utils.events INFO:  eta: 1 day, 4:57:37  iter: 18039  total_loss: 43.47  loss_ce: 1.653  loss_mask: 2.79  loss_ce_0: 1.218  loss_mask_0: 3.199  loss_ce_1: 1.082  loss_mask_1: 3.21  loss_ce_2: 1.098  loss_mask_2: 3.011  loss_ce_3: 1.119  loss_mask_3: 2.919  loss_ce_4: 1.202  loss_mask_4: 2.873  loss_ce_5: 1.446  loss_mask_5: 2.855  loss_ce_6: 1.642  loss_mask_6: 2.741  loss_ce_7: 1.698  loss_mask_7: 2.875  loss_ce_8: 1.71  loss_mask_8: 2.775  time: 2.4420  data_time: 0.4361  lr: 7.2481e-05  max_mem: 18490M
[01/24 15:32:40] d2.utils.events INFO:  eta: 1 day, 4:56:47  iter: 18059  total_loss: 44.12  loss_ce: 1.662  loss_mask: 2.906  loss_ce_0: 1.146  loss_mask_0: 3.42  loss_ce_1: 1.057  loss_mask_1: 3.196  loss_ce_2: 1.078  loss_mask_2: 3.109  loss_ce_3: 1.112  loss_mask_3: 3.087  loss_ce_4: 1.197  loss_mask_4: 3.039  loss_ce_5: 1.449  loss_mask_5: 2.927  loss_ce_6: 1.659  loss_mask_6: 2.834  loss_ce_7: 1.701  loss_mask_7: 2.823  loss_ce_8: 1.694  loss_mask_8: 2.851  time: 2.4419  data_time: 0.3953  lr: 7.245e-05  max_mem: 18507M
[01/24 15:33:33] d2.utils.events INFO:  eta: 1 day, 4:56:39  iter: 18079  total_loss: 42.6  loss_ce: 1.67  loss_mask: 2.773  loss_ce_0: 1.149  loss_mask_0: 3.178  loss_ce_1: 1.033  loss_mask_1: 3.11  loss_ce_2: 1.06  loss_mask_2: 2.916  loss_ce_3: 1.104  loss_mask_3: 2.867  loss_ce_4: 1.181  loss_mask_4: 2.811  loss_ce_5: 1.378  loss_mask_5: 2.751  loss_ce_6: 1.643  loss_mask_6: 2.717  loss_ce_7: 1.705  loss_mask_7: 2.772  loss_ce_8: 1.702  loss_mask_8: 2.825  time: 2.4421  data_time: 0.4584  lr: 7.2419e-05  max_mem: 18507M
[01/24 15:34:21] d2.utils.events INFO:  eta: 1 day, 4:48:07  iter: 18099  total_loss: 43.97  loss_ce: 1.647  loss_mask: 2.867  loss_ce_0: 1.12  loss_mask_0: 3.297  loss_ce_1: 1.057  loss_mask_1: 3.162  loss_ce_2: 1.091  loss_mask_2: 3.051  loss_ce_3: 1.117  loss_mask_3: 2.995  loss_ce_4: 1.18  loss_mask_4: 2.991  loss_ce_5: 1.423  loss_mask_5: 2.855  loss_ce_6: 1.671  loss_mask_6: 2.849  loss_ce_7: 1.757  loss_mask_7: 2.933  loss_ce_8: 1.735  loss_mask_8: 2.975  time: 2.4421  data_time: 0.3963  lr: 7.2388e-05  max_mem: 18507M
[01/24 15:35:08] d2.utils.events INFO:  eta: 1 day, 4:41:18  iter: 18119  total_loss: 44.01  loss_ce: 1.683  loss_mask: 2.763  loss_ce_0: 1.135  loss_mask_0: 3.187  loss_ce_1: 1.074  loss_mask_1: 3.181  loss_ce_2: 1.12  loss_mask_2: 3.082  loss_ce_3: 1.157  loss_mask_3: 2.987  loss_ce_4: 1.254  loss_mask_4: 3.117  loss_ce_5: 1.495  loss_mask_5: 2.914  loss_ce_6: 1.71  loss_mask_6: 2.881  loss_ce_7: 1.79  loss_mask_7: 3.026  loss_ce_8: 1.745  loss_mask_8: 2.891  time: 2.4420  data_time: 0.4004  lr: 7.2357e-05  max_mem: 18507M
[01/24 15:35:59] d2.utils.events INFO:  eta: 1 day, 4:37:59  iter: 18139  total_loss: 43.75  loss_ce: 1.666  loss_mask: 2.826  loss_ce_0: 1.141  loss_mask_0: 3.286  loss_ce_1: 1.102  loss_mask_1: 3.157  loss_ce_2: 1.101  loss_mask_2: 3.129  loss_ce_3: 1.154  loss_mask_3: 2.936  loss_ce_4: 1.323  loss_mask_4: 2.994  loss_ce_5: 1.5  loss_mask_5: 2.778  loss_ce_6: 1.698  loss_mask_6: 2.651  loss_ce_7: 1.717  loss_mask_7: 2.739  loss_ce_8: 1.718  loss_mask_8: 2.848  time: 2.4421  data_time: 0.4497  lr: 7.2326e-05  max_mem: 18507M
[01/24 15:36:47] d2.utils.events INFO:  eta: 1 day, 4:33:46  iter: 18159  total_loss: 43.91  loss_ce: 1.658  loss_mask: 2.737  loss_ce_0: 1.07  loss_mask_0: 3.331  loss_ce_1: 1.011  loss_mask_1: 3.282  loss_ce_2: 1.051  loss_mask_2: 3.142  loss_ce_3: 1.1  loss_mask_3: 3.002  loss_ce_4: 1.258  loss_mask_4: 3.05  loss_ce_5: 1.493  loss_mask_5: 2.868  loss_ce_6: 1.704  loss_mask_6: 2.771  loss_ce_7: 1.718  loss_mask_7: 2.798  loss_ce_8: 1.731  loss_mask_8: 2.874  time: 2.4421  data_time: 0.4036  lr: 7.2295e-05  max_mem: 18507M
[01/24 15:37:36] d2.utils.events INFO:  eta: 1 day, 4:29:42  iter: 18179  total_loss: 44.86  loss_ce: 1.605  loss_mask: 2.843  loss_ce_0: 1.119  loss_mask_0: 3.377  loss_ce_1: 1.071  loss_mask_1: 3.327  loss_ce_2: 1.111  loss_mask_2: 3.247  loss_ce_3: 1.125  loss_mask_3: 3.065  loss_ce_4: 1.296  loss_mask_4: 3.121  loss_ce_5: 1.478  loss_mask_5: 2.946  loss_ce_6: 1.7  loss_mask_6: 2.944  loss_ce_7: 1.673  loss_mask_7: 2.945  loss_ce_8: 1.693  loss_mask_8: 2.92  time: 2.4421  data_time: 0.3929  lr: 7.2263e-05  max_mem: 18507M
[01/24 15:38:28] d2.utils.events INFO:  eta: 1 day, 4:26:24  iter: 18199  total_loss: 45.13  loss_ce: 1.673  loss_mask: 3.01  loss_ce_0: 1.123  loss_mask_0: 3.38  loss_ce_1: 1.037  loss_mask_1: 3.291  loss_ce_2: 1.067  loss_mask_2: 3.24  loss_ce_3: 1.079  loss_mask_3: 3.14  loss_ce_4: 1.237  loss_mask_4: 3.092  loss_ce_5: 1.432  loss_mask_5: 3.089  loss_ce_6: 1.718  loss_mask_6: 2.988  loss_ce_7: 1.76  loss_mask_7: 2.983  loss_ce_8: 1.738  loss_mask_8: 3.033  time: 2.4422  data_time: 0.4516  lr: 7.2232e-05  max_mem: 18593M
[01/24 15:39:16] d2.utils.events INFO:  eta: 1 day, 4:23:10  iter: 18219  total_loss: 43.91  loss_ce: 1.635  loss_mask: 2.866  loss_ce_0: 1.111  loss_mask_0: 3.319  loss_ce_1: 1.063  loss_mask_1: 3.179  loss_ce_2: 1.077  loss_mask_2: 3.066  loss_ce_3: 1.101  loss_mask_3: 3.039  loss_ce_4: 1.231  loss_mask_4: 3.088  loss_ce_5: 1.419  loss_mask_5: 2.939  loss_ce_6: 1.728  loss_mask_6: 2.85  loss_ce_7: 1.768  loss_mask_7: 2.869  loss_ce_8: 1.727  loss_mask_8: 2.945  time: 2.4422  data_time: 0.3894  lr: 7.2201e-05  max_mem: 18593M
[01/24 15:40:06] d2.utils.events INFO:  eta: 1 day, 4:21:35  iter: 18239  total_loss: 44.13  loss_ce: 1.686  loss_mask: 2.966  loss_ce_0: 1.088  loss_mask_0: 3.178  loss_ce_1: 1.044  loss_mask_1: 3.175  loss_ce_2: 1.035  loss_mask_2: 3.169  loss_ce_3: 1.056  loss_mask_3: 3.12  loss_ce_4: 1.217  loss_mask_4: 3.092  loss_ce_5: 1.405  loss_mask_5: 2.985  loss_ce_6: 1.726  loss_mask_6: 2.937  loss_ce_7: 1.764  loss_mask_7: 2.9  loss_ce_8: 1.784  loss_mask_8: 2.99  time: 2.4423  data_time: 0.3984  lr: 7.217e-05  max_mem: 18593M
[01/24 15:40:58] d2.utils.events INFO:  eta: 1 day, 4:20:12  iter: 18259  total_loss: 45.01  loss_ce: 1.682  loss_mask: 2.88  loss_ce_0: 1.051  loss_mask_0: 3.397  loss_ce_1: 0.99  loss_mask_1: 3.222  loss_ce_2: 1.044  loss_mask_2: 3.286  loss_ce_3: 1.074  loss_mask_3: 3.124  loss_ce_4: 1.27  loss_mask_4: 3.102  loss_ce_5: 1.433  loss_mask_5: 2.906  loss_ce_6: 1.708  loss_mask_6: 2.884  loss_ce_7: 1.783  loss_mask_7: 3.134  loss_ce_8: 1.781  loss_mask_8: 3.013  time: 2.4424  data_time: 0.4798  lr: 7.2139e-05  max_mem: 18593M
[01/24 15:41:46] d2.utils.events INFO:  eta: 1 day, 4:20:43  iter: 18279  total_loss: 44.71  loss_ce: 1.688  loss_mask: 2.848  loss_ce_0: 1.126  loss_mask_0: 3.437  loss_ce_1: 1.065  loss_mask_1: 3.191  loss_ce_2: 1.102  loss_mask_2: 3.2  loss_ce_3: 1.108  loss_mask_3: 3.052  loss_ce_4: 1.302  loss_mask_4: 3.1  loss_ce_5: 1.519  loss_mask_5: 2.961  loss_ce_6: 1.734  loss_mask_6: 2.935  loss_ce_7: 1.738  loss_mask_7: 2.891  loss_ce_8: 1.78  loss_mask_8: 3.061  time: 2.4424  data_time: 0.4279  lr: 7.2108e-05  max_mem: 18593M
[01/24 15:42:36] d2.utils.events INFO:  eta: 1 day, 4:19:09  iter: 18299  total_loss: 44.2  loss_ce: 1.652  loss_mask: 2.784  loss_ce_0: 1.148  loss_mask_0: 3.377  loss_ce_1: 1.098  loss_mask_1: 3.243  loss_ce_2: 1.133  loss_mask_2: 3.13  loss_ce_3: 1.151  loss_mask_3: 3.123  loss_ce_4: 1.264  loss_mask_4: 3.06  loss_ce_5: 1.496  loss_mask_5: 2.927  loss_ce_6: 1.683  loss_mask_6: 2.81  loss_ce_7: 1.728  loss_mask_7: 2.831  loss_ce_8: 1.711  loss_mask_8: 2.877  time: 2.4425  data_time: 0.4052  lr: 7.2077e-05  max_mem: 18593M
[01/24 15:43:24] d2.utils.events INFO:  eta: 1 day, 4:17:35  iter: 18319  total_loss: 42.77  loss_ce: 1.638  loss_mask: 2.662  loss_ce_0: 1.138  loss_mask_0: 3.134  loss_ce_1: 1.035  loss_mask_1: 3.13  loss_ce_2: 1.097  loss_mask_2: 3.074  loss_ce_3: 1.132  loss_mask_3: 3.025  loss_ce_4: 1.274  loss_mask_4: 2.903  loss_ce_5: 1.483  loss_mask_5: 2.825  loss_ce_6: 1.643  loss_mask_6: 2.703  loss_ce_7: 1.699  loss_mask_7: 2.739  loss_ce_8: 1.675  loss_mask_8: 2.696  time: 2.4424  data_time: 0.3880  lr: 7.2046e-05  max_mem: 18593M
[01/24 15:44:11] d2.utils.events INFO:  eta: 1 day, 4:17:45  iter: 18339  total_loss: 42.85  loss_ce: 1.666  loss_mask: 2.811  loss_ce_0: 1.06  loss_mask_0: 3.196  loss_ce_1: 1.013  loss_mask_1: 3.044  loss_ce_2: 1.071  loss_mask_2: 3.054  loss_ce_3: 1.085  loss_mask_3: 2.957  loss_ce_4: 1.218  loss_mask_4: 2.992  loss_ce_5: 1.489  loss_mask_5: 2.828  loss_ce_6: 1.673  loss_mask_6: 2.821  loss_ce_7: 1.713  loss_mask_7: 2.799  loss_ce_8: 1.686  loss_mask_8: 2.799  time: 2.4423  data_time: 0.4013  lr: 7.2015e-05  max_mem: 18593M
[01/24 15:45:05] d2.utils.events INFO:  eta: 1 day, 4:18:18  iter: 18359  total_loss: 44.72  loss_ce: 1.67  loss_mask: 2.83  loss_ce_0: 1.118  loss_mask_0: 3.227  loss_ce_1: 1.088  loss_mask_1: 3.134  loss_ce_2: 1.123  loss_mask_2: 3.119  loss_ce_3: 1.161  loss_mask_3: 3.134  loss_ce_4: 1.26  loss_mask_4: 3.067  loss_ce_5: 1.577  loss_mask_5: 2.968  loss_ce_6: 1.68  loss_mask_6: 2.912  loss_ce_7: 1.746  loss_mask_7: 2.894  loss_ce_8: 1.743  loss_mask_8: 2.897  time: 2.4426  data_time: 0.4855  lr: 7.1983e-05  max_mem: 18593M
[01/24 15:45:56] d2.utils.events INFO:  eta: 1 day, 4:20:14  iter: 18379  total_loss: 45.36  loss_ce: 1.711  loss_mask: 2.935  loss_ce_0: 1.17  loss_mask_0: 3.422  loss_ce_1: 1.114  loss_mask_1: 3.231  loss_ce_2: 1.153  loss_mask_2: 3.16  loss_ce_3: 1.209  loss_mask_3: 3.087  loss_ce_4: 1.307  loss_mask_4: 3.051  loss_ce_5: 1.658  loss_mask_5: 3.092  loss_ce_6: 1.748  loss_mask_6: 3.058  loss_ce_7: 1.775  loss_mask_7: 2.959  loss_ce_8: 1.794  loss_mask_8: 2.952  time: 2.4427  data_time: 0.4258  lr: 7.1952e-05  max_mem: 18593M
[01/24 15:46:48] d2.utils.events INFO:  eta: 1 day, 4:23:11  iter: 18399  total_loss: 46.48  loss_ce: 1.707  loss_mask: 2.949  loss_ce_0: 1.152  loss_mask_0: 3.471  loss_ce_1: 1.11  loss_mask_1: 3.37  loss_ce_2: 1.163  loss_mask_2: 3.289  loss_ce_3: 1.177  loss_mask_3: 3.22  loss_ce_4: 1.273  loss_mask_4: 3.325  loss_ce_5: 1.56  loss_mask_5: 3.111  loss_ce_6: 1.73  loss_mask_6: 3.032  loss_ce_7: 1.805  loss_mask_7: 3.213  loss_ce_8: 1.825  loss_mask_8: 3.162  time: 2.4429  data_time: 0.4109  lr: 7.1921e-05  max_mem: 18593M
[01/24 15:47:44] d2.utils.events INFO:  eta: 1 day, 4:23:07  iter: 18419  total_loss: 46.56  loss_ce: 1.697  loss_mask: 3.006  loss_ce_0: 1.112  loss_mask_0: 3.502  loss_ce_1: 1.061  loss_mask_1: 3.405  loss_ce_2: 1.109  loss_mask_2: 3.351  loss_ce_3: 1.141  loss_mask_3: 3.24  loss_ce_4: 1.248  loss_mask_4: 3.293  loss_ce_5: 1.588  loss_mask_5: 3.167  loss_ce_6: 1.765  loss_mask_6: 3.162  loss_ce_7: 1.779  loss_mask_7: 3.099  loss_ce_8: 1.807  loss_mask_8: 3.053  time: 2.4433  data_time: 0.5240  lr: 7.189e-05  max_mem: 18593M
[01/24 15:48:35] d2.utils.events INFO:  eta: 1 day, 4:23:02  iter: 18439  total_loss: 43.05  loss_ce: 1.674  loss_mask: 2.685  loss_ce_0: 1.071  loss_mask_0: 2.97  loss_ce_1: 1.06  loss_mask_1: 2.956  loss_ce_2: 1.106  loss_mask_2: 2.947  loss_ce_3: 1.146  loss_mask_3: 2.873  loss_ce_4: 1.288  loss_mask_4: 2.913  loss_ce_5: 1.556  loss_mask_5: 2.823  loss_ce_6: 1.806  loss_mask_6: 2.954  loss_ce_7: 1.784  loss_mask_7: 2.843  loss_ce_8: 1.787  loss_mask_8: 2.747  time: 2.4433  data_time: 0.4185  lr: 7.1859e-05  max_mem: 18593M
[01/24 15:49:26] d2.utils.events INFO:  eta: 1 day, 4:26:19  iter: 18459  total_loss: 46.73  loss_ce: 1.696  loss_mask: 2.878  loss_ce_0: 1.113  loss_mask_0: 3.466  loss_ce_1: 1.104  loss_mask_1: 3.327  loss_ce_2: 1.166  loss_mask_2: 3.282  loss_ce_3: 1.244  loss_mask_3: 3.197  loss_ce_4: 1.379  loss_mask_4: 3.312  loss_ce_5: 1.604  loss_mask_5: 3.071  loss_ce_6: 1.79  loss_mask_6: 3.065  loss_ce_7: 1.815  loss_mask_7: 2.928  loss_ce_8: 1.821  loss_mask_8: 2.867  time: 2.4435  data_time: 0.4751  lr: 7.1828e-05  max_mem: 18593M
[01/24 15:50:22] d2.utils.events INFO:  eta: 1 day, 4:26:05  iter: 18479  total_loss: 45.02  loss_ce: 1.726  loss_mask: 3.036  loss_ce_0: 1.165  loss_mask_0: 3.381  loss_ce_1: 1.081  loss_mask_1: 3.2  loss_ce_2: 1.132  loss_mask_2: 3.14  loss_ce_3: 1.207  loss_mask_3: 3.088  loss_ce_4: 1.32  loss_mask_4: 3.095  loss_ce_5: 1.571  loss_mask_5: 2.973  loss_ce_6: 1.705  loss_mask_6: 2.928  loss_ce_7: 1.737  loss_mask_7: 2.914  loss_ce_8: 1.763  loss_mask_8: 3.008  time: 2.4439  data_time: 0.5012  lr: 7.1797e-05  max_mem: 18593M
[01/24 15:51:12] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 15:51:13] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 15:51:13] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 15:55:54] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 7.859049268892017, 'error_1pix': 0.803124240490579, 'error_3pix': 0.6155334712433618, 'mIoU': 0.9452090209209726, 'fwIoU': 6.072614383780415, 'IoU-0': nan, 'IoU-1': 46.297585220264125, 'IoU-2': 0.0, 'IoU-3': 0.00011512646642336606, 'IoU-4': 0.0, 'IoU-5': 0.0001575701423488666, 'IoU-6': 0.0, 'IoU-7': 0.0010847143856629684, 'IoU-8': 0.0, 'IoU-9': 1.5443509803231152e-05, 'IoU-10': 1.870249099724425e-05, 'IoU-11': 0.0, 'IoU-12': 1.092415129581926, 'IoU-13': 3.499392754827843, 'IoU-14': 8.794627234468964, 'IoU-15': 0.042296439927199204, 'IoU-16': 7.977572816415922, 'IoU-17': 4.801745652729512, 'IoU-18': 0.1616999301288637, 'IoU-19': 0.00013000668990238948, 'IoU-20': 0.4561644982916526, 'IoU-21': 0.005055247291513325, 'IoU-22': 0.0003226875196985431, 'IoU-23': 2.9040480326869376, 'IoU-24': 0.09936181231435078, 'IoU-25': 4.242880086186263, 'IoU-26': 0.6737973190956628, 'IoU-27': 5.109097677358061, 'IoU-28': 0.040490315756719214, 'IoU-29': 0.510268800002737, 'IoU-30': 0.09823812003289013, 'IoU-31': 0.6623857025860029, 'IoU-32': 0.34671960896290926, 'IoU-33': 0.03661412716148171, 'IoU-34': 4.541706729276463, 'IoU-35': 0.0070853744724198335, 'IoU-36': 0.2873320739184997, 'IoU-37': 2.2004333579923414, 'IoU-38': 1.2585038694918151, 'IoU-39': 0.40801859949443586, 'IoU-40': 0.5284645704281079, 'IoU-41': 0.15378973475250518, 'IoU-42': 3.261200141745441, 'IoU-43': 0.0, 'IoU-44': 0.2185660158521811, 'IoU-45': 5.296170358128931e-05, 'IoU-46': 6.076190569428758, 'IoU-47': 0.8765194285359157, 'IoU-48': 0.8397424509076836, 'IoU-49': 0.0021062373404468473, 'IoU-50': 0.10764081181429488, 'IoU-51': 4.882146760852369, 'IoU-52': 0.10247989362663465, 'IoU-53': 0.9725746735509586, 'IoU-54': 4.64898346405445, 'IoU-55': 1.0370393547891246, 'IoU-56': 0.0, 'IoU-57': 0.5925115577362422, 'IoU-58': 1.8966466486914924, 'IoU-59': 3.8260380777074277, 'IoU-60': 0.9071301553826991, 'IoU-61': 0.8287397676141337, 'IoU-62': 1.721609540161849, 'IoU-63': 0.8516450134803755, 'IoU-64': 0.1942114055340788, 'IoU-65': 1.442908863463414, 'IoU-66': 0.5308686299818409, 'IoU-67': 0.3772918279214399, 'IoU-68': 0.07805200229221908, 'IoU-69': 0.15106533957414714, 'IoU-70': 0.01947021861237193, 'IoU-71': 2.317498395229273, 'IoU-72': 2.590662465658217, 'IoU-73': 0.3305344460624077, 'IoU-74': 2.1554620500523027, 'IoU-75': 1.285962804543434, 'IoU-76': 0.257873099380187, 'IoU-77': 0.22773000409667277, 'IoU-78': 2.377001373485825, 'IoU-79': 0.1674858129727444, 'IoU-80': 2.609195309734709, 'IoU-81': 3.262678733307915, 'IoU-82': 0.0014384175249599154, 'IoU-83': 0.6957038604163944, 'IoU-84': 0.003516446340385674, 'IoU-85': 0.07909501767234954, 'IoU-86': 1.1034990281627324, 'IoU-87': 0.2756250351177841, 'IoU-88': 1.7515019277811887, 'IoU-89': 2.0575793362176222, 'IoU-90': 1.6243534371853603, 'IoU-91': 0.011735582951531636, 'IoU-92': 3.433784713217405, 'IoU-93': 0.0015428078485720872, 'IoU-94': 0.3188732523021379, 'IoU-95': 0.6209618405386068, 'IoU-96': 0.9049212777047403, 'IoU-97': 0.00018829641896158633, 'IoU-98': 0.31218488833320024, 'IoU-99': 0.03217303887939766, 'IoU-100': 2.6063655059037862, 'IoU-101': 1.979983932554116, 'IoU-102': 0.7667339585250071, 'IoU-103': 0.34699281811094373, 'IoU-104': 0.008623413328799694, 'IoU-105': 0.3260934447327585, 'IoU-106': 0.00026202175461819896, 'IoU-107': 0.0028625794862783046, 'IoU-108': 1.391661063240527, 'IoU-109': 1.5762305831037215, 'IoU-110': 0.2452603073514571, 'IoU-111': 0.0011840363237417043, 'IoU-112': 0.5208646119286905, 'IoU-113': 0.7778173959919956, 'IoU-114': 0.0004733772627433159, 'IoU-115': 0.07603996790142631, 'IoU-116': 1.4122075831031347, 'IoU-117': 0.6855349180833015, 'IoU-118': 1.480346899572607, 'IoU-119': 0.3401301014543137, 'IoU-120': 0.9240370719081882, 'IoU-121': 0.0014973999691444855, 'IoU-122': 0.2502966305781084, 'IoU-123': 0.0006902440900314949, 'IoU-124': 0.018346202835408276, 'IoU-125': 0.0009233810956731448, 'IoU-126': 0.0015314413415426153, 'IoU-127': 0.00480003538003606, 'IoU-128': 0.0, 'IoU-129': 0.001317300737876599, 'IoU-130': 0.004744070232754343, 'IoU-131': 6.64528214871211e-05, 'IoU-132': 0.01751897120170922, 'IoU-133': 0.010463115141146744, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0005094317652538426, 'IoU-137': 0.03489535503221656, 'IoU-138': 0.0, 'IoU-139': 0.1252924214131033, 'IoU-140': 0.0009924638908554377, 'IoU-141': 0.0, 'IoU-142': 0.9521880490062526, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.005061807331628304, 'IoU-146': 0.005002255562508186, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.020393122873613116, 'IoU-150': 0.0, 'IoU-151': 0.006742882308257186, 'IoU-152': 0.0, 'IoU-153': 0.00400243347955557, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.01268446934074072, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.020594504724710097, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.00016785987058003977, 'IoU-167': 0.0, 'IoU-168': 0.013443723178026322, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0010135778894064893, 'IoU-180': 0.0, 'IoU-181': 0.0014172235174070478, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.903982789511765, 'pACC': 9.888556572146646, 'ACC-0': nan, 'ACC-1': 48.10195489750557, 'ACC-2': 0.0, 'ACC-3': 0.00011553988321228604, 'ACC-4': 0.0, 'ACC-5': 0.00015781757235541148, 'ACC-6': 0.0, 'ACC-7': 0.0010938884452563527, 'ACC-8': 0.0, 'ACC-9': 1.5443567043922123e-05, 'ACC-10': 1.870251897993968e-05, 'ACC-11': 0.0, 'ACC-12': 3.356445230657839, 'ACC-13': 4.875803259240272, 'ACC-14': 23.32992063221894, 'ACC-15': 0.04264715394969851, 'ACC-16': 40.18759313961221, 'ACC-17': 40.18457826543185, 'ACC-18': 0.16465318588916375, 'ACC-19': 0.00013001300674307924, 'ACC-20': 0.6297456162477683, 'ACC-21': 0.005073301575363401, 'ACC-22': 0.00032301352460412114, 'ACC-23': 8.218650496162095, 'ACC-24': 0.10330459652291527, 'ACC-25': 12.298140679774969, 'ACC-26': 0.9813976719911386, 'ACC-27': 44.175366892535614, 'ACC-28': 0.04116823727982882, 'ACC-29': 1.6679773922552112, 'ACC-30': 0.10028350642930162, 'ACC-31': 0.773068422494616, 'ACC-32': 0.3630089475690977, 'ACC-33': 0.03688896088561843, 'ACC-34': 11.825749847722097, 'ACC-35': 0.007097449900113096, 'ACC-36': 0.3144508629970648, 'ACC-37': 3.449767290454432, 'ACC-38': 1.4136722040051712, 'ACC-39': 0.43316959856924825, 'ACC-40': 0.5978141796629364, 'ACC-41': 0.15996140420250074, 'ACC-42': 6.458251517388604, 'ACC-43': 0.0, 'ACC-44': 0.2257040146891884, 'ACC-45': 5.297658998544922e-05, 'ACC-46': 48.52820878969385, 'ACC-47': 1.0568568062056294, 'ACC-48': 0.9757097385961998, 'ACC-49': 0.0021066832574026875, 'ACC-50': 0.11065700885962483, 'ACC-51': 14.048732187252009, 'ACC-52': 0.10371743870292056, 'ACC-53': 1.1268839603156529, 'ACC-54': 12.74795718902757, 'ACC-55': 1.212035463332177, 'ACC-56': 0.0, 'ACC-57': 0.6303102757971091, 'ACC-58': 2.974357397222206, 'ACC-59': 22.851570323445845, 'ACC-60': 1.18025605394518, 'ACC-61': 0.9549269600196589, 'ACC-62': 3.749036994145906, 'ACC-63': 1.2947730965208575, 'ACC-64': 0.21663906298422733, 'ACC-65': 2.2162069393591235, 'ACC-66': 0.7628787206703431, 'ACC-67': 0.5626628447632467, 'ACC-68': 0.08668561395280251, 'ACC-69': 0.1583406233148703, 'ACC-70': 0.019602577076994178, 'ACC-71': 13.19926545296975, 'ACC-72': 7.266044632842353, 'ACC-73': 0.3709721117897399, 'ACC-74': 5.487933002530313, 'ACC-75': 2.636264263070591, 'ACC-76': 0.2887028030225044, 'ACC-77': 0.251891835953627, 'ACC-78': 7.374761328931159, 'ACC-79': 0.17380005397558712, 'ACC-80': 10.67670393468883, 'ACC-81': 25.69973751186958, 'ACC-82': 0.0014401475791231708, 'ACC-83': 1.241424811067326, 'ACC-84': 0.0035272716508413906, 'ACC-85': 0.0806263837950111, 'ACC-86': 1.2959189179093638, 'ACC-87': 0.3018775772275125, 'ACC-88': 9.894807304668442, 'ACC-89': 3.8705373107516863, 'ACC-90': 3.256668146508511, 'ACC-91': 0.011784233675094253, 'ACC-92': 33.3329351761753, 'ACC-93': 0.0015468676592842775, 'ACC-94': 0.3949023357198985, 'ACC-95': 0.7199002735551785, 'ACC-96': 1.4282576355953809, 'ACC-97': 0.00018832943063390488, 'ACC-98': 0.39018276830278165, 'ACC-99': 0.03264792615282083, 'ACC-100': 13.333426590665995, 'ACC-101': 7.8765103486934525, 'ACC-102': 0.9011554145899411, 'ACC-103': 0.4133607254179654, 'ACC-104': 0.008632350409483288, 'ACC-105': 0.8064254558298437, 'ACC-106': 0.0002622237571052805, 'ACC-107': 0.002937221779825855, 'ACC-108': 3.1104123421586234, 'ACC-109': 6.650365777772108, 'ACC-110': 0.277853972501851, 'ACC-111': 0.0011908936748189606, 'ACC-112': 0.7003154405724509, 'ACC-113': 1.43350308023879, 'ACC-114': 0.0004737614509053764, 'ACC-115': 0.10599431690045553, 'ACC-116': 2.845308297083279, 'ACC-117': 1.4839748715570746, 'ACC-118': 7.480842441334897, 'ACC-119': 0.7335075531720063, 'ACC-120': 5.028252458912702, 'ACC-121': 0.0014988915016031325, 'ACC-122': 0.6580052270561484, 'ACC-123': 0.000690786292431548, 'ACC-124': 0.018592499817537786, 'ACC-125': 0.0009245531960716277, 'ACC-126': 0.0015368992431625062, 'ACC-127': 0.005198160902354008, 'ACC-128': 0.0, 'ACC-129': 0.0013178049887076662, 'ACC-130': 0.0047724323668942815, 'ACC-131': 6.645785608285434e-05, 'ACC-132': 0.017827641557170766, 'ACC-133': 0.010478542802125646, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0005095741707044353, 'ACC-137': 0.035642950747853216, 'ACC-138': 0.0, 'ACC-139': 0.15363766270712187, 'ACC-140': 0.000993892530400688, 'ACC-141': 0.0, 'ACC-142': 1.5847190673684632, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.00509850399159194, 'ACC-146': 0.005026158872312719, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.020485381854616666, 'ACC-150': 0.0, 'ACC-151': 0.006820969792695807, 'ACC-152': 0.0, 'ACC-153': 0.004007951776324227, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.01347428249445717, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.020942664487814275, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.00016788241515642443, 'ACC-167': 0.0, 'ACC-168': 0.01353822350376257, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0010144436486697601, 'ACC-180': 0.0, 'ACC-181': 0.0014211913847378258, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 15:55:54] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 15:55:54] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 15:55:54] d2.evaluation.testing INFO: copypaste: 7.8590,0.8031,0.6155,0.9452,6.0726,2.9040,9.8886
[01/24 15:55:54] d2.utils.events INFO:  eta: 1 day, 4:28:01  iter: 18499  total_loss: 45.93  loss_ce: 1.739  loss_mask: 2.886  loss_ce_0: 1.219  loss_mask_0: 3.243  loss_ce_1: 1.169  loss_mask_1: 3.178  loss_ce_2: 1.172  loss_mask_2: 3.173  loss_ce_3: 1.241  loss_mask_3: 3.179  loss_ce_4: 1.343  loss_mask_4: 3.01  loss_ce_5: 1.585  loss_mask_5: 2.92  loss_ce_6: 1.727  loss_mask_6: 2.978  loss_ce_7: 1.775  loss_mask_7: 3.035  loss_ce_8: 1.772  loss_mask_8: 3.106  time: 2.4439  data_time: 0.4116  lr: 7.1766e-05  max_mem: 18593M
[01/24 15:56:42] d2.utils.events INFO:  eta: 1 day, 4:29:02  iter: 18519  total_loss: 46.96  loss_ce: 1.817  loss_mask: 3.251  loss_ce_0: 1.202  loss_mask_0: 3.397  loss_ce_1: 1.143  loss_mask_1: 3.344  loss_ce_2: 1.179  loss_mask_2: 3.202  loss_ce_3: 1.232  loss_mask_3: 3.21  loss_ce_4: 1.382  loss_mask_4: 3.23  loss_ce_5: 1.64  loss_mask_5: 3.131  loss_ce_6: 1.734  loss_mask_6: 3.064  loss_ce_7: 1.772  loss_mask_7: 3.03  loss_ce_8: 1.843  loss_mask_8: 3.27  time: 2.4439  data_time: 0.4076  lr: 7.1735e-05  max_mem: 18593M
[01/24 15:57:35] d2.utils.events INFO:  eta: 1 day, 4:33:12  iter: 18539  total_loss: 45.94  loss_ce: 1.772  loss_mask: 2.899  loss_ce_0: 1.168  loss_mask_0: 3.321  loss_ce_1: 1.091  loss_mask_1: 3.234  loss_ce_2: 1.197  loss_mask_2: 3.063  loss_ce_3: 1.248  loss_mask_3: 3.184  loss_ce_4: 1.396  loss_mask_4: 3.27  loss_ce_5: 1.642  loss_mask_5: 2.993  loss_ce_6: 1.756  loss_mask_6: 3.135  loss_ce_7: 1.832  loss_mask_7: 3.098  loss_ce_8: 1.823  loss_mask_8: 3.03  time: 2.4441  data_time: 0.4717  lr: 7.1703e-05  max_mem: 18593M
[01/24 15:58:22] d2.utils.events INFO:  eta: 1 day, 4:33:19  iter: 18559  total_loss: 51.83  loss_ce: 1.825  loss_mask: 3.131  loss_ce_0: 1.117  loss_mask_0: 3.929  loss_ce_1: 1.067  loss_mask_1: 3.798  loss_ce_2: 1.191  loss_mask_2: 3.597  loss_ce_3: 1.324  loss_mask_3: 3.57  loss_ce_4: 1.451  loss_mask_4: 3.57  loss_ce_5: 1.656  loss_mask_5: 3.309  loss_ce_6: 1.992  loss_mask_6: 3.982  loss_ce_7: 1.907  loss_mask_7: 3.506  loss_ce_8: 1.922  loss_mask_8: 3.459  time: 2.4440  data_time: 0.3855  lr: 7.1672e-05  max_mem: 18593M
[01/24 15:59:09] d2.utils.events INFO:  eta: 1 day, 4:31:33  iter: 18579  total_loss: 49.07  loss_ce: 1.842  loss_mask: 2.988  loss_ce_0: 1.26  loss_mask_0: 3.539  loss_ce_1: 1.119  loss_mask_1: 3.481  loss_ce_2: 1.188  loss_mask_2: 3.438  loss_ce_3: 1.32  loss_mask_3: 3.281  loss_ce_4: 1.441  loss_mask_4: 3.259  loss_ce_5: 1.722  loss_mask_5: 3.241  loss_ce_6: 1.874  loss_mask_6: 3.292  loss_ce_7: 1.877  loss_mask_7: 3.194  loss_ce_8: 1.952  loss_mask_8: 3.446  time: 2.4439  data_time: 0.3764  lr: 7.1641e-05  max_mem: 18593M
[01/24 16:00:02] d2.utils.events INFO:  eta: 1 day, 4:32:51  iter: 18599  total_loss: 49.56  loss_ce: 1.743  loss_mask: 3.022  loss_ce_0: 1.289  loss_mask_0: 3.705  loss_ce_1: 1.133  loss_mask_1: 3.563  loss_ce_2: 1.263  loss_mask_2: 3.569  loss_ce_3: 1.321  loss_mask_3: 3.437  loss_ce_4: 1.458  loss_mask_4: 3.345  loss_ce_5: 1.77  loss_mask_5: 3.422  loss_ce_6: 1.9  loss_mask_6: 3.443  loss_ce_7: 1.879  loss_mask_7: 3.169  loss_ce_8: 1.811  loss_mask_8: 3.239  time: 2.4441  data_time: 0.4586  lr: 7.161e-05  max_mem: 18593M
[01/24 16:00:50] d2.utils.events INFO:  eta: 1 day, 4:29:01  iter: 18619  total_loss: 48.01  loss_ce: 1.706  loss_mask: 2.988  loss_ce_0: 1.248  loss_mask_0: 3.75  loss_ce_1: 1.046  loss_mask_1: 3.427  loss_ce_2: 1.103  loss_mask_2: 3.319  loss_ce_3: 1.183  loss_mask_3: 3.325  loss_ce_4: 1.36  loss_mask_4: 3.04  loss_ce_5: 1.625  loss_mask_5: 3.103  loss_ce_6: 1.859  loss_mask_6: 3.391  loss_ce_7: 1.889  loss_mask_7: 3.162  loss_ce_8: 1.773  loss_mask_8: 3.049  time: 2.4440  data_time: 0.3969  lr: 7.1579e-05  max_mem: 18593M
[01/24 16:01:38] d2.utils.events INFO:  eta: 1 day, 4:28:11  iter: 18639  total_loss: 48.99  loss_ce: 1.722  loss_mask: 3.02  loss_ce_0: 1.257  loss_mask_0: 3.668  loss_ce_1: 1.064  loss_mask_1: 3.573  loss_ce_2: 1.117  loss_mask_2: 3.572  loss_ce_3: 1.227  loss_mask_3: 3.418  loss_ce_4: 1.308  loss_mask_4: 3.302  loss_ce_5: 1.674  loss_mask_5: 3.263  loss_ce_6: 1.93  loss_mask_6: 3.844  loss_ce_7: 1.835  loss_mask_7: 3.37  loss_ce_8: 1.784  loss_mask_8: 3.197  time: 2.4440  data_time: 0.4110  lr: 7.1548e-05  max_mem: 18593M
[01/24 16:02:27] d2.utils.events INFO:  eta: 1 day, 4:28:31  iter: 18659  total_loss: 50.03  loss_ce: 1.734  loss_mask: 3.172  loss_ce_0: 1.216  loss_mask_0: 3.732  loss_ce_1: 1.079  loss_mask_1: 3.498  loss_ce_2: 1.114  loss_mask_2: 3.301  loss_ce_3: 1.145  loss_mask_3: 3.317  loss_ce_4: 1.27  loss_mask_4: 3.265  loss_ce_5: 1.661  loss_mask_5: 3.493  loss_ce_6: 1.895  loss_mask_6: 3.849  loss_ce_7: 1.881  loss_mask_7: 3.796  loss_ce_8: 1.818  loss_mask_8: 3.495  time: 2.4440  data_time: 0.4131  lr: 7.1517e-05  max_mem: 18593M
[01/24 16:03:15] d2.utils.events INFO:  eta: 1 day, 4:24:11  iter: 18679  total_loss: 50.23  loss_ce: 1.778  loss_mask: 3.269  loss_ce_0: 1.25  loss_mask_0: 3.681  loss_ce_1: 1.059  loss_mask_1: 3.439  loss_ce_2: 1.092  loss_mask_2: 3.374  loss_ce_3: 1.153  loss_mask_3: 3.277  loss_ce_4: 1.306  loss_mask_4: 3.146  loss_ce_5: 1.66  loss_mask_5: 3.365  loss_ce_6: 1.877  loss_mask_6: 3.632  loss_ce_7: 1.953  loss_mask_7: 3.764  loss_ce_8: 1.943  loss_mask_8: 3.63  time: 2.4439  data_time: 0.3848  lr: 7.1485e-05  max_mem: 18593M
[01/24 16:04:05] d2.utils.events INFO:  eta: 1 day, 4:23:49  iter: 18699  total_loss: 50.64  loss_ce: 1.747  loss_mask: 3.335  loss_ce_0: 1.315  loss_mask_0: 3.777  loss_ce_1: 1.104  loss_mask_1: 3.654  loss_ce_2: 1.091  loss_mask_2: 3.601  loss_ce_3: 1.143  loss_mask_3: 3.35  loss_ce_4: 1.255  loss_mask_4: 3.32  loss_ce_5: 1.649  loss_mask_5: 3.553  loss_ce_6: 1.893  loss_mask_6: 3.748  loss_ce_7: 1.938  loss_mask_7: 3.849  loss_ce_8: 1.908  loss_mask_8: 3.463  time: 2.4440  data_time: 0.4176  lr: 7.1454e-05  max_mem: 18593M
[01/24 16:04:54] d2.utils.events INFO:  eta: 1 day, 4:23:38  iter: 18719  total_loss: 49.2  loss_ce: 1.829  loss_mask: 3.432  loss_ce_0: 1.364  loss_mask_0: 3.557  loss_ce_1: 1.151  loss_mask_1: 3.451  loss_ce_2: 1.132  loss_mask_2: 3.444  loss_ce_3: 1.175  loss_mask_3: 3.175  loss_ce_4: 1.269  loss_mask_4: 3.193  loss_ce_5: 1.562  loss_mask_5: 3.239  loss_ce_6: 1.859  loss_mask_6: 3.432  loss_ce_7: 1.914  loss_mask_7: 3.644  loss_ce_8: 1.864  loss_mask_8: 3.306  time: 2.4440  data_time: 0.4242  lr: 7.1423e-05  max_mem: 18593M
[01/24 16:05:42] d2.utils.events INFO:  eta: 1 day, 4:19:29  iter: 18739  total_loss: 49.97  loss_ce: 1.814  loss_mask: 3.488  loss_ce_0: 1.292  loss_mask_0: 3.813  loss_ce_1: 1.12  loss_mask_1: 3.566  loss_ce_2: 1.134  loss_mask_2: 3.392  loss_ce_3: 1.148  loss_mask_3: 3.287  loss_ce_4: 1.306  loss_mask_4: 3.199  loss_ce_5: 1.563  loss_mask_5: 3.196  loss_ce_6: 1.855  loss_mask_6: 3.577  loss_ce_7: 1.883  loss_mask_7: 3.673  loss_ce_8: 1.881  loss_mask_8: 3.601  time: 2.4440  data_time: 0.3827  lr: 7.1392e-05  max_mem: 18593M
[01/24 16:06:30] d2.utils.events INFO:  eta: 1 day, 4:16:22  iter: 18759  total_loss: 47.63  loss_ce: 1.777  loss_mask: 3.373  loss_ce_0: 1.312  loss_mask_0: 3.58  loss_ce_1: 1.117  loss_mask_1: 3.463  loss_ce_2: 1.122  loss_mask_2: 3.334  loss_ce_3: 1.186  loss_mask_3: 3.179  loss_ce_4: 1.323  loss_mask_4: 3.208  loss_ce_5: 1.603  loss_mask_5: 3.048  loss_ce_6: 1.82  loss_mask_6: 3.256  loss_ce_7: 1.863  loss_mask_7: 3.643  loss_ce_8: 1.838  loss_mask_8: 3.262  time: 2.4439  data_time: 0.3955  lr: 7.1361e-05  max_mem: 18593M
[01/24 16:07:16] d2.utils.events INFO:  eta: 1 day, 4:12:22  iter: 18779  total_loss: 48.26  loss_ce: 1.758  loss_mask: 3.163  loss_ce_0: 1.277  loss_mask_0: 3.548  loss_ce_1: 1.064  loss_mask_1: 3.535  loss_ce_2: 1.085  loss_mask_2: 3.363  loss_ce_3: 1.14  loss_mask_3: 3.182  loss_ce_4: 1.25  loss_mask_4: 3.266  loss_ce_5: 1.541  loss_mask_5: 3.046  loss_ce_6: 1.842  loss_mask_6: 3.488  loss_ce_7: 1.84  loss_mask_7: 3.616  loss_ce_8: 1.83  loss_mask_8: 3.232  time: 2.4437  data_time: 0.3863  lr: 7.133e-05  max_mem: 18593M
[01/24 16:08:03] d2.utils.events INFO:  eta: 1 day, 4:07:15  iter: 18799  total_loss: 47.06  loss_ce: 1.78  loss_mask: 3.033  loss_ce_0: 1.29  loss_mask_0: 3.427  loss_ce_1: 1.075  loss_mask_1: 3.368  loss_ce_2: 1.098  loss_mask_2: 3.431  loss_ce_3: 1.156  loss_mask_3: 3.129  loss_ce_4: 1.259  loss_mask_4: 3.108  loss_ce_5: 1.54  loss_mask_5: 3.126  loss_ce_6: 1.769  loss_mask_6: 3.135  loss_ce_7: 1.853  loss_mask_7: 3.424  loss_ce_8: 1.837  loss_mask_8: 3.389  time: 2.4436  data_time: 0.3848  lr: 7.1299e-05  max_mem: 18593M
[01/24 16:08:50] d2.utils.events INFO:  eta: 1 day, 4:04:40  iter: 18819  total_loss: 51.75  loss_ce: 1.87  loss_mask: 3.59  loss_ce_0: 1.267  loss_mask_0: 3.925  loss_ce_1: 1.111  loss_mask_1: 3.923  loss_ce_2: 1.095  loss_mask_2: 3.709  loss_ce_3: 1.176  loss_mask_3: 3.541  loss_ce_4: 1.321  loss_mask_4: 3.544  loss_ce_5: 1.501  loss_mask_5: 3.671  loss_ce_6: 1.84  loss_mask_6: 3.471  loss_ce_7: 1.867  loss_mask_7: 3.585  loss_ce_8: 1.934  loss_mask_8: 3.924  time: 2.4435  data_time: 0.4171  lr: 7.1267e-05  max_mem: 18593M
[01/24 16:09:36] d2.utils.events INFO:  eta: 1 day, 3:57:32  iter: 18839  total_loss: 50.47  loss_ce: 1.871  loss_mask: 3.688  loss_ce_0: 1.287  loss_mask_0: 3.725  loss_ce_1: 1.155  loss_mask_1: 3.891  loss_ce_2: 1.147  loss_mask_2: 3.72  loss_ce_3: 1.198  loss_mask_3: 3.451  loss_ce_4: 1.39  loss_mask_4: 3.543  loss_ce_5: 1.515  loss_mask_5: 3.269  loss_ce_6: 1.817  loss_mask_6: 3.366  loss_ce_7: 1.832  loss_mask_7: 3.303  loss_ce_8: 1.878  loss_mask_8: 3.467  time: 2.4434  data_time: 0.3972  lr: 7.1236e-05  max_mem: 18593M
[01/24 16:10:22] d2.utils.events INFO:  eta: 1 day, 3:52:50  iter: 18859  total_loss: 50.21  loss_ce: 1.869  loss_mask: 3.529  loss_ce_0: 1.301  loss_mask_0: 3.79  loss_ce_1: 1.139  loss_mask_1: 3.931  loss_ce_2: 1.131  loss_mask_2: 3.653  loss_ce_3: 1.143  loss_mask_3: 3.516  loss_ce_4: 1.316  loss_mask_4: 3.558  loss_ce_5: 1.494  loss_mask_5: 3.283  loss_ce_6: 1.777  loss_mask_6: 3.202  loss_ce_7: 1.827  loss_mask_7: 3.285  loss_ce_8: 1.862  loss_mask_8: 3.453  time: 2.4432  data_time: 0.3985  lr: 7.1205e-05  max_mem: 18593M
[01/24 16:11:09] d2.utils.events INFO:  eta: 1 day, 3:48:00  iter: 18879  total_loss: 47.54  loss_ce: 1.814  loss_mask: 3.462  loss_ce_0: 1.256  loss_mask_0: 3.469  loss_ce_1: 1.117  loss_mask_1: 3.511  loss_ce_2: 1.168  loss_mask_2: 3.336  loss_ce_3: 1.236  loss_mask_3: 3.308  loss_ce_4: 1.446  loss_mask_4: 3.258  loss_ce_5: 1.565  loss_mask_5: 3.164  loss_ce_6: 1.805  loss_mask_6: 3.258  loss_ce_7: 1.799  loss_mask_7: 3.26  loss_ce_8: 1.8  loss_mask_8: 3.243  time: 2.4432  data_time: 0.4255  lr: 7.1174e-05  max_mem: 18593M
[01/24 16:11:56] d2.utils.events INFO:  eta: 1 day, 3:42:39  iter: 18899  total_loss: 47.66  loss_ce: 1.755  loss_mask: 3.142  loss_ce_0: 1.229  loss_mask_0: 3.421  loss_ce_1: 1.082  loss_mask_1: 3.463  loss_ce_2: 1.143  loss_mask_2: 3.187  loss_ce_3: 1.239  loss_mask_3: 3.254  loss_ce_4: 1.428  loss_mask_4: 3.207  loss_ce_5: 1.54  loss_mask_5: 3.104  loss_ce_6: 1.837  loss_mask_6: 3.443  loss_ce_7: 1.782  loss_mask_7: 3.066  loss_ce_8: 1.802  loss_mask_8: 3.193  time: 2.4430  data_time: 0.3920  lr: 7.1143e-05  max_mem: 18593M
[01/24 16:12:43] d2.utils.events INFO:  eta: 1 day, 3:40:54  iter: 18919  total_loss: 46.03  loss_ce: 1.722  loss_mask: 3.175  loss_ce_0: 1.222  loss_mask_0: 3.434  loss_ce_1: 1.058  loss_mask_1: 3.366  loss_ce_2: 1.116  loss_mask_2: 3.099  loss_ce_3: 1.189  loss_mask_3: 3.033  loss_ce_4: 1.309  loss_mask_4: 2.98  loss_ce_5: 1.477  loss_mask_5: 2.922  loss_ce_6: 1.803  loss_mask_6: 3.089  loss_ce_7: 1.779  loss_mask_7: 3.062  loss_ce_8: 1.772  loss_mask_8: 3.066  time: 2.4429  data_time: 0.3857  lr: 7.1112e-05  max_mem: 18593M
[01/24 16:13:30] d2.utils.events INFO:  eta: 1 day, 3:39:40  iter: 18939  total_loss: 48.33  loss_ce: 1.748  loss_mask: 3.489  loss_ce_0: 1.198  loss_mask_0: 3.684  loss_ce_1: 1.034  loss_mask_1: 3.67  loss_ce_2: 1.096  loss_mask_2: 3.485  loss_ce_3: 1.181  loss_mask_3: 3.359  loss_ce_4: 1.292  loss_mask_4: 3.257  loss_ce_5: 1.482  loss_mask_5: 3.245  loss_ce_6: 1.819  loss_mask_6: 3.391  loss_ce_7: 1.751  loss_mask_7: 3.296  loss_ce_8: 1.773  loss_mask_8: 3.336  time: 2.4428  data_time: 0.3935  lr: 7.108e-05  max_mem: 18593M
[01/24 16:14:17] d2.utils.events INFO:  eta: 1 day, 3:33:51  iter: 18959  total_loss: 47.2  loss_ce: 1.729  loss_mask: 3.187  loss_ce_0: 1.283  loss_mask_0: 3.532  loss_ce_1: 1.009  loss_mask_1: 3.745  loss_ce_2: 1.076  loss_mask_2: 3.302  loss_ce_3: 1.143  loss_mask_3: 3.231  loss_ce_4: 1.265  loss_mask_4: 3.19  loss_ce_5: 1.434  loss_mask_5: 3.097  loss_ce_6: 1.771  loss_mask_6: 3.19  loss_ce_7: 1.737  loss_mask_7: 3.002  loss_ce_8: 1.775  loss_mask_8: 3.16  time: 2.4427  data_time: 0.3956  lr: 7.1049e-05  max_mem: 18593M
[01/24 16:15:06] d2.utils.events INFO:  eta: 1 day, 3:35:09  iter: 18979  total_loss: 47.32  loss_ce: 1.735  loss_mask: 3.175  loss_ce_0: 1.347  loss_mask_0: 3.551  loss_ce_1: 1.024  loss_mask_1: 3.519  loss_ce_2: 1.091  loss_mask_2: 3.258  loss_ce_3: 1.176  loss_mask_3: 3.218  loss_ce_4: 1.348  loss_mask_4: 3.288  loss_ce_5: 1.653  loss_mask_5: 3.299  loss_ce_6: 1.826  loss_mask_6: 3.367  loss_ce_7: 1.724  loss_mask_7: 3.083  loss_ce_8: 1.75  loss_mask_8: 3.171  time: 2.4428  data_time: 0.4091  lr: 7.1018e-05  max_mem: 18593M
[01/24 16:16:01] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 16:16:02] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 16:16:02] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 16:21:03] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 12.150617796167554, 'error_1pix': 0.9150716846705994, 'error_3pix': 0.8075646313372005, 'mIoU': 0.317061897616201, 'fwIoU': 0.5377207761524099, 'IoU-0': nan, 'IoU-1': 0.8349318664568849, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 2.6327041352714165e-05, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.009587201865783924, 'IoU-17': 0.008116737775343783, 'IoU-18': 0.03530091579890078, 'IoU-19': 0.0, 'IoU-20': 0.5996698190634507, 'IoU-21': 0.0, 'IoU-22': 0.07078983860103914, 'IoU-23': 0.2572621833856919, 'IoU-24': 0.31167782102845815, 'IoU-25': 0.03217040924032432, 'IoU-26': 0.0, 'IoU-27': 0.44154775891351594, 'IoU-28': 1.1502830082574573, 'IoU-29': 0.00011021173556064978, 'IoU-30': 1.4583195319635995, 'IoU-31': 2.3440045277251906, 'IoU-32': 2.4200416885773803, 'IoU-33': 0.15944589058016562, 'IoU-34': 0.0011187870576642408, 'IoU-35': 0.00010256879386028745, 'IoU-36': 0.0002460850937645729, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0005963446210887098, 'IoU-40': 4.665637289686656, 'IoU-41': 0.027507635423649757, 'IoU-42': 0.0034956781589145884, 'IoU-43': 1.7459587821298428, 'IoU-44': 0.0035496930911020855, 'IoU-45': 0.2518898184183001, 'IoU-46': 8.641505182310658e-05, 'IoU-47': 0.0016839147752493373, 'IoU-48': 0.08958527577899372, 'IoU-49': 5.071333239268238, 'IoU-50': 0.10905736704809857, 'IoU-51': 0.003345448444554843, 'IoU-52': 1.275502385431475, 'IoU-53': 0.04228355442529981, 'IoU-54': 0.019012400148616014, 'IoU-55': 2.232122577565328, 'IoU-56': 0.0025603391896698, 'IoU-57': 0.00047912355094261735, 'IoU-58': 3.9131765774520857, 'IoU-59': 0.0007517436545206477, 'IoU-60': 2.726220859777192, 'IoU-61': 0.012472684778703516, 'IoU-62': 0.33746623206538, 'IoU-63': 0.25630280446523884, 'IoU-64': 0.17647268754571718, 'IoU-65': 1.8275605467468738, 'IoU-66': 0.13765925386073613, 'IoU-67': 0.7984138886932489, 'IoU-68': 0.12341000512819882, 'IoU-69': 0.026747968916544997, 'IoU-70': 0.43854347065166693, 'IoU-71': 0.7449490976292922, 'IoU-72': 0.00017812920691087883, 'IoU-73': 0.0, 'IoU-74': 2.025588019739129, 'IoU-75': 1.4533761894386383, 'IoU-76': 0.0015661841373272583, 'IoU-77': 0.8415059940603881, 'IoU-78': 0.9956146243149144, 'IoU-79': 0.0003007129570085164, 'IoU-80': 0.5881160890153064, 'IoU-81': 0.00042089038474808435, 'IoU-82': 0.016490903976201707, 'IoU-83': 0.06923224700325863, 'IoU-84': 0.6780086749150678, 'IoU-85': 1.7044457267259876, 'IoU-86': 0.0017168012086280508, 'IoU-87': 2.4276423806482543, 'IoU-88': 0.3505339290653719, 'IoU-89': 1.7350440761571735, 'IoU-90': 0.0, 'IoU-91': 0.0013052391483640868, 'IoU-92': 0.01371940181714324, 'IoU-93': 0.00331041009213092, 'IoU-94': 0.005810870576133404, 'IoU-95': 3.0866596220642553, 'IoU-96': 0.10891373899319522, 'IoU-97': 0.006107397568339659, 'IoU-98': 0.11954551116629093, 'IoU-99': 1.0169291796751052, 'IoU-100': 0.0007291787563491721, 'IoU-101': 0.004873068375804163, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.012847530106508296, 'IoU-106': 0.06694353912404671, 'IoU-107': 0.0010873515731122964, 'IoU-108': 0.016682878584509377, 'IoU-109': 0.03636126163096786, 'IoU-110': 0.22417560309900023, 'IoU-111': 0.001521473581319037, 'IoU-112': 0.8155901915026038, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.015543871081524614, 'IoU-116': 0.0, 'IoU-117': 0.04519918274594574, 'IoU-118': 0.02308818469249297, 'IoU-119': 0.013371043551814248, 'IoU-120': 0.0050881047742535115, 'IoU-121': 0.0007257647859833046, 'IoU-122': 1.2705267664784146, 'IoU-123': 0.0, 'IoU-124': 0.036958188376802474, 'IoU-125': 0.0339297598677795, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 6.269395943700824e-05, 'IoU-130': 0.005813362012585929, 'IoU-131': 0.011742196169043265, 'IoU-132': 0.0, 'IoU-133': 0.34275579814274015, 'IoU-134': 0.004824241337089447, 'IoU-135': 0.0004273330783579299, 'IoU-136': 0.0, 'IoU-137': 0.25381182811951364, 'IoU-138': 0.0024544229493296257, 'IoU-139': 0.0, 'IoU-140': 0.0016469756996970388, 'IoU-141': 0.030257586304391317, 'IoU-142': 0.0, 'IoU-143': 0.0012574842769555229, 'IoU-144': 0.0, 'IoU-145': 1.1118414358199284, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.10677102110036377, 'IoU-150': 0.002492825337076726, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0029827630710987465, 'IoU-155': 0.0006141887426573735, 'IoU-156': 0.001267851346965271, 'IoU-157': 0.0, 'IoU-158': 0.026045459128233278, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.004728439792185071, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0017334777898158182, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.08454149728387955, 'IoU-176': 0.0, 'IoU-177': 0.8003740660230917, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 1.3161159809956817, 'IoU-182': 0.0, 'IoU-183': 0.00046914217353569, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 2.229599534636519, 'pACC': 2.8845841301204804, 'ACC-0': nan, 'ACC-1': 0.906231290797779, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 2.6328981145998878e-05, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.011225811771975718, 'ACC-17': 0.009888512027402804, 'ACC-18': 0.23451699667693965, 'ACC-19': 0.0, 'ACC-20': 0.7403032021393579, 'ACC-21': 0.0, 'ACC-22': 0.07163660287901397, 'ACC-23': 0.27162638975433473, 'ACC-24': 1.0119896753399478, 'ACC-25': 0.03263066521220265, 'ACC-26': 0.0, 'ACC-27': 0.5235445324969613, 'ACC-28': 2.4814576501320023, 'ACC-29': 0.00011022030996854527, 'ACC-30': 2.245447251561836, 'ACC-31': 4.803399201328081, 'ACC-32': 38.694437296882086, 'ACC-33': 0.1733215572785956, 'ACC-34': 0.0011201986385756557, 'ACC-35': 0.00010258033058757208, 'ACC-36': 0.0002466238293862925, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0005973154504021493, 'ACC-40': 33.854658823577644, 'ACC-41': 0.027650659950416403, 'ACC-42': 0.0034997692803615324, 'ACC-43': 11.34884354584558, 'ACC-44': 0.0035564264338851723, 'ACC-45': 0.2956547806245085, 'ACC-46': 8.641957526836364e-05, 'ACC-47': 0.0016912298994450933, 'ACC-48': 0.09137338614532783, 'ACC-49': 67.91160447857251, 'ACC-50': 0.1133366632002269, 'ACC-51': 0.0033484688145937734, 'ACC-52': 1.468067404315097, 'ACC-53': 0.042510780743791735, 'ACC-54': 0.0190792315786266, 'ACC-55': 3.3147313331745103, 'ACC-56': 0.002562036568590042, 'ACC-57': 0.00047944657870160944, 'ACC-58': 12.281600391436822, 'ACC-59': 0.0007519814711765502, 'ACC-60': 9.774343264604127, 'ACC-61': 0.012503873028761912, 'ACC-62': 0.4162656332915768, 'ACC-63': 0.2978324899987752, 'ACC-64': 0.186675508973899, 'ACC-65': 8.085318318976283, 'ACC-66': 0.15197068230124638, 'ACC-67': 0.9175488383519799, 'ACC-68': 0.14062141158396385, 'ACC-69': 0.02741223714889855, 'ACC-70': 0.558604609983907, 'ACC-71': 0.9422864568029121, 'ACC-72': 0.0001781821324303063, 'ACC-73': 0.0, 'ACC-74': 2.9513238529470813, 'ACC-75': 2.7468416219031844, 'ACC-76': 0.0015674253428954751, 'ACC-77': 1.1050601276455738, 'ACC-78': 6.188155437285773, 'ACC-79': 0.00030073067529741426, 'ACC-80': 1.6896394662482912, 'ACC-81': 0.00042104470054303686, 'ACC-82': 0.01675296676026876, 'ACC-83': 0.07014963363149061, 'ACC-84': 1.262536416811453, 'ACC-85': 3.220785058184776, 'ACC-86': 0.0017194488040047742, 'ACC-87': 28.923490905745293, 'ACC-88': 0.422236259757183, 'ACC-89': 9.25449736419178, 'ACC-90': 0.0, 'ACC-91': 0.0013063353727587163, 'ACC-92': 0.01382174134317464, 'ACC-93': 0.0033147164127520236, 'ACC-94': 0.005823486623314382, 'ACC-95': 38.82257947738054, 'ACC-96': 0.12315006372328856, 'ACC-97': 0.006163508638927796, 'ACC-98': 0.1259568396080372, 'ACC-99': 1.873852115886446, 'ACC-100': 0.0007298399947451521, 'ACC-101': 0.004879025948680385, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.012999447587325514, 'ACC-106': 0.06920084950008351, 'ACC-107': 0.0010878599184540206, 'ACC-108': 0.01696869938235592, 'ACC-109': 0.03835670030319653, 'ACC-110': 0.26036013223054894, 'ACC-111': 0.0015356260543718178, 'ACC-112': 1.138575639339383, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.015636041074677132, 'ACC-116': 0.0, 'ACC-117': 0.049504672003420326, 'ACC-118': 0.023890528476124377, 'ACC-119': 0.013810632213857211, 'ACC-120': 0.00527098114042948, 'ACC-121': 0.0007267352735045491, 'ACC-122': 76.25600309471916, 'ACC-123': 0.0, 'ACC-124': 0.03867666151155425, 'ACC-125': 0.03671020043225581, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 6.275261850988887e-05, 'ACC-130': 0.005933294293976674, 'ACC-131': 0.011962414094913781, 'ACC-132': 0.0, 'ACC-133': 0.9659991698816742, 'ACC-134': 0.004894442050840155, 'ACC-135': 0.0004275696938600992, 'ACC-136': 0.0, 'ACC-137': 0.33322724403667486, 'ACC-138': 0.0024589435743838364, 'ACC-139': 0.0, 'ACC-140': 0.001656487550667813, 'ACC-141': 0.03080087319633958, 'ACC-142': 0.0, 'ACC-143': 0.0012580277898338774, 'ACC-144': 0.0, 'ACC-145': 7.124935709653616, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.10962721675663671, 'ACC-150': 0.0025015400105690066, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0030528363785376207, 'ACC-155': 0.0006162750854773544, 'ACC-156': 0.0012927663260227397, 'ACC-157': 0.0, 'ACC-158': 0.026250756826255273, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.004760473786153567, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0017371153809407174, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.08689559032611731, 'ACC-176': 0.0, 'ACC-177': 4.040275417121112, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 33.99513478815958, 'ACC-182': 0.0, 'ACC-183': 0.0004708641062646115, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 16:21:03] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 16:21:03] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 16:21:03] d2.evaluation.testing INFO: copypaste: 12.1506,0.9151,0.8076,0.3171,0.5377,2.2296,2.8846
[01/24 16:21:03] d2.utils.events INFO:  eta: 1 day, 3:38:59  iter: 18999  total_loss: 47.97  loss_ce: 1.78  loss_mask: 3.375  loss_ce_0: 1.206  loss_mask_0: 3.808  loss_ce_1: 1.031  loss_mask_1: 3.697  loss_ce_2: 1.081  loss_mask_2: 3.381  loss_ce_3: 1.173  loss_mask_3: 3.251  loss_ce_4: 1.26  loss_mask_4: 3.326  loss_ce_5: 1.452  loss_mask_5: 3.284  loss_ce_6: 1.737  loss_mask_6: 3.296  loss_ce_7: 1.729  loss_mask_7: 3.136  loss_ce_8: 1.742  loss_mask_8: 3.264  time: 2.4431  data_time: 0.5033  lr: 7.0987e-05  max_mem: 18593M
[01/24 16:21:59] d2.utils.events INFO:  eta: 1 day, 3:40:12  iter: 19019  total_loss: 45.35  loss_ce: 1.726  loss_mask: 3.142  loss_ce_0: 1.212  loss_mask_0: 3.486  loss_ce_1: 1.03  loss_mask_1: 3.484  loss_ce_2: 1.066  loss_mask_2: 3.25  loss_ce_3: 1.135  loss_mask_3: 3.108  loss_ce_4: 1.269  loss_mask_4: 3.092  loss_ce_5: 1.48  loss_mask_5: 3.018  loss_ce_6: 1.74  loss_mask_6: 2.886  loss_ce_7: 1.72  loss_mask_7: 2.936  loss_ce_8: 1.723  loss_mask_8: 2.969  time: 2.4435  data_time: 0.5111  lr: 7.0956e-05  max_mem: 18593M
[01/24 16:22:48] d2.utils.events INFO:  eta: 1 day, 3:39:23  iter: 19039  total_loss: 45.03  loss_ce: 1.701  loss_mask: 2.986  loss_ce_0: 1.191  loss_mask_0: 3.497  loss_ce_1: 1.025  loss_mask_1: 3.313  loss_ce_2: 1.06  loss_mask_2: 3.062  loss_ce_3: 1.116  loss_mask_3: 3.057  loss_ce_4: 1.226  loss_mask_4: 3.058  loss_ce_5: 1.446  loss_mask_5: 2.871  loss_ce_6: 1.721  loss_mask_6: 3.046  loss_ce_7: 1.702  loss_mask_7: 2.837  loss_ce_8: 1.68  loss_mask_8: 2.859  time: 2.4435  data_time: 0.3868  lr: 7.0925e-05  max_mem: 18593M
[01/24 16:23:37] d2.utils.events INFO:  eta: 1 day, 3:38:34  iter: 19059  total_loss: 47.8  loss_ce: 1.753  loss_mask: 3.33  loss_ce_0: 1.209  loss_mask_0: 3.674  loss_ce_1: 1.019  loss_mask_1: 3.658  loss_ce_2: 1.066  loss_mask_2: 3.504  loss_ce_3: 1.127  loss_mask_3: 3.341  loss_ce_4: 1.283  loss_mask_4: 3.301  loss_ce_5: 1.457  loss_mask_5: 3.188  loss_ce_6: 1.727  loss_mask_6: 3.321  loss_ce_7: 1.723  loss_mask_7: 3.242  loss_ce_8: 1.71  loss_mask_8: 3.241  time: 2.4435  data_time: 0.4243  lr: 7.0894e-05  max_mem: 18593M
[01/24 16:24:27] d2.utils.events INFO:  eta: 1 day, 3:36:59  iter: 19079  total_loss: 46.37  loss_ce: 1.779  loss_mask: 3.389  loss_ce_0: 1.221  loss_mask_0: 3.502  loss_ce_1: 1.026  loss_mask_1: 3.497  loss_ce_2: 1.051  loss_mask_2: 3.197  loss_ce_3: 1.134  loss_mask_3: 3.204  loss_ce_4: 1.282  loss_mask_4: 3.172  loss_ce_5: 1.47  loss_mask_5: 3.052  loss_ce_6: 1.708  loss_mask_6: 3.237  loss_ce_7: 1.685  loss_mask_7: 3.094  loss_ce_8: 1.693  loss_mask_8: 3.106  time: 2.4435  data_time: 0.4657  lr: 7.0862e-05  max_mem: 18593M
[01/24 16:25:15] d2.utils.events INFO:  eta: 1 day, 3:36:37  iter: 19099  total_loss: 49.31  loss_ce: 1.741  loss_mask: 3.314  loss_ce_0: 1.301  loss_mask_0: 3.765  loss_ce_1: 1.055  loss_mask_1: 3.702  loss_ce_2: 1.075  loss_mask_2: 3.55  loss_ce_3: 1.105  loss_mask_3: 3.484  loss_ce_4: 1.235  loss_mask_4: 3.529  loss_ce_5: 1.496  loss_mask_5: 3.365  loss_ce_6: 1.754  loss_mask_6: 3.409  loss_ce_7: 1.746  loss_mask_7: 3.333  loss_ce_8: 1.782  loss_mask_8: 3.354  time: 2.4435  data_time: 0.3797  lr: 7.0831e-05  max_mem: 18593M
[01/24 16:26:05] d2.utils.events INFO:  eta: 1 day, 3:37:47  iter: 19119  total_loss: 47.48  loss_ce: 1.691  loss_mask: 3.154  loss_ce_0: 1.279  loss_mask_0: 3.719  loss_ce_1: 1.106  loss_mask_1: 3.541  loss_ce_2: 1.178  loss_mask_2: 3.345  loss_ce_3: 1.208  loss_mask_3: 3.342  loss_ce_4: 1.336  loss_mask_4: 3.267  loss_ce_5: 1.475  loss_mask_5: 3.17  loss_ce_6: 1.703  loss_mask_6: 3.173  loss_ce_7: 1.719  loss_mask_7: 3.096  loss_ce_8: 1.716  loss_mask_8: 3.089  time: 2.4436  data_time: 0.4061  lr: 7.08e-05  max_mem: 18593M
[01/24 16:26:23] d2.engine.hooks INFO: Overall training speed: 19124 iterations in 12:58:53 (2.4437 s / it)
[01/24 16:26:23] d2.engine.hooks INFO: Total training time: 15:35:35 (2:36:41 on hooks)
[01/24 16:26:23] d2.utils.events INFO:  eta: 1 day, 3:37:46  iter: 19126  total_loss: 47.4  loss_ce: 1.698  loss_mask: 3.154  loss_ce_0: 1.242  loss_mask_0: 3.746  loss_ce_1: 1.06  loss_mask_1: 3.441  loss_ce_2: 1.122  loss_mask_2: 3.345  loss_ce_3: 1.168  loss_mask_3: 3.277  loss_ce_4: 1.287  loss_mask_4: 3.158  loss_ce_5: 1.454  loss_mask_5: 3.151  loss_ce_6: 1.706  loss_mask_6: 3.172  loss_ce_7: 1.719  loss_mask_7: 3.097  loss_ce_8: 1.704  loss_mask_8: 3.089  time: 2.4436  data_time: 0.4544  lr: 7.0791e-05  max_mem: 18593M
