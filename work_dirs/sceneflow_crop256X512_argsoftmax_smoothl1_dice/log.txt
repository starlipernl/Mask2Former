[01/24 13:07:41] detectron2 INFO: Rank of current process: 0. World size: 2
[01/24 13:07:44] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/24 13:07:44] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '32', 'OUTPUT_DIR', './work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_dice'], resume=False)
[01/24 13:07:44] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/24 13:07:44] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_dice[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/24 13:07:44] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_dice/config.yaml
[01/24 13:07:44] d2.utils.env INFO: Using a generated random seed 44623875
[01/24 13:07:46] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 0.5
          cost_mask: 1.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 0.5, 'loss_mask': 1.0, 'loss_dice': 0.5, 'loss_ce_0': 0.5, 'loss_mask_0': 1.0, 'loss_dice_0': 0.5, 'loss_ce_1': 0.5, 'loss_mask_1': 1.0, 'loss_dice_1': 0.5, 'loss_ce_2': 0.5, 'loss_mask_2': 1.0, 'loss_dice_2': 0.5, 'loss_ce_3': 0.5, 'loss_mask_3': 1.0, 'loss_dice_3': 0.5, 'loss_ce_4': 0.5, 'loss_mask_4': 1.0, 'loss_dice_4': 0.5, 'loss_ce_5': 0.5, 'loss_mask_5': 1.0, 'loss_dice_5': 0.5, 'loss_ce_6': 0.5, 'loss_mask_6': 1.0, 'loss_dice_6': 0.5, 'loss_ce_7': 0.5, 'loss_mask_7': 1.0, 'loss_dice_7': 0.5, 'loss_ce_8': 0.5, 'loss_mask_8': 1.0, 'loss_dice_8': 0.5}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/24 13:07:46] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/24 13:07:53] d2.data.build INFO: Using training sampler TrainingSampler
[01/24 13:07:53] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/24 13:07:53] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/24 13:07:53] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/24 13:07:53] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/24 13:07:53] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/24 13:07:53] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/24 13:07:53] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/24 13:07:53] d2.engine.train_loop INFO: Starting training from iteration 0
[01/24 13:08:12] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 395, in run_step
    loss_dict = self.model(data)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 799, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 353, in forward
    losses = self.criterion(outputs, targets)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/modeling/criterion.py", line 259, in forward
    losses.update(self.get_loss(loss, outputs, targets, indices, num_masks))
  File "/home/nstarli/Mask2Former/mask2former/modeling/criterion.py", line 233, in get_loss
    return loss_map[loss](outputs, targets, indices, num_masks)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 93, in loss_masks
    target_masks_disp, valid = nested_tensor_from_tensor_list(target_masks).decompose()
  File "/home/nstarli/Mask2Former/mask2former/utils/misc.py", line 69, in nested_tensor_from_tensor_list
    raise ValueError("not supported")
ValueError: not supported
[01/24 13:08:12] d2.engine.hooks INFO: Total training time: 0:00:18 (0:00:00 on hooks)
[01/24 13:08:12] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 16604M
[01/24 13:10:47] detectron2 INFO: Rank of current process: 0. World size: 2
[01/24 13:10:50] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/24 13:10:50] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '32', 'OUTPUT_DIR', './work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_dice'], resume=False)
[01/24 13:10:50] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/24 13:10:50] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_dice[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/24 13:10:50] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_dice/config.yaml
[01/24 13:10:50] d2.utils.env INFO: Using a generated random seed 50730003
[01/24 13:10:51] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 0.5
          cost_mask: 1.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 0.5, 'loss_mask': 1.0, 'loss_dice': 0.5, 'loss_ce_0': 0.5, 'loss_mask_0': 1.0, 'loss_dice_0': 0.5, 'loss_ce_1': 0.5, 'loss_mask_1': 1.0, 'loss_dice_1': 0.5, 'loss_ce_2': 0.5, 'loss_mask_2': 1.0, 'loss_dice_2': 0.5, 'loss_ce_3': 0.5, 'loss_mask_3': 1.0, 'loss_dice_3': 0.5, 'loss_ce_4': 0.5, 'loss_mask_4': 1.0, 'loss_dice_4': 0.5, 'loss_ce_5': 0.5, 'loss_mask_5': 1.0, 'loss_dice_5': 0.5, 'loss_ce_6': 0.5, 'loss_mask_6': 1.0, 'loss_dice_6': 0.5, 'loss_ce_7': 0.5, 'loss_mask_7': 1.0, 'loss_dice_7': 0.5, 'loss_ce_8': 0.5, 'loss_mask_8': 1.0, 'loss_dice_8': 0.5}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/24 13:10:51] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/24 13:10:56] d2.data.build INFO: Using training sampler TrainingSampler
[01/24 13:10:56] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/24 13:10:57] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/24 13:10:57] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/24 13:10:57] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/24 13:10:57] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/24 13:10:57] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/24 13:10:57] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/24 13:10:57] d2.engine.train_loop INFO: Starting training from iteration 0
[01/24 13:11:14] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 395, in run_step
    loss_dict = self.model(data)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 799, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 353, in forward
    losses = self.criterion(outputs, targets)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/modeling/criterion.py", line 259, in forward
    losses.update(self.get_loss(loss, outputs, targets, indices, num_masks))
  File "/home/nstarli/Mask2Former/mask2former/modeling/criterion.py", line 233, in get_loss
    return loss_map[loss](outputs, targets, indices, num_masks)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 110, in loss_masks
    point_coords = get_uncertain_point_coords_with_randomness(
  File "/home/nstarli/detectron2/projects/PointRend/point_rend/point_features.py", line 91, in get_uncertain_point_coords_with_randomness
    point_logits = point_sample(coarse_logits, point_coords, align_corners=False)
  File "/home/nstarli/detectron2/projects/PointRend/point_rend/point_features.py", line 39, in point_sample
    output = F.grid_sample(input, 2.0 * point_coords - 1.0, **kwargs)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/functional.py", line 3989, in grid_sample
    return torch.grid_sampler(input, grid, mode_enum, padding_mode_enum, align_corners)
RuntimeError: grid_sampler(): expected 4D or 5D input and grid with same number of dimensions, but got input with sizes [1010, 64, 128] and grid with sizes [1010, 37632, 1, 2]
[01/24 13:11:14] d2.engine.hooks INFO: Total training time: 0:00:17 (0:00:00 on hooks)
[01/24 13:11:14] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 16884M
[01/24 13:15:45] detectron2 INFO: Rank of current process: 0. World size: 2
[01/24 13:15:48] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/24 13:15:48] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '32', 'OUTPUT_DIR', './work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_dice'], resume=False)
[01/24 13:15:48] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/24 13:15:48] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_dice[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/24 13:15:48] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_dice/config.yaml
[01/24 13:15:48] d2.utils.env INFO: Using a generated random seed 48912002
[01/24 13:15:50] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 0.5
          cost_mask: 1.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 0.5, 'loss_mask': 1.0, 'loss_dice': 0.5, 'loss_ce_0': 0.5, 'loss_mask_0': 1.0, 'loss_dice_0': 0.5, 'loss_ce_1': 0.5, 'loss_mask_1': 1.0, 'loss_dice_1': 0.5, 'loss_ce_2': 0.5, 'loss_mask_2': 1.0, 'loss_dice_2': 0.5, 'loss_ce_3': 0.5, 'loss_mask_3': 1.0, 'loss_dice_3': 0.5, 'loss_ce_4': 0.5, 'loss_mask_4': 1.0, 'loss_dice_4': 0.5, 'loss_ce_5': 0.5, 'loss_mask_5': 1.0, 'loss_dice_5': 0.5, 'loss_ce_6': 0.5, 'loss_mask_6': 1.0, 'loss_dice_6': 0.5, 'loss_ce_7': 0.5, 'loss_mask_7': 1.0, 'loss_dice_7': 0.5, 'loss_ce_8': 0.5, 'loss_mask_8': 1.0, 'loss_dice_8': 0.5}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/24 13:15:50] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/24 13:15:56] d2.data.build INFO: Using training sampler TrainingSampler
[01/24 13:15:56] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/24 13:15:56] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/24 13:15:56] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/24 13:15:56] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/24 13:15:56] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/24 13:15:56] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/24 13:15:56] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/24 13:15:56] d2.engine.train_loop INFO: Starting training from iteration 0
[01/24 13:16:14] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 395, in run_step
    loss_dict = self.model(data)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 799, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 355, in forward
    losses = self.criterion(outputs, targets)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/modeling/criterion.py", line 259, in forward
    losses.update(self.get_loss(loss, outputs, targets, indices, num_masks))
  File "/home/nstarli/Mask2Former/mask2former/modeling/criterion.py", line 233, in get_loss
    return loss_map[loss](outputs, targets, indices, num_masks)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 133, in loss_masks
    "loss_mask": smooth_l1_loss(src_masks[valid_mask], target_masks[valid_mask], num_masks),
IndexError: The shape of the mask [16, 131072] at index 0 does not match the shape of the indexed tensor [920, 1, 64, 128] at index 0
[01/24 13:16:14] d2.engine.hooks INFO: Total training time: 0:00:18 (0:00:00 on hooks)
[01/24 13:16:14] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 16733M
[01/24 13:17:18] detectron2 INFO: Rank of current process: 0. World size: 2
[01/24 13:17:22] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1                 Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/24 13:17:22] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '32', 'OUTPUT_DIR', './work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_dice'], resume=False)
[01/24 13:17:22] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/24 13:17:22] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_dice[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/24 13:17:22] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop256X512_argsoftmax_smoothl1_dice/config.yaml
[01/24 13:17:22] d2.utils.env INFO: Using a generated random seed 22501641
[01/24 13:17:23] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 0.5
          cost_mask: 1.0
          cost_dice: 0.5
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 0.5, 'loss_mask': 1.0, 'loss_dice': 0.5, 'loss_ce_0': 0.5, 'loss_mask_0': 1.0, 'loss_dice_0': 0.5, 'loss_ce_1': 0.5, 'loss_mask_1': 1.0, 'loss_dice_1': 0.5, 'loss_ce_2': 0.5, 'loss_mask_2': 1.0, 'loss_dice_2': 0.5, 'loss_ce_3': 0.5, 'loss_mask_3': 1.0, 'loss_dice_3': 0.5, 'loss_ce_4': 0.5, 'loss_mask_4': 1.0, 'loss_dice_4': 0.5, 'loss_ce_5': 0.5, 'loss_mask_5': 1.0, 'loss_dice_5': 0.5, 'loss_ce_6': 0.5, 'loss_mask_6': 1.0, 'loss_dice_6': 0.5, 'loss_ce_7': 0.5, 'loss_mask_7': 1.0, 'loss_dice_7': 0.5, 'loss_ce_8': 0.5, 'loss_mask_8': 1.0, 'loss_dice_8': 0.5}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/24 13:17:23] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/24 13:17:28] d2.data.build INFO: Using training sampler TrainingSampler
[01/24 13:17:29] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/24 13:17:29] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/24 13:17:29] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/24 13:17:30] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/24 13:17:30] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/24 13:17:30] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/24 13:17:30] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/24 13:17:30] d2.engine.train_loop INFO: Starting training from iteration 0
[01/24 13:18:56] d2.utils.events INFO:  eta: 2 days, 5:09:45  iter: 19  total_loss: 275.7  loss_ce: 2.622  loss_mask: 24.96  loss_dice: 0.4871  loss_ce_0: 2.369  loss_mask_0: 23.56  loss_dice_0: 0.4843  loss_ce_1: 2.565  loss_mask_1: 23.86  loss_dice_1: 0.4852  loss_ce_2: 2.545  loss_mask_2: 24.12  loss_dice_2: 0.4843  loss_ce_3: 2.547  loss_mask_3: 24.43  loss_dice_3: 0.4868  loss_ce_4: 2.546  loss_mask_4: 24.6  loss_dice_4: 0.4863  loss_ce_5: 2.753  loss_mask_5: 24.7  loss_dice_5: 0.4869  loss_ce_6: 2.732  loss_mask_6: 24.84  loss_dice_6: 0.4872  loss_ce_7: 2.766  loss_mask_7: 24.9  loss_dice_7: 0.4872  loss_ce_8: 2.619  loss_mask_8: 24.92  loss_dice_8: 0.4871  time: 3.2072  data_time: 0.7827  lr: 2.8802e-06  max_mem: 21877M
[01/24 13:19:51] d2.utils.events INFO:  eta: 2 days, 0:49:08  iter: 39  total_loss: 292.3  loss_ce: 2.502  loss_mask: 26.83  loss_dice: 0.4871  loss_ce_0: 2.371  loss_mask_0: 25.2  loss_dice_0: 0.4828  loss_ce_1: 2.546  loss_mask_1: 25.43  loss_dice_1: 0.4836  loss_ce_2: 2.477  loss_mask_2: 25.69  loss_dice_2: 0.4833  loss_ce_3: 2.457  loss_mask_3: 26.11  loss_dice_3: 0.4864  loss_ce_4: 2.433  loss_mask_4: 26.31  loss_dice_4: 0.4855  loss_ce_5: 2.588  loss_mask_5: 26.44  loss_dice_5: 0.4864  loss_ce_6: 2.598  loss_mask_6: 26.63  loss_dice_6: 0.487  loss_ce_7: 2.644  loss_mask_7: 26.75  loss_dice_7: 0.4872  loss_ce_8: 2.507  loss_mask_8: 26.79  loss_dice_8: 0.4871  time: 2.9552  data_time: 0.3485  lr: 4.8582e-06  max_mem: 21877M
[01/24 13:20:50] d2.utils.events INFO:  eta: 2 days, 1:10:44  iter: 59  total_loss: 272.6  loss_ce: 2.382  loss_mask: 25.61  loss_dice: 0.4878  loss_ce_0: 2.371  loss_mask_0: 23.23  loss_dice_0: 0.4821  loss_ce_1: 2.504  loss_mask_1: 22.97  loss_dice_1: 0.4828  loss_ce_2: 2.409  loss_mask_2: 23.19  loss_dice_2: 0.4832  loss_ce_3: 2.364  loss_mask_3: 23.9  loss_dice_3: 0.4864  loss_ce_4: 2.338  loss_mask_4: 24.2  loss_dice_4: 0.4863  loss_ce_5: 2.435  loss_mask_5: 24.49  loss_dice_5: 0.4866  loss_ce_6: 2.448  loss_mask_6: 24.93  loss_dice_6: 0.4875  loss_ce_7: 2.484  loss_mask_7: 25.27  loss_dice_7: 0.4881  loss_ce_8: 2.384  loss_mask_8: 25.42  loss_dice_8: 0.4881  time: 2.9638  data_time: 0.4505  lr: 6.8349e-06  max_mem: 21933M
[01/24 13:21:56] d2.utils.events INFO:  eta: 2 days, 2:14:01  iter: 79  total_loss: 258.3  loss_ce: 2.298  loss_mask: 24.59  loss_dice: 0.4879  loss_ce_0: 2.389  loss_mask_0: 22.45  loss_dice_0: 0.4807  loss_ce_1: 2.486  loss_mask_1: 21.87  loss_dice_1: 0.482  loss_ce_2: 2.38  loss_mask_2: 21.54  loss_dice_2: 0.4826  loss_ce_3: 2.32  loss_mask_3: 22.6  loss_dice_3: 0.4843  loss_ce_4: 2.333  loss_mask_4: 23.01  loss_dice_4: 0.4871  loss_ce_5: 2.426  loss_mask_5: 22.76  loss_dice_5: 0.4871  loss_ce_6: 2.374  loss_mask_6: 22.92  loss_dice_6: 0.4879  loss_ce_7: 2.37  loss_mask_7: 23.31  loss_dice_7: 0.4881  loss_ce_8: 2.293  loss_mask_8: 23.78  loss_dice_8: 0.4881  time: 3.0448  data_time: 0.5151  lr: 8.8105e-06  max_mem: 21933M
[01/24 13:22:54] d2.utils.events INFO:  eta: 2 days, 1:40:01  iter: 99  total_loss: 223.4  loss_ce: 2.291  loss_mask: 20.4  loss_dice: 0.4868  loss_ce_0: 2.391  loss_mask_0: 22.2  loss_dice_0: 0.4802  loss_ce_1: 2.504  loss_mask_1: 19.16  loss_dice_1: 0.4819  loss_ce_2: 2.411  loss_mask_2: 18.08  loss_dice_2: 0.4825  loss_ce_3: 2.351  loss_mask_3: 18.53  loss_dice_3: 0.4824  loss_ce_4: 2.4  loss_mask_4: 19.81  loss_dice_4: 0.4838  loss_ce_5: 2.477  loss_mask_5: 18.56  loss_dice_5: 0.4842  loss_ce_6: 2.383  loss_mask_6: 19.88  loss_dice_6: 0.487  loss_ce_7: 2.353  loss_mask_7: 19.67  loss_dice_7: 0.4876  loss_ce_8: 2.288  loss_mask_8: 19.18  loss_dice_8: 0.4863  time: 3.0128  data_time: 0.4464  lr: 1.0785e-05  max_mem: 21933M
[01/24 13:23:52] d2.utils.events INFO:  eta: 2 days, 1:14:12  iter: 119  total_loss: 205.3  loss_ce: 2.324  loss_mask: 17.6  loss_dice: 0.4786  loss_ce_0: 2.419  loss_mask_0: 20.95  loss_dice_0: 0.4782  loss_ce_1: 2.526  loss_mask_1: 17.32  loss_dice_1: 0.48  loss_ce_2: 2.425  loss_mask_2: 16.85  loss_dice_2: 0.478  loss_ce_3: 2.383  loss_mask_3: 16.91  loss_dice_3: 0.4783  loss_ce_4: 2.428  loss_mask_4: 17.24  loss_dice_4: 0.4781  loss_ce_5: 2.483  loss_mask_5: 17.43  loss_dice_5: 0.4758  loss_ce_6: 2.426  loss_mask_6: 17.15  loss_dice_6: 0.4782  loss_ce_7: 2.38  loss_mask_7: 17.33  loss_dice_7: 0.4752  loss_ce_8: 2.326  loss_mask_8: 17.58  loss_dice_8: 0.4764  time: 2.9937  data_time: 0.4985  lr: 1.2758e-05  max_mem: 21933M
[01/24 13:24:48] d2.utils.events INFO:  eta: 2 days, 0:46:32  iter: 139  total_loss: 198.2  loss_ce: 2.274  loss_mask: 17.41  loss_dice: 0.4811  loss_ce_0: 2.429  loss_mask_0: 18.95  loss_dice_0: 0.4787  loss_ce_1: 2.506  loss_mask_1: 16.69  loss_dice_1: 0.4794  loss_ce_2: 2.402  loss_mask_2: 16.11  loss_dice_2: 0.4769  loss_ce_3: 2.348  loss_mask_3: 16.54  loss_dice_3: 0.4792  loss_ce_4: 2.363  loss_mask_4: 16.27  loss_dice_4: 0.4761  loss_ce_5: 2.393  loss_mask_5: 16.74  loss_dice_5: 0.4777  loss_ce_6: 2.348  loss_mask_6: 17.01  loss_dice_6: 0.4803  loss_ce_7: 2.298  loss_mask_7: 16.69  loss_dice_7: 0.479  loss_ce_8: 2.264  loss_mask_8: 16.76  loss_dice_8: 0.4799  time: 2.9655  data_time: 0.4873  lr: 1.473e-05  max_mem: 22063M
[01/24 13:25:42] d2.utils.events INFO:  eta: 1 day, 23:51:05  iter: 159  total_loss: 194.4  loss_ce: 2.268  loss_mask: 16.95  loss_dice: 0.4829  loss_ce_0: 2.411  loss_mask_0: 18.63  loss_dice_0: 0.48  loss_ce_1: 2.466  loss_mask_1: 16.12  loss_dice_1: 0.4788  loss_ce_2: 2.381  loss_mask_2: 16.23  loss_dice_2: 0.4779  loss_ce_3: 2.32  loss_mask_3: 16.41  loss_dice_3: 0.4801  loss_ce_4: 2.327  loss_mask_4: 16.22  loss_dice_4: 0.4802  loss_ce_5: 2.361  loss_mask_5: 16.67  loss_dice_5: 0.4835  loss_ce_6: 2.308  loss_mask_6: 16.7  loss_dice_6: 0.4839  loss_ce_7: 2.274  loss_mask_7: 16.5  loss_dice_7: 0.4782  loss_ce_8: 2.245  loss_mask_8: 16.76  loss_dice_8: 0.4799  time: 2.9333  data_time: 0.3704  lr: 1.6701e-05  max_mem: 22063M
[01/24 13:26:41] d2.utils.events INFO:  eta: 1 day, 23:57:17  iter: 179  total_loss: 179  loss_ce: 2.263  loss_mask: 14.75  loss_dice: 0.4695  loss_ce_0: 2.423  loss_mask_0: 17.45  loss_dice_0: 0.4791  loss_ce_1: 2.46  loss_mask_1: 14.86  loss_dice_1: 0.4771  loss_ce_2: 2.356  loss_mask_2: 14.91  loss_dice_2: 0.4756  loss_ce_3: 2.315  loss_mask_3: 15.1  loss_dice_3: 0.4783  loss_ce_4: 2.307  loss_mask_4: 15.01  loss_dice_4: 0.4773  loss_ce_5: 2.316  loss_mask_5: 14.77  loss_dice_5: 0.4764  loss_ce_6: 2.262  loss_mask_6: 14.82  loss_dice_6: 0.4752  loss_ce_7: 2.26  loss_mask_7: 14.6  loss_dice_7: 0.469  loss_ce_8: 2.245  loss_mask_8: 14.55  loss_dice_8: 0.4692  time: 2.9349  data_time: 0.4547  lr: 1.8671e-05  max_mem: 22242M
[01/24 13:27:34] d2.utils.events INFO:  eta: 1 day, 23:15:39  iter: 199  total_loss: 167  loss_ce: 2.208  loss_mask: 13.75  loss_dice: 0.4753  loss_ce_0: 2.422  loss_mask_0: 15.55  loss_dice_0: 0.4786  loss_ce_1: 2.43  loss_mask_1: 13.78  loss_dice_1: 0.4765  loss_ce_2: 2.307  loss_mask_2: 13.48  loss_dice_2: 0.476  loss_ce_3: 2.263  loss_mask_3: 13.81  loss_dice_3: 0.4779  loss_ce_4: 2.252  loss_mask_4: 13.57  loss_dice_4: 0.4777  loss_ce_5: 2.278  loss_mask_5: 13.84  loss_dice_5: 0.4795  loss_ce_6: 2.227  loss_mask_6: 13.79  loss_dice_6: 0.4795  loss_ce_7: 2.223  loss_mask_7: 13.61  loss_dice_7: 0.4742  loss_ce_8: 2.199  loss_mask_8: 13.87  loss_dice_8: 0.475  time: 2.9037  data_time: 0.4043  lr: 2.0639e-05  max_mem: 22578M
[01/24 13:28:28] d2.utils.events INFO:  eta: 1 day, 23:01:58  iter: 219  total_loss: 166.1  loss_ce: 2.182  loss_mask: 13.55  loss_dice: 0.4773  loss_ce_0: 2.431  loss_mask_0: 16.55  loss_dice_0: 0.4782  loss_ce_1: 2.411  loss_mask_1: 13.99  loss_dice_1: 0.4769  loss_ce_2: 2.266  loss_mask_2: 13.55  loss_dice_2: 0.4765  loss_ce_3: 2.242  loss_mask_3: 13.56  loss_dice_3: 0.4784  loss_ce_4: 2.23  loss_mask_4: 13.55  loss_dice_4: 0.4781  loss_ce_5: 2.24  loss_mask_5: 13.32  loss_dice_5: 0.4786  loss_ce_6: 2.21  loss_mask_6: 13.47  loss_dice_6: 0.478  loss_ce_7: 2.203  loss_mask_7: 13.4  loss_dice_7: 0.4762  loss_ce_8: 2.185  loss_mask_8: 13.49  loss_dice_8: 0.4768  time: 2.8843  data_time: 0.4139  lr: 2.2606e-05  max_mem: 22578M
[01/24 13:29:24] d2.utils.events INFO:  eta: 1 day, 22:54:44  iter: 239  total_loss: 154.4  loss_ce: 2.172  loss_mask: 12.27  loss_dice: 0.4809  loss_ce_0: 2.431  loss_mask_0: 14.93  loss_dice_0: 0.478  loss_ce_1: 2.396  loss_mask_1: 12.69  loss_dice_1: 0.4775  loss_ce_2: 2.262  loss_mask_2: 12.44  loss_dice_2: 0.4774  loss_ce_3: 2.222  loss_mask_3: 12.48  loss_dice_3: 0.4796  loss_ce_4: 2.217  loss_mask_4: 12.37  loss_dice_4: 0.4798  loss_ce_5: 2.245  loss_mask_5: 12.37  loss_dice_5: 0.4806  loss_ce_6: 2.212  loss_mask_6: 12.4  loss_dice_6: 0.4806  loss_ce_7: 2.2  loss_mask_7: 12.42  loss_dice_7: 0.4784  loss_ce_8: 2.189  loss_mask_8: 12.31  loss_dice_8: 0.4792  time: 2.8789  data_time: 0.4067  lr: 2.4573e-05  max_mem: 22578M
[01/24 13:30:18] d2.utils.events INFO:  eta: 1 day, 22:31:19  iter: 259  total_loss: 144.7  loss_ce: 2.16  loss_mask: 11.79  loss_dice: 0.4796  loss_ce_0: 2.44  loss_mask_0: 13.77  loss_dice_0: 0.4776  loss_ce_1: 2.373  loss_mask_1: 11.85  loss_dice_1: 0.4778  loss_ce_2: 2.239  loss_mask_2: 11.57  loss_dice_2: 0.4769  loss_ce_3: 2.205  loss_mask_3: 11.6  loss_dice_3: 0.4789  loss_ce_4: 2.207  loss_mask_4: 11.66  loss_dice_4: 0.4794  loss_ce_5: 2.221  loss_mask_5: 11.53  loss_dice_5: 0.4809  loss_ce_6: 2.187  loss_mask_6: 11.45  loss_dice_6: 0.4805  loss_ce_7: 2.186  loss_mask_7: 11.37  loss_dice_7: 0.4777  loss_ce_8: 2.162  loss_mask_8: 11.25  loss_dice_8: 0.479  time: 2.8637  data_time: 0.3751  lr: 2.6537e-05  max_mem: 22578M
[01/24 13:31:17] d2.utils.events INFO:  eta: 1 day, 22:34:54  iter: 279  total_loss: 146.9  loss_ce: 2.171  loss_mask: 11.7  loss_dice: 0.4808  loss_ce_0: 2.43  loss_mask_0: 14.2  loss_dice_0: 0.4786  loss_ce_1: 2.358  loss_mask_1: 11.87  loss_dice_1: 0.4795  loss_ce_2: 2.219  loss_mask_2: 11.56  loss_dice_2: 0.4781  loss_ce_3: 2.197  loss_mask_3: 11.42  loss_dice_3: 0.4797  loss_ce_4: 2.2  loss_mask_4: 11.65  loss_dice_4: 0.4794  loss_ce_5: 2.224  loss_mask_5: 11.46  loss_dice_5: 0.4805  loss_ce_6: 2.204  loss_mask_6: 11.67  loss_dice_6: 0.4808  loss_ce_7: 2.212  loss_mask_7: 11.88  loss_dice_7: 0.4798  loss_ce_8: 2.194  loss_mask_8: 11.77  loss_dice_8: 0.4798  time: 2.8691  data_time: 0.4250  lr: 2.8501e-05  max_mem: 22578M
[01/24 13:32:11] d2.utils.events INFO:  eta: 1 day, 22:26:32  iter: 299  total_loss: 133.2  loss_ce: 2.163  loss_mask: 10.27  loss_dice: 0.4789  loss_ce_0: 2.427  loss_mask_0: 12.8  loss_dice_0: 0.479  loss_ce_1: 2.333  loss_mask_1: 10.68  loss_dice_1: 0.4798  loss_ce_2: 2.205  loss_mask_2: 10.42  loss_dice_2: 0.4788  loss_ce_3: 2.183  loss_mask_3: 10.38  loss_dice_3: 0.4797  loss_ce_4: 2.176  loss_mask_4: 10.3  loss_dice_4: 0.4796  loss_ce_5: 2.193  loss_mask_5: 10.38  loss_dice_5: 0.4803  loss_ce_6: 2.193  loss_mask_6: 10.26  loss_dice_6: 0.4803  loss_ce_7: 2.198  loss_mask_7: 10.4  loss_dice_7: 0.4785  loss_ce_8: 2.184  loss_mask_8: 10.44  loss_dice_8: 0.4798  time: 2.8590  data_time: 0.3542  lr: 3.0464e-05  max_mem: 22578M
[01/24 13:33:07] d2.utils.events INFO:  eta: 1 day, 22:28:31  iter: 319  total_loss: 130.7  loss_ce: 2.137  loss_mask: 10.43  loss_dice: 0.4793  loss_ce_0: 2.437  loss_mask_0: 11.79  loss_dice_0: 0.4803  loss_ce_1: 2.323  loss_mask_1: 10.38  loss_dice_1: 0.4799  loss_ce_2: 2.189  loss_mask_2: 10.15  loss_dice_2: 0.4779  loss_ce_3: 2.161  loss_mask_3: 9.969  loss_dice_3: 0.4788  loss_ce_4: 2.162  loss_mask_4: 10.02  loss_dice_4: 0.4795  loss_ce_5: 2.164  loss_mask_5: 10.14  loss_dice_5: 0.481  loss_ce_6: 2.16  loss_mask_6: 10.29  loss_dice_6: 0.4808  loss_ce_7: 2.167  loss_mask_7: 10.12  loss_dice_7: 0.4792  loss_ce_8: 2.144  loss_mask_8: 10.34  loss_dice_8: 0.4806  time: 2.8551  data_time: 0.3828  lr: 3.2425e-05  max_mem: 22578M
[01/24 13:34:04] d2.utils.events INFO:  eta: 1 day, 22:27:35  iter: 339  total_loss: 127.3  loss_ce: 2.158  loss_mask: 9.893  loss_dice: 0.4776  loss_ce_0: 2.444  loss_mask_0: 11.65  loss_dice_0: 0.4794  loss_ce_1: 2.32  loss_mask_1: 9.871  loss_dice_1: 0.4793  loss_ce_2: 2.193  loss_mask_2: 10  loss_dice_2: 0.4776  loss_ce_3: 2.171  loss_mask_3: 9.799  loss_dice_3: 0.4788  loss_ce_4: 2.181  loss_mask_4: 9.7  loss_dice_4: 0.4795  loss_ce_5: 2.209  loss_mask_5: 9.799  loss_dice_5: 0.4802  loss_ce_6: 2.197  loss_mask_6: 9.71  loss_dice_6: 0.4804  loss_ce_7: 2.217  loss_mask_7: 9.761  loss_dice_7: 0.4802  loss_ce_8: 2.2  loss_mask_8: 9.889  loss_dice_8: 0.4796  time: 2.8528  data_time: 0.3819  lr: 3.4385e-05  max_mem: 22578M
[01/24 13:34:59] d2.utils.events INFO:  eta: 1 day, 22:26:39  iter: 359  total_loss: 131.4  loss_ce: 2.204  loss_mask: 10.39  loss_dice: 0.4791  loss_ce_0: 2.424  loss_mask_0: 12.22  loss_dice_0: 0.4801  loss_ce_1: 2.299  loss_mask_1: 10.51  loss_dice_1: 0.4809  loss_ce_2: 2.174  loss_mask_2: 10.18  loss_dice_2: 0.4787  loss_ce_3: 2.165  loss_mask_3: 9.942  loss_dice_3: 0.48  loss_ce_4: 2.206  loss_mask_4: 10.05  loss_dice_4: 0.4804  loss_ce_5: 2.202  loss_mask_5: 10.21  loss_dice_5: 0.481  loss_ce_6: 2.224  loss_mask_6: 10.17  loss_dice_6: 0.4819  loss_ce_7: 2.26  loss_mask_7: 10.11  loss_dice_7: 0.4812  loss_ce_8: 2.226  loss_mask_8: 10.28  loss_dice_8: 0.4812  time: 2.8492  data_time: 0.3672  lr: 3.6344e-05  max_mem: 23006M
[01/24 13:35:56] d2.utils.events INFO:  eta: 1 day, 22:22:51  iter: 379  total_loss: 115.2  loss_ce: 2.153  loss_mask: 8.764  loss_dice: 0.4769  loss_ce_0: 2.444  loss_mask_0: 9.905  loss_dice_0: 0.479  loss_ce_1: 2.284  loss_mask_1: 9.024  loss_dice_1: 0.4787  loss_ce_2: 2.139  loss_mask_2: 8.767  loss_dice_2: 0.4776  loss_ce_3: 2.15  loss_mask_3: 8.672  loss_dice_3: 0.4769  loss_ce_4: 2.181  loss_mask_4: 8.735  loss_dice_4: 0.478  loss_ce_5: 2.196  loss_mask_5: 8.733  loss_dice_5: 0.4774  loss_ce_6: 2.215  loss_mask_6: 8.819  loss_dice_6: 0.4778  loss_ce_7: 2.222  loss_mask_7: 8.769  loss_dice_7: 0.4775  loss_ce_8: 2.191  loss_mask_8: 8.907  loss_dice_8: 0.4778  time: 2.8486  data_time: 0.4055  lr: 3.8302e-05  max_mem: 23006M
[01/24 13:36:51] d2.utils.events INFO:  eta: 1 day, 22:20:14  iter: 399  total_loss: 123.7  loss_ce: 2.161  loss_mask: 9.769  loss_dice: 0.4796  loss_ce_0: 2.438  loss_mask_0: 10.7  loss_dice_0: 0.4811  loss_ce_1: 2.275  loss_mask_1: 9.849  loss_dice_1: 0.4809  loss_ce_2: 2.151  loss_mask_2: 9.424  loss_dice_2: 0.4784  loss_ce_3: 2.17  loss_mask_3: 9.566  loss_dice_3: 0.4783  loss_ce_4: 2.192  loss_mask_4: 9.509  loss_dice_4: 0.4794  loss_ce_5: 2.191  loss_mask_5: 9.493  loss_dice_5: 0.4801  loss_ce_6: 2.216  loss_mask_6: 9.502  loss_dice_6: 0.4823  loss_ce_7: 2.221  loss_mask_7: 9.617  loss_dice_7: 0.4807  loss_ce_8: 2.186  loss_mask_8: 9.478  loss_dice_8: 0.48  time: 2.8427  data_time: 0.3758  lr: 4.0259e-05  max_mem: 23006M
[01/24 13:37:45] d2.utils.events INFO:  eta: 1 day, 22:10:24  iter: 419  total_loss: 113  loss_ce: 2.219  loss_mask: 8.769  loss_dice: 0.4773  loss_ce_0: 2.449  loss_mask_0: 9.714  loss_dice_0: 0.4803  loss_ce_1: 2.257  loss_mask_1: 8.613  loss_dice_1: 0.4789  loss_ce_2: 2.133  loss_mask_2: 8.421  loss_dice_2: 0.4766  loss_ce_3: 2.14  loss_mask_3: 8.401  loss_dice_3: 0.4777  loss_ce_4: 2.152  loss_mask_4: 8.6  loss_dice_4: 0.478  loss_ce_5: 2.182  loss_mask_5: 8.259  loss_dice_5: 0.4775  loss_ce_6: 2.214  loss_mask_6: 8.353  loss_dice_6: 0.4786  loss_ce_7: 2.217  loss_mask_7: 8.655  loss_dice_7: 0.4776  loss_ce_8: 2.203  loss_mask_8: 8.741  loss_dice_8: 0.4766  time: 2.8365  data_time: 0.3751  lr: 4.2214e-05  max_mem: 23006M
[01/24 13:38:42] d2.utils.events INFO:  eta: 1 day, 22:14:33  iter: 439  total_loss: 117.1  loss_ce: 2.303  loss_mask: 8.893  loss_dice: 0.4809  loss_ce_0: 2.439  loss_mask_0: 9.953  loss_dice_0: 0.4802  loss_ce_1: 2.264  loss_mask_1: 8.721  loss_dice_1: 0.4791  loss_ce_2: 2.147  loss_mask_2: 8.722  loss_dice_2: 0.4781  loss_ce_3: 2.169  loss_mask_3: 8.732  loss_dice_3: 0.48  loss_ce_4: 2.201  loss_mask_4: 8.85  loss_dice_4: 0.4811  loss_ce_5: 2.201  loss_mask_5: 8.752  loss_dice_5: 0.4796  loss_ce_6: 2.221  loss_mask_6: 8.805  loss_dice_6: 0.4817  loss_ce_7: 2.267  loss_mask_7: 8.707  loss_dice_7: 0.481  loss_ce_8: 2.267  loss_mask_8: 8.926  loss_dice_8: 0.4827  time: 2.8356  data_time: 0.3859  lr: 4.4168e-05  max_mem: 23006M
[01/24 13:39:34] d2.utils.events INFO:  eta: 1 day, 22:04:31  iter: 459  total_loss: 115.9  loss_ce: 2.277  loss_mask: 9.082  loss_dice: 0.4803  loss_ce_0: 2.452  loss_mask_0: 9.952  loss_dice_0: 0.4798  loss_ce_1: 2.248  loss_mask_1: 8.922  loss_dice_1: 0.4801  loss_ce_2: 2.125  loss_mask_2: 8.81  loss_dice_2: 0.4774  loss_ce_3: 2.142  loss_mask_3: 8.712  loss_dice_3: 0.4792  loss_ce_4: 2.148  loss_mask_4: 8.784  loss_dice_4: 0.4794  loss_ce_5: 2.163  loss_mask_5: 8.803  loss_dice_5: 0.4785  loss_ce_6: 2.212  loss_mask_6: 8.697  loss_dice_6: 0.4791  loss_ce_7: 2.238  loss_mask_7: 8.581  loss_dice_7: 0.4792  loss_ce_8: 2.244  loss_mask_8: 9.037  loss_dice_8: 0.4816  time: 2.8270  data_time: 0.3638  lr: 4.6121e-05  max_mem: 23006M
[01/24 13:40:33] d2.utils.events INFO:  eta: 1 day, 22:05:19  iter: 479  total_loss: 116.7  loss_ce: 2.215  loss_mask: 9.018  loss_dice: 0.4833  loss_ce_0: 2.454  loss_mask_0: 9.708  loss_dice_0: 0.4814  loss_ce_1: 2.247  loss_mask_1: 8.605  loss_dice_1: 0.481  loss_ce_2: 2.156  loss_mask_2: 8.899  loss_dice_2: 0.4798  loss_ce_3: 2.186  loss_mask_3: 9.001  loss_dice_3: 0.482  loss_ce_4: 2.182  loss_mask_4: 8.663  loss_dice_4: 0.4811  loss_ce_5: 2.212  loss_mask_5: 9.094  loss_dice_5: 0.4803  loss_ce_6: 2.199  loss_mask_6: 8.661  loss_dice_6: 0.479  loss_ce_7: 2.233  loss_mask_7: 9.248  loss_dice_7: 0.4817  loss_ce_8: 2.214  loss_mask_8: 9.443  loss_dice_8: 0.4837  time: 2.8312  data_time: 0.4225  lr: 4.8073e-05  max_mem: 23006M
[01/24 13:41:27] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 13:41:28] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 13:41:28] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 13:49:34] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 25.681409342308136, 'error_1pix': 0.950586596933693, 'error_3pix': 0.89115733898199, 'mIoU': 0.028894946702970374, 'fwIoU': 0.08294936897869774, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.014439992351239547, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.8983425049223113, 'IoU-22': 1.5879370889423796, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 1.8341143030116718, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.03138166027586358, 'IoU-43': 0.6140062001702101, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.4579190665045005, 'IoU-47': 0.010945182972754307, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.09479527194175727, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0004143943222452595, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0012842781176096187, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.00224982343776934, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5282753003484125, 'pACC': 1.6208765154730818, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.01739865564366353, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 7.508630000255012, 'ACC-22': 49.387525980660016, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 42.43071953286001, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.03542190726184097, 'ACC-43': 0.9189646365013978, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.9473108080024526, 'ACC-47': 0.01116126533135049, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.16773505913747533, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0004154534847892093, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0012853628650171828, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0022890048921674123, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 13:49:34] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 13:49:34] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 13:49:34] d2.evaluation.testing INFO: copypaste: 25.6814,0.9506,0.8912,0.0289,0.0829,0.5283,1.6209
[01/24 13:49:34] d2.utils.events INFO:  eta: 1 day, 21:58:52  iter: 499  total_loss: 121.1  loss_ce: 2.222  loss_mask: 9.369  loss_dice: 0.482  loss_ce_0: 2.44  loss_mask_0: 9.993  loss_dice_0: 0.4818  loss_ce_1: 2.256  loss_mask_1: 9.416  loss_dice_1: 0.4797  loss_ce_2: 2.201  loss_mask_2: 8.97  loss_dice_2: 0.4798  loss_ce_3: 2.211  loss_mask_3: 9.337  loss_dice_3: 0.4813  loss_ce_4: 2.211  loss_mask_4: 9.376  loss_dice_4: 0.4824  loss_ce_5: 2.207  loss_mask_5: 8.987  loss_dice_5: 0.4821  loss_ce_6: 2.201  loss_mask_6: 9.047  loss_dice_6: 0.4793  loss_ce_7: 2.243  loss_mask_7: 10.06  loss_dice_7: 0.4843  loss_ce_8: 2.239  loss_mask_8: 10.05  loss_dice_8: 0.4841  time: 2.8259  data_time: 0.3494  lr: 5.0024e-05  max_mem: 23006M
[01/24 13:50:28] d2.utils.events INFO:  eta: 1 day, 21:53:45  iter: 519  total_loss: 120.3  loss_ce: 2.212  loss_mask: 9.773  loss_dice: 0.4809  loss_ce_0: 2.444  loss_mask_0: 9.515  loss_dice_0: 0.4802  loss_ce_1: 2.334  loss_mask_1: 9.358  loss_dice_1: 0.4827  loss_ce_2: 2.246  loss_mask_2: 8.981  loss_dice_2: 0.482  loss_ce_3: 2.261  loss_mask_3: 8.858  loss_dice_3: 0.4835  loss_ce_4: 2.329  loss_mask_4: 9.058  loss_dice_4: 0.4839  loss_ce_5: 2.268  loss_mask_5: 9.168  loss_dice_5: 0.484  loss_ce_6: 2.257  loss_mask_6: 9.481  loss_dice_6: 0.4837  loss_ce_7: 2.234  loss_mask_7: 9.158  loss_dice_7: 0.4844  loss_ce_8: 2.226  loss_mask_8: 9.348  loss_dice_8: 0.4829  time: 2.8216  data_time: 0.3746  lr: 5.1973e-05  max_mem: 23006M
[01/24 13:51:28] d2.utils.events INFO:  eta: 1 day, 21:57:20  iter: 539  total_loss: 114.4  loss_ce: 2.183  loss_mask: 9.274  loss_dice: 0.4785  loss_ce_0: 2.441  loss_mask_0: 9.05  loss_dice_0: 0.478  loss_ce_1: 2.325  loss_mask_1: 8.838  loss_dice_1: 0.4832  loss_ce_2: 2.216  loss_mask_2: 8.879  loss_dice_2: 0.4816  loss_ce_3: 2.223  loss_mask_3: 8.719  loss_dice_3: 0.4784  loss_ce_4: 2.263  loss_mask_4: 8.902  loss_dice_4: 0.4794  loss_ce_5: 2.236  loss_mask_5: 8.226  loss_dice_5: 0.4785  loss_ce_6: 2.237  loss_mask_6: 8.534  loss_dice_6: 0.4799  loss_ce_7: 2.213  loss_mask_7: 8.649  loss_dice_7: 0.4788  loss_ce_8: 2.204  loss_mask_8: 8.78  loss_dice_8: 0.4786  time: 2.8265  data_time: 0.5000  lr: 5.3921e-05  max_mem: 23006M
[01/24 13:52:21] d2.utils.events INFO:  eta: 1 day, 21:50:47  iter: 559  total_loss: 110.2  loss_ce: 2.23  loss_mask: 8.377  loss_dice: 0.4775  loss_ce_0: 2.445  loss_mask_0: 8.681  loss_dice_0: 0.4797  loss_ce_1: 2.302  loss_mask_1: 8.191  loss_dice_1: 0.4781  loss_ce_2: 2.21  loss_mask_2: 8.285  loss_dice_2: 0.4793  loss_ce_3: 2.213  loss_mask_3: 8.053  loss_dice_3: 0.4771  loss_ce_4: 2.255  loss_mask_4: 8.049  loss_dice_4: 0.4771  loss_ce_5: 2.227  loss_mask_5: 8.163  loss_dice_5: 0.477  loss_ce_6: 2.294  loss_mask_6: 8.402  loss_dice_6: 0.4793  loss_ce_7: 2.28  loss_mask_7: 8.42  loss_dice_7: 0.4801  loss_ce_8: 2.234  loss_mask_8: 8.277  loss_dice_8: 0.4784  time: 2.8203  data_time: 0.3725  lr: 5.5868e-05  max_mem: 23006M
[01/24 13:53:18] d2.utils.events INFO:  eta: 1 day, 21:50:58  iter: 579  total_loss: 110.9  loss_ce: 2.246  loss_mask: 9.278  loss_dice: 0.4821  loss_ce_0: 2.449  loss_mask_0: 8.401  loss_dice_0: 0.4801  loss_ce_1: 2.264  loss_mask_1: 8.183  loss_dice_1: 0.479  loss_ce_2: 2.186  loss_mask_2: 7.982  loss_dice_2: 0.4809  loss_ce_3: 2.185  loss_mask_3: 7.929  loss_dice_3: 0.4795  loss_ce_4: 2.2  loss_mask_4: 7.818  loss_dice_4: 0.48  loss_ce_5: 2.235  loss_mask_5: 7.897  loss_dice_5: 0.4796  loss_ce_6: 2.262  loss_mask_6: 8.305  loss_dice_6: 0.4818  loss_ce_7: 2.263  loss_mask_7: 9.113  loss_dice_7: 0.4857  loss_ce_8: 2.234  loss_mask_8: 9.263  loss_dice_8: 0.4845  time: 2.8218  data_time: 0.4149  lr: 5.7814e-05  max_mem: 23006M
[01/24 13:54:14] d2.utils.events INFO:  eta: 1 day, 21:52:27  iter: 599  total_loss: 116.1  loss_ce: 2.241  loss_mask: 8.833  loss_dice: 0.4791  loss_ce_0: 2.441  loss_mask_0: 9.378  loss_dice_0: 0.4809  loss_ce_1: 2.242  loss_mask_1: 8.805  loss_dice_1: 0.4782  loss_ce_2: 2.221  loss_mask_2: 8.71  loss_dice_2: 0.4804  loss_ce_3: 2.214  loss_mask_3: 8.711  loss_dice_3: 0.4808  loss_ce_4: 2.22  loss_mask_4: 8.525  loss_dice_4: 0.4819  loss_ce_5: 2.258  loss_mask_5: 8.61  loss_dice_5: 0.4811  loss_ce_6: 2.257  loss_mask_6: 8.689  loss_dice_6: 0.4792  loss_ce_7: 2.268  loss_mask_7: 9.145  loss_dice_7: 0.4817  loss_ce_8: 2.257  loss_mask_8: 8.807  loss_dice_8: 0.4809  time: 2.8215  data_time: 0.3844  lr: 5.9759e-05  max_mem: 23006M
[01/24 13:55:07] d2.utils.events INFO:  eta: 1 day, 21:46:19  iter: 619  total_loss: 107.2  loss_ce: 2.167  loss_mask: 8.343  loss_dice: 0.4796  loss_ce_0: 2.46  loss_mask_0: 8.188  loss_dice_0: 0.4787  loss_ce_1: 2.199  loss_mask_1: 7.628  loss_dice_1: 0.4756  loss_ce_2: 2.174  loss_mask_2: 7.757  loss_dice_2: 0.4814  loss_ce_3: 2.167  loss_mask_3: 7.546  loss_dice_3: 0.4792  loss_ce_4: 2.16  loss_mask_4: 7.832  loss_dice_4: 0.481  loss_ce_5: 2.173  loss_mask_5: 7.858  loss_dice_5: 0.4814  loss_ce_6: 2.198  loss_mask_6: 8.222  loss_dice_6: 0.4785  loss_ce_7: 2.22  loss_mask_7: 8.839  loss_dice_7: 0.482  loss_ce_8: 2.185  loss_mask_8: 8.202  loss_dice_8: 0.4803  time: 2.8149  data_time: 0.3553  lr: 6.1702e-05  max_mem: 23006M
[01/24 13:55:57] d2.utils.events INFO:  eta: 1 day, 21:39:25  iter: 639  total_loss: 106.4  loss_ce: 2.156  loss_mask: 8.272  loss_dice: 0.4789  loss_ce_0: 2.469  loss_mask_0: 8.245  loss_dice_0: 0.4761  loss_ce_1: 2.167  loss_mask_1: 7.678  loss_dice_1: 0.4809  loss_ce_2: 2.113  loss_mask_2: 7.708  loss_dice_2: 0.4831  loss_ce_3: 2.119  loss_mask_3: 7.788  loss_dice_3: 0.4804  loss_ce_4: 2.13  loss_mask_4: 8.028  loss_dice_4: 0.4808  loss_ce_5: 2.172  loss_mask_5: 7.998  loss_dice_5: 0.4795  loss_ce_6: 2.178  loss_mask_6: 8.057  loss_dice_6: 0.4771  loss_ce_7: 2.179  loss_mask_7: 8.007  loss_dice_7: 0.4764  loss_ce_8: 2.17  loss_mask_8: 7.956  loss_dice_8: 0.4778  time: 2.8060  data_time: 0.3278  lr: 6.3645e-05  max_mem: 23006M
[01/24 13:56:49] d2.utils.events INFO:  eta: 1 day, 21:34:00  iter: 659  total_loss: 108  loss_ce: 2.223  loss_mask: 8.083  loss_dice: 0.4786  loss_ce_0: 2.45  loss_mask_0: 8.713  loss_dice_0: 0.4789  loss_ce_1: 2.23  loss_mask_1: 8.13  loss_dice_1: 0.4799  loss_ce_2: 2.156  loss_mask_2: 8.06  loss_dice_2: 0.4821  loss_ce_3: 2.171  loss_mask_3: 7.778  loss_dice_3: 0.4812  loss_ce_4: 2.182  loss_mask_4: 7.858  loss_dice_4: 0.4815  loss_ce_5: 2.225  loss_mask_5: 8.096  loss_dice_5: 0.48  loss_ce_6: 2.204  loss_mask_6: 8.142  loss_dice_6: 0.4783  loss_ce_7: 2.223  loss_mask_7: 7.937  loss_dice_7: 0.4799  loss_ce_8: 2.243  loss_mask_8: 7.862  loss_dice_8: 0.4802  time: 2.7997  data_time: 0.3515  lr: 6.5586e-05  max_mem: 23006M
[01/24 13:57:42] d2.utils.events INFO:  eta: 1 day, 21:30:37  iter: 679  total_loss: 106.6  loss_ce: 2.199  loss_mask: 8.036  loss_dice: 0.4813  loss_ce_0: 2.46  loss_mask_0: 8.337  loss_dice_0: 0.4774  loss_ce_1: 2.217  loss_mask_1: 7.834  loss_dice_1: 0.483  loss_ce_2: 2.16  loss_mask_2: 7.647  loss_dice_2: 0.4865  loss_ce_3: 2.168  loss_mask_3: 7.64  loss_dice_3: 0.486  loss_ce_4: 2.204  loss_mask_4: 7.796  loss_dice_4: 0.4859  loss_ce_5: 2.201  loss_mask_5: 7.932  loss_dice_5: 0.4847  loss_ce_6: 2.195  loss_mask_6: 7.772  loss_dice_6: 0.4831  loss_ce_7: 2.21  loss_mask_7: 7.972  loss_dice_7: 0.4807  loss_ce_8: 2.223  loss_mask_8: 8.256  loss_dice_8: 0.4829  time: 2.7950  data_time: 0.3693  lr: 6.7526e-05  max_mem: 23006M
[01/24 13:58:34] d2.utils.events INFO:  eta: 1 day, 21:25:41  iter: 699  total_loss: 104  loss_ce: 2.219  loss_mask: 7.628  loss_dice: 0.4782  loss_ce_0: 2.452  loss_mask_0: 8.092  loss_dice_0: 0.4784  loss_ce_1: 2.191  loss_mask_1: 7.35  loss_dice_1: 0.4802  loss_ce_2: 2.133  loss_mask_2: 7.408  loss_dice_2: 0.4805  loss_ce_3: 2.144  loss_mask_3: 7.536  loss_dice_3: 0.4816  loss_ce_4: 2.185  loss_mask_4: 7.454  loss_dice_4: 0.4823  loss_ce_5: 2.176  loss_mask_5: 7.422  loss_dice_5: 0.4808  loss_ce_6: 2.225  loss_mask_6: 7.536  loss_dice_6: 0.4782  loss_ce_7: 2.235  loss_mask_7: 7.967  loss_dice_7: 0.482  loss_ce_8: 2.24  loss_mask_8: 7.686  loss_dice_8: 0.4801  time: 2.7896  data_time: 0.3472  lr: 6.9465e-05  max_mem: 23006M
[01/24 13:59:27] d2.utils.events INFO:  eta: 1 day, 21:21:13  iter: 719  total_loss: 112.5  loss_ce: 2.19  loss_mask: 8.983  loss_dice: 0.4818  loss_ce_0: 2.459  loss_mask_0: 8.125  loss_dice_0: 0.4774  loss_ce_1: 2.2  loss_mask_1: 7.989  loss_dice_1: 0.4792  loss_ce_2: 2.185  loss_mask_2: 8.187  loss_dice_2: 0.4763  loss_ce_3: 2.233  loss_mask_3: 8.402  loss_dice_3: 0.4797  loss_ce_4: 2.249  loss_mask_4: 8.555  loss_dice_4: 0.4803  loss_ce_5: 2.241  loss_mask_5: 8.872  loss_dice_5: 0.4822  loss_ce_6: 2.26  loss_mask_6: 8.893  loss_dice_6: 0.4833  loss_ce_7: 2.248  loss_mask_7: 8.778  loss_dice_7: 0.4804  loss_ce_8: 2.234  loss_mask_8: 8.537  loss_dice_8: 0.4793  time: 2.7853  data_time: 0.3703  lr: 7.1402e-05  max_mem: 23006M
[01/24 14:00:21] d2.utils.events INFO:  eta: 1 day, 21:19:32  iter: 739  total_loss: 109.4  loss_ce: 2.193  loss_mask: 8.295  loss_dice: 0.4876  loss_ce_0: 2.441  loss_mask_0: 8.038  loss_dice_0: 0.4801  loss_ce_1: 2.157  loss_mask_1: 7.801  loss_dice_1: 0.4887  loss_ce_2: 2.135  loss_mask_2: 7.892  loss_dice_2: 0.487  loss_ce_3: 2.166  loss_mask_3: 7.868  loss_dice_3: 0.4862  loss_ce_4: 2.189  loss_mask_4: 7.683  loss_dice_4: 0.4858  loss_ce_5: 2.224  loss_mask_5: 8.665  loss_dice_5: 0.4821  loss_ce_6: 2.218  loss_mask_6: 8.395  loss_dice_6: 0.4836  loss_ce_7: 2.236  loss_mask_7: 8.34  loss_dice_7: 0.4838  loss_ce_8: 2.22  loss_mask_8: 7.944  loss_dice_8: 0.4852  time: 2.7822  data_time: 0.3835  lr: 7.3338e-05  max_mem: 23006M
[01/24 14:01:13] d2.utils.events INFO:  eta: 1 day, 21:16:11  iter: 759  total_loss: 105.3  loss_ce: 2.193  loss_mask: 7.712  loss_dice: 0.4802  loss_ce_0: 2.459  loss_mask_0: 7.849  loss_dice_0: 0.4787  loss_ce_1: 2.173  loss_mask_1: 7.766  loss_dice_1: 0.4807  loss_ce_2: 2.139  loss_mask_2: 7.668  loss_dice_2: 0.4797  loss_ce_3: 2.16  loss_mask_3: 7.762  loss_dice_3: 0.4812  loss_ce_4: 2.178  loss_mask_4: 8.278  loss_dice_4: 0.484  loss_ce_5: 2.197  loss_mask_5: 7.663  loss_dice_5: 0.4798  loss_ce_6: 2.198  loss_mask_6: 7.58  loss_dice_6: 0.4803  loss_ce_7: 2.225  loss_mask_7: 7.465  loss_dice_7: 0.4792  loss_ce_8: 2.219  loss_mask_8: 7.652  loss_dice_8: 0.4795  time: 2.7784  data_time: 0.3768  lr: 7.5274e-05  max_mem: 23006M
[01/24 14:02:05] d2.utils.events INFO:  eta: 1 day, 21:01:26  iter: 779  total_loss: 110.5  loss_ce: 2.21  loss_mask: 8.714  loss_dice: 0.4862  loss_ce_0: 2.454  loss_mask_0: 8.007  loss_dice_0: 0.4781  loss_ce_1: 2.157  loss_mask_1: 7.9  loss_dice_1: 0.4881  loss_ce_2: 2.126  loss_mask_2: 7.959  loss_dice_2: 0.4858  loss_ce_3: 2.149  loss_mask_3: 8.062  loss_dice_3: 0.4857  loss_ce_4: 2.203  loss_mask_4: 8.26  loss_dice_4: 0.4871  loss_ce_5: 2.223  loss_mask_5: 8.258  loss_dice_5: 0.4816  loss_ce_6: 2.21  loss_mask_6: 8.352  loss_dice_6: 0.4852  loss_ce_7: 2.217  loss_mask_7: 8.192  loss_dice_7: 0.4859  loss_ce_8: 2.221  loss_mask_8: 8.634  loss_dice_8: 0.4864  time: 2.7731  data_time: 0.3441  lr: 7.7208e-05  max_mem: 23006M
[01/24 14:02:56] d2.utils.events INFO:  eta: 1 day, 20:56:15  iter: 799  total_loss: 106.2  loss_ce: 2.173  loss_mask: 8.646  loss_dice: 0.4875  loss_ce_0: 2.46  loss_mask_0: 8.032  loss_dice_0: 0.4747  loss_ce_1: 2.152  loss_mask_1: 7.646  loss_dice_1: 0.4878  loss_ce_2: 2.149  loss_mask_2: 7.808  loss_dice_2: 0.4846  loss_ce_3: 2.183  loss_mask_3: 7.375  loss_dice_3: 0.4858  loss_ce_4: 2.277  loss_mask_4: 7.576  loss_dice_4: 0.4866  loss_ce_5: 2.271  loss_mask_5: 8.011  loss_dice_5: 0.4812  loss_ce_6: 2.192  loss_mask_6: 8.179  loss_dice_6: 0.4864  loss_ce_7: 2.219  loss_mask_7: 8.409  loss_dice_7: 0.487  loss_ce_8: 2.204  loss_mask_8: 8.375  loss_dice_8: 0.4872  time: 2.7679  data_time: 0.3621  lr: 7.914e-05  max_mem: 23006M
[01/24 14:03:53] d2.utils.events INFO:  eta: 1 day, 20:55:48  iter: 819  total_loss: 106.2  loss_ce: 2.184  loss_mask: 7.808  loss_dice: 0.4815  loss_ce_0: 2.446  loss_mask_0: 7.806  loss_dice_0: 0.4782  loss_ce_1: 2.155  loss_mask_1: 7.916  loss_dice_1: 0.4866  loss_ce_2: 2.157  loss_mask_2: 7.713  loss_dice_2: 0.4838  loss_ce_3: 2.171  loss_mask_3: 7.647  loss_dice_3: 0.4854  loss_ce_4: 2.248  loss_mask_4: 7.904  loss_dice_4: 0.4832  loss_ce_5: 2.268  loss_mask_5: 7.562  loss_dice_5: 0.479  loss_ce_6: 2.214  loss_mask_6: 7.807  loss_dice_6: 0.4782  loss_ce_7: 2.211  loss_mask_7: 7.678  loss_dice_7: 0.4786  loss_ce_8: 2.229  loss_mask_8: 7.972  loss_dice_8: 0.4779  time: 2.7689  data_time: 0.3706  lr: 8.1072e-05  max_mem: 23006M
[01/24 14:04:49] d2.utils.events INFO:  eta: 1 day, 20:56:26  iter: 839  total_loss: 102.1  loss_ce: 2.157  loss_mask: 7.71  loss_dice: 0.4786  loss_ce_0: 2.462  loss_mask_0: 7.541  loss_dice_0: 0.4718  loss_ce_1: 2.132  loss_mask_1: 7.297  loss_dice_1: 0.4827  loss_ce_2: 2.131  loss_mask_2: 7.462  loss_dice_2: 0.485  loss_ce_3: 2.155  loss_mask_3: 7.468  loss_dice_3: 0.4893  loss_ce_4: 2.231  loss_mask_4: 7.726  loss_dice_4: 0.4894  loss_ce_5: 2.215  loss_mask_5: 7.716  loss_dice_5: 0.4887  loss_ce_6: 2.175  loss_mask_6: 7.767  loss_dice_6: 0.487  loss_ce_7: 2.181  loss_mask_7: 7.566  loss_dice_7: 0.4856  loss_ce_8: 2.215  loss_mask_8: 7.571  loss_dice_8: 0.4792  time: 2.7698  data_time: 0.3685  lr: 8.3002e-05  max_mem: 23006M
[01/24 14:05:45] d2.utils.events INFO:  eta: 1 day, 20:55:31  iter: 859  total_loss: 101.9  loss_ce: 2.152  loss_mask: 7.505  loss_dice: 0.4832  loss_ce_0: 2.454  loss_mask_0: 7.491  loss_dice_0: 0.4725  loss_ce_1: 2.111  loss_mask_1: 7.215  loss_dice_1: 0.4858  loss_ce_2: 2.148  loss_mask_2: 7.484  loss_dice_2: 0.485  loss_ce_3: 2.189  loss_mask_3: 7.637  loss_dice_3: 0.487  loss_ce_4: 2.178  loss_mask_4: 7.677  loss_dice_4: 0.4874  loss_ce_5: 2.171  loss_mask_5: 7.631  loss_dice_5: 0.4863  loss_ce_6: 2.164  loss_mask_6: 7.592  loss_dice_6: 0.486  loss_ce_7: 2.177  loss_mask_7: 7.799  loss_dice_7: 0.4852  loss_ce_8: 2.17  loss_mask_8: 7.537  loss_dice_8: 0.4829  time: 2.7709  data_time: 0.3643  lr: 8.4932e-05  max_mem: 23006M
[01/24 14:06:39] d2.utils.events INFO:  eta: 1 day, 20:52:36  iter: 879  total_loss: 99.87  loss_ce: 2.114  loss_mask: 7.579  loss_dice: 0.4817  loss_ce_0: 2.46  loss_mask_0: 7.571  loss_dice_0: 0.4718  loss_ce_1: 2.107  loss_mask_1: 7.192  loss_dice_1: 0.4868  loss_ce_2: 2.131  loss_mask_2: 7.191  loss_dice_2: 0.4864  loss_ce_3: 2.141  loss_mask_3: 7.622  loss_dice_3: 0.4876  loss_ce_4: 2.136  loss_mask_4: 7.37  loss_dice_4: 0.488  loss_ce_5: 2.111  loss_mask_5: 7.518  loss_dice_5: 0.4871  loss_ce_6: 2.112  loss_mask_6: 7.768  loss_dice_6: 0.4853  loss_ce_7: 2.107  loss_mask_7: 7.41  loss_dice_7: 0.4839  loss_ce_8: 2.115  loss_mask_8: 7.277  loss_dice_8: 0.4814  time: 2.7690  data_time: 0.3515  lr: 8.686e-05  max_mem: 23006M
[01/24 14:07:37] d2.utils.events INFO:  eta: 1 day, 20:56:03  iter: 899  total_loss: 103  loss_ce: 2.095  loss_mask: 7.656  loss_dice: 0.4824  loss_ce_0: 2.468  loss_mask_0: 7.552  loss_dice_0: 0.472  loss_ce_1: 2.119  loss_mask_1: 7.25  loss_dice_1: 0.4824  loss_ce_2: 2.081  loss_mask_2: 7.584  loss_dice_2: 0.4801  loss_ce_3: 2.107  loss_mask_3: 7.47  loss_dice_3: 0.4825  loss_ce_4: 2.142  loss_mask_4: 7.752  loss_dice_4: 0.4827  loss_ce_5: 2.111  loss_mask_5: 7.825  loss_dice_5: 0.4818  loss_ce_6: 2.105  loss_mask_6: 7.741  loss_dice_6: 0.4819  loss_ce_7: 2.102  loss_mask_7: 7.584  loss_dice_7: 0.4809  loss_ce_8: 2.09  loss_mask_8: 7.715  loss_dice_8: 0.4814  time: 2.7723  data_time: 0.4451  lr: 8.8786e-05  max_mem: 23006M
[01/24 14:08:30] d2.utils.events INFO:  eta: 1 day, 20:51:14  iter: 919  total_loss: 100.7  loss_ce: 2.224  loss_mask: 7.571  loss_dice: 0.4723  loss_ce_0: 2.473  loss_mask_0: 7.22  loss_dice_0: 0.4708  loss_ce_1: 2.087  loss_mask_1: 7.286  loss_dice_1: 0.482  loss_ce_2: 2.068  loss_mask_2: 7.133  loss_dice_2: 0.4821  loss_ce_3: 2.074  loss_mask_3: 7.401  loss_dice_3: 0.4831  loss_ce_4: 2.094  loss_mask_4: 7.793  loss_dice_4: 0.4821  loss_ce_5: 2.113  loss_mask_5: 7.543  loss_dice_5: 0.4807  loss_ce_6: 2.074  loss_mask_6: 7.276  loss_dice_6: 0.4788  loss_ce_7: 2.095  loss_mask_7: 7.865  loss_dice_7: 0.4767  loss_ce_8: 2.19  loss_mask_8: 7.621  loss_dice_8: 0.4777  time: 2.7688  data_time: 0.3609  lr: 9.0712e-05  max_mem: 23006M
[01/24 14:09:24] d2.utils.events INFO:  eta: 1 day, 20:49:52  iter: 939  total_loss: 102.4  loss_ce: 2.14  loss_mask: 7.709  loss_dice: 0.4749  loss_ce_0: 2.478  loss_mask_0: 7.687  loss_dice_0: 0.4683  loss_ce_1: 2.074  loss_mask_1: 7.178  loss_dice_1: 0.4838  loss_ce_2: 2.058  loss_mask_2: 7.399  loss_dice_2: 0.4845  loss_ce_3: 2.079  loss_mask_3: 7.34  loss_dice_3: 0.486  loss_ce_4: 2.105  loss_mask_4: 7.755  loss_dice_4: 0.4828  loss_ce_5: 2.082  loss_mask_5: 7.645  loss_dice_5: 0.4804  loss_ce_6: 2.07  loss_mask_6: 7.694  loss_dice_6: 0.4779  loss_ce_7: 2.058  loss_mask_7: 7.796  loss_dice_7: 0.4781  loss_ce_8: 2.08  loss_mask_8: 7.58  loss_dice_8: 0.479  time: 2.7675  data_time: 0.3585  lr: 9.2637e-05  max_mem: 23006M
[01/24 14:10:24] d2.utils.events INFO:  eta: 1 day, 20:54:01  iter: 959  total_loss: 98.52  loss_ce: 2.257  loss_mask: 7.759  loss_dice: 0.4745  loss_ce_0: 2.48  loss_mask_0: 7.165  loss_dice_0: 0.4696  loss_ce_1: 2.079  loss_mask_1: 7.051  loss_dice_1: 0.4835  loss_ce_2: 2.069  loss_mask_2: 7.016  loss_dice_2: 0.484  loss_ce_3: 2.084  loss_mask_3: 7.484  loss_dice_3: 0.483  loss_ce_4: 2.108  loss_mask_4: 7.411  loss_dice_4: 0.4776  loss_ce_5: 2.079  loss_mask_5: 7.456  loss_dice_5: 0.4772  loss_ce_6: 2.081  loss_mask_6: 7.706  loss_dice_6: 0.477  loss_ce_7: 2.068  loss_mask_7: 7.374  loss_dice_7: 0.4799  loss_ce_8: 2.125  loss_mask_8: 7.14  loss_dice_8: 0.4767  time: 2.7723  data_time: 0.4393  lr: 9.456e-05  max_mem: 23006M
[01/24 14:11:24] d2.utils.events INFO:  eta: 1 day, 21:01:22  iter: 979  total_loss: 103.3  loss_ce: 2.099  loss_mask: 7.726  loss_dice: 0.4798  loss_ce_0: 2.467  loss_mask_0: 7.448  loss_dice_0: 0.4681  loss_ce_1: 2.062  loss_mask_1: 7.334  loss_dice_1: 0.4807  loss_ce_2: 2.059  loss_mask_2: 7.417  loss_dice_2: 0.4818  loss_ce_3: 2.064  loss_mask_3: 7.608  loss_dice_3: 0.4845  loss_ce_4: 2.099  loss_mask_4: 7.629  loss_dice_4: 0.4791  loss_ce_5: 2.115  loss_mask_5: 7.844  loss_dice_5: 0.478  loss_ce_6: 2.073  loss_mask_6: 7.832  loss_dice_6: 0.4813  loss_ce_7: 2.051  loss_mask_7: 7.952  loss_dice_7: 0.4816  loss_ce_8: 2.066  loss_mask_8: 7.598  loss_dice_8: 0.4801  time: 2.7770  data_time: 0.3911  lr: 9.6482e-05  max_mem: 23006M
[01/24 14:12:30] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 14:12:31] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 14:12:31] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 14:20:02] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 21.700845855874153, 'error_1pix': 0.9494849878816906, 'error_3pix': 0.8835134143045513, 'mIoU': 0.035398044456538456, 'fwIoU': 0.08156477539341914, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0007681312816831293, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.3730661697322901, 'IoU-25': 0.2166676363489594, 'IoU-26': 0.4847065122917286, 'IoU-27': 2.0146643987187, 'IoU-28': 0.06177736997049281, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.0007065667898744687, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 1.1102290593805197, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.4211101565476611, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 5.377466800864338e-05, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.3090463632171542, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.00411697353107787, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.5043070599510967, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.5557607062474675, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.7393588549327913, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 8.480204587762415e-05, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5771083972962714, 'pACC': 1.6934221557258327, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0007700689879137306, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.40749985571156305, 'ACC-25': 0.2508810605882873, 'ACC-26': 0.5867841289124833, 'ACC-27': 95.28770166014097, 'ACC-28': 0.06509394297791345, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.0007072065394079056, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 4.0628075945427575, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 6.3824298916433415, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 5.377660938334434e-05, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.4415542899382229, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.00416517532800547, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.9973563945394406, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.7371160704490363, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 1.5798058445843588, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 8.531939100725087e-05, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 14:20:02] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 14:20:02] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 14:20:02] d2.evaluation.testing INFO: copypaste: 21.7008,0.9495,0.8835,0.0354,0.0816,0.5771,1.6934
[01/24 14:20:02] d2.utils.events INFO:  eta: 1 day, 21:08:51  iter: 999  total_loss: 102.8  loss_ce: 2.109  loss_mask: 8.441  loss_dice: 0.4818  loss_ce_0: 2.478  loss_mask_0: 7.333  loss_dice_0: 0.4648  loss_ce_1: 2.101  loss_mask_1: 7.36  loss_dice_1: 0.4756  loss_ce_2: 2.069  loss_mask_2: 7.332  loss_dice_2: 0.4771  loss_ce_3: 2.073  loss_mask_3: 7.1  loss_dice_3: 0.4804  loss_ce_4: 2.091  loss_mask_4: 7.438  loss_dice_4: 0.4767  loss_ce_5: 2.101  loss_mask_5: 7.504  loss_dice_5: 0.4768  loss_ce_6: 2.076  loss_mask_6: 7.493  loss_dice_6: 0.4767  loss_ce_7: 2.092  loss_mask_7: 8.054  loss_dice_7: 0.4791  loss_ce_8: 2.085  loss_mask_8: 8.071  loss_dice_8: 0.4813  time: 2.7879  data_time: 0.4741  lr: 9.8403e-05  max_mem: 23006M
[01/24 14:20:54] d2.utils.events INFO:  eta: 1 day, 20:53:41  iter: 1019  total_loss: 96.31  loss_ce: 2.087  loss_mask: 7.014  loss_dice: 0.4742  loss_ce_0: 2.493  loss_mask_0: 6.834  loss_dice_0: 0.4604  loss_ce_1: 2.071  loss_mask_1: 6.879  loss_dice_1: 0.4815  loss_ce_2: 2.077  loss_mask_2: 6.908  loss_dice_2: 0.4837  loss_ce_3: 2.11  loss_mask_3: 7.136  loss_dice_3: 0.4844  loss_ce_4: 2.11  loss_mask_4: 7.331  loss_dice_4: 0.4824  loss_ce_5: 2.121  loss_mask_5: 7.339  loss_dice_5: 0.4826  loss_ce_6: 2.069  loss_mask_6: 7.254  loss_dice_6: 0.4788  loss_ce_7: 2.057  loss_mask_7: 7.058  loss_dice_7: 0.4816  loss_ce_8: 2.071  loss_mask_8: 6.853  loss_dice_8: 0.4784  time: 2.7839  data_time: 0.3511  lr: 9.847e-05  max_mem: 23006M
[01/24 14:21:50] d2.utils.events INFO:  eta: 1 day, 20:55:49  iter: 1039  total_loss: 95.01  loss_ce: 2.057  loss_mask: 6.97  loss_dice: 0.4806  loss_ce_0: 2.481  loss_mask_0: 7.006  loss_dice_0: 0.4635  loss_ce_1: 2.072  loss_mask_1: 7.141  loss_dice_1: 0.4811  loss_ce_2: 2.081  loss_mask_2: 6.867  loss_dice_2: 0.481  loss_ce_3: 2.089  loss_mask_3: 6.844  loss_dice_3: 0.4812  loss_ce_4: 2.104  loss_mask_4: 7.176  loss_dice_4: 0.4807  loss_ce_5: 2.082  loss_mask_5: 7.119  loss_dice_5: 0.4838  loss_ce_6: 2.072  loss_mask_6: 7.133  loss_dice_6: 0.4802  loss_ce_7: 2.069  loss_mask_7: 6.885  loss_dice_7: 0.4833  loss_ce_8: 2.056  loss_mask_8: 6.969  loss_dice_8: 0.4824  time: 2.7849  data_time: 0.4037  lr: 9.844e-05  max_mem: 23006M
[01/24 14:22:47] d2.utils.events INFO:  eta: 1 day, 20:50:17  iter: 1059  total_loss: 101  loss_ce: 2.071  loss_mask: 7.539  loss_dice: 0.4805  loss_ce_0: 2.49  loss_mask_0: 7.209  loss_dice_0: 0.463  loss_ce_1: 2.07  loss_mask_1: 7.323  loss_dice_1: 0.4804  loss_ce_2: 2.09  loss_mask_2: 7.19  loss_dice_2: 0.4799  loss_ce_3: 2.1  loss_mask_3: 7.277  loss_dice_3: 0.4824  loss_ce_4: 2.113  loss_mask_4: 7.472  loss_dice_4: 0.4786  loss_ce_5: 2.091  loss_mask_5: 7.553  loss_dice_5: 0.4818  loss_ce_6: 2.081  loss_mask_6: 7.43  loss_dice_6: 0.4797  loss_ce_7: 2.075  loss_mask_7: 7.571  loss_dice_7: 0.4797  loss_ce_8: 2.051  loss_mask_8: 7.297  loss_dice_8: 0.4807  time: 2.7857  data_time: 0.3964  lr: 9.841e-05  max_mem: 23006M
[01/24 14:23:42] d2.utils.events INFO:  eta: 1 day, 20:43:30  iter: 1079  total_loss: 95.75  loss_ce: 2.052  loss_mask: 7.271  loss_dice: 0.4807  loss_ce_0: 2.484  loss_mask_0: 6.459  loss_dice_0: 0.4637  loss_ce_1: 2.091  loss_mask_1: 7.006  loss_dice_1: 0.4764  loss_ce_2: 2.086  loss_mask_2: 6.941  loss_dice_2: 0.4773  loss_ce_3: 2.067  loss_mask_3: 7.239  loss_dice_3: 0.4769  loss_ce_4: 2.087  loss_mask_4: 7.18  loss_dice_4: 0.4744  loss_ce_5: 2.044  loss_mask_5: 7.158  loss_dice_5: 0.4806  loss_ce_6: 2.059  loss_mask_6: 7.026  loss_dice_6: 0.4809  loss_ce_7: 2.062  loss_mask_7: 7.158  loss_dice_7: 0.4815  loss_ce_8: 2.066  loss_mask_8: 7.311  loss_dice_8: 0.4807  time: 2.7846  data_time: 0.3726  lr: 9.838e-05  max_mem: 23006M
[01/24 14:24:40] d2.utils.events INFO:  eta: 1 day, 20:43:03  iter: 1099  total_loss: 97.99  loss_ce: 2.047  loss_mask: 7.447  loss_dice: 0.4794  loss_ce_0: 2.491  loss_mask_0: 6.375  loss_dice_0: 0.4614  loss_ce_1: 2.082  loss_mask_1: 6.942  loss_dice_1: 0.4717  loss_ce_2: 2.089  loss_mask_2: 6.813  loss_dice_2: 0.4786  loss_ce_3: 2.059  loss_mask_3: 7.016  loss_dice_3: 0.4843  loss_ce_4: 2.07  loss_mask_4: 7.124  loss_dice_4: 0.4821  loss_ce_5: 2.065  loss_mask_5: 7.366  loss_dice_5: 0.4778  loss_ce_6: 2.091  loss_mask_6: 7.234  loss_dice_6: 0.4783  loss_ce_7: 2.062  loss_mask_7: 7.367  loss_dice_7: 0.479  loss_ce_8: 2.053  loss_mask_8: 7.395  loss_dice_8: 0.4792  time: 2.7870  data_time: 0.4306  lr: 9.835e-05  max_mem: 23006M
[01/24 14:25:34] d2.utils.events INFO:  eta: 1 day, 20:38:09  iter: 1119  total_loss: 92.52  loss_ce: 2.042  loss_mask: 6.882  loss_dice: 0.479  loss_ce_0: 2.491  loss_mask_0: 6.083  loss_dice_0: 0.4602  loss_ce_1: 2.072  loss_mask_1: 6.51  loss_dice_1: 0.4742  loss_ce_2: 2.11  loss_mask_2: 6.69  loss_dice_2: 0.4753  loss_ce_3: 2.072  loss_mask_3: 6.886  loss_dice_3: 0.4795  loss_ce_4: 2.062  loss_mask_4: 6.527  loss_dice_4: 0.4796  loss_ce_5: 2.068  loss_mask_5: 6.866  loss_dice_5: 0.4831  loss_ce_6: 2.071  loss_mask_6: 7.319  loss_dice_6: 0.4819  loss_ce_7: 2.06  loss_mask_7: 6.959  loss_dice_7: 0.4762  loss_ce_8: 2.051  loss_mask_8: 6.831  loss_dice_8: 0.4774  time: 2.7852  data_time: 0.3686  lr: 9.832e-05  max_mem: 23006M
[01/24 14:26:30] d2.utils.events INFO:  eta: 1 day, 20:39:24  iter: 1139  total_loss: 95.49  loss_ce: 2.067  loss_mask: 7.072  loss_dice: 0.4759  loss_ce_0: 2.49  loss_mask_0: 6.429  loss_dice_0: 0.4626  loss_ce_1: 2.102  loss_mask_1: 6.72  loss_dice_1: 0.4734  loss_ce_2: 2.149  loss_mask_2: 7.155  loss_dice_2: 0.4755  loss_ce_3: 2.083  loss_mask_3: 6.937  loss_dice_3: 0.4828  loss_ce_4: 2.102  loss_mask_4: 6.924  loss_dice_4: 0.4773  loss_ce_5: 2.08  loss_mask_5: 7.178  loss_dice_5: 0.4813  loss_ce_6: 2.09  loss_mask_6: 7.327  loss_dice_6: 0.4821  loss_ce_7: 2.094  loss_mask_7: 6.748  loss_dice_7: 0.4771  loss_ce_8: 2.089  loss_mask_8: 6.629  loss_dice_8: 0.4757  time: 2.7853  data_time: 0.3549  lr: 9.829e-05  max_mem: 23006M
[01/24 14:27:26] d2.utils.events INFO:  eta: 1 day, 20:39:49  iter: 1159  total_loss: 98.5  loss_ce: 2.06  loss_mask: 7.018  loss_dice: 0.4767  loss_ce_0: 2.489  loss_mask_0: 6.398  loss_dice_0: 0.4601  loss_ce_1: 2.089  loss_mask_1: 6.699  loss_dice_1: 0.4709  loss_ce_2: 2.116  loss_mask_2: 7.451  loss_dice_2: 0.4803  loss_ce_3: 2.069  loss_mask_3: 7.496  loss_dice_3: 0.4839  loss_ce_4: 2.088  loss_mask_4: 7.359  loss_dice_4: 0.4797  loss_ce_5: 2.072  loss_mask_5: 7.476  loss_dice_5: 0.4795  loss_ce_6: 2.089  loss_mask_6: 7.27  loss_dice_6: 0.4792  loss_ce_7: 2.062  loss_mask_7: 6.983  loss_dice_7: 0.4794  loss_ce_8: 2.08  loss_mask_8: 7.113  loss_dice_8: 0.4768  time: 2.7856  data_time: 0.3968  lr: 9.826e-05  max_mem: 23006M
[01/24 14:28:20] d2.utils.events INFO:  eta: 1 day, 20:36:18  iter: 1179  total_loss: 95.67  loss_ce: 2.101  loss_mask: 7.288  loss_dice: 0.4764  loss_ce_0: 2.489  loss_mask_0: 6.546  loss_dice_0: 0.4622  loss_ce_1: 2.138  loss_mask_1: 6.394  loss_dice_1: 0.469  loss_ce_2: 2.119  loss_mask_2: 7.059  loss_dice_2: 0.48  loss_ce_3: 2.079  loss_mask_3: 7.249  loss_dice_3: 0.4817  loss_ce_4: 2.101  loss_mask_4: 6.971  loss_dice_4: 0.4822  loss_ce_5: 2.085  loss_mask_5: 6.906  loss_dice_5: 0.4811  loss_ce_6: 2.1  loss_mask_6: 6.986  loss_dice_6: 0.4781  loss_ce_7: 2.083  loss_mask_7: 7.091  loss_dice_7: 0.4786  loss_ce_8: 2.105  loss_mask_8: 7.149  loss_dice_8: 0.479  time: 2.7846  data_time: 0.3878  lr: 9.823e-05  max_mem: 23006M
[01/24 14:29:18] d2.utils.events INFO:  eta: 1 day, 20:41:21  iter: 1199  total_loss: 92.08  loss_ce: 2.078  loss_mask: 6.735  loss_dice: 0.4734  loss_ce_0: 2.493  loss_mask_0: 6.125  loss_dice_0: 0.4627  loss_ce_1: 2.106  loss_mask_1: 6.402  loss_dice_1: 0.4787  loss_ce_2: 2.078  loss_mask_2: 6.689  loss_dice_2: 0.4778  loss_ce_3: 2.056  loss_mask_3: 7.075  loss_dice_3: 0.4781  loss_ce_4: 2.075  loss_mask_4: 7.079  loss_dice_4: 0.4781  loss_ce_5: 2.084  loss_mask_5: 6.953  loss_dice_5: 0.4786  loss_ce_6: 2.123  loss_mask_6: 7.202  loss_dice_6: 0.4797  loss_ce_7: 2.067  loss_mask_7: 6.567  loss_dice_7: 0.4748  loss_ce_8: 2.079  loss_mask_8: 6.599  loss_dice_8: 0.4747  time: 2.7864  data_time: 0.4007  lr: 9.82e-05  max_mem: 23006M
[01/24 14:30:12] d2.utils.events INFO:  eta: 1 day, 20:39:12  iter: 1219  total_loss: 97.79  loss_ce: 2.112  loss_mask: 7.25  loss_dice: 0.4788  loss_ce_0: 2.485  loss_mask_0: 6.223  loss_dice_0: 0.4593  loss_ce_1: 2.135  loss_mask_1: 6.54  loss_dice_1: 0.475  loss_ce_2: 2.132  loss_mask_2: 6.921  loss_dice_2: 0.4806  loss_ce_3: 2.097  loss_mask_3: 7.028  loss_dice_3: 0.4781  loss_ce_4: 2.132  loss_mask_4: 7.18  loss_dice_4: 0.4775  loss_ce_5: 2.165  loss_mask_5: 7.19  loss_dice_5: 0.4795  loss_ce_6: 2.122  loss_mask_6: 7.559  loss_dice_6: 0.4849  loss_ce_7: 2.089  loss_mask_7: 7.045  loss_dice_7: 0.4825  loss_ce_8: 2.124  loss_mask_8: 7.421  loss_dice_8: 0.4797  time: 2.7846  data_time: 0.3545  lr: 9.817e-05  max_mem: 23006M
[01/24 14:31:07] d2.utils.events INFO:  eta: 1 day, 20:36:12  iter: 1239  total_loss: 90.54  loss_ce: 2.056  loss_mask: 6.721  loss_dice: 0.4794  loss_ce_0: 2.487  loss_mask_0: 5.933  loss_dice_0: 0.4597  loss_ce_1: 2.148  loss_mask_1: 6.239  loss_dice_1: 0.4774  loss_ce_2: 2.115  loss_mask_2: 6.45  loss_dice_2: 0.4788  loss_ce_3: 2.069  loss_mask_3: 6.653  loss_dice_3: 0.4759  loss_ce_4: 2.112  loss_mask_4: 6.617  loss_dice_4: 0.472  loss_ce_5: 2.173  loss_mask_5: 6.922  loss_dice_5: 0.4809  loss_ce_6: 2.129  loss_mask_6: 6.709  loss_dice_6: 0.4838  loss_ce_7: 2.079  loss_mask_7: 6.763  loss_dice_7: 0.4794  loss_ce_8: 2.085  loss_mask_8: 6.483  loss_dice_8: 0.475  time: 2.7844  data_time: 0.3779  lr: 9.814e-05  max_mem: 23006M
[01/24 14:32:04] d2.utils.events INFO:  eta: 1 day, 20:39:40  iter: 1259  total_loss: 94.6  loss_ce: 2.109  loss_mask: 6.931  loss_dice: 0.4753  loss_ce_0: 2.492  loss_mask_0: 5.973  loss_dice_0: 0.4572  loss_ce_1: 2.211  loss_mask_1: 6.525  loss_dice_1: 0.4727  loss_ce_2: 2.163  loss_mask_2: 6.992  loss_dice_2: 0.4731  loss_ce_3: 2.138  loss_mask_3: 6.764  loss_dice_3: 0.4736  loss_ce_4: 2.157  loss_mask_4: 7.03  loss_dice_4: 0.4732  loss_ce_5: 2.177  loss_mask_5: 7.533  loss_dice_5: 0.4732  loss_ce_6: 2.163  loss_mask_6: 7.047  loss_dice_6: 0.4688  loss_ce_7: 2.118  loss_mask_7: 6.977  loss_dice_7: 0.4711  loss_ce_8: 2.17  loss_mask_8: 6.602  loss_dice_8: 0.4713  time: 2.7849  data_time: 0.3827  lr: 9.811e-05  max_mem: 23006M
[01/24 14:32:57] d2.utils.events INFO:  eta: 1 day, 20:34:51  iter: 1279  total_loss: 94.51  loss_ce: 2.064  loss_mask: 6.804  loss_dice: 0.479  loss_ce_0: 2.49  loss_mask_0: 5.902  loss_dice_0: 0.4553  loss_ce_1: 2.168  loss_mask_1: 6.779  loss_dice_1: 0.4685  loss_ce_2: 2.109  loss_mask_2: 6.669  loss_dice_2: 0.4749  loss_ce_3: 2.085  loss_mask_3: 6.754  loss_dice_3: 0.4755  loss_ce_4: 2.095  loss_mask_4: 6.981  loss_dice_4: 0.4776  loss_ce_5: 2.117  loss_mask_5: 6.745  loss_dice_5: 0.4735  loss_ce_6: 2.117  loss_mask_6: 7.294  loss_dice_6: 0.472  loss_ce_7: 2.098  loss_mask_7: 7.168  loss_dice_7: 0.4764  loss_ce_8: 2.122  loss_mask_8: 6.903  loss_dice_8: 0.4775  time: 2.7829  data_time: 0.3622  lr: 9.8079e-05  max_mem: 23006M
[01/24 14:33:54] d2.utils.events INFO:  eta: 1 day, 20:37:13  iter: 1299  total_loss: 89.29  loss_ce: 2.058  loss_mask: 6.332  loss_dice: 0.4754  loss_ce_0: 2.488  loss_mask_0: 5.693  loss_dice_0: 0.4552  loss_ce_1: 2.133  loss_mask_1: 6.209  loss_dice_1: 0.4663  loss_ce_2: 2.079  loss_mask_2: 6.367  loss_dice_2: 0.4711  loss_ce_3: 2.033  loss_mask_3: 6.495  loss_dice_3: 0.4752  loss_ce_4: 2.073  loss_mask_4: 6.482  loss_dice_4: 0.475  loss_ce_5: 2.114  loss_mask_5: 6.507  loss_dice_5: 0.4722  loss_ce_6: 2.097  loss_mask_6: 6.523  loss_dice_6: 0.476  loss_ce_7: 2.086  loss_mask_7: 6.499  loss_dice_7: 0.4767  loss_ce_8: 2.193  loss_mask_8: 6.202  loss_dice_8: 0.4704  time: 2.7841  data_time: 0.4008  lr: 9.8049e-05  max_mem: 23006M
[01/24 14:34:46] d2.utils.events INFO:  eta: 1 day, 20:29:56  iter: 1319  total_loss: 86.9  loss_ce: 2.174  loss_mask: 6.204  loss_dice: 0.4714  loss_ce_0: 2.481  loss_mask_0: 5.277  loss_dice_0: 0.4531  loss_ce_1: 2.124  loss_mask_1: 5.806  loss_dice_1: 0.4636  loss_ce_2: 2.104  loss_mask_2: 6.212  loss_dice_2: 0.466  loss_ce_3: 2.2  loss_mask_3: 6.146  loss_dice_3: 0.4684  loss_ce_4: 2.268  loss_mask_4: 6.125  loss_dice_4: 0.4668  loss_ce_5: 2.256  loss_mask_5: 6.144  loss_dice_5: 0.4604  loss_ce_6: 2.177  loss_mask_6: 6.235  loss_dice_6: 0.4592  loss_ce_7: 2.176  loss_mask_7: 6.25  loss_dice_7: 0.4685  loss_ce_8: 2.264  loss_mask_8: 6.297  loss_dice_8: 0.467  time: 2.7810  data_time: 0.3511  lr: 9.8019e-05  max_mem: 23006M
[01/24 14:35:40] d2.utils.events INFO:  eta: 1 day, 20:25:22  iter: 1339  total_loss: 91.79  loss_ce: 2.076  loss_mask: 6.614  loss_dice: 0.4751  loss_ce_0: 2.485  loss_mask_0: 5.452  loss_dice_0: 0.4484  loss_ce_1: 2.085  loss_mask_1: 6.459  loss_dice_1: 0.4669  loss_ce_2: 2.11  loss_mask_2: 6.465  loss_dice_2: 0.4714  loss_ce_3: 2.144  loss_mask_3: 6.728  loss_dice_3: 0.4766  loss_ce_4: 2.196  loss_mask_4: 6.638  loss_dice_4: 0.4753  loss_ce_5: 2.142  loss_mask_5: 6.409  loss_dice_5: 0.4586  loss_ce_6: 2.158  loss_mask_6: 6.577  loss_dice_6: 0.4543  loss_ce_7: 2.091  loss_mask_7: 6.701  loss_dice_7: 0.4724  loss_ce_8: 2.09  loss_mask_8: 6.525  loss_dice_8: 0.4731  time: 2.7801  data_time: 0.3643  lr: 9.7989e-05  max_mem: 23006M
[01/24 14:36:45] d2.utils.events INFO:  eta: 1 day, 20:28:06  iter: 1359  total_loss: 94.73  loss_ce: 2.169  loss_mask: 7.192  loss_dice: 0.4635  loss_ce_0: 2.472  loss_mask_0: 5.537  loss_dice_0: 0.4481  loss_ce_1: 2.104  loss_mask_1: 6.734  loss_dice_1: 0.465  loss_ce_2: 2.16  loss_mask_2: 6.848  loss_dice_2: 0.4661  loss_ce_3: 2.311  loss_mask_3: 6.886  loss_dice_3: 0.4707  loss_ce_4: 2.324  loss_mask_4: 7.207  loss_dice_4: 0.4751  loss_ce_5: 2.171  loss_mask_5: 7.363  loss_dice_5: 0.4656  loss_ce_6: 2.165  loss_mask_6: 6.701  loss_dice_6: 0.4628  loss_ce_7: 2.113  loss_mask_7: 7.708  loss_dice_7: 0.4757  loss_ce_8: 2.12  loss_mask_8: 6.763  loss_dice_8: 0.4636  time: 2.7864  data_time: 0.4616  lr: 9.7959e-05  max_mem: 23006M
[01/24 14:37:44] d2.utils.events INFO:  eta: 1 day, 20:29:47  iter: 1379  total_loss: 102.2  loss_ce: 2.123  loss_mask: 7.824  loss_dice: 0.4718  loss_ce_0: 2.448  loss_mask_0: 5.993  loss_dice_0: 0.4519  loss_ce_1: 2.105  loss_mask_1: 7.298  loss_dice_1: 0.4696  loss_ce_2: 2.16  loss_mask_2: 7.068  loss_dice_2: 0.4615  loss_ce_3: 2.255  loss_mask_3: 7.683  loss_dice_3: 0.4715  loss_ce_4: 2.239  loss_mask_4: 7.458  loss_dice_4: 0.4786  loss_ce_5: 2.186  loss_mask_5: 7.331  loss_dice_5: 0.4615  loss_ce_6: 2.144  loss_mask_6: 7.143  loss_dice_6: 0.4598  loss_ce_7: 2.131  loss_mask_7: 7.865  loss_dice_7: 0.4745  loss_ce_8: 2.167  loss_mask_8: 7.073  loss_dice_8: 0.4671  time: 2.7891  data_time: 0.4088  lr: 9.7929e-05  max_mem: 23006M
[01/24 14:38:48] d2.utils.events INFO:  eta: 1 day, 20:33:09  iter: 1399  total_loss: 98.06  loss_ce: 2.168  loss_mask: 7.825  loss_dice: 0.4652  loss_ce_0: 2.449  loss_mask_0: 5.971  loss_dice_0: 0.4532  loss_ce_1: 2.104  loss_mask_1: 7.055  loss_dice_1: 0.4643  loss_ce_2: 2.109  loss_mask_2: 6.963  loss_dice_2: 0.4693  loss_ce_3: 2.162  loss_mask_3: 7.419  loss_dice_3: 0.4765  loss_ce_4: 2.208  loss_mask_4: 7.303  loss_dice_4: 0.4693  loss_ce_5: 2.186  loss_mask_5: 7.278  loss_dice_5: 0.461  loss_ce_6: 2.151  loss_mask_6: 7.071  loss_dice_6: 0.4563  loss_ce_7: 2.119  loss_mask_7: 7.22  loss_dice_7: 0.4623  loss_ce_8: 2.166  loss_mask_8: 7.335  loss_dice_8: 0.4614  time: 2.7948  data_time: 0.4940  lr: 9.7899e-05  max_mem: 23006M
[01/24 14:39:48] d2.utils.events INFO:  eta: 1 day, 20:38:18  iter: 1419  total_loss: 95.12  loss_ce: 2.232  loss_mask: 7.173  loss_dice: 0.4627  loss_ce_0: 2.459  loss_mask_0: 6  loss_dice_0: 0.4566  loss_ce_1: 2.115  loss_mask_1: 6.179  loss_dice_1: 0.4594  loss_ce_2: 2.13  loss_mask_2: 6.623  loss_dice_2: 0.4691  loss_ce_3: 2.218  loss_mask_3: 6.886  loss_dice_3: 0.4717  loss_ce_4: 2.232  loss_mask_4: 7.359  loss_dice_4: 0.4655  loss_ce_5: 2.169  loss_mask_5: 6.886  loss_dice_5: 0.4598  loss_ce_6: 2.177  loss_mask_6: 7.158  loss_dice_6: 0.4638  loss_ce_7: 2.155  loss_mask_7: 7  loss_dice_7: 0.4633  loss_ce_8: 2.301  loss_mask_8: 6.821  loss_dice_8: 0.4611  time: 2.7976  data_time: 0.4015  lr: 9.7869e-05  max_mem: 23006M
[01/24 14:40:43] d2.utils.events INFO:  eta: 1 day, 20:37:23  iter: 1439  total_loss: 99.61  loss_ce: 2.137  loss_mask: 8.286  loss_dice: 0.4762  loss_ce_0: 2.458  loss_mask_0: 5.873  loss_dice_0: 0.4566  loss_ce_1: 2.088  loss_mask_1: 6.862  loss_dice_1: 0.4722  loss_ce_2: 2.1  loss_mask_2: 7.012  loss_dice_2: 0.4733  loss_ce_3: 2.192  loss_mask_3: 6.98  loss_dice_3: 0.4714  loss_ce_4: 2.169  loss_mask_4: 7.412  loss_dice_4: 0.4748  loss_ce_5: 2.174  loss_mask_5: 7.326  loss_dice_5: 0.4795  loss_ce_6: 2.144  loss_mask_6: 7.32  loss_dice_6: 0.4717  loss_ce_7: 2.105  loss_mask_7: 7.438  loss_dice_7: 0.4737  loss_ce_8: 2.171  loss_mask_8: 8.088  loss_dice_8: 0.4713  time: 2.7973  data_time: 0.3814  lr: 9.7839e-05  max_mem: 23006M
[01/24 14:41:42] d2.utils.events INFO:  eta: 1 day, 20:40:07  iter: 1459  total_loss: 97.66  loss_ce: 2.131  loss_mask: 7.566  loss_dice: 0.4717  loss_ce_0: 2.441  loss_mask_0: 6.078  loss_dice_0: 0.4564  loss_ce_1: 2.166  loss_mask_1: 6.705  loss_dice_1: 0.4684  loss_ce_2: 2.134  loss_mask_2: 6.972  loss_dice_2: 0.4674  loss_ce_3: 2.274  loss_mask_3: 7.066  loss_dice_3: 0.4718  loss_ce_4: 2.291  loss_mask_4: 7.013  loss_dice_4: 0.4701  loss_ce_5: 2.29  loss_mask_5: 7.08  loss_dice_5: 0.4666  loss_ce_6: 2.225  loss_mask_6: 7.246  loss_dice_6: 0.4618  loss_ce_7: 2.221  loss_mask_7: 7.42  loss_dice_7: 0.4641  loss_ce_8: 2.189  loss_mask_8: 7.507  loss_dice_8: 0.4598  time: 2.7992  data_time: 0.4201  lr: 9.7809e-05  max_mem: 23006M
[01/24 14:42:36] d2.utils.events INFO:  eta: 1 day, 20:34:09  iter: 1479  total_loss: 94.7  loss_ce: 2.167  loss_mask: 7.207  loss_dice: 0.4724  loss_ce_0: 2.456  loss_mask_0: 5.384  loss_dice_0: 0.4536  loss_ce_1: 2.146  loss_mask_1: 6.076  loss_dice_1: 0.4617  loss_ce_2: 2.284  loss_mask_2: 6.379  loss_dice_2: 0.4701  loss_ce_3: 2.492  loss_mask_3: 6.896  loss_dice_3: 0.4751  loss_ce_4: 2.401  loss_mask_4: 7.427  loss_dice_4: 0.4754  loss_ce_5: 2.292  loss_mask_5: 7.101  loss_dice_5: 0.4682  loss_ce_6: 2.198  loss_mask_6: 7.511  loss_dice_6: 0.4709  loss_ce_7: 2.401  loss_mask_7: 6.244  loss_dice_7: 0.4561  loss_ce_8: 2.328  loss_mask_8: 6.896  loss_dice_8: 0.4672  time: 2.7975  data_time: 0.3746  lr: 9.7779e-05  max_mem: 23006M
[01/24 14:43:33] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 14:43:34] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 14:43:34] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 14:50:39] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 28.716856931444454, 'error_1pix': 0.9698016651742078, 'error_3pix': 0.9312098185102237, 'mIoU': 0.0455701689969825, 'fwIoU': 0.10243880398082712, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 1.822738184945264e-05, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.658001891709446, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.21176523913824247, 'IoU-24': 0.0014873679697538767, 'IoU-25': 0.1364145251641051, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 1.0043945171342432, 'IoU-29': 0.0, 'IoU-30': 0.3947774784226333, 'IoU-31': 0.4635083686218204, 'IoU-32': 0.051290590255829334, 'IoU-33': 0.3477696373921914, 'IoU-34': 0.0, 'IoU-35': 1.9624759969081689, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.8352509655854382, 'IoU-47': 0.010858934977858238, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.013683009910661894, 'IoU-61': 0.000843006696060613, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.4537577092710291, 'IoU-65': 0.0, 'IoU-66': 0.05844571968705423, 'IoU-67': 0.0, 'IoU-68': 0.24406160143079786, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 2.117225033603008e-05, 'IoU-77': 0.0, 'IoU-78': 1.104001250451506, 'IoU-79': 0.07815391540383426, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.010510443077485948, 'IoU-87': 0.615822919687119, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.09214326711277107, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 1.469178040430898e-05, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5874386951939207, 'pACC': 0.9965015784520612, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 1.8227756177999222e-05, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.9911847068236369, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.28906975505162663, 'ACC-24': 0.0014966709827955488, 'ACC-25': 0.1428216964558859, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 2.1377165579687833, 'ACC-29': 0.0, 'ACC-30': 0.554018460793485, 'ACC-31': 1.3874527939634946, 'ACC-32': 0.054388543438914, 'ACC-33': 0.6598536444616584, 'ACC-34': 0.0, 'ACC-35': 30.478235323326132, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 10.292456188361752, 'ACC-47': 0.010918443910019582, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.014011386560499037, 'ACC-61': 0.0008430515192956964, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 47.30195360280119, 'ACC-65': 0.0, 'ACC-66': 0.059126397008051, 'ACC-67': 0.0, 'ACC-68': 0.29439237063040485, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 2.1181423552641557e-05, 'ACC-77': 0.0, 'ACC-78': 16.8845015044014, 'ACC-79': 0.08029509030440962, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.010601291246760468, 'ACC-87': 1.035197599269445, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.10764025670045292, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 1.4732072945564549e-05, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 14:50:39] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 14:50:39] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 14:50:39] d2.evaluation.testing INFO: copypaste: 28.7169,0.9698,0.9312,0.0456,0.1024,0.5874,0.9965
[01/24 14:50:39] d2.utils.events INFO:  eta: 1 day, 20:36:13  iter: 1499  total_loss: 99.66  loss_ce: 2.18  loss_mask: 7.56  loss_dice: 0.4793  loss_ce_0: 2.452  loss_mask_0: 5.718  loss_dice_0: 0.4544  loss_ce_1: 2.145  loss_mask_1: 6.636  loss_dice_1: 0.4675  loss_ce_2: 2.177  loss_mask_2: 6.558  loss_dice_2: 0.4763  loss_ce_3: 2.353  loss_mask_3: 7.158  loss_dice_3: 0.4766  loss_ce_4: 2.313  loss_mask_4: 6.91  loss_dice_4: 0.4743  loss_ce_5: 2.246  loss_mask_5: 7.135  loss_dice_5: 0.4794  loss_ce_6: 2.201  loss_mask_6: 6.865  loss_dice_6: 0.4621  loss_ce_7: 2.338  loss_mask_7: 8.904  loss_dice_7: 0.4795  loss_ce_8: 2.241  loss_mask_8: 7.528  loss_dice_8: 0.4747  time: 2.7986  data_time: 0.4151  lr: 9.7749e-05  max_mem: 23006M
[01/24 14:51:34] d2.utils.events INFO:  eta: 1 day, 20:36:12  iter: 1519  total_loss: 93.63  loss_ce: 2.19  loss_mask: 7.193  loss_dice: 0.4744  loss_ce_0: 2.454  loss_mask_0: 5.29  loss_dice_0: 0.4557  loss_ce_1: 2.14  loss_mask_1: 6.213  loss_dice_1: 0.4708  loss_ce_2: 2.181  loss_mask_2: 6.34  loss_dice_2: 0.4767  loss_ce_3: 2.324  loss_mask_3: 6.745  loss_dice_3: 0.4768  loss_ce_4: 2.27  loss_mask_4: 6.633  loss_dice_4: 0.4762  loss_ce_5: 2.223  loss_mask_5: 6.582  loss_dice_5: 0.4737  loss_ce_6: 2.202  loss_mask_6: 6.195  loss_dice_6: 0.4613  loss_ce_7: 2.325  loss_mask_7: 7.596  loss_dice_7: 0.4871  loss_ce_8: 2.248  loss_mask_8: 7.286  loss_dice_8: 0.4746  time: 2.7983  data_time: 0.3614  lr: 9.7719e-05  max_mem: 23006M
[01/24 14:52:30] d2.utils.events INFO:  eta: 1 day, 20:33:13  iter: 1539  total_loss: 93.95  loss_ce: 2.174  loss_mask: 6.837  loss_dice: 0.4794  loss_ce_0: 2.459  loss_mask_0: 5.552  loss_dice_0: 0.4535  loss_ce_1: 2.128  loss_mask_1: 6.038  loss_dice_1: 0.4735  loss_ce_2: 2.128  loss_mask_2: 6.307  loss_dice_2: 0.4766  loss_ce_3: 2.228  loss_mask_3: 6.841  loss_dice_3: 0.4787  loss_ce_4: 2.211  loss_mask_4: 6.586  loss_dice_4: 0.477  loss_ce_5: 2.115  loss_mask_5: 6.594  loss_dice_5: 0.4743  loss_ce_6: 2.191  loss_mask_6: 6.954  loss_dice_6: 0.4752  loss_ce_7: 2.231  loss_mask_7: 7.24  loss_dice_7: 0.4871  loss_ce_8: 2.245  loss_mask_8: 7.037  loss_dice_8: 0.4747  time: 2.7979  data_time: 0.3620  lr: 9.7689e-05  max_mem: 23006M
[01/24 14:53:26] d2.utils.events INFO:  eta: 1 day, 20:35:32  iter: 1559  total_loss: 91.69  loss_ce: 2.18  loss_mask: 6.921  loss_dice: 0.4792  loss_ce_0: 2.454  loss_mask_0: 5.185  loss_dice_0: 0.4486  loss_ce_1: 2.111  loss_mask_1: 5.958  loss_dice_1: 0.4662  loss_ce_2: 2.15  loss_mask_2: 6.088  loss_dice_2: 0.4717  loss_ce_3: 2.22  loss_mask_3: 6.275  loss_dice_3: 0.4742  loss_ce_4: 2.237  loss_mask_4: 6.692  loss_dice_4: 0.4746  loss_ce_5: 2.178  loss_mask_5: 6.321  loss_dice_5: 0.4731  loss_ce_6: 2.177  loss_mask_6: 6.945  loss_dice_6: 0.4777  loss_ce_7: 2.167  loss_mask_7: 7.612  loss_dice_7: 0.4859  loss_ce_8: 2.263  loss_mask_8: 6.948  loss_dice_8: 0.4728  time: 2.7980  data_time: 0.4124  lr: 9.7658e-05  max_mem: 23006M
[01/24 14:54:19] d2.utils.events INFO:  eta: 1 day, 20:29:47  iter: 1579  total_loss: 99.02  loss_ce: 2.204  loss_mask: 7.413  loss_dice: 0.4829  loss_ce_0: 2.456  loss_mask_0: 5.912  loss_dice_0: 0.4539  loss_ce_1: 2.177  loss_mask_1: 6.435  loss_dice_1: 0.4728  loss_ce_2: 2.202  loss_mask_2: 7.021  loss_dice_2: 0.4825  loss_ce_3: 2.211  loss_mask_3: 7.244  loss_dice_3: 0.4843  loss_ce_4: 2.201  loss_mask_4: 7.463  loss_dice_4: 0.4845  loss_ce_5: 2.232  loss_mask_5: 7.596  loss_dice_5: 0.4835  loss_ce_6: 2.173  loss_mask_6: 7.578  loss_dice_6: 0.4866  loss_ce_7: 2.199  loss_mask_7: 7.966  loss_dice_7: 0.4865  loss_ce_8: 2.219  loss_mask_8: 7.09  loss_dice_8: 0.486  time: 2.7960  data_time: 0.3257  lr: 9.7628e-05  max_mem: 23006M
[01/24 14:55:16] d2.utils.events INFO:  eta: 1 day, 20:29:24  iter: 1599  total_loss: 95.96  loss_ce: 2.17  loss_mask: 7.149  loss_dice: 0.4877  loss_ce_0: 2.45  loss_mask_0: 6.199  loss_dice_0: 0.4582  loss_ce_1: 2.178  loss_mask_1: 6.717  loss_dice_1: 0.4849  loss_ce_2: 2.158  loss_mask_2: 6.893  loss_dice_2: 0.4879  loss_ce_3: 2.132  loss_mask_3: 6.972  loss_dice_3: 0.4881  loss_ce_4: 2.159  loss_mask_4: 6.693  loss_dice_4: 0.4878  loss_ce_5: 2.167  loss_mask_5: 6.945  loss_dice_5: 0.4878  loss_ce_6: 2.159  loss_mask_6: 6.923  loss_dice_6: 0.4854  loss_ce_7: 2.175  loss_mask_7: 7.052  loss_dice_7: 0.4871  loss_ce_8: 2.173  loss_mask_8: 6.762  loss_dice_8: 0.4889  time: 2.7965  data_time: 0.3960  lr: 9.7598e-05  max_mem: 23006M
[01/24 14:56:12] d2.utils.events INFO:  eta: 1 day, 20:31:37  iter: 1619  total_loss: 89.92  loss_ce: 2.154  loss_mask: 6.568  loss_dice: 0.4881  loss_ce_0: 2.447  loss_mask_0: 5.802  loss_dice_0: 0.4578  loss_ce_1: 2.126  loss_mask_1: 6.384  loss_dice_1: 0.4891  loss_ce_2: 2.093  loss_mask_2: 6.504  loss_dice_2: 0.4895  loss_ce_3: 2.089  loss_mask_3: 6.518  loss_dice_3: 0.4893  loss_ce_4: 2.091  loss_mask_4: 6.656  loss_dice_4: 0.4898  loss_ce_5: 2.087  loss_mask_5: 6.417  loss_dice_5: 0.4902  loss_ce_6: 2.125  loss_mask_6: 6.442  loss_dice_6: 0.4853  loss_ce_7: 2.142  loss_mask_7: 6.699  loss_dice_7: 0.4885  loss_ce_8: 2.148  loss_mask_8: 6.628  loss_dice_8: 0.4898  time: 2.7968  data_time: 0.3820  lr: 9.7568e-05  max_mem: 23006M
[01/24 14:57:05] d2.utils.events INFO:  eta: 1 day, 20:32:25  iter: 1639  total_loss: 88.67  loss_ce: 2.092  loss_mask: 6.291  loss_dice: 0.488  loss_ce_0: 2.444  loss_mask_0: 5.793  loss_dice_0: 0.4525  loss_ce_1: 2.088  loss_mask_1: 6.366  loss_dice_1: 0.4898  loss_ce_2: 2.063  loss_mask_2: 6.168  loss_dice_2: 0.4896  loss_ce_3: 2.066  loss_mask_3: 6.165  loss_dice_3: 0.4901  loss_ce_4: 2.078  loss_mask_4: 6.264  loss_dice_4: 0.4896  loss_ce_5: 2.071  loss_mask_5: 6.16  loss_dice_5: 0.4891  loss_ce_6: 2.091  loss_mask_6: 6.58  loss_dice_6: 0.4857  loss_ce_7: 2.111  loss_mask_7: 6.22  loss_dice_7: 0.4887  loss_ce_8: 2.09  loss_mask_8: 6.059  loss_dice_8: 0.49  time: 2.7950  data_time: 0.3488  lr: 9.7538e-05  max_mem: 23006M
[01/24 14:58:03] d2.utils.events INFO:  eta: 1 day, 20:41:58  iter: 1659  total_loss: 91.83  loss_ce: 2.103  loss_mask: 6.621  loss_dice: 0.485  loss_ce_0: 2.436  loss_mask_0: 5.744  loss_dice_0: 0.452  loss_ce_1: 2.132  loss_mask_1: 6.533  loss_dice_1: 0.4865  loss_ce_2: 2.106  loss_mask_2: 6.589  loss_dice_2: 0.4873  loss_ce_3: 2.093  loss_mask_3: 6.56  loss_dice_3: 0.484  loss_ce_4: 2.105  loss_mask_4: 6.593  loss_dice_4: 0.4833  loss_ce_5: 2.112  loss_mask_5: 6.502  loss_dice_5: 0.4768  loss_ce_6: 2.125  loss_mask_6: 6.908  loss_dice_6: 0.4857  loss_ce_7: 2.129  loss_mask_7: 6.617  loss_dice_7: 0.4868  loss_ce_8: 2.113  loss_mask_8: 6.621  loss_dice_8: 0.4867  time: 2.7965  data_time: 0.4359  lr: 9.7508e-05  max_mem: 23006M
[01/24 14:58:57] d2.utils.events INFO:  eta: 1 day, 20:42:32  iter: 1679  total_loss: 89.45  loss_ce: 2.104  loss_mask: 6.488  loss_dice: 0.4857  loss_ce_0: 2.425  loss_mask_0: 5.668  loss_dice_0: 0.4493  loss_ce_1: 2.103  loss_mask_1: 6.153  loss_dice_1: 0.484  loss_ce_2: 2.092  loss_mask_2: 6.329  loss_dice_2: 0.4872  loss_ce_3: 2.092  loss_mask_3: 6.344  loss_dice_3: 0.4834  loss_ce_4: 2.111  loss_mask_4: 6.299  loss_dice_4: 0.4843  loss_ce_5: 2.135  loss_mask_5: 6.178  loss_dice_5: 0.4832  loss_ce_6: 2.189  loss_mask_6: 6.539  loss_dice_6: 0.4802  loss_ce_7: 2.125  loss_mask_7: 6.399  loss_dice_7: 0.4863  loss_ce_8: 2.117  loss_mask_8: 6.185  loss_dice_8: 0.4856  time: 2.7953  data_time: 0.3471  lr: 9.7478e-05  max_mem: 23006M
[01/24 14:59:54] d2.utils.events INFO:  eta: 1 day, 20:44:39  iter: 1699  total_loss: 88.34  loss_ce: 2.062  loss_mask: 6.13  loss_dice: 0.486  loss_ce_0: 2.414  loss_mask_0: 5.68  loss_dice_0: 0.4474  loss_ce_1: 2.071  loss_mask_1: 6.131  loss_dice_1: 0.4832  loss_ce_2: 2.077  loss_mask_2: 6.062  loss_dice_2: 0.4843  loss_ce_3: 2.089  loss_mask_3: 6.333  loss_dice_3: 0.4858  loss_ce_4: 2.098  loss_mask_4: 6.309  loss_dice_4: 0.486  loss_ce_5: 2.087  loss_mask_5: 6.099  loss_dice_5: 0.4852  loss_ce_6: 2.176  loss_mask_6: 6.847  loss_dice_6: 0.4813  loss_ce_7: 2.118  loss_mask_7: 6.403  loss_dice_7: 0.4872  loss_ce_8: 2.073  loss_mask_8: 5.944  loss_dice_8: 0.4869  time: 2.7955  data_time: 0.3871  lr: 9.7448e-05  max_mem: 23006M
[01/24 15:00:49] d2.utils.events INFO:  eta: 1 day, 20:48:08  iter: 1719  total_loss: 84.77  loss_ce: 2.044  loss_mask: 5.99  loss_dice: 0.4845  loss_ce_0: 2.4  loss_mask_0: 5.214  loss_dice_0: 0.4499  loss_ce_1: 2.07  loss_mask_1: 5.734  loss_dice_1: 0.481  loss_ce_2: 2.059  loss_mask_2: 5.91  loss_dice_2: 0.4823  loss_ce_3: 2.068  loss_mask_3: 6.129  loss_dice_3: 0.48  loss_ce_4: 2.064  loss_mask_4: 5.977  loss_dice_4: 0.4819  loss_ce_5: 2.057  loss_mask_5: 5.832  loss_dice_5: 0.4802  loss_ce_6: 2.12  loss_mask_6: 6.368  loss_dice_6: 0.4657  loss_ce_7: 2.072  loss_mask_7: 5.827  loss_dice_7: 0.4815  loss_ce_8: 2.065  loss_mask_8: 6.028  loss_dice_8: 0.484  time: 2.7951  data_time: 0.3674  lr: 9.7418e-05  max_mem: 23006M
[01/24 15:01:47] d2.utils.events INFO:  eta: 1 day, 20:50:12  iter: 1739  total_loss: 82.18  loss_ce: 2.055  loss_mask: 5.854  loss_dice: 0.4811  loss_ce_0: 2.389  loss_mask_0: 4.988  loss_dice_0: 0.4483  loss_ce_1: 2.07  loss_mask_1: 5.412  loss_dice_1: 0.4763  loss_ce_2: 2.108  loss_mask_2: 5.543  loss_dice_2: 0.4787  loss_ce_3: 2.09  loss_mask_3: 5.888  loss_dice_3: 0.4728  loss_ce_4: 2.07  loss_mask_4: 5.763  loss_dice_4: 0.4737  loss_ce_5: 2.088  loss_mask_5: 5.679  loss_dice_5: 0.478  loss_ce_6: 2.196  loss_mask_6: 5.903  loss_dice_6: 0.4513  loss_ce_7: 2.112  loss_mask_7: 5.802  loss_dice_7: 0.4731  loss_ce_8: 2.055  loss_mask_8: 5.775  loss_dice_8: 0.4806  time: 2.7964  data_time: 0.4318  lr: 9.7388e-05  max_mem: 23006M
[01/24 15:02:43] d2.utils.events INFO:  eta: 1 day, 20:51:38  iter: 1759  total_loss: 84.61  loss_ce: 2.075  loss_mask: 5.824  loss_dice: 0.4762  loss_ce_0: 2.377  loss_mask_0: 5.174  loss_dice_0: 0.445  loss_ce_1: 2.07  loss_mask_1: 6.152  loss_dice_1: 0.4706  loss_ce_2: 2.159  loss_mask_2: 6.04  loss_dice_2: 0.4722  loss_ce_3: 2.096  loss_mask_3: 5.987  loss_dice_3: 0.4686  loss_ce_4: 2.1  loss_mask_4: 5.948  loss_dice_4: 0.472  loss_ce_5: 2.083  loss_mask_5: 5.803  loss_dice_5: 0.4688  loss_ce_6: 2.147  loss_mask_6: 6.003  loss_dice_6: 0.4523  loss_ce_7: 2.089  loss_mask_7: 5.726  loss_dice_7: 0.4609  loss_ce_8: 2.078  loss_mask_8: 5.704  loss_dice_8: 0.4781  time: 2.7961  data_time: 0.3737  lr: 9.7358e-05  max_mem: 23006M
[01/24 15:03:38] d2.utils.events INFO:  eta: 1 day, 20:55:56  iter: 1779  total_loss: 85.44  loss_ce: 2.113  loss_mask: 5.828  loss_dice: 0.4776  loss_ce_0: 2.367  loss_mask_0: 5.15  loss_dice_0: 0.4452  loss_ce_1: 2.135  loss_mask_1: 6.038  loss_dice_1: 0.4697  loss_ce_2: 2.183  loss_mask_2: 5.976  loss_dice_2: 0.4703  loss_ce_3: 2.154  loss_mask_3: 6.102  loss_dice_3: 0.4734  loss_ce_4: 2.179  loss_mask_4: 6.016  loss_dice_4: 0.4776  loss_ce_5: 2.214  loss_mask_5: 6.216  loss_dice_5: 0.4643  loss_ce_6: 2.151  loss_mask_6: 6.07  loss_dice_6: 0.4547  loss_ce_7: 2.133  loss_mask_7: 6.184  loss_dice_7: 0.4623  loss_ce_8: 2.138  loss_mask_8: 5.998  loss_dice_8: 0.4792  time: 2.7959  data_time: 0.3873  lr: 9.7328e-05  max_mem: 23006M
[01/24 15:04:31] d2.utils.events INFO:  eta: 1 day, 20:57:44  iter: 1799  total_loss: 81.05  loss_ce: 2.07  loss_mask: 5.555  loss_dice: 0.4752  loss_ce_0: 2.376  loss_mask_0: 4.916  loss_dice_0: 0.4447  loss_ce_1: 2.091  loss_mask_1: 5.648  loss_dice_1: 0.4717  loss_ce_2: 2.088  loss_mask_2: 5.731  loss_dice_2: 0.477  loss_ce_3: 2.076  loss_mask_3: 5.491  loss_dice_3: 0.478  loss_ce_4: 2.112  loss_mask_4: 5.589  loss_dice_4: 0.4764  loss_ce_5: 2.151  loss_mask_5: 5.416  loss_dice_5: 0.4775  loss_ce_6: 2.071  loss_mask_6: 5.554  loss_dice_6: 0.4652  loss_ce_7: 2.053  loss_mask_7: 5.737  loss_dice_7: 0.4723  loss_ce_8: 2.058  loss_mask_8: 5.845  loss_dice_8: 0.4767  time: 2.7942  data_time: 0.3490  lr: 9.7297e-05  max_mem: 23006M
[01/24 15:05:22] d2.utils.events INFO:  eta: 1 day, 20:52:57  iter: 1819  total_loss: 82.03  loss_ce: 2.108  loss_mask: 5.9  loss_dice: 0.4764  loss_ce_0: 2.361  loss_mask_0: 4.903  loss_dice_0: 0.444  loss_ce_1: 2.095  loss_mask_1: 5.758  loss_dice_1: 0.4695  loss_ce_2: 2.106  loss_mask_2: 5.579  loss_dice_2: 0.4757  loss_ce_3: 2.097  loss_mask_3: 5.706  loss_dice_3: 0.4785  loss_ce_4: 2.108  loss_mask_4: 5.684  loss_dice_4: 0.4766  loss_ce_5: 2.103  loss_mask_5: 5.915  loss_dice_5: 0.4758  loss_ce_6: 2.082  loss_mask_6: 5.579  loss_dice_6: 0.464  loss_ce_7: 2.073  loss_mask_7: 5.748  loss_dice_7: 0.4665  loss_ce_8: 2.102  loss_mask_8: 5.699  loss_dice_8: 0.4779  time: 2.7915  data_time: 0.3486  lr: 9.7267e-05  max_mem: 23006M
[01/24 15:06:17] d2.utils.events INFO:  eta: 1 day, 20:47:26  iter: 1839  total_loss: 85.17  loss_ce: 2.126  loss_mask: 6.19  loss_dice: 0.4784  loss_ce_0: 2.344  loss_mask_0: 5.193  loss_dice_0: 0.445  loss_ce_1: 2.11  loss_mask_1: 5.915  loss_dice_1: 0.4675  loss_ce_2: 2.096  loss_mask_2: 5.87  loss_dice_2: 0.4666  loss_ce_3: 2.112  loss_mask_3: 5.917  loss_dice_3: 0.4804  loss_ce_4: 2.116  loss_mask_4: 5.918  loss_dice_4: 0.4776  loss_ce_5: 2.119  loss_mask_5: 6.099  loss_dice_5: 0.4775  loss_ce_6: 2.089  loss_mask_6: 6.074  loss_dice_6: 0.4661  loss_ce_7: 2.07  loss_mask_7: 6.401  loss_dice_7: 0.4666  loss_ce_8: 2.126  loss_mask_8: 6.079  loss_dice_8: 0.4787  time: 2.7907  data_time: 0.3619  lr: 9.7237e-05  max_mem: 23006M
[01/24 15:07:08] d2.utils.events INFO:  eta: 1 day, 20:43:53  iter: 1859  total_loss: 84.79  loss_ce: 2.077  loss_mask: 5.945  loss_dice: 0.4768  loss_ce_0: 2.326  loss_mask_0: 4.915  loss_dice_0: 0.4442  loss_ce_1: 2.079  loss_mask_1: 5.761  loss_dice_1: 0.466  loss_ce_2: 2.05  loss_mask_2: 5.963  loss_dice_2: 0.4668  loss_ce_3: 2.064  loss_mask_3: 5.894  loss_dice_3: 0.4793  loss_ce_4: 2.084  loss_mask_4: 5.859  loss_dice_4: 0.4786  loss_ce_5: 2.072  loss_mask_5: 6.149  loss_dice_5: 0.4762  loss_ce_6: 2.053  loss_mask_6: 6.2  loss_dice_6: 0.4649  loss_ce_7: 2.058  loss_mask_7: 6.181  loss_dice_7: 0.467  loss_ce_8: 2.058  loss_mask_8: 5.731  loss_dice_8: 0.4796  time: 2.7883  data_time: 0.3456  lr: 9.7207e-05  max_mem: 23006M
[01/24 15:08:00] d2.utils.events INFO:  eta: 1 day, 20:42:58  iter: 1879  total_loss: 78.55  loss_ce: 2.067  loss_mask: 5.631  loss_dice: 0.4747  loss_ce_0: 2.323  loss_mask_0: 4.506  loss_dice_0: 0.4425  loss_ce_1: 2.058  loss_mask_1: 5.317  loss_dice_1: 0.4642  loss_ce_2: 2.023  loss_mask_2: 5.32  loss_dice_2: 0.468  loss_ce_3: 2.032  loss_mask_3: 5.44  loss_dice_3: 0.4732  loss_ce_4: 2.03  loss_mask_4: 5.34  loss_dice_4: 0.4738  loss_ce_5: 2.012  loss_mask_5: 5.285  loss_dice_5: 0.4671  loss_ce_6: 1.974  loss_mask_6: 5.332  loss_dice_6: 0.4599  loss_ce_7: 1.989  loss_mask_7: 5.543  loss_dice_7: 0.4629  loss_ce_8: 2.021  loss_mask_8: 5.319  loss_dice_8: 0.475  time: 2.7863  data_time: 0.3643  lr: 9.7177e-05  max_mem: 23006M
[01/24 15:08:53] d2.utils.events INFO:  eta: 1 day, 20:37:59  iter: 1899  total_loss: 80  loss_ce: 2.064  loss_mask: 5.669  loss_dice: 0.4672  loss_ce_0: 2.301  loss_mask_0: 4.434  loss_dice_0: 0.4467  loss_ce_1: 2.053  loss_mask_1: 5.335  loss_dice_1: 0.4586  loss_ce_2: 2.053  loss_mask_2: 5.441  loss_dice_2: 0.4661  loss_ce_3: 2.069  loss_mask_3: 5.725  loss_dice_3: 0.4737  loss_ce_4: 2.066  loss_mask_4: 5.598  loss_dice_4: 0.4755  loss_ce_5: 2.047  loss_mask_5: 5.716  loss_dice_5: 0.4579  loss_ce_6: 2.026  loss_mask_6: 5.511  loss_dice_6: 0.4575  loss_ce_7: 2.026  loss_mask_7: 5.411  loss_dice_7: 0.4643  loss_ce_8: 2.042  loss_mask_8: 5.465  loss_dice_8: 0.4669  time: 2.7848  data_time: 0.3573  lr: 9.7147e-05  max_mem: 23006M
[01/24 15:09:50] d2.utils.events INFO:  eta: 1 day, 20:41:07  iter: 1919  total_loss: 78.71  loss_ce: 2.081  loss_mask: 5.657  loss_dice: 0.4566  loss_ce_0: 2.297  loss_mask_0: 4.438  loss_dice_0: 0.4466  loss_ce_1: 2.034  loss_mask_1: 5.414  loss_dice_1: 0.4517  loss_ce_2: 2.032  loss_mask_2: 5.438  loss_dice_2: 0.4559  loss_ce_3: 2.048  loss_mask_3: 5.35  loss_dice_3: 0.4658  loss_ce_4: 2.047  loss_mask_4: 5.661  loss_dice_4: 0.4664  loss_ce_5: 2.109  loss_mask_5: 5.664  loss_dice_5: 0.453  loss_ce_6: 2.099  loss_mask_6: 5.413  loss_dice_6: 0.4502  loss_ce_7: 2.032  loss_mask_7: 5.345  loss_dice_7: 0.4579  loss_ce_8: 2.069  loss_mask_8: 5.498  loss_dice_8: 0.4606  time: 2.7853  data_time: 0.4012  lr: 9.7117e-05  max_mem: 23006M
[01/24 15:10:43] d2.utils.events INFO:  eta: 1 day, 20:39:31  iter: 1939  total_loss: 81.92  loss_ce: 2.103  loss_mask: 5.751  loss_dice: 0.4605  loss_ce_0: 2.285  loss_mask_0: 4.873  loss_dice_0: 0.4513  loss_ce_1: 2.068  loss_mask_1: 5.786  loss_dice_1: 0.4576  loss_ce_2: 2.08  loss_mask_2: 5.378  loss_dice_2: 0.4525  loss_ce_3: 2.079  loss_mask_3: 5.672  loss_dice_3: 0.4603  loss_ce_4: 2.076  loss_mask_4: 5.726  loss_dice_4: 0.4608  loss_ce_5: 2.126  loss_mask_5: 6.027  loss_dice_5: 0.458  loss_ce_6: 2.106  loss_mask_6: 5.791  loss_dice_6: 0.4567  loss_ce_7: 2.087  loss_mask_7: 5.62  loss_dice_7: 0.4653  loss_ce_8: 2.105  loss_mask_8: 5.612  loss_dice_8: 0.458  time: 2.7842  data_time: 0.3714  lr: 9.7087e-05  max_mem: 23006M
[01/24 15:11:37] d2.utils.events INFO:  eta: 1 day, 20:32:37  iter: 1959  total_loss: 77.08  loss_ce: 2.038  loss_mask: 5.253  loss_dice: 0.4525  loss_ce_0: 2.284  loss_mask_0: 4.398  loss_dice_0: 0.4462  loss_ce_1: 2.019  loss_mask_1: 5.266  loss_dice_1: 0.4437  loss_ce_2: 2.025  loss_mask_2: 5.177  loss_dice_2: 0.4465  loss_ce_3: 2.053  loss_mask_3: 5.224  loss_dice_3: 0.4534  loss_ce_4: 2.04  loss_mask_4: 5.214  loss_dice_4: 0.4541  loss_ce_5: 2.095  loss_mask_5: 5.28  loss_dice_5: 0.4484  loss_ce_6: 2.049  loss_mask_6: 5.295  loss_dice_6: 0.4509  loss_ce_7: 2.015  loss_mask_7: 5.213  loss_dice_7: 0.459  loss_ce_8: 2.027  loss_mask_8: 5.205  loss_dice_8: 0.452  time: 2.7832  data_time: 0.3971  lr: 9.7057e-05  max_mem: 23006M
[01/24 15:12:30] d2.utils.events INFO:  eta: 1 day, 20:24:31  iter: 1979  total_loss: 79.65  loss_ce: 2.038  loss_mask: 5.629  loss_dice: 0.462  loss_ce_0: 2.283  loss_mask_0: 4.563  loss_dice_0: 0.4463  loss_ce_1: 2.012  loss_mask_1: 5.412  loss_dice_1: 0.4603  loss_ce_2: 1.999  loss_mask_2: 5.611  loss_dice_2: 0.4585  loss_ce_3: 2.03  loss_mask_3: 5.54  loss_dice_3: 0.4704  loss_ce_4: 2.028  loss_mask_4: 5.568  loss_dice_4: 0.466  loss_ce_5: 2.075  loss_mask_5: 5.491  loss_dice_5: 0.4593  loss_ce_6: 2.03  loss_mask_6: 5.471  loss_dice_6: 0.4607  loss_ce_7: 2.013  loss_mask_7: 5.538  loss_dice_7: 0.4682  loss_ce_8: 2.037  loss_mask_8: 5.551  loss_dice_8: 0.4737  time: 2.7819  data_time: 0.3626  lr: 9.7027e-05  max_mem: 23006M
[01/24 15:13:23] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 15:13:24] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 15:13:24] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 15:21:34] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 24.236432395971786, 'error_1pix': 0.9401250824299026, 'error_3pix': 0.8582347627032041, 'mIoU': 0.09928507260996919, 'fwIoU': 0.2331547913097186, 'IoU-0': nan, 'IoU-1': 0.024793503788317843, 'IoU-2': 0.0003044438656252431, 'IoU-3': 0.0, 'IoU-4': 0.002209149191376084, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.042054800018629976, 'IoU-11': 0.0007298024930107221, 'IoU-12': 0.0784989449951144, 'IoU-13': 4.253134580438805e-05, 'IoU-14': 0.055998770662941476, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.01809972400336729, 'IoU-19': 0.0, 'IoU-20': 0.05711319617272052, 'IoU-21': 0.016464593170413516, 'IoU-22': 0.04303348574380175, 'IoU-23': 0.004464783812800326, 'IoU-24': 0.1251883094972668, 'IoU-25': 2.1111580524237743, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.3524702205908656, 'IoU-30': 0.0, 'IoU-31': 0.04262792814959649, 'IoU-32': 0.026461557800382944, 'IoU-33': 0.013689718555959449, 'IoU-34': 0.0, 'IoU-35': 0.7649031182817562, 'IoU-36': 0.9019701628189944, 'IoU-37': 1.620752045444375, 'IoU-38': 2.791607670809416, 'IoU-39': 2.6337858881243226, 'IoU-40': 0.0003639379233225, 'IoU-41': 0.0, 'IoU-42': 1.9220319186189023, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.03394477818088262, 'IoU-48': 0.0, 'IoU-49': 0.10269455316683479, 'IoU-50': 0.000795580451731522, 'IoU-51': 0.6800841145304829, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.00948454118056544, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.17868647279097538, 'IoU-61': 0.0, 'IoU-62': 0.00047310370398146557, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0024471042206946005, 'IoU-66': 0.00042846527411371957, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.028037529596583087, 'IoU-70': 1.0905039853435499, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.8400648541034977, 'IoU-77': 0.05018743706900332, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.8477613323232799, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.8427236637404005, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.29836559989247824, 'IoU-87': 0.0, 'IoU-88': 0.32410294428515135, 'IoU-89': 0.0, 'IoU-90': 0.05928665667033447, 'IoU-91': 0.0, 'IoU-92': 0.005809419655938181, 'IoU-93': 0.01575211183455733, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.00013589260787698785, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.00014554218831412663, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.7607267643644785, 'pACC': 1.9684841357393894, 'ACC-0': nan, 'ACC-1': 0.040243589798469655, 'ACC-2': 0.0003328126664063332, 'ACC-3': 0.0, 'ACC-4': 0.005900203422922559, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.06107619281548967, 'ACC-11': 0.0007304855058283409, 'ACC-12': 0.30272278541659875, 'ACC-13': 4.253143108199819e-05, 'ACC-14': 0.059857150411697216, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.018448678364559434, 'ACC-19': 0.0, 'ACC-20': 0.06221770172748806, 'ACC-21': 0.03633621305304524, 'ACC-22': 0.04837962910751725, 'ACC-23': 0.00448352094221848, 'ACC-24': 0.13035380647239733, 'ACC-25': 76.61812255749713, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.4013013953945008, 'ACC-30': 0.0, 'ACC-31': 0.0447976053462719, 'ACC-32': 0.026621774982417717, 'ACC-33': 0.013779800783043463, 'ACC-34': 0.0, 'ACC-35': 0.9397550431609513, 'ACC-36': 1.2944599738293754, 'ACC-37': 3.7926482645679207, 'ACC-38': 16.683025134549307, 'ACC-39': 15.01710179512312, 'ACC-40': 0.00036408616163265535, 'ACC-41': 0.0, 'ACC-42': 15.280940090348489, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.035038705095556406, 'ACC-48': 0.0, 'ACC-49': 0.11025127055928764, 'ACC-50': 0.0007958903050294334, 'ACC-51': 1.1323707038541782, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.009510686616900008, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.19763554102265596, 'ACC-61': 0.0, 'ACC-62': 0.0004731784906377254, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0024630456598217407, 'ACC-66': 0.00042926684085361144, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.029191702311578208, 'ACC-70': 5.693812617578396, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 3.4556962990545883, 'ACC-77': 0.05222320880616042, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 1.8130577445163127, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 1.7405077907495303, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.3880262328596153, 'ACC-87': 0.0, 'ACC-88': 0.42374447083534533, 'ACC-89': 0.0, 'ACC-90': 0.0679216142364954, 'ACC-91': 0.0, 'ACC-92': 0.005844378283996685, 'ACC-93': 0.016220012313066568, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.00013598248980675257, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.00014559262020126724, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 15:21:34] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 15:21:34] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 15:21:34] d2.evaluation.testing INFO: copypaste: 24.2364,0.9401,0.8582,0.0993,0.2332,0.7607,1.9685
[01/24 15:21:34] d2.utils.events INFO:  eta: 1 day, 20:15:53  iter: 1999  total_loss: 80.79  loss_ce: 2.127  loss_mask: 5.868  loss_dice: 0.455  loss_ce_0: 2.275  loss_mask_0: 4.577  loss_dice_0: 0.4464  loss_ce_1: 1.999  loss_mask_1: 5.402  loss_dice_1: 0.4573  loss_ce_2: 2.014  loss_mask_2: 5.432  loss_dice_2: 0.4564  loss_ce_3: 2.018  loss_mask_3: 5.462  loss_dice_3: 0.4622  loss_ce_4: 2.03  loss_mask_4: 5.591  loss_dice_4: 0.4637  loss_ce_5: 2.093  loss_mask_5: 5.523  loss_dice_5: 0.4497  loss_ce_6: 2.037  loss_mask_6: 5.371  loss_dice_6: 0.454  loss_ce_7: 2.002  loss_mask_7: 5.638  loss_dice_7: 0.4636  loss_ce_8: 2.044  loss_mask_8: 5.584  loss_dice_8: 0.4644  time: 2.7805  data_time: 0.3665  lr: 9.6996e-05  max_mem: 23006M
[01/24 15:22:26] d2.utils.events INFO:  eta: 1 day, 20:12:18  iter: 2019  total_loss: 74.33  loss_ce: 2.391  loss_mask: 5.089  loss_dice: 0.4481  loss_ce_0: 2.257  loss_mask_0: 4.305  loss_dice_0: 0.4499  loss_ce_1: 1.997  loss_mask_1: 4.878  loss_dice_1: 0.4471  loss_ce_2: 1.99  loss_mask_2: 4.727  loss_dice_2: 0.4493  loss_ce_3: 2.024  loss_mask_3: 5.038  loss_dice_3: 0.457  loss_ce_4: 2.015  loss_mask_4: 5.061  loss_dice_4: 0.4576  loss_ce_5: 2.179  loss_mask_5: 4.886  loss_dice_5: 0.4418  loss_ce_6: 2.116  loss_mask_6: 5.18  loss_dice_6: 0.4502  loss_ce_7: 2.003  loss_mask_7: 5.367  loss_dice_7: 0.4574  loss_ce_8: 2.043  loss_mask_8: 5.13  loss_dice_8: 0.4542  time: 2.7784  data_time: 0.3539  lr: 9.6966e-05  max_mem: 23006M
[01/24 15:23:17] d2.utils.events INFO:  eta: 1 day, 20:06:21  iter: 2039  total_loss: 77.91  loss_ce: 2.283  loss_mask: 5.419  loss_dice: 0.4489  loss_ce_0: 2.247  loss_mask_0: 4.667  loss_dice_0: 0.4499  loss_ce_1: 2.006  loss_mask_1: 5.01  loss_dice_1: 0.4423  loss_ce_2: 1.992  loss_mask_2: 5.083  loss_dice_2: 0.447  loss_ce_3: 2.008  loss_mask_3: 5.223  loss_dice_3: 0.454  loss_ce_4: 2.01  loss_mask_4: 5.32  loss_dice_4: 0.4528  loss_ce_5: 2.137  loss_mask_5: 5.141  loss_dice_5: 0.4379  loss_ce_6: 2.029  loss_mask_6: 5.511  loss_dice_6: 0.451  loss_ce_7: 1.994  loss_mask_7: 5.609  loss_dice_7: 0.4525  loss_ce_8: 2.027  loss_mask_8: 5.622  loss_dice_8: 0.4544  time: 2.7763  data_time: 0.3496  lr: 9.6936e-05  max_mem: 23006M
[01/24 15:24:11] d2.utils.events INFO:  eta: 1 day, 20:01:59  iter: 2059  total_loss: 77.69  loss_ce: 2.327  loss_mask: 5.616  loss_dice: 0.4528  loss_ce_0: 2.217  loss_mask_0: 4.636  loss_dice_0: 0.4536  loss_ce_1: 1.99  loss_mask_1: 5.031  loss_dice_1: 0.4484  loss_ce_2: 1.983  loss_mask_2: 5.042  loss_dice_2: 0.4506  loss_ce_3: 2.019  loss_mask_3: 5.288  loss_dice_3: 0.4597  loss_ce_4: 2.024  loss_mask_4: 5.39  loss_dice_4: 0.454  loss_ce_5: 2.133  loss_mask_5: 5.321  loss_dice_5: 0.4434  loss_ce_6: 2.036  loss_mask_6: 5.559  loss_dice_6: 0.4491  loss_ce_7: 2.019  loss_mask_7: 5.618  loss_dice_7: 0.4542  loss_ce_8: 2.067  loss_mask_8: 5.647  loss_dice_8: 0.4557  time: 2.7756  data_time: 0.3770  lr: 9.6906e-05  max_mem: 23006M
[01/24 15:25:03] d2.utils.events INFO:  eta: 1 day, 19:58:49  iter: 2079  total_loss: 77.73  loss_ce: 2.189  loss_mask: 5.557  loss_dice: 0.4509  loss_ce_0: 2.224  loss_mask_0: 4.585  loss_dice_0: 0.4497  loss_ce_1: 1.986  loss_mask_1: 4.964  loss_dice_1: 0.4436  loss_ce_2: 2.014  loss_mask_2: 5.109  loss_dice_2: 0.448  loss_ce_3: 1.999  loss_mask_3: 5.301  loss_dice_3: 0.4556  loss_ce_4: 2.021  loss_mask_4: 5.411  loss_dice_4: 0.4495  loss_ce_5: 2.219  loss_mask_5: 5.522  loss_dice_5: 0.4493  loss_ce_6: 2.097  loss_mask_6: 5.574  loss_dice_6: 0.4512  loss_ce_7: 1.996  loss_mask_7: 5.564  loss_dice_7: 0.452  loss_ce_8: 2.072  loss_mask_8: 5.496  loss_dice_8: 0.4505  time: 2.7735  data_time: 0.3314  lr: 9.6876e-05  max_mem: 23006M
[01/24 15:25:59] d2.utils.events INFO:  eta: 1 day, 19:53:32  iter: 2099  total_loss: 79.54  loss_ce: 2.169  loss_mask: 5.62  loss_dice: 0.4507  loss_ce_0: 2.193  loss_mask_0: 4.603  loss_dice_0: 0.4502  loss_ce_1: 2.014  loss_mask_1: 4.971  loss_dice_1: 0.4416  loss_ce_2: 2.067  loss_mask_2: 5.216  loss_dice_2: 0.4427  loss_ce_3: 2.082  loss_mask_3: 5.362  loss_dice_3: 0.4517  loss_ce_4: 2.073  loss_mask_4: 5.518  loss_dice_4: 0.4488  loss_ce_5: 2.362  loss_mask_5: 5.372  loss_dice_5: 0.4466  loss_ce_6: 2.089  loss_mask_6: 5.624  loss_dice_6: 0.4539  loss_ce_7: 2.024  loss_mask_7: 5.668  loss_dice_7: 0.4535  loss_ce_8: 2.141  loss_mask_8: 5.64  loss_dice_8: 0.4453  time: 2.7740  data_time: 0.4052  lr: 9.6846e-05  max_mem: 23006M
[01/24 15:27:00] d2.utils.events INFO:  eta: 1 day, 19:59:15  iter: 2119  total_loss: 82.16  loss_ce: 2.081  loss_mask: 5.908  loss_dice: 0.4574  loss_ce_0: 2.183  loss_mask_0: 4.799  loss_dice_0: 0.4468  loss_ce_1: 2.037  loss_mask_1: 5.231  loss_dice_1: 0.4444  loss_ce_2: 2.082  loss_mask_2: 5.585  loss_dice_2: 0.4504  loss_ce_3: 2.107  loss_mask_3: 5.534  loss_dice_3: 0.4538  loss_ce_4: 2.074  loss_mask_4: 5.721  loss_dice_4: 0.4529  loss_ce_5: 2.281  loss_mask_5: 5.309  loss_dice_5: 0.4455  loss_ce_6: 2.043  loss_mask_6: 5.801  loss_dice_6: 0.4548  loss_ce_7: 2.017  loss_mask_7: 5.683  loss_dice_7: 0.4575  loss_ce_8: 2.12  loss_mask_8: 5.775  loss_dice_8: 0.4512  time: 2.7764  data_time: 0.5042  lr: 9.6816e-05  max_mem: 23006M
[01/24 15:27:56] d2.utils.events INFO:  eta: 1 day, 20:00:47  iter: 2139  total_loss: 77.22  loss_ce: 2.027  loss_mask: 5.45  loss_dice: 0.4648  loss_ce_0: 2.195  loss_mask_0: 4.458  loss_dice_0: 0.4443  loss_ce_1: 1.963  loss_mask_1: 5.058  loss_dice_1: 0.4477  loss_ce_2: 2.005  loss_mask_2: 5.309  loss_dice_2: 0.4502  loss_ce_3: 2.03  loss_mask_3: 5.181  loss_dice_3: 0.4554  loss_ce_4: 2.016  loss_mask_4: 5.24  loss_dice_4: 0.4564  loss_ce_5: 2.236  loss_mask_5: 5.149  loss_dice_5: 0.4463  loss_ce_6: 1.996  loss_mask_6: 5.245  loss_dice_6: 0.4543  loss_ce_7: 1.971  loss_mask_7: 5.094  loss_dice_7: 0.4621  loss_ce_8: 2.081  loss_mask_8: 5.264  loss_dice_8: 0.446  time: 2.7768  data_time: 0.4161  lr: 9.6786e-05  max_mem: 23006M
[01/24 15:28:59] d2.utils.events INFO:  eta: 1 day, 20:06:17  iter: 2159  total_loss: 78.77  loss_ce: 2.062  loss_mask: 5.451  loss_dice: 0.4539  loss_ce_0: 2.174  loss_mask_0: 4.604  loss_dice_0: 0.4446  loss_ce_1: 2.012  loss_mask_1: 5.23  loss_dice_1: 0.4424  loss_ce_2: 2.075  loss_mask_2: 5.345  loss_dice_2: 0.4446  loss_ce_3: 2.115  loss_mask_3: 5.383  loss_dice_3: 0.451  loss_ce_4: 2.083  loss_mask_4: 5.577  loss_dice_4: 0.4532  loss_ce_5: 2.262  loss_mask_5: 5.495  loss_dice_5: 0.4489  loss_ce_6: 2.047  loss_mask_6: 5.411  loss_dice_6: 0.4459  loss_ce_7: 2.06  loss_mask_7: 5.586  loss_dice_7: 0.457  loss_ce_8: 2.194  loss_mask_8: 5.54  loss_dice_8: 0.4444  time: 2.7802  data_time: 0.5025  lr: 9.6756e-05  max_mem: 23006M
[01/24 15:29:57] d2.utils.events INFO:  eta: 1 day, 20:10:07  iter: 2179  total_loss: 81.48  loss_ce: 2.088  loss_mask: 5.834  loss_dice: 0.4667  loss_ce_0: 2.171  loss_mask_0: 4.477  loss_dice_0: 0.4461  loss_ce_1: 2.031  loss_mask_1: 5.339  loss_dice_1: 0.4469  loss_ce_2: 2.184  loss_mask_2: 5.341  loss_dice_2: 0.4484  loss_ce_3: 2.286  loss_mask_3: 5.843  loss_dice_3: 0.459  loss_ce_4: 2.165  loss_mask_4: 5.971  loss_dice_4: 0.46  loss_ce_5: 2.239  loss_mask_5: 5.504  loss_dice_5: 0.4531  loss_ce_6: 2.091  loss_mask_6: 5.861  loss_dice_6: 0.4607  loss_ce_7: 2.066  loss_mask_7: 5.389  loss_dice_7: 0.4595  loss_ce_8: 2.237  loss_mask_8: 5.593  loss_dice_8: 0.4505  time: 2.7813  data_time: 0.4147  lr: 9.6725e-05  max_mem: 23006M
[01/24 15:30:54] d2.utils.events INFO:  eta: 1 day, 20:05:36  iter: 2199  total_loss: 81.3  loss_ce: 2.097  loss_mask: 5.766  loss_dice: 0.4694  loss_ce_0: 2.177  loss_mask_0: 4.6  loss_dice_0: 0.4471  loss_ce_1: 2.044  loss_mask_1: 5.325  loss_dice_1: 0.447  loss_ce_2: 2.352  loss_mask_2: 5.257  loss_dice_2: 0.4504  loss_ce_3: 2.337  loss_mask_3: 5.816  loss_dice_3: 0.4615  loss_ce_4: 2.219  loss_mask_4: 5.38  loss_dice_4: 0.4524  loss_ce_5: 2.223  loss_mask_5: 5.706  loss_dice_5: 0.4624  loss_ce_6: 2.105  loss_mask_6: 5.666  loss_dice_6: 0.4639  loss_ce_7: 2.065  loss_mask_7: 5.539  loss_dice_7: 0.4692  loss_ce_8: 2.167  loss_mask_8: 5.398  loss_dice_8: 0.4587  time: 2.7819  data_time: 0.4213  lr: 9.6695e-05  max_mem: 23006M
[01/24 15:31:49] d2.utils.events INFO:  eta: 1 day, 20:11:34  iter: 2219  total_loss: 78.02  loss_ce: 2.069  loss_mask: 5.579  loss_dice: 0.4714  loss_ce_0: 2.175  loss_mask_0: 4.431  loss_dice_0: 0.4454  loss_ce_1: 2.011  loss_mask_1: 4.972  loss_dice_1: 0.4472  loss_ce_2: 2.244  loss_mask_2: 5.312  loss_dice_2: 0.4588  loss_ce_3: 2.215  loss_mask_3: 5.492  loss_dice_3: 0.457  loss_ce_4: 2.169  loss_mask_4: 5.319  loss_dice_4: 0.4448  loss_ce_5: 2.17  loss_mask_5: 5.678  loss_dice_5: 0.4598  loss_ce_6: 2.019  loss_mask_6: 5.313  loss_dice_6: 0.4641  loss_ce_7: 2.045  loss_mask_7: 5.209  loss_dice_7: 0.4684  loss_ce_8: 2.077  loss_mask_8: 5.436  loss_dice_8: 0.4585  time: 2.7817  data_time: 0.4079  lr: 9.6665e-05  max_mem: 23006M
[01/24 15:32:42] d2.utils.events INFO:  eta: 1 day, 20:06:57  iter: 2239  total_loss: 80.19  loss_ce: 2.056  loss_mask: 5.519  loss_dice: 0.4714  loss_ce_0: 2.168  loss_mask_0: 4.56  loss_dice_0: 0.4444  loss_ce_1: 2.016  loss_mask_1: 5.262  loss_dice_1: 0.4512  loss_ce_2: 2.144  loss_mask_2: 5.453  loss_dice_2: 0.4565  loss_ce_3: 2.145  loss_mask_3: 5.816  loss_dice_3: 0.4567  loss_ce_4: 2.148  loss_mask_4: 5.404  loss_dice_4: 0.4447  loss_ce_5: 2.157  loss_mask_5: 5.676  loss_dice_5: 0.4557  loss_ce_6: 2.025  loss_mask_6: 5.591  loss_dice_6: 0.4668  loss_ce_7: 2.014  loss_mask_7: 5.502  loss_dice_7: 0.4661  loss_ce_8: 2.027  loss_mask_8: 5.452  loss_dice_8: 0.4571  time: 2.7804  data_time: 0.3803  lr: 9.6635e-05  max_mem: 23006M
[01/24 15:33:40] d2.utils.events INFO:  eta: 1 day, 20:08:17  iter: 2259  total_loss: 82.74  loss_ce: 2.054  loss_mask: 5.959  loss_dice: 0.4721  loss_ce_0: 2.152  loss_mask_0: 4.711  loss_dice_0: 0.4429  loss_ce_1: 2.033  loss_mask_1: 5.58  loss_dice_1: 0.4541  loss_ce_2: 2.103  loss_mask_2: 5.627  loss_dice_2: 0.4526  loss_ce_3: 2.142  loss_mask_3: 6.023  loss_dice_3: 0.4546  loss_ce_4: 2.18  loss_mask_4: 5.83  loss_dice_4: 0.453  loss_ce_5: 2.192  loss_mask_5: 5.555  loss_dice_5: 0.448  loss_ce_6: 2.054  loss_mask_6: 5.763  loss_dice_6: 0.461  loss_ce_7: 2.029  loss_mask_7: 5.768  loss_dice_7: 0.466  loss_ce_8: 2.045  loss_mask_8: 5.954  loss_dice_8: 0.4566  time: 2.7815  data_time: 0.4455  lr: 9.6605e-05  max_mem: 23006M
[01/24 15:34:33] d2.utils.events INFO:  eta: 1 day, 20:03:15  iter: 2279  total_loss: 81.24  loss_ce: 2.089  loss_mask: 6.032  loss_dice: 0.4638  loss_ce_0: 2.163  loss_mask_0: 4.588  loss_dice_0: 0.4461  loss_ce_1: 2.081  loss_mask_1: 5.381  loss_dice_1: 0.4457  loss_ce_2: 2.16  loss_mask_2: 5.195  loss_dice_2: 0.4456  loss_ce_3: 2.189  loss_mask_3: 5.601  loss_dice_3: 0.4557  loss_ce_4: 2.259  loss_mask_4: 5.695  loss_dice_4: 0.4533  loss_ce_5: 2.178  loss_mask_5: 5.558  loss_dice_5: 0.4428  loss_ce_6: 2.094  loss_mask_6: 5.735  loss_dice_6: 0.4543  loss_ce_7: 2.07  loss_mask_7: 5.728  loss_dice_7: 0.4581  loss_ce_8: 2.138  loss_mask_8: 6.013  loss_dice_8: 0.4507  time: 2.7800  data_time: 0.3655  lr: 9.6575e-05  max_mem: 23006M
[01/24 15:35:27] d2.utils.events INFO:  eta: 1 day, 19:57:24  iter: 2299  total_loss: 80.86  loss_ce: 2.095  loss_mask: 5.369  loss_dice: 0.4624  loss_ce_0: 2.172  loss_mask_0: 4.585  loss_dice_0: 0.453  loss_ce_1: 2.133  loss_mask_1: 5.068  loss_dice_1: 0.4469  loss_ce_2: 2.223  loss_mask_2: 5.269  loss_dice_2: 0.4573  loss_ce_3: 2.214  loss_mask_3: 5.593  loss_dice_3: 0.4652  loss_ce_4: 2.327  loss_mask_4: 6.136  loss_dice_4: 0.4634  loss_ce_5: 2.156  loss_mask_5: 5.677  loss_dice_5: 0.4597  loss_ce_6: 2.164  loss_mask_6: 5.935  loss_dice_6: 0.4662  loss_ce_7: 2.114  loss_mask_7: 5.413  loss_dice_7: 0.4662  loss_ce_8: 2.136  loss_mask_8: 5.766  loss_dice_8: 0.4656  time: 2.7794  data_time: 0.3728  lr: 9.6545e-05  max_mem: 23006M
[01/24 15:36:22] d2.utils.events INFO:  eta: 1 day, 20:00:07  iter: 2319  total_loss: 77.08  loss_ce: 2.072  loss_mask: 5.19  loss_dice: 0.4716  loss_ce_0: 2.159  loss_mask_0: 4.407  loss_dice_0: 0.4531  loss_ce_1: 2.081  loss_mask_1: 5.003  loss_dice_1: 0.4499  loss_ce_2: 2.153  loss_mask_2: 5.027  loss_dice_2: 0.45  loss_ce_3: 2.147  loss_mask_3: 5.064  loss_dice_3: 0.4489  loss_ce_4: 2.248  loss_mask_4: 5.121  loss_dice_4: 0.4534  loss_ce_5: 2.12  loss_mask_5: 5.192  loss_dice_5: 0.4585  loss_ce_6: 2.08  loss_mask_6: 5.464  loss_dice_6: 0.4702  loss_ce_7: 2.099  loss_mask_7: 5.499  loss_dice_7: 0.4692  loss_ce_8: 2.12  loss_mask_8: 5.183  loss_dice_8: 0.4522  time: 2.7793  data_time: 0.3801  lr: 9.6515e-05  max_mem: 23006M
[01/24 15:37:14] d2.utils.events INFO:  eta: 1 day, 19:57:27  iter: 2339  total_loss: 76.11  loss_ce: 2.014  loss_mask: 5.299  loss_dice: 0.4657  loss_ce_0: 2.152  loss_mask_0: 4.189  loss_dice_0: 0.4451  loss_ce_1: 1.984  loss_mask_1: 5.094  loss_dice_1: 0.4479  loss_ce_2: 2.03  loss_mask_2: 5.111  loss_dice_2: 0.4499  loss_ce_3: 2.091  loss_mask_3: 5.376  loss_dice_3: 0.4499  loss_ce_4: 2.195  loss_mask_4: 5.167  loss_dice_4: 0.4451  loss_ce_5: 2.11  loss_mask_5: 5.388  loss_dice_5: 0.4456  loss_ce_6: 2.038  loss_mask_6: 5.613  loss_dice_6: 0.462  loss_ce_7: 2.066  loss_mask_7: 5.567  loss_dice_7: 0.4658  loss_ce_8: 2.052  loss_mask_8: 5.3  loss_dice_8: 0.4575  time: 2.7777  data_time: 0.3428  lr: 9.6485e-05  max_mem: 23006M
[01/24 15:38:12] d2.utils.events INFO:  eta: 1 day, 19:54:39  iter: 2359  total_loss: 78.95  loss_ce: 2.045  loss_mask: 5.485  loss_dice: 0.4703  loss_ce_0: 2.141  loss_mask_0: 4.379  loss_dice_0: 0.4457  loss_ce_1: 2.018  loss_mask_1: 5.279  loss_dice_1: 0.4533  loss_ce_2: 2.074  loss_mask_2: 5.369  loss_dice_2: 0.4555  loss_ce_3: 2.109  loss_mask_3: 5.688  loss_dice_3: 0.4623  loss_ce_4: 2.163  loss_mask_4: 5.658  loss_dice_4: 0.4507  loss_ce_5: 2.156  loss_mask_5: 5.508  loss_dice_5: 0.4528  loss_ce_6: 2.052  loss_mask_6: 5.454  loss_dice_6: 0.4663  loss_ce_7: 2.121  loss_mask_7: 5.512  loss_dice_7: 0.4643  loss_ce_8: 2.067  loss_mask_8: 5.362  loss_dice_8: 0.4526  time: 2.7788  data_time: 0.4312  lr: 9.6454e-05  max_mem: 23006M
[01/24 15:39:04] d2.utils.events INFO:  eta: 1 day, 19:46:11  iter: 2379  total_loss: 78.21  loss_ce: 2.006  loss_mask: 5.543  loss_dice: 0.46  loss_ce_0: 2.14  loss_mask_0: 4.513  loss_dice_0: 0.4465  loss_ce_1: 2  loss_mask_1: 5.122  loss_dice_1: 0.4417  loss_ce_2: 2.12  loss_mask_2: 4.751  loss_dice_2: 0.4369  loss_ce_3: 2.135  loss_mask_3: 4.978  loss_dice_3: 0.4414  loss_ce_4: 2.208  loss_mask_4: 5.401  loss_dice_4: 0.445  loss_ce_5: 2.103  loss_mask_5: 5.729  loss_dice_5: 0.4621  loss_ce_6: 2.064  loss_mask_6: 5.812  loss_dice_6: 0.4619  loss_ce_7: 2.116  loss_mask_7: 5.893  loss_dice_7: 0.4638  loss_ce_8: 2.028  loss_mask_8: 5.757  loss_dice_8: 0.4557  time: 2.7772  data_time: 0.3746  lr: 9.6424e-05  max_mem: 23006M
[01/24 15:39:56] d2.utils.events INFO:  eta: 1 day, 19:36:50  iter: 2399  total_loss: 79.99  loss_ce: 2.075  loss_mask: 5.788  loss_dice: 0.454  loss_ce_0: 2.126  loss_mask_0: 4.826  loss_dice_0: 0.4498  loss_ce_1: 2.049  loss_mask_1: 5.042  loss_dice_1: 0.4424  loss_ce_2: 2.156  loss_mask_2: 5.292  loss_dice_2: 0.4498  loss_ce_3: 2.193  loss_mask_3: 5.02  loss_dice_3: 0.4412  loss_ce_4: 2.214  loss_mask_4: 5.661  loss_dice_4: 0.4483  loss_ce_5: 2.135  loss_mask_5: 5.905  loss_dice_5: 0.4625  loss_ce_6: 2.096  loss_mask_6: 5.706  loss_dice_6: 0.4615  loss_ce_7: 2.065  loss_mask_7: 5.787  loss_dice_7: 0.4561  loss_ce_8: 2.107  loss_mask_8: 6.183  loss_dice_8: 0.4646  time: 2.7756  data_time: 0.3828  lr: 9.6394e-05  max_mem: 23006M
[01/24 15:40:51] d2.utils.events INFO:  eta: 1 day, 19:32:02  iter: 2419  total_loss: 80.59  loss_ce: 2.011  loss_mask: 5.657  loss_dice: 0.4546  loss_ce_0: 2.134  loss_mask_0: 4.693  loss_dice_0: 0.4447  loss_ce_1: 1.991  loss_mask_1: 5.427  loss_dice_1: 0.4419  loss_ce_2: 2.054  loss_mask_2: 5.335  loss_dice_2: 0.4456  loss_ce_3: 2.098  loss_mask_3: 5.487  loss_dice_3: 0.4486  loss_ce_4: 2.134  loss_mask_4: 5.571  loss_dice_4: 0.4514  loss_ce_5: 2.02  loss_mask_5: 5.665  loss_dice_5: 0.4596  loss_ce_6: 1.98  loss_mask_6: 5.858  loss_dice_6: 0.4572  loss_ce_7: 2.023  loss_mask_7: 5.948  loss_dice_7: 0.4658  loss_ce_8: 2.056  loss_mask_8: 5.535  loss_dice_8: 0.4506  time: 2.7753  data_time: 0.3874  lr: 9.6364e-05  max_mem: 23006M
[01/24 15:41:43] d2.utils.events INFO:  eta: 1 day, 19:25:35  iter: 2439  total_loss: 76.78  loss_ce: 2.036  loss_mask: 5.144  loss_dice: 0.4658  loss_ce_0: 2.116  loss_mask_0: 4.408  loss_dice_0: 0.4462  loss_ce_1: 2.035  loss_mask_1: 4.88  loss_dice_1: 0.4467  loss_ce_2: 2.093  loss_mask_2: 5.077  loss_dice_2: 0.448  loss_ce_3: 2.09  loss_mask_3: 5.271  loss_dice_3: 0.4528  loss_ce_4: 2.156  loss_mask_4: 5.027  loss_dice_4: 0.4466  loss_ce_5: 2.035  loss_mask_5: 5.224  loss_dice_5: 0.4689  loss_ce_6: 2.002  loss_mask_6: 5.351  loss_dice_6: 0.4625  loss_ce_7: 2.003  loss_mask_7: 5.134  loss_dice_7: 0.4675  loss_ce_8: 2.051  loss_mask_8: 5.414  loss_dice_8: 0.4629  time: 2.7737  data_time: 0.3471  lr: 9.6334e-05  max_mem: 23006M
[01/24 15:42:39] d2.utils.events INFO:  eta: 1 day, 19:23:40  iter: 2459  total_loss: 78.66  loss_ce: 2.05  loss_mask: 5.46  loss_dice: 0.4732  loss_ce_0: 2.115  loss_mask_0: 4.773  loss_dice_0: 0.4506  loss_ce_1: 2.023  loss_mask_1: 5.277  loss_dice_1: 0.4596  loss_ce_2: 2.101  loss_mask_2: 5.117  loss_dice_2: 0.4601  loss_ce_3: 2.083  loss_mask_3: 5.521  loss_dice_3: 0.4645  loss_ce_4: 2.158  loss_mask_4: 5.705  loss_dice_4: 0.4615  loss_ce_5: 2.075  loss_mask_5: 5.605  loss_dice_5: 0.4673  loss_ce_6: 2.051  loss_mask_6: 5.676  loss_dice_6: 0.4699  loss_ce_7: 2.037  loss_mask_7: 5.582  loss_dice_7: 0.4719  loss_ce_8: 2.054  loss_mask_8: 5.36  loss_dice_8: 0.4701  time: 2.7740  data_time: 0.3883  lr: 9.6304e-05  max_mem: 23006M
[01/24 15:43:32] d2.utils.events INFO:  eta: 1 day, 19:20:56  iter: 2479  total_loss: 79.29  loss_ce: 2.034  loss_mask: 5.446  loss_dice: 0.469  loss_ce_0: 2.108  loss_mask_0: 4.712  loss_dice_0: 0.4434  loss_ce_1: 2.016  loss_mask_1: 5.224  loss_dice_1: 0.4554  loss_ce_2: 2.049  loss_mask_2: 5.361  loss_dice_2: 0.4583  loss_ce_3: 2.035  loss_mask_3: 5.486  loss_dice_3: 0.4622  loss_ce_4: 2.062  loss_mask_4: 5.571  loss_dice_4: 0.4603  loss_ce_5: 2.052  loss_mask_5: 5.438  loss_dice_5: 0.4659  loss_ce_6: 2.03  loss_mask_6: 5.555  loss_dice_6: 0.4616  loss_ce_7: 2.028  loss_mask_7: 5.398  loss_dice_7: 0.4663  loss_ce_8: 2.049  loss_mask_8: 5.486  loss_dice_8: 0.4626  time: 2.7731  data_time: 0.4219  lr: 9.6274e-05  max_mem: 23006M
[01/24 15:44:23] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 15:44:24] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 15:44:24] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 15:52:28] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 13.684145966994045, 'error_1pix': 0.8381454100933068, 'error_3pix': 0.7478946141792119, 'mIoU': 0.41504552804677725, 'fwIoU': 6.238451562827659, 'IoU-0': nan, 'IoU-1': 57.74731666789849, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0001663688876870514, 'IoU-13': 3.0379027583124158e-05, 'IoU-14': 1.2649899673698035, 'IoU-15': 0.7866002304215035, 'IoU-16': 0.024561851504586382, 'IoU-17': 0.11342964677449245, 'IoU-18': 0.0010759605175542958, 'IoU-19': 0.0, 'IoU-20': 0.0012433011380913956, 'IoU-21': 0.18090896950040075, 'IoU-22': 0.0, 'IoU-23': 0.07738006377644614, 'IoU-24': 1.870794804054511e-05, 'IoU-25': 2.593259750256151, 'IoU-26': 0.0009177888509441616, 'IoU-27': 0.09769271135213807, 'IoU-28': 0.0036820826521171447, 'IoU-29': 1.2360243346415678, 'IoU-30': 2.6961187758427054, 'IoU-31': 1.1161657794011117, 'IoU-32': 0.0, 'IoU-33': 0.0029789205594863213, 'IoU-34': 0.0002561940230452569, 'IoU-35': 2.043898940917148, 'IoU-36': 0.015878139706350547, 'IoU-37': 0.04282595445458778, 'IoU-38': 3.3417623808955974, 'IoU-39': 2.971693666880985e-05, 'IoU-40': 0.0, 'IoU-41': 0.12975703531417815, 'IoU-42': 0.0, 'IoU-43': 0.3214264190735944, 'IoU-44': 0.026574774323612604, 'IoU-45': 0.0021827509562113677, 'IoU-46': 0.00624731195242126, 'IoU-47': 0.0, 'IoU-48': 1.441627163387486, 'IoU-49': 0.00024966598096283276, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 7.716347081291717e-05, 'IoU-72': 1.1824234337274862, 'IoU-73': 0.0004084335117709434, 'IoU-74': 0.0, 'IoU-75': 1.3938806260653394, 'IoU-76': 0.0, 'IoU-77': 0.15036967768855375, 'IoU-78': 0.5469982193437395, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0005977461648772102, 'IoU-82': 0.0, 'IoU-83': 1.0966846973971593, 'IoU-84': 2.2681368729877373e-05, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.4997258192871468, 'pACC': 11.388152805219644, 'ACC-0': nan, 'ACC-1': 88.84349856416851, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0001664179500619843, 'ACC-13': 3.037959362999871e-05, 'ACC-14': 1.835101878976712, 'ACC-15': 0.9311527522045608, 'ACC-16': 0.024911821500112195, 'ACC-17': 0.11839024150127864, 'ACC-18': 0.001077491164796304, 'ACC-19': 0.0, 'ACC-20': 0.0012439845341930703, 'ACC-21': 0.22595796804065443, 'ACC-22': 0.0, 'ACC-23': 0.08202618327463203, 'ACC-24': 1.870838728494436e-05, 'ACC-25': 35.298953105964834, 'ACC-26': 0.0009183706826884845, 'ACC-27': 0.10545155885096963, 'ACC-28': 0.0037205596309596786, 'ACC-29': 1.6916935770001504, 'ACC-30': 24.399227816180314, 'ACC-31': 1.8128191924329948, 'ACC-32': 0.0, 'ACC-33': 0.0029850522011360737, 'ACC-34': 0.00025629223350445593, 'ACC-35': 6.6365398401349305, 'ACC-36': 0.016112756853237774, 'ACC-37': 0.04412429899471148, 'ACC-38': 49.26419366249697, 'ACC-39': 2.9717186587171607e-05, 'ACC-40': 0.0, 'ACC-41': 0.14439901954267786, 'ACC-42': 0.0, 'ACC-43': 0.3864112809550711, 'ACC-44': 0.026870379155211056, 'ACC-45': 0.002183392315828872, 'ACC-46': 0.006263361598021403, 'ACC-47': 0.0, 'ACC-48': 3.77583463708742, 'ACC-49': 0.0002497146102524737, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 7.718146520190947e-05, 'ACC-72': 4.145229128858645, 'ACC-73': 0.00040882731090189956, 'ACC-74': 0.0, 'ACC-75': 59.60600127328857, 'ACC-76': 0.0, 'ACC-77': 0.3184917098930887, 'ACC-78': 0.8839287160200835, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0005983266797190524, 'ACC-82': 0.0, 'ACC-83': 7.309785478792118, 'ACC-84': 2.2683418976471965e-05, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 15:52:28] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 15:52:28] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 15:52:28] d2.evaluation.testing INFO: copypaste: 13.6841,0.8381,0.7479,0.4150,6.2385,1.4997,11.3882
[01/24 15:52:28] d2.utils.events INFO:  eta: 1 day, 19:08:03  iter: 2499  total_loss: 72.45  loss_ce: 2.001  loss_mask: 4.991  loss_dice: 0.465  loss_ce_0: 2.079  loss_mask_0: 4.05  loss_dice_0: 0.441  loss_ce_1: 1.993  loss_mask_1: 4.743  loss_dice_1: 0.4504  loss_ce_2: 2.062  loss_mask_2: 4.69  loss_dice_2: 0.4466  loss_ce_3: 2.013  loss_mask_3: 4.577  loss_dice_3: 0.4505  loss_ce_4: 2.097  loss_mask_4: 4.837  loss_dice_4: 0.4459  loss_ce_5: 1.984  loss_mask_5: 4.932  loss_dice_5: 0.4639  loss_ce_6: 2  loss_mask_6: 5.025  loss_dice_6: 0.4663  loss_ce_7: 2.038  loss_mask_7: 5.009  loss_dice_7: 0.4725  loss_ce_8: 2.03  loss_mask_8: 5.065  loss_dice_8: 0.4588  time: 2.7714  data_time: 0.3377  lr: 9.6244e-05  max_mem: 23006M
[01/24 15:53:26] d2.utils.events INFO:  eta: 1 day, 19:12:24  iter: 2519  total_loss: 76.1  loss_ce: 2.02  loss_mask: 5.519  loss_dice: 0.4664  loss_ce_0: 2.064  loss_mask_0: 4.243  loss_dice_0: 0.4438  loss_ce_1: 2.016  loss_mask_1: 4.844  loss_dice_1: 0.4491  loss_ce_2: 2.128  loss_mask_2: 4.916  loss_dice_2: 0.4438  loss_ce_3: 2.084  loss_mask_3: 4.983  loss_dice_3: 0.4441  loss_ce_4: 2.197  loss_mask_4: 4.958  loss_dice_4: 0.4404  loss_ce_5: 2.038  loss_mask_5: 5.221  loss_dice_5: 0.4586  loss_ce_6: 2.025  loss_mask_6: 5.354  loss_dice_6: 0.4682  loss_ce_7: 2.084  loss_mask_7: 5.202  loss_dice_7: 0.4665  loss_ce_8: 2.04  loss_mask_8: 5.117  loss_dice_8: 0.4567  time: 2.7724  data_time: 0.4234  lr: 9.6213e-05  max_mem: 23006M
[01/24 15:54:22] d2.utils.events INFO:  eta: 1 day, 19:11:30  iter: 2539  total_loss: 75.18  loss_ce: 2.046  loss_mask: 5.333  loss_dice: 0.4611  loss_ce_0: 2.063  loss_mask_0: 4.114  loss_dice_0: 0.4467  loss_ce_1: 1.999  loss_mask_1: 4.77  loss_dice_1: 0.4455  loss_ce_2: 2.073  loss_mask_2: 4.937  loss_dice_2: 0.445  loss_ce_3: 2.052  loss_mask_3: 4.746  loss_dice_3: 0.4446  loss_ce_4: 2.168  loss_mask_4: 5.147  loss_dice_4: 0.4446  loss_ce_5: 2.078  loss_mask_5: 5.207  loss_dice_5: 0.4618  loss_ce_6: 2.046  loss_mask_6: 5.462  loss_dice_6: 0.4629  loss_ce_7: 2.088  loss_mask_7: 5.027  loss_dice_7: 0.4533  loss_ce_8: 2.144  loss_mask_8: 5.111  loss_dice_8: 0.4514  time: 2.7728  data_time: 0.3942  lr: 9.6183e-05  max_mem: 23006M
[01/24 15:55:25] d2.utils.events INFO:  eta: 1 day, 19:15:28  iter: 2559  total_loss: 78.29  loss_ce: 2.045  loss_mask: 5.248  loss_dice: 0.4609  loss_ce_0: 2.044  loss_mask_0: 4.364  loss_dice_0: 0.4468  loss_ce_1: 1.979  loss_mask_1: 5.25  loss_dice_1: 0.4502  loss_ce_2: 2.041  loss_mask_2: 5.143  loss_dice_2: 0.4482  loss_ce_3: 2.047  loss_mask_3: 5.187  loss_dice_3: 0.4518  loss_ce_4: 2.113  loss_mask_4: 5.404  loss_dice_4: 0.4579  loss_ce_5: 2.072  loss_mask_5: 5.434  loss_dice_5: 0.4698  loss_ce_6: 2.04  loss_mask_6: 5.835  loss_dice_6: 0.4708  loss_ce_7: 2.044  loss_mask_7: 5.36  loss_dice_7: 0.4658  loss_ce_8: 2.073  loss_mask_8: 5.568  loss_dice_8: 0.4668  time: 2.7758  data_time: 0.4984  lr: 9.6153e-05  max_mem: 23006M
[01/24 15:56:18] d2.utils.events INFO:  eta: 1 day, 19:18:20  iter: 2579  total_loss: 77.57  loss_ce: 2.103  loss_mask: 5.382  loss_dice: 0.4573  loss_ce_0: 2.046  loss_mask_0: 4.075  loss_dice_0: 0.4446  loss_ce_1: 1.983  loss_mask_1: 4.903  loss_dice_1: 0.4437  loss_ce_2: 2.162  loss_mask_2: 4.899  loss_dice_2: 0.4385  loss_ce_3: 2.196  loss_mask_3: 4.68  loss_dice_3: 0.4401  loss_ce_4: 2.152  loss_mask_4: 5.198  loss_dice_4: 0.4487  loss_ce_5: 2.065  loss_mask_5: 5.629  loss_dice_5: 0.4636  loss_ce_6: 2.012  loss_mask_6: 5.536  loss_dice_6: 0.4614  loss_ce_7: 2.071  loss_mask_7: 5.683  loss_dice_7: 0.4636  loss_ce_8: 2.133  loss_mask_8: 5.289  loss_dice_8: 0.4539  time: 2.7745  data_time: 0.4017  lr: 9.6123e-05  max_mem: 23006M
[01/24 15:57:15] d2.utils.events INFO:  eta: 1 day, 19:15:31  iter: 2599  total_loss: 80.36  loss_ce: 2.126  loss_mask: 5.601  loss_dice: 0.4618  loss_ce_0: 2.064  loss_mask_0: 4.611  loss_dice_0: 0.4486  loss_ce_1: 1.986  loss_mask_1: 5.407  loss_dice_1: 0.4563  loss_ce_2: 2.038  loss_mask_2: 5.367  loss_dice_2: 0.4577  loss_ce_3: 2.153  loss_mask_3: 5.471  loss_dice_3: 0.4515  loss_ce_4: 2.184  loss_mask_4: 5.96  loss_dice_4: 0.4484  loss_ce_5: 2.057  loss_mask_5: 5.743  loss_dice_5: 0.4704  loss_ce_6: 1.993  loss_mask_6: 5.377  loss_dice_6: 0.4659  loss_ce_7: 2.124  loss_mask_7: 5.532  loss_dice_7: 0.4533  loss_ce_8: 2.142  loss_mask_8: 5.753  loss_dice_8: 0.4537  time: 2.7751  data_time: 0.4168  lr: 9.6093e-05  max_mem: 23006M
[01/24 15:58:08] d2.utils.events INFO:  eta: 1 day, 19:12:05  iter: 2619  total_loss: 80.38  loss_ce: 2.269  loss_mask: 5.948  loss_dice: 0.4544  loss_ce_0: 2.065  loss_mask_0: 4.766  loss_dice_0: 0.4493  loss_ce_1: 2.014  loss_mask_1: 5.355  loss_dice_1: 0.4526  loss_ce_2: 2.092  loss_mask_2: 5.347  loss_dice_2: 0.4521  loss_ce_3: 2.238  loss_mask_3: 5.299  loss_dice_3: 0.4476  loss_ce_4: 2.25  loss_mask_4: 5.546  loss_dice_4: 0.4473  loss_ce_5: 2.165  loss_mask_5: 5.801  loss_dice_5: 0.4605  loss_ce_6: 2.053  loss_mask_6: 5.304  loss_dice_6: 0.4568  loss_ce_7: 2.376  loss_mask_7: 5.34  loss_dice_7: 0.4475  loss_ce_8: 2.272  loss_mask_8: 5.465  loss_dice_8: 0.4439  time: 2.7744  data_time: 0.4261  lr: 9.6063e-05  max_mem: 23006M
[01/24 15:58:58] d2.utils.events INFO:  eta: 1 day, 19:06:27  iter: 2639  total_loss: 77.41  loss_ce: 2.22  loss_mask: 5.635  loss_dice: 0.465  loss_ce_0: 2.065  loss_mask_0: 4.21  loss_dice_0: 0.4454  loss_ce_1: 2.032  loss_mask_1: 4.916  loss_dice_1: 0.4415  loss_ce_2: 2.145  loss_mask_2: 4.66  loss_dice_2: 0.4372  loss_ce_3: 2.184  loss_mask_3: 4.779  loss_dice_3: 0.4375  loss_ce_4: 2.159  loss_mask_4: 5.073  loss_dice_4: 0.4402  loss_ce_5: 2.071  loss_mask_5: 5.215  loss_dice_5: 0.4577  loss_ce_6: 2.087  loss_mask_6: 5.054  loss_dice_6: 0.4463  loss_ce_7: 2.329  loss_mask_7: 5.341  loss_dice_7: 0.4532  loss_ce_8: 2.383  loss_mask_8: 5.369  loss_dice_8: 0.4433  time: 2.7723  data_time: 0.3638  lr: 9.6033e-05  max_mem: 23006M
[01/24 15:59:52] d2.utils.events INFO:  eta: 1 day, 19:03:14  iter: 2659  total_loss: 80.57  loss_ce: 2.221  loss_mask: 7.201  loss_dice: 0.4779  loss_ce_0: 2.035  loss_mask_0: 4.324  loss_dice_0: 0.448  loss_ce_1: 2.046  loss_mask_1: 4.784  loss_dice_1: 0.4417  loss_ce_2: 2.11  loss_mask_2: 4.967  loss_dice_2: 0.4419  loss_ce_3: 2.243  loss_mask_3: 4.766  loss_dice_3: 0.4377  loss_ce_4: 2.205  loss_mask_4: 4.991  loss_dice_4: 0.4435  loss_ce_5: 2.197  loss_mask_5: 5.633  loss_dice_5: 0.4497  loss_ce_6: 2.21  loss_mask_6: 5.262  loss_dice_6: 0.4502  loss_ce_7: 2.367  loss_mask_7: 5.783  loss_dice_7: 0.462  loss_ce_8: 2.328  loss_mask_8: 5.763  loss_dice_8: 0.4572  time: 2.7717  data_time: 0.3852  lr: 9.6003e-05  max_mem: 23006M
[01/24 16:00:44] d2.utils.events INFO:  eta: 1 day, 19:00:04  iter: 2679  total_loss: 76.63  loss_ce: 2.11  loss_mask: 5.36  loss_dice: 0.4574  loss_ce_0: 2.067  loss_mask_0: 4.153  loss_dice_0: 0.4496  loss_ce_1: 1.988  loss_mask_1: 4.749  loss_dice_1: 0.4554  loss_ce_2: 2.088  loss_mask_2: 4.846  loss_dice_2: 0.4536  loss_ce_3: 2.234  loss_mask_3: 5.195  loss_dice_3: 0.4542  loss_ce_4: 2.189  loss_mask_4: 4.945  loss_dice_4: 0.4541  loss_ce_5: 2.192  loss_mask_5: 5.378  loss_dice_5: 0.4584  loss_ce_6: 2.013  loss_mask_6: 4.994  loss_dice_6: 0.457  loss_ce_7: 2.273  loss_mask_7: 5.195  loss_dice_7: 0.452  loss_ce_8: 2.14  loss_mask_8: 5.346  loss_dice_8: 0.4543  time: 2.7703  data_time: 0.3698  lr: 9.5972e-05  max_mem: 23006M
[01/24 16:01:38] d2.utils.events INFO:  eta: 1 day, 18:58:25  iter: 2699  total_loss: 79.5  loss_ce: 2.117  loss_mask: 5.534  loss_dice: 0.4684  loss_ce_0: 2.082  loss_mask_0: 4.495  loss_dice_0: 0.4519  loss_ce_1: 2.046  loss_mask_1: 4.774  loss_dice_1: 0.452  loss_ce_2: 2.296  loss_mask_2: 5.324  loss_dice_2: 0.4621  loss_ce_3: 2.298  loss_mask_3: 5.663  loss_dice_3: 0.4701  loss_ce_4: 2.169  loss_mask_4: 5.415  loss_dice_4: 0.453  loss_ce_5: 2.104  loss_mask_5: 5.383  loss_dice_5: 0.4635  loss_ce_6: 2.051  loss_mask_6: 5.011  loss_dice_6: 0.4577  loss_ce_7: 2.241  loss_mask_7: 5.697  loss_dice_7: 0.4649  loss_ce_8: 2.256  loss_mask_8: 5.516  loss_dice_8: 0.4651  time: 2.7697  data_time: 0.3742  lr: 9.5942e-05  max_mem: 23006M
[01/24 16:02:32] d2.utils.events INFO:  eta: 1 day, 18:55:33  iter: 2719  total_loss: 78.03  loss_ce: 2.104  loss_mask: 5.616  loss_dice: 0.4744  loss_ce_0: 2.061  loss_mask_0: 4.346  loss_dice_0: 0.4515  loss_ce_1: 2.065  loss_mask_1: 4.741  loss_dice_1: 0.4455  loss_ce_2: 2.341  loss_mask_2: 5.794  loss_dice_2: 0.48  loss_ce_3: 2.276  loss_mask_3: 5.94  loss_dice_3: 0.4788  loss_ce_4: 2.138  loss_mask_4: 5.698  loss_dice_4: 0.4705  loss_ce_5: 2.068  loss_mask_5: 5.02  loss_dice_5: 0.4538  loss_ce_6: 2.071  loss_mask_6: 5.122  loss_dice_6: 0.4531  loss_ce_7: 2.171  loss_mask_7: 4.585  loss_dice_7: 0.4502  loss_ce_8: 2.213  loss_mask_8: 5.397  loss_dice_8: 0.4721  time: 2.7693  data_time: 0.4063  lr: 9.5912e-05  max_mem: 23006M
[01/24 16:03:25] d2.utils.events INFO:  eta: 1 day, 18:50:50  iter: 2739  total_loss: 78.13  loss_ce: 2.144  loss_mask: 5.51  loss_dice: 0.4827  loss_ce_0: 2.045  loss_mask_0: 4.517  loss_dice_0: 0.4565  loss_ce_1: 2.071  loss_mask_1: 4.6  loss_dice_1: 0.4483  loss_ce_2: 2.212  loss_mask_2: 5.6  loss_dice_2: 0.4805  loss_ce_3: 2.149  loss_mask_3: 5.587  loss_dice_3: 0.4806  loss_ce_4: 2.115  loss_mask_4: 6.106  loss_dice_4: 0.4837  loss_ce_5: 2.053  loss_mask_5: 5.254  loss_dice_5: 0.4576  loss_ce_6: 2.063  loss_mask_6: 5.021  loss_dice_6: 0.451  loss_ce_7: 2.161  loss_mask_7: 4.977  loss_dice_7: 0.4497  loss_ce_8: 2.199  loss_mask_8: 5.829  loss_dice_8: 0.4849  time: 2.7682  data_time: 0.3455  lr: 9.5882e-05  max_mem: 23006M
[01/24 16:04:19] d2.utils.events INFO:  eta: 1 day, 18:46:31  iter: 2759  total_loss: 81.52  loss_ce: 2.117  loss_mask: 5.651  loss_dice: 0.4851  loss_ce_0: 2.088  loss_mask_0: 4.842  loss_dice_0: 0.4573  loss_ce_1: 2.031  loss_mask_1: 4.897  loss_dice_1: 0.4577  loss_ce_2: 2.157  loss_mask_2: 5.657  loss_dice_2: 0.4793  loss_ce_3: 2.111  loss_mask_3: 5.492  loss_dice_3: 0.4799  loss_ce_4: 2.099  loss_mask_4: 5.745  loss_dice_4: 0.4807  loss_ce_5: 2.058  loss_mask_5: 5.69  loss_dice_5: 0.4648  loss_ce_6: 2.069  loss_mask_6: 5.562  loss_dice_6: 0.4698  loss_ce_7: 2.108  loss_mask_7: 5.619  loss_dice_7: 0.4718  loss_ce_8: 2.158  loss_mask_8: 5.879  loss_dice_8: 0.4842  time: 2.7678  data_time: 0.3975  lr: 9.5852e-05  max_mem: 23006M
[01/24 16:05:12] d2.utils.events INFO:  eta: 1 day, 18:41:07  iter: 2779  total_loss: 80.17  loss_ce: 2.128  loss_mask: 5.54  loss_dice: 0.4842  loss_ce_0: 2.093  loss_mask_0: 4.821  loss_dice_0: 0.4584  loss_ce_1: 2.012  loss_mask_1: 5.008  loss_dice_1: 0.4621  loss_ce_2: 2.116  loss_mask_2: 5.776  loss_dice_2: 0.4808  loss_ce_3: 2.112  loss_mask_3: 5.542  loss_dice_3: 0.477  loss_ce_4: 2.105  loss_mask_4: 5.646  loss_dice_4: 0.4713  loss_ce_5: 2.038  loss_mask_5: 5.463  loss_dice_5: 0.4667  loss_ce_6: 2.025  loss_mask_6: 5.304  loss_dice_6: 0.4743  loss_ce_7: 2.09  loss_mask_7: 5.422  loss_dice_7: 0.4749  loss_ce_8: 2.146  loss_mask_8: 6.147  loss_dice_8: 0.4812  time: 2.7669  data_time: 0.3555  lr: 9.5822e-05  max_mem: 23006M
[01/24 16:06:06] d2.utils.events INFO:  eta: 1 day, 18:43:51  iter: 2799  total_loss: 76.5  loss_ce: 2.125  loss_mask: 5.043  loss_dice: 0.4824  loss_ce_0: 2.068  loss_mask_0: 4.548  loss_dice_0: 0.4529  loss_ce_1: 2.016  loss_mask_1: 4.894  loss_dice_1: 0.4559  loss_ce_2: 2.094  loss_mask_2: 5.321  loss_dice_2: 0.4711  loss_ce_3: 2.11  loss_mask_3: 5.429  loss_dice_3: 0.4699  loss_ce_4: 2.079  loss_mask_4: 5.24  loss_dice_4: 0.463  loss_ce_5: 2.06  loss_mask_5: 5.102  loss_dice_5: 0.4609  loss_ce_6: 2.033  loss_mask_6: 5.335  loss_dice_6: 0.4675  loss_ce_7: 2.093  loss_mask_7: 5.032  loss_dice_7: 0.4722  loss_ce_8: 2.106  loss_mask_8: 5.278  loss_dice_8: 0.4737  time: 2.7664  data_time: 0.3729  lr: 9.5792e-05  max_mem: 23006M
[01/24 16:06:58] d2.utils.events INFO:  eta: 1 day, 18:44:04  iter: 2819  total_loss: 78.61  loss_ce: 2.147  loss_mask: 5.863  loss_dice: 0.4801  loss_ce_0: 2.033  loss_mask_0: 4.764  loss_dice_0: 0.4511  loss_ce_1: 2.026  loss_mask_1: 4.923  loss_dice_1: 0.4542  loss_ce_2: 2.104  loss_mask_2: 5.452  loss_dice_2: 0.4707  loss_ce_3: 2.117  loss_mask_3: 5.36  loss_dice_3: 0.472  loss_ce_4: 2.095  loss_mask_4: 5.411  loss_dice_4: 0.4665  loss_ce_5: 2.081  loss_mask_5: 5.245  loss_dice_5: 0.4607  loss_ce_6: 2.05  loss_mask_6: 5.223  loss_dice_6: 0.4596  loss_ce_7: 2.1  loss_mask_7: 5.539  loss_dice_7: 0.4733  loss_ce_8: 2.129  loss_mask_8: 5.415  loss_dice_8: 0.4774  time: 2.7652  data_time: 0.3794  lr: 9.5761e-05  max_mem: 23006M
[01/24 16:07:49] d2.utils.events INFO:  eta: 1 day, 18:39:11  iter: 2839  total_loss: 74.8  loss_ce: 2.064  loss_mask: 5.468  loss_dice: 0.4749  loss_ce_0: 2.068  loss_mask_0: 4.111  loss_dice_0: 0.4478  loss_ce_1: 1.985  loss_mask_1: 4.664  loss_dice_1: 0.4516  loss_ce_2: 2.042  loss_mask_2: 4.988  loss_dice_2: 0.4705  loss_ce_3: 2.065  loss_mask_3: 5.176  loss_dice_3: 0.4755  loss_ce_4: 2.031  loss_mask_4: 4.972  loss_dice_4: 0.4686  loss_ce_5: 2.033  loss_mask_5: 4.953  loss_dice_5: 0.4621  loss_ce_6: 1.996  loss_mask_6: 5.041  loss_dice_6: 0.4573  loss_ce_7: 2.005  loss_mask_7: 4.992  loss_dice_7: 0.4707  loss_ce_8: 2.044  loss_mask_8: 5.083  loss_dice_8: 0.4792  time: 2.7635  data_time: 0.3236  lr: 9.5731e-05  max_mem: 23006M
[01/24 16:08:41] d2.utils.events INFO:  eta: 1 day, 18:36:09  iter: 2859  total_loss: 77.4  loss_ce: 2.105  loss_mask: 5.676  loss_dice: 0.4779  loss_ce_0: 2.077  loss_mask_0: 4.274  loss_dice_0: 0.4477  loss_ce_1: 2.014  loss_mask_1: 4.814  loss_dice_1: 0.458  loss_ce_2: 2.066  loss_mask_2: 5.187  loss_dice_2: 0.4712  loss_ce_3: 2.062  loss_mask_3: 5.356  loss_dice_3: 0.4775  loss_ce_4: 2.064  loss_mask_4: 5.349  loss_dice_4: 0.4729  loss_ce_5: 2.044  loss_mask_5: 5.072  loss_dice_5: 0.4671  loss_ce_6: 2.037  loss_mask_6: 5.164  loss_dice_6: 0.4627  loss_ce_7: 2.03  loss_mask_7: 5.122  loss_dice_7: 0.4704  loss_ce_8: 2.099  loss_mask_8: 5.406  loss_dice_8: 0.4834  time: 2.7626  data_time: 0.3583  lr: 9.5701e-05  max_mem: 23006M
[01/24 16:09:35] d2.utils.events INFO:  eta: 1 day, 18:40:16  iter: 2879  total_loss: 80.7  loss_ce: 2.107  loss_mask: 5.63  loss_dice: 0.4814  loss_ce_0: 2.039  loss_mask_0: 4.697  loss_dice_0: 0.4562  loss_ce_1: 2.041  loss_mask_1: 5.173  loss_dice_1: 0.4691  loss_ce_2: 2.089  loss_mask_2: 5.379  loss_dice_2: 0.4775  loss_ce_3: 2.073  loss_mask_3: 5.546  loss_dice_3: 0.4808  loss_ce_4: 2.057  loss_mask_4: 5.69  loss_dice_4: 0.4782  loss_ce_5: 2.059  loss_mask_5: 5.733  loss_dice_5: 0.4755  loss_ce_6: 2.059  loss_mask_6: 5.506  loss_dice_6: 0.4713  loss_ce_7: 2.065  loss_mask_7: 5.219  loss_dice_7: 0.4772  loss_ce_8: 2.101  loss_mask_8: 5.588  loss_dice_8: 0.4825  time: 2.7621  data_time: 0.3948  lr: 9.5671e-05  max_mem: 23006M
[01/24 16:10:27] d2.utils.events INFO:  eta: 1 day, 18:35:37  iter: 2899  total_loss: 77.38  loss_ce: 2.084  loss_mask: 5.269  loss_dice: 0.4796  loss_ce_0: 2.067  loss_mask_0: 4.775  loss_dice_0: 0.4562  loss_ce_1: 1.989  loss_mask_1: 5.04  loss_dice_1: 0.4674  loss_ce_2: 2.047  loss_mask_2: 5.193  loss_dice_2: 0.4754  loss_ce_3: 2.05  loss_mask_3: 5.391  loss_dice_3: 0.4816  loss_ce_4: 2.048  loss_mask_4: 5.334  loss_dice_4: 0.4796  loss_ce_5: 2.054  loss_mask_5: 5.362  loss_dice_5: 0.4769  loss_ce_6: 2.026  loss_mask_6: 5.485  loss_dice_6: 0.4715  loss_ce_7: 2.029  loss_mask_7: 5.065  loss_dice_7: 0.4716  loss_ce_8: 2.061  loss_mask_8: 5.253  loss_dice_8: 0.4814  time: 2.7608  data_time: 0.4014  lr: 9.5641e-05  max_mem: 23006M
[01/24 16:11:18] d2.utils.events INFO:  eta: 1 day, 18:27:22  iter: 2919  total_loss: 74.19  loss_ce: 2.082  loss_mask: 5.235  loss_dice: 0.4716  loss_ce_0: 2.053  loss_mask_0: 4.184  loss_dice_0: 0.4507  loss_ce_1: 1.98  loss_mask_1: 4.777  loss_dice_1: 0.4664  loss_ce_2: 2.007  loss_mask_2: 4.832  loss_dice_2: 0.4742  loss_ce_3: 2.043  loss_mask_3: 4.906  loss_dice_3: 0.4791  loss_ce_4: 2.021  loss_mask_4: 4.961  loss_dice_4: 0.4767  loss_ce_5: 2.02  loss_mask_5: 5.081  loss_dice_5: 0.475  loss_ce_6: 1.988  loss_mask_6: 4.929  loss_dice_6: 0.4719  loss_ce_7: 2.012  loss_mask_7: 4.804  loss_dice_7: 0.474  loss_ce_8: 2.052  loss_mask_8: 5.071  loss_dice_8: 0.4759  time: 2.7594  data_time: 0.3816  lr: 9.5611e-05  max_mem: 23006M
[01/24 16:12:09] d2.utils.events INFO:  eta: 1 day, 18:23:25  iter: 2939  total_loss: 72.78  loss_ce: 2.066  loss_mask: 5.351  loss_dice: 0.4754  loss_ce_0: 2.038  loss_mask_0: 4.024  loss_dice_0: 0.448  loss_ce_1: 1.974  loss_mask_1: 4.966  loss_dice_1: 0.4632  loss_ce_2: 2.017  loss_mask_2: 4.925  loss_dice_2: 0.4705  loss_ce_3: 2.02  loss_mask_3: 4.93  loss_dice_3: 0.4785  loss_ce_4: 2.002  loss_mask_4: 4.837  loss_dice_4: 0.4783  loss_ce_5: 2.014  loss_mask_5: 4.947  loss_dice_5: 0.4769  loss_ce_6: 1.997  loss_mask_6: 5.191  loss_dice_6: 0.4724  loss_ce_7: 2.001  loss_mask_7: 4.623  loss_dice_7: 0.4725  loss_ce_8: 2.026  loss_mask_8: 5.164  loss_dice_8: 0.478  time: 2.7581  data_time: 0.3801  lr: 9.5581e-05  max_mem: 23006M
[01/24 16:13:00] d2.utils.events INFO:  eta: 1 day, 18:16:45  iter: 2959  total_loss: 73.13  loss_ce: 2.094  loss_mask: 4.969  loss_dice: 0.4781  loss_ce_0: 2.027  loss_mask_0: 4.225  loss_dice_0: 0.4502  loss_ce_1: 1.984  loss_mask_1: 4.68  loss_dice_1: 0.4651  loss_ce_2: 2.049  loss_mask_2: 4.729  loss_dice_2: 0.4746  loss_ce_3: 2.065  loss_mask_3: 4.899  loss_dice_3: 0.4806  loss_ce_4: 2.024  loss_mask_4: 4.829  loss_dice_4: 0.478  loss_ce_5: 2.021  loss_mask_5: 4.796  loss_dice_5: 0.4758  loss_ce_6: 1.999  loss_mask_6: 4.993  loss_dice_6: 0.4704  loss_ce_7: 2.01  loss_mask_7: 4.715  loss_dice_7: 0.4645  loss_ce_8: 2.037  loss_mask_8: 4.935  loss_dice_8: 0.4759  time: 2.7565  data_time: 0.3574  lr: 9.555e-05  max_mem: 23006M
[01/24 16:13:50] d2.utils.events INFO:  eta: 1 day, 18:12:31  iter: 2979  total_loss: 72.91  loss_ce: 2.068  loss_mask: 5.068  loss_dice: 0.4772  loss_ce_0: 2.005  loss_mask_0: 4.089  loss_dice_0: 0.4455  loss_ce_1: 1.962  loss_mask_1: 4.67  loss_dice_1: 0.4578  loss_ce_2: 1.995  loss_mask_2: 4.841  loss_dice_2: 0.477  loss_ce_3: 2.034  loss_mask_3: 4.955  loss_dice_3: 0.4784  loss_ce_4: 1.983  loss_mask_4: 4.7  loss_dice_4: 0.474  loss_ce_5: 1.99  loss_mask_5: 4.668  loss_dice_5: 0.4711  loss_ce_6: 1.982  loss_mask_6: 4.847  loss_dice_6: 0.4687  loss_ce_7: 1.981  loss_mask_7: 4.827  loss_dice_7: 0.4612  loss_ce_8: 2.007  loss_mask_8: 5.003  loss_dice_8: 0.4744  time: 2.7549  data_time: 0.3665  lr: 9.552e-05  max_mem: 23006M
[01/24 16:14:44] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 16:14:44] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 16:14:44] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 16:23:10] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 19.155164150165056, 'error_1pix': 0.9407313474719166, 'error_3pix': 0.8631941443341937, 'mIoU': 0.06479603213841473, 'fwIoU': 0.167343511822175, 'IoU-0': nan, 'IoU-1': 0.00039378474787189917, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0011640342082791485, 'IoU-13': 0.06433728917188547, 'IoU-14': 0.005237128171642305, 'IoU-15': 0.0, 'IoU-16': 2.9128240228753075e-05, 'IoU-17': 4.374698009128057e-05, 'IoU-18': 0.5454465518598935, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.12254484654652437, 'IoU-24': 0.0, 'IoU-25': 1.1328584199760223, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.000552687601757568, 'IoU-30': 0.0002514644249451398, 'IoU-31': 1.1991491627054023, 'IoU-32': 0.0, 'IoU-33': 2.455659461592231, 'IoU-34': 0.058628537262249016, 'IoU-35': 0.05980155162474481, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 2.43842515594293, 'IoU-40': 0.006743091779098357, 'IoU-41': 6.772053361071664e-06, 'IoU-42': 0.0, 'IoU-43': 2.385122074877344, 'IoU-44': 0.0007635958783890751, 'IoU-45': 0.0, 'IoU-46': 0.03513228156224903, 'IoU-47': 0.024172502614261345, 'IoU-48': 0.29392575931533765, 'IoU-49': 0.005097800047787911, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.6133371277509513, 'IoU-54': 0.04934404168908577, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 9.070419954612914e-05, 'IoU-58': 0.0, 'IoU-59': 3.722039296397602e-05, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.17811919956075775, 'IoU-71': 0.0, 'IoU-72': 0.14378603490385033, 'IoU-73': 0.0, 'IoU-74': 0.0017708729425824324, 'IoU-75': 0.0039358798294117725, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.1865878458264365, 'IoU-82': 0.17496719484884618, 'IoU-83': 4.451290529278475e-05, 'IoU-84': 0.0, 'IoU-85': 0.001605820695678494, 'IoU-86': 0.20554166493539347, 'IoU-87': 0.0, 'IoU-88': 0.0024418761472904628, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.043741344763012, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.7059150377071183, 'pACC': 1.9249148872741606, 'ACC-0': nan, 'ACC-1': 0.0003938009024259944, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0011649256504338902, 'ACC-13': 0.06665890434294316, 'ACC-14': 0.005249650647738807, 'ACC-15': 0.0, 'ACC-16': 2.9130438662829182e-05, 'ACC-17': 4.3754477997357544e-05, 'ACC-18': 2.1255229451146596, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.37348552392700596, 'ACC-24': 0.0, 'ACC-25': 8.23646651627952, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0005537898500858616, 'ACC-30': 0.00025152211203336187, 'ACC-31': 3.023279143850525, 'ACC-32': 0.0, 'ACC-33': 66.5119676455762, 'ACC-34': 0.0608506874851984, 'ACC-35': 0.06197515432309693, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 8.030680380038834, 'ACC-40': 0.006865624762215788, 'ACC-41': 6.772143019940339e-06, 'ACC-42': 0.0, 'ACC-43': 40.40258043921408, 'ACC-44': 0.0007636278532434895, 'ACC-45': 0.0, 'ACC-46': 0.035880584607850596, 'ACC-47': 0.02481464525004451, 'ACC-48': 4.440227188550535, 'ACC-49': 0.005107798846073326, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.9694493215933488, 'ACC-54': 0.05024122960325954, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 9.070610948408827e-05, 'ACC-58': 0.0, 'ACC-59': 3.722680550378961e-05, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.19857802418731377, 'ACC-71': 0.0, 'ACC-72': 0.15850414318003433, 'ACC-73': 0.0, 'ACC-74': 0.0017755436186254307, 'ACC-75': 0.003942171295532898, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.21857760020032863, 'ACC-82': 0.20542355077836605, 'ACC-83': 4.4518250757728455e-05, 'ACC-84': 0.0, 'ACC-85': 0.0016085929880158664, 'ACC-86': 0.2645579504644587, 'ACC-87': 0.0, 'ACC-88': 0.002450843002013713, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.045585661445226036, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 16:23:10] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 16:23:10] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 16:23:10] d2.evaluation.testing INFO: copypaste: 19.1552,0.9407,0.8632,0.0648,0.1673,0.7059,1.9249
[01/24 16:23:10] d2.utils.events INFO:  eta: 1 day, 18:11:09  iter: 2999  total_loss: 70.03  loss_ce: 2.075  loss_mask: 4.982  loss_dice: 0.4809  loss_ce_0: 2.006  loss_mask_0: 3.84  loss_dice_0: 0.4418  loss_ce_1: 1.989  loss_mask_1: 4.471  loss_dice_1: 0.4531  loss_ce_2: 2.008  loss_mask_2: 4.437  loss_dice_2: 0.4731  loss_ce_3: 2.033  loss_mask_3: 4.588  loss_dice_3: 0.4755  loss_ce_4: 1.971  loss_mask_4: 4.688  loss_dice_4: 0.4724  loss_ce_5: 2.006  loss_mask_5: 4.584  loss_dice_5: 0.4693  loss_ce_6: 1.988  loss_mask_6: 4.807  loss_dice_6: 0.4717  loss_ce_7: 1.978  loss_mask_7: 4.486  loss_dice_7: 0.4645  loss_ce_8: 2.014  loss_mask_8: 4.793  loss_dice_8: 0.4744  time: 2.7544  data_time: 0.3730  lr: 9.549e-05  max_mem: 23006M
[01/24 16:24:05] d2.utils.events INFO:  eta: 1 day, 18:15:42  iter: 3019  total_loss: 68.71  loss_ce: 1.997  loss_mask: 4.743  loss_dice: 0.4773  loss_ce_0: 2.022  loss_mask_0: 3.762  loss_dice_0: 0.4393  loss_ce_1: 1.943  loss_mask_1: 4.511  loss_dice_1: 0.4519  loss_ce_2: 1.952  loss_mask_2: 4.444  loss_dice_2: 0.4706  loss_ce_3: 1.983  loss_mask_3: 4.632  loss_dice_3: 0.4717  loss_ce_4: 1.929  loss_mask_4: 4.486  loss_dice_4: 0.4677  loss_ce_5: 1.941  loss_mask_5: 4.517  loss_dice_5: 0.4621  loss_ce_6: 1.936  loss_mask_6: 4.581  loss_dice_6: 0.463  loss_ce_7: 1.943  loss_mask_7: 4.517  loss_dice_7: 0.4644  loss_ce_8: 1.975  loss_mask_8: 4.809  loss_dice_8: 0.4671  time: 2.7544  data_time: 0.3950  lr: 9.546e-05  max_mem: 23006M
[01/24 16:24:59] d2.utils.events INFO:  eta: 1 day, 18:17:46  iter: 3039  total_loss: 77.6  loss_ce: 2.035  loss_mask: 5.273  loss_dice: 0.4779  loss_ce_0: 2.009  loss_mask_0: 4.193  loss_dice_0: 0.4425  loss_ce_1: 1.99  loss_mask_1: 5.257  loss_dice_1: 0.4658  loss_ce_2: 2.017  loss_mask_2: 5.162  loss_dice_2: 0.4719  loss_ce_3: 2.039  loss_mask_3: 5.344  loss_dice_3: 0.4762  loss_ce_4: 2.017  loss_mask_4: 5.453  loss_dice_4: 0.472  loss_ce_5: 2.015  loss_mask_5: 5.153  loss_dice_5: 0.4649  loss_ce_6: 2.001  loss_mask_6: 5.308  loss_dice_6: 0.4673  loss_ce_7: 2.012  loss_mask_7: 5.156  loss_dice_7: 0.4681  loss_ce_8: 2.019  loss_mask_8: 5.817  loss_dice_8: 0.4674  time: 2.7537  data_time: 0.3902  lr: 9.543e-05  max_mem: 23006M
[01/24 16:25:52] d2.utils.events INFO:  eta: 1 day, 18:17:30  iter: 3059  total_loss: 74.28  loss_ce: 2.025  loss_mask: 5.258  loss_dice: 0.4727  loss_ce_0: 1.997  loss_mask_0: 3.873  loss_dice_0: 0.4419  loss_ce_1: 1.978  loss_mask_1: 4.989  loss_dice_1: 0.4674  loss_ce_2: 1.987  loss_mask_2: 4.897  loss_dice_2: 0.4713  loss_ce_3: 2.044  loss_mask_3: 5.16  loss_dice_3: 0.477  loss_ce_4: 1.973  loss_mask_4: 5.023  loss_dice_4: 0.4744  loss_ce_5: 1.974  loss_mask_5: 4.896  loss_dice_5: 0.4663  loss_ce_6: 1.971  loss_mask_6: 5.105  loss_dice_6: 0.4692  loss_ce_7: 1.984  loss_mask_7: 5.175  loss_dice_7: 0.4697  loss_ce_8: 2.026  loss_mask_8: 5.427  loss_dice_8: 0.4665  time: 2.7530  data_time: 0.3855  lr: 9.54e-05  max_mem: 23006M
[01/24 16:26:47] d2.utils.events INFO:  eta: 1 day, 18:18:33  iter: 3079  total_loss: 73.44  loss_ce: 2.028  loss_mask: 4.879  loss_dice: 0.465  loss_ce_0: 2.022  loss_mask_0: 3.878  loss_dice_0: 0.4405  loss_ce_1: 1.968  loss_mask_1: 5.041  loss_dice_1: 0.4644  loss_ce_2: 2.034  loss_mask_2: 4.9  loss_dice_2: 0.4649  loss_ce_3: 2.076  loss_mask_3: 4.973  loss_dice_3: 0.4676  loss_ce_4: 1.987  loss_mask_4: 5.094  loss_dice_4: 0.4663  loss_ce_5: 1.972  loss_mask_5: 4.863  loss_dice_5: 0.4656  loss_ce_6: 1.985  loss_mask_6: 4.912  loss_dice_6: 0.4671  loss_ce_7: 2.002  loss_mask_7: 4.95  loss_dice_7: 0.4684  loss_ce_8: 2.04  loss_mask_8: 5.213  loss_dice_8: 0.4637  time: 2.7530  data_time: 0.4313  lr: 9.5369e-05  max_mem: 23006M
[01/24 16:27:38] d2.utils.events INFO:  eta: 1 day, 18:14:23  iter: 3099  total_loss: 80.04  loss_ce: 2.024  loss_mask: 5.124  loss_dice: 0.4742  loss_ce_0: 1.993  loss_mask_0: 3.944  loss_dice_0: 0.4398  loss_ce_1: 2.004  loss_mask_1: 5.255  loss_dice_1: 0.4591  loss_ce_2: 2.072  loss_mask_2: 5.689  loss_dice_2: 0.465  loss_ce_3: 2.108  loss_mask_3: 5.581  loss_dice_3: 0.4645  loss_ce_4: 2.041  loss_mask_4: 5.385  loss_dice_4: 0.4584  loss_ce_5: 2.022  loss_mask_5: 5.533  loss_dice_5: 0.4642  loss_ce_6: 2.008  loss_mask_6: 5.465  loss_dice_6: 0.4659  loss_ce_7: 2.008  loss_mask_7: 5.252  loss_dice_7: 0.4666  loss_ce_8: 1.996  loss_mask_8: 5.587  loss_dice_8: 0.4645  time: 2.7516  data_time: 0.3425  lr: 9.5339e-05  max_mem: 23006M
[01/24 16:28:31] d2.utils.events INFO:  eta: 1 day, 18:08:01  iter: 3119  total_loss: 73.33  loss_ce: 2.022  loss_mask: 4.993  loss_dice: 0.478  loss_ce_0: 1.971  loss_mask_0: 3.737  loss_dice_0: 0.4388  loss_ce_1: 1.98  loss_mask_1: 4.881  loss_dice_1: 0.4566  loss_ce_2: 2.045  loss_mask_2: 5.007  loss_dice_2: 0.4642  loss_ce_3: 2.047  loss_mask_3: 4.991  loss_dice_3: 0.4639  loss_ce_4: 1.996  loss_mask_4: 5.185  loss_dice_4: 0.4612  loss_ce_5: 1.976  loss_mask_5: 4.801  loss_dice_5: 0.4627  loss_ce_6: 1.984  loss_mask_6: 4.872  loss_dice_6: 0.4662  loss_ce_7: 1.996  loss_mask_7: 4.803  loss_dice_7: 0.4687  loss_ce_8: 2.039  loss_mask_8: 5.282  loss_dice_8: 0.4691  time: 2.7513  data_time: 0.3812  lr: 9.5309e-05  max_mem: 23006M
[01/24 16:29:25] d2.utils.events INFO:  eta: 1 day, 18:04:46  iter: 3139  total_loss: 71.87  loss_ce: 1.991  loss_mask: 4.72  loss_dice: 0.4761  loss_ce_0: 1.991  loss_mask_0: 3.758  loss_dice_0: 0.4413  loss_ce_1: 1.971  loss_mask_1: 4.913  loss_dice_1: 0.4577  loss_ce_2: 1.977  loss_mask_2: 4.77  loss_dice_2: 0.464  loss_ce_3: 2.013  loss_mask_3: 4.877  loss_dice_3: 0.4666  loss_ce_4: 1.958  loss_mask_4: 4.884  loss_dice_4: 0.4633  loss_ce_5: 1.968  loss_mask_5: 4.689  loss_dice_5: 0.4619  loss_ce_6: 1.974  loss_mask_6: 4.729  loss_dice_6: 0.4675  loss_ce_7: 1.975  loss_mask_7: 4.746  loss_dice_7: 0.4716  loss_ce_8: 2.033  loss_mask_8: 5.183  loss_dice_8: 0.4686  time: 2.7509  data_time: 0.3796  lr: 9.5279e-05  max_mem: 23006M
[01/24 16:30:17] d2.utils.events INFO:  eta: 1 day, 17:54:15  iter: 3159  total_loss: 73.32  loss_ce: 1.987  loss_mask: 4.996  loss_dice: 0.4736  loss_ce_0: 1.983  loss_mask_0: 3.89  loss_dice_0: 0.4415  loss_ce_1: 1.962  loss_mask_1: 4.836  loss_dice_1: 0.4579  loss_ce_2: 1.962  loss_mask_2: 4.752  loss_dice_2: 0.4631  loss_ce_3: 1.976  loss_mask_3: 4.923  loss_dice_3: 0.4696  loss_ce_4: 1.939  loss_mask_4: 4.841  loss_dice_4: 0.4682  loss_ce_5: 1.991  loss_mask_5: 4.778  loss_dice_5: 0.465  loss_ce_6: 1.977  loss_mask_6: 5.269  loss_dice_6: 0.4645  loss_ce_7: 1.984  loss_mask_7: 4.825  loss_dice_7: 0.4699  loss_ce_8: 2.076  loss_mask_8: 5.248  loss_dice_8: 0.473  time: 2.7499  data_time: 0.3598  lr: 9.5249e-05  max_mem: 23006M
[01/24 16:31:13] d2.utils.events INFO:  eta: 1 day, 17:52:41  iter: 3179  total_loss: 71.75  loss_ce: 1.991  loss_mask: 4.861  loss_dice: 0.4687  loss_ce_0: 1.956  loss_mask_0: 3.791  loss_dice_0: 0.4385  loss_ce_1: 1.976  loss_mask_1: 4.892  loss_dice_1: 0.4534  loss_ce_2: 1.951  loss_mask_2: 4.847  loss_dice_2: 0.4646  loss_ce_3: 1.968  loss_mask_3: 4.788  loss_dice_3: 0.4647  loss_ce_4: 1.943  loss_mask_4: 4.942  loss_dice_4: 0.4616  loss_ce_5: 1.987  loss_mask_5: 4.983  loss_dice_5: 0.457  loss_ce_6: 1.981  loss_mask_6: 4.93  loss_dice_6: 0.4549  loss_ce_7: 1.982  loss_mask_7: 4.927  loss_dice_7: 0.4666  loss_ce_8: 2.089  loss_mask_8: 5.072  loss_dice_8: 0.4663  time: 2.7502  data_time: 0.4141  lr: 9.5219e-05  max_mem: 23006M
[01/24 16:32:06] d2.utils.events INFO:  eta: 1 day, 17:51:02  iter: 3199  total_loss: 72.81  loss_ce: 1.994  loss_mask: 4.785  loss_dice: 0.4733  loss_ce_0: 1.948  loss_mask_0: 3.814  loss_dice_0: 0.4403  loss_ce_1: 1.96  loss_mask_1: 4.86  loss_dice_1: 0.4527  loss_ce_2: 1.949  loss_mask_2: 4.816  loss_dice_2: 0.4638  loss_ce_3: 1.991  loss_mask_3: 4.843  loss_dice_3: 0.465  loss_ce_4: 1.938  loss_mask_4: 4.9  loss_dice_4: 0.4658  loss_ce_5: 1.97  loss_mask_5: 4.884  loss_dice_5: 0.4639  loss_ce_6: 1.978  loss_mask_6: 4.884  loss_dice_6: 0.4587  loss_ce_7: 1.979  loss_mask_7: 5.035  loss_dice_7: 0.4676  loss_ce_8: 2.082  loss_mask_8: 5.084  loss_dice_8: 0.4678  time: 2.7496  data_time: 0.3660  lr: 9.5188e-05  max_mem: 23006M
[01/24 16:33:01] d2.utils.events INFO:  eta: 1 day, 17:49:24  iter: 3219  total_loss: 70.69  loss_ce: 1.984  loss_mask: 4.655  loss_dice: 0.4694  loss_ce_0: 1.953  loss_mask_0: 3.568  loss_dice_0: 0.4368  loss_ce_1: 1.98  loss_mask_1: 4.545  loss_dice_1: 0.4546  loss_ce_2: 1.947  loss_mask_2: 4.683  loss_dice_2: 0.4618  loss_ce_3: 1.999  loss_mask_3: 4.78  loss_dice_3: 0.4651  loss_ce_4: 1.935  loss_mask_4: 4.716  loss_dice_4: 0.4588  loss_ce_5: 1.961  loss_mask_5: 4.889  loss_dice_5: 0.4648  loss_ce_6: 1.971  loss_mask_6: 4.641  loss_dice_6: 0.4634  loss_ce_7: 1.99  loss_mask_7: 4.868  loss_dice_7: 0.4711  loss_ce_8: 2.025  loss_mask_8: 5.149  loss_dice_8: 0.4673  time: 2.7494  data_time: 0.4056  lr: 9.5158e-05  max_mem: 23006M
[01/24 16:33:55] d2.utils.events INFO:  eta: 1 day, 17:48:19  iter: 3239  total_loss: 70.34  loss_ce: 1.969  loss_mask: 4.413  loss_dice: 0.4658  loss_ce_0: 1.966  loss_mask_0: 3.642  loss_dice_0: 0.4382  loss_ce_1: 2.004  loss_mask_1: 4.714  loss_dice_1: 0.4478  loss_ce_2: 1.96  loss_mask_2: 4.683  loss_dice_2: 0.4497  loss_ce_3: 2.012  loss_mask_3: 4.823  loss_dice_3: 0.4533  loss_ce_4: 1.969  loss_mask_4: 4.889  loss_dice_4: 0.4523  loss_ce_5: 2.039  loss_mask_5: 4.726  loss_dice_5: 0.4503  loss_ce_6: 2.001  loss_mask_6: 4.556  loss_dice_6: 0.4566  loss_ce_7: 2.014  loss_mask_7: 4.598  loss_dice_7: 0.4603  loss_ce_8: 2.035  loss_mask_8: 4.969  loss_dice_8: 0.4589  time: 2.7490  data_time: 0.3725  lr: 9.5128e-05  max_mem: 23006M
[01/24 16:34:46] d2.utils.events INFO:  eta: 1 day, 17:43:02  iter: 3259  total_loss: 70.46  loss_ce: 1.934  loss_mask: 4.618  loss_dice: 0.4684  loss_ce_0: 1.944  loss_mask_0: 3.595  loss_dice_0: 0.4366  loss_ce_1: 1.938  loss_mask_1: 4.728  loss_dice_1: 0.4508  loss_ce_2: 1.906  loss_mask_2: 4.586  loss_dice_2: 0.453  loss_ce_3: 1.969  loss_mask_3: 4.501  loss_dice_3: 0.4539  loss_ce_4: 1.914  loss_mask_4: 4.67  loss_dice_4: 0.4592  loss_ce_5: 1.957  loss_mask_5: 4.721  loss_dice_5: 0.4558  loss_ce_6: 1.916  loss_mask_6: 4.782  loss_dice_6: 0.4542  loss_ce_7: 1.937  loss_mask_7: 4.578  loss_dice_7: 0.4645  loss_ce_8: 2.045  loss_mask_8: 5.02  loss_dice_8: 0.4678  time: 2.7480  data_time: 0.4007  lr: 9.5098e-05  max_mem: 23006M
[01/24 16:35:41] d2.utils.events INFO:  eta: 1 day, 17:43:36  iter: 3279  total_loss: 68.6  loss_ce: 1.927  loss_mask: 4.412  loss_dice: 0.4698  loss_ce_0: 1.94  loss_mask_0: 3.693  loss_dice_0: 0.4355  loss_ce_1: 1.922  loss_mask_1: 4.552  loss_dice_1: 0.4543  loss_ce_2: 1.906  loss_mask_2: 4.473  loss_dice_2: 0.4598  loss_ce_3: 1.956  loss_mask_3: 4.572  loss_dice_3: 0.4662  loss_ce_4: 1.924  loss_mask_4: 4.641  loss_dice_4: 0.4633  loss_ce_5: 1.953  loss_mask_5: 4.756  loss_dice_5: 0.4641  loss_ce_6: 1.937  loss_mask_6: 4.579  loss_dice_6: 0.4617  loss_ce_7: 1.936  loss_mask_7: 4.499  loss_dice_7: 0.4638  loss_ce_8: 1.978  loss_mask_8: 4.743  loss_dice_8: 0.4659  time: 2.7480  data_time: 0.4222  lr: 9.5068e-05  max_mem: 23006M
[01/24 16:36:34] d2.utils.events INFO:  eta: 1 day, 17:41:40  iter: 3299  total_loss: 69.9  loss_ce: 2.003  loss_mask: 4.569  loss_dice: 0.4719  loss_ce_0: 1.928  loss_mask_0: 3.715  loss_dice_0: 0.4373  loss_ce_1: 1.942  loss_mask_1: 4.451  loss_dice_1: 0.4492  loss_ce_2: 1.936  loss_mask_2: 4.46  loss_dice_2: 0.4621  loss_ce_3: 1.984  loss_mask_3: 4.645  loss_dice_3: 0.4658  loss_ce_4: 1.972  loss_mask_4: 4.709  loss_dice_4: 0.4669  loss_ce_5: 1.988  loss_mask_5: 4.703  loss_dice_5: 0.4617  loss_ce_6: 1.989  loss_mask_6: 4.628  loss_dice_6: 0.4619  loss_ce_7: 1.967  loss_mask_7: 4.781  loss_dice_7: 0.4675  loss_ce_8: 2.015  loss_mask_8: 4.902  loss_dice_8: 0.4665  time: 2.7472  data_time: 0.3679  lr: 9.5038e-05  max_mem: 23006M
[01/24 16:37:27] d2.utils.events INFO:  eta: 1 day, 17:40:23  iter: 3319  total_loss: 73.02  loss_ce: 1.962  loss_mask: 5.069  loss_dice: 0.475  loss_ce_0: 1.929  loss_mask_0: 4.03  loss_dice_0: 0.4419  loss_ce_1: 1.946  loss_mask_1: 4.827  loss_dice_1: 0.457  loss_ce_2: 1.946  loss_mask_2: 4.869  loss_dice_2: 0.4639  loss_ce_3: 1.951  loss_mask_3: 4.919  loss_dice_3: 0.4697  loss_ce_4: 1.958  loss_mask_4: 4.874  loss_dice_4: 0.4716  loss_ce_5: 1.978  loss_mask_5: 4.754  loss_dice_5: 0.4697  loss_ce_6: 1.978  loss_mask_6: 4.882  loss_dice_6: 0.4708  loss_ce_7: 1.979  loss_mask_7: 4.893  loss_dice_7: 0.4716  loss_ce_8: 2.008  loss_mask_8: 5.205  loss_dice_8: 0.4713  time: 2.7467  data_time: 0.3302  lr: 9.5007e-05  max_mem: 23006M
[01/24 16:38:23] d2.utils.events INFO:  eta: 1 day, 17:43:25  iter: 3339  total_loss: 70.95  loss_ce: 1.952  loss_mask: 4.684  loss_dice: 0.4732  loss_ce_0: 1.922  loss_mask_0: 3.903  loss_dice_0: 0.4396  loss_ce_1: 1.954  loss_mask_1: 4.528  loss_dice_1: 0.4556  loss_ce_2: 1.927  loss_mask_2: 4.75  loss_dice_2: 0.4599  loss_ce_3: 1.959  loss_mask_3: 4.756  loss_dice_3: 0.4676  loss_ce_4: 1.986  loss_mask_4: 4.823  loss_dice_4: 0.4705  loss_ce_5: 1.966  loss_mask_5: 4.743  loss_dice_5: 0.4705  loss_ce_6: 1.961  loss_mask_6: 4.908  loss_dice_6: 0.47  loss_ce_7: 1.96  loss_mask_7: 4.654  loss_dice_7: 0.4697  loss_ce_8: 1.976  loss_mask_8: 4.918  loss_dice_8: 0.469  time: 2.7471  data_time: 0.4149  lr: 9.4977e-05  max_mem: 23006M
[01/24 16:39:16] d2.utils.events INFO:  eta: 1 day, 17:37:49  iter: 3359  total_loss: 66.95  loss_ce: 1.983  loss_mask: 4.48  loss_dice: 0.4687  loss_ce_0: 1.903  loss_mask_0: 3.626  loss_dice_0: 0.4404  loss_ce_1: 1.949  loss_mask_1: 4.237  loss_dice_1: 0.449  loss_ce_2: 1.928  loss_mask_2: 4.484  loss_dice_2: 0.4562  loss_ce_3: 1.939  loss_mask_3: 4.411  loss_dice_3: 0.4634  loss_ce_4: 1.95  loss_mask_4: 4.407  loss_dice_4: 0.462  loss_ce_5: 1.968  loss_mask_5: 4.539  loss_dice_5: 0.4638  loss_ce_6: 1.962  loss_mask_6: 4.295  loss_dice_6: 0.4677  loss_ce_7: 1.966  loss_mask_7: 4.379  loss_dice_7: 0.4672  loss_ce_8: 1.997  loss_mask_8: 4.427  loss_dice_8: 0.4621  time: 2.7463  data_time: 0.3660  lr: 9.4947e-05  max_mem: 23006M
[01/24 16:40:11] d2.utils.events INFO:  eta: 1 day, 17:38:09  iter: 3379  total_loss: 69.77  loss_ce: 1.925  loss_mask: 4.703  loss_dice: 0.4667  loss_ce_0: 1.899  loss_mask_0: 3.683  loss_dice_0: 0.4391  loss_ce_1: 1.928  loss_mask_1: 4.464  loss_dice_1: 0.4494  loss_ce_2: 1.904  loss_mask_2: 4.489  loss_dice_2: 0.4571  loss_ce_3: 1.925  loss_mask_3: 4.632  loss_dice_3: 0.4649  loss_ce_4: 1.924  loss_mask_4: 4.671  loss_dice_4: 0.4642  loss_ce_5: 1.939  loss_mask_5: 4.595  loss_dice_5: 0.466  loss_ce_6: 1.931  loss_mask_6: 4.744  loss_dice_6: 0.4703  loss_ce_7: 1.945  loss_mask_7: 4.707  loss_dice_7: 0.4714  loss_ce_8: 1.955  loss_mask_8: 4.718  loss_dice_8: 0.4628  time: 2.7465  data_time: 0.4026  lr: 9.4917e-05  max_mem: 23006M
[01/24 16:41:04] d2.utils.events INFO:  eta: 1 day, 17:39:49  iter: 3399  total_loss: 68.72  loss_ce: 1.915  loss_mask: 4.57  loss_dice: 0.4659  loss_ce_0: 1.903  loss_mask_0: 3.501  loss_dice_0: 0.4383  loss_ce_1: 1.912  loss_mask_1: 4.51  loss_dice_1: 0.4505  loss_ce_2: 1.906  loss_mask_2: 4.303  loss_dice_2: 0.454  loss_ce_3: 1.937  loss_mask_3: 4.513  loss_dice_3: 0.46  loss_ce_4: 1.916  loss_mask_4: 4.549  loss_dice_4: 0.4631  loss_ce_5: 1.932  loss_mask_5: 4.436  loss_dice_5: 0.4655  loss_ce_6: 1.949  loss_mask_6: 4.613  loss_dice_6: 0.4694  loss_ce_7: 1.924  loss_mask_7: 4.441  loss_dice_7: 0.4679  loss_ce_8: 1.964  loss_mask_8: 4.691  loss_dice_8: 0.4634  time: 2.7458  data_time: 0.3629  lr: 9.4887e-05  max_mem: 23006M
[01/24 16:41:55] d2.utils.events INFO:  eta: 1 day, 17:36:23  iter: 3419  total_loss: 66.97  loss_ce: 1.972  loss_mask: 4.279  loss_dice: 0.4616  loss_ce_0: 1.9  loss_mask_0: 3.361  loss_dice_0: 0.439  loss_ce_1: 1.95  loss_mask_1: 4.214  loss_dice_1: 0.4451  loss_ce_2: 1.943  loss_mask_2: 4.152  loss_dice_2: 0.4529  loss_ce_3: 1.989  loss_mask_3: 4.193  loss_dice_3: 0.4564  loss_ce_4: 1.979  loss_mask_4: 4.396  loss_dice_4: 0.4604  loss_ce_5: 2.018  loss_mask_5: 4.352  loss_dice_5: 0.4632  loss_ce_6: 2.022  loss_mask_6: 4.314  loss_dice_6: 0.4672  loss_ce_7: 1.972  loss_mask_7: 4.326  loss_dice_7: 0.4661  loss_ce_8: 1.97  loss_mask_8: 4.577  loss_dice_8: 0.4592  time: 2.7447  data_time: 0.3509  lr: 9.4857e-05  max_mem: 23006M
[01/24 16:42:51] d2.utils.events INFO:  eta: 1 day, 17:39:19  iter: 3439  total_loss: 64.79  loss_ce: 1.966  loss_mask: 4.225  loss_dice: 0.4621  loss_ce_0: 1.889  loss_mask_0: 3.176  loss_dice_0: 0.4382  loss_ce_1: 2.003  loss_mask_1: 4.05  loss_dice_1: 0.4375  loss_ce_2: 1.966  loss_mask_2: 4.187  loss_dice_2: 0.4499  loss_ce_3: 2.022  loss_mask_3: 4.258  loss_dice_3: 0.4554  loss_ce_4: 1.982  loss_mask_4: 4.291  loss_dice_4: 0.4579  loss_ce_5: 2.017  loss_mask_5: 4.256  loss_dice_5: 0.4574  loss_ce_6: 2.046  loss_mask_6: 4.058  loss_dice_6: 0.4632  loss_ce_7: 1.974  loss_mask_7: 4.253  loss_dice_7: 0.4635  loss_ce_8: 2.025  loss_mask_8: 4.469  loss_dice_8: 0.4592  time: 2.7450  data_time: 0.4368  lr: 9.4826e-05  max_mem: 23006M
[01/24 16:43:43] d2.utils.events INFO:  eta: 1 day, 17:35:39  iter: 3459  total_loss: 66.8  loss_ce: 1.966  loss_mask: 4.333  loss_dice: 0.4644  loss_ce_0: 1.889  loss_mask_0: 3.335  loss_dice_0: 0.4397  loss_ce_1: 1.977  loss_mask_1: 4.067  loss_dice_1: 0.4379  loss_ce_2: 1.943  loss_mask_2: 4.154  loss_dice_2: 0.4508  loss_ce_3: 1.983  loss_mask_3: 4.345  loss_dice_3: 0.4574  loss_ce_4: 1.966  loss_mask_4: 4.312  loss_dice_4: 0.4562  loss_ce_5: 1.951  loss_mask_5: 4.227  loss_dice_5: 0.4527  loss_ce_6: 1.966  loss_mask_6: 4.275  loss_dice_6: 0.4613  loss_ce_7: 1.957  loss_mask_7: 4.464  loss_dice_7: 0.4627  loss_ce_8: 2.012  loss_mask_8: 4.479  loss_dice_8: 0.4579  time: 2.7442  data_time: 0.3555  lr: 9.4796e-05  max_mem: 23006M
[01/24 16:44:36] d2.utils.events INFO:  eta: 1 day, 17:34:46  iter: 3479  total_loss: 68.15  loss_ce: 1.931  loss_mask: 4.541  loss_dice: 0.4645  loss_ce_0: 1.902  loss_mask_0: 3.541  loss_dice_0: 0.4428  loss_ce_1: 1.952  loss_mask_1: 4.395  loss_dice_1: 0.4427  loss_ce_2: 1.924  loss_mask_2: 4.357  loss_dice_2: 0.4548  loss_ce_3: 1.93  loss_mask_3: 4.373  loss_dice_3: 0.4573  loss_ce_4: 1.915  loss_mask_4: 4.469  loss_dice_4: 0.4584  loss_ce_5: 1.925  loss_mask_5: 4.472  loss_dice_5: 0.4547  loss_ce_6: 1.93  loss_mask_6: 4.404  loss_dice_6: 0.463  loss_ce_7: 1.938  loss_mask_7: 4.462  loss_dice_7: 0.4637  loss_ce_8: 1.964  loss_mask_8: 4.551  loss_dice_8: 0.4591  time: 2.7436  data_time: 0.3863  lr: 9.4766e-05  max_mem: 23006M
[01/24 16:45:33] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/24 16:45:34] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/24 16:45:34] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/24 16:53:59] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 12.60864135623078, 'error_1pix': 0.8233803165460214, 'error_3pix': 0.7061157496075507, 'mIoU': 0.48676017228241025, 'fwIoU': 6.24662252411332, 'IoU-0': nan, 'IoU-1': 55.55521964697135, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.10428075664216084, 'IoU-14': 6.807065713924584, 'IoU-15': 0.37181333507078235, 'IoU-16': 0.0, 'IoU-17': 1.8751701130886968e-05, 'IoU-18': 0.03788770896439394, 'IoU-19': 0.2298342331870944, 'IoU-20': 0.0, 'IoU-21': 0.00011073481558567988, 'IoU-22': 0.005705563956183709, 'IoU-23': 0.4949960298080914, 'IoU-24': 1.9109379729043543, 'IoU-25': 2.2394131502873993, 'IoU-26': 0.019066259931823003, 'IoU-27': 0.03176995561363354, 'IoU-28': 0.16738594329626344, 'IoU-29': 1.2959531224701277, 'IoU-30': 0.9157103642884454, 'IoU-31': 3.608677040406858, 'IoU-32': 0.09330033413416164, 'IoU-33': 3.453943255913932, 'IoU-34': 1.7791817232598195, 'IoU-35': 0.012438589999982833, 'IoU-36': 0.4055014643891835, 'IoU-37': 0.6894807227477158, 'IoU-38': 1.1816293236603033, 'IoU-39': 0.004099097383498421, 'IoU-40': 0.22179358862095003, 'IoU-41': 0.010386127111310189, 'IoU-42': 0.0637098433359549, 'IoU-43': 0.001127875135636081, 'IoU-44': 0.7743803641486464, 'IoU-45': 0.0038314089468494874, 'IoU-46': 2.833642057399237, 'IoU-47': 0.8249237445132954, 'IoU-48': 0.0, 'IoU-49': 0.31309462975218333, 'IoU-50': 0.04832761308325069, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 3.8872389719030366e-05, 'IoU-58': 6.926445306709925e-06, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.00013826046945144145, 'IoU-64': 0.0, 'IoU-65': 0.06298112971936021, 'IoU-66': 6.131408343620474e-05, 'IoU-67': 0.39909491041183187, 'IoU-68': 0.0, 'IoU-69': 0.037298726929091135, 'IoU-70': 0.0015724906584556623, 'IoU-71': 0.9937384318482669, 'IoU-72': 0.021524103728233986, 'IoU-73': 0.018909731737227736, 'IoU-74': 0.04545566141043282, 'IoU-75': 0.14878052529844243, 'IoU-76': 1.0175684778135397, 'IoU-77': 0.004918054548188557, 'IoU-78': 1.6321022771502998, 'IoU-79': 0.0, 'IoU-80': 0.10610281696774718, 'IoU-81': 1.419143655595568, 'IoU-82': 0.0, 'IoU-83': 0.0005668754027872041, 'IoU-84': 0.0059033542723005445, 'IoU-85': 0.31540527867115326, 'IoU-86': 0.36690781987721105, 'IoU-87': 0.009708028321263745, 'IoU-88': 0.0026987206055979246, 'IoU-89': 0.0, 'IoU-90': 0.0002962358851650607, 'IoU-91': 0.004611870411867156, 'IoU-92': 0.16943790678529766, 'IoU-93': 0.0, 'IoU-94': 0.15406312725910812, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.008279445750245919, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 1.7121369243985052, 'pACC': 11.184210149724029, 'ACC-0': nan, 'ACC-1': 77.81796802229982, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.10532605111520553, 'ACC-14': 58.083689108494994, 'ACC-15': 0.40457468894224446, 'ACC-16': 0.0, 'ACC-17': 1.875191914172466e-05, 'ACC-18': 0.0399298526389057, 'ACC-19': 0.25648542672113184, 'ACC-20': 0.0, 'ACC-21': 0.00011074463615837513, 'ACC-22': 0.0057307054623731155, 'ACC-23': 0.5843816928970421, 'ACC-24': 3.9157340561589, 'ACC-25': 7.439975004183319, 'ACC-26': 0.01927057952383088, 'ACC-27': 0.03198705743601108, 'ACC-28': 0.18176562082436706, 'ACC-29': 2.0949278602694656, 'ACC-30': 1.17604084565999, 'ACC-31': 26.881845169962688, 'ACC-32': 0.09578425312941874, 'ACC-33': 35.824374153812684, 'ACC-34': 10.060495333983912, 'ACC-35': 0.0124538066216047, 'ACC-36': 0.4846240455383777, 'ACC-37': 0.8015757938969035, 'ACC-38': 1.5989794109169928, 'ACC-39': 0.004109886905005833, 'ACC-40': 0.23736582009903084, 'ACC-41': 0.01039523953560842, 'ACC-42': 0.06477401265057006, 'ACC-43': 0.0011286226831242183, 'ACC-44': 1.0487908723741957, 'ACC-45': 0.0038408027739450686, 'ACC-46': 9.850625821757568, 'ACC-47': 1.1702927501915839, 'ACC-48': 0.0, 'ACC-49': 0.367116799196264, 'ACC-50': 0.05040481618183446, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 3.8874046921752116e-05, 'ACC-58': 6.9266141850963085e-06, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0001383422831567717, 'ACC-64': 0.0, 'ACC-65': 0.06525587236081937, 'ACC-66': 6.132383440765878e-05, 'ACC-67': 0.5755179661695525, 'ACC-68': 0.0, 'ACC-69': 0.04019684697838871, 'ACC-70': 0.0015779492082507469, 'ACC-71': 5.695032876547695, 'ACC-72': 0.02163799270700532, 'ACC-73': 0.019060192197453425, 'ACC-74': 0.047798069929622024, 'ACC-75': 0.1765022566473635, 'ACC-76': 9.648318470328427, 'ACC-77': 0.004934132604595424, 'ACC-78': 46.336306198204745, 'ACC-79': 0.0, 'ACC-80': 0.13426617101785854, 'ACC-81': 23.873467203387857, 'ACC-82': 0.0, 'ACC-83': 0.0005676076971610377, 'ACC-84': 0.005909030643370947, 'ACC-85': 0.36795118024434875, 'ACC-86': 0.4705479171842306, 'ACC-87': 0.009799948908131535, 'ACC-88': 0.002702211515040761, 'ACC-89': 0.0, 'ACC-90': 0.00029961586640571425, 'ACC-91': 0.00462660444518712, 'ACC-92': 0.31211255220302486, 'ACC-93': 0.0, 'ACC-94': 0.1801327572491005, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.008628912094498915, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/24 16:53:59] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/24 16:53:59] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/24 16:53:59] d2.evaluation.testing INFO: copypaste: 12.6086,0.8234,0.7061,0.4868,6.2466,1.7121,11.1842
[01/24 16:53:59] d2.utils.events INFO:  eta: 1 day, 17:39:43  iter: 3499  total_loss: 70.95  loss_ce: 1.968  loss_mask: 4.925  loss_dice: 0.4688  loss_ce_0: 1.849  loss_mask_0: 3.915  loss_dice_0: 0.4435  loss_ce_1: 1.943  loss_mask_1: 4.589  loss_dice_1: 0.4445  loss_ce_2: 1.926  loss_mask_2: 4.658  loss_dice_2: 0.4559  loss_ce_3: 1.94  loss_mask_3: 4.869  loss_dice_3: 0.4586  loss_ce_4: 1.931  loss_mask_4: 4.767  loss_dice_4: 0.4571  loss_ce_5: 1.977  loss_mask_5: 4.912  loss_dice_5: 0.4549  loss_ce_6: 1.949  loss_mask_6: 4.977  loss_dice_6: 0.4615  loss_ce_7: 1.964  loss_mask_7: 4.897  loss_dice_7: 0.4636  loss_ce_8: 1.98  loss_mask_8: 4.782  loss_dice_8: 0.4629  time: 2.7442  data_time: 0.4148  lr: 9.4736e-05  max_mem: 23006M
[01/24 16:54:21] d2.engine.hooks INFO: Overall training speed: 3505 iterations in 2:40:21 (2.7451 s / it)
[01/24 16:54:21] d2.engine.hooks INFO: Total training time: 3:36:22 (0:56:01 on hooks)
[01/24 16:54:21] d2.utils.events INFO:  eta: 1 day, 17:38:51  iter: 3507  total_loss: 70.25  loss_ce: 1.957  loss_mask: 4.652  loss_dice: 0.4679  loss_ce_0: 1.849  loss_mask_0: 3.81  loss_dice_0: 0.4428  loss_ce_1: 1.94  loss_mask_1: 4.417  loss_dice_1: 0.4454  loss_ce_2: 1.916  loss_mask_2: 4.7  loss_dice_2: 0.4552  loss_ce_3: 1.939  loss_mask_3: 4.681  loss_dice_3: 0.4582  loss_ce_4: 1.928  loss_mask_4: 4.757  loss_dice_4: 0.457  loss_ce_5: 1.98  loss_mask_5: 4.959  loss_dice_5: 0.4546  loss_ce_6: 1.949  loss_mask_6: 4.809  loss_dice_6: 0.4607  loss_ce_7: 1.961  loss_mask_7: 4.8  loss_dice_7: 0.4632  loss_ce_8: 1.98  loss_mask_8: 4.698  loss_dice_8: 0.4629  time: 2.7445  data_time: 0.4069  lr: 9.4725e-05  max_mem: 23006M
