[01/19 00:39:16] detectron2 INFO: Rank of current process: 0. World size: 4
[01/19 00:39:19] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/19 00:39:19] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/19 00:39:19] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/19 00:39:19] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m192[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop192x384[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/19 00:39:19] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop192x384/config.yaml
[01/19 00:39:19] d2.utils.env INFO: Using a generated random seed 20080168
[01/19 00:39:21] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/19 00:39:21] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 00:39:25] d2.data.build INFO: Using training sampler TrainingSampler
[01/19 00:39:25] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/19 00:39:26] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/19 00:39:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/19 00:39:26] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/19 00:39:26] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/19 00:39:26] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/19 00:39:26] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/19 00:39:26] d2.engine.train_loop INFO: Starting training from iteration 0
[01/19 00:41:03] d2.utils.events INFO:  eta: 1 day, 18:24:09  iter: 19  total_loss: 142.9  loss_ce: 8.961  loss_mask: 0.5173  loss_dice: 4.918  loss_ce_0: 10.03  loss_mask_0: 0.614  loss_dice_0: 4.775  loss_ce_1: 8.892  loss_mask_1: 0.5666  loss_dice_1: 4.81  loss_ce_2: 8.872  loss_mask_2: 0.5337  loss_dice_2: 4.848  loss_ce_3: 8.781  loss_mask_3: 0.5149  loss_dice_3: 4.886  loss_ce_4: 8.754  loss_mask_4: 0.5128  loss_dice_4: 4.905  loss_ce_5: 8.728  loss_mask_5: 0.5015  loss_dice_5: 4.911  loss_ce_6: 8.757  loss_mask_6: 0.51  loss_dice_6: 4.921  loss_ce_7: 8.817  loss_mask_7: 0.5078  loss_dice_7: 4.917  loss_ce_8: 8.827  loss_mask_8: 0.5064  loss_dice_8: 4.918  time: 3.8699  data_time: 1.2014  lr: 9.9957e-06  max_mem: 29132M
[01/19 00:41:40] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 395, in run_step
    loss_dict = self.model(data)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 799, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 260, in forward
    losses = self.criterion(outputs, targets)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/modeling/criterion.py", line 265, in forward
    l_dict = self.get_loss(loss, aux_outputs, targets, indices, num_masks)
  File "/home/nstarli/Mask2Former/mask2former/modeling/criterion.py", line 232, in get_loss
    return loss_map[loss](outputs, targets, indices, num_masks)
  File "/home/nstarli/Mask2Former/mask2former/modeling/criterion.py", line 185, in loss_masks
    point_coords = get_uncertain_point_coords_with_randomness(
  File "/home/nstarli/detectron2/projects/PointRend/point_rend/point_features.py", line 91, in get_uncertain_point_coords_with_randomness
    point_logits = point_sample(coarse_logits, point_coords, align_corners=False)
  File "/home/nstarli/detectron2/projects/PointRend/point_rend/point_features.py", line 39, in point_sample
    output = F.grid_sample(input, 2.0 * point_coords - 1.0, **kwargs)
RuntimeError: CUDA out of memory. Tried to allocate 644.00 MiB (GPU 0; 31.75 GiB total capacity; 28.07 GiB already allocated; 571.75 MiB free; 29.73 GiB reserved in total by PyTorch)
[01/19 00:41:40] d2.engine.hooks INFO: Overall training speed: 28 iterations in 0:01:46 (3.8193 s / it)
[01/19 00:41:40] d2.engine.hooks INFO: Total training time: 0:01:46 (0:00:00 on hooks)
[01/19 00:41:40] d2.utils.events INFO:  eta: 1 day, 17:15:25  iter: 30  total_loss: 137.6  loss_ce: 8.322  loss_mask: 0.4653  loss_dice: 4.92  loss_ce_0: 10.08  loss_mask_0: 0.5798  loss_dice_0: 4.762  loss_ce_1: 8.02  loss_mask_1: 0.5607  loss_dice_1: 4.781  loss_ce_2: 8.059  loss_mask_2: 0.5308  loss_dice_2: 4.816  loss_ce_3: 8.163  loss_mask_3: 0.4755  loss_dice_3: 4.858  loss_ce_4: 8.257  loss_mask_4: 0.4659  loss_dice_4: 4.884  loss_ce_5: 8.271  loss_mask_5: 0.4546  loss_dice_5: 4.904  loss_ce_6: 8.299  loss_mask_6: 0.4607  loss_dice_6: 4.918  loss_ce_7: 8.318  loss_mask_7: 0.4651  loss_dice_7: 4.92  loss_ce_8: 8.336  loss_mask_8: 0.4598  loss_dice_8: 4.918  time: 3.7109  data_time: 0.8198  lr: 9.9935e-06  max_mem: 29132M
[01/19 00:42:35] detectron2 INFO: Rank of current process: 0. World size: 4
[01/19 00:42:38] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/19 00:42:38] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/19 00:42:38] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/19 00:42:38] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m192[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop192x384[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/19 00:42:38] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop192x384/config.yaml
[01/19 00:42:39] d2.utils.env INFO: Using a generated random seed 39165732
[01/19 00:42:40] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/19 00:42:40] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 00:42:45] d2.data.build INFO: Using training sampler TrainingSampler
[01/19 00:42:45] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/19 00:42:45] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/19 00:42:45] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/19 00:42:45] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/19 00:42:45] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/19 00:42:45] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/19 00:42:45] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/19 00:42:45] d2.engine.train_loop INFO: Starting training from iteration 0
[01/19 00:43:50] d2.utils.events INFO:  eta: 1 day, 0:31:26  iter: 19  total_loss: 141.2  loss_ce: 8.626  loss_mask: 0.5267  loss_dice: 4.923  loss_ce_0: 9.872  loss_mask_0: 0.554  loss_dice_0: 4.813  loss_ce_1: 8.382  loss_mask_1: 0.539  loss_dice_1: 4.835  loss_ce_2: 8.622  loss_mask_2: 0.5339  loss_dice_2: 4.876  loss_ce_3: 8.668  loss_mask_3: 0.5351  loss_dice_3: 4.901  loss_ce_4: 8.659  loss_mask_4: 0.5202  loss_dice_4: 4.918  loss_ce_5: 8.713  loss_mask_5: 0.5229  loss_dice_5: 4.922  loss_ce_6: 8.644  loss_mask_6: 0.5244  loss_dice_6: 4.924  loss_ce_7: 8.644  loss_mask_7: 0.524  loss_dice_7: 4.921  loss_ce_8: 8.63  loss_mask_8: 0.5264  loss_dice_8: 4.923  time: 2.2631  data_time: 0.7143  lr: 9.9957e-06  max_mem: 15664M
[01/19 00:44:26] d2.utils.events INFO:  eta: 22:50:13  iter: 39  total_loss: 134.4  loss_ce: 8.101  loss_mask: 0.4711  loss_dice: 4.915  loss_ce_0: 10.04  loss_mask_0: 0.6137  loss_dice_0: 4.726  loss_ce_1: 7.764  loss_mask_1: 0.5997  loss_dice_1: 4.71  loss_ce_2: 7.75  loss_mask_2: 0.5876  loss_dice_2: 4.7  loss_ce_3: 7.776  loss_mask_3: 0.5492  loss_dice_3: 4.759  loss_ce_4: 7.889  loss_mask_4: 0.5076  loss_dice_4: 4.804  loss_ce_5: 7.979  loss_mask_5: 0.5097  loss_dice_5: 4.86  loss_ce_6: 8.064  loss_mask_6: 0.4842  loss_dice_6: 4.898  loss_ce_7: 8.101  loss_mask_7: 0.4842  loss_dice_7: 4.91  loss_ce_8: 8.096  loss_mask_8: 0.48  loss_dice_8: 4.913  time: 2.0388  data_time: 0.3350  lr: 9.9912e-06  max_mem: 15664M
[01/19 00:45:02] d2.utils.events INFO:  eta: 20:40:11  iter: 59  total_loss: 130.9  loss_ce: 7.975  loss_mask: 0.4995  loss_dice: 4.659  loss_ce_0: 10.06  loss_mask_0: 0.631  loss_dice_0: 4.526  loss_ce_1: 7.502  loss_mask_1: 0.6363  loss_dice_1: 4.517  loss_ce_2: 7.493  loss_mask_2: 0.6337  loss_dice_2: 4.524  loss_ce_3: 7.48  loss_mask_3: 0.6339  loss_dice_3: 4.524  loss_ce_4: 7.551  loss_mask_4: 0.6274  loss_dice_4: 4.537  loss_ce_5: 7.638  loss_mask_5: 0.6229  loss_dice_5: 4.548  loss_ce_6: 7.751  loss_mask_6: 0.6021  loss_dice_6: 4.582  loss_ce_7: 7.871  loss_mask_7: 0.5895  loss_dice_7: 4.593  loss_ce_8: 7.937  loss_mask_8: 0.5601  loss_dice_8: 4.615  time: 1.9553  data_time: 0.3289  lr: 9.9867e-06  max_mem: 15664M
[01/19 00:45:37] d2.utils.events INFO:  eta: 20:16:31  iter: 79  total_loss: 128.4  loss_ce: 7.717  loss_mask: 0.6445  loss_dice: 4.539  loss_ce_0: 10.14  loss_mask_0: 0.673  loss_dice_0: 4.479  loss_ce_1: 7.404  loss_mask_1: 0.6775  loss_dice_1: 4.443  loss_ce_2: 7.26  loss_mask_2: 0.6847  loss_dice_2: 4.433  loss_ce_3: 7.217  loss_mask_3: 0.6849  loss_dice_3: 4.434  loss_ce_4: 7.257  loss_mask_4: 0.6839  loss_dice_4: 4.446  loss_ce_5: 7.303  loss_mask_5: 0.6823  loss_dice_5: 4.451  loss_ce_6: 7.414  loss_mask_6: 0.6858  loss_dice_6: 4.458  loss_ce_7: 7.528  loss_mask_7: 0.6848  loss_dice_7: 4.48  loss_ce_8: 7.664  loss_mask_8: 0.6594  loss_dice_8: 4.512  time: 1.9005  data_time: 0.3503  lr: 9.9822e-06  max_mem: 15996M
[01/19 00:46:12] d2.utils.events INFO:  eta: 19:46:06  iter: 99  total_loss: 126  loss_ce: 7.715  loss_mask: 0.6837  loss_dice: 4.388  loss_ce_0: 10.16  loss_mask_0: 0.6646  loss_dice_0: 4.44  loss_ce_1: 7.454  loss_mask_1: 0.6693  loss_dice_1: 4.385  loss_ce_2: 7.123  loss_mask_2: 0.675  loss_dice_2: 4.368  loss_ce_3: 6.987  loss_mask_3: 0.6816  loss_dice_3: 4.363  loss_ce_4: 6.972  loss_mask_4: 0.6808  loss_dice_4: 4.356  loss_ce_5: 7.088  loss_mask_5: 0.6835  loss_dice_5: 4.345  loss_ce_6: 7.262  loss_mask_6: 0.6889  loss_dice_6: 4.343  loss_ce_7: 7.451  loss_mask_7: 0.6913  loss_dice_7: 4.346  loss_ce_8: 7.618  loss_mask_8: 0.6945  loss_dice_8: 4.374  time: 1.8669  data_time: 0.3533  lr: 9.9777e-06  max_mem: 15996M
[01/19 00:46:46] d2.utils.events INFO:  eta: 19:24:18  iter: 119  total_loss: 121.1  loss_ce: 7.196  loss_mask: 0.687  loss_dice: 4.281  loss_ce_0: 10.13  loss_mask_0: 0.6567  loss_dice_0: 4.4  loss_ce_1: 7.283  loss_mask_1: 0.6603  loss_dice_1: 4.353  loss_ce_2: 6.867  loss_mask_2: 0.6718  loss_dice_2: 4.32  loss_ce_3: 6.637  loss_mask_3: 0.6768  loss_dice_3: 4.304  loss_ce_4: 6.514  loss_mask_4: 0.676  loss_dice_4: 4.294  loss_ce_5: 6.552  loss_mask_5: 0.6858  loss_dice_5: 4.286  loss_ce_6: 6.636  loss_mask_6: 0.6828  loss_dice_6: 4.29  loss_ce_7: 6.786  loss_mask_7: 0.6931  loss_dice_7: 4.282  loss_ce_8: 6.992  loss_mask_8: 0.6876  loss_dice_8: 4.28  time: 1.8421  data_time: 0.3275  lr: 9.9732e-06  max_mem: 15996M
[01/19 00:47:21] d2.utils.events INFO:  eta: 19:22:19  iter: 139  total_loss: 119.4  loss_ce: 6.974  loss_mask: 0.7063  loss_dice: 4.207  loss_ce_0: 10.15  loss_mask_0: 0.6802  loss_dice_0: 4.357  loss_ce_1: 7.222  loss_mask_1: 0.685  loss_dice_1: 4.288  loss_ce_2: 6.767  loss_mask_2: 0.7051  loss_dice_2: 4.249  loss_ce_3: 6.521  loss_mask_3: 0.7023  loss_dice_3: 4.23  loss_ce_4: 6.392  loss_mask_4: 0.7049  loss_dice_4: 4.235  loss_ce_5: 6.405  loss_mask_5: 0.7129  loss_dice_5: 4.205  loss_ce_6: 6.426  loss_mask_6: 0.7115  loss_dice_6: 4.214  loss_ce_7: 6.554  loss_mask_7: 0.7167  loss_dice_7: 4.201  loss_ce_8: 6.741  loss_mask_8: 0.7157  loss_dice_8: 4.21  time: 1.8257  data_time: 0.3514  lr: 9.9687e-06  max_mem: 15996M
[01/19 00:47:55] d2.utils.events INFO:  eta: 19:19:59  iter: 159  total_loss: 115.3  loss_ce: 6.344  loss_mask: 0.7169  loss_dice: 4.159  loss_ce_0: 10.14  loss_mask_0: 0.6686  loss_dice_0: 4.317  loss_ce_1: 7.007  loss_mask_1: 0.6889  loss_dice_1: 4.228  loss_ce_2: 6.421  loss_mask_2: 0.7008  loss_dice_2: 4.187  loss_ce_3: 6.116  loss_mask_3: 0.6994  loss_dice_3: 4.165  loss_ce_4: 5.926  loss_mask_4: 0.7066  loss_dice_4: 4.177  loss_ce_5: 5.907  loss_mask_5: 0.7134  loss_dice_5: 4.169  loss_ce_6: 5.914  loss_mask_6: 0.7111  loss_dice_6: 4.181  loss_ce_7: 5.998  loss_mask_7: 0.7248  loss_dice_7: 4.156  loss_ce_8: 6.12  loss_mask_8: 0.7186  loss_dice_8: 4.172  time: 1.8115  data_time: 0.3494  lr: 9.9642e-06  max_mem: 15996M
[01/19 00:48:30] d2.utils.events INFO:  eta: 19:12:32  iter: 179  total_loss: 113.6  loss_ce: 6.116  loss_mask: 0.7201  loss_dice: 4.129  loss_ce_0: 10.1  loss_mask_0: 0.6698  loss_dice_0: 4.302  loss_ce_1: 6.886  loss_mask_1: 0.6927  loss_dice_1: 4.2  loss_ce_2: 6.275  loss_mask_2: 0.7042  loss_dice_2: 4.168  loss_ce_3: 5.973  loss_mask_3: 0.7113  loss_dice_3: 4.168  loss_ce_4: 5.802  loss_mask_4: 0.7086  loss_dice_4: 4.173  loss_ce_5: 5.772  loss_mask_5: 0.7195  loss_dice_5: 4.146  loss_ce_6: 5.753  loss_mask_6: 0.7153  loss_dice_6: 4.147  loss_ce_7: 5.816  loss_mask_7: 0.7266  loss_dice_7: 4.129  loss_ce_8: 5.929  loss_mask_8: 0.7214  loss_dice_8: 4.132  time: 1.8010  data_time: 0.3446  lr: 9.9597e-06  max_mem: 15996M
[01/19 00:49:04] d2.utils.events INFO:  eta: 19:10:31  iter: 199  total_loss: 111.3  loss_ce: 5.832  loss_mask: 0.7415  loss_dice: 4.082  loss_ce_0: 10.11  loss_mask_0: 0.6957  loss_dice_0: 4.25  loss_ce_1: 6.741  loss_mask_1: 0.7116  loss_dice_1: 4.142  loss_ce_2: 6.085  loss_mask_2: 0.7229  loss_dice_2: 4.107  loss_ce_3: 5.808  loss_mask_3: 0.7169  loss_dice_3: 4.1  loss_ce_4: 5.643  loss_mask_4: 0.7309  loss_dice_4: 4.099  loss_ce_5: 5.626  loss_mask_5: 0.7299  loss_dice_5: 4.1  loss_ce_6: 5.585  loss_mask_6: 0.7338  loss_dice_6: 4.093  loss_ce_7: 5.652  loss_mask_7: 0.7332  loss_dice_7: 4.089  loss_ce_8: 5.721  loss_mask_8: 0.7394  loss_dice_8: 4.085  time: 1.7918  data_time: 0.3507  lr: 9.9552e-06  max_mem: 15996M
[01/19 00:49:39] d2.utils.events INFO:  eta: 19:08:47  iter: 219  total_loss: 108.8  loss_ce: 5.528  loss_mask: 0.7217  loss_dice: 4.06  loss_ce_0: 10.02  loss_mask_0: 0.6716  loss_dice_0: 4.235  loss_ce_1: 6.547  loss_mask_1: 0.6948  loss_dice_1: 4.127  loss_ce_2: 5.904  loss_mask_2: 0.7163  loss_dice_2: 4.106  loss_ce_3: 5.611  loss_mask_3: 0.7115  loss_dice_3: 4.085  loss_ce_4: 5.441  loss_mask_4: 0.7127  loss_dice_4: 4.085  loss_ce_5: 5.377  loss_mask_5: 0.7225  loss_dice_5: 4.067  loss_ce_6: 5.335  loss_mask_6: 0.7172  loss_dice_6: 4.062  loss_ce_7: 5.378  loss_mask_7: 0.7238  loss_dice_7: 4.043  loss_ce_8: 5.419  loss_mask_8: 0.727  loss_dice_8: 4.061  time: 1.7857  data_time: 0.3421  lr: 9.9507e-06  max_mem: 15996M
[01/19 00:50:13] d2.utils.events INFO:  eta: 19:07:39  iter: 239  total_loss: 107.5  loss_ce: 5.416  loss_mask: 0.7134  loss_dice: 4.043  loss_ce_0: 9.971  loss_mask_0: 0.6668  loss_dice_0: 4.201  loss_ce_1: 6.45  loss_mask_1: 0.6932  loss_dice_1: 4.098  loss_ce_2: 5.758  loss_mask_2: 0.7091  loss_dice_2: 4.085  loss_ce_3: 5.497  loss_mask_3: 0.7064  loss_dice_3: 4.06  loss_ce_4: 5.313  loss_mask_4: 0.7091  loss_dice_4: 4.062  loss_ce_5: 5.264  loss_mask_5: 0.7052  loss_dice_5: 4.048  loss_ce_6: 5.217  loss_mask_6: 0.7055  loss_dice_6: 4.05  loss_ce_7: 5.265  loss_mask_7: 0.707  loss_dice_7: 4.05  loss_ce_8: 5.313  loss_mask_8: 0.7147  loss_dice_8: 4.07  time: 1.7804  data_time: 0.3529  lr: 9.9462e-06  max_mem: 15996M
[01/19 00:50:47] d2.utils.events INFO:  eta: 19:05:35  iter: 259  total_loss: 105.2  loss_ce: 5.182  loss_mask: 0.7101  loss_dice: 4.02  loss_ce_0: 9.933  loss_mask_0: 0.6718  loss_dice_0: 4.185  loss_ce_1: 6.258  loss_mask_1: 0.6982  loss_dice_1: 4.073  loss_ce_2: 5.563  loss_mask_2: 0.7091  loss_dice_2: 4.047  loss_ce_3: 5.263  loss_mask_3: 0.7129  loss_dice_3: 4.038  loss_ce_4: 5.108  loss_mask_4: 0.7161  loss_dice_4: 4.054  loss_ce_5: 5.07  loss_mask_5: 0.7091  loss_dice_5: 4.026  loss_ce_6: 5.024  loss_mask_6: 0.7024  loss_dice_6: 4.032  loss_ce_7: 5.085  loss_mask_7: 0.7099  loss_dice_7: 4.013  loss_ce_8: 5.087  loss_mask_8: 0.7128  loss_dice_8: 4.027  time: 1.7738  data_time: 0.3513  lr: 9.9417e-06  max_mem: 15996M
[01/19 00:51:21] d2.utils.events INFO:  eta: 19:04:37  iter: 279  total_loss: 104.7  loss_ce: 5.173  loss_mask: 0.7079  loss_dice: 4.038  loss_ce_0: 9.894  loss_mask_0: 0.6639  loss_dice_0: 4.158  loss_ce_1: 6.198  loss_mask_1: 0.7042  loss_dice_1: 4.053  loss_ce_2: 5.464  loss_mask_2: 0.7048  loss_dice_2: 4.055  loss_ce_3: 5.19  loss_mask_3: 0.7056  loss_dice_3: 4.049  loss_ce_4: 5.08  loss_mask_4: 0.7038  loss_dice_4: 4.049  loss_ce_5: 5.02  loss_mask_5: 0.7094  loss_dice_5: 4.044  loss_ce_6: 5.018  loss_mask_6: 0.7098  loss_dice_6: 4.047  loss_ce_7: 5.014  loss_mask_7: 0.7088  loss_dice_7: 4.041  loss_ce_8: 5.091  loss_mask_8: 0.715  loss_dice_8: 4.04  time: 1.7689  data_time: 0.3529  lr: 9.9372e-06  max_mem: 15996M
[01/19 00:51:55] d2.utils.events INFO:  eta: 19:01:04  iter: 299  total_loss: 103.8  loss_ce: 5.167  loss_mask: 0.7458  loss_dice: 3.959  loss_ce_0: 9.879  loss_mask_0: 0.7008  loss_dice_0: 4.121  loss_ce_1: 6.007  loss_mask_1: 0.7336  loss_dice_1: 3.999  loss_ce_2: 5.388  loss_mask_2: 0.7435  loss_dice_2: 3.987  loss_ce_3: 5.17  loss_mask_3: 0.7396  loss_dice_3: 3.979  loss_ce_4: 5.052  loss_mask_4: 0.7351  loss_dice_4: 3.989  loss_ce_5: 5.015  loss_mask_5: 0.7425  loss_dice_5: 3.982  loss_ce_6: 5.015  loss_mask_6: 0.7385  loss_dice_6: 3.976  loss_ce_7: 5.077  loss_mask_7: 0.7432  loss_dice_7: 3.984  loss_ce_8: 5.056  loss_mask_8: 0.7463  loss_dice_8: 3.983  time: 1.7633  data_time: 0.3587  lr: 9.9327e-06  max_mem: 15996M
[01/19 00:52:29] d2.utils.events INFO:  eta: 19:00:06  iter: 319  total_loss: 102.7  loss_ce: 5.041  loss_mask: 0.7099  loss_dice: 3.99  loss_ce_0: 9.749  loss_mask_0: 0.6771  loss_dice_0: 4.142  loss_ce_1: 5.868  loss_mask_1: 0.7129  loss_dice_1: 4.041  loss_ce_2: 5.214  loss_mask_2: 0.7208  loss_dice_2: 4.023  loss_ce_3: 4.982  loss_mask_3: 0.7161  loss_dice_3: 4.006  loss_ce_4: 4.9  loss_mask_4: 0.7143  loss_dice_4: 4.009  loss_ce_5: 4.873  loss_mask_5: 0.7096  loss_dice_5: 4  loss_ce_6: 4.851  loss_mask_6: 0.7126  loss_dice_6: 4.005  loss_ce_7: 4.914  loss_mask_7: 0.7107  loss_dice_7: 3.982  loss_ce_8: 4.955  loss_mask_8: 0.7083  loss_dice_8: 3.99  time: 1.7597  data_time: 0.3430  lr: 9.9282e-06  max_mem: 15996M
[01/19 00:53:04] d2.utils.events INFO:  eta: 18:59:13  iter: 339  total_loss: 101.8  loss_ce: 4.971  loss_mask: 0.7019  loss_dice: 3.966  loss_ce_0: 9.683  loss_mask_0: 0.6732  loss_dice_0: 4.116  loss_ce_1: 5.725  loss_mask_1: 0.7021  loss_dice_1: 4.029  loss_ce_2: 5.134  loss_mask_2: 0.7048  loss_dice_2: 4.023  loss_ce_3: 4.953  loss_mask_3: 0.6975  loss_dice_3: 4.003  loss_ce_4: 4.872  loss_mask_4: 0.6953  loss_dice_4: 4.005  loss_ce_5: 4.854  loss_mask_5: 0.6973  loss_dice_5: 3.996  loss_ce_6: 4.87  loss_mask_6: 0.703  loss_dice_6: 3.998  loss_ce_7: 4.873  loss_mask_7: 0.6991  loss_dice_7: 3.997  loss_ce_8: 4.896  loss_mask_8: 0.6992  loss_dice_8: 3.986  time: 1.7575  data_time: 0.3482  lr: 9.9237e-06  max_mem: 15996M
[01/19 00:53:38] d2.utils.events INFO:  eta: 18:57:51  iter: 359  total_loss: 101.3  loss_ce: 4.896  loss_mask: 0.7015  loss_dice: 3.988  loss_ce_0: 9.631  loss_mask_0: 0.6675  loss_dice_0: 4.125  loss_ce_1: 5.645  loss_mask_1: 0.7065  loss_dice_1: 4.032  loss_ce_2: 5.052  loss_mask_2: 0.7082  loss_dice_2: 4.022  loss_ce_3: 4.878  loss_mask_3: 0.7016  loss_dice_3: 4.014  loss_ce_4: 4.849  loss_mask_4: 0.7045  loss_dice_4: 4.016  loss_ce_5: 4.791  loss_mask_5: 0.7041  loss_dice_5: 4.003  loss_ce_6: 4.783  loss_mask_6: 0.7013  loss_dice_6: 3.992  loss_ce_7: 4.805  loss_mask_7: 0.7024  loss_dice_7: 3.985  loss_ce_8: 4.802  loss_mask_8: 0.6999  loss_dice_8: 3.993  time: 1.7552  data_time: 0.3473  lr: 9.9192e-06  max_mem: 15996M
[01/19 00:54:12] d2.utils.events INFO:  eta: 18:56:25  iter: 379  total_loss: 100.6  loss_ce: 4.867  loss_mask: 0.7191  loss_dice: 3.933  loss_ce_0: 9.643  loss_mask_0: 0.7089  loss_dice_0: 4.058  loss_ce_1: 5.435  loss_mask_1: 0.7405  loss_dice_1: 3.975  loss_ce_2: 4.91  loss_mask_2: 0.7309  loss_dice_2: 3.972  loss_ce_3: 4.794  loss_mask_3: 0.7231  loss_dice_3: 3.954  loss_ce_4: 4.76  loss_mask_4: 0.7221  loss_dice_4: 3.957  loss_ce_5: 4.763  loss_mask_5: 0.7271  loss_dice_5: 3.938  loss_ce_6: 4.8  loss_mask_6: 0.7255  loss_dice_6: 3.934  loss_ce_7: 4.843  loss_mask_7: 0.7212  loss_dice_7: 3.928  loss_ce_8: 4.821  loss_mask_8: 0.7198  loss_dice_8: 3.925  time: 1.7510  data_time: 0.3392  lr: 9.9147e-06  max_mem: 15996M
[01/19 00:54:45] d2.utils.events INFO:  eta: 18:55:04  iter: 399  total_loss: 99.61  loss_ce: 4.773  loss_mask: 0.7028  loss_dice: 3.935  loss_ce_0: 9.574  loss_mask_0: 0.6815  loss_dice_0: 4.056  loss_ce_1: 5.376  loss_mask_1: 0.7242  loss_dice_1: 3.98  loss_ce_2: 4.888  loss_mask_2: 0.7161  loss_dice_2: 3.976  loss_ce_3: 4.786  loss_mask_3: 0.7021  loss_dice_3: 3.958  loss_ce_4: 4.734  loss_mask_4: 0.6983  loss_dice_4: 3.948  loss_ce_5: 4.734  loss_mask_5: 0.7028  loss_dice_5: 3.955  loss_ce_6: 4.718  loss_mask_6: 0.7113  loss_dice_6: 3.945  loss_ce_7: 4.744  loss_mask_7: 0.7053  loss_dice_7: 3.934  loss_ce_8: 4.694  loss_mask_8: 0.7046  loss_dice_8: 3.943  time: 1.7482  data_time: 0.3398  lr: 9.9102e-06  max_mem: 15996M
[01/19 00:55:20] d2.utils.events INFO:  eta: 18:54:42  iter: 419  total_loss: 98.97  loss_ce: 4.741  loss_mask: 0.6858  loss_dice: 3.922  loss_ce_0: 9.432  loss_mask_0: 0.6713  loss_dice_0: 4.042  loss_ce_1: 5.316  loss_mask_1: 0.7007  loss_dice_1: 3.975  loss_ce_2: 4.838  loss_mask_2: 0.6916  loss_dice_2: 3.971  loss_ce_3: 4.783  loss_mask_3: 0.6849  loss_dice_3: 3.944  loss_ce_4: 4.688  loss_mask_4: 0.6843  loss_dice_4: 3.942  loss_ce_5: 4.645  loss_mask_5: 0.6846  loss_dice_5: 3.931  loss_ce_6: 4.631  loss_mask_6: 0.684  loss_dice_6: 3.917  loss_ce_7: 4.691  loss_mask_7: 0.6897  loss_dice_7: 3.921  loss_ce_8: 4.665  loss_mask_8: 0.6865  loss_dice_8: 3.924  time: 1.7471  data_time: 0.3446  lr: 9.9057e-06  max_mem: 15996M
[01/19 00:55:54] d2.utils.events INFO:  eta: 18:53:45  iter: 439  total_loss: 97.78  loss_ce: 4.565  loss_mask: 0.6858  loss_dice: 3.97  loss_ce_0: 9.262  loss_mask_0: 0.6628  loss_dice_0: 4.088  loss_ce_1: 5.098  loss_mask_1: 0.7006  loss_dice_1: 4.023  loss_ce_2: 4.673  loss_mask_2: 0.6868  loss_dice_2: 4.012  loss_ce_3: 4.569  loss_mask_3: 0.6872  loss_dice_3: 3.993  loss_ce_4: 4.539  loss_mask_4: 0.6828  loss_dice_4: 3.983  loss_ce_5: 4.538  loss_mask_5: 0.6765  loss_dice_5: 3.979  loss_ce_6: 4.529  loss_mask_6: 0.6814  loss_dice_6: 3.978  loss_ce_7: 4.544  loss_mask_7: 0.6785  loss_dice_7: 3.974  loss_ce_8: 4.523  loss_mask_8: 0.6858  loss_dice_8: 3.97  time: 1.7452  data_time: 0.3454  lr: 9.9012e-06  max_mem: 15996M
[01/19 00:56:29] d2.utils.events INFO:  eta: 18:52:09  iter: 459  total_loss: 97.78  loss_ce: 4.746  loss_mask: 0.6983  loss_dice: 3.909  loss_ce_0: 9.231  loss_mask_0: 0.682  loss_dice_0: 4.018  loss_ce_1: 5.115  loss_mask_1: 0.7182  loss_dice_1: 3.962  loss_ce_2: 4.694  loss_mask_2: 0.7047  loss_dice_2: 3.955  loss_ce_3: 4.623  loss_mask_3: 0.6943  loss_dice_3: 3.927  loss_ce_4: 4.597  loss_mask_4: 0.693  loss_dice_4: 3.92  loss_ce_5: 4.616  loss_mask_5: 0.6977  loss_dice_5: 3.918  loss_ce_6: 4.625  loss_mask_6: 0.6909  loss_dice_6: 3.9  loss_ce_7: 4.678  loss_mask_7: 0.6926  loss_dice_7: 3.904  loss_ce_8: 4.695  loss_mask_8: 0.6952  loss_dice_8: 3.921  time: 1.7442  data_time: 0.3662  lr: 9.8967e-06  max_mem: 15996M
[01/19 00:57:03] d2.utils.events INFO:  eta: 18:50:30  iter: 479  total_loss: 96.16  loss_ce: 4.489  loss_mask: 0.6885  loss_dice: 3.933  loss_ce_0: 9.159  loss_mask_0: 0.6737  loss_dice_0: 4.034  loss_ce_1: 4.961  loss_mask_1: 0.6987  loss_dice_1: 4.003  loss_ce_2: 4.533  loss_mask_2: 0.6845  loss_dice_2: 3.987  loss_ce_3: 4.461  loss_mask_3: 0.6773  loss_dice_3: 3.966  loss_ce_4: 4.408  loss_mask_4: 0.6763  loss_dice_4: 3.949  loss_ce_5: 4.412  loss_mask_5: 0.6798  loss_dice_5: 3.948  loss_ce_6: 4.402  loss_mask_6: 0.6857  loss_dice_6: 3.931  loss_ce_7: 4.406  loss_mask_7: 0.6832  loss_dice_7: 3.944  loss_ce_8: 4.438  loss_mask_8: 0.6847  loss_dice_8: 3.948  time: 1.7423  data_time: 0.3444  lr: 9.8922e-06  max_mem: 15996M
[01/19 00:57:36] d2.utils.events INFO:  eta: 18:49:14  iter: 499  total_loss: 98.15  loss_ce: 4.808  loss_mask: 0.7199  loss_dice: 3.85  loss_ce_0: 9.185  loss_mask_0: 0.7109  loss_dice_0: 3.985  loss_ce_1: 4.991  loss_mask_1: 0.7368  loss_dice_1: 3.928  loss_ce_2: 4.719  loss_mask_2: 0.7244  loss_dice_2: 3.916  loss_ce_3: 4.694  loss_mask_3: 0.7202  loss_dice_3: 3.879  loss_ce_4: 4.683  loss_mask_4: 0.7183  loss_dice_4: 3.872  loss_ce_5: 4.688  loss_mask_5: 0.7162  loss_dice_5: 3.869  loss_ce_6: 4.68  loss_mask_6: 0.7216  loss_dice_6: 3.862  loss_ce_7: 4.726  loss_mask_7: 0.7209  loss_dice_7: 3.858  loss_ce_8: 4.729  loss_mask_8: 0.7169  loss_dice_8: 3.857  time: 1.7393  data_time: 0.3248  lr: 9.8877e-06  max_mem: 15996M
[01/19 00:58:10] d2.utils.events INFO:  eta: 18:47:34  iter: 519  total_loss: 96.17  loss_ce: 4.649  loss_mask: 0.6948  loss_dice: 3.863  loss_ce_0: 9.041  loss_mask_0: 0.6835  loss_dice_0: 3.982  loss_ce_1: 4.882  loss_mask_1: 0.7187  loss_dice_1: 3.94  loss_ce_2: 4.612  loss_mask_2: 0.6998  loss_dice_2: 3.924  loss_ce_3: 4.561  loss_mask_3: 0.6901  loss_dice_3: 3.892  loss_ce_4: 4.541  loss_mask_4: 0.6942  loss_dice_4: 3.88  loss_ce_5: 4.558  loss_mask_5: 0.6958  loss_dice_5: 3.87  loss_ce_6: 4.537  loss_mask_6: 0.6993  loss_dice_6: 3.862  loss_ce_7: 4.563  loss_mask_7: 0.6977  loss_dice_7: 3.87  loss_ce_8: 4.568  loss_mask_8: 0.6954  loss_dice_8: 3.865  time: 1.7373  data_time: 0.3457  lr: 9.8831e-06  max_mem: 15996M
[01/19 00:58:43] d2.utils.events INFO:  eta: 18:45:28  iter: 539  total_loss: 95.94  loss_ce: 4.676  loss_mask: 0.6975  loss_dice: 3.868  loss_ce_0: 8.966  loss_mask_0: 0.6862  loss_dice_0: 3.986  loss_ce_1: 4.818  loss_mask_1: 0.7078  loss_dice_1: 3.954  loss_ce_2: 4.594  loss_mask_2: 0.6921  loss_dice_2: 3.934  loss_ce_3: 4.524  loss_mask_3: 0.6979  loss_dice_3: 3.893  loss_ce_4: 4.523  loss_mask_4: 0.6933  loss_dice_4: 3.88  loss_ce_5: 4.577  loss_mask_5: 0.7005  loss_dice_5: 3.867  loss_ce_6: 4.562  loss_mask_6: 0.6979  loss_dice_6: 3.856  loss_ce_7: 4.606  loss_mask_7: 0.697  loss_dice_7: 3.866  loss_ce_8: 4.631  loss_mask_8: 0.7016  loss_dice_8: 3.865  time: 1.7351  data_time: 0.3472  lr: 9.8786e-06  max_mem: 15996M
[01/19 00:59:17] d2.utils.events INFO:  eta: 18:43:35  iter: 559  total_loss: 96.33  loss_ce: 4.667  loss_mask: 0.692  loss_dice: 3.849  loss_ce_0: 8.919  loss_mask_0: 0.6926  loss_dice_0: 3.98  loss_ce_1: 4.865  loss_mask_1: 0.719  loss_dice_1: 3.939  loss_ce_2: 4.56  loss_mask_2: 0.7024  loss_dice_2: 3.916  loss_ce_3: 4.541  loss_mask_3: 0.6983  loss_dice_3: 3.881  loss_ce_4: 4.54  loss_mask_4: 0.6883  loss_dice_4: 3.876  loss_ce_5: 4.546  loss_mask_5: 0.6879  loss_dice_5: 3.864  loss_ce_6: 4.55  loss_mask_6: 0.691  loss_dice_6: 3.855  loss_ce_7: 4.566  loss_mask_7: 0.6952  loss_dice_7: 3.853  loss_ce_8: 4.624  loss_mask_8: 0.6931  loss_dice_8: 3.849  time: 1.7334  data_time: 0.3401  lr: 9.8741e-06  max_mem: 15996M
[01/19 00:59:52] d2.utils.events INFO:  eta: 18:43:14  iter: 579  total_loss: 94.91  loss_ce: 4.526  loss_mask: 0.7003  loss_dice: 3.854  loss_ce_0: 8.806  loss_mask_0: 0.6908  loss_dice_0: 3.966  loss_ce_1: 4.714  loss_mask_1: 0.7165  loss_dice_1: 3.933  loss_ce_2: 4.447  loss_mask_2: 0.7003  loss_dice_2: 3.919  loss_ce_3: 4.443  loss_mask_3: 0.7001  loss_dice_3: 3.887  loss_ce_4: 4.413  loss_mask_4: 0.6951  loss_dice_4: 3.881  loss_ce_5: 4.455  loss_mask_5: 0.6994  loss_dice_5: 3.866  loss_ce_6: 4.437  loss_mask_6: 0.7078  loss_dice_6: 3.859  loss_ce_7: 4.436  loss_mask_7: 0.698  loss_dice_7: 3.863  loss_ce_8: 4.468  loss_mask_8: 0.7083  loss_dice_8: 3.853  time: 1.7328  data_time: 0.3692  lr: 9.8696e-06  max_mem: 15996M
[01/19 01:00:26] d2.utils.events INFO:  eta: 18:42:40  iter: 599  total_loss: 94.84  loss_ce: 4.48  loss_mask: 0.6729  loss_dice: 3.878  loss_ce_0: 8.692  loss_mask_0: 0.6706  loss_dice_0: 4.001  loss_ce_1: 4.733  loss_mask_1: 0.6927  loss_dice_1: 3.952  loss_ce_2: 4.469  loss_mask_2: 0.6744  loss_dice_2: 3.936  loss_ce_3: 4.412  loss_mask_3: 0.6691  loss_dice_3: 3.909  loss_ce_4: 4.387  loss_mask_4: 0.67  loss_dice_4: 3.898  loss_ce_5: 4.402  loss_mask_5: 0.6715  loss_dice_5: 3.879  loss_ce_6: 4.406  loss_mask_6: 0.6799  loss_dice_6: 3.874  loss_ce_7: 4.442  loss_mask_7: 0.67  loss_dice_7: 3.876  loss_ce_8: 4.455  loss_mask_8: 0.6701  loss_dice_8: 3.875  time: 1.7321  data_time: 0.3438  lr: 9.8651e-06  max_mem: 15996M
[01/19 01:01:00] d2.utils.events INFO:  eta: 18:42:33  iter: 619  total_loss: 93.17  loss_ce: 4.321  loss_mask: 0.6752  loss_dice: 3.873  loss_ce_0: 8.688  loss_mask_0: 0.676  loss_dice_0: 3.984  loss_ce_1: 4.637  loss_mask_1: 0.6883  loss_dice_1: 3.952  loss_ce_2: 4.362  loss_mask_2: 0.6726  loss_dice_2: 3.92  loss_ce_3: 4.264  loss_mask_3: 0.6724  loss_dice_3: 3.898  loss_ce_4: 4.235  loss_mask_4: 0.6726  loss_dice_4: 3.884  loss_ce_5: 4.236  loss_mask_5: 0.6705  loss_dice_5: 3.882  loss_ce_6: 4.234  loss_mask_6: 0.6722  loss_dice_6: 3.866  loss_ce_7: 4.284  loss_mask_7: 0.6739  loss_dice_7: 3.872  loss_ce_8: 4.297  loss_mask_8: 0.6755  loss_dice_8: 3.877  time: 1.7311  data_time: 0.3349  lr: 9.8606e-06  max_mem: 15996M
[01/19 01:01:34] d2.utils.events INFO:  eta: 18:42:02  iter: 639  total_loss: 93.37  loss_ce: 4.342  loss_mask: 0.6651  loss_dice: 3.87  loss_ce_0: 8.565  loss_mask_0: 0.6699  loss_dice_0: 3.981  loss_ce_1: 4.62  loss_mask_1: 0.6802  loss_dice_1: 3.949  loss_ce_2: 4.388  loss_mask_2: 0.6709  loss_dice_2: 3.93  loss_ce_3: 4.283  loss_mask_3: 0.6628  loss_dice_3: 3.895  loss_ce_4: 4.253  loss_mask_4: 0.6662  loss_dice_4: 3.883  loss_ce_5: 4.246  loss_mask_5: 0.6619  loss_dice_5: 3.876  loss_ce_6: 4.255  loss_mask_6: 0.6626  loss_dice_6: 3.881  loss_ce_7: 4.287  loss_mask_7: 0.6637  loss_dice_7: 3.879  loss_ce_8: 4.315  loss_mask_8: 0.6654  loss_dice_8: 3.872  time: 1.7307  data_time: 0.3537  lr: 9.8561e-06  max_mem: 15996M
[01/19 01:02:09] d2.utils.events INFO:  eta: 18:41:46  iter: 659  total_loss: 93.9  loss_ce: 4.473  loss_mask: 0.6654  loss_dice: 3.886  loss_ce_0: 8.393  loss_mask_0: 0.6497  loss_dice_0: 4  loss_ce_1: 4.594  loss_mask_1: 0.6671  loss_dice_1: 3.97  loss_ce_2: 4.411  loss_mask_2: 0.6628  loss_dice_2: 3.945  loss_ce_3: 4.397  loss_mask_3: 0.6661  loss_dice_3: 3.901  loss_ce_4: 4.376  loss_mask_4: 0.6617  loss_dice_4: 3.902  loss_ce_5: 4.381  loss_mask_5: 0.6644  loss_dice_5: 3.9  loss_ce_6: 4.363  loss_mask_6: 0.6608  loss_dice_6: 3.882  loss_ce_7: 4.421  loss_mask_7: 0.6615  loss_dice_7: 3.885  loss_ce_8: 4.408  loss_mask_8: 0.6647  loss_dice_8: 3.884  time: 1.7301  data_time: 0.3436  lr: 9.8516e-06  max_mem: 15996M
[01/19 01:02:43] d2.utils.events INFO:  eta: 18:41:00  iter: 679  total_loss: 92.86  loss_ce: 4.364  loss_mask: 0.6829  loss_dice: 3.827  loss_ce_0: 8.408  loss_mask_0: 0.6913  loss_dice_0: 3.956  loss_ce_1: 4.495  loss_mask_1: 0.6947  loss_dice_1: 3.924  loss_ce_2: 4.336  loss_mask_2: 0.6901  loss_dice_2: 3.885  loss_ce_3: 4.306  loss_mask_3: 0.6903  loss_dice_3: 3.845  loss_ce_4: 4.312  loss_mask_4: 0.6871  loss_dice_4: 3.839  loss_ce_5: 4.302  loss_mask_5: 0.6859  loss_dice_5: 3.832  loss_ce_6: 4.281  loss_mask_6: 0.683  loss_dice_6: 3.823  loss_ce_7: 4.303  loss_mask_7: 0.6782  loss_dice_7: 3.828  loss_ce_8: 4.31  loss_mask_8: 0.6841  loss_dice_8: 3.828  time: 1.7292  data_time: 0.3171  lr: 9.8471e-06  max_mem: 15996M
[01/19 01:03:17] d2.utils.events INFO:  eta: 18:41:03  iter: 699  total_loss: 92.63  loss_ce: 4.357  loss_mask: 0.6675  loss_dice: 3.888  loss_ce_0: 8.259  loss_mask_0: 0.6734  loss_dice_0: 3.997  loss_ce_1: 4.499  loss_mask_1: 0.6793  loss_dice_1: 3.976  loss_ce_2: 4.293  loss_mask_2: 0.6615  loss_dice_2: 3.947  loss_ce_3: 4.262  loss_mask_3: 0.6636  loss_dice_3: 3.909  loss_ce_4: 4.222  loss_mask_4: 0.6627  loss_dice_4: 3.907  loss_ce_5: 4.253  loss_mask_5: 0.6676  loss_dice_5: 3.896  loss_ce_6: 4.253  loss_mask_6: 0.6743  loss_dice_6: 3.892  loss_ce_7: 4.3  loss_mask_7: 0.6725  loss_dice_7: 3.891  loss_ce_8: 4.334  loss_mask_8: 0.673  loss_dice_8: 3.888  time: 1.7287  data_time: 0.3320  lr: 9.8426e-06  max_mem: 15996M
[01/19 01:03:51] d2.utils.events INFO:  eta: 18:40:04  iter: 719  total_loss: 91.39  loss_ce: 4.18  loss_mask: 0.6782  loss_dice: 3.854  loss_ce_0: 8.28  loss_mask_0: 0.6883  loss_dice_0: 3.975  loss_ce_1: 4.385  loss_mask_1: 0.6884  loss_dice_1: 3.949  loss_ce_2: 4.183  loss_mask_2: 0.6775  loss_dice_2: 3.905  loss_ce_3: 4.105  loss_mask_3: 0.6756  loss_dice_3: 3.879  loss_ce_4: 4.081  loss_mask_4: 0.6792  loss_dice_4: 3.87  loss_ce_5: 4.08  loss_mask_5: 0.6776  loss_dice_5: 3.868  loss_ce_6: 4.111  loss_mask_6: 0.6805  loss_dice_6: 3.851  loss_ce_7: 4.123  loss_mask_7: 0.6791  loss_dice_7: 3.855  loss_ce_8: 4.147  loss_mask_8: 0.6775  loss_dice_8: 3.855  time: 1.7279  data_time: 0.3613  lr: 9.8381e-06  max_mem: 15996M
[01/19 01:04:25] d2.utils.events INFO:  eta: 18:39:11  iter: 739  total_loss: 92.16  loss_ce: 4.243  loss_mask: 0.6596  loss_dice: 3.85  loss_ce_0: 8.206  loss_mask_0: 0.6731  loss_dice_0: 3.965  loss_ce_1: 4.489  loss_mask_1: 0.6721  loss_dice_1: 3.932  loss_ce_2: 4.284  loss_mask_2: 0.6629  loss_dice_2: 3.897  loss_ce_3: 4.252  loss_mask_3: 0.6547  loss_dice_3: 3.872  loss_ce_4: 4.21  loss_mask_4: 0.655  loss_dice_4: 3.869  loss_ce_5: 4.219  loss_mask_5: 0.6614  loss_dice_5: 3.868  loss_ce_6: 4.223  loss_mask_6: 0.6576  loss_dice_6: 3.864  loss_ce_7: 4.237  loss_mask_7: 0.6538  loss_dice_7: 3.861  loss_ce_8: 4.205  loss_mask_8: 0.66  loss_dice_8: 3.862  time: 1.7271  data_time: 0.3533  lr: 9.8336e-06  max_mem: 15996M
[01/19 01:04:59] d2.utils.events INFO:  eta: 18:39:10  iter: 759  total_loss: 90.12  loss_ce: 4.109  loss_mask: 0.6587  loss_dice: 3.878  loss_ce_0: 8.051  loss_mask_0: 0.6686  loss_dice_0: 3.987  loss_ce_1: 4.301  loss_mask_1: 0.6677  loss_dice_1: 3.972  loss_ce_2: 4.093  loss_mask_2: 0.662  loss_dice_2: 3.939  loss_ce_3: 4.028  loss_mask_3: 0.662  loss_dice_3: 3.902  loss_ce_4: 3.992  loss_mask_4: 0.6624  loss_dice_4: 3.895  loss_ce_5: 4.001  loss_mask_5: 0.6646  loss_dice_5: 3.894  loss_ce_6: 3.993  loss_mask_6: 0.6606  loss_dice_6: 3.877  loss_ce_7: 4.019  loss_mask_7: 0.6574  loss_dice_7: 3.879  loss_ce_8: 4.045  loss_mask_8: 0.659  loss_dice_8: 3.872  time: 1.7268  data_time: 0.3512  lr: 9.8291e-06  max_mem: 15996M
[01/19 01:05:33] d2.utils.events INFO:  eta: 18:38:09  iter: 779  total_loss: 90.6  loss_ce: 4.142  loss_mask: 0.6609  loss_dice: 3.85  loss_ce_0: 8.024  loss_mask_0: 0.6761  loss_dice_0: 3.972  loss_ce_1: 4.31  loss_mask_1: 0.6667  loss_dice_1: 3.958  loss_ce_2: 4.112  loss_mask_2: 0.66  loss_dice_2: 3.921  loss_ce_3: 4.058  loss_mask_3: 0.6625  loss_dice_3: 3.886  loss_ce_4: 4.033  loss_mask_4: 0.6645  loss_dice_4: 3.883  loss_ce_5: 4.046  loss_mask_5: 0.661  loss_dice_5: 3.877  loss_ce_6: 4.058  loss_mask_6: 0.6605  loss_dice_6: 3.858  loss_ce_7: 4.07  loss_mask_7: 0.6624  loss_dice_7: 3.856  loss_ce_8: 4.118  loss_mask_8: 0.6595  loss_dice_8: 3.854  time: 1.7262  data_time: 0.3299  lr: 9.8246e-06  max_mem: 15996M
[01/19 01:06:08] d2.utils.events INFO:  eta: 18:37:35  iter: 799  total_loss: 89.99  loss_ce: 4.109  loss_mask: 0.6773  loss_dice: 3.84  loss_ce_0: 7.929  loss_mask_0: 0.6881  loss_dice_0: 3.968  loss_ce_1: 4.261  loss_mask_1: 0.6879  loss_dice_1: 3.941  loss_ce_2: 4.093  loss_mask_2: 0.6813  loss_dice_2: 3.89  loss_ce_3: 4.036  loss_mask_3: 0.6793  loss_dice_3: 3.855  loss_ce_4: 4.001  loss_mask_4: 0.6718  loss_dice_4: 3.862  loss_ce_5: 4.016  loss_mask_5: 0.6755  loss_dice_5: 3.853  loss_ce_6: 4.023  loss_mask_6: 0.6768  loss_dice_6: 3.857  loss_ce_7: 4.056  loss_mask_7: 0.6756  loss_dice_7: 3.846  loss_ce_8: 4.068  loss_mask_8: 0.6734  loss_dice_8: 3.84  time: 1.7258  data_time: 0.3411  lr: 9.82e-06  max_mem: 15996M
[01/19 01:06:42] d2.utils.events INFO:  eta: 18:36:54  iter: 819  total_loss: 91.03  loss_ce: 4.224  loss_mask: 0.6764  loss_dice: 3.832  loss_ce_0: 7.889  loss_mask_0: 0.6863  loss_dice_0: 3.956  loss_ce_1: 4.323  loss_mask_1: 0.6774  loss_dice_1: 3.936  loss_ce_2: 4.229  loss_mask_2: 0.6721  loss_dice_2: 3.891  loss_ce_3: 4.117  loss_mask_3: 0.6707  loss_dice_3: 3.855  loss_ce_4: 4.109  loss_mask_4: 0.6726  loss_dice_4: 3.859  loss_ce_5: 4.16  loss_mask_5: 0.677  loss_dice_5: 3.848  loss_ce_6: 4.174  loss_mask_6: 0.6778  loss_dice_6: 3.837  loss_ce_7: 4.189  loss_mask_7: 0.6744  loss_dice_7: 3.837  loss_ce_8: 4.196  loss_mask_8: 0.6768  loss_dice_8: 3.83  time: 1.7254  data_time: 0.3639  lr: 9.8155e-06  max_mem: 16170M
[01/19 01:07:16] d2.utils.events INFO:  eta: 18:36:17  iter: 839  total_loss: 89.7  loss_ce: 4.096  loss_mask: 0.6476  loss_dice: 3.833  loss_ce_0: 7.741  loss_mask_0: 0.6678  loss_dice_0: 3.978  loss_ce_1: 4.264  loss_mask_1: 0.648  loss_dice_1: 3.932  loss_ce_2: 4.113  loss_mask_2: 0.6466  loss_dice_2: 3.892  loss_ce_3: 4.068  loss_mask_3: 0.647  loss_dice_3: 3.854  loss_ce_4: 4.046  loss_mask_4: 0.6411  loss_dice_4: 3.848  loss_ce_5: 4.05  loss_mask_5: 0.6421  loss_dice_5: 3.84  loss_ce_6: 4.031  loss_mask_6: 0.6461  loss_dice_6: 3.829  loss_ce_7: 4.037  loss_mask_7: 0.644  loss_dice_7: 3.826  loss_ce_8: 4.085  loss_mask_8: 0.6443  loss_dice_8: 3.824  time: 1.7250  data_time: 0.3529  lr: 9.811e-06  max_mem: 16170M
[01/19 01:07:51] d2.utils.events INFO:  eta: 18:35:35  iter: 859  total_loss: 88.63  loss_ce: 3.956  loss_mask: 0.6575  loss_dice: 3.846  loss_ce_0: 7.625  loss_mask_0: 0.6619  loss_dice_0: 3.975  loss_ce_1: 4.146  loss_mask_1: 0.6467  loss_dice_1: 3.944  loss_ce_2: 3.961  loss_mask_2: 0.6512  loss_dice_2: 3.895  loss_ce_3: 3.886  loss_mask_3: 0.6584  loss_dice_3: 3.869  loss_ce_4: 3.866  loss_mask_4: 0.6542  loss_dice_4: 3.864  loss_ce_5: 3.9  loss_mask_5: 0.6499  loss_dice_5: 3.853  loss_ce_6: 3.917  loss_mask_6: 0.6568  loss_dice_6: 3.839  loss_ce_7: 3.884  loss_mask_7: 0.6574  loss_dice_7: 3.842  loss_ce_8: 3.912  loss_mask_8: 0.6577  loss_dice_8: 3.835  time: 1.7249  data_time: 0.3442  lr: 9.8065e-06  max_mem: 16170M
[01/19 01:08:25] d2.utils.events INFO:  eta: 18:34:43  iter: 879  total_loss: 89.02  loss_ce: 4.034  loss_mask: 0.6661  loss_dice: 3.826  loss_ce_0: 7.633  loss_mask_0: 0.6851  loss_dice_0: 3.96  loss_ce_1: 4.231  loss_mask_1: 0.6691  loss_dice_1: 3.926  loss_ce_2: 4.054  loss_mask_2: 0.6782  loss_dice_2: 3.878  loss_ce_3: 4.012  loss_mask_3: 0.675  loss_dice_3: 3.846  loss_ce_4: 3.968  loss_mask_4: 0.6732  loss_dice_4: 3.843  loss_ce_5: 3.953  loss_mask_5: 0.6738  loss_dice_5: 3.834  loss_ce_6: 3.971  loss_mask_6: 0.6745  loss_dice_6: 3.829  loss_ce_7: 3.953  loss_mask_7: 0.6703  loss_dice_7: 3.829  loss_ce_8: 4.01  loss_mask_8: 0.6655  loss_dice_8: 3.831  time: 1.7242  data_time: 0.3396  lr: 9.802e-06  max_mem: 16220M
[01/19 01:08:59] d2.utils.events INFO:  eta: 18:33:54  iter: 899  total_loss: 87.73  loss_ce: 3.896  loss_mask: 0.6507  loss_dice: 3.856  loss_ce_0: 7.5  loss_mask_0: 0.6674  loss_dice_0: 4.004  loss_ce_1: 4.096  loss_mask_1: 0.6461  loss_dice_1: 3.954  loss_ce_2: 3.906  loss_mask_2: 0.646  loss_dice_2: 3.914  loss_ce_3: 3.897  loss_mask_3: 0.6433  loss_dice_3: 3.88  loss_ce_4: 3.848  loss_mask_4: 0.6417  loss_dice_4: 3.876  loss_ce_5: 3.845  loss_mask_5: 0.645  loss_dice_5: 3.875  loss_ce_6: 3.848  loss_mask_6: 0.6478  loss_dice_6: 3.854  loss_ce_7: 3.845  loss_mask_7: 0.6445  loss_dice_7: 3.858  loss_ce_8: 3.85  loss_mask_8: 0.6492  loss_dice_8: 3.857  time: 1.7238  data_time: 0.3518  lr: 9.7975e-06  max_mem: 16220M
[01/19 01:09:33] d2.utils.events INFO:  eta: 18:33:20  iter: 919  total_loss: 89.03  loss_ce: 3.98  loss_mask: 0.6564  loss_dice: 3.852  loss_ce_0: 7.489  loss_mask_0: 0.67  loss_dice_0: 3.967  loss_ce_1: 4.164  loss_mask_1: 0.6568  loss_dice_1: 3.952  loss_ce_2: 4.053  loss_mask_2: 0.6522  loss_dice_2: 3.896  loss_ce_3: 3.995  loss_mask_3: 0.6587  loss_dice_3: 3.865  loss_ce_4: 3.949  loss_mask_4: 0.6519  loss_dice_4: 3.865  loss_ce_5: 3.969  loss_mask_5: 0.654  loss_dice_5: 3.862  loss_ce_6: 3.956  loss_mask_6: 0.6542  loss_dice_6: 3.855  loss_ce_7: 3.974  loss_mask_7: 0.657  loss_dice_7: 3.845  loss_ce_8: 3.981  loss_mask_8: 0.6581  loss_dice_8: 3.847  time: 1.7234  data_time: 0.3421  lr: 9.793e-06  max_mem: 16220M
[01/19 01:10:07] d2.utils.events INFO:  eta: 18:32:40  iter: 939  total_loss: 88.24  loss_ce: 3.984  loss_mask: 0.6551  loss_dice: 3.825  loss_ce_0: 7.397  loss_mask_0: 0.6641  loss_dice_0: 3.992  loss_ce_1: 4.112  loss_mask_1: 0.6503  loss_dice_1: 3.954  loss_ce_2: 3.976  loss_mask_2: 0.6528  loss_dice_2: 3.899  loss_ce_3: 3.936  loss_mask_3: 0.6548  loss_dice_3: 3.855  loss_ce_4: 3.932  loss_mask_4: 0.6549  loss_dice_4: 3.852  loss_ce_5: 3.9  loss_mask_5: 0.6555  loss_dice_5: 3.844  loss_ce_6: 3.96  loss_mask_6: 0.6514  loss_dice_6: 3.828  loss_ce_7: 3.935  loss_mask_7: 0.6513  loss_dice_7: 3.826  loss_ce_8: 3.927  loss_mask_8: 0.6524  loss_dice_8: 3.833  time: 1.7231  data_time: 0.3606  lr: 9.7885e-06  max_mem: 16220M
[01/19 01:10:41] d2.utils.events INFO:  eta: 18:32:02  iter: 959  total_loss: 87.83  loss_ce: 3.961  loss_mask: 0.669  loss_dice: 3.785  loss_ce_0: 7.421  loss_mask_0: 0.6944  loss_dice_0: 3.933  loss_ce_1: 4.151  loss_mask_1: 0.6664  loss_dice_1: 3.893  loss_ce_2: 4.03  loss_mask_2: 0.6676  loss_dice_2: 3.843  loss_ce_3: 3.954  loss_mask_3: 0.6679  loss_dice_3: 3.819  loss_ce_4: 3.882  loss_mask_4: 0.6663  loss_dice_4: 3.81  loss_ce_5: 3.908  loss_mask_5: 0.6662  loss_dice_5: 3.807  loss_ce_6: 3.894  loss_mask_6: 0.6706  loss_dice_6: 3.81  loss_ce_7: 3.932  loss_mask_7: 0.6648  loss_dice_7: 3.797  loss_ce_8: 3.936  loss_mask_8: 0.6659  loss_dice_8: 3.79  time: 1.7222  data_time: 0.3466  lr: 9.784e-06  max_mem: 16220M
[01/19 01:11:15] d2.utils.events INFO:  eta: 18:31:32  iter: 979  total_loss: 86.58  loss_ce: 3.795  loss_mask: 0.6401  loss_dice: 3.878  loss_ce_0: 7.22  loss_mask_0: 0.6585  loss_dice_0: 4.004  loss_ce_1: 3.966  loss_mask_1: 0.6336  loss_dice_1: 3.977  loss_ce_2: 3.815  loss_mask_2: 0.6404  loss_dice_2: 3.925  loss_ce_3: 3.737  loss_mask_3: 0.6366  loss_dice_3: 3.898  loss_ce_4: 3.724  loss_mask_4: 0.6408  loss_dice_4: 3.901  loss_ce_5: 3.725  loss_mask_5: 0.6445  loss_dice_5: 3.892  loss_ce_6: 3.733  loss_mask_6: 0.6478  loss_dice_6: 3.879  loss_ce_7: 3.738  loss_mask_7: 0.6399  loss_dice_7: 3.884  loss_ce_8: 3.741  loss_mask_8: 0.6427  loss_dice_8: 3.879  time: 1.7224  data_time: 0.3567  lr: 9.7795e-06  max_mem: 16220M
[01/19 01:11:50] d2.utils.events INFO:  eta: 18:31:01  iter: 999  total_loss: 87.18  loss_ce: 3.905  loss_mask: 0.6533  loss_dice: 3.823  loss_ce_0: 7.257  loss_mask_0: 0.671  loss_dice_0: 3.95  loss_ce_1: 4.079  loss_mask_1: 0.6448  loss_dice_1: 3.937  loss_ce_2: 3.928  loss_mask_2: 0.6444  loss_dice_2: 3.885  loss_ce_3: 3.886  loss_mask_3: 0.6493  loss_dice_3: 3.838  loss_ce_4: 3.858  loss_mask_4: 0.6471  loss_dice_4: 3.84  loss_ce_5: 3.866  loss_mask_5: 0.6498  loss_dice_5: 3.835  loss_ce_6: 3.878  loss_mask_6: 0.6494  loss_dice_6: 3.821  loss_ce_7: 3.843  loss_mask_7: 0.6457  loss_dice_7: 3.825  loss_ce_8: 3.87  loss_mask_8: 0.6511  loss_dice_8: 3.829  time: 1.7221  data_time: 0.3400  lr: 9.7749e-06  max_mem: 16220M
[01/19 01:12:24] d2.utils.events INFO:  eta: 18:29:55  iter: 1019  total_loss: 87.76  loss_ce: 3.962  loss_mask: 0.6641  loss_dice: 3.775  loss_ce_0: 7.23  loss_mask_0: 0.6777  loss_dice_0: 3.936  loss_ce_1: 4.143  loss_mask_1: 0.6584  loss_dice_1: 3.893  loss_ce_2: 4.01  loss_mask_2: 0.6575  loss_dice_2: 3.847  loss_ce_3: 3.961  loss_mask_3: 0.6604  loss_dice_3: 3.808  loss_ce_4: 3.931  loss_mask_4: 0.6562  loss_dice_4: 3.81  loss_ce_5: 3.922  loss_mask_5: 0.6553  loss_dice_5: 3.809  loss_ce_6: 3.934  loss_mask_6: 0.6616  loss_dice_6: 3.788  loss_ce_7: 3.932  loss_mask_7: 0.6622  loss_dice_7: 3.787  loss_ce_8: 3.934  loss_mask_8: 0.6599  loss_dice_8: 3.779  time: 1.7217  data_time: 0.3357  lr: 9.7704e-06  max_mem: 16220M
[01/19 01:12:58] d2.utils.events INFO:  eta: 18:28:16  iter: 1039  total_loss: 85.98  loss_ce: 3.719  loss_mask: 0.6383  loss_dice: 3.839  loss_ce_0: 7.025  loss_mask_0: 0.664  loss_dice_0: 3.979  loss_ce_1: 3.943  loss_mask_1: 0.6403  loss_dice_1: 3.948  loss_ce_2: 3.789  loss_mask_2: 0.6406  loss_dice_2: 3.898  loss_ce_3: 3.705  loss_mask_3: 0.6421  loss_dice_3: 3.859  loss_ce_4: 3.689  loss_mask_4: 0.6401  loss_dice_4: 3.863  loss_ce_5: 3.686  loss_mask_5: 0.6429  loss_dice_5: 3.849  loss_ce_6: 3.675  loss_mask_6: 0.641  loss_dice_6: 3.836  loss_ce_7: 3.682  loss_mask_7: 0.6391  loss_dice_7: 3.833  loss_ce_8: 3.698  loss_mask_8: 0.6399  loss_dice_8: 3.828  time: 1.7214  data_time: 0.3339  lr: 9.7659e-06  max_mem: 16700M
[01/19 01:13:32] d2.utils.events INFO:  eta: 18:25:45  iter: 1059  total_loss: 86.65  loss_ce: 3.784  loss_mask: 0.6641  loss_dice: 3.816  loss_ce_0: 7.059  loss_mask_0: 0.686  loss_dice_0: 3.955  loss_ce_1: 4.024  loss_mask_1: 0.6623  loss_dice_1: 3.915  loss_ce_2: 3.876  loss_mask_2: 0.6659  loss_dice_2: 3.87  loss_ce_3: 3.796  loss_mask_3: 0.6711  loss_dice_3: 3.839  loss_ce_4: 3.747  loss_mask_4: 0.6699  loss_dice_4: 3.833  loss_ce_5: 3.739  loss_mask_5: 0.6694  loss_dice_5: 3.831  loss_ce_6: 3.783  loss_mask_6: 0.6682  loss_dice_6: 3.82  loss_ce_7: 3.732  loss_mask_7: 0.6663  loss_dice_7: 3.823  loss_ce_8: 3.789  loss_mask_8: 0.6644  loss_dice_8: 3.819  time: 1.7207  data_time: 0.3485  lr: 9.7614e-06  max_mem: 16700M
[01/19 01:14:05] d2.utils.events INFO:  eta: 18:24:52  iter: 1079  total_loss: 85.76  loss_ce: 3.724  loss_mask: 0.6506  loss_dice: 3.795  loss_ce_0: 6.979  loss_mask_0: 0.6899  loss_dice_0: 3.944  loss_ce_1: 3.865  loss_mask_1: 0.6632  loss_dice_1: 3.903  loss_ce_2: 3.72  loss_mask_2: 0.6599  loss_dice_2: 3.85  loss_ce_3: 3.632  loss_mask_3: 0.6554  loss_dice_3: 3.816  loss_ce_4: 3.618  loss_mask_4: 0.6512  loss_dice_4: 3.821  loss_ce_5: 3.649  loss_mask_5: 0.6507  loss_dice_5: 3.823  loss_ce_6: 3.664  loss_mask_6: 0.6534  loss_dice_6: 3.808  loss_ce_7: 3.651  loss_mask_7: 0.6522  loss_dice_7: 3.814  loss_ce_8: 3.653  loss_mask_8: 0.6516  loss_dice_8: 3.805  time: 1.7199  data_time: 0.3411  lr: 9.7569e-06  max_mem: 16700M
[01/19 01:14:39] d2.utils.events INFO:  eta: 18:23:42  iter: 1099  total_loss: 87.04  loss_ce: 3.865  loss_mask: 0.6567  loss_dice: 3.795  loss_ce_0: 7.052  loss_mask_0: 0.6934  loss_dice_0: 3.958  loss_ce_1: 4.108  loss_mask_1: 0.6675  loss_dice_1: 3.912  loss_ce_2: 3.974  loss_mask_2: 0.6605  loss_dice_2: 3.867  loss_ce_3: 3.875  loss_mask_3: 0.6525  loss_dice_3: 3.829  loss_ce_4: 3.855  loss_mask_4: 0.6514  loss_dice_4: 3.825  loss_ce_5: 3.861  loss_mask_5: 0.6561  loss_dice_5: 3.814  loss_ce_6: 3.836  loss_mask_6: 0.6566  loss_dice_6: 3.802  loss_ce_7: 3.814  loss_mask_7: 0.6591  loss_dice_7: 3.805  loss_ce_8: 3.855  loss_mask_8: 0.6577  loss_dice_8: 3.805  time: 1.7196  data_time: 0.3407  lr: 9.7524e-06  max_mem: 16700M
[01/19 01:15:13] d2.utils.events INFO:  eta: 18:22:35  iter: 1119  total_loss: 86.6  loss_ce: 3.835  loss_mask: 0.657  loss_dice: 3.816  loss_ce_0: 6.897  loss_mask_0: 0.686  loss_dice_0: 3.957  loss_ce_1: 4.032  loss_mask_1: 0.6599  loss_dice_1: 3.915  loss_ce_2: 3.894  loss_mask_2: 0.655  loss_dice_2: 3.863  loss_ce_3: 3.761  loss_mask_3: 0.6566  loss_dice_3: 3.837  loss_ce_4: 3.776  loss_mask_4: 0.6511  loss_dice_4: 3.832  loss_ce_5: 3.822  loss_mask_5: 0.653  loss_dice_5: 3.83  loss_ce_6: 3.795  loss_mask_6: 0.6561  loss_dice_6: 3.817  loss_ce_7: 3.779  loss_mask_7: 0.6535  loss_dice_7: 3.825  loss_ce_8: 3.802  loss_mask_8: 0.6538  loss_dice_8: 3.826  time: 1.7188  data_time: 0.3195  lr: 9.7479e-06  max_mem: 16700M
[01/19 01:15:47] d2.utils.events INFO:  eta: 18:21:39  iter: 1139  total_loss: 85.5  loss_ce: 3.754  loss_mask: 0.6471  loss_dice: 3.8  loss_ce_0: 6.816  loss_mask_0: 0.6786  loss_dice_0: 3.972  loss_ce_1: 3.901  loss_mask_1: 0.6537  loss_dice_1: 3.914  loss_ce_2: 3.765  loss_mask_2: 0.6556  loss_dice_2: 3.865  loss_ce_3: 3.702  loss_mask_3: 0.6496  loss_dice_3: 3.831  loss_ce_4: 3.631  loss_mask_4: 0.6521  loss_dice_4: 3.825  loss_ce_5: 3.655  loss_mask_5: 0.653  loss_dice_5: 3.826  loss_ce_6: 3.7  loss_mask_6: 0.6541  loss_dice_6: 3.814  loss_ce_7: 3.696  loss_mask_7: 0.65  loss_dice_7: 3.809  loss_ce_8: 3.685  loss_mask_8: 0.6548  loss_dice_8: 3.804  time: 1.7183  data_time: 0.3577  lr: 9.7434e-06  max_mem: 16700M
[01/19 01:16:21] d2.utils.events INFO:  eta: 18:20:56  iter: 1159  total_loss: 85.81  loss_ce: 3.791  loss_mask: 0.6627  loss_dice: 3.76  loss_ce_0: 6.82  loss_mask_0: 0.6765  loss_dice_0: 3.953  loss_ce_1: 3.982  loss_mask_1: 0.6649  loss_dice_1: 3.892  loss_ce_2: 3.812  loss_mask_2: 0.663  loss_dice_2: 3.842  loss_ce_3: 3.778  loss_mask_3: 0.6626  loss_dice_3: 3.799  loss_ce_4: 3.728  loss_mask_4: 0.6595  loss_dice_4: 3.799  loss_ce_5: 3.745  loss_mask_5: 0.6597  loss_dice_5: 3.802  loss_ce_6: 3.738  loss_mask_6: 0.6632  loss_dice_6: 3.778  loss_ce_7: 3.753  loss_mask_7: 0.661  loss_dice_7: 3.779  loss_ce_8: 3.73  loss_mask_8: 0.6602  loss_dice_8: 3.773  time: 1.7181  data_time: 0.3368  lr: 9.7388e-06  max_mem: 16700M
[01/19 01:16:55] d2.utils.events INFO:  eta: 18:20:31  iter: 1179  total_loss: 85.25  loss_ce: 3.759  loss_mask: 0.6457  loss_dice: 3.803  loss_ce_0: 6.735  loss_mask_0: 0.6622  loss_dice_0: 3.982  loss_ce_1: 3.933  loss_mask_1: 0.6465  loss_dice_1: 3.921  loss_ce_2: 3.787  loss_mask_2: 0.6472  loss_dice_2: 3.876  loss_ce_3: 3.703  loss_mask_3: 0.6502  loss_dice_3: 3.844  loss_ce_4: 3.654  loss_mask_4: 0.6476  loss_dice_4: 3.829  loss_ce_5: 3.685  loss_mask_5: 0.6485  loss_dice_5: 3.827  loss_ce_6: 3.683  loss_mask_6: 0.6508  loss_dice_6: 3.811  loss_ce_7: 3.7  loss_mask_7: 0.6505  loss_dice_7: 3.813  loss_ce_8: 3.72  loss_mask_8: 0.6457  loss_dice_8: 3.808  time: 1.7180  data_time: 0.3529  lr: 9.7343e-06  max_mem: 16700M
[01/19 01:17:30] d2.utils.events INFO:  eta: 18:20:28  iter: 1199  total_loss: 84.17  loss_ce: 3.59  loss_mask: 0.6401  loss_dice: 3.864  loss_ce_0: 6.615  loss_mask_0: 0.6592  loss_dice_0: 4.015  loss_ce_1: 3.784  loss_mask_1: 0.6395  loss_dice_1: 3.976  loss_ce_2: 3.61  loss_mask_2: 0.6369  loss_dice_2: 3.928  loss_ce_3: 3.533  loss_mask_3: 0.642  loss_dice_3: 3.896  loss_ce_4: 3.492  loss_mask_4: 0.6352  loss_dice_4: 3.878  loss_ce_5: 3.528  loss_mask_5: 0.6371  loss_dice_5: 3.884  loss_ce_6: 3.538  loss_mask_6: 0.6384  loss_dice_6: 3.871  loss_ce_7: 3.573  loss_mask_7: 0.6392  loss_dice_7: 3.862  loss_ce_8: 3.586  loss_mask_8: 0.6383  loss_dice_8: 3.866  time: 1.7180  data_time: 0.3552  lr: 9.7298e-06  max_mem: 16700M
[01/19 01:18:03] d2.utils.events INFO:  eta: 18:19:03  iter: 1219  total_loss: 85.75  loss_ce: 3.848  loss_mask: 0.6646  loss_dice: 3.755  loss_ce_0: 6.714  loss_mask_0: 0.7  loss_dice_0: 3.91  loss_ce_1: 4.011  loss_mask_1: 0.6726  loss_dice_1: 3.857  loss_ce_2: 3.846  loss_mask_2: 0.6702  loss_dice_2: 3.806  loss_ce_3: 3.776  loss_mask_3: 0.6671  loss_dice_3: 3.77  loss_ce_4: 3.777  loss_mask_4: 0.6655  loss_dice_4: 3.766  loss_ce_5: 3.772  loss_mask_5: 0.664  loss_dice_5: 3.767  loss_ce_6: 3.803  loss_mask_6: 0.6671  loss_dice_6: 3.755  loss_ce_7: 3.804  loss_mask_7: 0.6618  loss_dice_7: 3.749  loss_ce_8: 3.809  loss_mask_8: 0.6653  loss_dice_8: 3.76  time: 1.7173  data_time: 0.3383  lr: 9.7253e-06  max_mem: 16700M
[01/19 01:18:37] d2.utils.events INFO:  eta: 18:18:29  iter: 1239  total_loss: 84.68  loss_ce: 3.703  loss_mask: 0.6461  loss_dice: 3.829  loss_ce_0: 6.549  loss_mask_0: 0.6758  loss_dice_0: 3.975  loss_ce_1: 3.85  loss_mask_1: 0.6478  loss_dice_1: 3.93  loss_ce_2: 3.712  loss_mask_2: 0.6509  loss_dice_2: 3.884  loss_ce_3: 3.67  loss_mask_3: 0.6465  loss_dice_3: 3.847  loss_ce_4: 3.641  loss_mask_4: 0.645  loss_dice_4: 3.839  loss_ce_5: 3.628  loss_mask_5: 0.6488  loss_dice_5: 3.836  loss_ce_6: 3.671  loss_mask_6: 0.6501  loss_dice_6: 3.815  loss_ce_7: 3.669  loss_mask_7: 0.6441  loss_dice_7: 3.827  loss_ce_8: 3.678  loss_mask_8: 0.6435  loss_dice_8: 3.827  time: 1.7172  data_time: 0.3526  lr: 9.7208e-06  max_mem: 16700M
[01/19 01:19:12] d2.utils.events INFO:  eta: 18:18:10  iter: 1259  total_loss: 82.98  loss_ce: 3.524  loss_mask: 0.643  loss_dice: 3.862  loss_ce_0: 6.386  loss_mask_0: 0.6604  loss_dice_0: 4.014  loss_ce_1: 3.661  loss_mask_1: 0.6375  loss_dice_1: 3.956  loss_ce_2: 3.483  loss_mask_2: 0.6385  loss_dice_2: 3.918  loss_ce_3: 3.441  loss_mask_3: 0.6384  loss_dice_3: 3.883  loss_ce_4: 3.411  loss_mask_4: 0.6377  loss_dice_4: 3.882  loss_ce_5: 3.428  loss_mask_5: 0.6339  loss_dice_5: 3.876  loss_ce_6: 3.428  loss_mask_6: 0.6414  loss_dice_6: 3.868  loss_ce_7: 3.46  loss_mask_7: 0.6415  loss_dice_7: 3.869  loss_ce_8: 3.478  loss_mask_8: 0.6426  loss_dice_8: 3.87  time: 1.7170  data_time: 0.3386  lr: 9.7163e-06  max_mem: 16700M
[01/19 01:19:46] d2.utils.events INFO:  eta: 18:17:36  iter: 1279  total_loss: 84.43  loss_ce: 3.64  loss_mask: 0.6374  loss_dice: 3.828  loss_ce_0: 6.423  loss_mask_0: 0.6558  loss_dice_0: 4.003  loss_ce_1: 3.785  loss_mask_1: 0.6369  loss_dice_1: 3.951  loss_ce_2: 3.609  loss_mask_2: 0.634  loss_dice_2: 3.89  loss_ce_3: 3.597  loss_mask_3: 0.6344  loss_dice_3: 3.847  loss_ce_4: 3.527  loss_mask_4: 0.6324  loss_dice_4: 3.846  loss_ce_5: 3.543  loss_mask_5: 0.6364  loss_dice_5: 3.839  loss_ce_6: 3.566  loss_mask_6: 0.6371  loss_dice_6: 3.827  loss_ce_7: 3.596  loss_mask_7: 0.6345  loss_dice_7: 3.821  loss_ce_8: 3.606  loss_mask_8: 0.6348  loss_dice_8: 3.825  time: 1.7170  data_time: 0.3353  lr: 9.7118e-06  max_mem: 16700M
[01/19 01:20:20] d2.utils.events INFO:  eta: 18:17:29  iter: 1299  total_loss: 83.81  loss_ce: 3.618  loss_mask: 0.6256  loss_dice: 3.838  loss_ce_0: 6.344  loss_mask_0: 0.6426  loss_dice_0: 4.008  loss_ce_1: 3.834  loss_mask_1: 0.627  loss_dice_1: 3.949  loss_ce_2: 3.66  loss_mask_2: 0.6329  loss_dice_2: 3.905  loss_ce_3: 3.638  loss_mask_3: 0.6282  loss_dice_3: 3.86  loss_ce_4: 3.593  loss_mask_4: 0.6291  loss_dice_4: 3.859  loss_ce_5: 3.581  loss_mask_5: 0.6324  loss_dice_5: 3.851  loss_ce_6: 3.583  loss_mask_6: 0.6294  loss_dice_6: 3.842  loss_ce_7: 3.573  loss_mask_7: 0.629  loss_dice_7: 3.836  loss_ce_8: 3.595  loss_mask_8: 0.6305  loss_dice_8: 3.836  time: 1.7169  data_time: 0.3419  lr: 9.7072e-06  max_mem: 16700M
[01/19 01:20:54] d2.utils.events INFO:  eta: 18:16:50  iter: 1319  total_loss: 83.71  loss_ce: 3.571  loss_mask: 0.6382  loss_dice: 3.858  loss_ce_0: 6.241  loss_mask_0: 0.6508  loss_dice_0: 4.003  loss_ce_1: 3.753  loss_mask_1: 0.6315  loss_dice_1: 3.959  loss_ce_2: 3.604  loss_mask_2: 0.6348  loss_dice_2: 3.916  loss_ce_3: 3.553  loss_mask_3: 0.6403  loss_dice_3: 3.879  loss_ce_4: 3.52  loss_mask_4: 0.6375  loss_dice_4: 3.885  loss_ce_5: 3.511  loss_mask_5: 0.6414  loss_dice_5: 3.875  loss_ce_6: 3.518  loss_mask_6: 0.6391  loss_dice_6: 3.863  loss_ce_7: 3.53  loss_mask_7: 0.6394  loss_dice_7: 3.863  loss_ce_8: 3.557  loss_mask_8: 0.6366  loss_dice_8: 3.864  time: 1.7169  data_time: 0.3505  lr: 9.7027e-06  max_mem: 16700M
[01/19 01:21:29] d2.utils.events INFO:  eta: 18:16:25  iter: 1339  total_loss: 83.87  loss_ce: 3.641  loss_mask: 0.6405  loss_dice: 3.779  loss_ce_0: 6.333  loss_mask_0: 0.6587  loss_dice_0: 3.973  loss_ce_1: 3.863  loss_mask_1: 0.6435  loss_dice_1: 3.897  loss_ce_2: 3.7  loss_mask_2: 0.6417  loss_dice_2: 3.837  loss_ce_3: 3.653  loss_mask_3: 0.6404  loss_dice_3: 3.798  loss_ce_4: 3.617  loss_mask_4: 0.6405  loss_dice_4: 3.8  loss_ce_5: 3.61  loss_mask_5: 0.6414  loss_dice_5: 3.796  loss_ce_6: 3.609  loss_mask_6: 0.6409  loss_dice_6: 3.79  loss_ce_7: 3.609  loss_mask_7: 0.6432  loss_dice_7: 3.784  loss_ce_8: 3.616  loss_mask_8: 0.6452  loss_dice_8: 3.784  time: 1.7170  data_time: 0.3638  lr: 9.6982e-06  max_mem: 16700M
[01/19 01:22:03] d2.utils.events INFO:  eta: 18:15:33  iter: 1359  total_loss: 84.07  loss_ce: 3.701  loss_mask: 0.6668  loss_dice: 3.741  loss_ce_0: 6.334  loss_mask_0: 0.692  loss_dice_0: 3.94  loss_ce_1: 3.841  loss_mask_1: 0.6652  loss_dice_1: 3.86  loss_ce_2: 3.685  loss_mask_2: 0.6665  loss_dice_2: 3.816  loss_ce_3: 3.643  loss_mask_3: 0.6662  loss_dice_3: 3.762  loss_ce_4: 3.633  loss_mask_4: 0.6672  loss_dice_4: 3.761  loss_ce_5: 3.648  loss_mask_5: 0.6651  loss_dice_5: 3.758  loss_ce_6: 3.664  loss_mask_6: 0.6622  loss_dice_6: 3.749  loss_ce_7: 3.643  loss_mask_7: 0.6618  loss_dice_7: 3.742  loss_ce_8: 3.655  loss_mask_8: 0.6607  loss_dice_8: 3.748  time: 1.7168  data_time: 0.3425  lr: 9.6937e-06  max_mem: 16700M
[01/19 01:22:37] d2.utils.events INFO:  eta: 18:15:13  iter: 1379  total_loss: 83.59  loss_ce: 3.649  loss_mask: 0.6486  loss_dice: 3.751  loss_ce_0: 6.26  loss_mask_0: 0.6688  loss_dice_0: 3.965  loss_ce_1: 3.813  loss_mask_1: 0.6561  loss_dice_1: 3.872  loss_ce_2: 3.663  loss_mask_2: 0.648  loss_dice_2: 3.82  loss_ce_3: 3.613  loss_mask_3: 0.6504  loss_dice_3: 3.782  loss_ce_4: 3.608  loss_mask_4: 0.6494  loss_dice_4: 3.773  loss_ce_5: 3.631  loss_mask_5: 0.652  loss_dice_5: 3.771  loss_ce_6: 3.621  loss_mask_6: 0.6504  loss_dice_6: 3.762  loss_ce_7: 3.591  loss_mask_7: 0.6476  loss_dice_7: 3.754  loss_ce_8: 3.608  loss_mask_8: 0.6488  loss_dice_8: 3.756  time: 1.7164  data_time: 0.3523  lr: 9.6892e-06  max_mem: 16700M
[01/19 01:23:11] d2.utils.events INFO:  eta: 18:14:54  iter: 1399  total_loss: 83.45  loss_ce: 3.6  loss_mask: 0.6362  loss_dice: 3.791  loss_ce_0: 6.175  loss_mask_0: 0.6551  loss_dice_0: 3.988  loss_ce_1: 3.808  loss_mask_1: 0.6303  loss_dice_1: 3.911  loss_ce_2: 3.672  loss_mask_2: 0.6329  loss_dice_2: 3.851  loss_ce_3: 3.618  loss_mask_3: 0.6308  loss_dice_3: 3.812  loss_ce_4: 3.575  loss_mask_4: 0.6279  loss_dice_4: 3.81  loss_ce_5: 3.57  loss_mask_5: 0.6331  loss_dice_5: 3.796  loss_ce_6: 3.579  loss_mask_6: 0.6355  loss_dice_6: 3.793  loss_ce_7: 3.591  loss_mask_7: 0.6345  loss_dice_7: 3.788  loss_ce_8: 3.58  loss_mask_8: 0.6379  loss_dice_8: 3.794  time: 1.7165  data_time: 0.3509  lr: 9.6847e-06  max_mem: 16700M
[01/19 01:23:45] d2.utils.events INFO:  eta: 18:14:05  iter: 1419  total_loss: 83.69  loss_ce: 3.655  loss_mask: 0.6393  loss_dice: 3.801  loss_ce_0: 6.107  loss_mask_0: 0.6543  loss_dice_0: 3.987  loss_ce_1: 3.751  loss_mask_1: 0.6376  loss_dice_1: 3.919  loss_ce_2: 3.653  loss_mask_2: 0.6374  loss_dice_2: 3.865  loss_ce_3: 3.58  loss_mask_3: 0.6376  loss_dice_3: 3.824  loss_ce_4: 3.586  loss_mask_4: 0.6375  loss_dice_4: 3.816  loss_ce_5: 3.613  loss_mask_5: 0.639  loss_dice_5: 3.812  loss_ce_6: 3.6  loss_mask_6: 0.6396  loss_dice_6: 3.807  loss_ce_7: 3.613  loss_mask_7: 0.639  loss_dice_7: 3.807  loss_ce_8: 3.609  loss_mask_8: 0.6392  loss_dice_8: 3.806  time: 1.7161  data_time: 0.3422  lr: 9.6802e-06  max_mem: 16700M
[01/19 01:24:19] d2.utils.events INFO:  eta: 18:13:31  iter: 1439  total_loss: 83.3  loss_ce: 3.637  loss_mask: 0.6403  loss_dice: 3.755  loss_ce_0: 6.102  loss_mask_0: 0.6635  loss_dice_0: 3.955  loss_ce_1: 3.786  loss_mask_1: 0.6413  loss_dice_1: 3.883  loss_ce_2: 3.64  loss_mask_2: 0.6405  loss_dice_2: 3.827  loss_ce_3: 3.605  loss_mask_3: 0.6394  loss_dice_3: 3.786  loss_ce_4: 3.593  loss_mask_4: 0.6367  loss_dice_4: 3.787  loss_ce_5: 3.587  loss_mask_5: 0.6348  loss_dice_5: 3.778  loss_ce_6: 3.604  loss_mask_6: 0.6433  loss_dice_6: 3.762  loss_ce_7: 3.588  loss_mask_7: 0.6433  loss_dice_7: 3.755  loss_ce_8: 3.603  loss_mask_8: 0.6409  loss_dice_8: 3.762  time: 1.7156  data_time: 0.3361  lr: 9.6756e-06  max_mem: 16700M
[01/19 01:24:53] d2.utils.events INFO:  eta: 18:12:52  iter: 1459  total_loss: 83.53  loss_ce: 3.678  loss_mask: 0.6593  loss_dice: 3.739  loss_ce_0: 6.165  loss_mask_0: 0.6843  loss_dice_0: 3.945  loss_ce_1: 3.838  loss_mask_1: 0.66  loss_dice_1: 3.86  loss_ce_2: 3.71  loss_mask_2: 0.6543  loss_dice_2: 3.802  loss_ce_3: 3.648  loss_mask_3: 0.6608  loss_dice_3: 3.76  loss_ce_4: 3.626  loss_mask_4: 0.6607  loss_dice_4: 3.749  loss_ce_5: 3.613  loss_mask_5: 0.6601  loss_dice_5: 3.748  loss_ce_6: 3.628  loss_mask_6: 0.664  loss_dice_6: 3.737  loss_ce_7: 3.649  loss_mask_7: 0.6614  loss_dice_7: 3.746  loss_ce_8: 3.641  loss_mask_8: 0.6599  loss_dice_8: 3.747  time: 1.7151  data_time: 0.3329  lr: 9.6711e-06  max_mem: 16700M
[01/19 01:25:27] d2.utils.events INFO:  eta: 18:12:41  iter: 1479  total_loss: 83.23  loss_ce: 3.593  loss_mask: 0.6466  loss_dice: 3.775  loss_ce_0: 5.978  loss_mask_0: 0.6703  loss_dice_0: 3.963  loss_ce_1: 3.784  loss_mask_1: 0.6464  loss_dice_1: 3.904  loss_ce_2: 3.581  loss_mask_2: 0.6471  loss_dice_2: 3.84  loss_ce_3: 3.535  loss_mask_3: 0.6496  loss_dice_3: 3.798  loss_ce_4: 3.505  loss_mask_4: 0.6455  loss_dice_4: 3.794  loss_ce_5: 3.52  loss_mask_5: 0.6449  loss_dice_5: 3.788  loss_ce_6: 3.542  loss_mask_6: 0.6468  loss_dice_6: 3.78  loss_ce_7: 3.548  loss_mask_7: 0.6446  loss_dice_7: 3.774  loss_ce_8: 3.55  loss_mask_8: 0.6445  loss_dice_8: 3.779  time: 1.7152  data_time: 0.3529  lr: 9.6666e-06  max_mem: 16700M
[01/19 01:26:02] d2.utils.events INFO:  eta: 18:12:51  iter: 1499  total_loss: 81.85  loss_ce: 3.405  loss_mask: 0.6274  loss_dice: 3.811  loss_ce_0: 5.904  loss_mask_0: 0.6458  loss_dice_0: 4.004  loss_ce_1: 3.629  loss_mask_1: 0.6295  loss_dice_1: 3.924  loss_ce_2: 3.468  loss_mask_2: 0.6265  loss_dice_2: 3.872  loss_ce_3: 3.397  loss_mask_3: 0.6267  loss_dice_3: 3.833  loss_ce_4: 3.347  loss_mask_4: 0.624  loss_dice_4: 3.828  loss_ce_5: 3.365  loss_mask_5: 0.6221  loss_dice_5: 3.818  loss_ce_6: 3.357  loss_mask_6: 0.6245  loss_dice_6: 3.818  loss_ce_7: 3.386  loss_mask_7: 0.6253  loss_dice_7: 3.808  loss_ce_8: 3.385  loss_mask_8: 0.6264  loss_dice_8: 3.804  time: 1.7154  data_time: 0.3457  lr: 9.6621e-06  max_mem: 16700M
[01/19 01:26:36] d2.utils.events INFO:  eta: 18:12:36  iter: 1519  total_loss: 81.98  loss_ce: 3.445  loss_mask: 0.6358  loss_dice: 3.85  loss_ce_0: 5.78  loss_mask_0: 0.6482  loss_dice_0: 4.033  loss_ce_1: 3.546  loss_mask_1: 0.6371  loss_dice_1: 3.961  loss_ce_2: 3.417  loss_mask_2: 0.6321  loss_dice_2: 3.901  loss_ce_3: 3.405  loss_mask_3: 0.6349  loss_dice_3: 3.876  loss_ce_4: 3.376  loss_mask_4: 0.6351  loss_dice_4: 3.867  loss_ce_5: 3.352  loss_mask_5: 0.6362  loss_dice_5: 3.867  loss_ce_6: 3.387  loss_mask_6: 0.6354  loss_dice_6: 3.853  loss_ce_7: 3.402  loss_mask_7: 0.6392  loss_dice_7: 3.851  loss_ce_8: 3.426  loss_mask_8: 0.6373  loss_dice_8: 3.853  time: 1.7153  data_time: 0.3661  lr: 9.6576e-06  max_mem: 16700M
[01/19 01:27:10] d2.utils.events INFO:  eta: 18:12:15  iter: 1539  total_loss: 83  loss_ce: 3.627  loss_mask: 0.6519  loss_dice: 3.776  loss_ce_0: 5.861  loss_mask_0: 0.6634  loss_dice_0: 3.979  loss_ce_1: 3.717  loss_mask_1: 0.6591  loss_dice_1: 3.895  loss_ce_2: 3.628  loss_mask_2: 0.6557  loss_dice_2: 3.843  loss_ce_3: 3.58  loss_mask_3: 0.6527  loss_dice_3: 3.805  loss_ce_4: 3.562  loss_mask_4: 0.6507  loss_dice_4: 3.795  loss_ce_5: 3.562  loss_mask_5: 0.6531  loss_dice_5: 3.794  loss_ce_6: 3.568  loss_mask_6: 0.6553  loss_dice_6: 3.785  loss_ce_7: 3.559  loss_mask_7: 0.6531  loss_dice_7: 3.786  loss_ce_8: 3.594  loss_mask_8: 0.6509  loss_dice_8: 3.779  time: 1.7152  data_time: 0.3449  lr: 9.653e-06  max_mem: 16700M
[01/19 01:27:44] d2.utils.events INFO:  eta: 18:11:51  iter: 1559  total_loss: 82.72  loss_ce: 3.565  loss_mask: 0.6309  loss_dice: 3.78  loss_ce_0: 5.878  loss_mask_0: 0.6516  loss_dice_0: 3.955  loss_ce_1: 3.762  loss_mask_1: 0.6322  loss_dice_1: 3.898  loss_ce_2: 3.62  loss_mask_2: 0.629  loss_dice_2: 3.844  loss_ce_3: 3.571  loss_mask_3: 0.63  loss_dice_3: 3.815  loss_ce_4: 3.556  loss_mask_4: 0.6312  loss_dice_4: 3.805  loss_ce_5: 3.547  loss_mask_5: 0.6318  loss_dice_5: 3.801  loss_ce_6: 3.55  loss_mask_6: 0.631  loss_dice_6: 3.79  loss_ce_7: 3.571  loss_mask_7: 0.6299  loss_dice_7: 3.789  loss_ce_8: 3.545  loss_mask_8: 0.6294  loss_dice_8: 3.788  time: 1.7151  data_time: 0.3361  lr: 9.6485e-06  max_mem: 16700M
[01/19 01:28:19] d2.utils.events INFO:  eta: 18:11:13  iter: 1579  total_loss: 82.4  loss_ce: 3.549  loss_mask: 0.6361  loss_dice: 3.778  loss_ce_0: 5.793  loss_mask_0: 0.6613  loss_dice_0: 3.97  loss_ce_1: 3.677  loss_mask_1: 0.6409  loss_dice_1: 3.892  loss_ce_2: 3.576  loss_mask_2: 0.6409  loss_dice_2: 3.831  loss_ce_3: 3.517  loss_mask_3: 0.6373  loss_dice_3: 3.804  loss_ce_4: 3.505  loss_mask_4: 0.6363  loss_dice_4: 3.798  loss_ce_5: 3.526  loss_mask_5: 0.6358  loss_dice_5: 3.796  loss_ce_6: 3.497  loss_mask_6: 0.6365  loss_dice_6: 3.781  loss_ce_7: 3.491  loss_mask_7: 0.6382  loss_dice_7: 3.781  loss_ce_8: 3.513  loss_mask_8: 0.6367  loss_dice_8: 3.78  time: 1.7151  data_time: 0.3658  lr: 9.644e-06  max_mem: 16700M
[01/19 01:28:53] d2.utils.events INFO:  eta: 18:10:27  iter: 1599  total_loss: 82.2  loss_ce: 3.523  loss_mask: 0.6327  loss_dice: 3.768  loss_ce_0: 5.749  loss_mask_0: 0.6494  loss_dice_0: 3.963  loss_ce_1: 3.676  loss_mask_1: 0.6328  loss_dice_1: 3.877  loss_ce_2: 3.526  loss_mask_2: 0.6348  loss_dice_2: 3.823  loss_ce_3: 3.489  loss_mask_3: 0.635  loss_dice_3: 3.781  loss_ce_4: 3.446  loss_mask_4: 0.6348  loss_dice_4: 3.776  loss_ce_5: 3.445  loss_mask_5: 0.6349  loss_dice_5: 3.78  loss_ce_6: 3.452  loss_mask_6: 0.6359  loss_dice_6: 3.771  loss_ce_7: 3.471  loss_mask_7: 0.6311  loss_dice_7: 3.759  loss_ce_8: 3.501  loss_mask_8: 0.6308  loss_dice_8: 3.775  time: 1.7149  data_time: 0.3330  lr: 9.6395e-06  max_mem: 16700M
[01/19 01:29:26] d2.utils.events INFO:  eta: 18:08:46  iter: 1619  total_loss: 82.44  loss_ce: 3.636  loss_mask: 0.6554  loss_dice: 3.671  loss_ce_0: 5.81  loss_mask_0: 0.6811  loss_dice_0: 3.914  loss_ce_1: 3.786  loss_mask_1: 0.6646  loss_dice_1: 3.81  loss_ce_2: 3.678  loss_mask_2: 0.6614  loss_dice_2: 3.746  loss_ce_3: 3.641  loss_mask_3: 0.6616  loss_dice_3: 3.693  loss_ce_4: 3.617  loss_mask_4: 0.6577  loss_dice_4: 3.689  loss_ce_5: 3.645  loss_mask_5: 0.658  loss_dice_5: 3.681  loss_ce_6: 3.623  loss_mask_6: 0.6545  loss_dice_6: 3.672  loss_ce_7: 3.625  loss_mask_7: 0.6574  loss_dice_7: 3.673  loss_ce_8: 3.628  loss_mask_8: 0.6581  loss_dice_8: 3.67  time: 1.7144  data_time: 0.3302  lr: 9.635e-06  max_mem: 16700M
[01/19 01:30:01] d2.utils.events INFO:  eta: 18:08:08  iter: 1639  total_loss: 81.97  loss_ce: 3.552  loss_mask: 0.6374  loss_dice: 3.741  loss_ce_0: 5.687  loss_mask_0: 0.6616  loss_dice_0: 3.961  loss_ce_1: 3.722  loss_mask_1: 0.6444  loss_dice_1: 3.876  loss_ce_2: 3.604  loss_mask_2: 0.6436  loss_dice_2: 3.806  loss_ce_3: 3.547  loss_mask_3: 0.637  loss_dice_3: 3.77  loss_ce_4: 3.51  loss_mask_4: 0.6371  loss_dice_4: 3.766  loss_ce_5: 3.551  loss_mask_5: 0.6376  loss_dice_5: 3.756  loss_ce_6: 3.532  loss_mask_6: 0.6378  loss_dice_6: 3.752  loss_ce_7: 3.507  loss_mask_7: 0.6377  loss_dice_7: 3.75  loss_ce_8: 3.53  loss_mask_8: 0.6401  loss_dice_8: 3.749  time: 1.7145  data_time: 0.3491  lr: 9.6305e-06  max_mem: 16700M
[01/19 01:30:35] d2.utils.events INFO:  eta: 18:07:18  iter: 1659  total_loss: 82.09  loss_ce: 3.52  loss_mask: 0.6386  loss_dice: 3.757  loss_ce_0: 5.65  loss_mask_0: 0.6621  loss_dice_0: 3.967  loss_ce_1: 3.704  loss_mask_1: 0.6394  loss_dice_1: 3.873  loss_ce_2: 3.573  loss_mask_2: 0.6425  loss_dice_2: 3.818  loss_ce_3: 3.505  loss_mask_3: 0.642  loss_dice_3: 3.774  loss_ce_4: 3.522  loss_mask_4: 0.6404  loss_dice_4: 3.786  loss_ce_5: 3.533  loss_mask_5: 0.6387  loss_dice_5: 3.773  loss_ce_6: 3.523  loss_mask_6: 0.6403  loss_dice_6: 3.758  loss_ce_7: 3.518  loss_mask_7: 0.6389  loss_dice_7: 3.762  loss_ce_8: 3.499  loss_mask_8: 0.6386  loss_dice_8: 3.757  time: 1.7143  data_time: 0.3471  lr: 9.6259e-06  max_mem: 16700M
[01/19 01:31:09] d2.utils.events INFO:  eta: 18:06:44  iter: 1679  total_loss: 81.07  loss_ce: 3.497  loss_mask: 0.6394  loss_dice: 3.784  loss_ce_0: 5.558  loss_mask_0: 0.6467  loss_dice_0: 3.986  loss_ce_1: 3.652  loss_mask_1: 0.6428  loss_dice_1: 3.891  loss_ce_2: 3.517  loss_mask_2: 0.6402  loss_dice_2: 3.844  loss_ce_3: 3.456  loss_mask_3: 0.6426  loss_dice_3: 3.806  loss_ce_4: 3.439  loss_mask_4: 0.6399  loss_dice_4: 3.802  loss_ce_5: 3.432  loss_mask_5: 0.6407  loss_dice_5: 3.802  loss_ce_6: 3.423  loss_mask_6: 0.6425  loss_dice_6: 3.784  loss_ce_7: 3.437  loss_mask_7: 0.6433  loss_dice_7: 3.787  loss_ce_8: 3.466  loss_mask_8: 0.6404  loss_dice_8: 3.784  time: 1.7143  data_time: 0.3458  lr: 9.6214e-06  max_mem: 16700M
[01/19 01:31:43] d2.utils.events INFO:  eta: 18:05:54  iter: 1699  total_loss: 81.41  loss_ce: 3.479  loss_mask: 0.6413  loss_dice: 3.731  loss_ce_0: 5.576  loss_mask_0: 0.6546  loss_dice_0: 3.947  loss_ce_1: 3.698  loss_mask_1: 0.6418  loss_dice_1: 3.849  loss_ce_2: 3.577  loss_mask_2: 0.6407  loss_dice_2: 3.795  loss_ce_3: 3.461  loss_mask_3: 0.64  loss_dice_3: 3.758  loss_ce_4: 3.454  loss_mask_4: 0.6441  loss_dice_4: 3.756  loss_ce_5: 3.461  loss_mask_5: 0.6417  loss_dice_5: 3.747  loss_ce_6: 3.443  loss_mask_6: 0.6405  loss_dice_6: 3.735  loss_ce_7: 3.461  loss_mask_7: 0.6438  loss_dice_7: 3.732  loss_ce_8: 3.464  loss_mask_8: 0.6439  loss_dice_8: 3.744  time: 1.7141  data_time: 0.3442  lr: 9.6169e-06  max_mem: 16700M
[01/19 01:32:16] d2.utils.events INFO:  eta: 18:05:06  iter: 1719  total_loss: 81.82  loss_ce: 3.56  loss_mask: 0.6466  loss_dice: 3.733  loss_ce_0: 5.55  loss_mask_0: 0.6688  loss_dice_0: 3.969  loss_ce_1: 3.683  loss_mask_1: 0.644  loss_dice_1: 3.861  loss_ce_2: 3.521  loss_mask_2: 0.6516  loss_dice_2: 3.805  loss_ce_3: 3.489  loss_mask_3: 0.6477  loss_dice_3: 3.756  loss_ce_4: 3.487  loss_mask_4: 0.6452  loss_dice_4: 3.752  loss_ce_5: 3.494  loss_mask_5: 0.6474  loss_dice_5: 3.743  loss_ce_6: 3.508  loss_mask_6: 0.6467  loss_dice_6: 3.739  loss_ce_7: 3.522  loss_mask_7: 0.6475  loss_dice_7: 3.737  loss_ce_8: 3.553  loss_mask_8: 0.6483  loss_dice_8: 3.738  time: 1.7136  data_time: 0.3419  lr: 9.6124e-06  max_mem: 16700M
[01/19 01:32:50] d2.utils.events INFO:  eta: 18:04:25  iter: 1739  total_loss: 81.52  loss_ce: 3.52  loss_mask: 0.6487  loss_dice: 3.733  loss_ce_0: 5.464  loss_mask_0: 0.67  loss_dice_0: 3.946  loss_ce_1: 3.652  loss_mask_1: 0.6525  loss_dice_1: 3.855  loss_ce_2: 3.54  loss_mask_2: 0.6477  loss_dice_2: 3.793  loss_ce_3: 3.506  loss_mask_3: 0.6511  loss_dice_3: 3.761  loss_ce_4: 3.494  loss_mask_4: 0.6527  loss_dice_4: 3.75  loss_ce_5: 3.494  loss_mask_5: 0.65  loss_dice_5: 3.749  loss_ce_6: 3.493  loss_mask_6: 0.6506  loss_dice_6: 3.738  loss_ce_7: 3.488  loss_mask_7: 0.6525  loss_dice_7: 3.742  loss_ce_8: 3.487  loss_mask_8: 0.6533  loss_dice_8: 3.738  time: 1.7132  data_time: 0.3452  lr: 9.6079e-06  max_mem: 16700M
[01/19 01:33:24] d2.utils.events INFO:  eta: 18:03:42  iter: 1759  total_loss: 80.69  loss_ce: 3.368  loss_mask: 0.6397  loss_dice: 3.755  loss_ce_0: 5.471  loss_mask_0: 0.6566  loss_dice_0: 3.954  loss_ce_1: 3.616  loss_mask_1: 0.6413  loss_dice_1: 3.875  loss_ce_2: 3.445  loss_mask_2: 0.6377  loss_dice_2: 3.82  loss_ce_3: 3.367  loss_mask_3: 0.637  loss_dice_3: 3.778  loss_ce_4: 3.367  loss_mask_4: 0.6363  loss_dice_4: 3.77  loss_ce_5: 3.355  loss_mask_5: 0.6396  loss_dice_5: 3.768  loss_ce_6: 3.367  loss_mask_6: 0.6388  loss_dice_6: 3.753  loss_ce_7: 3.355  loss_mask_7: 0.6399  loss_dice_7: 3.757  loss_ce_8: 3.358  loss_mask_8: 0.6407  loss_dice_8: 3.758  time: 1.7133  data_time: 0.3516  lr: 9.6033e-06  max_mem: 16700M
[01/19 01:33:58] d2.utils.events INFO:  eta: 18:02:55  iter: 1779  total_loss: 80.74  loss_ce: 3.462  loss_mask: 0.6423  loss_dice: 3.742  loss_ce_0: 5.44  loss_mask_0: 0.6593  loss_dice_0: 3.951  loss_ce_1: 3.646  loss_mask_1: 0.6471  loss_dice_1: 3.855  loss_ce_2: 3.48  loss_mask_2: 0.6463  loss_dice_2: 3.8  loss_ce_3: 3.426  loss_mask_3: 0.6431  loss_dice_3: 3.761  loss_ce_4: 3.441  loss_mask_4: 0.6435  loss_dice_4: 3.762  loss_ce_5: 3.402  loss_mask_5: 0.6397  loss_dice_5: 3.754  loss_ce_6: 3.419  loss_mask_6: 0.6406  loss_dice_6: 3.747  loss_ce_7: 3.431  loss_mask_7: 0.6408  loss_dice_7: 3.749  loss_ce_8: 3.426  loss_mask_8: 0.6408  loss_dice_8: 3.751  time: 1.7130  data_time: 0.3456  lr: 9.5988e-06  max_mem: 16700M
[01/19 01:34:32] d2.utils.events INFO:  eta: 18:02:09  iter: 1799  total_loss: 81.31  loss_ce: 3.555  loss_mask: 0.6414  loss_dice: 3.694  loss_ce_0: 5.36  loss_mask_0: 0.6609  loss_dice_0: 3.93  loss_ce_1: 3.679  loss_mask_1: 0.6514  loss_dice_1: 3.82  loss_ce_2: 3.554  loss_mask_2: 0.646  loss_dice_2: 3.754  loss_ce_3: 3.503  loss_mask_3: 0.6477  loss_dice_3: 3.72  loss_ce_4: 3.484  loss_mask_4: 0.649  loss_dice_4: 3.716  loss_ce_5: 3.497  loss_mask_5: 0.6476  loss_dice_5: 3.706  loss_ce_6: 3.507  loss_mask_6: 0.6425  loss_dice_6: 3.703  loss_ce_7: 3.52  loss_mask_7: 0.6479  loss_dice_7: 3.7  loss_ce_8: 3.547  loss_mask_8: 0.6451  loss_dice_8: 3.693  time: 1.7129  data_time: 0.3539  lr: 9.5943e-06  max_mem: 16700M
[01/19 01:35:06] d2.utils.events INFO:  eta: 18:01:19  iter: 1819  total_loss: 79.87  loss_ce: 3.416  loss_mask: 0.6313  loss_dice: 3.734  loss_ce_0: 5.333  loss_mask_0: 0.6472  loss_dice_0: 3.951  loss_ce_1: 3.495  loss_mask_1: 0.633  loss_dice_1: 3.858  loss_ce_2: 3.416  loss_mask_2: 0.6366  loss_dice_2: 3.792  loss_ce_3: 3.402  loss_mask_3: 0.6333  loss_dice_3: 3.757  loss_ce_4: 3.368  loss_mask_4: 0.6329  loss_dice_4: 3.753  loss_ce_5: 3.355  loss_mask_5: 0.6307  loss_dice_5: 3.748  loss_ce_6: 3.374  loss_mask_6: 0.6311  loss_dice_6: 3.747  loss_ce_7: 3.365  loss_mask_7: 0.6292  loss_dice_7: 3.75  loss_ce_8: 3.365  loss_mask_8: 0.6303  loss_dice_8: 3.746  time: 1.7127  data_time: 0.3515  lr: 9.5898e-06  max_mem: 16700M
[01/19 01:35:40] d2.utils.events INFO:  eta: 18:00:41  iter: 1839  total_loss: 80.81  loss_ce: 3.481  loss_mask: 0.6488  loss_dice: 3.693  loss_ce_0: 5.353  loss_mask_0: 0.6743  loss_dice_0: 3.931  loss_ce_1: 3.728  loss_mask_1: 0.6588  loss_dice_1: 3.816  loss_ce_2: 3.524  loss_mask_2: 0.658  loss_dice_2: 3.757  loss_ce_3: 3.466  loss_mask_3: 0.6531  loss_dice_3: 3.723  loss_ce_4: 3.428  loss_mask_4: 0.6518  loss_dice_4: 3.721  loss_ce_5: 3.431  loss_mask_5: 0.6529  loss_dice_5: 3.71  loss_ce_6: 3.429  loss_mask_6: 0.652  loss_dice_6: 3.696  loss_ce_7: 3.441  loss_mask_7: 0.6502  loss_dice_7: 3.71  loss_ce_8: 3.46  loss_mask_8: 0.6523  loss_dice_8: 3.707  time: 1.7124  data_time: 0.3327  lr: 9.5853e-06  max_mem: 16700M
[01/19 01:36:15] d2.utils.events INFO:  eta: 18:00:45  iter: 1859  total_loss: 79.74  loss_ce: 3.336  loss_mask: 0.6392  loss_dice: 3.734  loss_ce_0: 5.332  loss_mask_0: 0.6484  loss_dice_0: 3.981  loss_ce_1: 3.531  loss_mask_1: 0.638  loss_dice_1: 3.876  loss_ce_2: 3.399  loss_mask_2: 0.6365  loss_dice_2: 3.812  loss_ce_3: 3.332  loss_mask_3: 0.6376  loss_dice_3: 3.776  loss_ce_4: 3.266  loss_mask_4: 0.6375  loss_dice_4: 3.768  loss_ce_5: 3.268  loss_mask_5: 0.6359  loss_dice_5: 3.76  loss_ce_6: 3.285  loss_mask_6: 0.6368  loss_dice_6: 3.752  loss_ce_7: 3.264  loss_mask_7: 0.6382  loss_dice_7: 3.752  loss_ce_8: 3.291  loss_mask_8: 0.6372  loss_dice_8: 3.745  time: 1.7125  data_time: 0.3492  lr: 9.5807e-06  max_mem: 16700M
[01/19 01:36:49] d2.utils.events INFO:  eta: 18:00:18  iter: 1879  total_loss: 80.27  loss_ce: 3.4  loss_mask: 0.6193  loss_dice: 3.745  loss_ce_0: 5.312  loss_mask_0: 0.6416  loss_dice_0: 3.956  loss_ce_1: 3.437  loss_mask_1: 0.6279  loss_dice_1: 3.87  loss_ce_2: 3.342  loss_mask_2: 0.6284  loss_dice_2: 3.815  loss_ce_3: 3.333  loss_mask_3: 0.6269  loss_dice_3: 3.772  loss_ce_4: 3.328  loss_mask_4: 0.6239  loss_dice_4: 3.767  loss_ce_5: 3.333  loss_mask_5: 0.6264  loss_dice_5: 3.758  loss_ce_6: 3.355  loss_mask_6: 0.6236  loss_dice_6: 3.746  loss_ce_7: 3.364  loss_mask_7: 0.6243  loss_dice_7: 3.747  loss_ce_8: 3.371  loss_mask_8: 0.6232  loss_dice_8: 3.749  time: 1.7124  data_time: 0.3427  lr: 9.5762e-06  max_mem: 16700M
[01/19 01:37:23] d2.utils.events INFO:  eta: 17:59:37  iter: 1899  total_loss: 79.83  loss_ce: 3.366  loss_mask: 0.6376  loss_dice: 3.734  loss_ce_0: 5.294  loss_mask_0: 0.661  loss_dice_0: 3.95  loss_ce_1: 3.571  loss_mask_1: 0.6453  loss_dice_1: 3.852  loss_ce_2: 3.395  loss_mask_2: 0.6451  loss_dice_2: 3.792  loss_ce_3: 3.354  loss_mask_3: 0.6429  loss_dice_3: 3.764  loss_ce_4: 3.342  loss_mask_4: 0.6423  loss_dice_4: 3.752  loss_ce_5: 3.336  loss_mask_5: 0.6435  loss_dice_5: 3.75  loss_ce_6: 3.325  loss_mask_6: 0.6437  loss_dice_6: 3.741  loss_ce_7: 3.327  loss_mask_7: 0.6395  loss_dice_7: 3.747  loss_ce_8: 3.349  loss_mask_8: 0.6407  loss_dice_8: 3.742  time: 1.7122  data_time: 0.3319  lr: 9.5717e-06  max_mem: 16700M
[01/19 01:37:57] d2.utils.events INFO:  eta: 17:58:37  iter: 1919  total_loss: 80.56  loss_ce: 3.451  loss_mask: 0.6363  loss_dice: 3.759  loss_ce_0: 5.251  loss_mask_0: 0.6408  loss_dice_0: 3.978  loss_ce_1: 3.59  loss_mask_1: 0.6308  loss_dice_1: 3.894  loss_ce_2: 3.457  loss_mask_2: 0.6364  loss_dice_2: 3.834  loss_ce_3: 3.444  loss_mask_3: 0.6373  loss_dice_3: 3.786  loss_ce_4: 3.417  loss_mask_4: 0.6364  loss_dice_4: 3.789  loss_ce_5: 3.427  loss_mask_5: 0.636  loss_dice_5: 3.793  loss_ce_6: 3.421  loss_mask_6: 0.6386  loss_dice_6: 3.778  loss_ce_7: 3.44  loss_mask_7: 0.6345  loss_dice_7: 3.775  loss_ce_8: 3.438  loss_mask_8: 0.6344  loss_dice_8: 3.771  time: 1.7121  data_time: 0.3565  lr: 9.5672e-06  max_mem: 16700M
[01/19 01:38:31] d2.utils.events INFO:  eta: 17:58:29  iter: 1939  total_loss: 79.81  loss_ce: 3.39  loss_mask: 0.6393  loss_dice: 3.758  loss_ce_0: 5.185  loss_mask_0: 0.6447  loss_dice_0: 3.985  loss_ce_1: 3.51  loss_mask_1: 0.6392  loss_dice_1: 3.87  loss_ce_2: 3.387  loss_mask_2: 0.6409  loss_dice_2: 3.814  loss_ce_3: 3.402  loss_mask_3: 0.6436  loss_dice_3: 3.772  loss_ce_4: 3.37  loss_mask_4: 0.6436  loss_dice_4: 3.765  loss_ce_5: 3.374  loss_mask_5: 0.6452  loss_dice_5: 3.765  loss_ce_6: 3.366  loss_mask_6: 0.6417  loss_dice_6: 3.758  loss_ce_7: 3.353  loss_mask_7: 0.642  loss_dice_7: 3.754  loss_ce_8: 3.357  loss_mask_8: 0.644  loss_dice_8: 3.759  time: 1.7120  data_time: 0.3461  lr: 9.5626e-06  max_mem: 16700M
[01/19 01:39:05] d2.utils.events INFO:  eta: 17:58:15  iter: 1959  total_loss: 79.98  loss_ce: 3.423  loss_mask: 0.6504  loss_dice: 3.737  loss_ce_0: 5.212  loss_mask_0: 0.6611  loss_dice_0: 3.956  loss_ce_1: 3.614  loss_mask_1: 0.6592  loss_dice_1: 3.841  loss_ce_2: 3.459  loss_mask_2: 0.6582  loss_dice_2: 3.781  loss_ce_3: 3.415  loss_mask_3: 0.6527  loss_dice_3: 3.756  loss_ce_4: 3.407  loss_mask_4: 0.6507  loss_dice_4: 3.747  loss_ce_5: 3.4  loss_mask_5: 0.6534  loss_dice_5: 3.748  loss_ce_6: 3.41  loss_mask_6: 0.653  loss_dice_6: 3.742  loss_ce_7: 3.411  loss_mask_7: 0.6548  loss_dice_7: 3.739  loss_ce_8: 3.423  loss_mask_8: 0.6519  loss_dice_8: 3.743  time: 1.7120  data_time: 0.3669  lr: 9.5581e-06  max_mem: 16700M
[01/19 01:39:39] d2.utils.events INFO:  eta: 17:56:43  iter: 1979  total_loss: 79.13  loss_ce: 3.261  loss_mask: 0.6382  loss_dice: 3.725  loss_ce_0: 5.143  loss_mask_0: 0.6468  loss_dice_0: 3.951  loss_ce_1: 3.43  loss_mask_1: 0.6366  loss_dice_1: 3.853  loss_ce_2: 3.303  loss_mask_2: 0.6332  loss_dice_2: 3.797  loss_ce_3: 3.243  loss_mask_3: 0.6329  loss_dice_3: 3.762  loss_ce_4: 3.231  loss_mask_4: 0.6349  loss_dice_4: 3.747  loss_ce_5: 3.222  loss_mask_5: 0.633  loss_dice_5: 3.736  loss_ce_6: 3.243  loss_mask_6: 0.634  loss_dice_6: 3.737  loss_ce_7: 3.224  loss_mask_7: 0.6364  loss_dice_7: 3.734  loss_ce_8: 3.234  loss_mask_8: 0.6406  loss_dice_8: 3.725  time: 1.7119  data_time: 0.3472  lr: 9.5536e-06  max_mem: 16700M
[01/19 01:40:13] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 01:40:14] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 01:40:14] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 01:44:59] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 8.060820649033351, 'error_1pix': 0.7294322934722054, 'error_3pix': 0.545026022153771, 'mIoU': 1.9182522175051575, 'fwIoU': 11.344144537871049, 'IoU-0': nan, 'IoU-1': 89.5896741325965, 'IoU-2': 3.15509942181212, 'IoU-3': 20.390950127397524, 'IoU-4': 13.93214053577232, 'IoU-5': 3.512470750406995, 'IoU-6': 10.84679213304615, 'IoU-7': 3.8655306210834266, 'IoU-8': 0.06720594677397851, 'IoU-9': 0.24007698484588758, 'IoU-10': 1.687829752282955, 'IoU-11': 0.24635684375330216, 'IoU-12': 13.828516293022282, 'IoU-13': 5.490935729951439, 'IoU-14': 1.4945464153607864, 'IoU-15': 6.323381605378165, 'IoU-16': 4.155089170659426, 'IoU-17': 5.488282509663142, 'IoU-18': 3.1051917864429854, 'IoU-19': 4.592335146173452, 'IoU-20': 0.1256682169252987, 'IoU-21': 4.363403075819292, 'IoU-22': 0.47235937500834485, 'IoU-23': 1.9506234995244724, 'IoU-24': 3.039939064409437, 'IoU-25': 1.3865086360433705, 'IoU-26': 4.78260522690379, 'IoU-27': 2.9248685262304566, 'IoU-28': 0.26067020559764653, 'IoU-29': 5.899962251709424, 'IoU-30': 0.6694502211475315, 'IoU-31': 1.6344470299193254, 'IoU-32': 2.689493806532998, 'IoU-33': 2.61065250760932, 'IoU-34': 4.134812834851522, 'IoU-35': 0.02654015263138375, 'IoU-36': 0.7899452575164825, 'IoU-37': 4.682213783148028, 'IoU-38': 1.409910034472652, 'IoU-39': 1.1756759415777382, 'IoU-40': 3.7235064916512517, 'IoU-41': 2.5449310239887906, 'IoU-42': 1.4328741252780397, 'IoU-43': 0.15803850480889506, 'IoU-44': 2.426584846858698, 'IoU-45': 3.365138215797256, 'IoU-46': 1.4347468421210863, 'IoU-47': 0.395982695243822, 'IoU-48': 0.02420095237143923, 'IoU-49': 0.5942898896882399, 'IoU-50': 2.5534296686757507, 'IoU-51': 3.066241548603384, 'IoU-52': 0.7363912742471609, 'IoU-53': 0.24164737046715212, 'IoU-54': 1.0600657029433989, 'IoU-55': 3.784731837555101, 'IoU-56': 0.8621625164011709, 'IoU-57': 0.4371188963513412, 'IoU-58': 0.22046683546527332, 'IoU-59': 0.18661943818228444, 'IoU-60': 0.40965523428684764, 'IoU-61': 0.7759371255919244, 'IoU-62': 3.585734340409167, 'IoU-63': 0.47600648847245286, 'IoU-64': 1.7186152817006095, 'IoU-65': 0.5320843913172378, 'IoU-66': 2.6868311509901184, 'IoU-67': 1.185022743800561, 'IoU-68': 0.9810554855702897, 'IoU-69': 0.9716834696146757, 'IoU-70': 1.2432506293407195, 'IoU-71': 0.6662030360629895, 'IoU-72': 1.2584395613871204, 'IoU-73': 3.1668239716122244, 'IoU-74': 2.1800853271483045, 'IoU-75': 0.8103078560051722, 'IoU-76': 0.4895216195783517, 'IoU-77': 0.45113050903850804, 'IoU-78': 0.2565279344891787, 'IoU-79': 1.1985117446844338, 'IoU-80': 3.3944880348756077, 'IoU-81': 0.2534591985086346, 'IoU-82': 1.459853505897377, 'IoU-83': 0.4395596886028262, 'IoU-84': 2.9480748222644064, 'IoU-85': 2.0576602971732996, 'IoU-86': 0.9000597132422501, 'IoU-87': 0.8322305742357119, 'IoU-88': 0.5533005515682886, 'IoU-89': 0.7965093473810695, 'IoU-90': 0.7318055662779347, 'IoU-91': 1.737662483350872, 'IoU-92': 3.2569422073650482, 'IoU-93': 1.5244478439097269, 'IoU-94': 0.43391791719399747, 'IoU-95': 0.31552317861725643, 'IoU-96': 0.892535119054456, 'IoU-97': 1.039184660262118, 'IoU-98': 1.0235361429147523, 'IoU-99': 1.4428106540772045, 'IoU-100': 1.4912107976995477, 'IoU-101': 1.1778486555655463, 'IoU-102': 0.5267496427727006, 'IoU-103': 1.739315282024638, 'IoU-104': 0.5202318395388307, 'IoU-105': 0.5398603669426855, 'IoU-106': 1.4504090140153756, 'IoU-107': 0.6898179405354297, 'IoU-108': 1.0009163229477984, 'IoU-109': 2.258560057604871, 'IoU-110': 0.7883712449175913, 'IoU-111': 0.2564467580393697, 'IoU-112': 1.777115406597819, 'IoU-113': 1.081255717990112, 'IoU-114': 0.2011941277595645, 'IoU-115': 0.9206499859962695, 'IoU-116': 0.11532351514050414, 'IoU-117': 1.1195140806313881, 'IoU-118': 0.8075778289779383, 'IoU-119': 0.30811464662004373, 'IoU-120': 1.6554286599487464, 'IoU-121': 1.507172969241437, 'IoU-122': 1.7134895516714845, 'IoU-123': 1.0560161774478514, 'IoU-124': 0.6783881329897258, 'IoU-125': 0.6797637730444784, 'IoU-126': 0.008729579727421707, 'IoU-127': 0.6614911073348473, 'IoU-128': 0.31919643563980205, 'IoU-129': 1.4795239988941014, 'IoU-130': 1.0012683623794734, 'IoU-131': 0.7888456442710792, 'IoU-132': 0.7664888631676381, 'IoU-133': 0.861607964265721, 'IoU-134': 0.7848328834608731, 'IoU-135': 0.5994057943715715, 'IoU-136': 0.03944657910500095, 'IoU-137': 0.28068874924237136, 'IoU-138': 0.013294795951171293, 'IoU-139': 0.6057493069433622, 'IoU-140': 0.6467445612566166, 'IoU-141': 0.22509385805199555, 'IoU-142': 0.5006462899929353, 'IoU-143': 0.31248993665978847, 'IoU-144': 0.38542910408680536, 'IoU-145': 0.4275841587833866, 'IoU-146': 1.393614561846266, 'IoU-147': 0.26750160040518844, 'IoU-148': 0.7354636652982832, 'IoU-149': 0.16948964871431463, 'IoU-150': 0.6512220427950784, 'IoU-151': 0.4694732693069707, 'IoU-152': 0.5809675812732048, 'IoU-153': 0.037800348420602835, 'IoU-154': 0.7980116093907585, 'IoU-155': 0.9414512972711451, 'IoU-156': 0.0111015065714452, 'IoU-157': 0.21876196230903805, 'IoU-158': 0.2126215103012643, 'IoU-159': 0.01008525150251571, 'IoU-160': 0.7284420573744744, 'IoU-161': 0.0, 'IoU-162': 0.7275781813680702, 'IoU-163': 0.6573792790090087, 'IoU-164': 0.01748812265003352, 'IoU-165': 0.00047013322008346433, 'IoU-166': 0.024536421948387076, 'IoU-167': 0.3748945160305709, 'IoU-168': 0.10211762783668182, 'IoU-169': 0.005468646427151001, 'IoU-170': 0.05728364464266404, 'IoU-171': 0.2130077034279264, 'IoU-172': 0.00864246306669865, 'IoU-173': 0.25550860549426857, 'IoU-174': 0.0, 'IoU-175': 0.33462301556910934, 'IoU-176': 0.0008985016586340618, 'IoU-177': 0.03640296499511989, 'IoU-178': 0.22957917379074513, 'IoU-179': 0.0498706240924985, 'IoU-180': 0.06915585844424466, 'IoU-181': 0.39995376257080106, 'IoU-182': 0.0431315758892256, 'IoU-183': 0.0, 'IoU-184': 0.06976328185558404, 'IoU-185': 0.5604347730758708, 'IoU-186': 1.1317321143415686, 'IoU-187': 0.03480009280024747, 'IoU-188': 0.04897220209195397, 'IoU-189': 0.17117197225680242, 'IoU-190': 0.2458755970662218, 'IoU-191': 0.005794793755731807, 'IoU-192': 1.0642680900114343, 'mACC': 4.13359636409781, 'pACC': 15.816405002963718, 'ACC-0': nan, 'ACC-1': 97.80216506965438, 'ACC-2': 3.345691777012555, 'ACC-3': 36.23712019151891, 'ACC-4': 25.75358336786293, 'ACC-5': 6.820244206911463, 'ACC-6': 26.489513432223195, 'ACC-7': 4.7841211153286585, 'ACC-8': 0.0685679133257159, 'ACC-9': 0.248085460993565, 'ACC-10': 1.8447665987973032, 'ACC-11': 0.2480782887830515, 'ACC-12': 54.814415822643184, 'ACC-13': 10.679018550367209, 'ACC-14': 1.8088814583067052, 'ACC-15': 14.197759485501996, 'ACC-16': 8.673582815413996, 'ACC-17': 18.087532395893643, 'ACC-18': 4.580588056473073, 'ACC-19': 9.848403624714251, 'ACC-20': 0.12801955691487893, 'ACC-21': 10.579722429643933, 'ACC-22': 0.5172003448781987, 'ACC-23': 2.6572649071432637, 'ACC-24': 5.588466553628512, 'ACC-25': 1.8604979244988988, 'ACC-26': 15.458623523517664, 'ACC-27': 5.832513568066738, 'ACC-28': 0.27426086587134685, 'ACC-29': 42.08972223567866, 'ACC-30': 0.7307072766249211, 'ACC-31': 2.2652532663774627, 'ACC-32': 5.084217653568934, 'ACC-33': 4.373207165507833, 'ACC-34': 15.234790754957443, 'ACC-35': 0.026684748159604903, 'ACC-36': 0.8648714059509344, 'ACC-37': 16.717758334350506, 'ACC-38': 2.331027074806513, 'ACC-39': 1.5678431037152694, 'ACC-40': 8.174138188933243, 'ACC-41': 4.731347562666787, 'ACC-42': 1.864153874744813, 'ACC-43': 0.1624452112849016, 'ACC-44': 4.77477137053776, 'ACC-45': 9.428043165476883, 'ACC-46': 2.034629558375394, 'ACC-47': 0.4438690381430278, 'ACC-48': 0.0244382001097507, 'ACC-49': 0.6544929129404518, 'ACC-50': 4.597396769966322, 'ACC-51': 6.6623166738462665, 'ACC-52': 0.8412735410260324, 'ACC-53': 0.25666455255525866, 'ACC-54': 1.3640978380306559, 'ACC-55': 11.894995626435197, 'ACC-56': 1.011177981183844, 'ACC-57': 0.49110231377031477, 'ACC-58': 0.23089868386018544, 'ACC-59': 0.19543328353379472, 'ACC-60': 0.43108497546783825, 'ACC-61': 0.985811025578016, 'ACC-62': 16.06185985084012, 'ACC-63': 0.5105106933051189, 'ACC-64': 3.5179932045207973, 'ACC-65': 0.6263258035686465, 'ACC-66': 9.93730251170161, 'ACC-67': 1.6777044371646954, 'ACC-68': 1.3792462170240578, 'ACC-69': 1.2753257348052476, 'ACC-70': 2.2508757088592635, 'ACC-71': 0.7917495218883878, 'ACC-72': 1.950337076049025, 'ACC-73': 12.088692101765735, 'ACC-74': 3.697803783258628, 'ACC-75': 1.021557452505572, 'ACC-76': 0.544627353097296, 'ACC-77': 0.5204090788913223, 'ACC-78': 0.2839539613019555, 'ACC-79': 2.1595135647912542, 'ACC-80': 11.45412519043249, 'ACC-81': 0.2818894270135632, 'ACC-82': 2.3568015132350686, 'ACC-83': 0.5154323072729801, 'ACC-84': 12.156951566250385, 'ACC-85': 4.401862634954008, 'ACC-86': 1.2408135483079141, 'ACC-87': 1.1733144821956583, 'ACC-88': 0.7065466164164251, 'ACC-89': 1.0844336314855276, 'ACC-90': 0.997746888684629, 'ACC-91': 4.519158360777715, 'ACC-92': 15.350124473881529, 'ACC-93': 2.3762539019736706, 'ACC-94': 0.5371596225285913, 'ACC-95': 0.3518442152051349, 'ACC-96': 1.2940332253709448, 'ACC-97': 1.6662531979621384, 'ACC-98': 1.4245742028766253, 'ACC-99': 2.317539939232047, 'ACC-100': 3.374678769035646, 'ACC-101': 3.229141411796668, 'ACC-102': 0.7429542365201631, 'ACC-103': 4.167587607443091, 'ACC-104': 0.6974004574407909, 'ACC-105': 0.7744503902515891, 'ACC-106': 4.128503276616957, 'ACC-107': 1.032569438098595, 'ACC-108': 1.5326272990998575, 'ACC-109': 12.278254755961518, 'ACC-110': 1.9553356062278073, 'ACC-111': 0.3522851525957878, 'ACC-112': 3.703707411018332, 'ACC-113': 2.572974697481192, 'ACC-114': 0.2834551203955398, 'ACC-115': 2.4055823673567573, 'ACC-116': 0.1636558291187896, 'ACC-117': 3.070133493848482, 'ACC-118': 1.6156127332737957, 'ACC-119': 0.46299930046145527, 'ACC-120': 8.29894018139203, 'ACC-121': 4.44062504684036, 'ACC-122': 6.809514374404409, 'ACC-123': 2.480860285511843, 'ACC-124': 1.30744163473356, 'ACC-125': 1.1853859683280705, 'ACC-126': 0.008766017905445404, 'ACC-127': 1.8304535132558943, 'ACC-128': 0.4917726868571554, 'ACC-129': 5.913681263134907, 'ACC-130': 2.4152377316242006, 'ACC-131': 1.686833303095009, 'ACC-132': 1.812588593660464, 'ACC-133': 2.9950941367790045, 'ACC-134': 1.7009220163722534, 'ACC-135': 1.1089020010261674, 'ACC-136': 0.041275507827059264, 'ACC-137': 0.3803186800354445, 'ACC-138': 0.014039774602127065, 'ACC-139': 1.6455790639580308, 'ACC-140': 1.7427077276800726, 'ACC-141': 0.3205478852591734, 'ACC-142': 0.6937621663824023, 'ACC-143': 0.45342915910726755, 'ACC-144': 0.7472924187725631, 'ACC-145': 0.6181712471209105, 'ACC-146': 10.80267757190834, 'ACC-147': 0.3344528186610188, 'ACC-148': 3.019625474430422, 'ACC-149': 0.21732759066556195, 'ACC-150': 1.1945895858804745, 'ACC-151': 1.436986495545587, 'ACC-152': 1.0816010857104323, 'ACC-153': 0.039506953223767384, 'ACC-154': 1.1362422167349446, 'ACC-155': 2.5710996566115223, 'ACC-156': 0.013315493158034219, 'ACC-157': 0.3764632866633185, 'ACC-158': 0.21790950827816202, 'ACC-159': 0.011483269868183403, 'ACC-160': 2.9311631905171245, 'ACC-161': 0.0, 'ACC-162': 2.6582783151493152, 'ACC-163': 1.035056797423288, 'ACC-164': 0.018074638745049294, 'ACC-165': 0.0004764521467345558, 'ACC-166': 0.029547305067530703, 'ACC-167': 0.5440645373106328, 'ACC-168': 0.12307475912511429, 'ACC-169': 0.005790560684198613, 'ACC-170': 0.06956571120291892, 'ACC-171': 0.3161226210441047, 'ACC-172': 0.009075082416564803, 'ACC-173': 0.4325445056123543, 'ACC-174': 0.0, 'ACC-175': 0.6058656372312476, 'ACC-176': 0.0009069537961458091, 'ACC-177': 0.03820111502964739, 'ACC-178': 0.25728640110022777, 'ACC-179': 0.05275106973082753, 'ACC-180': 0.09312878864844729, 'ACC-181': 0.8605313834587535, 'ACC-182': 0.04572495374198333, 'ACC-183': 0.0, 'ACC-184': 0.08277969987052405, 'ACC-185': 1.3578057083731736, 'ACC-186': 9.096274193662612, 'ACC-187': 0.04348929076214982, 'ACC-188': 0.04993745208022275, 'ACC-189': 0.21744655615486713, 'ACC-190': 0.955018497751973, 'ACC-191': 0.00600326264274062, 'ACC-192': 1.301182043800991})])
[01/19 01:44:59] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 01:44:59] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 01:44:59] d2.evaluation.testing INFO: copypaste: 8.0608,0.7294,0.5450,1.9183,11.3441,4.1336,15.8164
[01/19 01:45:00] d2.utils.events INFO:  eta: 17:56:09  iter: 1999  total_loss: 79.5  loss_ce: 3.349  loss_mask: 0.6445  loss_dice: 3.72  loss_ce_0: 5.147  loss_mask_0: 0.6556  loss_dice_0: 3.949  loss_ce_1: 3.555  loss_mask_1: 0.6428  loss_dice_1: 3.856  loss_ce_2: 3.406  loss_mask_2: 0.6458  loss_dice_2: 3.788  loss_ce_3: 3.331  loss_mask_3: 0.6481  loss_dice_3: 3.751  loss_ce_4: 3.314  loss_mask_4: 0.645  loss_dice_4: 3.751  loss_ce_5: 3.303  loss_mask_5: 0.6458  loss_dice_5: 3.741  loss_ce_6: 3.308  loss_mask_6: 0.6458  loss_dice_6: 3.731  loss_ce_7: 3.298  loss_mask_7: 0.6428  loss_dice_7: 3.73  loss_ce_8: 3.303  loss_mask_8: 0.645  loss_dice_8: 3.729  time: 1.7119  data_time: 0.3740  lr: 9.5491e-06  max_mem: 16700M
[01/19 01:45:34] d2.utils.events INFO:  eta: 17:55:39  iter: 2019  total_loss: 79.65  loss_ce: 3.407  loss_mask: 0.633  loss_dice: 3.723  loss_ce_0: 5.158  loss_mask_0: 0.6428  loss_dice_0: 3.958  loss_ce_1: 3.551  loss_mask_1: 0.6401  loss_dice_1: 3.848  loss_ce_2: 3.406  loss_mask_2: 0.6393  loss_dice_2: 3.786  loss_ce_3: 3.384  loss_mask_3: 0.639  loss_dice_3: 3.745  loss_ce_4: 3.372  loss_mask_4: 0.6407  loss_dice_4: 3.745  loss_ce_5: 3.388  loss_mask_5: 0.639  loss_dice_5: 3.738  loss_ce_6: 3.386  loss_mask_6: 0.6378  loss_dice_6: 3.73  loss_ce_7: 3.39  loss_mask_7: 0.6372  loss_dice_7: 3.726  loss_ce_8: 3.382  loss_mask_8: 0.6356  loss_dice_8: 3.723  time: 1.7118  data_time: 0.3414  lr: 9.5446e-06  max_mem: 16700M
[01/19 01:46:08] d2.utils.events INFO:  eta: 17:55:24  iter: 2039  total_loss: 79.27  loss_ce: 3.412  loss_mask: 0.6258  loss_dice: 3.727  loss_ce_0: 5.064  loss_mask_0: 0.6268  loss_dice_0: 3.963  loss_ce_1: 3.578  loss_mask_1: 0.6321  loss_dice_1: 3.851  loss_ce_2: 3.439  loss_mask_2: 0.6358  loss_dice_2: 3.793  loss_ce_3: 3.402  loss_mask_3: 0.6313  loss_dice_3: 3.752  loss_ce_4: 3.359  loss_mask_4: 0.6286  loss_dice_4: 3.747  loss_ce_5: 3.382  loss_mask_5: 0.6297  loss_dice_5: 3.741  loss_ce_6: 3.376  loss_mask_6: 0.6271  loss_dice_6: 3.729  loss_ce_7: 3.374  loss_mask_7: 0.6256  loss_dice_7: 3.729  loss_ce_8: 3.407  loss_mask_8: 0.6246  loss_dice_8: 3.73  time: 1.7118  data_time: 0.3540  lr: 9.54e-06  max_mem: 16700M
[01/19 01:46:42] d2.utils.events INFO:  eta: 17:55:05  iter: 2059  total_loss: 79.59  loss_ce: 3.347  loss_mask: 0.6279  loss_dice: 3.732  loss_ce_0: 5.09  loss_mask_0: 0.6354  loss_dice_0: 3.963  loss_ce_1: 3.533  loss_mask_1: 0.6321  loss_dice_1: 3.851  loss_ce_2: 3.379  loss_mask_2: 0.6327  loss_dice_2: 3.8  loss_ce_3: 3.352  loss_mask_3: 0.6309  loss_dice_3: 3.76  loss_ce_4: 3.308  loss_mask_4: 0.6302  loss_dice_4: 3.756  loss_ce_5: 3.354  loss_mask_5: 0.6288  loss_dice_5: 3.748  loss_ce_6: 3.353  loss_mask_6: 0.6273  loss_dice_6: 3.74  loss_ce_7: 3.33  loss_mask_7: 0.6305  loss_dice_7: 3.738  loss_ce_8: 3.335  loss_mask_8: 0.6324  loss_dice_8: 3.736  time: 1.7117  data_time: 0.3629  lr: 9.5355e-06  max_mem: 16700M
[01/19 01:47:16] d2.utils.events INFO:  eta: 17:54:37  iter: 2079  total_loss: 79  loss_ce: 3.276  loss_mask: 0.6531  loss_dice: 3.736  loss_ce_0: 5.132  loss_mask_0: 0.6603  loss_dice_0: 3.947  loss_ce_1: 3.502  loss_mask_1: 0.6527  loss_dice_1: 3.853  loss_ce_2: 3.355  loss_mask_2: 0.6499  loss_dice_2: 3.802  loss_ce_3: 3.278  loss_mask_3: 0.6471  loss_dice_3: 3.761  loss_ce_4: 3.245  loss_mask_4: 0.6493  loss_dice_4: 3.75  loss_ce_5: 3.239  loss_mask_5: 0.6515  loss_dice_5: 3.756  loss_ce_6: 3.234  loss_mask_6: 0.6547  loss_dice_6: 3.735  loss_ce_7: 3.245  loss_mask_7: 0.6517  loss_dice_7: 3.736  loss_ce_8: 3.255  loss_mask_8: 0.6493  loss_dice_8: 3.735  time: 1.7118  data_time: 0.3649  lr: 9.531e-06  max_mem: 16700M
[01/19 01:47:51] d2.utils.events INFO:  eta: 17:54:01  iter: 2099  total_loss: 78.39  loss_ce: 3.239  loss_mask: 0.6324  loss_dice: 3.772  loss_ce_0: 4.97  loss_mask_0: 0.6472  loss_dice_0: 3.98  loss_ce_1: 3.388  loss_mask_1: 0.6378  loss_dice_1: 3.885  loss_ce_2: 3.273  loss_mask_2: 0.6399  loss_dice_2: 3.825  loss_ce_3: 3.223  loss_mask_3: 0.6399  loss_dice_3: 3.793  loss_ce_4: 3.206  loss_mask_4: 0.6366  loss_dice_4: 3.789  loss_ce_5: 3.206  loss_mask_5: 0.6349  loss_dice_5: 3.783  loss_ce_6: 3.222  loss_mask_6: 0.6336  loss_dice_6: 3.772  loss_ce_7: 3.24  loss_mask_7: 0.6342  loss_dice_7: 3.769  loss_ce_8: 3.23  loss_mask_8: 0.6287  loss_dice_8: 3.776  time: 1.7117  data_time: 0.3517  lr: 9.5265e-06  max_mem: 16700M
[01/19 01:48:24] d2.utils.events INFO:  eta: 17:53:37  iter: 2119  total_loss: 78.96  loss_ce: 3.383  loss_mask: 0.6419  loss_dice: 3.715  loss_ce_0: 5.054  loss_mask_0: 0.6549  loss_dice_0: 3.953  loss_ce_1: 3.514  loss_mask_1: 0.6529  loss_dice_1: 3.831  loss_ce_2: 3.375  loss_mask_2: 0.6498  loss_dice_2: 3.774  loss_ce_3: 3.34  loss_mask_3: 0.6497  loss_dice_3: 3.733  loss_ce_4: 3.324  loss_mask_4: 0.6451  loss_dice_4: 3.73  loss_ce_5: 3.321  loss_mask_5: 0.6475  loss_dice_5: 3.723  loss_ce_6: 3.331  loss_mask_6: 0.647  loss_dice_6: 3.713  loss_ce_7: 3.325  loss_mask_7: 0.6473  loss_dice_7: 3.715  loss_ce_8: 3.335  loss_mask_8: 0.643  loss_dice_8: 3.717  time: 1.7115  data_time: 0.3423  lr: 9.5219e-06  max_mem: 16700M
[01/19 01:48:58] d2.utils.events INFO:  eta: 17:52:45  iter: 2139  total_loss: 78.7  loss_ce: 3.291  loss_mask: 0.6369  loss_dice: 3.723  loss_ce_0: 4.882  loss_mask_0: 0.6429  loss_dice_0: 3.975  loss_ce_1: 3.406  loss_mask_1: 0.6398  loss_dice_1: 3.853  loss_ce_2: 3.268  loss_mask_2: 0.6388  loss_dice_2: 3.793  loss_ce_3: 3.261  loss_mask_3: 0.6347  loss_dice_3: 3.75  loss_ce_4: 3.225  loss_mask_4: 0.6348  loss_dice_4: 3.738  loss_ce_5: 3.256  loss_mask_5: 0.6362  loss_dice_5: 3.734  loss_ce_6: 3.251  loss_mask_6: 0.6364  loss_dice_6: 3.729  loss_ce_7: 3.251  loss_mask_7: 0.6408  loss_dice_7: 3.729  loss_ce_8: 3.282  loss_mask_8: 0.6388  loss_dice_8: 3.724  time: 1.7113  data_time: 0.3473  lr: 9.5174e-06  max_mem: 16700M
[01/19 01:49:33] d2.utils.events INFO:  eta: 17:52:11  iter: 2159  total_loss: 78.27  loss_ce: 3.198  loss_mask: 0.6235  loss_dice: 3.769  loss_ce_0: 4.906  loss_mask_0: 0.6273  loss_dice_0: 4.002  loss_ce_1: 3.387  loss_mask_1: 0.6235  loss_dice_1: 3.899  loss_ce_2: 3.225  loss_mask_2: 0.6242  loss_dice_2: 3.839  loss_ce_3: 3.192  loss_mask_3: 0.6227  loss_dice_3: 3.795  loss_ce_4: 3.169  loss_mask_4: 0.6223  loss_dice_4: 3.794  loss_ce_5: 3.174  loss_mask_5: 0.6239  loss_dice_5: 3.789  loss_ce_6: 3.167  loss_mask_6: 0.622  loss_dice_6: 3.776  loss_ce_7: 3.175  loss_mask_7: 0.6236  loss_dice_7: 3.774  loss_ce_8: 3.176  loss_mask_8: 0.6217  loss_dice_8: 3.772  time: 1.7114  data_time: 0.3309  lr: 9.5129e-06  max_mem: 16700M
[01/19 01:50:08] d2.utils.events INFO:  eta: 17:51:57  iter: 2179  total_loss: 78.75  loss_ce: 3.279  loss_mask: 0.6273  loss_dice: 3.747  loss_ce_0: 4.971  loss_mask_0: 0.6476  loss_dice_0: 3.972  loss_ce_1: 3.433  loss_mask_1: 0.6386  loss_dice_1: 3.858  loss_ce_2: 3.313  loss_mask_2: 0.635  loss_dice_2: 3.809  loss_ce_3: 3.265  loss_mask_3: 0.6317  loss_dice_3: 3.761  loss_ce_4: 3.234  loss_mask_4: 0.6313  loss_dice_4: 3.761  loss_ce_5: 3.261  loss_mask_5: 0.6311  loss_dice_5: 3.761  loss_ce_6: 3.261  loss_mask_6: 0.6294  loss_dice_6: 3.752  loss_ce_7: 3.26  loss_mask_7: 0.6291  loss_dice_7: 3.755  loss_ce_8: 3.24  loss_mask_8: 0.6305  loss_dice_8: 3.745  time: 1.7116  data_time: 0.3701  lr: 9.5084e-06  max_mem: 16700M
[01/19 01:50:41] d2.utils.events INFO:  eta: 17:50:59  iter: 2199  total_loss: 79.62  loss_ce: 3.446  loss_mask: 0.6599  loss_dice: 3.668  loss_ce_0: 5.054  loss_mask_0: 0.6604  loss_dice_0: 3.916  loss_ce_1: 3.598  loss_mask_1: 0.6553  loss_dice_1: 3.821  loss_ce_2: 3.431  loss_mask_2: 0.6547  loss_dice_2: 3.751  loss_ce_3: 3.381  loss_mask_3: 0.6505  loss_dice_3: 3.716  loss_ce_4: 3.377  loss_mask_4: 0.6526  loss_dice_4: 3.708  loss_ce_5: 3.382  loss_mask_5: 0.6579  loss_dice_5: 3.689  loss_ce_6: 3.394  loss_mask_6: 0.6587  loss_dice_6: 3.679  loss_ce_7: 3.398  loss_mask_7: 0.6564  loss_dice_7: 3.678  loss_ce_8: 3.424  loss_mask_8: 0.6595  loss_dice_8: 3.67  time: 1.7114  data_time: 0.3482  lr: 9.5038e-06  max_mem: 16700M
[01/19 01:51:15] d2.utils.events INFO:  eta: 17:50:51  iter: 2219  total_loss: 78.38  loss_ce: 3.23  loss_mask: 0.6358  loss_dice: 3.781  loss_ce_0: 4.894  loss_mask_0: 0.6346  loss_dice_0: 3.992  loss_ce_1: 3.413  loss_mask_1: 0.6349  loss_dice_1: 3.889  loss_ce_2: 3.272  loss_mask_2: 0.6358  loss_dice_2: 3.832  loss_ce_3: 3.249  loss_mask_3: 0.6364  loss_dice_3: 3.797  loss_ce_4: 3.233  loss_mask_4: 0.6373  loss_dice_4: 3.792  loss_ce_5: 3.219  loss_mask_5: 0.641  loss_dice_5: 3.782  loss_ce_6: 3.225  loss_mask_6: 0.636  loss_dice_6: 3.777  loss_ce_7: 3.218  loss_mask_7: 0.6367  loss_dice_7: 3.78  loss_ce_8: 3.218  loss_mask_8: 0.6367  loss_dice_8: 3.771  time: 1.7113  data_time: 0.3499  lr: 9.4993e-06  max_mem: 16700M
[01/19 01:51:50] d2.utils.events INFO:  eta: 17:50:17  iter: 2239  total_loss: 77.91  loss_ce: 3.207  loss_mask: 0.6468  loss_dice: 3.753  loss_ce_0: 4.843  loss_mask_0: 0.6553  loss_dice_0: 3.987  loss_ce_1: 3.314  loss_mask_1: 0.6509  loss_dice_1: 3.882  loss_ce_2: 3.199  loss_mask_2: 0.6524  loss_dice_2: 3.815  loss_ce_3: 3.18  loss_mask_3: 0.6473  loss_dice_3: 3.772  loss_ce_4: 3.164  loss_mask_4: 0.6437  loss_dice_4: 3.776  loss_ce_5: 3.145  loss_mask_5: 0.6459  loss_dice_5: 3.766  loss_ce_6: 3.184  loss_mask_6: 0.6457  loss_dice_6: 3.762  loss_ce_7: 3.17  loss_mask_7: 0.6458  loss_dice_7: 3.759  loss_ce_8: 3.202  loss_mask_8: 0.647  loss_dice_8: 3.755  time: 1.7114  data_time: 0.3559  lr: 9.4948e-06  max_mem: 17674M
[01/19 01:52:24] d2.utils.events INFO:  eta: 17:49:46  iter: 2259  total_loss: 78.02  loss_ce: 3.235  loss_mask: 0.6406  loss_dice: 3.726  loss_ce_0: 4.884  loss_mask_0: 0.6449  loss_dice_0: 3.971  loss_ce_1: 3.372  loss_mask_1: 0.6399  loss_dice_1: 3.857  loss_ce_2: 3.245  loss_mask_2: 0.6472  loss_dice_2: 3.788  loss_ce_3: 3.23  loss_mask_3: 0.6394  loss_dice_3: 3.754  loss_ce_4: 3.203  loss_mask_4: 0.641  loss_dice_4: 3.75  loss_ce_5: 3.184  loss_mask_5: 0.6397  loss_dice_5: 3.744  loss_ce_6: 3.211  loss_mask_6: 0.6416  loss_dice_6: 3.731  loss_ce_7: 3.221  loss_mask_7: 0.6416  loss_dice_7: 3.731  loss_ce_8: 3.195  loss_mask_8: 0.6387  loss_dice_8: 3.737  time: 1.7113  data_time: 0.3443  lr: 9.4903e-06  max_mem: 17674M
[01/19 01:52:58] d2.utils.events INFO:  eta: 17:49:04  iter: 2279  total_loss: 78.51  loss_ce: 3.29  loss_mask: 0.6566  loss_dice: 3.675  loss_ce_0: 4.842  loss_mask_0: 0.6573  loss_dice_0: 3.938  loss_ce_1: 3.424  loss_mask_1: 0.6591  loss_dice_1: 3.812  loss_ce_2: 3.297  loss_mask_2: 0.6581  loss_dice_2: 3.741  loss_ce_3: 3.282  loss_mask_3: 0.6536  loss_dice_3: 3.703  loss_ce_4: 3.247  loss_mask_4: 0.6574  loss_dice_4: 3.697  loss_ce_5: 3.254  loss_mask_5: 0.6541  loss_dice_5: 3.695  loss_ce_6: 3.278  loss_mask_6: 0.6581  loss_dice_6: 3.682  loss_ce_7: 3.281  loss_mask_7: 0.6543  loss_dice_7: 3.682  loss_ce_8: 3.256  loss_mask_8: 0.6565  loss_dice_8: 3.685  time: 1.7112  data_time: 0.3398  lr: 9.4857e-06  max_mem: 17674M
[01/19 01:53:32] d2.utils.events INFO:  eta: 17:48:13  iter: 2299  total_loss: 78.41  loss_ce: 3.307  loss_mask: 0.6446  loss_dice: 3.658  loss_ce_0: 4.944  loss_mask_0: 0.658  loss_dice_0: 3.92  loss_ce_1: 3.479  loss_mask_1: 0.6514  loss_dice_1: 3.798  loss_ce_2: 3.366  loss_mask_2: 0.6539  loss_dice_2: 3.731  loss_ce_3: 3.303  loss_mask_3: 0.6501  loss_dice_3: 3.689  loss_ce_4: 3.294  loss_mask_4: 0.6534  loss_dice_4: 3.679  loss_ce_5: 3.3  loss_mask_5: 0.651  loss_dice_5: 3.683  loss_ce_6: 3.291  loss_mask_6: 0.6499  loss_dice_6: 3.672  loss_ce_7: 3.29  loss_mask_7: 0.651  loss_dice_7: 3.666  loss_ce_8: 3.288  loss_mask_8: 0.6499  loss_dice_8: 3.664  time: 1.7111  data_time: 0.3521  lr: 9.4812e-06  max_mem: 17674M
[01/19 01:54:06] d2.utils.events INFO:  eta: 17:47:29  iter: 2319  total_loss: 79.01  loss_ce: 3.335  loss_mask: 0.6448  loss_dice: 3.717  loss_ce_0: 4.832  loss_mask_0: 0.6524  loss_dice_0: 3.95  loss_ce_1: 3.465  loss_mask_1: 0.6532  loss_dice_1: 3.837  loss_ce_2: 3.36  loss_mask_2: 0.6501  loss_dice_2: 3.771  loss_ce_3: 3.335  loss_mask_3: 0.6459  loss_dice_3: 3.73  loss_ce_4: 3.301  loss_mask_4: 0.6438  loss_dice_4: 3.735  loss_ce_5: 3.307  loss_mask_5: 0.641  loss_dice_5: 3.729  loss_ce_6: 3.303  loss_mask_6: 0.6434  loss_dice_6: 3.716  loss_ce_7: 3.302  loss_mask_7: 0.645  loss_dice_7: 3.722  loss_ce_8: 3.302  loss_mask_8: 0.6445  loss_dice_8: 3.72  time: 1.7109  data_time: 0.3347  lr: 9.4767e-06  max_mem: 17674M
[01/19 01:54:39] d2.utils.events INFO:  eta: 17:46:28  iter: 2339  total_loss: 78.61  loss_ce: 3.318  loss_mask: 0.6407  loss_dice: 3.692  loss_ce_0: 4.883  loss_mask_0: 0.6402  loss_dice_0: 3.951  loss_ce_1: 3.484  loss_mask_1: 0.6392  loss_dice_1: 3.823  loss_ce_2: 3.33  loss_mask_2: 0.6408  loss_dice_2: 3.75  loss_ce_3: 3.289  loss_mask_3: 0.6418  loss_dice_3: 3.704  loss_ce_4: 3.278  loss_mask_4: 0.6396  loss_dice_4: 3.703  loss_ce_5: 3.286  loss_mask_5: 0.6388  loss_dice_5: 3.696  loss_ce_6: 3.294  loss_mask_6: 0.642  loss_dice_6: 3.687  loss_ce_7: 3.302  loss_mask_7: 0.6412  loss_dice_7: 3.684  loss_ce_8: 3.303  loss_mask_8: 0.641  loss_dice_8: 3.69  time: 1.7106  data_time: 0.3392  lr: 9.4722e-06  max_mem: 17674M
[01/19 01:55:13] d2.utils.events INFO:  eta: 17:45:18  iter: 2359  total_loss: 77.64  loss_ce: 3.254  loss_mask: 0.6486  loss_dice: 3.659  loss_ce_0: 4.828  loss_mask_0: 0.6527  loss_dice_0: 3.924  loss_ce_1: 3.426  loss_mask_1: 0.6525  loss_dice_1: 3.801  loss_ce_2: 3.241  loss_mask_2: 0.6533  loss_dice_2: 3.732  loss_ce_3: 3.233  loss_mask_3: 0.6542  loss_dice_3: 3.69  loss_ce_4: 3.234  loss_mask_4: 0.6524  loss_dice_4: 3.695  loss_ce_5: 3.206  loss_mask_5: 0.6524  loss_dice_5: 3.684  loss_ce_6: 3.205  loss_mask_6: 0.6505  loss_dice_6: 3.668  loss_ce_7: 3.198  loss_mask_7: 0.6527  loss_dice_7: 3.672  loss_ce_8: 3.22  loss_mask_8: 0.6531  loss_dice_8: 3.67  time: 1.7104  data_time: 0.3446  lr: 9.4676e-06  max_mem: 17674M
[01/19 01:55:47] d2.utils.events INFO:  eta: 17:44:30  iter: 2379  total_loss: 78.02  loss_ce: 3.231  loss_mask: 0.6542  loss_dice: 3.697  loss_ce_0: 4.797  loss_mask_0: 0.6638  loss_dice_0: 3.944  loss_ce_1: 3.375  loss_mask_1: 0.6587  loss_dice_1: 3.831  loss_ce_2: 3.223  loss_mask_2: 0.6572  loss_dice_2: 3.764  loss_ce_3: 3.216  loss_mask_3: 0.654  loss_dice_3: 3.728  loss_ce_4: 3.18  loss_mask_4: 0.6552  loss_dice_4: 3.719  loss_ce_5: 3.198  loss_mask_5: 0.6521  loss_dice_5: 3.715  loss_ce_6: 3.187  loss_mask_6: 0.6538  loss_dice_6: 3.711  loss_ce_7: 3.194  loss_mask_7: 0.6544  loss_dice_7: 3.701  loss_ce_8: 3.205  loss_mask_8: 0.6511  loss_dice_8: 3.704  time: 1.7102  data_time: 0.3392  lr: 9.4631e-06  max_mem: 17674M
[01/19 01:56:21] d2.utils.events INFO:  eta: 17:43:57  iter: 2399  total_loss: 77.73  loss_ce: 3.225  loss_mask: 0.6396  loss_dice: 3.718  loss_ce_0: 4.747  loss_mask_0: 0.6402  loss_dice_0: 3.96  loss_ce_1: 3.407  loss_mask_1: 0.6501  loss_dice_1: 3.838  loss_ce_2: 3.275  loss_mask_2: 0.6457  loss_dice_2: 3.771  loss_ce_3: 3.24  loss_mask_3: 0.6433  loss_dice_3: 3.737  loss_ce_4: 3.203  loss_mask_4: 0.6422  loss_dice_4: 3.731  loss_ce_5: 3.206  loss_mask_5: 0.6433  loss_dice_5: 3.731  loss_ce_6: 3.197  loss_mask_6: 0.6426  loss_dice_6: 3.725  loss_ce_7: 3.199  loss_mask_7: 0.6397  loss_dice_7: 3.719  loss_ce_8: 3.227  loss_mask_8: 0.6386  loss_dice_8: 3.723  time: 1.7102  data_time: 0.3369  lr: 9.4586e-06  max_mem: 17674M
[01/19 01:56:55] d2.utils.events INFO:  eta: 17:42:59  iter: 2419  total_loss: 78.25  loss_ce: 3.261  loss_mask: 0.6375  loss_dice: 3.692  loss_ce_0: 4.811  loss_mask_0: 0.6481  loss_dice_0: 3.944  loss_ce_1: 3.452  loss_mask_1: 0.645  loss_dice_1: 3.831  loss_ce_2: 3.303  loss_mask_2: 0.6438  loss_dice_2: 3.756  loss_ce_3: 3.246  loss_mask_3: 0.6426  loss_dice_3: 3.728  loss_ce_4: 3.239  loss_mask_4: 0.6426  loss_dice_4: 3.711  loss_ce_5: 3.235  loss_mask_5: 0.6409  loss_dice_5: 3.699  loss_ce_6: 3.229  loss_mask_6: 0.6399  loss_dice_6: 3.699  loss_ce_7: 3.244  loss_mask_7: 0.6373  loss_dice_7: 3.7  loss_ce_8: 3.253  loss_mask_8: 0.6353  loss_dice_8: 3.693  time: 1.7100  data_time: 0.3347  lr: 9.454e-06  max_mem: 17674M
[01/19 01:57:29] d2.utils.events INFO:  eta: 17:42:49  iter: 2439  total_loss: 78.13  loss_ce: 3.27  loss_mask: 0.6431  loss_dice: 3.699  loss_ce_0: 4.713  loss_mask_0: 0.6434  loss_dice_0: 3.953  loss_ce_1: 3.411  loss_mask_1: 0.644  loss_dice_1: 3.837  loss_ce_2: 3.316  loss_mask_2: 0.6478  loss_dice_2: 3.775  loss_ce_3: 3.244  loss_mask_3: 0.6415  loss_dice_3: 3.738  loss_ce_4: 3.244  loss_mask_4: 0.6398  loss_dice_4: 3.731  loss_ce_5: 3.244  loss_mask_5: 0.6422  loss_dice_5: 3.731  loss_ce_6: 3.259  loss_mask_6: 0.6418  loss_dice_6: 3.709  loss_ce_7: 3.274  loss_mask_7: 0.6388  loss_dice_7: 3.714  loss_ce_8: 3.27  loss_mask_8: 0.6396  loss_dice_8: 3.704  time: 1.7100  data_time: 0.3582  lr: 9.4495e-06  max_mem: 17674M
[01/19 01:58:03] d2.utils.events INFO:  eta: 17:42:21  iter: 2459  total_loss: 78.19  loss_ce: 3.267  loss_mask: 0.6301  loss_dice: 3.667  loss_ce_0: 4.819  loss_mask_0: 0.641  loss_dice_0: 3.932  loss_ce_1: 3.42  loss_mask_1: 0.6362  loss_dice_1: 3.815  loss_ce_2: 3.343  loss_mask_2: 0.6369  loss_dice_2: 3.737  loss_ce_3: 3.257  loss_mask_3: 0.6331  loss_dice_3: 3.701  loss_ce_4: 3.244  loss_mask_4: 0.6322  loss_dice_4: 3.694  loss_ce_5: 3.242  loss_mask_5: 0.6341  loss_dice_5: 3.685  loss_ce_6: 3.241  loss_mask_6: 0.631  loss_dice_6: 3.681  loss_ce_7: 3.267  loss_mask_7: 0.6346  loss_dice_7: 3.666  loss_ce_8: 3.253  loss_mask_8: 0.6313  loss_dice_8: 3.675  time: 1.7100  data_time: 0.3386  lr: 9.445e-06  max_mem: 17674M
[01/19 01:58:37] d2.utils.events INFO:  eta: 17:41:41  iter: 2479  total_loss: 78.66  loss_ce: 3.392  loss_mask: 0.6477  loss_dice: 3.62  loss_ce_0: 4.791  loss_mask_0: 0.6445  loss_dice_0: 3.892  loss_ce_1: 3.534  loss_mask_1: 0.6508  loss_dice_1: 3.759  loss_ce_2: 3.409  loss_mask_2: 0.6517  loss_dice_2: 3.687  loss_ce_3: 3.4  loss_mask_3: 0.6519  loss_dice_3: 3.649  loss_ce_4: 3.369  loss_mask_4: 0.6528  loss_dice_4: 3.644  loss_ce_5: 3.385  loss_mask_5: 0.6489  loss_dice_5: 3.633  loss_ce_6: 3.376  loss_mask_6: 0.6517  loss_dice_6: 3.621  loss_ce_7: 3.363  loss_mask_7: 0.6484  loss_dice_7: 3.621  loss_ce_8: 3.35  loss_mask_8: 0.6484  loss_dice_8: 3.623  time: 1.7099  data_time: 0.3401  lr: 9.4405e-06  max_mem: 17674M
[01/19 01:59:11] d2.utils.events INFO:  eta: 17:40:48  iter: 2499  total_loss: 78.14  loss_ce: 3.273  loss_mask: 0.6351  loss_dice: 3.734  loss_ce_0: 4.695  loss_mask_0: 0.633  loss_dice_0: 3.982  loss_ce_1: 3.39  loss_mask_1: 0.6352  loss_dice_1: 3.863  loss_ce_2: 3.285  loss_mask_2: 0.6353  loss_dice_2: 3.802  loss_ce_3: 3.233  loss_mask_3: 0.6323  loss_dice_3: 3.766  loss_ce_4: 3.209  loss_mask_4: 0.6337  loss_dice_4: 3.76  loss_ce_5: 3.217  loss_mask_5: 0.6327  loss_dice_5: 3.764  loss_ce_6: 3.24  loss_mask_6: 0.6334  loss_dice_6: 3.747  loss_ce_7: 3.245  loss_mask_7: 0.6348  loss_dice_7: 3.747  loss_ce_8: 3.258  loss_mask_8: 0.6358  loss_dice_8: 3.747  time: 1.7098  data_time: 0.3339  lr: 9.4359e-06  max_mem: 17674M
[01/19 01:59:46] d2.utils.events INFO:  eta: 17:40:09  iter: 2519  total_loss: 77.75  loss_ce: 3.218  loss_mask: 0.6512  loss_dice: 3.675  loss_ce_0: 4.751  loss_mask_0: 0.6547  loss_dice_0: 3.942  loss_ce_1: 3.382  loss_mask_1: 0.6555  loss_dice_1: 3.809  loss_ce_2: 3.237  loss_mask_2: 0.6548  loss_dice_2: 3.74  loss_ce_3: 3.231  loss_mask_3: 0.6526  loss_dice_3: 3.697  loss_ce_4: 3.195  loss_mask_4: 0.6529  loss_dice_4: 3.691  loss_ce_5: 3.201  loss_mask_5: 0.6496  loss_dice_5: 3.685  loss_ce_6: 3.2  loss_mask_6: 0.6527  loss_dice_6: 3.683  loss_ce_7: 3.211  loss_mask_7: 0.6482  loss_dice_7: 3.678  loss_ce_8: 3.21  loss_mask_8: 0.6525  loss_dice_8: 3.675  time: 1.7098  data_time: 0.3720  lr: 9.4314e-06  max_mem: 17674M
[01/19 02:00:20] d2.utils.events INFO:  eta: 17:39:27  iter: 2539  total_loss: 77.08  loss_ce: 3.16  loss_mask: 0.6377  loss_dice: 3.742  loss_ce_0: 4.736  loss_mask_0: 0.6476  loss_dice_0: 3.95  loss_ce_1: 3.323  loss_mask_1: 0.6453  loss_dice_1: 3.849  loss_ce_2: 3.18  loss_mask_2: 0.6476  loss_dice_2: 3.783  loss_ce_3: 3.135  loss_mask_3: 0.6427  loss_dice_3: 3.754  loss_ce_4: 3.099  loss_mask_4: 0.6449  loss_dice_4: 3.746  loss_ce_5: 3.101  loss_mask_5: 0.6453  loss_dice_5: 3.744  loss_ce_6: 3.122  loss_mask_6: 0.6416  loss_dice_6: 3.743  loss_ce_7: 3.116  loss_mask_7: 0.6405  loss_dice_7: 3.739  loss_ce_8: 3.129  loss_mask_8: 0.637  loss_dice_8: 3.74  time: 1.7097  data_time: 0.3341  lr: 9.4269e-06  max_mem: 17674M
[01/19 02:00:54] d2.utils.events INFO:  eta: 17:38:52  iter: 2559  total_loss: 77.46  loss_ce: 3.193  loss_mask: 0.6345  loss_dice: 3.709  loss_ce_0: 4.699  loss_mask_0: 0.6387  loss_dice_0: 3.975  loss_ce_1: 3.313  loss_mask_1: 0.6436  loss_dice_1: 3.846  loss_ce_2: 3.208  loss_mask_2: 0.6443  loss_dice_2: 3.777  loss_ce_3: 3.158  loss_mask_3: 0.6365  loss_dice_3: 3.738  loss_ce_4: 3.148  loss_mask_4: 0.6383  loss_dice_4: 3.729  loss_ce_5: 3.14  loss_mask_5: 0.6394  loss_dice_5: 3.722  loss_ce_6: 3.176  loss_mask_6: 0.6365  loss_dice_6: 3.718  loss_ce_7: 3.186  loss_mask_7: 0.6343  loss_dice_7: 3.713  loss_ce_8: 3.193  loss_mask_8: 0.6358  loss_dice_8: 3.713  time: 1.7096  data_time: 0.3356  lr: 9.4223e-06  max_mem: 17674M
[01/19 02:01:28] d2.utils.events INFO:  eta: 17:38:17  iter: 2579  total_loss: 76.91  loss_ce: 3.135  loss_mask: 0.6362  loss_dice: 3.733  loss_ce_0: 4.657  loss_mask_0: 0.6475  loss_dice_0: 3.981  loss_ce_1: 3.27  loss_mask_1: 0.6404  loss_dice_1: 3.865  loss_ce_2: 3.114  loss_mask_2: 0.6377  loss_dice_2: 3.801  loss_ce_3: 3.102  loss_mask_3: 0.639  loss_dice_3: 3.767  loss_ce_4: 3.095  loss_mask_4: 0.6357  loss_dice_4: 3.754  loss_ce_5: 3.092  loss_mask_5: 0.6383  loss_dice_5: 3.751  loss_ce_6: 3.128  loss_mask_6: 0.639  loss_dice_6: 3.738  loss_ce_7: 3.103  loss_mask_7: 0.6404  loss_dice_7: 3.735  loss_ce_8: 3.13  loss_mask_8: 0.6373  loss_dice_8: 3.745  time: 1.7096  data_time: 0.3710  lr: 9.4178e-06  max_mem: 17674M
[01/19 02:02:02] d2.utils.events INFO:  eta: 17:37:44  iter: 2599  total_loss: 76.55  loss_ce: 3.054  loss_mask: 0.6344  loss_dice: 3.665  loss_ce_0: 4.667  loss_mask_0: 0.6333  loss_dice_0: 3.956  loss_ce_1: 3.219  loss_mask_1: 0.6339  loss_dice_1: 3.82  loss_ce_2: 3.089  loss_mask_2: 0.6318  loss_dice_2: 3.741  loss_ce_3: 3.048  loss_mask_3: 0.6321  loss_dice_3: 3.699  loss_ce_4: 3.019  loss_mask_4: 0.6294  loss_dice_4: 3.695  loss_ce_5: 3.026  loss_mask_5: 0.6315  loss_dice_5: 3.68  loss_ce_6: 3.051  loss_mask_6: 0.6301  loss_dice_6: 3.677  loss_ce_7: 3.052  loss_mask_7: 0.6334  loss_dice_7: 3.671  loss_ce_8: 3.054  loss_mask_8: 0.6345  loss_dice_8: 3.677  time: 1.7095  data_time: 0.3333  lr: 9.4133e-06  max_mem: 17674M
[01/19 02:02:36] d2.utils.events INFO:  eta: 17:37:17  iter: 2619  total_loss: 76.67  loss_ce: 3.151  loss_mask: 0.6296  loss_dice: 3.705  loss_ce_0: 4.633  loss_mask_0: 0.6361  loss_dice_0: 3.963  loss_ce_1: 3.316  loss_mask_1: 0.6334  loss_dice_1: 3.833  loss_ce_2: 3.157  loss_mask_2: 0.6363  loss_dice_2: 3.768  loss_ce_3: 3.117  loss_mask_3: 0.6338  loss_dice_3: 3.727  loss_ce_4: 3.107  loss_mask_4: 0.6345  loss_dice_4: 3.726  loss_ce_5: 3.092  loss_mask_5: 0.6342  loss_dice_5: 3.721  loss_ce_6: 3.116  loss_mask_6: 0.635  loss_dice_6: 3.711  loss_ce_7: 3.11  loss_mask_7: 0.6328  loss_dice_7: 3.711  loss_ce_8: 3.115  loss_mask_8: 0.6311  loss_dice_8: 3.713  time: 1.7094  data_time: 0.3401  lr: 9.4087e-06  max_mem: 17674M
[01/19 02:03:10] d2.utils.events INFO:  eta: 17:36:38  iter: 2639  total_loss: 76.84  loss_ce: 3.173  loss_mask: 0.6332  loss_dice: 3.69  loss_ce_0: 4.631  loss_mask_0: 0.6357  loss_dice_0: 3.942  loss_ce_1: 3.282  loss_mask_1: 0.6393  loss_dice_1: 3.818  loss_ce_2: 3.181  loss_mask_2: 0.6392  loss_dice_2: 3.76  loss_ce_3: 3.154  loss_mask_3: 0.6324  loss_dice_3: 3.719  loss_ce_4: 3.138  loss_mask_4: 0.6322  loss_dice_4: 3.718  loss_ce_5: 3.125  loss_mask_5: 0.6324  loss_dice_5: 3.714  loss_ce_6: 3.153  loss_mask_6: 0.6319  loss_dice_6: 3.703  loss_ce_7: 3.143  loss_mask_7: 0.6375  loss_dice_7: 3.701  loss_ce_8: 3.147  loss_mask_8: 0.6389  loss_dice_8: 3.695  time: 1.7093  data_time: 0.3284  lr: 9.4042e-06  max_mem: 17674M
[01/19 02:03:44] d2.utils.events INFO:  eta: 17:36:05  iter: 2659  total_loss: 76.6  loss_ce: 3.185  loss_mask: 0.6466  loss_dice: 3.675  loss_ce_0: 4.636  loss_mask_0: 0.6495  loss_dice_0: 3.957  loss_ce_1: 3.31  loss_mask_1: 0.6518  loss_dice_1: 3.811  loss_ce_2: 3.157  loss_mask_2: 0.6506  loss_dice_2: 3.741  loss_ce_3: 3.137  loss_mask_3: 0.6502  loss_dice_3: 3.696  loss_ce_4: 3.115  loss_mask_4: 0.6514  loss_dice_4: 3.692  loss_ce_5: 3.126  loss_mask_5: 0.6532  loss_dice_5: 3.684  loss_ce_6: 3.126  loss_mask_6: 0.6498  loss_dice_6: 3.675  loss_ce_7: 3.136  loss_mask_7: 0.6501  loss_dice_7: 3.683  loss_ce_8: 3.134  loss_mask_8: 0.6499  loss_dice_8: 3.68  time: 1.7092  data_time: 0.3570  lr: 9.3997e-06  max_mem: 17674M
[01/19 02:04:18] d2.utils.events INFO:  eta: 17:35:33  iter: 2679  total_loss: 76.99  loss_ce: 3.161  loss_mask: 0.6537  loss_dice: 3.697  loss_ce_0: 4.592  loss_mask_0: 0.6503  loss_dice_0: 3.949  loss_ce_1: 3.299  loss_mask_1: 0.6616  loss_dice_1: 3.824  loss_ce_2: 3.139  loss_mask_2: 0.6588  loss_dice_2: 3.763  loss_ce_3: 3.144  loss_mask_3: 0.6574  loss_dice_3: 3.724  loss_ce_4: 3.123  loss_mask_4: 0.655  loss_dice_4: 3.716  loss_ce_5: 3.121  loss_mask_5: 0.6578  loss_dice_5: 3.714  loss_ce_6: 3.13  loss_mask_6: 0.6546  loss_dice_6: 3.707  loss_ce_7: 3.115  loss_mask_7: 0.6539  loss_dice_7: 3.704  loss_ce_8: 3.139  loss_mask_8: 0.6525  loss_dice_8: 3.695  time: 1.7092  data_time: 0.3217  lr: 9.3952e-06  max_mem: 17674M
[01/19 02:04:52] d2.utils.events INFO:  eta: 17:34:59  iter: 2699  total_loss: 78  loss_ce: 3.333  loss_mask: 0.6407  loss_dice: 3.643  loss_ce_0: 4.684  loss_mask_0: 0.6477  loss_dice_0: 3.927  loss_ce_1: 3.396  loss_mask_1: 0.647  loss_dice_1: 3.79  loss_ce_2: 3.303  loss_mask_2: 0.6462  loss_dice_2: 3.717  loss_ce_3: 3.283  loss_mask_3: 0.6446  loss_dice_3: 3.669  loss_ce_4: 3.26  loss_mask_4: 0.6459  loss_dice_4: 3.672  loss_ce_5: 3.265  loss_mask_5: 0.6455  loss_dice_5: 3.659  loss_ce_6: 3.296  loss_mask_6: 0.645  loss_dice_6: 3.651  loss_ce_7: 3.298  loss_mask_7: 0.6433  loss_dice_7: 3.649  loss_ce_8: 3.297  loss_mask_8: 0.6436  loss_dice_8: 3.647  time: 1.7090  data_time: 0.3455  lr: 9.3906e-06  max_mem: 17674M
[01/19 02:05:26] d2.utils.events INFO:  eta: 17:34:23  iter: 2719  total_loss: 77.01  loss_ce: 3.195  loss_mask: 0.6386  loss_dice: 3.691  loss_ce_0: 4.577  loss_mask_0: 0.643  loss_dice_0: 3.933  loss_ce_1: 3.329  loss_mask_1: 0.6496  loss_dice_1: 3.825  loss_ce_2: 3.202  loss_mask_2: 0.6485  loss_dice_2: 3.742  loss_ce_3: 3.163  loss_mask_3: 0.6455  loss_dice_3: 3.714  loss_ce_4: 3.131  loss_mask_4: 0.6446  loss_dice_4: 3.706  loss_ce_5: 3.139  loss_mask_5: 0.6425  loss_dice_5: 3.698  loss_ce_6: 3.159  loss_mask_6: 0.64  loss_dice_6: 3.688  loss_ce_7: 3.157  loss_mask_7: 0.6403  loss_dice_7: 3.694  loss_ce_8: 3.164  loss_mask_8: 0.6393  loss_dice_8: 3.696  time: 1.7091  data_time: 0.3293  lr: 9.3861e-06  max_mem: 17674M
[01/19 02:06:00] d2.utils.events INFO:  eta: 17:33:48  iter: 2739  total_loss: 77.63  loss_ce: 3.321  loss_mask: 0.6482  loss_dice: 3.637  loss_ce_0: 4.665  loss_mask_0: 0.6539  loss_dice_0: 3.896  loss_ce_1: 3.404  loss_mask_1: 0.6605  loss_dice_1: 3.777  loss_ce_2: 3.303  loss_mask_2: 0.654  loss_dice_2: 3.7  loss_ce_3: 3.309  loss_mask_3: 0.6514  loss_dice_3: 3.663  loss_ce_4: 3.259  loss_mask_4: 0.6484  loss_dice_4: 3.657  loss_ce_5: 3.26  loss_mask_5: 0.6501  loss_dice_5: 3.654  loss_ce_6: 3.277  loss_mask_6: 0.6502  loss_dice_6: 3.643  loss_ce_7: 3.291  loss_mask_7: 0.6487  loss_dice_7: 3.644  loss_ce_8: 3.307  loss_mask_8: 0.6502  loss_dice_8: 3.647  time: 1.7089  data_time: 0.3279  lr: 9.3816e-06  max_mem: 17674M
[01/19 02:06:34] d2.utils.events INFO:  eta: 17:33:13  iter: 2759  total_loss: 77.23  loss_ce: 3.234  loss_mask: 0.6326  loss_dice: 3.686  loss_ce_0: 4.599  loss_mask_0: 0.6408  loss_dice_0: 3.94  loss_ce_1: 3.322  loss_mask_1: 0.6413  loss_dice_1: 3.818  loss_ce_2: 3.251  loss_mask_2: 0.6378  loss_dice_2: 3.75  loss_ce_3: 3.215  loss_mask_3: 0.6292  loss_dice_3: 3.713  loss_ce_4: 3.179  loss_mask_4: 0.6302  loss_dice_4: 3.699  loss_ce_5: 3.186  loss_mask_5: 0.6316  loss_dice_5: 3.7  loss_ce_6: 3.178  loss_mask_6: 0.6337  loss_dice_6: 3.694  loss_ce_7: 3.193  loss_mask_7: 0.6325  loss_dice_7: 3.69  loss_ce_8: 3.214  loss_mask_8: 0.6342  loss_dice_8: 3.686  time: 1.7088  data_time: 0.3638  lr: 9.377e-06  max_mem: 17674M
[01/19 02:07:08] d2.utils.events INFO:  eta: 17:32:41  iter: 2779  total_loss: 76.46  loss_ce: 3.102  loss_mask: 0.639  loss_dice: 3.694  loss_ce_0: 4.54  loss_mask_0: 0.6444  loss_dice_0: 3.952  loss_ce_1: 3.241  loss_mask_1: 0.646  loss_dice_1: 3.823  loss_ce_2: 3.135  loss_mask_2: 0.6461  loss_dice_2: 3.757  loss_ce_3: 3.091  loss_mask_3: 0.6404  loss_dice_3: 3.721  loss_ce_4: 3.068  loss_mask_4: 0.6392  loss_dice_4: 3.715  loss_ce_5: 3.081  loss_mask_5: 0.64  loss_dice_5: 3.706  loss_ce_6: 3.088  loss_mask_6: 0.6393  loss_dice_6: 3.698  loss_ce_7: 3.092  loss_mask_7: 0.6394  loss_dice_7: 3.696  loss_ce_8: 3.081  loss_mask_8: 0.6382  loss_dice_8: 3.696  time: 1.7088  data_time: 0.3527  lr: 9.3725e-06  max_mem: 17674M
[01/19 02:07:42] d2.utils.events INFO:  eta: 17:32:06  iter: 2799  total_loss: 76.98  loss_ce: 3.25  loss_mask: 0.6487  loss_dice: 3.621  loss_ce_0: 4.598  loss_mask_0: 0.6517  loss_dice_0: 3.888  loss_ce_1: 3.335  loss_mask_1: 0.6581  loss_dice_1: 3.762  loss_ce_2: 3.234  loss_mask_2: 0.6575  loss_dice_2: 3.692  loss_ce_3: 3.222  loss_mask_3: 0.6547  loss_dice_3: 3.655  loss_ce_4: 3.219  loss_mask_4: 0.6553  loss_dice_4: 3.646  loss_ce_5: 3.214  loss_mask_5: 0.6511  loss_dice_5: 3.639  loss_ce_6: 3.199  loss_mask_6: 0.6527  loss_dice_6: 3.632  loss_ce_7: 3.208  loss_mask_7: 0.6525  loss_dice_7: 3.62  loss_ce_8: 3.223  loss_mask_8: 0.6539  loss_dice_8: 3.619  time: 1.7086  data_time: 0.3625  lr: 9.368e-06  max_mem: 17674M
[01/19 02:08:16] d2.utils.events INFO:  eta: 17:31:38  iter: 2819  total_loss: 76  loss_ce: 3.121  loss_mask: 0.6335  loss_dice: 3.709  loss_ce_0: 4.481  loss_mask_0: 0.6361  loss_dice_0: 3.951  loss_ce_1: 3.209  loss_mask_1: 0.643  loss_dice_1: 3.825  loss_ce_2: 3.134  loss_mask_2: 0.6408  loss_dice_2: 3.757  loss_ce_3: 3.104  loss_mask_3: 0.6342  loss_dice_3: 3.729  loss_ce_4: 3.111  loss_mask_4: 0.6386  loss_dice_4: 3.722  loss_ce_5: 3.086  loss_mask_5: 0.6362  loss_dice_5: 3.719  loss_ce_6: 3.085  loss_mask_6: 0.6347  loss_dice_6: 3.714  loss_ce_7: 3.091  loss_mask_7: 0.6344  loss_dice_7: 3.705  loss_ce_8: 3.105  loss_mask_8: 0.6359  loss_dice_8: 3.709  time: 1.7086  data_time: 0.3417  lr: 9.3634e-06  max_mem: 17674M
[01/19 02:08:50] d2.utils.events INFO:  eta: 17:31:01  iter: 2839  total_loss: 77.05  loss_ce: 3.208  loss_mask: 0.6469  loss_dice: 3.683  loss_ce_0: 4.592  loss_mask_0: 0.6482  loss_dice_0: 3.942  loss_ce_1: 3.367  loss_mask_1: 0.6526  loss_dice_1: 3.829  loss_ce_2: 3.281  loss_mask_2: 0.6463  loss_dice_2: 3.749  loss_ce_3: 3.212  loss_mask_3: 0.6461  loss_dice_3: 3.715  loss_ce_4: 3.192  loss_mask_4: 0.6453  loss_dice_4: 3.711  loss_ce_5: 3.174  loss_mask_5: 0.647  loss_dice_5: 3.706  loss_ce_6: 3.18  loss_mask_6: 0.643  loss_dice_6: 3.695  loss_ce_7: 3.177  loss_mask_7: 0.6428  loss_dice_7: 3.688  loss_ce_8: 3.186  loss_mask_8: 0.642  loss_dice_8: 3.683  time: 1.7085  data_time: 0.3306  lr: 9.3589e-06  max_mem: 17674M
[01/19 02:09:24] d2.utils.events INFO:  eta: 17:30:23  iter: 2859  total_loss: 76.73  loss_ce: 3.116  loss_mask: 0.6361  loss_dice: 3.696  loss_ce_0: 4.529  loss_mask_0: 0.6386  loss_dice_0: 3.958  loss_ce_1: 3.28  loss_mask_1: 0.6438  loss_dice_1: 3.826  loss_ce_2: 3.139  loss_mask_2: 0.6415  loss_dice_2: 3.745  loss_ce_3: 3.131  loss_mask_3: 0.6364  loss_dice_3: 3.718  loss_ce_4: 3.12  loss_mask_4: 0.6348  loss_dice_4: 3.712  loss_ce_5: 3.094  loss_mask_5: 0.6383  loss_dice_5: 3.714  loss_ce_6: 3.114  loss_mask_6: 0.6387  loss_dice_6: 3.7  loss_ce_7: 3.119  loss_mask_7: 0.6404  loss_dice_7: 3.697  loss_ce_8: 3.114  loss_mask_8: 0.637  loss_dice_8: 3.701  time: 1.7085  data_time: 0.3441  lr: 9.3544e-06  max_mem: 17674M
[01/19 02:09:58] d2.utils.events INFO:  eta: 17:29:49  iter: 2879  total_loss: 76.07  loss_ce: 3.115  loss_mask: 0.6313  loss_dice: 3.679  loss_ce_0: 4.546  loss_mask_0: 0.6436  loss_dice_0: 3.931  loss_ce_1: 3.24  loss_mask_1: 0.6431  loss_dice_1: 3.804  loss_ce_2: 3.136  loss_mask_2: 0.6367  loss_dice_2: 3.731  loss_ce_3: 3.114  loss_mask_3: 0.6382  loss_dice_3: 3.699  loss_ce_4: 3.097  loss_mask_4: 0.6349  loss_dice_4: 3.693  loss_ce_5: 3.092  loss_mask_5: 0.6365  loss_dice_5: 3.696  loss_ce_6: 3.105  loss_mask_6: 0.6336  loss_dice_6: 3.685  loss_ce_7: 3.094  loss_mask_7: 0.6314  loss_dice_7: 3.688  loss_ce_8: 3.114  loss_mask_8: 0.6322  loss_dice_8: 3.681  time: 1.7085  data_time: 0.3534  lr: 9.3498e-06  max_mem: 17674M
[01/19 02:10:32] d2.utils.events INFO:  eta: 17:29:15  iter: 2899  total_loss: 76.47  loss_ce: 3.204  loss_mask: 0.6417  loss_dice: 3.644  loss_ce_0: 4.56  loss_mask_0: 0.6506  loss_dice_0: 3.91  loss_ce_1: 3.335  loss_mask_1: 0.6552  loss_dice_1: 3.764  loss_ce_2: 3.229  loss_mask_2: 0.6517  loss_dice_2: 3.699  loss_ce_3: 3.215  loss_mask_3: 0.6459  loss_dice_3: 3.66  loss_ce_4: 3.189  loss_mask_4: 0.6471  loss_dice_4: 3.658  loss_ce_5: 3.178  loss_mask_5: 0.6457  loss_dice_5: 3.651  loss_ce_6: 3.173  loss_mask_6: 0.641  loss_dice_6: 3.645  loss_ce_7: 3.19  loss_mask_7: 0.645  loss_dice_7: 3.642  loss_ce_8: 3.202  loss_mask_8: 0.645  loss_dice_8: 3.648  time: 1.7083  data_time: 0.3187  lr: 9.3453e-06  max_mem: 17674M
[01/19 02:11:06] d2.utils.events INFO:  eta: 17:28:46  iter: 2919  total_loss: 75.89  loss_ce: 3.094  loss_mask: 0.6403  loss_dice: 3.667  loss_ce_0: 4.495  loss_mask_0: 0.6441  loss_dice_0: 3.935  loss_ce_1: 3.217  loss_mask_1: 0.6491  loss_dice_1: 3.8  loss_ce_2: 3.071  loss_mask_2: 0.646  loss_dice_2: 3.74  loss_ce_3: 3.038  loss_mask_3: 0.6442  loss_dice_3: 3.686  loss_ce_4: 3.031  loss_mask_4: 0.643  loss_dice_4: 3.688  loss_ce_5: 3.035  loss_mask_5: 0.6415  loss_dice_5: 3.679  loss_ce_6: 3.062  loss_mask_6: 0.6398  loss_dice_6: 3.662  loss_ce_7: 3.043  loss_mask_7: 0.6389  loss_dice_7: 3.672  loss_ce_8: 3.076  loss_mask_8: 0.6397  loss_dice_8: 3.66  time: 1.7083  data_time: 0.3523  lr: 9.3408e-06  max_mem: 17674M
[01/19 02:11:40] d2.utils.events INFO:  eta: 17:28:06  iter: 2939  total_loss: 76.22  loss_ce: 3.098  loss_mask: 0.6449  loss_dice: 3.662  loss_ce_0: 4.539  loss_mask_0: 0.6496  loss_dice_0: 3.934  loss_ce_1: 3.227  loss_mask_1: 0.6553  loss_dice_1: 3.805  loss_ce_2: 3.1  loss_mask_2: 0.6539  loss_dice_2: 3.742  loss_ce_3: 3.06  loss_mask_3: 0.6478  loss_dice_3: 3.709  loss_ce_4: 3.083  loss_mask_4: 0.6468  loss_dice_4: 3.695  loss_ce_5: 3.073  loss_mask_5: 0.6448  loss_dice_5: 3.689  loss_ce_6: 3.066  loss_mask_6: 0.6426  loss_dice_6: 3.671  loss_ce_7: 3.09  loss_mask_7: 0.6438  loss_dice_7: 3.676  loss_ce_8: 3.086  loss_mask_8: 0.6412  loss_dice_8: 3.676  time: 1.7083  data_time: 0.3473  lr: 9.3362e-06  max_mem: 17674M
[01/19 02:12:14] d2.utils.events INFO:  eta: 17:27:12  iter: 2959  total_loss: 75.86  loss_ce: 3.071  loss_mask: 0.6363  loss_dice: 3.708  loss_ce_0: 4.443  loss_mask_0: 0.6353  loss_dice_0: 3.969  loss_ce_1: 3.173  loss_mask_1: 0.6398  loss_dice_1: 3.838  loss_ce_2: 3.039  loss_mask_2: 0.6387  loss_dice_2: 3.773  loss_ce_3: 3.018  loss_mask_3: 0.6358  loss_dice_3: 3.727  loss_ce_4: 3  loss_mask_4: 0.6358  loss_dice_4: 3.72  loss_ce_5: 3.005  loss_mask_5: 0.6379  loss_dice_5: 3.717  loss_ce_6: 3.016  loss_mask_6: 0.637  loss_dice_6: 3.71  loss_ce_7: 3.031  loss_mask_7: 0.6369  loss_dice_7: 3.706  loss_ce_8: 3.029  loss_mask_8: 0.6351  loss_dice_8: 3.708  time: 1.7082  data_time: 0.3429  lr: 9.3317e-06  max_mem: 17674M
[01/19 02:12:48] d2.utils.events INFO:  eta: 17:26:53  iter: 2979  total_loss: 76.07  loss_ce: 3.107  loss_mask: 0.6313  loss_dice: 3.667  loss_ce_0: 4.502  loss_mask_0: 0.6369  loss_dice_0: 3.925  loss_ce_1: 3.261  loss_mask_1: 0.6444  loss_dice_1: 3.798  loss_ce_2: 3.127  loss_mask_2: 0.6416  loss_dice_2: 3.73  loss_ce_3: 3.102  loss_mask_3: 0.635  loss_dice_3: 3.679  loss_ce_4: 3.102  loss_mask_4: 0.6342  loss_dice_4: 3.674  loss_ce_5: 3.105  loss_mask_5: 0.6356  loss_dice_5: 3.666  loss_ce_6: 3.093  loss_mask_6: 0.633  loss_dice_6: 3.665  loss_ce_7: 3.079  loss_mask_7: 0.6328  loss_dice_7: 3.662  loss_ce_8: 3.099  loss_mask_8: 0.6324  loss_dice_8: 3.665  time: 1.7081  data_time: 0.3365  lr: 9.3272e-06  max_mem: 17674M
[01/19 02:13:22] d2.utils.events INFO:  eta: 17:26:06  iter: 2999  total_loss: 75.11  loss_ce: 2.976  loss_mask: 0.6393  loss_dice: 3.71  loss_ce_0: 4.407  loss_mask_0: 0.6343  loss_dice_0: 3.959  loss_ce_1: 3.181  loss_mask_1: 0.6431  loss_dice_1: 3.832  loss_ce_2: 3.031  loss_mask_2: 0.6418  loss_dice_2: 3.761  loss_ce_3: 2.985  loss_mask_3: 0.6371  loss_dice_3: 3.73  loss_ce_4: 2.955  loss_mask_4: 0.6415  loss_dice_4: 3.725  loss_ce_5: 2.953  loss_mask_5: 0.6389  loss_dice_5: 3.713  loss_ce_6: 2.954  loss_mask_6: 0.6409  loss_dice_6: 3.707  loss_ce_7: 2.965  loss_mask_7: 0.6391  loss_dice_7: 3.707  loss_ce_8: 2.978  loss_mask_8: 0.6401  loss_dice_8: 3.711  time: 1.7080  data_time: 0.3344  lr: 9.3226e-06  max_mem: 17674M
[01/19 02:13:56] d2.utils.events INFO:  eta: 17:25:19  iter: 3019  total_loss: 76.37  loss_ce: 3.139  loss_mask: 0.6293  loss_dice: 3.674  loss_ce_0: 4.491  loss_mask_0: 0.6404  loss_dice_0: 3.963  loss_ce_1: 3.216  loss_mask_1: 0.6406  loss_dice_1: 3.805  loss_ce_2: 3.099  loss_mask_2: 0.6393  loss_dice_2: 3.731  loss_ce_3: 3.084  loss_mask_3: 0.6299  loss_dice_3: 3.7  loss_ce_4: 3.059  loss_mask_4: 0.6283  loss_dice_4: 3.698  loss_ce_5: 3.1  loss_mask_5: 0.6306  loss_dice_5: 3.689  loss_ce_6: 3.117  loss_mask_6: 0.6303  loss_dice_6: 3.686  loss_ce_7: 3.103  loss_mask_7: 0.6296  loss_dice_7: 3.681  loss_ce_8: 3.125  loss_mask_8: 0.6259  loss_dice_8: 3.676  time: 1.7081  data_time: 0.3420  lr: 9.3181e-06  max_mem: 17674M
[01/19 02:14:31] d2.utils.events INFO:  eta: 17:24:48  iter: 3039  total_loss: 75.98  loss_ce: 3.049  loss_mask: 0.6404  loss_dice: 3.672  loss_ce_0: 4.444  loss_mask_0: 0.6406  loss_dice_0: 3.956  loss_ce_1: 3.217  loss_mask_1: 0.6427  loss_dice_1: 3.815  loss_ce_2: 3.1  loss_mask_2: 0.6418  loss_dice_2: 3.739  loss_ce_3: 3.061  loss_mask_3: 0.6407  loss_dice_3: 3.705  loss_ce_4: 3.036  loss_mask_4: 0.6398  loss_dice_4: 3.695  loss_ce_5: 3.061  loss_mask_5: 0.6398  loss_dice_5: 3.687  loss_ce_6: 3.037  loss_mask_6: 0.6439  loss_dice_6: 3.677  loss_ce_7: 3.038  loss_mask_7: 0.6419  loss_dice_7: 3.677  loss_ce_8: 3.038  loss_mask_8: 0.6393  loss_dice_8: 3.674  time: 1.7081  data_time: 0.3450  lr: 9.3136e-06  max_mem: 17674M
[01/19 02:15:05] d2.utils.events INFO:  eta: 17:24:11  iter: 3059  total_loss: 75.33  loss_ce: 3.028  loss_mask: 0.6297  loss_dice: 3.668  loss_ce_0: 4.379  loss_mask_0: 0.6427  loss_dice_0: 3.941  loss_ce_1: 3.144  loss_mask_1: 0.6451  loss_dice_1: 3.806  loss_ce_2: 3.036  loss_mask_2: 0.6383  loss_dice_2: 3.728  loss_ce_3: 3.033  loss_mask_3: 0.6365  loss_dice_3: 3.687  loss_ce_4: 2.998  loss_mask_4: 0.6364  loss_dice_4: 3.688  loss_ce_5: 3.014  loss_mask_5: 0.6361  loss_dice_5: 3.679  loss_ce_6: 3.013  loss_mask_6: 0.6335  loss_dice_6: 3.674  loss_ce_7: 3.019  loss_mask_7: 0.6326  loss_dice_7: 3.674  loss_ce_8: 3.024  loss_mask_8: 0.6315  loss_dice_8: 3.671  time: 1.7081  data_time: 0.3449  lr: 9.309e-06  max_mem: 17674M
[01/19 02:15:39] d2.utils.events INFO:  eta: 17:24:02  iter: 3079  total_loss: 75.74  loss_ce: 3.13  loss_mask: 0.6332  loss_dice: 3.648  loss_ce_0: 4.479  loss_mask_0: 0.636  loss_dice_0: 3.927  loss_ce_1: 3.287  loss_mask_1: 0.6414  loss_dice_1: 3.776  loss_ce_2: 3.152  loss_mask_2: 0.6407  loss_dice_2: 3.713  loss_ce_3: 3.104  loss_mask_3: 0.6367  loss_dice_3: 3.672  loss_ce_4: 3.075  loss_mask_4: 0.6374  loss_dice_4: 3.675  loss_ce_5: 3.107  loss_mask_5: 0.6341  loss_dice_5: 3.658  loss_ce_6: 3.115  loss_mask_6: 0.6352  loss_dice_6: 3.658  loss_ce_7: 3.117  loss_mask_7: 0.6351  loss_dice_7: 3.656  loss_ce_8: 3.119  loss_mask_8: 0.6341  loss_dice_8: 3.653  time: 1.7081  data_time: 0.3580  lr: 9.3045e-06  max_mem: 17674M
[01/19 02:16:13] d2.utils.events INFO:  eta: 17:23:28  iter: 3099  total_loss: 76.6  loss_ce: 3.163  loss_mask: 0.6351  loss_dice: 3.693  loss_ce_0: 4.471  loss_mask_0: 0.6416  loss_dice_0: 3.944  loss_ce_1: 3.324  loss_mask_1: 0.6488  loss_dice_1: 3.818  loss_ce_2: 3.159  loss_mask_2: 0.6432  loss_dice_2: 3.747  loss_ce_3: 3.118  loss_mask_3: 0.6403  loss_dice_3: 3.71  loss_ce_4: 3.086  loss_mask_4: 0.6371  loss_dice_4: 3.716  loss_ce_5: 3.096  loss_mask_5: 0.6381  loss_dice_5: 3.708  loss_ce_6: 3.109  loss_mask_6: 0.6374  loss_dice_6: 3.696  loss_ce_7: 3.107  loss_mask_7: 0.6371  loss_dice_7: 3.693  loss_ce_8: 3.137  loss_mask_8: 0.6387  loss_dice_8: 3.69  time: 1.7081  data_time: 0.3479  lr: 9.2999e-06  max_mem: 17674M
[01/19 02:16:48] d2.utils.events INFO:  eta: 17:23:02  iter: 3119  total_loss: 75.41  loss_ce: 3.047  loss_mask: 0.6356  loss_dice: 3.676  loss_ce_0: 4.37  loss_mask_0: 0.6542  loss_dice_0: 3.947  loss_ce_1: 3.163  loss_mask_1: 0.6519  loss_dice_1: 3.819  loss_ce_2: 3.065  loss_mask_2: 0.6459  loss_dice_2: 3.752  loss_ce_3: 3.016  loss_mask_3: 0.6405  loss_dice_3: 3.716  loss_ce_4: 2.996  loss_mask_4: 0.6389  loss_dice_4: 3.715  loss_ce_5: 2.999  loss_mask_5: 0.6375  loss_dice_5: 3.708  loss_ce_6: 3.011  loss_mask_6: 0.6346  loss_dice_6: 3.692  loss_ce_7: 3.037  loss_mask_7: 0.6354  loss_dice_7: 3.688  loss_ce_8: 3.044  loss_mask_8: 0.6372  loss_dice_8: 3.683  time: 1.7081  data_time: 0.3386  lr: 9.2954e-06  max_mem: 17674M
[01/19 02:17:22] d2.utils.events INFO:  eta: 17:22:42  iter: 3139  total_loss: 75.7  loss_ce: 3.012  loss_mask: 0.6187  loss_dice: 3.698  loss_ce_0: 4.302  loss_mask_0: 0.6212  loss_dice_0: 3.953  loss_ce_1: 3.126  loss_mask_1: 0.6303  loss_dice_1: 3.825  loss_ce_2: 3.002  loss_mask_2: 0.6273  loss_dice_2: 3.759  loss_ce_3: 2.976  loss_mask_3: 0.6192  loss_dice_3: 3.721  loss_ce_4: 2.96  loss_mask_4: 0.6183  loss_dice_4: 3.724  loss_ce_5: 2.977  loss_mask_5: 0.6167  loss_dice_5: 3.716  loss_ce_6: 2.979  loss_mask_6: 0.6176  loss_dice_6: 3.709  loss_ce_7: 2.972  loss_mask_7: 0.6182  loss_dice_7: 3.711  loss_ce_8: 2.968  loss_mask_8: 0.6198  loss_dice_8: 3.708  time: 1.7081  data_time: 0.3532  lr: 9.2909e-06  max_mem: 17674M
[01/19 02:17:56] d2.utils.events INFO:  eta: 17:22:08  iter: 3159  total_loss: 75.31  loss_ce: 3.048  loss_mask: 0.6274  loss_dice: 3.688  loss_ce_0: 4.328  loss_mask_0: 0.6318  loss_dice_0: 3.943  loss_ce_1: 3.237  loss_mask_1: 0.6443  loss_dice_1: 3.817  loss_ce_2: 3.092  loss_mask_2: 0.6392  loss_dice_2: 3.741  loss_ce_3: 3.078  loss_mask_3: 0.6329  loss_dice_3: 3.705  loss_ce_4: 3.055  loss_mask_4: 0.6296  loss_dice_4: 3.706  loss_ce_5: 3.043  loss_mask_5: 0.6279  loss_dice_5: 3.698  loss_ce_6: 3.058  loss_mask_6: 0.6324  loss_dice_6: 3.683  loss_ce_7: 3.04  loss_mask_7: 0.6262  loss_dice_7: 3.682  loss_ce_8: 3.051  loss_mask_8: 0.6271  loss_dice_8: 3.69  time: 1.7081  data_time: 0.3384  lr: 9.2863e-06  max_mem: 17674M
[01/19 02:18:30] d2.utils.events INFO:  eta: 17:21:00  iter: 3179  total_loss: 75.15  loss_ce: 3.015  loss_mask: 0.634  loss_dice: 3.693  loss_ce_0: 4.35  loss_mask_0: 0.6352  loss_dice_0: 3.962  loss_ce_1: 3.12  loss_mask_1: 0.6394  loss_dice_1: 3.834  loss_ce_2: 3.024  loss_mask_2: 0.6392  loss_dice_2: 3.757  loss_ce_3: 2.994  loss_mask_3: 0.6371  loss_dice_3: 3.712  loss_ce_4: 2.984  loss_mask_4: 0.6371  loss_dice_4: 3.711  loss_ce_5: 2.986  loss_mask_5: 0.6367  loss_dice_5: 3.705  loss_ce_6: 2.99  loss_mask_6: 0.6345  loss_dice_6: 3.696  loss_ce_7: 2.991  loss_mask_7: 0.6364  loss_dice_7: 3.698  loss_ce_8: 2.996  loss_mask_8: 0.6349  loss_dice_8: 3.691  time: 1.7080  data_time: 0.3438  lr: 9.2818e-06  max_mem: 17674M
[01/19 02:19:04] d2.utils.events INFO:  eta: 17:20:13  iter: 3199  total_loss: 74.54  loss_ce: 2.904  loss_mask: 0.6399  loss_dice: 3.712  loss_ce_0: 4.225  loss_mask_0: 0.6393  loss_dice_0: 3.958  loss_ce_1: 3.077  loss_mask_1: 0.6521  loss_dice_1: 3.837  loss_ce_2: 2.956  loss_mask_2: 0.6442  loss_dice_2: 3.764  loss_ce_3: 2.907  loss_mask_3: 0.6364  loss_dice_3: 3.741  loss_ce_4: 2.864  loss_mask_4: 0.6405  loss_dice_4: 3.729  loss_ce_5: 2.87  loss_mask_5: 0.6429  loss_dice_5: 3.726  loss_ce_6: 2.894  loss_mask_6: 0.6401  loss_dice_6: 3.721  loss_ce_7: 2.862  loss_mask_7: 0.6416  loss_dice_7: 3.715  loss_ce_8: 2.872  loss_mask_8: 0.6402  loss_dice_8: 3.716  time: 1.7080  data_time: 0.3364  lr: 9.2773e-06  max_mem: 17674M
[01/19 02:19:39] d2.utils.events INFO:  eta: 17:19:52  iter: 3219  total_loss: 75.27  loss_ce: 2.975  loss_mask: 0.6452  loss_dice: 3.677  loss_ce_0: 4.396  loss_mask_0: 0.6449  loss_dice_0: 3.945  loss_ce_1: 3.175  loss_mask_1: 0.6546  loss_dice_1: 3.81  loss_ce_2: 3.032  loss_mask_2: 0.6507  loss_dice_2: 3.742  loss_ce_3: 2.983  loss_mask_3: 0.6451  loss_dice_3: 3.698  loss_ce_4: 2.955  loss_mask_4: 0.6462  loss_dice_4: 3.697  loss_ce_5: 2.938  loss_mask_5: 0.6454  loss_dice_5: 3.687  loss_ce_6: 2.94  loss_mask_6: 0.6437  loss_dice_6: 3.679  loss_ce_7: 2.943  loss_mask_7: 0.646  loss_dice_7: 3.673  loss_ce_8: 2.958  loss_mask_8: 0.6456  loss_dice_8: 3.68  time: 1.7081  data_time: 0.3693  lr: 9.2727e-06  max_mem: 17674M
[01/19 02:20:13] d2.utils.events INFO:  eta: 17:18:41  iter: 3239  total_loss: 75.33  loss_ce: 3.12  loss_mask: 0.6446  loss_dice: 3.637  loss_ce_0: 4.384  loss_mask_0: 0.6492  loss_dice_0: 3.916  loss_ce_1: 3.304  loss_mask_1: 0.6513  loss_dice_1: 3.763  loss_ce_2: 3.138  loss_mask_2: 0.6461  loss_dice_2: 3.688  loss_ce_3: 3.108  loss_mask_3: 0.6425  loss_dice_3: 3.651  loss_ce_4: 3.095  loss_mask_4: 0.642  loss_dice_4: 3.651  loss_ce_5: 3.088  loss_mask_5: 0.6389  loss_dice_5: 3.651  loss_ce_6: 3.085  loss_mask_6: 0.64  loss_dice_6: 3.636  loss_ce_7: 3.076  loss_mask_7: 0.6422  loss_dice_7: 3.629  loss_ce_8: 3.074  loss_mask_8: 0.6416  loss_dice_8: 3.64  time: 1.7080  data_time: 0.3528  lr: 9.2682e-06  max_mem: 17674M
[01/19 02:20:47] d2.utils.events INFO:  eta: 17:17:31  iter: 3259  total_loss: 74.97  loss_ce: 3.042  loss_mask: 0.6492  loss_dice: 3.66  loss_ce_0: 4.336  loss_mask_0: 0.6601  loss_dice_0: 3.926  loss_ce_1: 3.198  loss_mask_1: 0.6565  loss_dice_1: 3.779  loss_ce_2: 3.071  loss_mask_2: 0.6493  loss_dice_2: 3.724  loss_ce_3: 3.035  loss_mask_3: 0.6512  loss_dice_3: 3.683  loss_ce_4: 3.016  loss_mask_4: 0.649  loss_dice_4: 3.681  loss_ce_5: 3.008  loss_mask_5: 0.6457  loss_dice_5: 3.675  loss_ce_6: 3.036  loss_mask_6: 0.6451  loss_dice_6: 3.663  loss_ce_7: 3.027  loss_mask_7: 0.6482  loss_dice_7: 3.665  loss_ce_8: 3.034  loss_mask_8: 0.6486  loss_dice_8: 3.658  time: 1.7079  data_time: 0.3511  lr: 9.2636e-06  max_mem: 17674M
[01/19 02:21:21] d2.utils.events INFO:  eta: 17:17:33  iter: 3279  total_loss: 75.63  loss_ce: 3.119  loss_mask: 0.6535  loss_dice: 3.608  loss_ce_0: 4.33  loss_mask_0: 0.6588  loss_dice_0: 3.905  loss_ce_1: 3.304  loss_mask_1: 0.6609  loss_dice_1: 3.754  loss_ce_2: 3.155  loss_mask_2: 0.6622  loss_dice_2: 3.666  loss_ce_3: 3.121  loss_mask_3: 0.6535  loss_dice_3: 3.635  loss_ce_4: 3.099  loss_mask_4: 0.6552  loss_dice_4: 3.626  loss_ce_5: 3.109  loss_mask_5: 0.654  loss_dice_5: 3.62  loss_ce_6: 3.094  loss_mask_6: 0.655  loss_dice_6: 3.619  loss_ce_7: 3.106  loss_mask_7: 0.6575  loss_dice_7: 3.615  loss_ce_8: 3.111  loss_mask_8: 0.6565  loss_dice_8: 3.609  time: 1.7079  data_time: 0.3604  lr: 9.2591e-06  max_mem: 17674M
[01/19 02:21:55] d2.utils.events INFO:  eta: 17:17:19  iter: 3299  total_loss: 74.99  loss_ce: 3.059  loss_mask: 0.6285  loss_dice: 3.698  loss_ce_0: 4.361  loss_mask_0: 0.634  loss_dice_0: 3.949  loss_ce_1: 3.261  loss_mask_1: 0.6376  loss_dice_1: 3.816  loss_ce_2: 3.063  loss_mask_2: 0.6369  loss_dice_2: 3.747  loss_ce_3: 3.043  loss_mask_3: 0.6309  loss_dice_3: 3.711  loss_ce_4: 3.019  loss_mask_4: 0.6293  loss_dice_4: 3.707  loss_ce_5: 3.015  loss_mask_5: 0.6291  loss_dice_5: 3.705  loss_ce_6: 3.037  loss_mask_6: 0.63  loss_dice_6: 3.698  loss_ce_7: 3.018  loss_mask_7: 0.6319  loss_dice_7: 3.699  loss_ce_8: 3.041  loss_mask_8: 0.6303  loss_dice_8: 3.694  time: 1.7079  data_time: 0.3472  lr: 9.2546e-06  max_mem: 17674M
[01/19 02:22:28] d2.utils.events INFO:  eta: 17:16:10  iter: 3319  total_loss: 75.47  loss_ce: 3.092  loss_mask: 0.6383  loss_dice: 3.652  loss_ce_0: 4.279  loss_mask_0: 0.6493  loss_dice_0: 3.917  loss_ce_1: 3.19  loss_mask_1: 0.6477  loss_dice_1: 3.791  loss_ce_2: 3.095  loss_mask_2: 0.6417  loss_dice_2: 3.716  loss_ce_3: 3.067  loss_mask_3: 0.6391  loss_dice_3: 3.674  loss_ce_4: 3.058  loss_mask_4: 0.6368  loss_dice_4: 3.667  loss_ce_5: 3.054  loss_mask_5: 0.6393  loss_dice_5: 3.667  loss_ce_6: 3.048  loss_mask_6: 0.6374  loss_dice_6: 3.659  loss_ce_7: 3.041  loss_mask_7: 0.6397  loss_dice_7: 3.658  loss_ce_8: 3.068  loss_mask_8: 0.6396  loss_dice_8: 3.655  time: 1.7078  data_time: 0.3283  lr: 9.25e-06  max_mem: 17674M
[01/19 02:23:03] d2.utils.events INFO:  eta: 17:15:19  iter: 3339  total_loss: 75.08  loss_ce: 3.01  loss_mask: 0.6369  loss_dice: 3.645  loss_ce_0: 4.213  loss_mask_0: 0.6371  loss_dice_0: 3.935  loss_ce_1: 3.15  loss_mask_1: 0.6459  loss_dice_1: 3.79  loss_ce_2: 3.028  loss_mask_2: 0.6394  loss_dice_2: 3.717  loss_ce_3: 3.001  loss_mask_3: 0.6381  loss_dice_3: 3.675  loss_ce_4: 2.969  loss_mask_4: 0.6379  loss_dice_4: 3.673  loss_ce_5: 2.986  loss_mask_5: 0.6425  loss_dice_5: 3.662  loss_ce_6: 2.982  loss_mask_6: 0.64  loss_dice_6: 3.66  loss_ce_7: 2.982  loss_mask_7: 0.6411  loss_dice_7: 3.656  loss_ce_8: 2.979  loss_mask_8: 0.639  loss_dice_8: 3.649  time: 1.7077  data_time: 0.3434  lr: 9.2455e-06  max_mem: 17674M
[01/19 02:23:37] d2.utils.events INFO:  eta: 17:15:18  iter: 3359  total_loss: 74.85  loss_ce: 2.993  loss_mask: 0.6236  loss_dice: 3.661  loss_ce_0: 4.295  loss_mask_0: 0.633  loss_dice_0: 3.925  loss_ce_1: 3.138  loss_mask_1: 0.6412  loss_dice_1: 3.799  loss_ce_2: 3.039  loss_mask_2: 0.6301  loss_dice_2: 3.724  loss_ce_3: 3  loss_mask_3: 0.6312  loss_dice_3: 3.681  loss_ce_4: 2.993  loss_mask_4: 0.6285  loss_dice_4: 3.682  loss_ce_5: 2.983  loss_mask_5: 0.6266  loss_dice_5: 3.67  loss_ce_6: 2.977  loss_mask_6: 0.6247  loss_dice_6: 3.656  loss_ce_7: 2.955  loss_mask_7: 0.6262  loss_dice_7: 3.659  loss_ce_8: 2.967  loss_mask_8: 0.6243  loss_dice_8: 3.657  time: 1.7077  data_time: 0.3380  lr: 9.2409e-06  max_mem: 17674M
[01/19 02:24:11] d2.utils.events INFO:  eta: 17:15:21  iter: 3379  total_loss: 75.83  loss_ce: 3.148  loss_mask: 0.6647  loss_dice: 3.576  loss_ce_0: 4.353  loss_mask_0: 0.6636  loss_dice_0: 3.883  loss_ce_1: 3.267  loss_mask_1: 0.6732  loss_dice_1: 3.731  loss_ce_2: 3.164  loss_mask_2: 0.6724  loss_dice_2: 3.656  loss_ce_3: 3.144  loss_mask_3: 0.665  loss_dice_3: 3.61  loss_ce_4: 3.119  loss_mask_4: 0.6639  loss_dice_4: 3.606  loss_ce_5: 3.127  loss_mask_5: 0.6687  loss_dice_5: 3.598  loss_ce_6: 3.141  loss_mask_6: 0.6653  loss_dice_6: 3.582  loss_ce_7: 3.138  loss_mask_7: 0.669  loss_dice_7: 3.585  loss_ce_8: 3.145  loss_mask_8: 0.6673  loss_dice_8: 3.59  time: 1.7076  data_time: 0.3494  lr: 9.2364e-06  max_mem: 17674M
[01/19 02:24:44] d2.utils.events INFO:  eta: 17:14:30  iter: 3399  total_loss: 74.56  loss_ce: 2.94  loss_mask: 0.6336  loss_dice: 3.663  loss_ce_0: 4.246  loss_mask_0: 0.6527  loss_dice_0: 3.933  loss_ce_1: 3.069  loss_mask_1: 0.6543  loss_dice_1: 3.789  loss_ce_2: 2.934  loss_mask_2: 0.6448  loss_dice_2: 3.723  loss_ce_3: 2.913  loss_mask_3: 0.6382  loss_dice_3: 3.692  loss_ce_4: 2.919  loss_mask_4: 0.6403  loss_dice_4: 3.683  loss_ce_5: 2.892  loss_mask_5: 0.6418  loss_dice_5: 3.677  loss_ce_6: 2.922  loss_mask_6: 0.6378  loss_dice_6: 3.669  loss_ce_7: 2.92  loss_mask_7: 0.6381  loss_dice_7: 3.667  loss_ce_8: 2.92  loss_mask_8: 0.6375  loss_dice_8: 3.663  time: 1.7075  data_time: 0.3453  lr: 9.2319e-06  max_mem: 17674M
[01/19 02:25:19] d2.utils.events INFO:  eta: 17:14:34  iter: 3419  total_loss: 75.4  loss_ce: 3.099  loss_mask: 0.6454  loss_dice: 3.624  loss_ce_0: 4.315  loss_mask_0: 0.6413  loss_dice_0: 3.911  loss_ce_1: 3.261  loss_mask_1: 0.6563  loss_dice_1: 3.764  loss_ce_2: 3.108  loss_mask_2: 0.6508  loss_dice_2: 3.685  loss_ce_3: 3.088  loss_mask_3: 0.6458  loss_dice_3: 3.656  loss_ce_4: 3.07  loss_mask_4: 0.6465  loss_dice_4: 3.647  loss_ce_5: 3.068  loss_mask_5: 0.6453  loss_dice_5: 3.643  loss_ce_6: 3.064  loss_mask_6: 0.6438  loss_dice_6: 3.634  loss_ce_7: 3.066  loss_mask_7: 0.6428  loss_dice_7: 3.631  loss_ce_8: 3.071  loss_mask_8: 0.646  loss_dice_8: 3.624  time: 1.7075  data_time: 0.3556  lr: 9.2273e-06  max_mem: 17674M
[01/19 02:25:53] d2.utils.events INFO:  eta: 17:13:26  iter: 3439  total_loss: 75.02  loss_ce: 3.042  loss_mask: 0.6316  loss_dice: 3.69  loss_ce_0: 4.288  loss_mask_0: 0.6352  loss_dice_0: 3.962  loss_ce_1: 3.209  loss_mask_1: 0.6439  loss_dice_1: 3.825  loss_ce_2: 3.071  loss_mask_2: 0.6394  loss_dice_2: 3.749  loss_ce_3: 3.048  loss_mask_3: 0.6353  loss_dice_3: 3.704  loss_ce_4: 3.017  loss_mask_4: 0.6345  loss_dice_4: 3.704  loss_ce_5: 3.014  loss_mask_5: 0.6333  loss_dice_5: 3.697  loss_ce_6: 3.029  loss_mask_6: 0.6314  loss_dice_6: 3.689  loss_ce_7: 3.036  loss_mask_7: 0.6326  loss_dice_7: 3.681  loss_ce_8: 3.014  loss_mask_8: 0.6318  loss_dice_8: 3.688  time: 1.7074  data_time: 0.3639  lr: 9.2228e-06  max_mem: 17674M
[01/19 02:26:27] d2.utils.events INFO:  eta: 17:13:05  iter: 3459  total_loss: 74.6  loss_ce: 2.992  loss_mask: 0.649  loss_dice: 3.613  loss_ce_0: 4.314  loss_mask_0: 0.6519  loss_dice_0: 3.919  loss_ce_1: 3.198  loss_mask_1: 0.6688  loss_dice_1: 3.735  loss_ce_2: 3.088  loss_mask_2: 0.6596  loss_dice_2: 3.669  loss_ce_3: 3.036  loss_mask_3: 0.6511  loss_dice_3: 3.633  loss_ce_4: 2.992  loss_mask_4: 0.6518  loss_dice_4: 3.626  loss_ce_5: 2.995  loss_mask_5: 0.6548  loss_dice_5: 3.631  loss_ce_6: 2.975  loss_mask_6: 0.6541  loss_dice_6: 3.619  loss_ce_7: 2.99  loss_mask_7: 0.6514  loss_dice_7: 3.624  loss_ce_8: 2.999  loss_mask_8: 0.6501  loss_dice_8: 3.613  time: 1.7074  data_time: 0.3355  lr: 9.2182e-06  max_mem: 17674M
[01/19 02:27:00] d2.utils.events INFO:  eta: 17:11:54  iter: 3479  total_loss: 74.12  loss_ce: 2.956  loss_mask: 0.6517  loss_dice: 3.578  loss_ce_0: 4.312  loss_mask_0: 0.6596  loss_dice_0: 3.86  loss_ce_1: 3.136  loss_mask_1: 0.6662  loss_dice_1: 3.719  loss_ce_2: 2.993  loss_mask_2: 0.6595  loss_dice_2: 3.639  loss_ce_3: 2.936  loss_mask_3: 0.6589  loss_dice_3: 3.608  loss_ce_4: 2.939  loss_mask_4: 0.6563  loss_dice_4: 3.604  loss_ce_5: 2.921  loss_mask_5: 0.6532  loss_dice_5: 3.597  loss_ce_6: 2.915  loss_mask_6: 0.6524  loss_dice_6: 3.588  loss_ce_7: 2.93  loss_mask_7: 0.651  loss_dice_7: 3.587  loss_ce_8: 2.934  loss_mask_8: 0.6539  loss_dice_8: 3.589  time: 1.7073  data_time: 0.3267  lr: 9.2137e-06  max_mem: 17674M
[01/19 02:27:35] d2.utils.events INFO:  eta: 17:12:11  iter: 3499  total_loss: 74.66  loss_ce: 2.971  loss_mask: 0.6297  loss_dice: 3.69  loss_ce_0: 4.211  loss_mask_0: 0.6321  loss_dice_0: 3.957  loss_ce_1: 3.124  loss_mask_1: 0.6379  loss_dice_1: 3.823  loss_ce_2: 3.038  loss_mask_2: 0.6347  loss_dice_2: 3.753  loss_ce_3: 2.99  loss_mask_3: 0.6294  loss_dice_3: 3.717  loss_ce_4: 2.95  loss_mask_4: 0.6317  loss_dice_4: 3.717  loss_ce_5: 2.961  loss_mask_5: 0.6281  loss_dice_5: 3.706  loss_ce_6: 2.972  loss_mask_6: 0.6302  loss_dice_6: 3.694  loss_ce_7: 2.978  loss_mask_7: 0.6319  loss_dice_7: 3.698  loss_ce_8: 2.988  loss_mask_8: 0.6287  loss_dice_8: 3.69  time: 1.7074  data_time: 0.3537  lr: 9.2092e-06  max_mem: 17674M
[01/19 02:28:09] d2.utils.events INFO:  eta: 17:10:46  iter: 3519  total_loss: 75.14  loss_ce: 3.027  loss_mask: 0.6375  loss_dice: 3.624  loss_ce_0: 4.323  loss_mask_0: 0.6445  loss_dice_0: 3.908  loss_ce_1: 3.142  loss_mask_1: 0.6509  loss_dice_1: 3.762  loss_ce_2: 3.033  loss_mask_2: 0.645  loss_dice_2: 3.688  loss_ce_3: 3.033  loss_mask_3: 0.6379  loss_dice_3: 3.648  loss_ce_4: 2.99  loss_mask_4: 0.6376  loss_dice_4: 3.647  loss_ce_5: 2.987  loss_mask_5: 0.6389  loss_dice_5: 3.648  loss_ce_6: 3.023  loss_mask_6: 0.6349  loss_dice_6: 3.632  loss_ce_7: 3.003  loss_mask_7: 0.6345  loss_dice_7: 3.638  loss_ce_8: 3.016  loss_mask_8: 0.6373  loss_dice_8: 3.625  time: 1.7073  data_time: 0.3370  lr: 9.2046e-06  max_mem: 17674M
[01/19 02:28:43] d2.utils.events INFO:  eta: 17:10:35  iter: 3539  total_loss: 74.82  loss_ce: 3.009  loss_mask: 0.6303  loss_dice: 3.656  loss_ce_0: 4.277  loss_mask_0: 0.6292  loss_dice_0: 3.935  loss_ce_1: 3.157  loss_mask_1: 0.632  loss_dice_1: 3.792  loss_ce_2: 3.016  loss_mask_2: 0.6251  loss_dice_2: 3.722  loss_ce_3: 2.981  loss_mask_3: 0.6251  loss_dice_3: 3.685  loss_ce_4: 2.979  loss_mask_4: 0.628  loss_dice_4: 3.68  loss_ce_5: 3.002  loss_mask_5: 0.6281  loss_dice_5: 3.674  loss_ce_6: 2.99  loss_mask_6: 0.6304  loss_dice_6: 3.659  loss_ce_7: 3.007  loss_mask_7: 0.6306  loss_dice_7: 3.656  loss_ce_8: 3.001  loss_mask_8: 0.6302  loss_dice_8: 3.661  time: 1.7072  data_time: 0.3523  lr: 9.2001e-06  max_mem: 17674M
[01/19 02:29:17] d2.utils.events INFO:  eta: 17:10:15  iter: 3559  total_loss: 74.6  loss_ce: 3.011  loss_mask: 0.6296  loss_dice: 3.665  loss_ce_0: 4.24  loss_mask_0: 0.6322  loss_dice_0: 3.938  loss_ce_1: 3.216  loss_mask_1: 0.6367  loss_dice_1: 3.792  loss_ce_2: 3.037  loss_mask_2: 0.6322  loss_dice_2: 3.723  loss_ce_3: 3.025  loss_mask_3: 0.6314  loss_dice_3: 3.686  loss_ce_4: 2.988  loss_mask_4: 0.6289  loss_dice_4: 3.682  loss_ce_5: 2.979  loss_mask_5: 0.6284  loss_dice_5: 3.671  loss_ce_6: 2.977  loss_mask_6: 0.6262  loss_dice_6: 3.669  loss_ce_7: 2.983  loss_mask_7: 0.6293  loss_dice_7: 3.666  loss_ce_8: 3.01  loss_mask_8: 0.6278  loss_dice_8: 3.665  time: 1.7072  data_time: 0.3490  lr: 9.1955e-06  max_mem: 17674M
[01/19 02:29:51] d2.utils.events INFO:  eta: 17:09:27  iter: 3579  total_loss: 74.72  loss_ce: 3.045  loss_mask: 0.6407  loss_dice: 3.606  loss_ce_0: 4.303  loss_mask_0: 0.6436  loss_dice_0: 3.91  loss_ce_1: 3.149  loss_mask_1: 0.6503  loss_dice_1: 3.761  loss_ce_2: 3.086  loss_mask_2: 0.6446  loss_dice_2: 3.684  loss_ce_3: 3.061  loss_mask_3: 0.6441  loss_dice_3: 3.647  loss_ce_4: 3.044  loss_mask_4: 0.6438  loss_dice_4: 3.642  loss_ce_5: 3.042  loss_mask_5: 0.6431  loss_dice_5: 3.633  loss_ce_6: 3.056  loss_mask_6: 0.64  loss_dice_6: 3.628  loss_ce_7: 3.025  loss_mask_7: 0.6409  loss_dice_7: 3.626  loss_ce_8: 3.038  loss_mask_8: 0.6453  loss_dice_8: 3.622  time: 1.7072  data_time: 0.3438  lr: 9.191e-06  max_mem: 17674M
[01/19 02:30:25] d2.utils.events INFO:  eta: 17:08:53  iter: 3599  total_loss: 74.28  loss_ce: 2.98  loss_mask: 0.6332  loss_dice: 3.706  loss_ce_0: 4.222  loss_mask_0: 0.6327  loss_dice_0: 3.954  loss_ce_1: 3.076  loss_mask_1: 0.6443  loss_dice_1: 3.837  loss_ce_2: 2.956  loss_mask_2: 0.6397  loss_dice_2: 3.782  loss_ce_3: 2.956  loss_mask_3: 0.6355  loss_dice_3: 3.742  loss_ce_4: 2.921  loss_mask_4: 0.6322  loss_dice_4: 3.73  loss_ce_5: 2.933  loss_mask_5: 0.6304  loss_dice_5: 3.727  loss_ce_6: 2.947  loss_mask_6: 0.6321  loss_dice_6: 3.714  loss_ce_7: 2.931  loss_mask_7: 0.6321  loss_dice_7: 3.715  loss_ce_8: 2.937  loss_mask_8: 0.63  loss_dice_8: 3.721  time: 1.7072  data_time: 0.3276  lr: 9.1865e-06  max_mem: 17674M
[01/19 02:31:00] d2.utils.events INFO:  eta: 17:08:49  iter: 3619  total_loss: 73.65  loss_ce: 2.889  loss_mask: 0.6341  loss_dice: 3.669  loss_ce_0: 4.224  loss_mask_0: 0.6361  loss_dice_0: 3.955  loss_ce_1: 3.064  loss_mask_1: 0.6452  loss_dice_1: 3.806  loss_ce_2: 2.929  loss_mask_2: 0.6406  loss_dice_2: 3.739  loss_ce_3: 2.893  loss_mask_3: 0.6387  loss_dice_3: 3.698  loss_ce_4: 2.868  loss_mask_4: 0.6364  loss_dice_4: 3.694  loss_ce_5: 2.866  loss_mask_5: 0.6369  loss_dice_5: 3.688  loss_ce_6: 2.877  loss_mask_6: 0.6356  loss_dice_6: 3.674  loss_ce_7: 2.847  loss_mask_7: 0.636  loss_dice_7: 3.673  loss_ce_8: 2.87  loss_mask_8: 0.6327  loss_dice_8: 3.679  time: 1.7073  data_time: 0.3505  lr: 9.1819e-06  max_mem: 17674M
[01/19 02:31:34] d2.utils.events INFO:  eta: 17:08:37  iter: 3639  total_loss: 74.52  loss_ce: 2.968  loss_mask: 0.6326  loss_dice: 3.667  loss_ce_0: 4.238  loss_mask_0: 0.6444  loss_dice_0: 3.934  loss_ce_1: 3.121  loss_mask_1: 0.6477  loss_dice_1: 3.789  loss_ce_2: 2.988  loss_mask_2: 0.646  loss_dice_2: 3.721  loss_ce_3: 2.974  loss_mask_3: 0.6371  loss_dice_3: 3.693  loss_ce_4: 2.939  loss_mask_4: 0.6356  loss_dice_4: 3.693  loss_ce_5: 2.937  loss_mask_5: 0.6397  loss_dice_5: 3.685  loss_ce_6: 2.965  loss_mask_6: 0.6388  loss_dice_6: 3.672  loss_ce_7: 2.955  loss_mask_7: 0.6371  loss_dice_7: 3.675  loss_ce_8: 2.965  loss_mask_8: 0.6347  loss_dice_8: 3.667  time: 1.7073  data_time: 0.3351  lr: 9.1774e-06  max_mem: 17674M
[01/19 02:32:08] d2.utils.events INFO:  eta: 17:07:50  iter: 3659  total_loss: 74.71  loss_ce: 3.044  loss_mask: 0.6227  loss_dice: 3.642  loss_ce_0: 4.217  loss_mask_0: 0.6375  loss_dice_0: 3.928  loss_ce_1: 3.166  loss_mask_1: 0.6345  loss_dice_1: 3.776  loss_ce_2: 3.05  loss_mask_2: 0.6326  loss_dice_2: 3.711  loss_ce_3: 3.044  loss_mask_3: 0.6285  loss_dice_3: 3.667  loss_ce_4: 3.009  loss_mask_4: 0.6266  loss_dice_4: 3.671  loss_ce_5: 3.017  loss_mask_5: 0.6235  loss_dice_5: 3.658  loss_ce_6: 3.035  loss_mask_6: 0.622  loss_dice_6: 3.639  loss_ce_7: 3.019  loss_mask_7: 0.6215  loss_dice_7: 3.643  loss_ce_8: 3.012  loss_mask_8: 0.6232  loss_dice_8: 3.645  time: 1.7073  data_time: 0.3576  lr: 9.1728e-06  max_mem: 17674M
[01/19 02:32:42] d2.utils.events INFO:  eta: 17:07:07  iter: 3679  total_loss: 73.98  loss_ce: 2.914  loss_mask: 0.6248  loss_dice: 3.657  loss_ce_0: 4.181  loss_mask_0: 0.6342  loss_dice_0: 3.93  loss_ce_1: 3.028  loss_mask_1: 0.6349  loss_dice_1: 3.793  loss_ce_2: 2.908  loss_mask_2: 0.631  loss_dice_2: 3.722  loss_ce_3: 2.898  loss_mask_3: 0.6212  loss_dice_3: 3.688  loss_ce_4: 2.883  loss_mask_4: 0.6219  loss_dice_4: 3.678  loss_ce_5: 2.867  loss_mask_5: 0.62  loss_dice_5: 3.685  loss_ce_6: 2.904  loss_mask_6: 0.6216  loss_dice_6: 3.669  loss_ce_7: 2.888  loss_mask_7: 0.6233  loss_dice_7: 3.664  loss_ce_8: 2.898  loss_mask_8: 0.6232  loss_dice_8: 3.665  time: 1.7073  data_time: 0.3459  lr: 9.1683e-06  max_mem: 17674M
[01/19 02:33:16] d2.utils.events INFO:  eta: 17:06:31  iter: 3699  total_loss: 73.75  loss_ce: 2.858  loss_mask: 0.6311  loss_dice: 3.692  loss_ce_0: 4.196  loss_mask_0: 0.6311  loss_dice_0: 3.951  loss_ce_1: 3.032  loss_mask_1: 0.6394  loss_dice_1: 3.822  loss_ce_2: 2.877  loss_mask_2: 0.6372  loss_dice_2: 3.757  loss_ce_3: 2.855  loss_mask_3: 0.6338  loss_dice_3: 3.716  loss_ce_4: 2.832  loss_mask_4: 0.6334  loss_dice_4: 3.714  loss_ce_5: 2.826  loss_mask_5: 0.6325  loss_dice_5: 3.711  loss_ce_6: 2.848  loss_mask_6: 0.6303  loss_dice_6: 3.701  loss_ce_7: 2.828  loss_mask_7: 0.6333  loss_dice_7: 3.694  loss_ce_8: 2.833  loss_mask_8: 0.6307  loss_dice_8: 3.697  time: 1.7072  data_time: 0.3505  lr: 9.1637e-06  max_mem: 17674M
[01/19 02:33:51] d2.utils.events INFO:  eta: 17:06:21  iter: 3719  total_loss: 75.13  loss_ce: 3.118  loss_mask: 0.6412  loss_dice: 3.599  loss_ce_0: 4.265  loss_mask_0: 0.656  loss_dice_0: 3.893  loss_ce_1: 3.244  loss_mask_1: 0.6557  loss_dice_1: 3.734  loss_ce_2: 3.129  loss_mask_2: 0.651  loss_dice_2: 3.659  loss_ce_3: 3.085  loss_mask_3: 0.6455  loss_dice_3: 3.622  loss_ce_4: 3.066  loss_mask_4: 0.6438  loss_dice_4: 3.623  loss_ce_5: 3.064  loss_mask_5: 0.6426  loss_dice_5: 3.616  loss_ce_6: 3.089  loss_mask_6: 0.6427  loss_dice_6: 3.608  loss_ce_7: 3.078  loss_mask_7: 0.642  loss_dice_7: 3.603  loss_ce_8: 3.094  loss_mask_8: 0.6394  loss_dice_8: 3.6  time: 1.7072  data_time: 0.3429  lr: 9.1592e-06  max_mem: 17674M
[01/19 02:34:24] d2.utils.events INFO:  eta: 17:05:47  iter: 3739  total_loss: 74  loss_ce: 2.936  loss_mask: 0.6158  loss_dice: 3.647  loss_ce_0: 4.149  loss_mask_0: 0.6308  loss_dice_0: 3.91  loss_ce_1: 3.121  loss_mask_1: 0.6305  loss_dice_1: 3.765  loss_ce_2: 2.941  loss_mask_2: 0.6255  loss_dice_2: 3.706  loss_ce_3: 2.918  loss_mask_3: 0.6182  loss_dice_3: 3.674  loss_ce_4: 2.889  loss_mask_4: 0.6163  loss_dice_4: 3.67  loss_ce_5: 2.9  loss_mask_5: 0.6187  loss_dice_5: 3.656  loss_ce_6: 2.913  loss_mask_6: 0.6193  loss_dice_6: 3.653  loss_ce_7: 2.901  loss_mask_7: 0.6205  loss_dice_7: 3.65  loss_ce_8: 2.923  loss_mask_8: 0.6209  loss_dice_8: 3.654  time: 1.7071  data_time: 0.3458  lr: 9.1547e-06  max_mem: 17674M
[01/19 02:34:58] d2.utils.events INFO:  eta: 17:05:28  iter: 3759  total_loss: 73.12  loss_ce: 2.796  loss_mask: 0.6337  loss_dice: 3.68  loss_ce_0: 4.132  loss_mask_0: 0.6395  loss_dice_0: 3.94  loss_ce_1: 2.959  loss_mask_1: 0.6418  loss_dice_1: 3.821  loss_ce_2: 2.841  loss_mask_2: 0.6366  loss_dice_2: 3.746  loss_ce_3: 2.813  loss_mask_3: 0.6342  loss_dice_3: 3.709  loss_ce_4: 2.788  loss_mask_4: 0.6336  loss_dice_4: 3.708  loss_ce_5: 2.798  loss_mask_5: 0.6318  loss_dice_5: 3.698  loss_ce_6: 2.77  loss_mask_6: 0.6322  loss_dice_6: 3.685  loss_ce_7: 2.783  loss_mask_7: 0.6332  loss_dice_7: 3.687  loss_ce_8: 2.805  loss_mask_8: 0.6349  loss_dice_8: 3.682  time: 1.7071  data_time: 0.3353  lr: 9.1501e-06  max_mem: 17674M
[01/19 02:35:33] d2.utils.events INFO:  eta: 17:04:39  iter: 3779  total_loss: 74.27  loss_ce: 3.01  loss_mask: 0.6477  loss_dice: 3.596  loss_ce_0: 4.251  loss_mask_0: 0.6534  loss_dice_0: 3.864  loss_ce_1: 3.165  loss_mask_1: 0.6588  loss_dice_1: 3.724  loss_ce_2: 3.017  loss_mask_2: 0.6537  loss_dice_2: 3.65  loss_ce_3: 2.999  loss_mask_3: 0.6507  loss_dice_3: 3.62  loss_ce_4: 2.98  loss_mask_4: 0.6505  loss_dice_4: 3.616  loss_ce_5: 2.992  loss_mask_5: 0.6505  loss_dice_5: 3.602  loss_ce_6: 2.993  loss_mask_6: 0.6481  loss_dice_6: 3.604  loss_ce_7: 2.977  loss_mask_7: 0.6492  loss_dice_7: 3.601  loss_ce_8: 2.996  loss_mask_8: 0.6471  loss_dice_8: 3.6  time: 1.7071  data_time: 0.3472  lr: 9.1456e-06  max_mem: 17674M
[01/19 02:36:06] d2.utils.events INFO:  eta: 17:04:02  iter: 3799  total_loss: 73.61  loss_ce: 2.929  loss_mask: 0.6325  loss_dice: 3.615  loss_ce_0: 4.108  loss_mask_0: 0.6342  loss_dice_0: 3.907  loss_ce_1: 3.065  loss_mask_1: 0.6453  loss_dice_1: 3.755  loss_ce_2: 2.914  loss_mask_2: 0.6415  loss_dice_2: 3.684  loss_ce_3: 2.911  loss_mask_3: 0.6413  loss_dice_3: 3.637  loss_ce_4: 2.873  loss_mask_4: 0.6356  loss_dice_4: 3.63  loss_ce_5: 2.902  loss_mask_5: 0.638  loss_dice_5: 3.632  loss_ce_6: 2.918  loss_mask_6: 0.6372  loss_dice_6: 3.622  loss_ce_7: 2.898  loss_mask_7: 0.6335  loss_dice_7: 3.626  loss_ce_8: 2.921  loss_mask_8: 0.636  loss_dice_8: 3.616  time: 1.7070  data_time: 0.3456  lr: 9.141e-06  max_mem: 17674M
[01/19 02:36:40] d2.utils.events INFO:  eta: 17:03:10  iter: 3819  total_loss: 74.01  loss_ce: 2.902  loss_mask: 0.6499  loss_dice: 3.627  loss_ce_0: 4.147  loss_mask_0: 0.6433  loss_dice_0: 3.922  loss_ce_1: 3.039  loss_mask_1: 0.6558  loss_dice_1: 3.762  loss_ce_2: 2.894  loss_mask_2: 0.6508  loss_dice_2: 3.69  loss_ce_3: 2.899  loss_mask_3: 0.6465  loss_dice_3: 3.653  loss_ce_4: 2.877  loss_mask_4: 0.6481  loss_dice_4: 3.65  loss_ce_5: 2.862  loss_mask_5: 0.6488  loss_dice_5: 3.643  loss_ce_6: 2.849  loss_mask_6: 0.6476  loss_dice_6: 3.632  loss_ce_7: 2.878  loss_mask_7: 0.6507  loss_dice_7: 3.634  loss_ce_8: 2.887  loss_mask_8: 0.6481  loss_dice_8: 3.63  time: 1.7069  data_time: 0.3471  lr: 9.1365e-06  max_mem: 17674M
[01/19 02:37:14] d2.utils.events INFO:  eta: 17:02:36  iter: 3839  total_loss: 74.62  loss_ce: 3.044  loss_mask: 0.6534  loss_dice: 3.626  loss_ce_0: 4.15  loss_mask_0: 0.6552  loss_dice_0: 3.883  loss_ce_1: 3.162  loss_mask_1: 0.6648  loss_dice_1: 3.759  loss_ce_2: 3.051  loss_mask_2: 0.6609  loss_dice_2: 3.689  loss_ce_3: 3.031  loss_mask_3: 0.6536  loss_dice_3: 3.652  loss_ce_4: 2.993  loss_mask_4: 0.6555  loss_dice_4: 3.645  loss_ce_5: 2.991  loss_mask_5: 0.6551  loss_dice_5: 3.64  loss_ce_6: 3  loss_mask_6: 0.6576  loss_dice_6: 3.632  loss_ce_7: 3.013  loss_mask_7: 0.6563  loss_dice_7: 3.627  loss_ce_8: 3.008  loss_mask_8: 0.6547  loss_dice_8: 3.629  time: 1.7068  data_time: 0.3182  lr: 9.1319e-06  max_mem: 17674M
[01/19 02:37:48] d2.utils.events INFO:  eta: 17:01:30  iter: 3859  total_loss: 74.08  loss_ce: 2.978  loss_mask: 0.6431  loss_dice: 3.602  loss_ce_0: 4.149  loss_mask_0: 0.6504  loss_dice_0: 3.898  loss_ce_1: 3.076  loss_mask_1: 0.6523  loss_dice_1: 3.75  loss_ce_2: 2.939  loss_mask_2: 0.645  loss_dice_2: 3.674  loss_ce_3: 2.955  loss_mask_3: 0.6439  loss_dice_3: 3.632  loss_ce_4: 2.925  loss_mask_4: 0.6447  loss_dice_4: 3.62  loss_ce_5: 2.94  loss_mask_5: 0.6453  loss_dice_5: 3.617  loss_ce_6: 2.941  loss_mask_6: 0.6455  loss_dice_6: 3.606  loss_ce_7: 2.947  loss_mask_7: 0.6455  loss_dice_7: 3.607  loss_ce_8: 2.947  loss_mask_8: 0.6429  loss_dice_8: 3.611  time: 1.7066  data_time: 0.3220  lr: 9.1274e-06  max_mem: 17674M
[01/19 02:38:21] d2.utils.events INFO:  eta: 17:00:22  iter: 3879  total_loss: 73.92  loss_ce: 3  loss_mask: 0.6311  loss_dice: 3.632  loss_ce_0: 4.206  loss_mask_0: 0.6442  loss_dice_0: 3.899  loss_ce_1: 3.142  loss_mask_1: 0.64  loss_dice_1: 3.758  loss_ce_2: 3.01  loss_mask_2: 0.6376  loss_dice_2: 3.68  loss_ce_3: 2.99  loss_mask_3: 0.6326  loss_dice_3: 3.642  loss_ce_4: 2.979  loss_mask_4: 0.6328  loss_dice_4: 3.65  loss_ce_5: 2.987  loss_mask_5: 0.63  loss_dice_5: 3.648  loss_ce_6: 2.991  loss_mask_6: 0.6295  loss_dice_6: 3.632  loss_ce_7: 2.984  loss_mask_7: 0.6301  loss_dice_7: 3.636  loss_ce_8: 2.995  loss_mask_8: 0.6332  loss_dice_8: 3.636  time: 1.7065  data_time: 0.3393  lr: 9.1228e-06  max_mem: 17674M
[01/19 02:38:56] d2.utils.events INFO:  eta: 16:59:36  iter: 3899  total_loss: 74.66  loss_ce: 3.032  loss_mask: 0.6388  loss_dice: 3.599  loss_ce_0: 4.208  loss_mask_0: 0.6411  loss_dice_0: 3.878  loss_ce_1: 3.2  loss_mask_1: 0.6521  loss_dice_1: 3.72  loss_ce_2: 3.065  loss_mask_2: 0.6455  loss_dice_2: 3.646  loss_ce_3: 3.014  loss_mask_3: 0.6414  loss_dice_3: 3.609  loss_ce_4: 2.985  loss_mask_4: 0.6401  loss_dice_4: 3.607  loss_ce_5: 3.004  loss_mask_5: 0.6384  loss_dice_5: 3.612  loss_ce_6: 3.023  loss_mask_6: 0.6373  loss_dice_6: 3.602  loss_ce_7: 3.025  loss_mask_7: 0.6352  loss_dice_7: 3.599  loss_ce_8: 3.013  loss_mask_8: 0.6359  loss_dice_8: 3.594  time: 1.7065  data_time: 0.3477  lr: 9.1183e-06  max_mem: 17674M
[01/19 02:39:30] d2.utils.events INFO:  eta: 16:59:02  iter: 3919  total_loss: 73.65  loss_ce: 2.936  loss_mask: 0.6363  loss_dice: 3.63  loss_ce_0: 4.189  loss_mask_0: 0.6455  loss_dice_0: 3.913  loss_ce_1: 3.061  loss_mask_1: 0.6528  loss_dice_1: 3.757  loss_ce_2: 2.944  loss_mask_2: 0.6465  loss_dice_2: 3.689  loss_ce_3: 2.909  loss_mask_3: 0.6404  loss_dice_3: 3.65  loss_ce_4: 2.879  loss_mask_4: 0.6452  loss_dice_4: 3.655  loss_ce_5: 2.905  loss_mask_5: 0.6431  loss_dice_5: 3.647  loss_ce_6: 2.921  loss_mask_6: 0.6361  loss_dice_6: 3.63  loss_ce_7: 2.921  loss_mask_7: 0.6375  loss_dice_7: 3.625  loss_ce_8: 2.918  loss_mask_8: 0.6351  loss_dice_8: 3.635  time: 1.7066  data_time: 0.3417  lr: 9.1137e-06  max_mem: 17674M
[01/19 02:40:04] d2.utils.events INFO:  eta: 16:58:36  iter: 3939  total_loss: 73.31  loss_ce: 2.919  loss_mask: 0.6403  loss_dice: 3.593  loss_ce_0: 4.112  loss_mask_0: 0.6649  loss_dice_0: 3.885  loss_ce_1: 3.034  loss_mask_1: 0.6584  loss_dice_1: 3.729  loss_ce_2: 2.886  loss_mask_2: 0.6476  loss_dice_2: 3.67  loss_ce_3: 2.906  loss_mask_3: 0.6422  loss_dice_3: 3.629  loss_ce_4: 2.872  loss_mask_4: 0.6422  loss_dice_4: 3.622  loss_ce_5: 2.88  loss_mask_5: 0.6438  loss_dice_5: 3.617  loss_ce_6: 2.905  loss_mask_6: 0.6458  loss_dice_6: 3.603  loss_ce_7: 2.903  loss_mask_7: 0.6446  loss_dice_7: 3.602  loss_ce_8: 2.896  loss_mask_8: 0.644  loss_dice_8: 3.6  time: 1.7065  data_time: 0.3271  lr: 9.1092e-06  max_mem: 17674M
[01/19 02:40:38] d2.utils.events INFO:  eta: 16:58:02  iter: 3959  total_loss: 73.82  loss_ce: 2.969  loss_mask: 0.6392  loss_dice: 3.608  loss_ce_0: 4.085  loss_mask_0: 0.641  loss_dice_0: 3.897  loss_ce_1: 3.133  loss_mask_1: 0.6496  loss_dice_1: 3.745  loss_ce_2: 3.005  loss_mask_2: 0.6465  loss_dice_2: 3.675  loss_ce_3: 2.99  loss_mask_3: 0.6417  loss_dice_3: 3.639  loss_ce_4: 2.941  loss_mask_4: 0.6418  loss_dice_4: 3.629  loss_ce_5: 2.933  loss_mask_5: 0.6388  loss_dice_5: 3.632  loss_ce_6: 2.927  loss_mask_6: 0.6414  loss_dice_6: 3.618  loss_ce_7: 2.927  loss_mask_7: 0.6406  loss_dice_7: 3.616  loss_ce_8: 2.957  loss_mask_8: 0.6398  loss_dice_8: 3.616  time: 1.7065  data_time: 0.3545  lr: 9.1046e-06  max_mem: 17674M
[01/19 02:41:12] d2.utils.events INFO:  eta: 16:57:04  iter: 3979  total_loss: 73.35  loss_ce: 2.845  loss_mask: 0.6211  loss_dice: 3.67  loss_ce_0: 4.119  loss_mask_0: 0.6359  loss_dice_0: 3.932  loss_ce_1: 2.955  loss_mask_1: 0.6352  loss_dice_1: 3.799  loss_ce_2: 2.813  loss_mask_2: 0.6292  loss_dice_2: 3.733  loss_ce_3: 2.836  loss_mask_3: 0.6225  loss_dice_3: 3.693  loss_ce_4: 2.823  loss_mask_4: 0.6266  loss_dice_4: 3.688  loss_ce_5: 2.822  loss_mask_5: 0.6247  loss_dice_5: 3.691  loss_ce_6: 2.824  loss_mask_6: 0.6242  loss_dice_6: 3.678  loss_ce_7: 2.822  loss_mask_7: 0.623  loss_dice_7: 3.679  loss_ce_8: 2.85  loss_mask_8: 0.6219  loss_dice_8: 3.673  time: 1.7064  data_time: 0.3386  lr: 9.1001e-06  max_mem: 17674M
[01/19 02:41:46] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 02:41:46] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 02:41:46] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 02:46:55] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 5.1132425531418, 'error_1pix': 0.6287042013383815, 'error_3pix': 0.3797977337166383, 'mIoU': 3.378880605595574, 'fwIoU': 13.949987049712295, 'IoU-0': nan, 'IoU-1': 93.95585333497387, 'IoU-2': 4.696919488058547, 'IoU-3': 29.42404449741756, 'IoU-4': 17.152113517639364, 'IoU-5': 20.577137747605107, 'IoU-6': 9.940262179569109, 'IoU-7': 7.042320143087316, 'IoU-8': 3.3542363387322602, 'IoU-9': 0.27596642859793197, 'IoU-10': 13.540990609265222, 'IoU-11': 7.687671302510559, 'IoU-12': 16.200716823371337, 'IoU-13': 0.5805437725715689, 'IoU-14': 9.6602145811595, 'IoU-15': 5.744869830794353, 'IoU-16': 6.430396650367679, 'IoU-17': 4.203469429639832, 'IoU-18': 1.4000806643638715, 'IoU-19': 2.4377229670463536, 'IoU-20': 5.148417418019634, 'IoU-21': 7.784173479313468, 'IoU-22': 0.34132498104285053, 'IoU-23': 7.944506911799606, 'IoU-24': 0.11057381216808833, 'IoU-25': 2.95730251042726, 'IoU-26': 6.053338672411888, 'IoU-27': 6.196091770150394, 'IoU-28': 2.988403191563899, 'IoU-29': 8.289751364370531, 'IoU-30': 3.3416750077089814, 'IoU-31': 5.7244491165388975, 'IoU-32': 6.7119314836605035, 'IoU-33': 6.752383023267143, 'IoU-34': 6.263800801174872, 'IoU-35': 0.942659287440312, 'IoU-36': 6.4248193034877055, 'IoU-37': 8.033197911247528, 'IoU-38': 6.515699713638934, 'IoU-39': 5.086675360768645, 'IoU-40': 3.9249679225506573, 'IoU-41': 8.018583857106364, 'IoU-42': 5.889465465474862, 'IoU-43': 5.656736211188599, 'IoU-44': 5.998991617227272, 'IoU-45': 2.1228577602851275, 'IoU-46': 5.905019576501468, 'IoU-47': 4.5495198847221365, 'IoU-48': 7.4726214296303315, 'IoU-49': 4.019965492437503, 'IoU-50': 7.984962655659925, 'IoU-51': 3.695838391640215, 'IoU-52': 2.636280380693728, 'IoU-53': 2.58915889268643, 'IoU-54': 3.120411310212813, 'IoU-55': 4.123659369565537, 'IoU-56': 5.619146642297512, 'IoU-57': 6.982572539887469, 'IoU-58': 3.513417073159574, 'IoU-59': 4.171464114346427, 'IoU-60': 5.145145588419097, 'IoU-61': 3.5320609842645116, 'IoU-62': 3.3417913087486886, 'IoU-63': 3.272980733892883, 'IoU-64': 4.622312189663346, 'IoU-65': 2.703470241443855, 'IoU-66': 3.804379048639036, 'IoU-67': 3.6116345450289056, 'IoU-68': 4.298696957104559, 'IoU-69': 2.4268826722850427, 'IoU-70': 3.122922545113261, 'IoU-71': 2.9835688130795712, 'IoU-72': 4.061503744680588, 'IoU-73': 2.376095765201424, 'IoU-74': 2.8086205197776852, 'IoU-75': 4.319861459972464, 'IoU-76': 2.6777221629787884, 'IoU-77': 3.8977841207302384, 'IoU-78': 0.53420906951978, 'IoU-79': 1.5674907292263767, 'IoU-80': 3.3534435840659578, 'IoU-81': 2.04528272542485, 'IoU-82': 3.1133845392668005, 'IoU-83': 1.7996742142723838, 'IoU-84': 3.3483061886786265, 'IoU-85': 2.6163031399972434, 'IoU-86': 2.3272631643453865, 'IoU-87': 2.212971344960672, 'IoU-88': 2.7835990876941046, 'IoU-89': 1.2153071025281257, 'IoU-90': 2.490040895351364, 'IoU-91': 1.2407817381712443, 'IoU-92': 3.5996000659721092, 'IoU-93': 3.1594354349572544, 'IoU-94': 2.609614704171635, 'IoU-95': 2.1303858674642693, 'IoU-96': 2.1166105733445075, 'IoU-97': 2.70744887963615, 'IoU-98': 1.982928936720722, 'IoU-99': 3.2566661781822965, 'IoU-100': 1.6624626496223178, 'IoU-101': 1.1840407428891384, 'IoU-102': 1.3447579252944608, 'IoU-103': 3.5155397051023725, 'IoU-104': 0.2837201079400177, 'IoU-105': 1.2585867956618735, 'IoU-106': 2.2517865859390747, 'IoU-107': 2.8029500799310667, 'IoU-108': 3.0402257924527163, 'IoU-109': 2.518980121857318, 'IoU-110': 1.4358466886006445, 'IoU-111': 1.03882756290284, 'IoU-112': 2.469221781745565, 'IoU-113': 1.6959641553074083, 'IoU-114': 1.5271254796768063, 'IoU-115': 0.9471071484635388, 'IoU-116': 1.01824829087967, 'IoU-117': 1.0261402375315545, 'IoU-118': 1.5394998037504837, 'IoU-119': 0.7362546505509938, 'IoU-120': 1.9999671720676078, 'IoU-121': 1.6939997606740431, 'IoU-122': 1.3562102842318489, 'IoU-123': 0.43663023310299004, 'IoU-124': 0.155936323388512, 'IoU-125': 1.6854196516658864, 'IoU-126': 0.46066472248650114, 'IoU-127': 1.0464887489714878, 'IoU-128': 0.7237764009916857, 'IoU-129': 1.4199894027931914, 'IoU-130': 0.4263627412004532, 'IoU-131': 0.9583508345119744, 'IoU-132': 1.5710075305710547, 'IoU-133': 2.169844482464114, 'IoU-134': 0.6678710456843707, 'IoU-135': 0.7291501551142411, 'IoU-136': 0.5429828146681445, 'IoU-137': 0.2929941449626489, 'IoU-138': 0.7855012813267507, 'IoU-139': 1.0866806597021228, 'IoU-140': 0.6295483233631524, 'IoU-141': 0.8134491457211003, 'IoU-142': 0.35074797262957863, 'IoU-143': 0.1006061502600608, 'IoU-144': 0.21241025435201752, 'IoU-145': 0.3343070844579009, 'IoU-146': 0.054599735516877496, 'IoU-147': 0.7476111141570676, 'IoU-148': 1.0892665018019387, 'IoU-149': 0.5604807566976575, 'IoU-150': 0.9555130191065018, 'IoU-151': 0.2856111045826753, 'IoU-152': 0.15244678061362274, 'IoU-153': 0.5731723567085518, 'IoU-154': 0.2734786891297475, 'IoU-155': 0.5858349841689101, 'IoU-156': 0.5192859427691796, 'IoU-157': 0.9509177454129568, 'IoU-158': 0.2472327249153409, 'IoU-159': 0.17564723978207014, 'IoU-160': 0.8726353740999466, 'IoU-161': 0.23236872900905978, 'IoU-162': 0.6453752770117508, 'IoU-163': 0.4597225264037938, 'IoU-164': 0.23387519353912375, 'IoU-165': 1.3170441233133157, 'IoU-166': 0.5535495439179463, 'IoU-167': 0.006667066690668107, 'IoU-168': 0.5462611664084749, 'IoU-169': 0.15793681919198369, 'IoU-170': 0.3390513996773935, 'IoU-171': 0.9960665535080854, 'IoU-172': 0.0, 'IoU-173': 0.22146092316540647, 'IoU-174': 0.03226533841023545, 'IoU-175': 0.5799818022595717, 'IoU-176': 0.0, 'IoU-177': 0.15986183611289018, 'IoU-178': 0.03293333838058826, 'IoU-179': 0.002632511517237888, 'IoU-180': 0.0, 'IoU-181': 0.21255930134128662, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.035714882454176346, 'IoU-185': 0.5997040421610115, 'IoU-186': 0.41129795442964256, 'IoU-187': 1.4510249139019442, 'IoU-188': 1.3492774012021997, 'IoU-189': 1.5782802955672346, 'IoU-190': 1.2559303933754662, 'IoU-191': 0.0030767810716428473, 'IoU-192': 0.20871088417943545, 'mACC': 6.462038198748201, 'pACC': 19.454531864230624, 'ACC-0': nan, 'ACC-1': 97.87427964306042, 'ACC-2': 5.034346267173134, 'ACC-3': 53.48075452165333, 'ACC-4': 23.172512561398992, 'ACC-5': 45.615275478463424, 'ACC-6': 15.424852156726804, 'ACC-7': 8.685838884817192, 'ACC-8': 3.9197527779721, 'ACC-9': 0.2848565941251436, 'ACC-10': 28.998928969079753, 'ACC-11': 11.342078002378624, 'ACC-12': 59.449147197615595, 'ACC-13': 0.6069660529711962, 'ACC-14': 19.040801903405143, 'ACC-15': 10.405546198198742, 'ACC-16': 14.756418289688918, 'ACC-17': 7.551307204096669, 'ACC-18': 1.584944732314333, 'ACC-19': 3.140198104749, 'ACC-20': 9.649818969458579, 'ACC-21': 22.92466647007997, 'ACC-22': 0.35534550765738365, 'ACC-23': 24.130132930452454, 'ACC-24': 0.11282092952185696, 'ACC-25': 4.309836260931591, 'ACC-26': 15.9636878664835, 'ACC-27': 11.19767212039652, 'ACC-28': 3.8695203483919363, 'ACC-29': 24.18001062738852, 'ACC-30': 4.577158385743115, 'ACC-31': 9.69395506042949, 'ACC-32': 14.22017742688946, 'ACC-33': 15.70252575121695, 'ACC-34': 12.675796314367938, 'ACC-35': 1.0393577717201166, 'ACC-36': 12.293151113764175, 'ACC-37': 22.935730437978663, 'ACC-38': 11.276319695306054, 'ACC-39': 7.1268054045220826, 'ACC-40': 5.60394077070799, 'ACC-41': 21.416946319490947, 'ACC-42': 11.179422600993885, 'ACC-43': 9.587358435673622, 'ACC-44': 10.463633962266314, 'ACC-45': 2.5886972855968344, 'ACC-46': 12.363476618360867, 'ACC-47': 7.104281704202528, 'ACC-48': 20.754574995633508, 'ACC-49': 6.0861670682455955, 'ACC-50': 20.56747261313204, 'ACC-51': 5.3812156329450715, 'ACC-52': 3.4902125355636993, 'ACC-53': 3.194038695585099, 'ACC-54': 4.743586554956254, 'ACC-55': 7.914128537477799, 'ACC-56': 13.03222177395412, 'ACC-57': 20.405602734970614, 'ACC-58': 5.851638296640287, 'ACC-59': 7.226728072034167, 'ACC-60': 13.738981524546212, 'ACC-61': 6.4527914520919705, 'ACC-62': 6.326361369567824, 'ACC-63': 5.876826302594047, 'ACC-64': 11.975608088504979, 'ACC-65': 4.497353215090656, 'ACC-66': 8.683649144266774, 'ACC-67': 7.280040408460637, 'ACC-68': 11.049535607388815, 'ACC-69': 3.6208197000351343, 'ACC-70': 6.552968895549929, 'ACC-71': 5.57115662489863, 'ACC-72': 12.024598934292666, 'ACC-73': 3.5812830459535157, 'ACC-74': 4.933974286424815, 'ACC-75': 10.93264565558527, 'ACC-76': 4.5884682399380825, 'ACC-77': 12.794260424828819, 'ACC-78': 0.6006957315729963, 'ACC-79': 2.1877933864423706, 'ACC-80': 7.1214701913508565, 'ACC-81': 3.2814561941769513, 'ACC-82': 7.2272118585352025, 'ACC-83': 2.6552354186312663, 'ACC-84': 9.636721642578955, 'ACC-85': 4.665857046771404, 'ACC-86': 3.863909777556687, 'ACC-87': 3.4221397117909653, 'ACC-88': 5.572173807250121, 'ACC-89': 1.595784141894289, 'ACC-90': 4.104685262651085, 'ACC-91': 1.5303446738665702, 'ACC-92': 8.187007022781273, 'ACC-93': 6.337177962409937, 'ACC-94': 6.0612308448343395, 'ACC-95': 3.7133462818216447, 'ACC-96': 3.3692991470754814, 'ACC-97': 5.211914267649336, 'ACC-98': 3.1495347973596903, 'ACC-99': 6.05539001255007, 'ACC-100': 2.2323372639271715, 'ACC-101': 1.4403443431670424, 'ACC-102': 1.800045310376076, 'ACC-103': 9.88103334277888, 'ACC-104': 0.31140404810506384, 'ACC-105': 1.8190287905840072, 'ACC-106': 3.7874812805015394, 'ACC-107': 6.723599815498958, 'ACC-108': 7.2255706692438455, 'ACC-109': 3.884997937583188, 'ACC-110': 2.0568661215373263, 'ACC-111': 1.3449890484790876, 'ACC-112': 11.806299335552827, 'ACC-113': 2.8016041862811902, 'ACC-114': 2.697379042324026, 'ACC-115': 1.2517853652669404, 'ACC-116': 1.4265254499749251, 'ACC-117': 1.5138303677409557, 'ACC-118': 2.746948919195011, 'ACC-119': 0.9956951144245191, 'ACC-120': 4.1210726798019515, 'ACC-121': 5.105406138278646, 'ACC-122': 2.424778510572051, 'ACC-123': 0.5719710501333217, 'ACC-124': 0.18017144522324585, 'ACC-125': 5.131379009161778, 'ACC-126': 0.549299173945118, 'ACC-127': 2.7336485716154715, 'ACC-128': 1.2366277956460066, 'ACC-129': 3.4357686160349252, 'ACC-130': 0.5526347696205014, 'ACC-131': 2.2456774148957312, 'ACC-132': 6.433298817410769, 'ACC-133': 6.451448284308722, 'ACC-134': 0.8231624299870746, 'ACC-135': 1.2161507325694088, 'ACC-136': 0.852008013417816, 'ACC-137': 0.4153510449032488, 'ACC-138': 1.05179328375257, 'ACC-139': 2.674885817046566, 'ACC-140': 0.9500784346855241, 'ACC-141': 1.523212581567613, 'ACC-142': 0.4158730408248993, 'ACC-143': 0.12589263811123302, 'ACC-144': 0.24837545126353788, 'ACC-145': 0.44661106017576424, 'ACC-146': 0.05976559822713669, 'ACC-147': 1.734567769407688, 'ACC-148': 3.500970960533282, 'ACC-149': 0.8765106701458012, 'ACC-150': 1.8548919178369185, 'ACC-151': 0.42481852490133576, 'ACC-152': 0.16416312630656146, 'ACC-153': 0.9999267117389472, 'ACC-154': 0.35142843388319617, 'ACC-155': 0.8529247183006584, 'ACC-156': 0.8163819348833602, 'ACC-157': 1.9215143460277406, 'ACC-158': 0.2599671724406571, 'ACC-159': 0.2269717908513781, 'ACC-160': 2.262277745102475, 'ACC-161': 0.29165040145811155, 'ACC-162': 1.3720578040529483, 'ACC-163': 0.702725756572863, 'ACC-164': 0.25050815102787616, 'ACC-165': 3.224628129099474, 'ACC-166': 0.6779091924016419, 'ACC-167': 0.006948461523762869, 'ACC-168': 0.8282931289120191, 'ACC-169': 0.1823149257843139, 'ACC-170': 0.42076607464826726, 'ACC-171': 1.9801289104331488, 'ACC-172': 0.0, 'ACC-173': 0.2666009414757312, 'ACC-174': 0.03280638084107359, 'ACC-175': 0.941615407512586, 'ACC-176': 0.0, 'ACC-177': 0.17458094114998274, 'ACC-178': 0.03360948482840813, 'ACC-179': 0.002637553486541376, 'ACC-180': 0.0, 'ACC-181': 0.24207626586700967, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.04032857173179377, 'ACC-185': 0.800271607333398, 'ACC-186': 0.5335058178101239, 'ACC-187': 4.242863528189517, 'ACC-188': 4.097645373471611, 'ACC-189': 2.726938984034237, 'ACC-190': 2.8194661328694046, 'ACC-191': 0.003132137030995106, 'ACC-192': 0.2535578754340339})])
[01/19 02:46:55] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 02:46:55] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 02:46:55] d2.evaluation.testing INFO: copypaste: 5.1132,0.6287,0.3798,3.3789,13.9500,6.4620,19.4545
[01/19 02:46:55] d2.utils.events INFO:  eta: 16:56:27  iter: 3999  total_loss: 74.03  loss_ce: 2.945  loss_mask: 0.6357  loss_dice: 3.649  loss_ce_0: 4.075  loss_mask_0: 0.646  loss_dice_0: 3.896  loss_ce_1: 3.113  loss_mask_1: 0.6472  loss_dice_1: 3.766  loss_ce_2: 2.985  loss_mask_2: 0.6431  loss_dice_2: 3.707  loss_ce_3: 2.962  loss_mask_3: 0.6405  loss_dice_3: 3.66  loss_ce_4: 2.92  loss_mask_4: 0.6378  loss_dice_4: 3.665  loss_ce_5: 2.926  loss_mask_5: 0.6407  loss_dice_5: 3.665  loss_ce_6: 2.95  loss_mask_6: 0.6366  loss_dice_6: 3.653  loss_ce_7: 2.949  loss_mask_7: 0.6391  loss_dice_7: 3.659  loss_ce_8: 2.942  loss_mask_8: 0.6401  loss_dice_8: 3.652  time: 1.7063  data_time: 0.3367  lr: 9.0956e-06  max_mem: 17674M
[01/19 02:47:29] d2.utils.events INFO:  eta: 16:55:53  iter: 4019  total_loss: 74.27  loss_ce: 2.981  loss_mask: 0.6364  loss_dice: 3.613  loss_ce_0: 4.181  loss_mask_0: 0.6351  loss_dice_0: 3.919  loss_ce_1: 3.059  loss_mask_1: 0.6416  loss_dice_1: 3.769  loss_ce_2: 2.976  loss_mask_2: 0.6397  loss_dice_2: 3.687  loss_ce_3: 2.936  loss_mask_3: 0.6329  loss_dice_3: 3.645  loss_ce_4: 2.931  loss_mask_4: 0.6341  loss_dice_4: 3.646  loss_ce_5: 2.933  loss_mask_5: 0.6329  loss_dice_5: 3.638  loss_ce_6: 2.938  loss_mask_6: 0.6308  loss_dice_6: 3.626  loss_ce_7: 2.926  loss_mask_7: 0.6322  loss_dice_7: 3.628  loss_ce_8: 2.94  loss_mask_8: 0.633  loss_dice_8: 3.622  time: 1.7063  data_time: 0.3590  lr: 9.091e-06  max_mem: 17674M
[01/19 02:48:03] d2.utils.events INFO:  eta: 16:54:44  iter: 4039  total_loss: 73.25  loss_ce: 2.94  loss_mask: 0.6431  loss_dice: 3.617  loss_ce_0: 4.037  loss_mask_0: 0.6472  loss_dice_0: 3.894  loss_ce_1: 3.125  loss_mask_1: 0.6561  loss_dice_1: 3.752  loss_ce_2: 2.974  loss_mask_2: 0.6501  loss_dice_2: 3.684  loss_ce_3: 2.944  loss_mask_3: 0.6511  loss_dice_3: 3.645  loss_ce_4: 2.912  loss_mask_4: 0.6478  loss_dice_4: 3.642  loss_ce_5: 2.922  loss_mask_5: 0.6473  loss_dice_5: 3.633  loss_ce_6: 2.921  loss_mask_6: 0.6426  loss_dice_6: 3.623  loss_ce_7: 2.916  loss_mask_7: 0.6423  loss_dice_7: 3.624  loss_ce_8: 2.927  loss_mask_8: 0.6422  loss_dice_8: 3.617  time: 1.7062  data_time: 0.3433  lr: 9.0865e-06  max_mem: 17674M
[01/19 02:48:37] d2.utils.events INFO:  eta: 16:54:10  iter: 4059  total_loss: 73.66  loss_ce: 2.95  loss_mask: 0.6402  loss_dice: 3.601  loss_ce_0: 4.151  loss_mask_0: 0.6514  loss_dice_0: 3.87  loss_ce_1: 3.131  loss_mask_1: 0.6598  loss_dice_1: 3.718  loss_ce_2: 2.98  loss_mask_2: 0.6529  loss_dice_2: 3.657  loss_ce_3: 2.954  loss_mask_3: 0.643  loss_dice_3: 3.622  loss_ce_4: 2.937  loss_mask_4: 0.6419  loss_dice_4: 3.614  loss_ce_5: 2.94  loss_mask_5: 0.6445  loss_dice_5: 3.615  loss_ce_6: 2.94  loss_mask_6: 0.6422  loss_dice_6: 3.604  loss_ce_7: 2.92  loss_mask_7: 0.6452  loss_dice_7: 3.597  loss_ce_8: 2.934  loss_mask_8: 0.6431  loss_dice_8: 3.603  time: 1.7061  data_time: 0.3392  lr: 9.0819e-06  max_mem: 17674M
[01/19 02:49:10] d2.utils.events INFO:  eta: 16:53:15  iter: 4079  total_loss: 74.17  loss_ce: 3.025  loss_mask: 0.6387  loss_dice: 3.589  loss_ce_0: 4.169  loss_mask_0: 0.6494  loss_dice_0: 3.883  loss_ce_1: 3.198  loss_mask_1: 0.6553  loss_dice_1: 3.725  loss_ce_2: 3.043  loss_mask_2: 0.6502  loss_dice_2: 3.654  loss_ce_3: 3.047  loss_mask_3: 0.6432  loss_dice_3: 3.611  loss_ce_4: 3.007  loss_mask_4: 0.6454  loss_dice_4: 3.609  loss_ce_5: 3.006  loss_mask_5: 0.6463  loss_dice_5: 3.6  loss_ce_6: 3.016  loss_mask_6: 0.6407  loss_dice_6: 3.591  loss_ce_7: 3.013  loss_mask_7: 0.6404  loss_dice_7: 3.591  loss_ce_8: 3.009  loss_mask_8: 0.6405  loss_dice_8: 3.582  time: 1.7060  data_time: 0.3478  lr: 9.0774e-06  max_mem: 17674M
[01/19 02:49:44] d2.utils.events INFO:  eta: 16:52:46  iter: 4099  total_loss: 73.13  loss_ce: 2.774  loss_mask: 0.6201  loss_dice: 3.626  loss_ce_0: 4.099  loss_mask_0: 0.6334  loss_dice_0: 3.923  loss_ce_1: 2.953  loss_mask_1: 0.6338  loss_dice_1: 3.768  loss_ce_2: 2.839  loss_mask_2: 0.6316  loss_dice_2: 3.684  loss_ce_3: 2.792  loss_mask_3: 0.6194  loss_dice_3: 3.661  loss_ce_4: 2.791  loss_mask_4: 0.622  loss_dice_4: 3.648  loss_ce_5: 2.768  loss_mask_5: 0.623  loss_dice_5: 3.651  loss_ce_6: 2.793  loss_mask_6: 0.6225  loss_dice_6: 3.636  loss_ce_7: 2.776  loss_mask_7: 0.6224  loss_dice_7: 3.637  loss_ce_8: 2.773  loss_mask_8: 0.6197  loss_dice_8: 3.632  time: 1.7060  data_time: 0.3435  lr: 9.0728e-06  max_mem: 17674M
[01/19 02:50:19] d2.utils.events INFO:  eta: 16:52:10  iter: 4119  total_loss: 73.37  loss_ce: 2.869  loss_mask: 0.6207  loss_dice: 3.671  loss_ce_0: 4.124  loss_mask_0: 0.6365  loss_dice_0: 3.932  loss_ce_1: 3.053  loss_mask_1: 0.6374  loss_dice_1: 3.804  loss_ce_2: 2.922  loss_mask_2: 0.6269  loss_dice_2: 3.736  loss_ce_3: 2.887  loss_mask_3: 0.6234  loss_dice_3: 3.696  loss_ce_4: 2.868  loss_mask_4: 0.6254  loss_dice_4: 3.694  loss_ce_5: 2.854  loss_mask_5: 0.6209  loss_dice_5: 3.692  loss_ce_6: 2.862  loss_mask_6: 0.6189  loss_dice_6: 3.68  loss_ce_7: 2.859  loss_mask_7: 0.6209  loss_dice_7: 3.684  loss_ce_8: 2.857  loss_mask_8: 0.6194  loss_dice_8: 3.674  time: 1.7061  data_time: 0.3686  lr: 9.0683e-06  max_mem: 17674M
[01/19 02:50:53] d2.utils.events INFO:  eta: 16:51:20  iter: 4139  total_loss: 73.94  loss_ce: 2.958  loss_mask: 0.6523  loss_dice: 3.597  loss_ce_0: 4.117  loss_mask_0: 0.66  loss_dice_0: 3.875  loss_ce_1: 3.036  loss_mask_1: 0.6627  loss_dice_1: 3.727  loss_ce_2: 2.916  loss_mask_2: 0.6586  loss_dice_2: 3.66  loss_ce_3: 2.938  loss_mask_3: 0.6525  loss_dice_3: 3.623  loss_ce_4: 2.912  loss_mask_4: 0.6544  loss_dice_4: 3.626  loss_ce_5: 2.93  loss_mask_5: 0.6516  loss_dice_5: 3.612  loss_ce_6: 2.94  loss_mask_6: 0.6489  loss_dice_6: 3.601  loss_ce_7: 2.93  loss_mask_7: 0.6513  loss_dice_7: 3.598  loss_ce_8: 2.945  loss_mask_8: 0.6502  loss_dice_8: 3.598  time: 1.7060  data_time: 0.3570  lr: 9.0637e-06  max_mem: 17674M
[01/19 02:51:27] d2.utils.events INFO:  eta: 16:50:25  iter: 4159  total_loss: 73.19  loss_ce: 2.937  loss_mask: 0.6349  loss_dice: 3.579  loss_ce_0: 4.125  loss_mask_0: 0.65  loss_dice_0: 3.877  loss_ce_1: 3.083  loss_mask_1: 0.6486  loss_dice_1: 3.73  loss_ce_2: 2.928  loss_mask_2: 0.6455  loss_dice_2: 3.643  loss_ce_3: 2.901  loss_mask_3: 0.6395  loss_dice_3: 3.588  loss_ce_4: 2.902  loss_mask_4: 0.6403  loss_dice_4: 3.587  loss_ce_5: 2.91  loss_mask_5: 0.6425  loss_dice_5: 3.581  loss_ce_6: 2.931  loss_mask_6: 0.6371  loss_dice_6: 3.571  loss_ce_7: 2.915  loss_mask_7: 0.6371  loss_dice_7: 3.572  loss_ce_8: 2.93  loss_mask_8: 0.6344  loss_dice_8: 3.576  time: 1.7060  data_time: 0.3466  lr: 9.0592e-06  max_mem: 17674M
[01/19 02:52:00] d2.utils.events INFO:  eta: 16:49:54  iter: 4179  total_loss: 73  loss_ce: 2.819  loss_mask: 0.6401  loss_dice: 3.653  loss_ce_0: 4.043  loss_mask_0: 0.6438  loss_dice_0: 3.929  loss_ce_1: 2.956  loss_mask_1: 0.6457  loss_dice_1: 3.797  loss_ce_2: 2.836  loss_mask_2: 0.646  loss_dice_2: 3.722  loss_ce_3: 2.827  loss_mask_3: 0.6404  loss_dice_3: 3.688  loss_ce_4: 2.782  loss_mask_4: 0.6419  loss_dice_4: 3.68  loss_ce_5: 2.774  loss_mask_5: 0.6372  loss_dice_5: 3.678  loss_ce_6: 2.789  loss_mask_6: 0.6386  loss_dice_6: 3.669  loss_ce_7: 2.788  loss_mask_7: 0.6383  loss_dice_7: 3.67  loss_ce_8: 2.801  loss_mask_8: 0.6385  loss_dice_8: 3.664  time: 1.7058  data_time: 0.3474  lr: 9.0546e-06  max_mem: 17674M
[01/19 02:52:34] d2.utils.events INFO:  eta: 16:49:25  iter: 4199  total_loss: 73.16  loss_ce: 2.872  loss_mask: 0.6303  loss_dice: 3.599  loss_ce_0: 4.094  loss_mask_0: 0.6382  loss_dice_0: 3.882  loss_ce_1: 3.076  loss_mask_1: 0.6438  loss_dice_1: 3.736  loss_ce_2: 2.913  loss_mask_2: 0.6344  loss_dice_2: 3.66  loss_ce_3: 2.87  loss_mask_3: 0.6316  loss_dice_3: 3.623  loss_ce_4: 2.833  loss_mask_4: 0.6333  loss_dice_4: 3.621  loss_ce_5: 2.847  loss_mask_5: 0.6359  loss_dice_5: 3.6  loss_ce_6: 2.848  loss_mask_6: 0.6311  loss_dice_6: 3.596  loss_ce_7: 2.835  loss_mask_7: 0.6339  loss_dice_7: 3.595  loss_ce_8: 2.836  loss_mask_8: 0.6313  loss_dice_8: 3.593  time: 1.7057  data_time: 0.3491  lr: 9.0501e-06  max_mem: 17674M
[01/19 02:53:08] d2.utils.events INFO:  eta: 16:48:16  iter: 4219  total_loss: 73.63  loss_ce: 2.979  loss_mask: 0.6352  loss_dice: 3.59  loss_ce_0: 4.074  loss_mask_0: 0.6446  loss_dice_0: 3.896  loss_ce_1: 3.134  loss_mask_1: 0.6545  loss_dice_1: 3.73  loss_ce_2: 2.982  loss_mask_2: 0.6485  loss_dice_2: 3.65  loss_ce_3: 2.955  loss_mask_3: 0.6382  loss_dice_3: 3.617  loss_ce_4: 2.949  loss_mask_4: 0.6387  loss_dice_4: 3.609  loss_ce_5: 2.944  loss_mask_5: 0.6395  loss_dice_5: 3.603  loss_ce_6: 2.937  loss_mask_6: 0.6377  loss_dice_6: 3.597  loss_ce_7: 2.95  loss_mask_7: 0.6374  loss_dice_7: 3.591  loss_ce_8: 2.944  loss_mask_8: 0.6378  loss_dice_8: 3.594  time: 1.7056  data_time: 0.3254  lr: 9.0455e-06  max_mem: 17674M
[01/19 02:53:42] d2.utils.events INFO:  eta: 16:47:49  iter: 4239  total_loss: 73.14  loss_ce: 2.864  loss_mask: 0.6425  loss_dice: 3.619  loss_ce_0: 4.07  loss_mask_0: 0.6531  loss_dice_0: 3.899  loss_ce_1: 3.082  loss_mask_1: 0.6587  loss_dice_1: 3.759  loss_ce_2: 2.91  loss_mask_2: 0.6491  loss_dice_2: 3.678  loss_ce_3: 2.907  loss_mask_3: 0.6471  loss_dice_3: 3.635  loss_ce_4: 2.854  loss_mask_4: 0.6519  loss_dice_4: 3.635  loss_ce_5: 2.845  loss_mask_5: 0.6472  loss_dice_5: 3.63  loss_ce_6: 2.853  loss_mask_6: 0.6436  loss_dice_6: 3.625  loss_ce_7: 2.859  loss_mask_7: 0.6432  loss_dice_7: 3.628  loss_ce_8: 2.851  loss_mask_8: 0.6444  loss_dice_8: 3.621  time: 1.7056  data_time: 0.3611  lr: 9.041e-06  max_mem: 17674M
[01/19 02:54:15] d2.utils.events INFO:  eta: 16:47:24  iter: 4259  total_loss: 73.65  loss_ce: 2.93  loss_mask: 0.6311  loss_dice: 3.605  loss_ce_0: 4.105  loss_mask_0: 0.6462  loss_dice_0: 3.894  loss_ce_1: 3.129  loss_mask_1: 0.6523  loss_dice_1: 3.75  loss_ce_2: 3.001  loss_mask_2: 0.6446  loss_dice_2: 3.673  loss_ce_3: 2.967  loss_mask_3: 0.6382  loss_dice_3: 3.63  loss_ce_4: 2.932  loss_mask_4: 0.6374  loss_dice_4: 3.622  loss_ce_5: 2.928  loss_mask_5: 0.6385  loss_dice_5: 3.618  loss_ce_6: 2.938  loss_mask_6: 0.6357  loss_dice_6: 3.607  loss_ce_7: 2.911  loss_mask_7: 0.6357  loss_dice_7: 3.61  loss_ce_8: 2.924  loss_mask_8: 0.6353  loss_dice_8: 3.609  time: 1.7054  data_time: 0.3343  lr: 9.0364e-06  max_mem: 17674M
[01/19 02:54:49] d2.utils.events INFO:  eta: 16:46:30  iter: 4279  total_loss: 73.2  loss_ce: 2.913  loss_mask: 0.6415  loss_dice: 3.603  loss_ce_0: 4.048  loss_mask_0: 0.6453  loss_dice_0: 3.866  loss_ce_1: 3.055  loss_mask_1: 0.6507  loss_dice_1: 3.737  loss_ce_2: 2.947  loss_mask_2: 0.6449  loss_dice_2: 3.667  loss_ce_3: 2.925  loss_mask_3: 0.6492  loss_dice_3: 3.627  loss_ce_4: 2.92  loss_mask_4: 0.6483  loss_dice_4: 3.622  loss_ce_5: 2.895  loss_mask_5: 0.6459  loss_dice_5: 3.618  loss_ce_6: 2.892  loss_mask_6: 0.6433  loss_dice_6: 3.612  loss_ce_7: 2.902  loss_mask_7: 0.6456  loss_dice_7: 3.61  loss_ce_8: 2.909  loss_mask_8: 0.6461  loss_dice_8: 3.606  time: 1.7053  data_time: 0.3420  lr: 9.0319e-06  max_mem: 17674M
[01/19 02:55:23] d2.utils.events INFO:  eta: 16:45:52  iter: 4299  total_loss: 73.13  loss_ce: 2.87  loss_mask: 0.6372  loss_dice: 3.572  loss_ce_0: 4.108  loss_mask_0: 0.6374  loss_dice_0: 3.867  loss_ce_1: 3.047  loss_mask_1: 0.6499  loss_dice_1: 3.726  loss_ce_2: 2.925  loss_mask_2: 0.6434  loss_dice_2: 3.647  loss_ce_3: 2.895  loss_mask_3: 0.6367  loss_dice_3: 3.603  loss_ce_4: 2.867  loss_mask_4: 0.6361  loss_dice_4: 3.601  loss_ce_5: 2.867  loss_mask_5: 0.6399  loss_dice_5: 3.589  loss_ce_6: 2.848  loss_mask_6: 0.6371  loss_dice_6: 3.576  loss_ce_7: 2.869  loss_mask_7: 0.6363  loss_dice_7: 3.581  loss_ce_8: 2.863  loss_mask_8: 0.6381  loss_dice_8: 3.576  time: 1.7053  data_time: 0.3484  lr: 9.0273e-06  max_mem: 17674M
[01/19 02:55:57] d2.utils.events INFO:  eta: 16:45:23  iter: 4319  total_loss: 73.36  loss_ce: 2.88  loss_mask: 0.6218  loss_dice: 3.614  loss_ce_0: 4.11  loss_mask_0: 0.6374  loss_dice_0: 3.89  loss_ce_1: 3.087  loss_mask_1: 0.6369  loss_dice_1: 3.746  loss_ce_2: 2.929  loss_mask_2: 0.6319  loss_dice_2: 3.673  loss_ce_3: 2.895  loss_mask_3: 0.6264  loss_dice_3: 3.639  loss_ce_4: 2.885  loss_mask_4: 0.6279  loss_dice_4: 3.639  loss_ce_5: 2.873  loss_mask_5: 0.6244  loss_dice_5: 3.631  loss_ce_6: 2.874  loss_mask_6: 0.6229  loss_dice_6: 3.617  loss_ce_7: 2.866  loss_mask_7: 0.6238  loss_dice_7: 3.616  loss_ce_8: 2.875  loss_mask_8: 0.6217  loss_dice_8: 3.614  time: 1.7052  data_time: 0.3616  lr: 9.0228e-06  max_mem: 17674M
[01/19 02:56:31] d2.utils.events INFO:  eta: 16:44:45  iter: 4339  total_loss: 72.96  loss_ce: 2.858  loss_mask: 0.6311  loss_dice: 3.614  loss_ce_0: 4.075  loss_mask_0: 0.6398  loss_dice_0: 3.893  loss_ce_1: 3.035  loss_mask_1: 0.6436  loss_dice_1: 3.751  loss_ce_2: 2.892  loss_mask_2: 0.6412  loss_dice_2: 3.673  loss_ce_3: 2.873  loss_mask_3: 0.6331  loss_dice_3: 3.637  loss_ce_4: 2.832  loss_mask_4: 0.6355  loss_dice_4: 3.632  loss_ce_5: 2.846  loss_mask_5: 0.6368  loss_dice_5: 3.627  loss_ce_6: 2.862  loss_mask_6: 0.6327  loss_dice_6: 3.617  loss_ce_7: 2.839  loss_mask_7: 0.6329  loss_dice_7: 3.613  loss_ce_8: 2.856  loss_mask_8: 0.6307  loss_dice_8: 3.614  time: 1.7051  data_time: 0.3453  lr: 9.0182e-06  max_mem: 17674M
[01/19 02:57:04] d2.utils.events INFO:  eta: 16:43:24  iter: 4359  total_loss: 73.22  loss_ce: 2.883  loss_mask: 0.6262  loss_dice: 3.627  loss_ce_0: 4.072  loss_mask_0: 0.6407  loss_dice_0: 3.888  loss_ce_1: 3.036  loss_mask_1: 0.6436  loss_dice_1: 3.744  loss_ce_2: 2.911  loss_mask_2: 0.637  loss_dice_2: 3.68  loss_ce_3: 2.869  loss_mask_3: 0.6308  loss_dice_3: 3.649  loss_ce_4: 2.832  loss_mask_4: 0.6313  loss_dice_4: 3.656  loss_ce_5: 2.84  loss_mask_5: 0.6285  loss_dice_5: 3.645  loss_ce_6: 2.888  loss_mask_6: 0.63  loss_dice_6: 3.638  loss_ce_7: 2.875  loss_mask_7: 0.6298  loss_dice_7: 3.633  loss_ce_8: 2.852  loss_mask_8: 0.629  loss_dice_8: 3.634  time: 1.7050  data_time: 0.3380  lr: 9.0137e-06  max_mem: 17674M
[01/19 02:57:38] d2.utils.events INFO:  eta: 16:42:41  iter: 4379  total_loss: 73.55  loss_ce: 2.997  loss_mask: 0.6522  loss_dice: 3.535  loss_ce_0: 4.067  loss_mask_0: 0.6663  loss_dice_0: 3.826  loss_ce_1: 3.146  loss_mask_1: 0.6736  loss_dice_1: 3.662  loss_ce_2: 3.022  loss_mask_2: 0.6629  loss_dice_2: 3.585  loss_ce_3: 2.986  loss_mask_3: 0.6534  loss_dice_3: 3.557  loss_ce_4: 2.936  loss_mask_4: 0.6576  loss_dice_4: 3.554  loss_ce_5: 2.968  loss_mask_5: 0.6532  loss_dice_5: 3.557  loss_ce_6: 2.958  loss_mask_6: 0.6558  loss_dice_6: 3.54  loss_ce_7: 2.972  loss_mask_7: 0.6537  loss_dice_7: 3.541  loss_ce_8: 2.979  loss_mask_8: 0.655  loss_dice_8: 3.542  time: 1.7049  data_time: 0.3372  lr: 9.0091e-06  max_mem: 17674M
[01/19 02:58:12] d2.utils.events INFO:  eta: 16:42:13  iter: 4399  total_loss: 72.36  loss_ce: 2.778  loss_mask: 0.6298  loss_dice: 3.611  loss_ce_0: 3.998  loss_mask_0: 0.6368  loss_dice_0: 3.887  loss_ce_1: 2.937  loss_mask_1: 0.6436  loss_dice_1: 3.742  loss_ce_2: 2.825  loss_mask_2: 0.637  loss_dice_2: 3.674  loss_ce_3: 2.817  loss_mask_3: 0.6326  loss_dice_3: 3.629  loss_ce_4: 2.776  loss_mask_4: 0.6378  loss_dice_4: 3.624  loss_ce_5: 2.766  loss_mask_5: 0.6353  loss_dice_5: 3.624  loss_ce_6: 2.766  loss_mask_6: 0.6335  loss_dice_6: 3.613  loss_ce_7: 2.762  loss_mask_7: 0.6346  loss_dice_7: 3.615  loss_ce_8: 2.772  loss_mask_8: 0.6344  loss_dice_8: 3.612  time: 1.7049  data_time: 0.3651  lr: 9.0045e-06  max_mem: 17674M
[01/19 02:58:45] d2.utils.events INFO:  eta: 16:41:32  iter: 4419  total_loss: 73.1  loss_ce: 2.836  loss_mask: 0.6385  loss_dice: 3.66  loss_ce_0: 4.029  loss_mask_0: 0.6509  loss_dice_0: 3.916  loss_ce_1: 2.985  loss_mask_1: 0.6546  loss_dice_1: 3.788  loss_ce_2: 2.812  loss_mask_2: 0.6475  loss_dice_2: 3.725  loss_ce_3: 2.825  loss_mask_3: 0.6435  loss_dice_3: 3.681  loss_ce_4: 2.808  loss_mask_4: 0.6403  loss_dice_4: 3.676  loss_ce_5: 2.8  loss_mask_5: 0.6417  loss_dice_5: 3.678  loss_ce_6: 2.82  loss_mask_6: 0.6389  loss_dice_6: 3.66  loss_ce_7: 2.803  loss_mask_7: 0.6411  loss_dice_7: 3.665  loss_ce_8: 2.798  loss_mask_8: 0.6405  loss_dice_8: 3.657  time: 1.7047  data_time: 0.3372  lr: 9e-06  max_mem: 17674M
[01/19 02:59:19] d2.utils.events INFO:  eta: 16:40:58  iter: 4439  total_loss: 72.62  loss_ce: 2.856  loss_mask: 0.6276  loss_dice: 3.613  loss_ce_0: 4.038  loss_mask_0: 0.6382  loss_dice_0: 3.882  loss_ce_1: 3.045  loss_mask_1: 0.6401  loss_dice_1: 3.74  loss_ce_2: 2.877  loss_mask_2: 0.6341  loss_dice_2: 3.675  loss_ce_3: 2.861  loss_mask_3: 0.6301  loss_dice_3: 3.627  loss_ce_4: 2.826  loss_mask_4: 0.6309  loss_dice_4: 3.631  loss_ce_5: 2.823  loss_mask_5: 0.6317  loss_dice_5: 3.63  loss_ce_6: 2.838  loss_mask_6: 0.6323  loss_dice_6: 3.619  loss_ce_7: 2.843  loss_mask_7: 0.6322  loss_dice_7: 3.615  loss_ce_8: 2.832  loss_mask_8: 0.6316  loss_dice_8: 3.614  time: 1.7046  data_time: 0.3452  lr: 8.9954e-06  max_mem: 17674M
[01/19 02:59:53] d2.utils.events INFO:  eta: 16:40:18  iter: 4459  total_loss: 72.49  loss_ce: 2.884  loss_mask: 0.6247  loss_dice: 3.583  loss_ce_0: 4.036  loss_mask_0: 0.6445  loss_dice_0: 3.892  loss_ce_1: 3.044  loss_mask_1: 0.6414  loss_dice_1: 3.736  loss_ce_2: 2.904  loss_mask_2: 0.6367  loss_dice_2: 3.657  loss_ce_3: 2.885  loss_mask_3: 0.6305  loss_dice_3: 3.608  loss_ce_4: 2.864  loss_mask_4: 0.6318  loss_dice_4: 3.607  loss_ce_5: 2.865  loss_mask_5: 0.6282  loss_dice_5: 3.596  loss_ce_6: 2.868  loss_mask_6: 0.6278  loss_dice_6: 3.581  loss_ce_7: 2.843  loss_mask_7: 0.6273  loss_dice_7: 3.576  loss_ce_8: 2.852  loss_mask_8: 0.6247  loss_dice_8: 3.584  time: 1.7045  data_time: 0.3509  lr: 8.9909e-06  max_mem: 17674M
[01/19 03:00:26] d2.utils.events INFO:  eta: 16:39:45  iter: 4479  total_loss: 72.77  loss_ce: 2.823  loss_mask: 0.6319  loss_dice: 3.604  loss_ce_0: 4.004  loss_mask_0: 0.6494  loss_dice_0: 3.884  loss_ce_1: 2.97  loss_mask_1: 0.6462  loss_dice_1: 3.755  loss_ce_2: 2.856  loss_mask_2: 0.6414  loss_dice_2: 3.682  loss_ce_3: 2.819  loss_mask_3: 0.6341  loss_dice_3: 3.644  loss_ce_4: 2.81  loss_mask_4: 0.6333  loss_dice_4: 3.642  loss_ce_5: 2.796  loss_mask_5: 0.6306  loss_dice_5: 3.636  loss_ce_6: 2.808  loss_mask_6: 0.6331  loss_dice_6: 3.619  loss_ce_7: 2.774  loss_mask_7: 0.6287  loss_dice_7: 3.615  loss_ce_8: 2.807  loss_mask_8: 0.6318  loss_dice_8: 3.612  time: 1.7044  data_time: 0.3477  lr: 8.9863e-06  max_mem: 17674M
[01/19 03:01:01] d2.utils.events INFO:  eta: 16:39:05  iter: 4499  total_loss: 72.67  loss_ce: 2.865  loss_mask: 0.6345  loss_dice: 3.631  loss_ce_0: 4.024  loss_mask_0: 0.64  loss_dice_0: 3.896  loss_ce_1: 3.027  loss_mask_1: 0.6474  loss_dice_1: 3.761  loss_ce_2: 2.908  loss_mask_2: 0.6403  loss_dice_2: 3.694  loss_ce_3: 2.872  loss_mask_3: 0.6369  loss_dice_3: 3.645  loss_ce_4: 2.845  loss_mask_4: 0.6358  loss_dice_4: 3.654  loss_ce_5: 2.829  loss_mask_5: 0.637  loss_dice_5: 3.64  loss_ce_6: 2.848  loss_mask_6: 0.6369  loss_dice_6: 3.632  loss_ce_7: 2.833  loss_mask_7: 0.633  loss_dice_7: 3.631  loss_ce_8: 2.84  loss_mask_8: 0.6321  loss_dice_8: 3.634  time: 1.7044  data_time: 0.3416  lr: 8.9818e-06  max_mem: 17674M
[01/19 03:01:35] d2.utils.events INFO:  eta: 16:38:37  iter: 4519  total_loss: 72.82  loss_ce: 2.854  loss_mask: 0.6384  loss_dice: 3.602  loss_ce_0: 4.036  loss_mask_0: 0.6408  loss_dice_0: 3.911  loss_ce_1: 3.006  loss_mask_1: 0.6566  loss_dice_1: 3.743  loss_ce_2: 2.863  loss_mask_2: 0.6544  loss_dice_2: 3.663  loss_ce_3: 2.83  loss_mask_3: 0.6466  loss_dice_3: 3.62  loss_ce_4: 2.803  loss_mask_4: 0.6466  loss_dice_4: 3.628  loss_ce_5: 2.825  loss_mask_5: 0.648  loss_dice_5: 3.617  loss_ce_6: 2.83  loss_mask_6: 0.6449  loss_dice_6: 3.601  loss_ce_7: 2.827  loss_mask_7: 0.6421  loss_dice_7: 3.607  loss_ce_8: 2.839  loss_mask_8: 0.642  loss_dice_8: 3.605  time: 1.7044  data_time: 0.3551  lr: 8.9772e-06  max_mem: 17674M
[01/19 03:02:09] d2.utils.events INFO:  eta: 16:38:00  iter: 4539  total_loss: 72.39  loss_ce: 2.773  loss_mask: 0.6227  loss_dice: 3.638  loss_ce_0: 4.019  loss_mask_0: 0.6333  loss_dice_0: 3.912  loss_ce_1: 2.976  loss_mask_1: 0.641  loss_dice_1: 3.781  loss_ce_2: 2.838  loss_mask_2: 0.6329  loss_dice_2: 3.698  loss_ce_3: 2.805  loss_mask_3: 0.628  loss_dice_3: 3.654  loss_ce_4: 2.773  loss_mask_4: 0.6281  loss_dice_4: 3.653  loss_ce_5: 2.787  loss_mask_5: 0.6272  loss_dice_5: 3.648  loss_ce_6: 2.77  loss_mask_6: 0.6262  loss_dice_6: 3.639  loss_ce_7: 2.751  loss_mask_7: 0.6269  loss_dice_7: 3.644  loss_ce_8: 2.763  loss_mask_8: 0.6263  loss_dice_8: 3.636  time: 1.7044  data_time: 0.3457  lr: 8.9727e-06  max_mem: 17674M
[01/19 03:02:42] d2.utils.events INFO:  eta: 16:37:13  iter: 4559  total_loss: 73.31  loss_ce: 2.889  loss_mask: 0.6371  loss_dice: 3.595  loss_ce_0: 4.006  loss_mask_0: 0.6445  loss_dice_0: 3.881  loss_ce_1: 2.987  loss_mask_1: 0.6534  loss_dice_1: 3.736  loss_ce_2: 2.882  loss_mask_2: 0.6483  loss_dice_2: 3.656  loss_ce_3: 2.877  loss_mask_3: 0.6402  loss_dice_3: 3.613  loss_ce_4: 2.856  loss_mask_4: 0.6375  loss_dice_4: 3.613  loss_ce_5: 2.868  loss_mask_5: 0.6396  loss_dice_5: 3.613  loss_ce_6: 2.892  loss_mask_6: 0.6402  loss_dice_6: 3.601  loss_ce_7: 2.878  loss_mask_7: 0.6363  loss_dice_7: 3.607  loss_ce_8: 2.87  loss_mask_8: 0.6357  loss_dice_8: 3.6  time: 1.7042  data_time: 0.3254  lr: 8.9681e-06  max_mem: 17674M
[01/19 03:03:16] d2.utils.events INFO:  eta: 16:36:26  iter: 4579  total_loss: 72.87  loss_ce: 2.848  loss_mask: 0.6464  loss_dice: 3.576  loss_ce_0: 4.008  loss_mask_0: 0.656  loss_dice_0: 3.884  loss_ce_1: 3.028  loss_mask_1: 0.6604  loss_dice_1: 3.705  loss_ce_2: 2.882  loss_mask_2: 0.6544  loss_dice_2: 3.626  loss_ce_3: 2.869  loss_mask_3: 0.6498  loss_dice_3: 3.584  loss_ce_4: 2.863  loss_mask_4: 0.6499  loss_dice_4: 3.579  loss_ce_5: 2.82  loss_mask_5: 0.6483  loss_dice_5: 3.571  loss_ce_6: 2.831  loss_mask_6: 0.6517  loss_dice_6: 3.567  loss_ce_7: 2.824  loss_mask_7: 0.6508  loss_dice_7: 3.57  loss_ce_8: 2.83  loss_mask_8: 0.6482  loss_dice_8: 3.571  time: 1.7042  data_time: 0.3564  lr: 8.9636e-06  max_mem: 17674M
[01/19 03:03:50] d2.utils.events INFO:  eta: 16:35:59  iter: 4599  total_loss: 72.36  loss_ce: 2.841  loss_mask: 0.6307  loss_dice: 3.591  loss_ce_0: 4.032  loss_mask_0: 0.6418  loss_dice_0: 3.868  loss_ce_1: 2.974  loss_mask_1: 0.6465  loss_dice_1: 3.725  loss_ce_2: 2.848  loss_mask_2: 0.6388  loss_dice_2: 3.664  loss_ce_3: 2.808  loss_mask_3: 0.6352  loss_dice_3: 3.612  loss_ce_4: 2.781  loss_mask_4: 0.6372  loss_dice_4: 3.607  loss_ce_5: 2.791  loss_mask_5: 0.6323  loss_dice_5: 3.605  loss_ce_6: 2.79  loss_mask_6: 0.6326  loss_dice_6: 3.596  loss_ce_7: 2.793  loss_mask_7: 0.6318  loss_dice_7: 3.6  loss_ce_8: 2.788  loss_mask_8: 0.6328  loss_dice_8: 3.599  time: 1.7041  data_time: 0.3596  lr: 8.959e-06  max_mem: 17674M
[01/19 03:04:24] d2.utils.events INFO:  eta: 16:34:42  iter: 4619  total_loss: 72.9  loss_ce: 2.846  loss_mask: 0.6317  loss_dice: 3.604  loss_ce_0: 4.07  loss_mask_0: 0.6477  loss_dice_0: 3.896  loss_ce_1: 3.006  loss_mask_1: 0.6512  loss_dice_1: 3.739  loss_ce_2: 2.875  loss_mask_2: 0.642  loss_dice_2: 3.657  loss_ce_3: 2.848  loss_mask_3: 0.6358  loss_dice_3: 3.626  loss_ce_4: 2.828  loss_mask_4: 0.6339  loss_dice_4: 3.613  loss_ce_5: 2.826  loss_mask_5: 0.6359  loss_dice_5: 3.612  loss_ce_6: 2.833  loss_mask_6: 0.6361  loss_dice_6: 3.605  loss_ce_7: 2.803  loss_mask_7: 0.6333  loss_dice_7: 3.605  loss_ce_8: 2.816  loss_mask_8: 0.6327  loss_dice_8: 3.603  time: 1.7041  data_time: 0.3585  lr: 8.9545e-06  max_mem: 17674M
[01/19 03:04:58] d2.utils.events INFO:  eta: 16:33:58  iter: 4639  total_loss: 72.26  loss_ce: 2.787  loss_mask: 0.6278  loss_dice: 3.61  loss_ce_0: 3.991  loss_mask_0: 0.6382  loss_dice_0: 3.908  loss_ce_1: 2.905  loss_mask_1: 0.6438  loss_dice_1: 3.752  loss_ce_2: 2.777  loss_mask_2: 0.6369  loss_dice_2: 3.676  loss_ce_3: 2.789  loss_mask_3: 0.6305  loss_dice_3: 3.635  loss_ce_4: 2.749  loss_mask_4: 0.6296  loss_dice_4: 3.634  loss_ce_5: 2.756  loss_mask_5: 0.6323  loss_dice_5: 3.633  loss_ce_6: 2.772  loss_mask_6: 0.6332  loss_dice_6: 3.622  loss_ce_7: 2.763  loss_mask_7: 0.6272  loss_dice_7: 3.617  loss_ce_8: 2.774  loss_mask_8: 0.6266  loss_dice_8: 3.616  time: 1.7040  data_time: 0.3709  lr: 8.9499e-06  max_mem: 17674M
[01/19 03:05:32] d2.utils.events INFO:  eta: 16:33:24  iter: 4659  total_loss: 72.97  loss_ce: 2.926  loss_mask: 0.6303  loss_dice: 3.607  loss_ce_0: 4.045  loss_mask_0: 0.6432  loss_dice_0: 3.896  loss_ce_1: 3.071  loss_mask_1: 0.6445  loss_dice_1: 3.738  loss_ce_2: 2.949  loss_mask_2: 0.6393  loss_dice_2: 3.665  loss_ce_3: 2.925  loss_mask_3: 0.6351  loss_dice_3: 3.626  loss_ce_4: 2.885  loss_mask_4: 0.6346  loss_dice_4: 3.621  loss_ce_5: 2.911  loss_mask_5: 0.6311  loss_dice_5: 3.62  loss_ce_6: 2.916  loss_mask_6: 0.6292  loss_dice_6: 3.609  loss_ce_7: 2.905  loss_mask_7: 0.6327  loss_dice_7: 3.608  loss_ce_8: 2.911  loss_mask_8: 0.6319  loss_dice_8: 3.606  time: 1.7040  data_time: 0.3522  lr: 8.9453e-06  max_mem: 17674M
[01/19 03:06:06] d2.utils.events INFO:  eta: 16:32:16  iter: 4679  total_loss: 72.53  loss_ce: 2.853  loss_mask: 0.6312  loss_dice: 3.59  loss_ce_0: 3.945  loss_mask_0: 0.6444  loss_dice_0: 3.882  loss_ce_1: 3.033  loss_mask_1: 0.6482  loss_dice_1: 3.723  loss_ce_2: 2.836  loss_mask_2: 0.6427  loss_dice_2: 3.656  loss_ce_3: 2.826  loss_mask_3: 0.6395  loss_dice_3: 3.619  loss_ce_4: 2.817  loss_mask_4: 0.6364  loss_dice_4: 3.613  loss_ce_5: 2.808  loss_mask_5: 0.6358  loss_dice_5: 3.613  loss_ce_6: 2.814  loss_mask_6: 0.6382  loss_dice_6: 3.594  loss_ce_7: 2.818  loss_mask_7: 0.6349  loss_dice_7: 3.598  loss_ce_8: 2.841  loss_mask_8: 0.6327  loss_dice_8: 3.596  time: 1.7040  data_time: 0.3467  lr: 8.9408e-06  max_mem: 17674M
[01/19 03:06:40] d2.utils.events INFO:  eta: 16:31:44  iter: 4699  total_loss: 72.57  loss_ce: 2.815  loss_mask: 0.6313  loss_dice: 3.639  loss_ce_0: 3.941  loss_mask_0: 0.6413  loss_dice_0: 3.887  loss_ce_1: 2.975  loss_mask_1: 0.6468  loss_dice_1: 3.757  loss_ce_2: 2.842  loss_mask_2: 0.6397  loss_dice_2: 3.687  loss_ce_3: 2.828  loss_mask_3: 0.6341  loss_dice_3: 3.648  loss_ce_4: 2.792  loss_mask_4: 0.6341  loss_dice_4: 3.652  loss_ce_5: 2.803  loss_mask_5: 0.6325  loss_dice_5: 3.648  loss_ce_6: 2.797  loss_mask_6: 0.6316  loss_dice_6: 3.638  loss_ce_7: 2.798  loss_mask_7: 0.632  loss_dice_7: 3.638  loss_ce_8: 2.799  loss_mask_8: 0.6311  loss_dice_8: 3.641  time: 1.7040  data_time: 0.3664  lr: 8.9362e-06  max_mem: 17674M
[01/19 03:07:14] d2.utils.events INFO:  eta: 16:31:07  iter: 4719  total_loss: 72.65  loss_ce: 2.823  loss_mask: 0.6335  loss_dice: 3.63  loss_ce_0: 3.979  loss_mask_0: 0.6358  loss_dice_0: 3.891  loss_ce_1: 2.977  loss_mask_1: 0.6467  loss_dice_1: 3.767  loss_ce_2: 2.805  loss_mask_2: 0.6345  loss_dice_2: 3.69  loss_ce_3: 2.801  loss_mask_3: 0.6328  loss_dice_3: 3.654  loss_ce_4: 2.768  loss_mask_4: 0.6343  loss_dice_4: 3.641  loss_ce_5: 2.769  loss_mask_5: 0.6328  loss_dice_5: 3.644  loss_ce_6: 2.785  loss_mask_6: 0.6331  loss_dice_6: 3.631  loss_ce_7: 2.787  loss_mask_7: 0.6311  loss_dice_7: 3.631  loss_ce_8: 2.788  loss_mask_8: 0.6339  loss_dice_8: 3.631  time: 1.7040  data_time: 0.3577  lr: 8.9317e-06  max_mem: 17674M
[01/19 03:07:49] d2.utils.events INFO:  eta: 16:30:37  iter: 4739  total_loss: 71.93  loss_ce: 2.731  loss_mask: 0.6259  loss_dice: 3.596  loss_ce_0: 3.954  loss_mask_0: 0.6378  loss_dice_0: 3.872  loss_ce_1: 2.935  loss_mask_1: 0.6408  loss_dice_1: 3.73  loss_ce_2: 2.808  loss_mask_2: 0.632  loss_dice_2: 3.656  loss_ce_3: 2.769  loss_mask_3: 0.6273  loss_dice_3: 3.622  loss_ce_4: 2.73  loss_mask_4: 0.6269  loss_dice_4: 3.622  loss_ce_5: 2.738  loss_mask_5: 0.6294  loss_dice_5: 3.614  loss_ce_6: 2.75  loss_mask_6: 0.6295  loss_dice_6: 3.599  loss_ce_7: 2.734  loss_mask_7: 0.6303  loss_dice_7: 3.596  loss_ce_8: 2.731  loss_mask_8: 0.6291  loss_dice_8: 3.601  time: 1.7041  data_time: 0.3600  lr: 8.9271e-06  max_mem: 17674M
[01/19 03:08:22] d2.utils.events INFO:  eta: 16:29:42  iter: 4759  total_loss: 72.44  loss_ce: 2.843  loss_mask: 0.6447  loss_dice: 3.55  loss_ce_0: 4.018  loss_mask_0: 0.6558  loss_dice_0: 3.844  loss_ce_1: 3.014  loss_mask_1: 0.6619  loss_dice_1: 3.682  loss_ce_2: 2.886  loss_mask_2: 0.6551  loss_dice_2: 3.606  loss_ce_3: 2.829  loss_mask_3: 0.6476  loss_dice_3: 3.563  loss_ce_4: 2.8  loss_mask_4: 0.6472  loss_dice_4: 3.569  loss_ce_5: 2.797  loss_mask_5: 0.6466  loss_dice_5: 3.561  loss_ce_6: 2.81  loss_mask_6: 0.6454  loss_dice_6: 3.548  loss_ce_7: 2.81  loss_mask_7: 0.6477  loss_dice_7: 3.548  loss_ce_8: 2.803  loss_mask_8: 0.6463  loss_dice_8: 3.548  time: 1.7039  data_time: 0.3422  lr: 8.9226e-06  max_mem: 17674M
[01/19 03:08:56] d2.utils.events INFO:  eta: 16:29:06  iter: 4779  total_loss: 71.98  loss_ce: 2.807  loss_mask: 0.6324  loss_dice: 3.589  loss_ce_0: 3.981  loss_mask_0: 0.6495  loss_dice_0: 3.873  loss_ce_1: 3.001  loss_mask_1: 0.6523  loss_dice_1: 3.737  loss_ce_2: 2.828  loss_mask_2: 0.6413  loss_dice_2: 3.667  loss_ce_3: 2.79  loss_mask_3: 0.6376  loss_dice_3: 3.62  loss_ce_4: 2.792  loss_mask_4: 0.6385  loss_dice_4: 3.619  loss_ce_5: 2.795  loss_mask_5: 0.6369  loss_dice_5: 3.609  loss_ce_6: 2.792  loss_mask_6: 0.6362  loss_dice_6: 3.602  loss_ce_7: 2.788  loss_mask_7: 0.634  loss_dice_7: 3.59  loss_ce_8: 2.792  loss_mask_8: 0.634  loss_dice_8: 3.6  time: 1.7039  data_time: 0.3672  lr: 8.918e-06  max_mem: 17674M
[01/19 03:09:29] d2.utils.events INFO:  eta: 16:28:33  iter: 4799  total_loss: 72.59  loss_ce: 2.812  loss_mask: 0.6407  loss_dice: 3.554  loss_ce_0: 4.009  loss_mask_0: 0.6604  loss_dice_0: 3.849  loss_ce_1: 2.989  loss_mask_1: 0.6552  loss_dice_1: 3.692  loss_ce_2: 2.844  loss_mask_2: 0.6526  loss_dice_2: 3.617  loss_ce_3: 2.846  loss_mask_3: 0.6445  loss_dice_3: 3.578  loss_ce_4: 2.819  loss_mask_4: 0.6467  loss_dice_4: 3.574  loss_ce_5: 2.827  loss_mask_5: 0.6433  loss_dice_5: 3.568  loss_ce_6: 2.813  loss_mask_6: 0.6437  loss_dice_6: 3.556  loss_ce_7: 2.813  loss_mask_7: 0.6441  loss_dice_7: 3.559  loss_ce_8: 2.814  loss_mask_8: 0.6445  loss_dice_8: 3.557  time: 1.7038  data_time: 0.3328  lr: 8.9134e-06  max_mem: 17674M
[01/19 03:10:03] d2.utils.events INFO:  eta: 16:27:55  iter: 4819  total_loss: 72.74  loss_ce: 2.901  loss_mask: 0.6521  loss_dice: 3.563  loss_ce_0: 4.088  loss_mask_0: 0.6613  loss_dice_0: 3.873  loss_ce_1: 3.019  loss_mask_1: 0.6601  loss_dice_1: 3.709  loss_ce_2: 2.897  loss_mask_2: 0.656  loss_dice_2: 3.629  loss_ce_3: 2.875  loss_mask_3: 0.6513  loss_dice_3: 3.585  loss_ce_4: 2.873  loss_mask_4: 0.6523  loss_dice_4: 3.581  loss_ce_5: 2.861  loss_mask_5: 0.6535  loss_dice_5: 3.587  loss_ce_6: 2.883  loss_mask_6: 0.6549  loss_dice_6: 3.569  loss_ce_7: 2.874  loss_mask_7: 0.6538  loss_dice_7: 3.563  loss_ce_8: 2.873  loss_mask_8: 0.6501  loss_dice_8: 3.567  time: 1.7036  data_time: 0.3404  lr: 8.9089e-06  max_mem: 17674M
[01/19 03:10:37] d2.utils.events INFO:  eta: 16:27:17  iter: 4839  total_loss: 72.11  loss_ce: 2.83  loss_mask: 0.6378  loss_dice: 3.538  loss_ce_0: 3.967  loss_mask_0: 0.6614  loss_dice_0: 3.841  loss_ce_1: 3.002  loss_mask_1: 0.6592  loss_dice_1: 3.683  loss_ce_2: 2.811  loss_mask_2: 0.6478  loss_dice_2: 3.614  loss_ce_3: 2.82  loss_mask_3: 0.6417  loss_dice_3: 3.561  loss_ce_4: 2.795  loss_mask_4: 0.6433  loss_dice_4: 3.558  loss_ce_5: 2.795  loss_mask_5: 0.6421  loss_dice_5: 3.552  loss_ce_6: 2.81  loss_mask_6: 0.6378  loss_dice_6: 3.54  loss_ce_7: 2.795  loss_mask_7: 0.6401  loss_dice_7: 3.539  loss_ce_8: 2.797  loss_mask_8: 0.6398  loss_dice_8: 3.541  time: 1.7035  data_time: 0.3174  lr: 8.9043e-06  max_mem: 17674M
[01/19 03:11:10] d2.utils.events INFO:  eta: 16:26:51  iter: 4859  total_loss: 72.48  loss_ce: 2.831  loss_mask: 0.6378  loss_dice: 3.609  loss_ce_0: 4.011  loss_mask_0: 0.6448  loss_dice_0: 3.866  loss_ce_1: 3.003  loss_mask_1: 0.6518  loss_dice_1: 3.73  loss_ce_2: 2.869  loss_mask_2: 0.6473  loss_dice_2: 3.671  loss_ce_3: 2.833  loss_mask_3: 0.6436  loss_dice_3: 3.633  loss_ce_4: 2.815  loss_mask_4: 0.6404  loss_dice_4: 3.624  loss_ce_5: 2.8  loss_mask_5: 0.6421  loss_dice_5: 3.625  loss_ce_6: 2.819  loss_mask_6: 0.6399  loss_dice_6: 3.615  loss_ce_7: 2.803  loss_mask_7: 0.6379  loss_dice_7: 3.615  loss_ce_8: 2.816  loss_mask_8: 0.6407  loss_dice_8: 3.617  time: 1.7034  data_time: 0.3275  lr: 8.8998e-06  max_mem: 17674M
[01/19 03:11:44] d2.utils.events INFO:  eta: 16:26:17  iter: 4879  total_loss: 72.89  loss_ce: 2.9  loss_mask: 0.6468  loss_dice: 3.546  loss_ce_0: 4  loss_mask_0: 0.6552  loss_dice_0: 3.815  loss_ce_1: 2.998  loss_mask_1: 0.6483  loss_dice_1: 3.69  loss_ce_2: 2.874  loss_mask_2: 0.6465  loss_dice_2: 3.624  loss_ce_3: 2.875  loss_mask_3: 0.638  loss_dice_3: 3.577  loss_ce_4: 2.861  loss_mask_4: 0.6406  loss_dice_4: 3.568  loss_ce_5: 2.877  loss_mask_5: 0.6432  loss_dice_5: 3.555  loss_ce_6: 2.878  loss_mask_6: 0.6437  loss_dice_6: 3.551  loss_ce_7: 2.894  loss_mask_7: 0.6443  loss_dice_7: 3.542  loss_ce_8: 2.895  loss_mask_8: 0.6463  loss_dice_8: 3.555  time: 1.7034  data_time: 0.3472  lr: 8.8952e-06  max_mem: 17674M
[01/19 03:12:18] d2.utils.events INFO:  eta: 16:25:43  iter: 4899  total_loss: 72.91  loss_ce: 2.897  loss_mask: 0.6307  loss_dice: 3.579  loss_ce_0: 4.035  loss_mask_0: 0.6384  loss_dice_0: 3.865  loss_ce_1: 3.093  loss_mask_1: 0.6456  loss_dice_1: 3.724  loss_ce_2: 2.935  loss_mask_2: 0.6365  loss_dice_2: 3.649  loss_ce_3: 2.91  loss_mask_3: 0.6324  loss_dice_3: 3.603  loss_ce_4: 2.877  loss_mask_4: 0.6379  loss_dice_4: 3.599  loss_ce_5: 2.874  loss_mask_5: 0.64  loss_dice_5: 3.591  loss_ce_6: 2.899  loss_mask_6: 0.6384  loss_dice_6: 3.574  loss_ce_7: 2.861  loss_mask_7: 0.6352  loss_dice_7: 3.585  loss_ce_8: 2.883  loss_mask_8: 0.6359  loss_dice_8: 3.579  time: 1.7033  data_time: 0.3508  lr: 8.8907e-06  max_mem: 17674M
[01/19 03:12:51] d2.utils.events INFO:  eta: 16:25:02  iter: 4919  total_loss: 72.09  loss_ce: 2.824  loss_mask: 0.6415  loss_dice: 3.567  loss_ce_0: 4.038  loss_mask_0: 0.6525  loss_dice_0: 3.866  loss_ce_1: 2.955  loss_mask_1: 0.6524  loss_dice_1: 3.705  loss_ce_2: 2.82  loss_mask_2: 0.6481  loss_dice_2: 3.629  loss_ce_3: 2.818  loss_mask_3: 0.6475  loss_dice_3: 3.587  loss_ce_4: 2.809  loss_mask_4: 0.6458  loss_dice_4: 3.582  loss_ce_5: 2.821  loss_mask_5: 0.6469  loss_dice_5: 3.579  loss_ce_6: 2.817  loss_mask_6: 0.647  loss_dice_6: 3.568  loss_ce_7: 2.798  loss_mask_7: 0.642  loss_dice_7: 3.575  loss_ce_8: 2.81  loss_mask_8: 0.6429  loss_dice_8: 3.568  time: 1.7032  data_time: 0.3334  lr: 8.8861e-06  max_mem: 17674M
[01/19 03:13:26] d2.utils.events INFO:  eta: 16:24:32  iter: 4939  total_loss: 71.48  loss_ce: 2.721  loss_mask: 0.6216  loss_dice: 3.642  loss_ce_0: 4.027  loss_mask_0: 0.6279  loss_dice_0: 3.907  loss_ce_1: 2.906  loss_mask_1: 0.6361  loss_dice_1: 3.775  loss_ce_2: 2.763  loss_mask_2: 0.6318  loss_dice_2: 3.701  loss_ce_3: 2.725  loss_mask_3: 0.6281  loss_dice_3: 3.672  loss_ce_4: 2.706  loss_mask_4: 0.6252  loss_dice_4: 3.664  loss_ce_5: 2.694  loss_mask_5: 0.6251  loss_dice_5: 3.666  loss_ce_6: 2.709  loss_mask_6: 0.6226  loss_dice_6: 3.655  loss_ce_7: 2.718  loss_mask_7: 0.6261  loss_dice_7: 3.653  loss_ce_8: 2.714  loss_mask_8: 0.6252  loss_dice_8: 3.654  time: 1.7032  data_time: 0.3422  lr: 8.8815e-06  max_mem: 17674M
[01/19 03:14:00] d2.utils.events INFO:  eta: 16:23:55  iter: 4959  total_loss: 71.88  loss_ce: 2.741  loss_mask: 0.633  loss_dice: 3.588  loss_ce_0: 4.032  loss_mask_0: 0.6404  loss_dice_0: 3.884  loss_ce_1: 2.904  loss_mask_1: 0.6415  loss_dice_1: 3.73  loss_ce_2: 2.772  loss_mask_2: 0.6379  loss_dice_2: 3.654  loss_ce_3: 2.741  loss_mask_3: 0.6372  loss_dice_3: 3.614  loss_ce_4: 2.746  loss_mask_4: 0.6354  loss_dice_4: 3.612  loss_ce_5: 2.738  loss_mask_5: 0.6362  loss_dice_5: 3.607  loss_ce_6: 2.728  loss_mask_6: 0.6344  loss_dice_6: 3.595  loss_ce_7: 2.72  loss_mask_7: 0.6298  loss_dice_7: 3.591  loss_ce_8: 2.736  loss_mask_8: 0.6332  loss_dice_8: 3.592  time: 1.7032  data_time: 0.3486  lr: 8.877e-06  max_mem: 17674M
[01/19 03:14:33] d2.utils.events INFO:  eta: 16:23:20  iter: 4979  total_loss: 71.93  loss_ce: 2.822  loss_mask: 0.6418  loss_dice: 3.537  loss_ce_0: 4.1  loss_mask_0: 0.6407  loss_dice_0: 3.838  loss_ce_1: 3.013  loss_mask_1: 0.6504  loss_dice_1: 3.684  loss_ce_2: 2.879  loss_mask_2: 0.6461  loss_dice_2: 3.608  loss_ce_3: 2.844  loss_mask_3: 0.6416  loss_dice_3: 3.572  loss_ce_4: 2.787  loss_mask_4: 0.6477  loss_dice_4: 3.568  loss_ce_5: 2.813  loss_mask_5: 0.6451  loss_dice_5: 3.562  loss_ce_6: 2.817  loss_mask_6: 0.6439  loss_dice_6: 3.549  loss_ce_7: 2.796  loss_mask_7: 0.6438  loss_dice_7: 3.554  loss_ce_8: 2.813  loss_mask_8: 0.6448  loss_dice_8: 3.542  time: 1.7031  data_time: 0.3256  lr: 8.8724e-06  max_mem: 17674M
[01/19 03:15:07] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/sceneflow_crop192x384/model_0004999.pth
[01/19 03:15:08] d2.utils.events INFO:  eta: 16:22:42  iter: 4999  total_loss: 72  loss_ce: 2.735  loss_mask: 0.6301  loss_dice: 3.629  loss_ce_0: 3.998  loss_mask_0: 0.6383  loss_dice_0: 3.881  loss_ce_1: 2.897  loss_mask_1: 0.6447  loss_dice_1: 3.743  loss_ce_2: 2.802  loss_mask_2: 0.6378  loss_dice_2: 3.669  loss_ce_3: 2.772  loss_mask_3: 0.6312  loss_dice_3: 3.643  loss_ce_4: 2.743  loss_mask_4: 0.631  loss_dice_4: 3.641  loss_ce_5: 2.726  loss_mask_5: 0.6284  loss_dice_5: 3.635  loss_ce_6: 2.71  loss_mask_6: 0.6327  loss_dice_6: 3.624  loss_ce_7: 2.744  loss_mask_7: 0.6314  loss_dice_7: 3.632  loss_ce_8: 2.722  loss_mask_8: 0.63  loss_dice_8: 3.626  time: 1.7030  data_time: 0.3484  lr: 8.8679e-06  max_mem: 17674M
[01/19 03:15:42] d2.utils.events INFO:  eta: 16:21:41  iter: 5019  total_loss: 71.77  loss_ce: 2.781  loss_mask: 0.6302  loss_dice: 3.614  loss_ce_0: 3.964  loss_mask_0: 0.6499  loss_dice_0: 3.888  loss_ce_1: 2.907  loss_mask_1: 0.6489  loss_dice_1: 3.74  loss_ce_2: 2.826  loss_mask_2: 0.6421  loss_dice_2: 3.681  loss_ce_3: 2.782  loss_mask_3: 0.6328  loss_dice_3: 3.637  loss_ce_4: 2.774  loss_mask_4: 0.6348  loss_dice_4: 3.631  loss_ce_5: 2.785  loss_mask_5: 0.632  loss_dice_5: 3.634  loss_ce_6: 2.786  loss_mask_6: 0.6317  loss_dice_6: 3.628  loss_ce_7: 2.783  loss_mask_7: 0.6277  loss_dice_7: 3.624  loss_ce_8: 2.765  loss_mask_8: 0.6306  loss_dice_8: 3.619  time: 1.7029  data_time: 0.3478  lr: 8.8633e-06  max_mem: 17674M
[01/19 03:16:15] d2.utils.events INFO:  eta: 16:21:10  iter: 5039  total_loss: 72.09  loss_ce: 2.852  loss_mask: 0.6305  loss_dice: 3.525  loss_ce_0: 4.013  loss_mask_0: 0.6486  loss_dice_0: 3.836  loss_ce_1: 3.014  loss_mask_1: 0.6511  loss_dice_1: 3.687  loss_ce_2: 2.883  loss_mask_2: 0.6425  loss_dice_2: 3.61  loss_ce_3: 2.867  loss_mask_3: 0.6343  loss_dice_3: 3.563  loss_ce_4: 2.832  loss_mask_4: 0.6353  loss_dice_4: 3.565  loss_ce_5: 2.818  loss_mask_5: 0.6367  loss_dice_5: 3.554  loss_ce_6: 2.822  loss_mask_6: 0.6343  loss_dice_6: 3.543  loss_ce_7: 2.835  loss_mask_7: 0.6324  loss_dice_7: 3.538  loss_ce_8: 2.842  loss_mask_8: 0.6321  loss_dice_8: 3.539  time: 1.7029  data_time: 0.3573  lr: 8.8587e-06  max_mem: 17674M
[01/19 03:16:49] d2.utils.events INFO:  eta: 16:20:14  iter: 5059  total_loss: 71.71  loss_ce: 2.812  loss_mask: 0.6347  loss_dice: 3.558  loss_ce_0: 3.989  loss_mask_0: 0.6444  loss_dice_0: 3.857  loss_ce_1: 2.983  loss_mask_1: 0.6493  loss_dice_1: 3.706  loss_ce_2: 2.825  loss_mask_2: 0.6451  loss_dice_2: 3.634  loss_ce_3: 2.842  loss_mask_3: 0.6368  loss_dice_3: 3.588  loss_ce_4: 2.813  loss_mask_4: 0.6384  loss_dice_4: 3.585  loss_ce_5: 2.787  loss_mask_5: 0.638  loss_dice_5: 3.575  loss_ce_6: 2.811  loss_mask_6: 0.6413  loss_dice_6: 3.566  loss_ce_7: 2.808  loss_mask_7: 0.6351  loss_dice_7: 3.563  loss_ce_8: 2.796  loss_mask_8: 0.637  loss_dice_8: 3.56  time: 1.7028  data_time: 0.3365  lr: 8.8542e-06  max_mem: 17674M
[01/19 03:17:23] d2.utils.events INFO:  eta: 16:19:58  iter: 5079  total_loss: 72.62  loss_ce: 2.889  loss_mask: 0.6396  loss_dice: 3.56  loss_ce_0: 4.011  loss_mask_0: 0.6499  loss_dice_0: 3.837  loss_ce_1: 3.05  loss_mask_1: 0.6517  loss_dice_1: 3.691  loss_ce_2: 2.961  loss_mask_2: 0.6465  loss_dice_2: 3.633  loss_ce_3: 2.891  loss_mask_3: 0.6414  loss_dice_3: 3.592  loss_ce_4: 2.891  loss_mask_4: 0.6418  loss_dice_4: 3.588  loss_ce_5: 2.872  loss_mask_5: 0.6392  loss_dice_5: 3.586  loss_ce_6: 2.881  loss_mask_6: 0.6379  loss_dice_6: 3.567  loss_ce_7: 2.885  loss_mask_7: 0.6381  loss_dice_7: 3.566  loss_ce_8: 2.879  loss_mask_8: 0.6394  loss_dice_8: 3.566  time: 1.7027  data_time: 0.3340  lr: 8.8496e-06  max_mem: 17674M
[01/19 03:17:57] d2.utils.events INFO:  eta: 16:18:58  iter: 5099  total_loss: 72.18  loss_ce: 2.77  loss_mask: 0.628  loss_dice: 3.587  loss_ce_0: 4.008  loss_mask_0: 0.6423  loss_dice_0: 3.877  loss_ce_1: 2.921  loss_mask_1: 0.6483  loss_dice_1: 3.727  loss_ce_2: 2.816  loss_mask_2: 0.6384  loss_dice_2: 3.657  loss_ce_3: 2.775  loss_mask_3: 0.6348  loss_dice_3: 3.619  loss_ce_4: 2.742  loss_mask_4: 0.6361  loss_dice_4: 3.612  loss_ce_5: 2.743  loss_mask_5: 0.6359  loss_dice_5: 3.605  loss_ce_6: 2.771  loss_mask_6: 0.6355  loss_dice_6: 3.592  loss_ce_7: 2.762  loss_mask_7: 0.6341  loss_dice_7: 3.595  loss_ce_8: 2.765  loss_mask_8: 0.6347  loss_dice_8: 3.589  time: 1.7027  data_time: 0.3470  lr: 8.845e-06  max_mem: 17674M
[01/19 03:18:31] d2.utils.events INFO:  eta: 16:18:05  iter: 5119  total_loss: 72.2  loss_ce: 2.751  loss_mask: 0.6452  loss_dice: 3.566  loss_ce_0: 3.937  loss_mask_0: 0.6471  loss_dice_0: 3.87  loss_ce_1: 2.966  loss_mask_1: 0.6521  loss_dice_1: 3.72  loss_ce_2: 2.822  loss_mask_2: 0.645  loss_dice_2: 3.635  loss_ce_3: 2.797  loss_mask_3: 0.6447  loss_dice_3: 3.598  loss_ce_4: 2.77  loss_mask_4: 0.6466  loss_dice_4: 3.587  loss_ce_5: 2.754  loss_mask_5: 0.6439  loss_dice_5: 3.58  loss_ce_6: 2.77  loss_mask_6: 0.6431  loss_dice_6: 3.581  loss_ce_7: 2.737  loss_mask_7: 0.6433  loss_dice_7: 3.574  loss_ce_8: 2.743  loss_mask_8: 0.6455  loss_dice_8: 3.574  time: 1.7026  data_time: 0.3330  lr: 8.8405e-06  max_mem: 17674M
[01/19 03:19:04] d2.utils.events INFO:  eta: 16:17:23  iter: 5139  total_loss: 72.35  loss_ce: 2.871  loss_mask: 0.6414  loss_dice: 3.541  loss_ce_0: 3.973  loss_mask_0: 0.6517  loss_dice_0: 3.821  loss_ce_1: 2.991  loss_mask_1: 0.6544  loss_dice_1: 3.683  loss_ce_2: 2.895  loss_mask_2: 0.6451  loss_dice_2: 3.609  loss_ce_3: 2.877  loss_mask_3: 0.6338  loss_dice_3: 3.573  loss_ce_4: 2.856  loss_mask_4: 0.6398  loss_dice_4: 3.564  loss_ce_5: 2.868  loss_mask_5: 0.6389  loss_dice_5: 3.564  loss_ce_6: 2.86  loss_mask_6: 0.6379  loss_dice_6: 3.556  loss_ce_7: 2.863  loss_mask_7: 0.6396  loss_dice_7: 3.558  loss_ce_8: 2.876  loss_mask_8: 0.6424  loss_dice_8: 3.545  time: 1.7025  data_time: 0.3340  lr: 8.8359e-06  max_mem: 17674M
[01/19 03:19:38] d2.utils.events INFO:  eta: 16:16:50  iter: 5159  total_loss: 70.89  loss_ce: 2.672  loss_mask: 0.6264  loss_dice: 3.56  loss_ce_0: 3.981  loss_mask_0: 0.6401  loss_dice_0: 3.862  loss_ce_1: 2.855  loss_mask_1: 0.6408  loss_dice_1: 3.704  loss_ce_2: 2.725  loss_mask_2: 0.6328  loss_dice_2: 3.628  loss_ce_3: 2.704  loss_mask_3: 0.6275  loss_dice_3: 3.58  loss_ce_4: 2.678  loss_mask_4: 0.6286  loss_dice_4: 3.578  loss_ce_5: 2.668  loss_mask_5: 0.6294  loss_dice_5: 3.573  loss_ce_6: 2.665  loss_mask_6: 0.6269  loss_dice_6: 3.558  loss_ce_7: 2.661  loss_mask_7: 0.6275  loss_dice_7: 3.563  loss_ce_8: 2.66  loss_mask_8: 0.629  loss_dice_8: 3.568  time: 1.7025  data_time: 0.3394  lr: 8.8314e-06  max_mem: 17674M
[01/19 03:20:12] d2.utils.events INFO:  eta: 16:16:24  iter: 5179  total_loss: 71.82  loss_ce: 2.818  loss_mask: 0.6281  loss_dice: 3.553  loss_ce_0: 3.946  loss_mask_0: 0.638  loss_dice_0: 3.844  loss_ce_1: 3.01  loss_mask_1: 0.653  loss_dice_1: 3.705  loss_ce_2: 2.864  loss_mask_2: 0.6419  loss_dice_2: 3.63  loss_ce_3: 2.821  loss_mask_3: 0.6279  loss_dice_3: 3.586  loss_ce_4: 2.803  loss_mask_4: 0.6312  loss_dice_4: 3.579  loss_ce_5: 2.815  loss_mask_5: 0.6277  loss_dice_5: 3.566  loss_ce_6: 2.801  loss_mask_6: 0.6297  loss_dice_6: 3.549  loss_ce_7: 2.813  loss_mask_7: 0.6307  loss_dice_7: 3.554  loss_ce_8: 2.823  loss_mask_8: 0.6288  loss_dice_8: 3.564  time: 1.7024  data_time: 0.3397  lr: 8.8268e-06  max_mem: 17674M
[01/19 03:20:46] d2.utils.events INFO:  eta: 16:15:50  iter: 5199  total_loss: 72.04  loss_ce: 2.815  loss_mask: 0.6354  loss_dice: 3.608  loss_ce_0: 3.914  loss_mask_0: 0.6442  loss_dice_0: 3.896  loss_ce_1: 2.944  loss_mask_1: 0.6463  loss_dice_1: 3.747  loss_ce_2: 2.816  loss_mask_2: 0.6395  loss_dice_2: 3.671  loss_ce_3: 2.806  loss_mask_3: 0.6335  loss_dice_3: 3.632  loss_ce_4: 2.815  loss_mask_4: 0.6356  loss_dice_4: 3.631  loss_ce_5: 2.815  loss_mask_5: 0.6347  loss_dice_5: 3.621  loss_ce_6: 2.815  loss_mask_6: 0.6324  loss_dice_6: 3.616  loss_ce_7: 2.81  loss_mask_7: 0.6326  loss_dice_7: 3.618  loss_ce_8: 2.817  loss_mask_8: 0.6316  loss_dice_8: 3.617  time: 1.7024  data_time: 0.3438  lr: 8.8222e-06  max_mem: 17674M
[01/19 03:21:20] d2.utils.events INFO:  eta: 16:15:25  iter: 5219  total_loss: 71.5  loss_ce: 2.73  loss_mask: 0.6387  loss_dice: 3.563  loss_ce_0: 3.963  loss_mask_0: 0.6549  loss_dice_0: 3.847  loss_ce_1: 2.953  loss_mask_1: 0.6601  loss_dice_1: 3.703  loss_ce_2: 2.796  loss_mask_2: 0.6489  loss_dice_2: 3.62  loss_ce_3: 2.77  loss_mask_3: 0.6469  loss_dice_3: 3.581  loss_ce_4: 2.721  loss_mask_4: 0.6465  loss_dice_4: 3.583  loss_ce_5: 2.745  loss_mask_5: 0.6406  loss_dice_5: 3.576  loss_ce_6: 2.712  loss_mask_6: 0.6422  loss_dice_6: 3.56  loss_ce_7: 2.716  loss_mask_7: 0.6392  loss_dice_7: 3.557  loss_ce_8: 2.725  loss_mask_8: 0.6416  loss_dice_8: 3.566  time: 1.7024  data_time: 0.3537  lr: 8.8177e-06  max_mem: 17674M
[01/19 03:21:53] d2.utils.events INFO:  eta: 16:14:35  iter: 5239  total_loss: 71.81  loss_ce: 2.812  loss_mask: 0.6442  loss_dice: 3.516  loss_ce_0: 3.959  loss_mask_0: 0.6584  loss_dice_0: 3.822  loss_ce_1: 2.985  loss_mask_1: 0.6623  loss_dice_1: 3.657  loss_ce_2: 2.863  loss_mask_2: 0.6557  loss_dice_2: 3.583  loss_ce_3: 2.84  loss_mask_3: 0.6473  loss_dice_3: 3.537  loss_ce_4: 2.822  loss_mask_4: 0.6485  loss_dice_4: 3.533  loss_ce_5: 2.816  loss_mask_5: 0.6461  loss_dice_5: 3.536  loss_ce_6: 2.824  loss_mask_6: 0.6481  loss_dice_6: 3.524  loss_ce_7: 2.803  loss_mask_7: 0.6466  loss_dice_7: 3.525  loss_ce_8: 2.825  loss_mask_8: 0.6462  loss_dice_8: 3.515  time: 1.7023  data_time: 0.3512  lr: 8.8131e-06  max_mem: 17674M
[01/19 03:22:28] d2.utils.events INFO:  eta: 16:14:37  iter: 5259  total_loss: 71.38  loss_ce: 2.737  loss_mask: 0.6278  loss_dice: 3.556  loss_ce_0: 3.973  loss_mask_0: 0.6383  loss_dice_0: 3.849  loss_ce_1: 2.875  loss_mask_1: 0.6411  loss_dice_1: 3.699  loss_ce_2: 2.741  loss_mask_2: 0.6316  loss_dice_2: 3.623  loss_ce_3: 2.764  loss_mask_3: 0.6293  loss_dice_3: 3.591  loss_ce_4: 2.723  loss_mask_4: 0.6298  loss_dice_4: 3.58  loss_ce_5: 2.697  loss_mask_5: 0.6321  loss_dice_5: 3.581  loss_ce_6: 2.703  loss_mask_6: 0.628  loss_dice_6: 3.567  loss_ce_7: 2.711  loss_mask_7: 0.6269  loss_dice_7: 3.561  loss_ce_8: 2.712  loss_mask_8: 0.6247  loss_dice_8: 3.566  time: 1.7023  data_time: 0.3577  lr: 8.8085e-06  max_mem: 17674M
[01/19 03:23:02] d2.utils.events INFO:  eta: 16:14:23  iter: 5279  total_loss: 71.85  loss_ce: 2.805  loss_mask: 0.6339  loss_dice: 3.597  loss_ce_0: 4.012  loss_mask_0: 0.649  loss_dice_0: 3.87  loss_ce_1: 2.935  loss_mask_1: 0.6517  loss_dice_1: 3.729  loss_ce_2: 2.83  loss_mask_2: 0.6412  loss_dice_2: 3.658  loss_ce_3: 2.801  loss_mask_3: 0.6356  loss_dice_3: 3.625  loss_ce_4: 2.799  loss_mask_4: 0.6351  loss_dice_4: 3.618  loss_ce_5: 2.792  loss_mask_5: 0.6374  loss_dice_5: 3.614  loss_ce_6: 2.784  loss_mask_6: 0.6373  loss_dice_6: 3.606  loss_ce_7: 2.794  loss_mask_7: 0.6353  loss_dice_7: 3.603  loss_ce_8: 2.78  loss_mask_8: 0.6354  loss_dice_8: 3.604  time: 1.7023  data_time: 0.3372  lr: 8.804e-06  max_mem: 17674M
[01/19 03:23:36] d2.utils.events INFO:  eta: 16:13:50  iter: 5299  total_loss: 71.54  loss_ce: 2.768  loss_mask: 0.634  loss_dice: 3.553  loss_ce_0: 3.922  loss_mask_0: 0.6446  loss_dice_0: 3.849  loss_ce_1: 2.9  loss_mask_1: 0.6475  loss_dice_1: 3.697  loss_ce_2: 2.785  loss_mask_2: 0.6405  loss_dice_2: 3.629  loss_ce_3: 2.77  loss_mask_3: 0.634  loss_dice_3: 3.574  loss_ce_4: 2.755  loss_mask_4: 0.6343  loss_dice_4: 3.572  loss_ce_5: 2.758  loss_mask_5: 0.6352  loss_dice_5: 3.568  loss_ce_6: 2.758  loss_mask_6: 0.6339  loss_dice_6: 3.564  loss_ce_7: 2.744  loss_mask_7: 0.6329  loss_dice_7: 3.561  loss_ce_8: 2.751  loss_mask_8: 0.6333  loss_dice_8: 3.56  time: 1.7023  data_time: 0.3500  lr: 8.7994e-06  max_mem: 17674M
[01/19 03:24:10] d2.utils.events INFO:  eta: 16:13:18  iter: 5319  total_loss: 72.14  loss_ce: 2.779  loss_mask: 0.6358  loss_dice: 3.591  loss_ce_0: 4.006  loss_mask_0: 0.6497  loss_dice_0: 3.87  loss_ce_1: 2.957  loss_mask_1: 0.6451  loss_dice_1: 3.711  loss_ce_2: 2.817  loss_mask_2: 0.6433  loss_dice_2: 3.64  loss_ce_3: 2.777  loss_mask_3: 0.6414  loss_dice_3: 3.603  loss_ce_4: 2.76  loss_mask_4: 0.6421  loss_dice_4: 3.607  loss_ce_5: 2.74  loss_mask_5: 0.6428  loss_dice_5: 3.607  loss_ce_6: 2.761  loss_mask_6: 0.6389  loss_dice_6: 3.586  loss_ce_7: 2.757  loss_mask_7: 0.6378  loss_dice_7: 3.594  loss_ce_8: 2.754  loss_mask_8: 0.6375  loss_dice_8: 3.59  time: 1.7022  data_time: 0.3361  lr: 8.7949e-06  max_mem: 17674M
[01/19 03:24:43] d2.utils.events INFO:  eta: 16:12:55  iter: 5339  total_loss: 71.82  loss_ce: 2.763  loss_mask: 0.6336  loss_dice: 3.579  loss_ce_0: 3.955  loss_mask_0: 0.6486  loss_dice_0: 3.854  loss_ce_1: 2.952  loss_mask_1: 0.6535  loss_dice_1: 3.706  loss_ce_2: 2.821  loss_mask_2: 0.6427  loss_dice_2: 3.639  loss_ce_3: 2.787  loss_mask_3: 0.6393  loss_dice_3: 3.595  loss_ce_4: 2.748  loss_mask_4: 0.6381  loss_dice_4: 3.595  loss_ce_5: 2.755  loss_mask_5: 0.6384  loss_dice_5: 3.594  loss_ce_6: 2.765  loss_mask_6: 0.6357  loss_dice_6: 3.587  loss_ce_7: 2.755  loss_mask_7: 0.6372  loss_dice_7: 3.588  loss_ce_8: 2.733  loss_mask_8: 0.6361  loss_dice_8: 3.591  time: 1.7021  data_time: 0.3286  lr: 8.7903e-06  max_mem: 17674M
[01/19 03:25:17] d2.utils.events INFO:  eta: 16:12:40  iter: 5359  total_loss: 71.81  loss_ce: 2.775  loss_mask: 0.6276  loss_dice: 3.551  loss_ce_0: 3.997  loss_mask_0: 0.6409  loss_dice_0: 3.842  loss_ce_1: 2.97  loss_mask_1: 0.6411  loss_dice_1: 3.698  loss_ce_2: 2.83  loss_mask_2: 0.6361  loss_dice_2: 3.62  loss_ce_3: 2.789  loss_mask_3: 0.6275  loss_dice_3: 3.577  loss_ce_4: 2.769  loss_mask_4: 0.6302  loss_dice_4: 3.569  loss_ce_5: 2.761  loss_mask_5: 0.6293  loss_dice_5: 3.567  loss_ce_6: 2.768  loss_mask_6: 0.6283  loss_dice_6: 3.56  loss_ce_7: 2.754  loss_mask_7: 0.6249  loss_dice_7: 3.559  loss_ce_8: 2.779  loss_mask_8: 0.6281  loss_dice_8: 3.556  time: 1.7020  data_time: 0.3285  lr: 8.7857e-06  max_mem: 17674M
[01/19 03:25:51] d2.utils.events INFO:  eta: 16:12:04  iter: 5379  total_loss: 71.25  loss_ce: 2.711  loss_mask: 0.6382  loss_dice: 3.599  loss_ce_0: 3.927  loss_mask_0: 0.6466  loss_dice_0: 3.869  loss_ce_1: 2.865  loss_mask_1: 0.6556  loss_dice_1: 3.733  loss_ce_2: 2.738  loss_mask_2: 0.6497  loss_dice_2: 3.664  loss_ce_3: 2.742  loss_mask_3: 0.6426  loss_dice_3: 3.616  loss_ce_4: 2.701  loss_mask_4: 0.6424  loss_dice_4: 3.617  loss_ce_5: 2.692  loss_mask_5: 0.6421  loss_dice_5: 3.613  loss_ce_6: 2.709  loss_mask_6: 0.6419  loss_dice_6: 3.602  loss_ce_7: 2.694  loss_mask_7: 0.6403  loss_dice_7: 3.601  loss_ce_8: 2.677  loss_mask_8: 0.6387  loss_dice_8: 3.606  time: 1.7020  data_time: 0.3345  lr: 8.7812e-06  max_mem: 17674M
[01/19 03:26:25] d2.utils.events INFO:  eta: 16:11:13  iter: 5399  total_loss: 71.39  loss_ce: 2.746  loss_mask: 0.6408  loss_dice: 3.556  loss_ce_0: 3.982  loss_mask_0: 0.6575  loss_dice_0: 3.843  loss_ce_1: 2.93  loss_mask_1: 0.6588  loss_dice_1: 3.704  loss_ce_2: 2.781  loss_mask_2: 0.6505  loss_dice_2: 3.636  loss_ce_3: 2.762  loss_mask_3: 0.6467  loss_dice_3: 3.585  loss_ce_4: 2.742  loss_mask_4: 0.646  loss_dice_4: 3.585  loss_ce_5: 2.756  loss_mask_5: 0.6418  loss_dice_5: 3.573  loss_ce_6: 2.749  loss_mask_6: 0.6424  loss_dice_6: 3.564  loss_ce_7: 2.738  loss_mask_7: 0.6421  loss_dice_7: 3.562  loss_ce_8: 2.728  loss_mask_8: 0.6417  loss_dice_8: 3.561  time: 1.7020  data_time: 0.3469  lr: 8.7766e-06  max_mem: 17674M
[01/19 03:26:58] d2.utils.events INFO:  eta: 16:10:56  iter: 5419  total_loss: 72.15  loss_ce: 2.878  loss_mask: 0.6246  loss_dice: 3.539  loss_ce_0: 3.996  loss_mask_0: 0.6366  loss_dice_0: 3.85  loss_ce_1: 3.038  loss_mask_1: 0.6428  loss_dice_1: 3.679  loss_ce_2: 2.88  loss_mask_2: 0.6361  loss_dice_2: 3.607  loss_ce_3: 2.885  loss_mask_3: 0.6312  loss_dice_3: 3.559  loss_ce_4: 2.838  loss_mask_4: 0.6342  loss_dice_4: 3.57  loss_ce_5: 2.844  loss_mask_5: 0.632  loss_dice_5: 3.562  loss_ce_6: 2.852  loss_mask_6: 0.629  loss_dice_6: 3.549  loss_ce_7: 2.846  loss_mask_7: 0.6263  loss_dice_7: 3.548  loss_ce_8: 2.847  loss_mask_8: 0.6241  loss_dice_8: 3.553  time: 1.7019  data_time: 0.3362  lr: 8.772e-06  max_mem: 17674M
[01/19 03:27:32] d2.utils.events INFO:  eta: 16:09:54  iter: 5439  total_loss: 71.19  loss_ce: 2.794  loss_mask: 0.6428  loss_dice: 3.553  loss_ce_0: 3.979  loss_mask_0: 0.656  loss_dice_0: 3.816  loss_ce_1: 2.904  loss_mask_1: 0.6596  loss_dice_1: 3.678  loss_ce_2: 2.786  loss_mask_2: 0.6544  loss_dice_2: 3.615  loss_ce_3: 2.767  loss_mask_3: 0.6507  loss_dice_3: 3.576  loss_ce_4: 2.747  loss_mask_4: 0.6497  loss_dice_4: 3.57  loss_ce_5: 2.746  loss_mask_5: 0.6471  loss_dice_5: 3.573  loss_ce_6: 2.781  loss_mask_6: 0.6432  loss_dice_6: 3.555  loss_ce_7: 2.766  loss_mask_7: 0.6449  loss_dice_7: 3.555  loss_ce_8: 2.778  loss_mask_8: 0.6446  loss_dice_8: 3.554  time: 1.7017  data_time: 0.3351  lr: 8.7675e-06  max_mem: 17674M
[01/19 03:28:05] d2.utils.events INFO:  eta: 16:09:41  iter: 5459  total_loss: 71.83  loss_ce: 2.791  loss_mask: 0.6252  loss_dice: 3.557  loss_ce_0: 4.008  loss_mask_0: 0.6378  loss_dice_0: 3.849  loss_ce_1: 2.994  loss_mask_1: 0.6425  loss_dice_1: 3.701  loss_ce_2: 2.86  loss_mask_2: 0.631  loss_dice_2: 3.627  loss_ce_3: 2.823  loss_mask_3: 0.6255  loss_dice_3: 3.588  loss_ce_4: 2.806  loss_mask_4: 0.6277  loss_dice_4: 3.579  loss_ce_5: 2.803  loss_mask_5: 0.6279  loss_dice_5: 3.575  loss_ce_6: 2.811  loss_mask_6: 0.6263  loss_dice_6: 3.564  loss_ce_7: 2.79  loss_mask_7: 0.6288  loss_dice_7: 3.562  loss_ce_8: 2.787  loss_mask_8: 0.6275  loss_dice_8: 3.564  time: 1.7017  data_time: 0.3524  lr: 8.7629e-06  max_mem: 17674M
[01/19 03:28:40] d2.utils.events INFO:  eta: 16:09:19  iter: 5479  total_loss: 70.65  loss_ce: 2.608  loss_mask: 0.6078  loss_dice: 3.622  loss_ce_0: 3.892  loss_mask_0: 0.6237  loss_dice_0: 3.872  loss_ce_1: 2.801  loss_mask_1: 0.6231  loss_dice_1: 3.741  loss_ce_2: 2.662  loss_mask_2: 0.6129  loss_dice_2: 3.665  loss_ce_3: 2.617  loss_mask_3: 0.6098  loss_dice_3: 3.632  loss_ce_4: 2.591  loss_mask_4: 0.6082  loss_dice_4: 3.631  loss_ce_5: 2.602  loss_mask_5: 0.6081  loss_dice_5: 3.623  loss_ce_6: 2.587  loss_mask_6: 0.6057  loss_dice_6: 3.621  loss_ce_7: 2.587  loss_mask_7: 0.6083  loss_dice_7: 3.622  loss_ce_8: 2.592  loss_mask_8: 0.6109  loss_dice_8: 3.619  time: 1.7017  data_time: 0.3464  lr: 8.7583e-06  max_mem: 17674M
[01/19 03:29:14] d2.utils.events INFO:  eta: 16:08:42  iter: 5499  total_loss: 71.42  loss_ce: 2.774  loss_mask: 0.6365  loss_dice: 3.568  loss_ce_0: 3.922  loss_mask_0: 0.6357  loss_dice_0: 3.841  loss_ce_1: 2.889  loss_mask_1: 0.6467  loss_dice_1: 3.705  loss_ce_2: 2.784  loss_mask_2: 0.6409  loss_dice_2: 3.636  loss_ce_3: 2.765  loss_mask_3: 0.6354  loss_dice_3: 3.591  loss_ce_4: 2.756  loss_mask_4: 0.6376  loss_dice_4: 3.596  loss_ce_5: 2.748  loss_mask_5: 0.6371  loss_dice_5: 3.589  loss_ce_6: 2.762  loss_mask_6: 0.6369  loss_dice_6: 3.572  loss_ce_7: 2.749  loss_mask_7: 0.636  loss_dice_7: 3.574  loss_ce_8: 2.754  loss_mask_8: 0.6343  loss_dice_8: 3.567  time: 1.7017  data_time: 0.3440  lr: 8.7538e-06  max_mem: 17674M
[01/19 03:29:47] d2.utils.events INFO:  eta: 16:07:45  iter: 5519  total_loss: 71.86  loss_ce: 2.817  loss_mask: 0.6417  loss_dice: 3.53  loss_ce_0: 3.904  loss_mask_0: 0.6672  loss_dice_0: 3.804  loss_ce_1: 2.968  loss_mask_1: 0.6646  loss_dice_1: 3.667  loss_ce_2: 2.83  loss_mask_2: 0.6516  loss_dice_2: 3.597  loss_ce_3: 2.811  loss_mask_3: 0.6462  loss_dice_3: 3.556  loss_ce_4: 2.805  loss_mask_4: 0.6424  loss_dice_4: 3.555  loss_ce_5: 2.791  loss_mask_5: 0.6427  loss_dice_5: 3.552  loss_ce_6: 2.815  loss_mask_6: 0.6424  loss_dice_6: 3.538  loss_ce_7: 2.801  loss_mask_7: 0.6417  loss_dice_7: 3.526  loss_ce_8: 2.818  loss_mask_8: 0.6427  loss_dice_8: 3.533  time: 1.7017  data_time: 0.3473  lr: 8.7492e-06  max_mem: 17674M
[01/19 03:30:21] d2.utils.events INFO:  eta: 16:07:02  iter: 5539  total_loss: 71.1  loss_ce: 2.766  loss_mask: 0.6382  loss_dice: 3.532  loss_ce_0: 3.969  loss_mask_0: 0.6548  loss_dice_0: 3.815  loss_ce_1: 2.937  loss_mask_1: 0.6528  loss_dice_1: 3.664  loss_ce_2: 2.79  loss_mask_2: 0.6416  loss_dice_2: 3.601  loss_ce_3: 2.749  loss_mask_3: 0.639  loss_dice_3: 3.559  loss_ce_4: 2.739  loss_mask_4: 0.6387  loss_dice_4: 3.557  loss_ce_5: 2.746  loss_mask_5: 0.6345  loss_dice_5: 3.548  loss_ce_6: 2.747  loss_mask_6: 0.6412  loss_dice_6: 3.54  loss_ce_7: 2.753  loss_mask_7: 0.6394  loss_dice_7: 3.538  loss_ce_8: 2.761  loss_mask_8: 0.6403  loss_dice_8: 3.536  time: 1.7016  data_time: 0.3319  lr: 8.7446e-06  max_mem: 17674M
[01/19 03:30:55] d2.utils.events INFO:  eta: 16:06:34  iter: 5559  total_loss: 71.02  loss_ce: 2.668  loss_mask: 0.6285  loss_dice: 3.588  loss_ce_0: 3.957  loss_mask_0: 0.635  loss_dice_0: 3.858  loss_ce_1: 2.842  loss_mask_1: 0.6397  loss_dice_1: 3.711  loss_ce_2: 2.701  loss_mask_2: 0.6364  loss_dice_2: 3.638  loss_ce_3: 2.696  loss_mask_3: 0.6313  loss_dice_3: 3.608  loss_ce_4: 2.679  loss_mask_4: 0.6303  loss_dice_4: 3.601  loss_ce_5: 2.649  loss_mask_5: 0.631  loss_dice_5: 3.604  loss_ce_6: 2.669  loss_mask_6: 0.6303  loss_dice_6: 3.596  loss_ce_7: 2.643  loss_mask_7: 0.629  loss_dice_7: 3.591  loss_ce_8: 2.659  loss_mask_8: 0.6282  loss_dice_8: 3.596  time: 1.7016  data_time: 0.3556  lr: 8.7401e-06  max_mem: 17674M
[01/19 03:31:29] d2.utils.events INFO:  eta: 16:06:01  iter: 5579  total_loss: 71.08  loss_ce: 2.835  loss_mask: 0.6462  loss_dice: 3.53  loss_ce_0: 3.934  loss_mask_0: 0.6639  loss_dice_0: 3.803  loss_ce_1: 2.981  loss_mask_1: 0.6586  loss_dice_1: 3.665  loss_ce_2: 2.84  loss_mask_2: 0.6528  loss_dice_2: 3.588  loss_ce_3: 2.81  loss_mask_3: 0.6463  loss_dice_3: 3.551  loss_ce_4: 2.791  loss_mask_4: 0.6478  loss_dice_4: 3.552  loss_ce_5: 2.803  loss_mask_5: 0.6484  loss_dice_5: 3.555  loss_ce_6: 2.825  loss_mask_6: 0.6506  loss_dice_6: 3.534  loss_ce_7: 2.82  loss_mask_7: 0.6482  loss_dice_7: 3.534  loss_ce_8: 2.818  loss_mask_8: 0.6471  loss_dice_8: 3.536  time: 1.7015  data_time: 0.3452  lr: 8.7355e-06  max_mem: 17674M
[01/19 03:32:02] d2.utils.events INFO:  eta: 16:05:21  iter: 5599  total_loss: 70.87  loss_ce: 2.693  loss_mask: 0.6148  loss_dice: 3.597  loss_ce_0: 3.934  loss_mask_0: 0.6312  loss_dice_0: 3.874  loss_ce_1: 2.822  loss_mask_1: 0.6313  loss_dice_1: 3.737  loss_ce_2: 2.704  loss_mask_2: 0.6224  loss_dice_2: 3.662  loss_ce_3: 2.698  loss_mask_3: 0.6202  loss_dice_3: 3.616  loss_ce_4: 2.673  loss_mask_4: 0.6171  loss_dice_4: 3.618  loss_ce_5: 2.671  loss_mask_5: 0.6175  loss_dice_5: 3.612  loss_ce_6: 2.671  loss_mask_6: 0.6153  loss_dice_6: 3.6  loss_ce_7: 2.668  loss_mask_7: 0.6153  loss_dice_7: 3.603  loss_ce_8: 2.67  loss_mask_8: 0.6147  loss_dice_8: 3.608  time: 1.7014  data_time: 0.3196  lr: 8.7309e-06  max_mem: 17674M
[01/19 03:32:36] d2.utils.events INFO:  eta: 16:04:51  iter: 5619  total_loss: 71.28  loss_ce: 2.717  loss_mask: 0.6386  loss_dice: 3.596  loss_ce_0: 3.972  loss_mask_0: 0.6454  loss_dice_0: 3.86  loss_ce_1: 2.843  loss_mask_1: 0.6494  loss_dice_1: 3.736  loss_ce_2: 2.714  loss_mask_2: 0.6416  loss_dice_2: 3.669  loss_ce_3: 2.714  loss_mask_3: 0.635  loss_dice_3: 3.623  loss_ce_4: 2.685  loss_mask_4: 0.6361  loss_dice_4: 3.615  loss_ce_5: 2.686  loss_mask_5: 0.6358  loss_dice_5: 3.61  loss_ce_6: 2.685  loss_mask_6: 0.6367  loss_dice_6: 3.6  loss_ce_7: 2.695  loss_mask_7: 0.6381  loss_dice_7: 3.598  loss_ce_8: 2.697  loss_mask_8: 0.6366  loss_dice_8: 3.598  time: 1.7014  data_time: 0.3529  lr: 8.7264e-06  max_mem: 17674M
[01/19 03:33:10] d2.utils.events INFO:  eta: 16:04:19  iter: 5639  total_loss: 71.31  loss_ce: 2.736  loss_mask: 0.6374  loss_dice: 3.586  loss_ce_0: 3.911  loss_mask_0: 0.6539  loss_dice_0: 3.873  loss_ce_1: 2.898  loss_mask_1: 0.6544  loss_dice_1: 3.736  loss_ce_2: 2.775  loss_mask_2: 0.6485  loss_dice_2: 3.664  loss_ce_3: 2.736  loss_mask_3: 0.6432  loss_dice_3: 3.616  loss_ce_4: 2.696  loss_mask_4: 0.6426  loss_dice_4: 3.611  loss_ce_5: 2.708  loss_mask_5: 0.6393  loss_dice_5: 3.614  loss_ce_6: 2.718  loss_mask_6: 0.6379  loss_dice_6: 3.601  loss_ce_7: 2.717  loss_mask_7: 0.6403  loss_dice_7: 3.592  loss_ce_8: 2.723  loss_mask_8: 0.6394  loss_dice_8: 3.593  time: 1.7013  data_time: 0.3410  lr: 8.7218e-06  max_mem: 17674M
[01/19 03:33:44] d2.utils.events INFO:  eta: 16:03:42  iter: 5659  total_loss: 71.53  loss_ce: 2.775  loss_mask: 0.643  loss_dice: 3.542  loss_ce_0: 4.017  loss_mask_0: 0.66  loss_dice_0: 3.804  loss_ce_1: 2.966  loss_mask_1: 0.6638  loss_dice_1: 3.682  loss_ce_2: 2.812  loss_mask_2: 0.654  loss_dice_2: 3.606  loss_ce_3: 2.781  loss_mask_3: 0.6501  loss_dice_3: 3.559  loss_ce_4: 2.747  loss_mask_4: 0.6485  loss_dice_4: 3.559  loss_ce_5: 2.74  loss_mask_5: 0.6478  loss_dice_5: 3.554  loss_ce_6: 2.762  loss_mask_6: 0.6449  loss_dice_6: 3.549  loss_ce_7: 2.763  loss_mask_7: 0.6443  loss_dice_7: 3.55  loss_ce_8: 2.769  loss_mask_8: 0.646  loss_dice_8: 3.547  time: 1.7013  data_time: 0.3470  lr: 8.7172e-06  max_mem: 17674M
[01/19 03:34:18] d2.utils.events INFO:  eta: 16:03:20  iter: 5679  total_loss: 71.54  loss_ce: 2.692  loss_mask: 0.6328  loss_dice: 3.611  loss_ce_0: 3.896  loss_mask_0: 0.6462  loss_dice_0: 3.859  loss_ce_1: 2.845  loss_mask_1: 0.6485  loss_dice_1: 3.737  loss_ce_2: 2.719  loss_mask_2: 0.639  loss_dice_2: 3.669  loss_ce_3: 2.725  loss_mask_3: 0.637  loss_dice_3: 3.637  loss_ce_4: 2.703  loss_mask_4: 0.6357  loss_dice_4: 3.627  loss_ce_5: 2.692  loss_mask_5: 0.637  loss_dice_5: 3.626  loss_ce_6: 2.71  loss_mask_6: 0.6364  loss_dice_6: 3.615  loss_ce_7: 2.702  loss_mask_7: 0.6367  loss_dice_7: 3.615  loss_ce_8: 2.699  loss_mask_8: 0.6331  loss_dice_8: 3.617  time: 1.7013  data_time: 0.3513  lr: 8.7126e-06  max_mem: 17674M
[01/19 03:34:52] d2.utils.events INFO:  eta: 16:02:51  iter: 5699  total_loss: 71.38  loss_ce: 2.748  loss_mask: 0.6414  loss_dice: 3.539  loss_ce_0: 3.98  loss_mask_0: 0.6543  loss_dice_0: 3.811  loss_ce_1: 2.906  loss_mask_1: 0.6613  loss_dice_1: 3.67  loss_ce_2: 2.76  loss_mask_2: 0.6465  loss_dice_2: 3.603  loss_ce_3: 2.717  loss_mask_3: 0.6401  loss_dice_3: 3.558  loss_ce_4: 2.696  loss_mask_4: 0.6427  loss_dice_4: 3.559  loss_ce_5: 2.71  loss_mask_5: 0.6438  loss_dice_5: 3.553  loss_ce_6: 2.718  loss_mask_6: 0.6433  loss_dice_6: 3.541  loss_ce_7: 2.741  loss_mask_7: 0.6418  loss_dice_7: 3.541  loss_ce_8: 2.733  loss_mask_8: 0.6404  loss_dice_8: 3.539  time: 1.7013  data_time: 0.3312  lr: 8.7081e-06  max_mem: 17674M
[01/19 03:35:26] d2.utils.events INFO:  eta: 16:02:26  iter: 5719  total_loss: 70.71  loss_ce: 2.655  loss_mask: 0.6097  loss_dice: 3.601  loss_ce_0: 3.916  loss_mask_0: 0.6289  loss_dice_0: 3.862  loss_ce_1: 2.782  loss_mask_1: 0.6267  loss_dice_1: 3.719  loss_ce_2: 2.659  loss_mask_2: 0.6164  loss_dice_2: 3.656  loss_ce_3: 2.659  loss_mask_3: 0.6122  loss_dice_3: 3.612  loss_ce_4: 2.648  loss_mask_4: 0.6118  loss_dice_4: 3.613  loss_ce_5: 2.642  loss_mask_5: 0.61  loss_dice_5: 3.61  loss_ce_6: 2.634  loss_mask_6: 0.611  loss_dice_6: 3.604  loss_ce_7: 2.645  loss_mask_7: 0.6104  loss_dice_7: 3.601  loss_ce_8: 2.638  loss_mask_8: 0.6089  loss_dice_8: 3.602  time: 1.7013  data_time: 0.3564  lr: 8.7035e-06  max_mem: 17674M
[01/19 03:36:00] d2.utils.events INFO:  eta: 16:01:31  iter: 5739  total_loss: 71.39  loss_ce: 2.7  loss_mask: 0.6338  loss_dice: 3.545  loss_ce_0: 3.946  loss_mask_0: 0.6501  loss_dice_0: 3.845  loss_ce_1: 2.857  loss_mask_1: 0.6454  loss_dice_1: 3.702  loss_ce_2: 2.743  loss_mask_2: 0.642  loss_dice_2: 3.617  loss_ce_3: 2.712  loss_mask_3: 0.6364  loss_dice_3: 3.577  loss_ce_4: 2.683  loss_mask_4: 0.6358  loss_dice_4: 3.573  loss_ce_5: 2.69  loss_mask_5: 0.6373  loss_dice_5: 3.564  loss_ce_6: 2.687  loss_mask_6: 0.636  loss_dice_6: 3.553  loss_ce_7: 2.681  loss_mask_7: 0.6343  loss_dice_7: 3.548  loss_ce_8: 2.686  loss_mask_8: 0.636  loss_dice_8: 3.545  time: 1.7012  data_time: 0.3345  lr: 8.6989e-06  max_mem: 17674M
[01/19 03:36:34] d2.utils.events INFO:  eta: 16:01:19  iter: 5759  total_loss: 71.32  loss_ce: 2.713  loss_mask: 0.6435  loss_dice: 3.6  loss_ce_0: 3.89  loss_mask_0: 0.655  loss_dice_0: 3.852  loss_ce_1: 2.904  loss_mask_1: 0.6591  loss_dice_1: 3.729  loss_ce_2: 2.786  loss_mask_2: 0.6501  loss_dice_2: 3.66  loss_ce_3: 2.747  loss_mask_3: 0.6434  loss_dice_3: 3.619  loss_ce_4: 2.714  loss_mask_4: 0.6407  loss_dice_4: 3.631  loss_ce_5: 2.709  loss_mask_5: 0.6443  loss_dice_5: 3.613  loss_ce_6: 2.698  loss_mask_6: 0.6419  loss_dice_6: 3.612  loss_ce_7: 2.699  loss_mask_7: 0.6454  loss_dice_7: 3.607  loss_ce_8: 2.686  loss_mask_8: 0.6413  loss_dice_8: 3.6  time: 1.7012  data_time: 0.3534  lr: 8.6944e-06  max_mem: 17674M
[01/19 03:37:07] d2.utils.events INFO:  eta: 16:00:45  iter: 5779  total_loss: 71.21  loss_ce: 2.767  loss_mask: 0.6335  loss_dice: 3.565  loss_ce_0: 3.945  loss_mask_0: 0.6455  loss_dice_0: 3.842  loss_ce_1: 2.964  loss_mask_1: 0.6439  loss_dice_1: 3.702  loss_ce_2: 2.763  loss_mask_2: 0.638  loss_dice_2: 3.63  loss_ce_3: 2.744  loss_mask_3: 0.6337  loss_dice_3: 3.582  loss_ce_4: 2.746  loss_mask_4: 0.6309  loss_dice_4: 3.589  loss_ce_5: 2.726  loss_mask_5: 0.6313  loss_dice_5: 3.578  loss_ce_6: 2.744  loss_mask_6: 0.6326  loss_dice_6: 3.562  loss_ce_7: 2.761  loss_mask_7: 0.6313  loss_dice_7: 3.561  loss_ce_8: 2.741  loss_mask_8: 0.6333  loss_dice_8: 3.564  time: 1.7011  data_time: 0.3449  lr: 8.6898e-06  max_mem: 17674M
[01/19 03:37:41] d2.utils.events INFO:  eta: 16:00:02  iter: 5799  total_loss: 70.97  loss_ce: 2.728  loss_mask: 0.6312  loss_dice: 3.522  loss_ce_0: 3.873  loss_mask_0: 0.649  loss_dice_0: 3.808  loss_ce_1: 2.907  loss_mask_1: 0.6487  loss_dice_1: 3.659  loss_ce_2: 2.787  loss_mask_2: 0.64  loss_dice_2: 3.583  loss_ce_3: 2.741  loss_mask_3: 0.6378  loss_dice_3: 3.536  loss_ce_4: 2.727  loss_mask_4: 0.6355  loss_dice_4: 3.534  loss_ce_5: 2.703  loss_mask_5: 0.6339  loss_dice_5: 3.535  loss_ce_6: 2.725  loss_mask_6: 0.6336  loss_dice_6: 3.52  loss_ce_7: 2.696  loss_mask_7: 0.6329  loss_dice_7: 3.52  loss_ce_8: 2.72  loss_mask_8: 0.6318  loss_dice_8: 3.525  time: 1.7011  data_time: 0.3422  lr: 8.6852e-06  max_mem: 17674M
[01/19 03:38:15] d2.utils.events INFO:  eta: 15:59:46  iter: 5819  total_loss: 70.67  loss_ce: 2.687  loss_mask: 0.6364  loss_dice: 3.563  loss_ce_0: 3.931  loss_mask_0: 0.65  loss_dice_0: 3.854  loss_ce_1: 2.816  loss_mask_1: 0.646  loss_dice_1: 3.697  loss_ce_2: 2.69  loss_mask_2: 0.6403  loss_dice_2: 3.629  loss_ce_3: 2.701  loss_mask_3: 0.6358  loss_dice_3: 3.584  loss_ce_4: 2.681  loss_mask_4: 0.6378  loss_dice_4: 3.58  loss_ce_5: 2.674  loss_mask_5: 0.6392  loss_dice_5: 3.579  loss_ce_6: 2.702  loss_mask_6: 0.6383  loss_dice_6: 3.566  loss_ce_7: 2.644  loss_mask_7: 0.637  loss_dice_7: 3.572  loss_ce_8: 2.676  loss_mask_8: 0.6366  loss_dice_8: 3.571  time: 1.7010  data_time: 0.3385  lr: 8.6807e-06  max_mem: 17674M
[01/19 03:38:49] d2.utils.events INFO:  eta: 15:59:12  iter: 5839  total_loss: 70.88  loss_ce: 2.671  loss_mask: 0.6268  loss_dice: 3.568  loss_ce_0: 3.907  loss_mask_0: 0.6453  loss_dice_0: 3.855  loss_ce_1: 2.817  loss_mask_1: 0.6438  loss_dice_1: 3.707  loss_ce_2: 2.718  loss_mask_2: 0.6336  loss_dice_2: 3.639  loss_ce_3: 2.693  loss_mask_3: 0.6279  loss_dice_3: 3.595  loss_ce_4: 2.664  loss_mask_4: 0.6307  loss_dice_4: 3.59  loss_ce_5: 2.654  loss_mask_5: 0.6286  loss_dice_5: 3.582  loss_ce_6: 2.67  loss_mask_6: 0.6248  loss_dice_6: 3.574  loss_ce_7: 2.678  loss_mask_7: 0.6276  loss_dice_7: 3.564  loss_ce_8: 2.674  loss_mask_8: 0.6285  loss_dice_8: 3.566  time: 1.7010  data_time: 0.3478  lr: 8.6761e-06  max_mem: 17674M
[01/19 03:39:23] d2.utils.events INFO:  eta: 15:58:41  iter: 5859  total_loss: 70.74  loss_ce: 2.67  loss_mask: 0.6151  loss_dice: 3.573  loss_ce_0: 3.904  loss_mask_0: 0.6325  loss_dice_0: 3.861  loss_ce_1: 2.832  loss_mask_1: 0.6298  loss_dice_1: 3.728  loss_ce_2: 2.695  loss_mask_2: 0.6247  loss_dice_2: 3.648  loss_ce_3: 2.675  loss_mask_3: 0.6217  loss_dice_3: 3.608  loss_ce_4: 2.663  loss_mask_4: 0.618  loss_dice_4: 3.61  loss_ce_5: 2.653  loss_mask_5: 0.6189  loss_dice_5: 3.603  loss_ce_6: 2.674  loss_mask_6: 0.6215  loss_dice_6: 3.585  loss_ce_7: 2.671  loss_mask_7: 0.6163  loss_dice_7: 3.584  loss_ce_8: 2.673  loss_mask_8: 0.6174  loss_dice_8: 3.581  time: 1.7009  data_time: 0.3397  lr: 8.6715e-06  max_mem: 17674M
[01/19 03:39:56] d2.utils.events INFO:  eta: 15:58:12  iter: 5879  total_loss: 72.09  loss_ce: 2.797  loss_mask: 0.6364  loss_dice: 3.516  loss_ce_0: 3.983  loss_mask_0: 0.656  loss_dice_0: 3.814  loss_ce_1: 2.962  loss_mask_1: 0.6564  loss_dice_1: 3.662  loss_ce_2: 2.816  loss_mask_2: 0.6429  loss_dice_2: 3.585  loss_ce_3: 2.809  loss_mask_3: 0.641  loss_dice_3: 3.546  loss_ce_4: 2.779  loss_mask_4: 0.6404  loss_dice_4: 3.542  loss_ce_5: 2.787  loss_mask_5: 0.6397  loss_dice_5: 3.536  loss_ce_6: 2.794  loss_mask_6: 0.6379  loss_dice_6: 3.529  loss_ce_7: 2.8  loss_mask_7: 0.6378  loss_dice_7: 3.527  loss_ce_8: 2.78  loss_mask_8: 0.6375  loss_dice_8: 3.53  time: 1.7009  data_time: 0.3427  lr: 8.6669e-06  max_mem: 17674M
[01/19 03:40:31] d2.utils.events INFO:  eta: 15:58:13  iter: 5899  total_loss: 71.02  loss_ce: 2.657  loss_mask: 0.6268  loss_dice: 3.592  loss_ce_0: 3.867  loss_mask_0: 0.6319  loss_dice_0: 3.858  loss_ce_1: 2.845  loss_mask_1: 0.6352  loss_dice_1: 3.725  loss_ce_2: 2.716  loss_mask_2: 0.6321  loss_dice_2: 3.652  loss_ce_3: 2.699  loss_mask_3: 0.6258  loss_dice_3: 3.616  loss_ce_4: 2.67  loss_mask_4: 0.6301  loss_dice_4: 3.612  loss_ce_5: 2.66  loss_mask_5: 0.6281  loss_dice_5: 3.611  loss_ce_6: 2.652  loss_mask_6: 0.6285  loss_dice_6: 3.598  loss_ce_7: 2.643  loss_mask_7: 0.6279  loss_dice_7: 3.599  loss_ce_8: 2.664  loss_mask_8: 0.625  loss_dice_8: 3.592  time: 1.7009  data_time: 0.3600  lr: 8.6624e-06  max_mem: 17674M
[01/19 03:41:05] d2.utils.events INFO:  eta: 15:57:58  iter: 5919  total_loss: 70.71  loss_ce: 2.676  loss_mask: 0.6305  loss_dice: 3.529  loss_ce_0: 3.89  loss_mask_0: 0.6423  loss_dice_0: 3.812  loss_ce_1: 2.84  loss_mask_1: 0.6428  loss_dice_1: 3.663  loss_ce_2: 2.69  loss_mask_2: 0.6322  loss_dice_2: 3.594  loss_ce_3: 2.698  loss_mask_3: 0.6303  loss_dice_3: 3.546  loss_ce_4: 2.65  loss_mask_4: 0.6285  loss_dice_4: 3.547  loss_ce_5: 2.652  loss_mask_5: 0.6326  loss_dice_5: 3.546  loss_ce_6: 2.659  loss_mask_6: 0.6289  loss_dice_6: 3.536  loss_ce_7: 2.668  loss_mask_7: 0.6334  loss_dice_7: 3.532  loss_ce_8: 2.67  loss_mask_8: 0.6344  loss_dice_8: 3.531  time: 1.7009  data_time: 0.3569  lr: 8.6578e-06  max_mem: 17674M
[01/19 03:41:38] d2.utils.events INFO:  eta: 15:56:51  iter: 5939  total_loss: 70.37  loss_ce: 2.724  loss_mask: 0.6485  loss_dice: 3.442  loss_ce_0: 3.921  loss_mask_0: 0.6637  loss_dice_0: 3.757  loss_ce_1: 2.947  loss_mask_1: 0.6545  loss_dice_1: 3.621  loss_ce_2: 2.753  loss_mask_2: 0.655  loss_dice_2: 3.529  loss_ce_3: 2.739  loss_mask_3: 0.6492  loss_dice_3: 3.472  loss_ce_4: 2.703  loss_mask_4: 0.6481  loss_dice_4: 3.47  loss_ce_5: 2.695  loss_mask_5: 0.6485  loss_dice_5: 3.459  loss_ce_6: 2.697  loss_mask_6: 0.6481  loss_dice_6: 3.449  loss_ce_7: 2.689  loss_mask_7: 0.647  loss_dice_7: 3.449  loss_ce_8: 2.694  loss_mask_8: 0.6495  loss_dice_8: 3.445  time: 1.7008  data_time: 0.3262  lr: 8.6532e-06  max_mem: 17674M
[01/19 03:42:12] d2.utils.events INFO:  eta: 15:56:10  iter: 5959  total_loss: 70.67  loss_ce: 2.691  loss_mask: 0.6307  loss_dice: 3.542  loss_ce_0: 3.959  loss_mask_0: 0.6573  loss_dice_0: 3.829  loss_ce_1: 2.861  loss_mask_1: 0.6494  loss_dice_1: 3.686  loss_ce_2: 2.71  loss_mask_2: 0.6459  loss_dice_2: 3.615  loss_ce_3: 2.704  loss_mask_3: 0.639  loss_dice_3: 3.568  loss_ce_4: 2.659  loss_mask_4: 0.6352  loss_dice_4: 3.571  loss_ce_5: 2.653  loss_mask_5: 0.6345  loss_dice_5: 3.565  loss_ce_6: 2.653  loss_mask_6: 0.6333  loss_dice_6: 3.552  loss_ce_7: 2.637  loss_mask_7: 0.6337  loss_dice_7: 3.551  loss_ce_8: 2.646  loss_mask_8: 0.6303  loss_dice_8: 3.549  time: 1.7007  data_time: 0.3443  lr: 8.6486e-06  max_mem: 17674M
[01/19 03:42:45] d2.utils.events INFO:  eta: 15:55:36  iter: 5979  total_loss: 70.57  loss_ce: 2.624  loss_mask: 0.6337  loss_dice: 3.56  loss_ce_0: 3.899  loss_mask_0: 0.6421  loss_dice_0: 3.816  loss_ce_1: 2.825  loss_mask_1: 0.6459  loss_dice_1: 3.691  loss_ce_2: 2.696  loss_mask_2: 0.6416  loss_dice_2: 3.628  loss_ce_3: 2.655  loss_mask_3: 0.6357  loss_dice_3: 3.586  loss_ce_4: 2.645  loss_mask_4: 0.6376  loss_dice_4: 3.578  loss_ce_5: 2.613  loss_mask_5: 0.6387  loss_dice_5: 3.565  loss_ce_6: 2.628  loss_mask_6: 0.6351  loss_dice_6: 3.564  loss_ce_7: 2.623  loss_mask_7: 0.6364  loss_dice_7: 3.561  loss_ce_8: 2.621  loss_mask_8: 0.6362  loss_dice_8: 3.564  time: 1.7006  data_time: 0.3208  lr: 8.6441e-06  max_mem: 17674M
[01/19 03:43:19] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 03:43:19] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 03:43:19] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 03:48:37] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.413488800470942, 'error_1pix': 0.5819075151016606, 'error_3pix': 0.31370966529191907, 'mIoU': 4.255341643145171, 'fwIoU': 15.327216618592987, 'IoU-0': nan, 'IoU-1': 94.86992552488903, 'IoU-2': 6.676046353691764, 'IoU-3': 33.05960170697013, 'IoU-4': 14.137274255075095, 'IoU-5': 14.302074335883425, 'IoU-6': 15.372227180942904, 'IoU-7': 6.9629103710042735, 'IoU-8': 5.567976424948159, 'IoU-9': 0.4118068448499769, 'IoU-10': 14.212425186373881, 'IoU-11': 18.284491572937636, 'IoU-12': 15.773374702069939, 'IoU-13': 2.9706228569024327, 'IoU-14': 10.798297879581979, 'IoU-15': 9.243666247080009, 'IoU-16': 3.3506088718755085, 'IoU-17': 6.848602731937377, 'IoU-18': 0.9540708426980269, 'IoU-19': 6.992553223750211, 'IoU-20': 3.4524187119907928, 'IoU-21': 7.939635900636094, 'IoU-22': 7.303017539364706, 'IoU-23': 5.623185149366112, 'IoU-24': 4.7023962924807865, 'IoU-25': 5.844469911062716, 'IoU-26': 9.824023580210229, 'IoU-27': 4.60727742858232, 'IoU-28': 6.693151199467162, 'IoU-29': 8.520750487875349, 'IoU-30': 4.83632549919897, 'IoU-31': 6.506624700663176, 'IoU-32': 7.072247269239856, 'IoU-33': 8.201214990339777, 'IoU-34': 6.641575177641995, 'IoU-35': 4.389038082314832, 'IoU-36': 7.003815368144561, 'IoU-37': 9.676739402589362, 'IoU-38': 4.909289137009634, 'IoU-39': 8.407513461575121, 'IoU-40': 7.458708914931403, 'IoU-41': 5.578794778800058, 'IoU-42': 5.928558865450512, 'IoU-43': 8.137071981948317, 'IoU-44': 6.018848343779825, 'IoU-45': 6.329108397215731, 'IoU-46': 7.1542685176714365, 'IoU-47': 2.8247791193148615, 'IoU-48': 7.081407018840647, 'IoU-49': 6.7160245287967975, 'IoU-50': 5.386824170852514, 'IoU-51': 8.585537807872916, 'IoU-52': 4.315478011108419, 'IoU-53': 6.867312943566188, 'IoU-54': 5.4565070344726765, 'IoU-55': 5.419988344690734, 'IoU-56': 7.748659497167336, 'IoU-57': 3.6433396280338433, 'IoU-58': 4.9873226835886175, 'IoU-59': 3.830512812674701, 'IoU-60': 5.395886587835547, 'IoU-61': 5.032044856972364, 'IoU-62': 4.34881706797391, 'IoU-63': 6.443741206703865, 'IoU-64': 4.016725921174504, 'IoU-65': 4.124675628818927, 'IoU-66': 5.012379223328176, 'IoU-67': 4.61614410936775, 'IoU-68': 4.373778801965362, 'IoU-69': 3.7872534420725095, 'IoU-70': 5.856719996339468, 'IoU-71': 3.9699175507265148, 'IoU-72': 4.558539485148472, 'IoU-73': 3.4338309323288296, 'IoU-74': 5.55530957726522, 'IoU-75': 5.7055260706983875, 'IoU-76': 2.7156129484632463, 'IoU-77': 4.919874508900825, 'IoU-78': 2.636753015719619, 'IoU-79': 5.643677032291, 'IoU-80': 4.885351545540529, 'IoU-81': 4.892385716191115, 'IoU-82': 6.446727000522301, 'IoU-83': 2.1383790990487617, 'IoU-84': 4.573548813313867, 'IoU-85': 3.1019885974597394, 'IoU-86': 4.905536909030349, 'IoU-87': 3.5559227417529553, 'IoU-88': 4.576885358904878, 'IoU-89': 2.6030832499742735, 'IoU-90': 3.9614153206296265, 'IoU-91': 5.5932638221543, 'IoU-92': 3.9422281163323927, 'IoU-93': 3.427101977585901, 'IoU-94': 4.243571513236226, 'IoU-95': 4.129368501439229, 'IoU-96': 5.556227937704588, 'IoU-97': 3.7139528563342052, 'IoU-98': 2.040952691197504, 'IoU-99': 2.096683557203622, 'IoU-100': 3.662156059868034, 'IoU-101': 2.421160918077115, 'IoU-102': 3.772127467818457, 'IoU-103': 5.125655595441706, 'IoU-104': 2.6537553283910347, 'IoU-105': 1.4734080743837303, 'IoU-106': 3.715400825543183, 'IoU-107': 1.430440301326205, 'IoU-108': 3.695606761554121, 'IoU-109': 1.8585629215801491, 'IoU-110': 1.9351413511595295, 'IoU-111': 2.6332744969914113, 'IoU-112': 1.5601414800607767, 'IoU-113': 4.027347560950338, 'IoU-114': 2.412300970312736, 'IoU-115': 0.6177089040935507, 'IoU-116': 2.090500455088206, 'IoU-117': 3.1546073072148753, 'IoU-118': 2.93578346057926, 'IoU-119': 0.772561418558619, 'IoU-120': 0.5051627166152295, 'IoU-121': 3.1301548720151056, 'IoU-122': 1.2015762752599268, 'IoU-123': 1.804514144655775, 'IoU-124': 1.1249214031393857, 'IoU-125': 1.9026111919262154, 'IoU-126': 2.7080713204655855, 'IoU-127': 2.0721747929510608, 'IoU-128': 0.7964920507917783, 'IoU-129': 1.2145858971119967, 'IoU-130': 1.5575365945218764, 'IoU-131': 2.1765493028513294, 'IoU-132': 2.1878747057865673, 'IoU-133': 2.0264824086952222, 'IoU-134': 0.6532928166440746, 'IoU-135': 0.4677205697846093, 'IoU-136': 1.2636162777569204, 'IoU-137': 0.7493676804342956, 'IoU-138': 0.4552097352418041, 'IoU-139': 0.9719076345093105, 'IoU-140': 1.2878053514224506, 'IoU-141': 1.424730217490895, 'IoU-142': 0.6777155252813453, 'IoU-143': 0.591485735971872, 'IoU-144': 0.08980465753305912, 'IoU-145': 0.3711893917321312, 'IoU-146': 0.3604552201880257, 'IoU-147': 2.8180014381373866, 'IoU-148': 0.9724349320378862, 'IoU-149': 1.0654144463618607, 'IoU-150': 0.3693180848048573, 'IoU-151': 1.0391691671102303, 'IoU-152': 0.20275738605978624, 'IoU-153': 0.9900859549318969, 'IoU-154': 0.3911201065076238, 'IoU-155': 0.29472295624658207, 'IoU-156': 0.11392626069393276, 'IoU-157': 0.252066461602308, 'IoU-158': 0.4300548055655433, 'IoU-159': 0.21248008370787852, 'IoU-160': 0.6339669031634019, 'IoU-161': 0.06742958424844912, 'IoU-162': 0.2625371664060876, 'IoU-163': 0.23084600294911062, 'IoU-164': 0.2565482519277581, 'IoU-165': 0.5135892269130584, 'IoU-166': 0.35657894736842105, 'IoU-167': 0.34375521436638046, 'IoU-168': 0.7488815487243314, 'IoU-169': 1.4292344697171637, 'IoU-170': 0.3289586222686566, 'IoU-171': 0.26438495909558757, 'IoU-172': 0.7899502508274182, 'IoU-173': 0.9995616075823062, 'IoU-174': 0.11685991739153563, 'IoU-175': 1.3148977050083726, 'IoU-176': 0.7002709146982865, 'IoU-177': 0.06418289067514288, 'IoU-178': 0.05985857711873257, 'IoU-179': 0.36609147119780616, 'IoU-180': 0.23481174937619176, 'IoU-181': 0.38740368809690956, 'IoU-182': 0.3083649702609259, 'IoU-183': 0.3023506546423536, 'IoU-184': 0.03171161769733173, 'IoU-185': 0.1531072982513751, 'IoU-186': 0.046776382538574045, 'IoU-187': 1.826753277304902, 'IoU-188': 0.30521124641820824, 'IoU-189': 2.420552562022516, 'IoU-190': 1.116667228821025, 'IoU-191': 0.0022272872383865532, 'IoU-192': 0.2249679623738182, 'mACC': 8.0658886264425, 'pACC': 21.353175108714, 'ACC-0': nan, 'ACC-1': 98.33210181642531, 'ACC-2': 6.843238577869289, 'ACC-3': 53.70501743496837, 'ACC-4': 17.766451175146198, 'ACC-5': 25.582701931529268, 'ACC-6': 28.98935390463182, 'ACC-7': 9.404705908091493, 'ACC-8': 7.246712348997909, 'ACC-9': 0.4226749864251046, 'ACC-10': 25.3571682391329, 'ACC-11': 35.740288486041464, 'ACC-12': 41.59808682510907, 'ACC-13': 3.373256912587924, 'ACC-14': 21.844984581827433, 'ACC-15': 31.8845646540877, 'ACC-16': 4.922037809773416, 'ACC-17': 14.631994368173618, 'ACC-18': 1.0300845382853354, 'ACC-19': 17.109016268981065, 'ACC-20': 4.527321595374446, 'ACC-21': 15.594622671474301, 'ACC-22': 12.686782222527416, 'ACC-23': 7.945091711929604, 'ACC-24': 6.594020543742439, 'ACC-25': 10.074000854842016, 'ACC-26': 32.06408524426151, 'ACC-27': 6.921494541336047, 'ACC-28': 12.419452837958445, 'ACC-29': 20.235499940239084, 'ACC-30': 7.461264022733662, 'ACC-31': 11.342843777027731, 'ACC-32': 12.111570437860122, 'ACC-33': 18.619304523970868, 'ACC-34': 11.286750002534125, 'ACC-35': 5.9249012726698025, 'ACC-36': 13.145236444293815, 'ACC-37': 25.750524642435806, 'ACC-38': 6.641076268027913, 'ACC-39': 17.98228564450976, 'ACC-40': 15.427377033646856, 'ACC-41': 8.889826002990782, 'ACC-42': 9.819914245754294, 'ACC-43': 16.11149292133314, 'ACC-44': 11.035921054216574, 'ACC-45': 11.573837238584652, 'ACC-46': 15.099647943111227, 'ACC-47': 3.526627562761776, 'ACC-48': 12.759823988331952, 'ACC-49': 13.519807794210461, 'ACC-50': 8.750804484978442, 'ACC-51': 20.16449428467656, 'ACC-52': 6.322812819446158, 'ACC-53': 13.010693268010828, 'ACC-54': 9.600533770351927, 'ACC-55': 9.0433082919972, 'ACC-56': 22.425378936651835, 'ACC-57': 5.565273347396236, 'ACC-58': 7.667782682744169, 'ACC-59': 5.504504369012348, 'ACC-60': 9.354996278891479, 'ACC-61': 8.649358012094535, 'ACC-62': 7.567000321761373, 'ACC-63': 16.36569841824967, 'ACC-64': 5.867759643799812, 'ACC-65': 6.98266520334717, 'ACC-66': 8.388047821143722, 'ACC-67': 7.79790606471829, 'ACC-68': 8.194908007642917, 'ACC-69': 6.045965915404014, 'ACC-70': 12.267485477572153, 'ACC-71': 6.038997589181805, 'ACC-72': 9.2700145307529, 'ACC-73': 5.0638124185383955, 'ACC-74': 11.8768835876264, 'ACC-75': 12.16138004387713, 'ACC-76': 4.134507970357869, 'ACC-77': 10.224035819182815, 'ACC-78': 3.85921163288391, 'ACC-79': 11.350489015923467, 'ACC-80': 8.678889215591196, 'ACC-81': 10.888138395177045, 'ACC-82': 18.565831283560783, 'ACC-83': 2.872529000579739, 'ACC-84': 8.435974859059412, 'ACC-85': 4.440677173672031, 'ACC-86': 8.891257907241073, 'ACC-87': 5.585041044779772, 'ACC-88': 8.955933340086768, 'ACC-89': 3.5976863468298994, 'ACC-90': 6.666895937938351, 'ACC-91': 12.952669020066127, 'ACC-92': 8.171734851790974, 'ACC-93': 5.745154879019481, 'ACC-94': 11.26277517874911, 'ACC-95': 6.915043646059263, 'ACC-96': 15.810236659617388, 'ACC-97': 7.346491397026004, 'ACC-98': 2.8288205569072353, 'ACC-99': 2.9320074637054567, 'ACC-100': 6.8543936773150325, 'ACC-101': 3.8551827721808687, 'ACC-102': 8.040869959220661, 'ACC-103': 15.31706337961651, 'ACC-104': 4.105580285777526, 'ACC-105': 2.1005983576768634, 'ACC-106': 10.24419062932915, 'ACC-107': 1.9198551840876554, 'ACC-108': 8.531580159002793, 'ACC-109': 2.3825095714567186, 'ACC-110': 3.225551003276256, 'ACC-111': 4.70064537035383, 'ACC-112': 2.9258164118518106, 'ACC-113': 13.479118009643843, 'ACC-114': 4.822454251954357, 'ACC-115': 0.6940748425119901, 'ACC-116': 3.7046979127200355, 'ACC-117': 7.798633317447906, 'ACC-118': 6.268681532537514, 'ACC-119': 1.117074273322705, 'ACC-120': 0.603219866679317, 'ACC-121': 8.018206535439473, 'ACC-122': 1.665157047562437, 'ACC-123': 3.2696888895906397, 'ACC-124': 1.7089117740601063, 'ACC-125': 4.071623504535205, 'ACC-126': 8.556487308627583, 'ACC-127': 5.565244512143838, 'ACC-128': 1.0047067232107683, 'ACC-129': 1.963968701503992, 'ACC-130': 3.7595158431856115, 'ACC-131': 5.095656115152856, 'ACC-132': 7.924453693371267, 'ACC-133': 3.932855675083522, 'ACC-134': 0.7545023696682465, 'ACC-135': 0.5711618493814492, 'ACC-136': 2.0042280096906446, 'ACC-137': 1.0569241583646067, 'ACC-138': 0.5872909104754169, 'ACC-139': 1.3603573838309888, 'ACC-140': 4.044811301220666, 'ACC-141': 2.203693075189476, 'ACC-142': 0.9423952086395397, 'ACC-143': 0.7198614731685137, 'ACC-144': 0.09350180505415162, 'ACC-145': 0.4250542275095597, 'ACC-146': 0.4160745699207238, 'ACC-147': 26.101340503981955, 'ACC-148': 2.61090004191812, 'ACC-149': 2.279049437716833, 'ACC-150': 0.4509025869050634, 'ACC-151': 2.116099300530863, 'ACC-152': 0.22411743880234675, 'ACC-153': 1.5477564631085217, 'ACC-154': 0.46015637567265144, 'ACC-155': 0.34807216827760973, 'ACC-156': 0.1172539057702625, 'ACC-157': 0.2909900603348427, 'ACC-158': 0.5570523505012341, 'ACC-159': 0.25334078091905854, 'ACC-160': 0.7524431072705062, 'ACC-161': 0.07372000999783754, 'ACC-162': 0.34572940871940283, 'ACC-163': 0.26659859026823424, 'ACC-164': 0.27888850484685707, 'ACC-165': 0.630663824894307, 'ACC-166': 0.5004574795813013, 'ACC-167': 0.493861902801446, 'ACC-168': 1.5677966101694913, 'ACC-169': 4.798269148770032, 'ACC-170': 0.4436588724675951, 'ACC-171': 0.31942895874241606, 'ACC-172': 1.4057117457495276, 'ACC-173': 1.3984790388067114, 'ACC-174': 0.12693832586801768, 'ACC-175': 2.629238702186626, 'ACC-176': 1.063856802879034, 'ACC-177': 0.06588308244243535, 'ACC-178': 0.06200370476964948, 'ACC-179': 0.3881261399810502, 'ACC-180': 0.26012563920214027, 'ACC-181': 0.531999308353526, 'ACC-182': 0.3361850225900225, 'ACC-183': 0.39481955310287675, 'ACC-184': 0.033253383708672056, 'ACC-185': 0.17229512815893647, 'ACC-186': 0.05028174300599839, 'ACC-187': 5.665929764795419, 'ACC-188': 0.4247205520358339, 'ACC-189': 31.96258995022091, 'ACC-190': 5.1177987151136595, 'ACC-191': 0.0023491027732463294, 'ACC-192': 0.38401566625444644})])
[01/19 03:48:37] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 03:48:37] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 03:48:37] d2.evaluation.testing INFO: copypaste: 4.4135,0.5819,0.3137,4.2553,15.3272,8.0659,21.3532
[01/19 03:48:37] d2.utils.events INFO:  eta: 15:55:24  iter: 5999  total_loss: 70.43  loss_ce: 2.657  loss_mask: 0.635  loss_dice: 3.541  loss_ce_0: 3.894  loss_mask_0: 0.6554  loss_dice_0: 3.817  loss_ce_1: 2.793  loss_mask_1: 0.6566  loss_dice_1: 3.68  loss_ce_2: 2.689  loss_mask_2: 0.6446  loss_dice_2: 3.611  loss_ce_3: 2.655  loss_mask_3: 0.6393  loss_dice_3: 3.559  loss_ce_4: 2.648  loss_mask_4: 0.6379  loss_dice_4: 3.559  loss_ce_5: 2.634  loss_mask_5: 0.6371  loss_dice_5: 3.552  loss_ce_6: 2.63  loss_mask_6: 0.6392  loss_dice_6: 3.537  loss_ce_7: 2.629  loss_mask_7: 0.6403  loss_dice_7: 3.542  loss_ce_8: 2.645  loss_mask_8: 0.6369  loss_dice_8: 3.539  time: 1.7005  data_time: 0.3430  lr: 8.6395e-06  max_mem: 17674M
[01/19 03:49:11] d2.utils.events INFO:  eta: 15:54:36  iter: 6019  total_loss: 70.66  loss_ce: 2.602  loss_mask: 0.6306  loss_dice: 3.599  loss_ce_0: 3.867  loss_mask_0: 0.6457  loss_dice_0: 3.864  loss_ce_1: 2.744  loss_mask_1: 0.6413  loss_dice_1: 3.726  loss_ce_2: 2.645  loss_mask_2: 0.6338  loss_dice_2: 3.653  loss_ce_3: 2.605  loss_mask_3: 0.629  loss_dice_3: 3.612  loss_ce_4: 2.586  loss_mask_4: 0.6309  loss_dice_4: 3.612  loss_ce_5: 2.582  loss_mask_5: 0.632  loss_dice_5: 3.607  loss_ce_6: 2.574  loss_mask_6: 0.6271  loss_dice_6: 3.598  loss_ce_7: 2.563  loss_mask_7: 0.6256  loss_dice_7: 3.601  loss_ce_8: 2.576  loss_mask_8: 0.6269  loss_dice_8: 3.601  time: 1.7005  data_time: 0.3460  lr: 8.6349e-06  max_mem: 17674M
[01/19 03:49:44] d2.utils.events INFO:  eta: 15:53:43  iter: 6039  total_loss: 70.65  loss_ce: 2.703  loss_mask: 0.6366  loss_dice: 3.516  loss_ce_0: 3.893  loss_mask_0: 0.6633  loss_dice_0: 3.803  loss_ce_1: 2.846  loss_mask_1: 0.6572  loss_dice_1: 3.653  loss_ce_2: 2.723  loss_mask_2: 0.6497  loss_dice_2: 3.577  loss_ce_3: 2.709  loss_mask_3: 0.6428  loss_dice_3: 3.533  loss_ce_4: 2.689  loss_mask_4: 0.643  loss_dice_4: 3.526  loss_ce_5: 2.678  loss_mask_5: 0.6412  loss_dice_5: 3.523  loss_ce_6: 2.699  loss_mask_6: 0.6426  loss_dice_6: 3.517  loss_ce_7: 2.685  loss_mask_7: 0.6396  loss_dice_7: 3.509  loss_ce_8: 2.709  loss_mask_8: 0.639  loss_dice_8: 3.513  time: 1.7003  data_time: 0.3300  lr: 8.6304e-06  max_mem: 17674M
[01/19 03:50:18] d2.utils.events INFO:  eta: 15:53:13  iter: 6059  total_loss: 71.09  loss_ce: 2.755  loss_mask: 0.6427  loss_dice: 3.521  loss_ce_0: 3.951  loss_mask_0: 0.6601  loss_dice_0: 3.789  loss_ce_1: 2.905  loss_mask_1: 0.6521  loss_dice_1: 3.652  loss_ce_2: 2.79  loss_mask_2: 0.6459  loss_dice_2: 3.58  loss_ce_3: 2.76  loss_mask_3: 0.6454  loss_dice_3: 3.53  loss_ce_4: 2.741  loss_mask_4: 0.6462  loss_dice_4: 3.534  loss_ce_5: 2.753  loss_mask_5: 0.6464  loss_dice_5: 3.529  loss_ce_6: 2.738  loss_mask_6: 0.6438  loss_dice_6: 3.522  loss_ce_7: 2.743  loss_mask_7: 0.642  loss_dice_7: 3.52  loss_ce_8: 2.731  loss_mask_8: 0.6429  loss_dice_8: 3.524  time: 1.7002  data_time: 0.3227  lr: 8.6258e-06  max_mem: 17674M
[01/19 03:50:52] d2.utils.events INFO:  eta: 15:52:40  iter: 6079  total_loss: 70.08  loss_ce: 2.587  loss_mask: 0.6287  loss_dice: 3.584  loss_ce_0: 3.871  loss_mask_0: 0.6392  loss_dice_0: 3.847  loss_ce_1: 2.758  loss_mask_1: 0.6384  loss_dice_1: 3.716  loss_ce_2: 2.619  loss_mask_2: 0.6303  loss_dice_2: 3.642  loss_ce_3: 2.612  loss_mask_3: 0.628  loss_dice_3: 3.606  loss_ce_4: 2.582  loss_mask_4: 0.6275  loss_dice_4: 3.598  loss_ce_5: 2.574  loss_mask_5: 0.6284  loss_dice_5: 3.597  loss_ce_6: 2.575  loss_mask_6: 0.6276  loss_dice_6: 3.593  loss_ce_7: 2.557  loss_mask_7: 0.6285  loss_dice_7: 3.592  loss_ce_8: 2.578  loss_mask_8: 0.6273  loss_dice_8: 3.593  time: 1.7002  data_time: 0.3335  lr: 8.6212e-06  max_mem: 17674M
[01/19 03:51:25] d2.utils.events INFO:  eta: 15:51:56  iter: 6099  total_loss: 70.06  loss_ce: 2.656  loss_mask: 0.6322  loss_dice: 3.532  loss_ce_0: 3.881  loss_mask_0: 0.6415  loss_dice_0: 3.816  loss_ce_1: 2.822  loss_mask_1: 0.641  loss_dice_1: 3.674  loss_ce_2: 2.697  loss_mask_2: 0.6353  loss_dice_2: 3.596  loss_ce_3: 2.647  loss_mask_3: 0.6351  loss_dice_3: 3.556  loss_ce_4: 2.627  loss_mask_4: 0.6324  loss_dice_4: 3.551  loss_ce_5: 2.645  loss_mask_5: 0.6345  loss_dice_5: 3.551  loss_ce_6: 2.631  loss_mask_6: 0.635  loss_dice_6: 3.54  loss_ce_7: 2.637  loss_mask_7: 0.6353  loss_dice_7: 3.54  loss_ce_8: 2.635  loss_mask_8: 0.6333  loss_dice_8: 3.536  time: 1.7001  data_time: 0.3313  lr: 8.6166e-06  max_mem: 17674M
[01/19 03:51:59] d2.utils.events INFO:  eta: 15:51:40  iter: 6119  total_loss: 69.81  loss_ce: 2.544  loss_mask: 0.6163  loss_dice: 3.606  loss_ce_0: 3.833  loss_mask_0: 0.6353  loss_dice_0: 3.882  loss_ce_1: 2.736  loss_mask_1: 0.6328  loss_dice_1: 3.742  loss_ce_2: 2.615  loss_mask_2: 0.6251  loss_dice_2: 3.666  loss_ce_3: 2.601  loss_mask_3: 0.62  loss_dice_3: 3.625  loss_ce_4: 2.581  loss_mask_4: 0.6161  loss_dice_4: 3.627  loss_ce_5: 2.556  loss_mask_5: 0.6181  loss_dice_5: 3.623  loss_ce_6: 2.559  loss_mask_6: 0.6194  loss_dice_6: 3.61  loss_ce_7: 2.546  loss_mask_7: 0.6151  loss_dice_7: 3.609  loss_ce_8: 2.54  loss_mask_8: 0.6156  loss_dice_8: 3.612  time: 1.7001  data_time: 0.3412  lr: 8.6121e-06  max_mem: 17674M
[01/19 03:52:33] d2.utils.events INFO:  eta: 15:51:14  iter: 6139  total_loss: 70.69  loss_ce: 2.702  loss_mask: 0.6302  loss_dice: 3.558  loss_ce_0: 3.899  loss_mask_0: 0.6511  loss_dice_0: 3.842  loss_ce_1: 2.853  loss_mask_1: 0.6499  loss_dice_1: 3.691  loss_ce_2: 2.709  loss_mask_2: 0.6454  loss_dice_2: 3.625  loss_ce_3: 2.69  loss_mask_3: 0.6387  loss_dice_3: 3.583  loss_ce_4: 2.675  loss_mask_4: 0.6424  loss_dice_4: 3.574  loss_ce_5: 2.679  loss_mask_5: 0.6396  loss_dice_5: 3.574  loss_ce_6: 2.681  loss_mask_6: 0.6386  loss_dice_6: 3.56  loss_ce_7: 2.685  loss_mask_7: 0.6353  loss_dice_7: 3.558  loss_ce_8: 2.672  loss_mask_8: 0.6334  loss_dice_8: 3.565  time: 1.7001  data_time: 0.3471  lr: 8.6075e-06  max_mem: 17674M
[01/19 03:53:06] d2.utils.events INFO:  eta: 15:50:25  iter: 6159  total_loss: 70.13  loss_ce: 2.621  loss_mask: 0.6457  loss_dice: 3.565  loss_ce_0: 3.906  loss_mask_0: 0.6574  loss_dice_0: 3.822  loss_ce_1: 2.809  loss_mask_1: 0.6532  loss_dice_1: 3.686  loss_ce_2: 2.663  loss_mask_2: 0.6514  loss_dice_2: 3.62  loss_ce_3: 2.634  loss_mask_3: 0.6418  loss_dice_3: 3.578  loss_ce_4: 2.622  loss_mask_4: 0.6412  loss_dice_4: 3.582  loss_ce_5: 2.636  loss_mask_5: 0.6456  loss_dice_5: 3.578  loss_ce_6: 2.625  loss_mask_6: 0.6462  loss_dice_6: 3.566  loss_ce_7: 2.61  loss_mask_7: 0.6461  loss_dice_7: 3.569  loss_ce_8: 2.616  loss_mask_8: 0.6455  loss_dice_8: 3.568  time: 1.6999  data_time: 0.3412  lr: 8.6029e-06  max_mem: 17674M
[01/19 03:53:40] d2.utils.events INFO:  eta: 15:49:47  iter: 6179  total_loss: 70.66  loss_ce: 2.633  loss_mask: 0.6355  loss_dice: 3.59  loss_ce_0: 3.934  loss_mask_0: 0.6466  loss_dice_0: 3.838  loss_ce_1: 2.833  loss_mask_1: 0.6513  loss_dice_1: 3.726  loss_ce_2: 2.693  loss_mask_2: 0.6417  loss_dice_2: 3.66  loss_ce_3: 2.678  loss_mask_3: 0.6348  loss_dice_3: 3.616  loss_ce_4: 2.621  loss_mask_4: 0.6389  loss_dice_4: 3.607  loss_ce_5: 2.634  loss_mask_5: 0.6375  loss_dice_5: 3.606  loss_ce_6: 2.633  loss_mask_6: 0.6354  loss_dice_6: 3.595  loss_ce_7: 2.617  loss_mask_7: 0.6352  loss_dice_7: 3.597  loss_ce_8: 2.633  loss_mask_8: 0.6359  loss_dice_8: 3.598  time: 1.6998  data_time: 0.3231  lr: 8.5983e-06  max_mem: 17674M
[01/19 03:54:14] d2.utils.events INFO:  eta: 15:48:49  iter: 6199  total_loss: 70.69  loss_ce: 2.663  loss_mask: 0.6264  loss_dice: 3.539  loss_ce_0: 3.894  loss_mask_0: 0.6504  loss_dice_0: 3.815  loss_ce_1: 2.795  loss_mask_1: 0.6416  loss_dice_1: 3.664  loss_ce_2: 2.698  loss_mask_2: 0.6405  loss_dice_2: 3.594  loss_ce_3: 2.662  loss_mask_3: 0.6341  loss_dice_3: 3.561  loss_ce_4: 2.661  loss_mask_4: 0.6303  loss_dice_4: 3.558  loss_ce_5: 2.636  loss_mask_5: 0.6309  loss_dice_5: 3.549  loss_ce_6: 2.641  loss_mask_6: 0.6286  loss_dice_6: 3.544  loss_ce_7: 2.636  loss_mask_7: 0.6267  loss_dice_7: 3.547  loss_ce_8: 2.649  loss_mask_8: 0.6278  loss_dice_8: 3.546  time: 1.6998  data_time: 0.3447  lr: 8.5937e-06  max_mem: 17674M
[01/19 03:54:47] d2.utils.events INFO:  eta: 15:48:15  iter: 6219  total_loss: 70.39  loss_ce: 2.618  loss_mask: 0.6461  loss_dice: 3.527  loss_ce_0: 3.835  loss_mask_0: 0.6588  loss_dice_0: 3.819  loss_ce_1: 2.846  loss_mask_1: 0.6645  loss_dice_1: 3.676  loss_ce_2: 2.688  loss_mask_2: 0.659  loss_dice_2: 3.591  loss_ce_3: 2.653  loss_mask_3: 0.6503  loss_dice_3: 3.557  loss_ce_4: 2.631  loss_mask_4: 0.6494  loss_dice_4: 3.557  loss_ce_5: 2.62  loss_mask_5: 0.6495  loss_dice_5: 3.555  loss_ce_6: 2.621  loss_mask_6: 0.6484  loss_dice_6: 3.537  loss_ce_7: 2.616  loss_mask_7: 0.6471  loss_dice_7: 3.538  loss_ce_8: 2.609  loss_mask_8: 0.6456  loss_dice_8: 3.539  time: 1.6997  data_time: 0.3473  lr: 8.5892e-06  max_mem: 17674M
[01/19 03:55:21] d2.utils.events INFO:  eta: 15:47:41  iter: 6239  total_loss: 71.64  loss_ce: 2.834  loss_mask: 0.6527  loss_dice: 3.495  loss_ce_0: 3.873  loss_mask_0: 0.6707  loss_dice_0: 3.796  loss_ce_1: 2.963  loss_mask_1: 0.6643  loss_dice_1: 3.648  loss_ce_2: 2.839  loss_mask_2: 0.658  loss_dice_2: 3.564  loss_ce_3: 2.841  loss_mask_3: 0.6576  loss_dice_3: 3.522  loss_ce_4: 2.81  loss_mask_4: 0.6556  loss_dice_4: 3.521  loss_ce_5: 2.83  loss_mask_5: 0.6559  loss_dice_5: 3.512  loss_ce_6: 2.829  loss_mask_6: 0.6537  loss_dice_6: 3.501  loss_ce_7: 2.826  loss_mask_7: 0.6519  loss_dice_7: 3.5  loss_ce_8: 2.813  loss_mask_8: 0.6536  loss_dice_8: 3.498  time: 1.6997  data_time: 0.3585  lr: 8.5846e-06  max_mem: 17674M
[01/19 03:55:55] d2.utils.events INFO:  eta: 15:46:37  iter: 6259  total_loss: 70.8  loss_ce: 2.686  loss_mask: 0.6371  loss_dice: 3.511  loss_ce_0: 3.936  loss_mask_0: 0.6596  loss_dice_0: 3.805  loss_ce_1: 2.862  loss_mask_1: 0.6577  loss_dice_1: 3.668  loss_ce_2: 2.72  loss_mask_2: 0.6448  loss_dice_2: 3.583  loss_ce_3: 2.702  loss_mask_3: 0.6379  loss_dice_3: 3.537  loss_ce_4: 2.689  loss_mask_4: 0.6381  loss_dice_4: 3.533  loss_ce_5: 2.689  loss_mask_5: 0.6343  loss_dice_5: 3.533  loss_ce_6: 2.703  loss_mask_6: 0.6343  loss_dice_6: 3.516  loss_ce_7: 2.675  loss_mask_7: 0.6348  loss_dice_7: 3.508  loss_ce_8: 2.678  loss_mask_8: 0.6363  loss_dice_8: 3.517  time: 1.6996  data_time: 0.3428  lr: 8.58e-06  max_mem: 17674M
[01/19 03:56:28] d2.utils.events INFO:  eta: 15:45:13  iter: 6279  total_loss: 69.92  loss_ce: 2.669  loss_mask: 0.6345  loss_dice: 3.5  loss_ce_0: 3.896  loss_mask_0: 0.6534  loss_dice_0: 3.791  loss_ce_1: 2.753  loss_mask_1: 0.6537  loss_dice_1: 3.666  loss_ce_2: 2.66  loss_mask_2: 0.6453  loss_dice_2: 3.58  loss_ce_3: 2.644  loss_mask_3: 0.6396  loss_dice_3: 3.533  loss_ce_4: 2.664  loss_mask_4: 0.6404  loss_dice_4: 3.522  loss_ce_5: 2.63  loss_mask_5: 0.6383  loss_dice_5: 3.524  loss_ce_6: 2.632  loss_mask_6: 0.6399  loss_dice_6: 3.516  loss_ce_7: 2.626  loss_mask_7: 0.6405  loss_dice_7: 3.508  loss_ce_8: 2.647  loss_mask_8: 0.6382  loss_dice_8: 3.507  time: 1.6994  data_time: 0.3194  lr: 8.5754e-06  max_mem: 17674M
[01/19 03:57:03] d2.utils.events INFO:  eta: 15:44:49  iter: 6299  total_loss: 70.48  loss_ce: 2.629  loss_mask: 0.6436  loss_dice: 3.569  loss_ce_0: 3.923  loss_mask_0: 0.6509  loss_dice_0: 3.839  loss_ce_1: 2.805  loss_mask_1: 0.6549  loss_dice_1: 3.716  loss_ce_2: 2.679  loss_mask_2: 0.648  loss_dice_2: 3.64  loss_ce_3: 2.634  loss_mask_3: 0.6434  loss_dice_3: 3.593  loss_ce_4: 2.613  loss_mask_4: 0.6443  loss_dice_4: 3.585  loss_ce_5: 2.622  loss_mask_5: 0.6464  loss_dice_5: 3.587  loss_ce_6: 2.646  loss_mask_6: 0.6429  loss_dice_6: 3.573  loss_ce_7: 2.625  loss_mask_7: 0.6447  loss_dice_7: 3.57  loss_ce_8: 2.608  loss_mask_8: 0.6409  loss_dice_8: 3.573  time: 1.6996  data_time: 0.4171  lr: 8.5709e-06  max_mem: 17674M
[01/19 03:57:38] d2.utils.events INFO:  eta: 15:44:30  iter: 6319  total_loss: 69.82  loss_ce: 2.544  loss_mask: 0.6184  loss_dice: 3.577  loss_ce_0: 3.924  loss_mask_0: 0.6367  loss_dice_0: 3.837  loss_ce_1: 2.731  loss_mask_1: 0.6382  loss_dice_1: 3.72  loss_ce_2: 2.601  loss_mask_2: 0.6245  loss_dice_2: 3.639  loss_ce_3: 2.569  loss_mask_3: 0.621  loss_dice_3: 3.606  loss_ce_4: 2.554  loss_mask_4: 0.6192  loss_dice_4: 3.595  loss_ce_5: 2.537  loss_mask_5: 0.6199  loss_dice_5: 3.598  loss_ce_6: 2.55  loss_mask_6: 0.6191  loss_dice_6: 3.583  loss_ce_7: 2.551  loss_mask_7: 0.6165  loss_dice_7: 3.579  loss_ce_8: 2.542  loss_mask_8: 0.6172  loss_dice_8: 3.583  time: 1.6997  data_time: 0.3954  lr: 8.5663e-06  max_mem: 17674M
[01/19 03:58:14] d2.utils.events INFO:  eta: 15:44:27  iter: 6339  total_loss: 70.38  loss_ce: 2.626  loss_mask: 0.6316  loss_dice: 3.554  loss_ce_0: 3.832  loss_mask_0: 0.6508  loss_dice_0: 3.838  loss_ce_1: 2.785  loss_mask_1: 0.6436  loss_dice_1: 3.695  loss_ce_2: 2.665  loss_mask_2: 0.634  loss_dice_2: 3.621  loss_ce_3: 2.65  loss_mask_3: 0.6285  loss_dice_3: 3.585  loss_ce_4: 2.614  loss_mask_4: 0.6296  loss_dice_4: 3.58  loss_ce_5: 2.611  loss_mask_5: 0.631  loss_dice_5: 3.575  loss_ce_6: 2.62  loss_mask_6: 0.6323  loss_dice_6: 3.565  loss_ce_7: 2.608  loss_mask_7: 0.6331  loss_dice_7: 3.561  loss_ce_8: 2.62  loss_mask_8: 0.6325  loss_dice_8: 3.562  time: 1.7001  data_time: 0.4802  lr: 8.5617e-06  max_mem: 17674M
[01/19 03:58:51] d2.utils.events INFO:  eta: 15:44:52  iter: 6359  total_loss: 69.85  loss_ce: 2.644  loss_mask: 0.6281  loss_dice: 3.57  loss_ce_0: 3.86  loss_mask_0: 0.645  loss_dice_0: 3.837  loss_ce_1: 2.802  loss_mask_1: 0.6377  loss_dice_1: 3.699  loss_ce_2: 2.658  loss_mask_2: 0.6321  loss_dice_2: 3.621  loss_ce_3: 2.624  loss_mask_3: 0.6304  loss_dice_3: 3.584  loss_ce_4: 2.613  loss_mask_4: 0.6314  loss_dice_4: 3.58  loss_ce_5: 2.618  loss_mask_5: 0.6305  loss_dice_5: 3.575  loss_ce_6: 2.617  loss_mask_6: 0.6289  loss_dice_6: 3.564  loss_ce_7: 2.634  loss_mask_7: 0.6273  loss_dice_7: 3.567  loss_ce_8: 2.604  loss_mask_8: 0.6282  loss_dice_8: 3.577  time: 1.7005  data_time: 0.4862  lr: 8.5571e-06  max_mem: 17674M
[01/19 03:59:27] d2.utils.events INFO:  eta: 15:45:14  iter: 6379  total_loss: 70.77  loss_ce: 2.72  loss_mask: 0.6439  loss_dice: 3.542  loss_ce_0: 3.899  loss_mask_0: 0.6562  loss_dice_0: 3.833  loss_ce_1: 2.888  loss_mask_1: 0.6609  loss_dice_1: 3.695  loss_ce_2: 2.711  loss_mask_2: 0.6514  loss_dice_2: 3.615  loss_ce_3: 2.692  loss_mask_3: 0.6427  loss_dice_3: 3.575  loss_ce_4: 2.696  loss_mask_4: 0.6422  loss_dice_4: 3.575  loss_ce_5: 2.691  loss_mask_5: 0.6444  loss_dice_5: 3.56  loss_ce_6: 2.709  loss_mask_6: 0.6458  loss_dice_6: 3.545  loss_ce_7: 2.691  loss_mask_7: 0.6451  loss_dice_7: 3.545  loss_ce_8: 2.717  loss_mask_8: 0.6472  loss_dice_8: 3.546  time: 1.7008  data_time: 0.4968  lr: 8.5525e-06  max_mem: 17674M
[01/19 04:00:03] d2.utils.events INFO:  eta: 15:45:19  iter: 6399  total_loss: 69.43  loss_ce: 2.641  loss_mask: 0.6265  loss_dice: 3.56  loss_ce_0: 3.851  loss_mask_0: 0.6493  loss_dice_0: 3.831  loss_ce_1: 2.769  loss_mask_1: 0.6547  loss_dice_1: 3.699  loss_ce_2: 2.692  loss_mask_2: 0.6471  loss_dice_2: 3.629  loss_ce_3: 2.659  loss_mask_3: 0.6362  loss_dice_3: 3.578  loss_ce_4: 2.639  loss_mask_4: 0.6389  loss_dice_4: 3.581  loss_ce_5: 2.638  loss_mask_5: 0.6335  loss_dice_5: 3.579  loss_ce_6: 2.64  loss_mask_6: 0.634  loss_dice_6: 3.567  loss_ce_7: 2.636  loss_mask_7: 0.6314  loss_dice_7: 3.566  loss_ce_8: 2.629  loss_mask_8: 0.631  loss_dice_8: 3.564  time: 1.7011  data_time: 0.4573  lr: 8.548e-06  max_mem: 17674M
[01/19 04:00:41] d2.utils.events INFO:  eta: 15:45:18  iter: 6419  total_loss: 70.09  loss_ce: 2.652  loss_mask: 0.6428  loss_dice: 3.528  loss_ce_0: 3.882  loss_mask_0: 0.6626  loss_dice_0: 3.811  loss_ce_1: 2.837  loss_mask_1: 0.6571  loss_dice_1: 3.661  loss_ce_2: 2.704  loss_mask_2: 0.6479  loss_dice_2: 3.592  loss_ce_3: 2.668  loss_mask_3: 0.6456  loss_dice_3: 3.539  loss_ce_4: 2.653  loss_mask_4: 0.6416  loss_dice_4: 3.548  loss_ce_5: 2.658  loss_mask_5: 0.6391  loss_dice_5: 3.544  loss_ce_6: 2.68  loss_mask_6: 0.6384  loss_dice_6: 3.53  loss_ce_7: 2.634  loss_mask_7: 0.6418  loss_dice_7: 3.537  loss_ce_8: 2.647  loss_mask_8: 0.6386  loss_dice_8: 3.536  time: 1.7017  data_time: 0.5450  lr: 8.5434e-06  max_mem: 17674M
[01/19 04:01:17] d2.utils.events INFO:  eta: 15:45:22  iter: 6439  total_loss: 70.14  loss_ce: 2.676  loss_mask: 0.6366  loss_dice: 3.523  loss_ce_0: 3.881  loss_mask_0: 0.6547  loss_dice_0: 3.807  loss_ce_1: 2.841  loss_mask_1: 0.6624  loss_dice_1: 3.674  loss_ce_2: 2.74  loss_mask_2: 0.6535  loss_dice_2: 3.592  loss_ce_3: 2.716  loss_mask_3: 0.6395  loss_dice_3: 3.548  loss_ce_4: 2.685  loss_mask_4: 0.6451  loss_dice_4: 3.536  loss_ce_5: 2.675  loss_mask_5: 0.6441  loss_dice_5: 3.539  loss_ce_6: 2.67  loss_mask_6: 0.6387  loss_dice_6: 3.52  loss_ce_7: 2.665  loss_mask_7: 0.6377  loss_dice_7: 3.52  loss_ce_8: 2.691  loss_mask_8: 0.6395  loss_dice_8: 3.513  time: 1.7020  data_time: 0.4775  lr: 8.5388e-06  max_mem: 17674M
[01/19 04:01:52] d2.utils.events INFO:  eta: 15:44:58  iter: 6459  total_loss: 70.55  loss_ce: 2.653  loss_mask: 0.6289  loss_dice: 3.532  loss_ce_0: 3.924  loss_mask_0: 0.6491  loss_dice_0: 3.814  loss_ce_1: 2.823  loss_mask_1: 0.6471  loss_dice_1: 3.67  loss_ce_2: 2.676  loss_mask_2: 0.6441  loss_dice_2: 3.597  loss_ce_3: 2.661  loss_mask_3: 0.6366  loss_dice_3: 3.555  loss_ce_4: 2.629  loss_mask_4: 0.632  loss_dice_4: 3.554  loss_ce_5: 2.643  loss_mask_5: 0.631  loss_dice_5: 3.556  loss_ce_6: 2.647  loss_mask_6: 0.6313  loss_dice_6: 3.542  loss_ce_7: 2.641  loss_mask_7: 0.631  loss_dice_7: 3.539  loss_ce_8: 2.663  loss_mask_8: 0.6301  loss_dice_8: 3.536  time: 1.7022  data_time: 0.4374  lr: 8.5342e-06  max_mem: 17674M
[01/19 04:02:28] d2.utils.events INFO:  eta: 15:44:47  iter: 6479  total_loss: 70.03  loss_ce: 2.643  loss_mask: 0.6268  loss_dice: 3.535  loss_ce_0: 3.842  loss_mask_0: 0.6453  loss_dice_0: 3.82  loss_ce_1: 2.788  loss_mask_1: 0.6393  loss_dice_1: 3.668  loss_ce_2: 2.67  loss_mask_2: 0.6292  loss_dice_2: 3.6  loss_ce_3: 2.669  loss_mask_3: 0.6314  loss_dice_3: 3.559  loss_ce_4: 2.634  loss_mask_4: 0.6286  loss_dice_4: 3.549  loss_ce_5: 2.619  loss_mask_5: 0.6297  loss_dice_5: 3.549  loss_ce_6: 2.635  loss_mask_6: 0.6279  loss_dice_6: 3.535  loss_ce_7: 2.613  loss_mask_7: 0.6279  loss_dice_7: 3.534  loss_ce_8: 2.626  loss_mask_8: 0.6292  loss_dice_8: 3.532  time: 1.7025  data_time: 0.4333  lr: 8.5297e-06  max_mem: 17674M
[01/19 04:03:04] d2.utils.events INFO:  eta: 15:44:33  iter: 6499  total_loss: 69.69  loss_ce: 2.591  loss_mask: 0.6141  loss_dice: 3.563  loss_ce_0: 3.843  loss_mask_0: 0.6276  loss_dice_0: 3.845  loss_ce_1: 2.746  loss_mask_1: 0.6263  loss_dice_1: 3.696  loss_ce_2: 2.614  loss_mask_2: 0.6255  loss_dice_2: 3.626  loss_ce_3: 2.607  loss_mask_3: 0.6192  loss_dice_3: 3.586  loss_ce_4: 2.566  loss_mask_4: 0.6172  loss_dice_4: 3.583  loss_ce_5: 2.583  loss_mask_5: 0.6172  loss_dice_5: 3.576  loss_ce_6: 2.592  loss_mask_6: 0.6162  loss_dice_6: 3.564  loss_ce_7: 2.578  loss_mask_7: 0.6159  loss_dice_7: 3.568  loss_ce_8: 2.579  loss_mask_8: 0.6147  loss_dice_8: 3.564  time: 1.7028  data_time: 0.4332  lr: 8.5251e-06  max_mem: 17674M
[01/19 04:03:40] d2.utils.events INFO:  eta: 15:44:42  iter: 6519  total_loss: 69.81  loss_ce: 2.652  loss_mask: 0.6346  loss_dice: 3.491  loss_ce_0: 3.91  loss_mask_0: 0.6579  loss_dice_0: 3.789  loss_ce_1: 2.802  loss_mask_1: 0.6501  loss_dice_1: 3.636  loss_ce_2: 2.691  loss_mask_2: 0.6417  loss_dice_2: 3.563  loss_ce_3: 2.68  loss_mask_3: 0.637  loss_dice_3: 3.519  loss_ce_4: 2.655  loss_mask_4: 0.6406  loss_dice_4: 3.513  loss_ce_5: 2.641  loss_mask_5: 0.6392  loss_dice_5: 3.507  loss_ce_6: 2.641  loss_mask_6: 0.6355  loss_dice_6: 3.495  loss_ce_7: 2.643  loss_mask_7: 0.6376  loss_dice_7: 3.489  loss_ce_8: 2.64  loss_mask_8: 0.6349  loss_dice_8: 3.487  time: 1.7030  data_time: 0.4438  lr: 8.5205e-06  max_mem: 17674M
[01/19 04:04:16] d2.utils.events INFO:  eta: 15:44:47  iter: 6539  total_loss: 69.52  loss_ce: 2.591  loss_mask: 0.6278  loss_dice: 3.538  loss_ce_0: 3.866  loss_mask_0: 0.6367  loss_dice_0: 3.814  loss_ce_1: 2.767  loss_mask_1: 0.6375  loss_dice_1: 3.676  loss_ce_2: 2.671  loss_mask_2: 0.6344  loss_dice_2: 3.6  loss_ce_3: 2.64  loss_mask_3: 0.6327  loss_dice_3: 3.553  loss_ce_4: 2.595  loss_mask_4: 0.6339  loss_dice_4: 3.552  loss_ce_5: 2.574  loss_mask_5: 0.6292  loss_dice_5: 3.557  loss_ce_6: 2.595  loss_mask_6: 0.6308  loss_dice_6: 3.541  loss_ce_7: 2.575  loss_mask_7: 0.6286  loss_dice_7: 3.539  loss_ce_8: 2.562  loss_mask_8: 0.6288  loss_dice_8: 3.537  time: 1.7033  data_time: 0.4526  lr: 8.5159e-06  max_mem: 17674M
[01/19 04:04:50] d2.utils.events INFO:  eta: 15:44:26  iter: 6559  total_loss: 70.75  loss_ce: 2.717  loss_mask: 0.6409  loss_dice: 3.488  loss_ce_0: 3.946  loss_mask_0: 0.6674  loss_dice_0: 3.777  loss_ce_1: 2.868  loss_mask_1: 0.6627  loss_dice_1: 3.628  loss_ce_2: 2.73  loss_mask_2: 0.6524  loss_dice_2: 3.552  loss_ce_3: 2.727  loss_mask_3: 0.6497  loss_dice_3: 3.514  loss_ce_4: 2.691  loss_mask_4: 0.6505  loss_dice_4: 3.506  loss_ce_5: 2.701  loss_mask_5: 0.6468  loss_dice_5: 3.509  loss_ce_6: 2.714  loss_mask_6: 0.6456  loss_dice_6: 3.495  loss_ce_7: 2.693  loss_mask_7: 0.6469  loss_dice_7: 3.499  loss_ce_8: 2.694  loss_mask_8: 0.6435  loss_dice_8: 3.498  time: 1.7033  data_time: 0.3901  lr: 8.5113e-06  max_mem: 17674M
[01/19 04:05:27] d2.utils.events INFO:  eta: 15:44:56  iter: 6579  total_loss: 70.3  loss_ce: 2.748  loss_mask: 0.629  loss_dice: 3.519  loss_ce_0: 3.851  loss_mask_0: 0.6361  loss_dice_0: 3.804  loss_ce_1: 2.913  loss_mask_1: 0.6382  loss_dice_1: 3.66  loss_ce_2: 2.764  loss_mask_2: 0.6359  loss_dice_2: 3.586  loss_ce_3: 2.746  loss_mask_3: 0.6308  loss_dice_3: 3.54  loss_ce_4: 2.73  loss_mask_4: 0.6306  loss_dice_4: 3.545  loss_ce_5: 2.726  loss_mask_5: 0.6307  loss_dice_5: 3.538  loss_ce_6: 2.736  loss_mask_6: 0.6311  loss_dice_6: 3.519  loss_ce_7: 2.736  loss_mask_7: 0.6291  loss_dice_7: 3.521  loss_ce_8: 2.742  loss_mask_8: 0.6305  loss_dice_8: 3.526  time: 1.7036  data_time: 0.4746  lr: 8.5067e-06  max_mem: 17674M
[01/19 04:06:04] d2.utils.events INFO:  eta: 15:45:43  iter: 6599  total_loss: 69.98  loss_ce: 2.598  loss_mask: 0.6329  loss_dice: 3.527  loss_ce_0: 3.859  loss_mask_0: 0.6521  loss_dice_0: 3.804  loss_ce_1: 2.809  loss_mask_1: 0.6536  loss_dice_1: 3.659  loss_ce_2: 2.661  loss_mask_2: 0.6464  loss_dice_2: 3.589  loss_ce_3: 2.624  loss_mask_3: 0.6376  loss_dice_3: 3.546  loss_ce_4: 2.604  loss_mask_4: 0.6365  loss_dice_4: 3.545  loss_ce_5: 2.594  loss_mask_5: 0.633  loss_dice_5: 3.536  loss_ce_6: 2.588  loss_mask_6: 0.6365  loss_dice_6: 3.532  loss_ce_7: 2.593  loss_mask_7: 0.6345  loss_dice_7: 3.53  loss_ce_8: 2.576  loss_mask_8: 0.6342  loss_dice_8: 3.526  time: 1.7041  data_time: 0.5386  lr: 8.5022e-06  max_mem: 17674M
[01/19 04:06:40] d2.utils.events INFO:  eta: 15:45:45  iter: 6619  total_loss: 69.84  loss_ce: 2.671  loss_mask: 0.6354  loss_dice: 3.476  loss_ce_0: 3.867  loss_mask_0: 0.6484  loss_dice_0: 3.763  loss_ce_1: 2.822  loss_mask_1: 0.6451  loss_dice_1: 3.632  loss_ce_2: 2.709  loss_mask_2: 0.6409  loss_dice_2: 3.549  loss_ce_3: 2.671  loss_mask_3: 0.6359  loss_dice_3: 3.504  loss_ce_4: 2.646  loss_mask_4: 0.6402  loss_dice_4: 3.502  loss_ce_5: 2.632  loss_mask_5: 0.6368  loss_dice_5: 3.499  loss_ce_6: 2.664  loss_mask_6: 0.6359  loss_dice_6: 3.478  loss_ce_7: 2.646  loss_mask_7: 0.6363  loss_dice_7: 3.48  loss_ce_8: 2.666  loss_mask_8: 0.6346  loss_dice_8: 3.477  time: 1.7044  data_time: 0.4783  lr: 8.4976e-06  max_mem: 17674M
[01/19 04:07:20] d2.utils.events INFO:  eta: 15:46:04  iter: 6639  total_loss: 69.7  loss_ce: 2.651  loss_mask: 0.6399  loss_dice: 3.485  loss_ce_0: 3.917  loss_mask_0: 0.6565  loss_dice_0: 3.789  loss_ce_1: 2.813  loss_mask_1: 0.6562  loss_dice_1: 3.647  loss_ce_2: 2.685  loss_mask_2: 0.6485  loss_dice_2: 3.563  loss_ce_3: 2.67  loss_mask_3: 0.6402  loss_dice_3: 3.516  loss_ce_4: 2.645  loss_mask_4: 0.6404  loss_dice_4: 3.511  loss_ce_5: 2.656  loss_mask_5: 0.6441  loss_dice_5: 3.504  loss_ce_6: 2.66  loss_mask_6: 0.6424  loss_dice_6: 3.49  loss_ce_7: 2.656  loss_mask_7: 0.6449  loss_dice_7: 3.493  loss_ce_8: 2.644  loss_mask_8: 0.6418  loss_dice_8: 3.493  time: 1.7053  data_time: 0.7082  lr: 8.493e-06  max_mem: 17674M
[01/19 04:07:56] d2.utils.events INFO:  eta: 15:45:56  iter: 6659  total_loss: 69.41  loss_ce: 2.661  loss_mask: 0.6319  loss_dice: 3.528  loss_ce_0: 3.837  loss_mask_0: 0.6431  loss_dice_0: 3.81  loss_ce_1: 2.789  loss_mask_1: 0.6421  loss_dice_1: 3.674  loss_ce_2: 2.685  loss_mask_2: 0.6353  loss_dice_2: 3.592  loss_ce_3: 2.663  loss_mask_3: 0.6319  loss_dice_3: 3.546  loss_ce_4: 2.642  loss_mask_4: 0.6331  loss_dice_4: 3.545  loss_ce_5: 2.642  loss_mask_5: 0.6312  loss_dice_5: 3.542  loss_ce_6: 2.635  loss_mask_6: 0.633  loss_dice_6: 3.531  loss_ce_7: 2.65  loss_mask_7: 0.6312  loss_dice_7: 3.528  loss_ce_8: 2.653  loss_mask_8: 0.6318  loss_dice_8: 3.525  time: 1.7056  data_time: 0.4718  lr: 8.4884e-06  max_mem: 17674M
[01/19 04:08:30] d2.utils.events INFO:  eta: 15:45:22  iter: 6679  total_loss: 69.37  loss_ce: 2.575  loss_mask: 0.6406  loss_dice: 3.563  loss_ce_0: 3.796  loss_mask_0: 0.6627  loss_dice_0: 3.819  loss_ce_1: 2.718  loss_mask_1: 0.6574  loss_dice_1: 3.692  loss_ce_2: 2.596  loss_mask_2: 0.649  loss_dice_2: 3.624  loss_ce_3: 2.567  loss_mask_3: 0.6401  loss_dice_3: 3.594  loss_ce_4: 2.544  loss_mask_4: 0.6423  loss_dice_4: 3.586  loss_ce_5: 2.536  loss_mask_5: 0.6392  loss_dice_5: 3.588  loss_ce_6: 2.566  loss_mask_6: 0.6405  loss_dice_6: 3.572  loss_ce_7: 2.56  loss_mask_7: 0.6394  loss_dice_7: 3.573  loss_ce_8: 2.563  loss_mask_8: 0.6409  loss_dice_8: 3.569  time: 1.7056  data_time: 0.3406  lr: 8.4838e-06  max_mem: 17674M
[01/19 04:09:04] d2.utils.events INFO:  eta: 15:44:31  iter: 6699  total_loss: 69.72  loss_ce: 2.639  loss_mask: 0.6328  loss_dice: 3.545  loss_ce_0: 3.913  loss_mask_0: 0.6469  loss_dice_0: 3.806  loss_ce_1: 2.799  loss_mask_1: 0.6448  loss_dice_1: 3.688  loss_ce_2: 2.67  loss_mask_2: 0.6413  loss_dice_2: 3.611  loss_ce_3: 2.631  loss_mask_3: 0.6331  loss_dice_3: 3.577  loss_ce_4: 2.601  loss_mask_4: 0.6352  loss_dice_4: 3.576  loss_ce_5: 2.595  loss_mask_5: 0.6343  loss_dice_5: 3.565  loss_ce_6: 2.58  loss_mask_6: 0.6344  loss_dice_6: 3.548  loss_ce_7: 2.586  loss_mask_7: 0.6358  loss_dice_7: 3.548  loss_ce_8: 2.616  loss_mask_8: 0.6336  loss_dice_8: 3.546  time: 1.7055  data_time: 0.3440  lr: 8.4793e-06  max_mem: 17674M
[01/19 04:09:38] d2.utils.events INFO:  eta: 15:43:42  iter: 6719  total_loss: 69.76  loss_ce: 2.672  loss_mask: 0.6394  loss_dice: 3.487  loss_ce_0: 3.95  loss_mask_0: 0.6607  loss_dice_0: 3.773  loss_ce_1: 2.835  loss_mask_1: 0.6509  loss_dice_1: 3.631  loss_ce_2: 2.729  loss_mask_2: 0.6424  loss_dice_2: 3.558  loss_ce_3: 2.7  loss_mask_3: 0.6422  loss_dice_3: 3.519  loss_ce_4: 2.686  loss_mask_4: 0.6411  loss_dice_4: 3.509  loss_ce_5: 2.655  loss_mask_5: 0.6411  loss_dice_5: 3.502  loss_ce_6: 2.67  loss_mask_6: 0.6405  loss_dice_6: 3.494  loss_ce_7: 2.675  loss_mask_7: 0.639  loss_dice_7: 3.491  loss_ce_8: 2.655  loss_mask_8: 0.6397  loss_dice_8: 3.49  time: 1.7054  data_time: 0.3348  lr: 8.4747e-06  max_mem: 17674M
[01/19 04:10:11] d2.utils.events INFO:  eta: 15:42:57  iter: 6739  total_loss: 70.15  loss_ce: 2.695  loss_mask: 0.6424  loss_dice: 3.508  loss_ce_0: 3.884  loss_mask_0: 0.6508  loss_dice_0: 3.802  loss_ce_1: 2.843  loss_mask_1: 0.6541  loss_dice_1: 3.666  loss_ce_2: 2.71  loss_mask_2: 0.6468  loss_dice_2: 3.598  loss_ce_3: 2.71  loss_mask_3: 0.6413  loss_dice_3: 3.551  loss_ce_4: 2.686  loss_mask_4: 0.6435  loss_dice_4: 3.536  loss_ce_5: 2.7  loss_mask_5: 0.6415  loss_dice_5: 3.527  loss_ce_6: 2.683  loss_mask_6: 0.6421  loss_dice_6: 3.527  loss_ce_7: 2.678  loss_mask_7: 0.6413  loss_dice_7: 3.517  loss_ce_8: 2.663  loss_mask_8: 0.6417  loss_dice_8: 3.517  time: 1.7053  data_time: 0.3197  lr: 8.4701e-06  max_mem: 17674M
[01/19 04:10:45] d2.utils.events INFO:  eta: 15:42:23  iter: 6759  total_loss: 68.9  loss_ce: 2.521  loss_mask: 0.6229  loss_dice: 3.565  loss_ce_0: 3.859  loss_mask_0: 0.6487  loss_dice_0: 3.839  loss_ce_1: 2.671  loss_mask_1: 0.6439  loss_dice_1: 3.704  loss_ce_2: 2.551  loss_mask_2: 0.6343  loss_dice_2: 3.631  loss_ce_3: 2.533  loss_mask_3: 0.6297  loss_dice_3: 3.582  loss_ce_4: 2.493  loss_mask_4: 0.6274  loss_dice_4: 3.582  loss_ce_5: 2.488  loss_mask_5: 0.6246  loss_dice_5: 3.576  loss_ce_6: 2.517  loss_mask_6: 0.6228  loss_dice_6: 3.568  loss_ce_7: 2.507  loss_mask_7: 0.623  loss_dice_7: 3.569  loss_ce_8: 2.503  loss_mask_8: 0.623  loss_dice_8: 3.56  time: 1.7053  data_time: 0.3544  lr: 8.4655e-06  max_mem: 17674M
[01/19 04:11:19] d2.utils.events INFO:  eta: 15:41:49  iter: 6779  total_loss: 69.9  loss_ce: 2.605  loss_mask: 0.6262  loss_dice: 3.495  loss_ce_0: 3.816  loss_mask_0: 0.6455  loss_dice_0: 3.798  loss_ce_1: 2.781  loss_mask_1: 0.6396  loss_dice_1: 3.641  loss_ce_2: 2.652  loss_mask_2: 0.6297  loss_dice_2: 3.559  loss_ce_3: 2.605  loss_mask_3: 0.623  loss_dice_3: 3.516  loss_ce_4: 2.582  loss_mask_4: 0.6253  loss_dice_4: 3.505  loss_ce_5: 2.568  loss_mask_5: 0.6241  loss_dice_5: 3.501  loss_ce_6: 2.578  loss_mask_6: 0.6225  loss_dice_6: 3.496  loss_ce_7: 2.581  loss_mask_7: 0.6231  loss_dice_7: 3.499  loss_ce_8: 2.584  loss_mask_8: 0.6262  loss_dice_8: 3.489  time: 1.7052  data_time: 0.3449  lr: 8.4609e-06  max_mem: 17674M
[01/19 04:11:52] d2.utils.events INFO:  eta: 15:41:25  iter: 6799  total_loss: 69.97  loss_ce: 2.616  loss_mask: 0.6357  loss_dice: 3.542  loss_ce_0: 3.788  loss_mask_0: 0.6506  loss_dice_0: 3.807  loss_ce_1: 2.769  loss_mask_1: 0.6478  loss_dice_1: 3.669  loss_ce_2: 2.662  loss_mask_2: 0.644  loss_dice_2: 3.6  loss_ce_3: 2.63  loss_mask_3: 0.6339  loss_dice_3: 3.556  loss_ce_4: 2.601  loss_mask_4: 0.6373  loss_dice_4: 3.557  loss_ce_5: 2.602  loss_mask_5: 0.6392  loss_dice_5: 3.555  loss_ce_6: 2.621  loss_mask_6: 0.6375  loss_dice_6: 3.556  loss_ce_7: 2.602  loss_mask_7: 0.6367  loss_dice_7: 3.551  loss_ce_8: 2.614  loss_mask_8: 0.6353  loss_dice_8: 3.555  time: 1.7051  data_time: 0.3376  lr: 8.4563e-06  max_mem: 17674M
[01/19 04:12:26] d2.utils.events INFO:  eta: 15:41:01  iter: 6819  total_loss: 69.5  loss_ce: 2.523  loss_mask: 0.6388  loss_dice: 3.548  loss_ce_0: 3.829  loss_mask_0: 0.65  loss_dice_0: 3.807  loss_ce_1: 2.687  loss_mask_1: 0.6507  loss_dice_1: 3.69  loss_ce_2: 2.574  loss_mask_2: 0.6448  loss_dice_2: 3.616  loss_ce_3: 2.551  loss_mask_3: 0.6411  loss_dice_3: 3.568  loss_ce_4: 2.526  loss_mask_4: 0.6418  loss_dice_4: 3.562  loss_ce_5: 2.489  loss_mask_5: 0.6447  loss_dice_5: 3.567  loss_ce_6: 2.519  loss_mask_6: 0.638  loss_dice_6: 3.554  loss_ce_7: 2.503  loss_mask_7: 0.6389  loss_dice_7: 3.552  loss_ce_8: 2.513  loss_mask_8: 0.6417  loss_dice_8: 3.551  time: 1.7051  data_time: 0.3470  lr: 8.4517e-06  max_mem: 17674M
[01/19 04:13:00] d2.utils.events INFO:  eta: 15:40:32  iter: 6839  total_loss: 69.35  loss_ce: 2.565  loss_mask: 0.6373  loss_dice: 3.531  loss_ce_0: 3.839  loss_mask_0: 0.6495  loss_dice_0: 3.78  loss_ce_1: 2.757  loss_mask_1: 0.6512  loss_dice_1: 3.658  loss_ce_2: 2.589  loss_mask_2: 0.6389  loss_dice_2: 3.597  loss_ce_3: 2.598  loss_mask_3: 0.6356  loss_dice_3: 3.55  loss_ce_4: 2.566  loss_mask_4: 0.635  loss_dice_4: 3.552  loss_ce_5: 2.575  loss_mask_5: 0.6358  loss_dice_5: 3.546  loss_ce_6: 2.562  loss_mask_6: 0.6378  loss_dice_6: 3.539  loss_ce_7: 2.552  loss_mask_7: 0.6406  loss_dice_7: 3.54  loss_ce_8: 2.553  loss_mask_8: 0.6371  loss_dice_8: 3.543  time: 1.7051  data_time: 0.3527  lr: 8.4472e-06  max_mem: 17674M
[01/19 04:13:34] d2.utils.events INFO:  eta: 15:40:06  iter: 6859  total_loss: 69.56  loss_ce: 2.604  loss_mask: 0.632  loss_dice: 3.515  loss_ce_0: 3.861  loss_mask_0: 0.6459  loss_dice_0: 3.811  loss_ce_1: 2.768  loss_mask_1: 0.6545  loss_dice_1: 3.668  loss_ce_2: 2.644  loss_mask_2: 0.6396  loss_dice_2: 3.586  loss_ce_3: 2.617  loss_mask_3: 0.6379  loss_dice_3: 3.533  loss_ce_4: 2.582  loss_mask_4: 0.6352  loss_dice_4: 3.533  loss_ce_5: 2.592  loss_mask_5: 0.6343  loss_dice_5: 3.527  loss_ce_6: 2.583  loss_mask_6: 0.6347  loss_dice_6: 3.521  loss_ce_7: 2.6  loss_mask_7: 0.6306  loss_dice_7: 3.519  loss_ce_8: 2.592  loss_mask_8: 0.631  loss_dice_8: 3.518  time: 1.7050  data_time: 0.3447  lr: 8.4426e-06  max_mem: 17674M
[01/19 04:14:08] d2.utils.events INFO:  eta: 15:39:32  iter: 6879  total_loss: 69.6  loss_ce: 2.687  loss_mask: 0.6355  loss_dice: 3.444  loss_ce_0: 3.93  loss_mask_0: 0.6556  loss_dice_0: 3.741  loss_ce_1: 2.802  loss_mask_1: 0.6502  loss_dice_1: 3.604  loss_ce_2: 2.705  loss_mask_2: 0.6442  loss_dice_2: 3.525  loss_ce_3: 2.67  loss_mask_3: 0.6389  loss_dice_3: 3.48  loss_ce_4: 2.653  loss_mask_4: 0.6389  loss_dice_4: 3.466  loss_ce_5: 2.646  loss_mask_5: 0.639  loss_dice_5: 3.458  loss_ce_6: 2.674  loss_mask_6: 0.6389  loss_dice_6: 3.451  loss_ce_7: 2.657  loss_mask_7: 0.6374  loss_dice_7: 3.454  loss_ce_8: 2.655  loss_mask_8: 0.6404  loss_dice_8: 3.455  time: 1.7050  data_time: 0.3563  lr: 8.438e-06  max_mem: 17674M
[01/19 04:14:41] d2.utils.events INFO:  eta: 15:38:35  iter: 6899  total_loss: 69.33  loss_ce: 2.578  loss_mask: 0.6352  loss_dice: 3.468  loss_ce_0: 3.829  loss_mask_0: 0.6589  loss_dice_0: 3.762  loss_ce_1: 2.808  loss_mask_1: 0.6537  loss_dice_1: 3.612  loss_ce_2: 2.672  loss_mask_2: 0.6432  loss_dice_2: 3.534  loss_ce_3: 2.666  loss_mask_3: 0.6412  loss_dice_3: 3.485  loss_ce_4: 2.622  loss_mask_4: 0.6398  loss_dice_4: 3.484  loss_ce_5: 2.604  loss_mask_5: 0.6439  loss_dice_5: 3.487  loss_ce_6: 2.606  loss_mask_6: 0.6369  loss_dice_6: 3.464  loss_ce_7: 2.583  loss_mask_7: 0.6378  loss_dice_7: 3.474  loss_ce_8: 2.599  loss_mask_8: 0.6357  loss_dice_8: 3.472  time: 1.7048  data_time: 0.3348  lr: 8.4334e-06  max_mem: 17674M
[01/19 04:15:15] d2.utils.events INFO:  eta: 15:37:57  iter: 6919  total_loss: 69.07  loss_ce: 2.56  loss_mask: 0.6217  loss_dice: 3.567  loss_ce_0: 3.861  loss_mask_0: 0.6324  loss_dice_0: 3.829  loss_ce_1: 2.679  loss_mask_1: 0.6421  loss_dice_1: 3.69  loss_ce_2: 2.608  loss_mask_2: 0.6312  loss_dice_2: 3.626  loss_ce_3: 2.577  loss_mask_3: 0.6259  loss_dice_3: 3.586  loss_ce_4: 2.579  loss_mask_4: 0.6238  loss_dice_4: 3.587  loss_ce_5: 2.551  loss_mask_5: 0.626  loss_dice_5: 3.586  loss_ce_6: 2.568  loss_mask_6: 0.6226  loss_dice_6: 3.571  loss_ce_7: 2.572  loss_mask_7: 0.6264  loss_dice_7: 3.565  loss_ce_8: 2.562  loss_mask_8: 0.6257  loss_dice_8: 3.567  time: 1.7049  data_time: 0.3567  lr: 8.4288e-06  max_mem: 17674M
[01/19 04:15:49] d2.utils.events INFO:  eta: 15:37:31  iter: 6939  total_loss: 69.6  loss_ce: 2.677  loss_mask: 0.6426  loss_dice: 3.48  loss_ce_0: 3.878  loss_mask_0: 0.6668  loss_dice_0: 3.767  loss_ce_1: 2.814  loss_mask_1: 0.6564  loss_dice_1: 3.63  loss_ce_2: 2.707  loss_mask_2: 0.6517  loss_dice_2: 3.551  loss_ce_3: 2.696  loss_mask_3: 0.6464  loss_dice_3: 3.503  loss_ce_4: 2.672  loss_mask_4: 0.6483  loss_dice_4: 3.503  loss_ce_5: 2.667  loss_mask_5: 0.6466  loss_dice_5: 3.5  loss_ce_6: 2.666  loss_mask_6: 0.6439  loss_dice_6: 3.487  loss_ce_7: 2.655  loss_mask_7: 0.6451  loss_dice_7: 3.489  loss_ce_8: 2.671  loss_mask_8: 0.645  loss_dice_8: 3.487  time: 1.7048  data_time: 0.3470  lr: 8.4242e-06  max_mem: 17674M
[01/19 04:16:23] d2.utils.events INFO:  eta: 15:37:07  iter: 6959  total_loss: 69.24  loss_ce: 2.538  loss_mask: 0.6351  loss_dice: 3.52  loss_ce_0: 3.905  loss_mask_0: 0.6597  loss_dice_0: 3.783  loss_ce_1: 2.736  loss_mask_1: 0.6597  loss_dice_1: 3.657  loss_ce_2: 2.571  loss_mask_2: 0.6447  loss_dice_2: 3.59  loss_ce_3: 2.526  loss_mask_3: 0.6396  loss_dice_3: 3.555  loss_ce_4: 2.527  loss_mask_4: 0.6408  loss_dice_4: 3.543  loss_ce_5: 2.531  loss_mask_5: 0.6386  loss_dice_5: 3.538  loss_ce_6: 2.527  loss_mask_6: 0.6372  loss_dice_6: 3.523  loss_ce_7: 2.51  loss_mask_7: 0.6363  loss_dice_7: 3.524  loss_ce_8: 2.519  loss_mask_8: 0.6375  loss_dice_8: 3.528  time: 1.7047  data_time: 0.3576  lr: 8.4196e-06  max_mem: 17674M
[01/19 04:16:57] d2.utils.events INFO:  eta: 15:36:42  iter: 6979  total_loss: 69.74  loss_ce: 2.58  loss_mask: 0.6256  loss_dice: 3.572  loss_ce_0: 3.906  loss_mask_0: 0.6466  loss_dice_0: 3.822  loss_ce_1: 2.757  loss_mask_1: 0.6399  loss_dice_1: 3.707  loss_ce_2: 2.613  loss_mask_2: 0.6349  loss_dice_2: 3.64  loss_ce_3: 2.623  loss_mask_3: 0.6269  loss_dice_3: 3.607  loss_ce_4: 2.582  loss_mask_4: 0.6265  loss_dice_4: 3.597  loss_ce_5: 2.55  loss_mask_5: 0.627  loss_dice_5: 3.595  loss_ce_6: 2.572  loss_mask_6: 0.6256  loss_dice_6: 3.581  loss_ce_7: 2.55  loss_mask_7: 0.6236  loss_dice_7: 3.573  loss_ce_8: 2.558  loss_mask_8: 0.625  loss_dice_8: 3.572  time: 1.7047  data_time: 0.3524  lr: 8.4151e-06  max_mem: 17674M
[01/19 04:17:31] d2.utils.events INFO:  eta: 15:36:01  iter: 6999  total_loss: 69.55  loss_ce: 2.614  loss_mask: 0.6296  loss_dice: 3.551  loss_ce_0: 3.86  loss_mask_0: 0.6363  loss_dice_0: 3.825  loss_ce_1: 2.653  loss_mask_1: 0.6409  loss_dice_1: 3.692  loss_ce_2: 2.591  loss_mask_2: 0.6337  loss_dice_2: 3.628  loss_ce_3: 2.612  loss_mask_3: 0.6293  loss_dice_3: 3.575  loss_ce_4: 2.599  loss_mask_4: 0.6313  loss_dice_4: 3.578  loss_ce_5: 2.605  loss_mask_5: 0.6308  loss_dice_5: 3.566  loss_ce_6: 2.6  loss_mask_6: 0.6291  loss_dice_6: 3.552  loss_ce_7: 2.572  loss_mask_7: 0.6321  loss_dice_7: 3.558  loss_ce_8: 2.596  loss_mask_8: 0.6309  loss_dice_8: 3.554  time: 1.7047  data_time: 0.3681  lr: 8.4105e-06  max_mem: 17674M
[01/19 04:18:05] d2.utils.events INFO:  eta: 15:35:51  iter: 7019  total_loss: 69.49  loss_ce: 2.642  loss_mask: 0.6204  loss_dice: 3.534  loss_ce_0: 3.866  loss_mask_0: 0.6526  loss_dice_0: 3.807  loss_ce_1: 2.775  loss_mask_1: 0.64  loss_dice_1: 3.674  loss_ce_2: 2.663  loss_mask_2: 0.6268  loss_dice_2: 3.602  loss_ce_3: 2.643  loss_mask_3: 0.626  loss_dice_3: 3.557  loss_ce_4: 2.637  loss_mask_4: 0.6248  loss_dice_4: 3.55  loss_ce_5: 2.603  loss_mask_5: 0.6254  loss_dice_5: 3.545  loss_ce_6: 2.628  loss_mask_6: 0.6249  loss_dice_6: 3.535  loss_ce_7: 2.636  loss_mask_7: 0.6232  loss_dice_7: 3.534  loss_ce_8: 2.624  loss_mask_8: 0.6216  loss_dice_8: 3.531  time: 1.7047  data_time: 0.3532  lr: 8.4059e-06  max_mem: 17674M
[01/19 04:18:39] d2.utils.events INFO:  eta: 15:36:27  iter: 7039  total_loss: 68.98  loss_ce: 2.594  loss_mask: 0.6319  loss_dice: 3.546  loss_ce_0: 3.846  loss_mask_0: 0.6453  loss_dice_0: 3.807  loss_ce_1: 2.729  loss_mask_1: 0.6464  loss_dice_1: 3.681  loss_ce_2: 2.617  loss_mask_2: 0.6408  loss_dice_2: 3.617  loss_ce_3: 2.587  loss_mask_3: 0.6365  loss_dice_3: 3.574  loss_ce_4: 2.577  loss_mask_4: 0.6341  loss_dice_4: 3.573  loss_ce_5: 2.566  loss_mask_5: 0.6355  loss_dice_5: 3.568  loss_ce_6: 2.578  loss_mask_6: 0.6346  loss_dice_6: 3.56  loss_ce_7: 2.575  loss_mask_7: 0.6329  loss_dice_7: 3.558  loss_ce_8: 2.582  loss_mask_8: 0.6303  loss_dice_8: 3.552  time: 1.7046  data_time: 0.3299  lr: 8.4013e-06  max_mem: 17674M
[01/19 04:19:13] d2.utils.events INFO:  eta: 15:35:41  iter: 7059  total_loss: 69.67  loss_ce: 2.625  loss_mask: 0.6215  loss_dice: 3.508  loss_ce_0: 3.81  loss_mask_0: 0.6422  loss_dice_0: 3.789  loss_ce_1: 2.762  loss_mask_1: 0.6354  loss_dice_1: 3.647  loss_ce_2: 2.665  loss_mask_2: 0.6298  loss_dice_2: 3.576  loss_ce_3: 2.644  loss_mask_3: 0.6247  loss_dice_3: 3.528  loss_ce_4: 2.619  loss_mask_4: 0.6248  loss_dice_4: 3.535  loss_ce_5: 2.594  loss_mask_5: 0.6244  loss_dice_5: 3.521  loss_ce_6: 2.634  loss_mask_6: 0.6224  loss_dice_6: 3.513  loss_ce_7: 2.612  loss_mask_7: 0.6236  loss_dice_7: 3.516  loss_ce_8: 2.614  loss_mask_8: 0.6219  loss_dice_8: 3.513  time: 1.7046  data_time: 0.3569  lr: 8.3967e-06  max_mem: 17674M
[01/19 04:19:47] d2.utils.events INFO:  eta: 15:35:27  iter: 7079  total_loss: 69.68  loss_ce: 2.587  loss_mask: 0.63  loss_dice: 3.549  loss_ce_0: 3.855  loss_mask_0: 0.6487  loss_dice_0: 3.813  loss_ce_1: 2.776  loss_mask_1: 0.6444  loss_dice_1: 3.705  loss_ce_2: 2.626  loss_mask_2: 0.637  loss_dice_2: 3.625  loss_ce_3: 2.617  loss_mask_3: 0.631  loss_dice_3: 3.583  loss_ce_4: 2.575  loss_mask_4: 0.6317  loss_dice_4: 3.576  loss_ce_5: 2.583  loss_mask_5: 0.6304  loss_dice_5: 3.57  loss_ce_6: 2.586  loss_mask_6: 0.6309  loss_dice_6: 3.559  loss_ce_7: 2.594  loss_mask_7: 0.6304  loss_dice_7: 3.564  loss_ce_8: 2.593  loss_mask_8: 0.6284  loss_dice_8: 3.562  time: 1.7046  data_time: 0.3446  lr: 8.3921e-06  max_mem: 17674M
[01/19 04:20:21] d2.utils.events INFO:  eta: 15:35:02  iter: 7099  total_loss: 68.92  loss_ce: 2.521  loss_mask: 0.6204  loss_dice: 3.526  loss_ce_0: 3.857  loss_mask_0: 0.6363  loss_dice_0: 3.795  loss_ce_1: 2.69  loss_mask_1: 0.6413  loss_dice_1: 3.666  loss_ce_2: 2.579  loss_mask_2: 0.6324  loss_dice_2: 3.598  loss_ce_3: 2.519  loss_mask_3: 0.6241  loss_dice_3: 3.561  loss_ce_4: 2.51  loss_mask_4: 0.6261  loss_dice_4: 3.554  loss_ce_5: 2.515  loss_mask_5: 0.6245  loss_dice_5: 3.556  loss_ce_6: 2.526  loss_mask_6: 0.6211  loss_dice_6: 3.54  loss_ce_7: 2.513  loss_mask_7: 0.6186  loss_dice_7: 3.535  loss_ce_8: 2.503  loss_mask_8: 0.6226  loss_dice_8: 3.537  time: 1.7046  data_time: 0.3405  lr: 8.3875e-06  max_mem: 17674M
[01/19 04:20:54] d2.utils.events INFO:  eta: 15:33:13  iter: 7119  total_loss: 69.8  loss_ce: 2.553  loss_mask: 0.6369  loss_dice: 3.535  loss_ce_0: 3.81  loss_mask_0: 0.6588  loss_dice_0: 3.799  loss_ce_1: 2.745  loss_mask_1: 0.6495  loss_dice_1: 3.681  loss_ce_2: 2.604  loss_mask_2: 0.6466  loss_dice_2: 3.603  loss_ce_3: 2.588  loss_mask_3: 0.6407  loss_dice_3: 3.561  loss_ce_4: 2.539  loss_mask_4: 0.6408  loss_dice_4: 3.556  loss_ce_5: 2.554  loss_mask_5: 0.6391  loss_dice_5: 3.547  loss_ce_6: 2.545  loss_mask_6: 0.6369  loss_dice_6: 3.543  loss_ce_7: 2.558  loss_mask_7: 0.6375  loss_dice_7: 3.539  loss_ce_8: 2.544  loss_mask_8: 0.638  loss_dice_8: 3.54  time: 1.7044  data_time: 0.3184  lr: 8.3829e-06  max_mem: 17674M
[01/19 04:21:28] d2.utils.events INFO:  eta: 15:33:21  iter: 7139  total_loss: 70.12  loss_ce: 2.664  loss_mask: 0.6222  loss_dice: 3.566  loss_ce_0: 3.834  loss_mask_0: 0.6389  loss_dice_0: 3.81  loss_ce_1: 2.78  loss_mask_1: 0.6409  loss_dice_1: 3.701  loss_ce_2: 2.685  loss_mask_2: 0.6306  loss_dice_2: 3.622  loss_ce_3: 2.677  loss_mask_3: 0.6277  loss_dice_3: 3.582  loss_ce_4: 2.652  loss_mask_4: 0.6282  loss_dice_4: 3.584  loss_ce_5: 2.65  loss_mask_5: 0.6287  loss_dice_5: 3.58  loss_ce_6: 2.657  loss_mask_6: 0.6259  loss_dice_6: 3.564  loss_ce_7: 2.647  loss_mask_7: 0.6238  loss_dice_7: 3.571  loss_ce_8: 2.645  loss_mask_8: 0.6223  loss_dice_8: 3.574  time: 1.7044  data_time: 0.3433  lr: 8.3784e-06  max_mem: 17674M
[01/19 04:22:02] d2.utils.events INFO:  eta: 15:33:19  iter: 7159  total_loss: 69.4  loss_ce: 2.56  loss_mask: 0.6301  loss_dice: 3.538  loss_ce_0: 3.846  loss_mask_0: 0.6493  loss_dice_0: 3.801  loss_ce_1: 2.73  loss_mask_1: 0.6468  loss_dice_1: 3.681  loss_ce_2: 2.609  loss_mask_2: 0.638  loss_dice_2: 3.611  loss_ce_3: 2.562  loss_mask_3: 0.6326  loss_dice_3: 3.563  loss_ce_4: 2.55  loss_mask_4: 0.633  loss_dice_4: 3.553  loss_ce_5: 2.556  loss_mask_5: 0.634  loss_dice_5: 3.552  loss_ce_6: 2.556  loss_mask_6: 0.6294  loss_dice_6: 3.545  loss_ce_7: 2.552  loss_mask_7: 0.6321  loss_dice_7: 3.547  loss_ce_8: 2.552  loss_mask_8: 0.6313  loss_dice_8: 3.543  time: 1.7044  data_time: 0.3565  lr: 8.3738e-06  max_mem: 17674M
[01/19 04:22:35] d2.utils.events INFO:  eta: 15:32:53  iter: 7179  total_loss: 69.65  loss_ce: 2.69  loss_mask: 0.6384  loss_dice: 3.443  loss_ce_0: 3.911  loss_mask_0: 0.6622  loss_dice_0: 3.733  loss_ce_1: 2.86  loss_mask_1: 0.6552  loss_dice_1: 3.581  loss_ce_2: 2.718  loss_mask_2: 0.6442  loss_dice_2: 3.513  loss_ce_3: 2.697  loss_mask_3: 0.6444  loss_dice_3: 3.466  loss_ce_4: 2.698  loss_mask_4: 0.6405  loss_dice_4: 3.465  loss_ce_5: 2.69  loss_mask_5: 0.6419  loss_dice_5: 3.468  loss_ce_6: 2.679  loss_mask_6: 0.6398  loss_dice_6: 3.459  loss_ce_7: 2.676  loss_mask_7: 0.6393  loss_dice_7: 3.441  loss_ce_8: 2.668  loss_mask_8: 0.6391  loss_dice_8: 3.449  time: 1.7043  data_time: 0.3251  lr: 8.3692e-06  max_mem: 17674M
[01/19 04:23:09] d2.utils.events INFO:  eta: 15:32:34  iter: 7199  total_loss: 69.11  loss_ce: 2.511  loss_mask: 0.6257  loss_dice: 3.558  loss_ce_0: 3.766  loss_mask_0: 0.6466  loss_dice_0: 3.804  loss_ce_1: 2.628  loss_mask_1: 0.6418  loss_dice_1: 3.693  loss_ce_2: 2.546  loss_mask_2: 0.6373  loss_dice_2: 3.619  loss_ce_3: 2.553  loss_mask_3: 0.635  loss_dice_3: 3.578  loss_ce_4: 2.53  loss_mask_4: 0.6322  loss_dice_4: 3.576  loss_ce_5: 2.517  loss_mask_5: 0.6362  loss_dice_5: 3.57  loss_ce_6: 2.532  loss_mask_6: 0.6321  loss_dice_6: 3.564  loss_ce_7: 2.517  loss_mask_7: 0.6314  loss_dice_7: 3.562  loss_ce_8: 2.516  loss_mask_8: 0.6275  loss_dice_8: 3.566  time: 1.7043  data_time: 0.3240  lr: 8.3646e-06  max_mem: 17674M
[01/19 04:23:43] d2.utils.events INFO:  eta: 15:31:59  iter: 7219  total_loss: 69.27  loss_ce: 2.543  loss_mask: 0.6174  loss_dice: 3.549  loss_ce_0: 3.808  loss_mask_0: 0.636  loss_dice_0: 3.817  loss_ce_1: 2.706  loss_mask_1: 0.6333  loss_dice_1: 3.684  loss_ce_2: 2.588  loss_mask_2: 0.6259  loss_dice_2: 3.613  loss_ce_3: 2.575  loss_mask_3: 0.62  loss_dice_3: 3.569  loss_ce_4: 2.545  loss_mask_4: 0.6239  loss_dice_4: 3.568  loss_ce_5: 2.543  loss_mask_5: 0.6237  loss_dice_5: 3.571  loss_ce_6: 2.556  loss_mask_6: 0.6244  loss_dice_6: 3.557  loss_ce_7: 2.548  loss_mask_7: 0.6196  loss_dice_7: 3.555  loss_ce_8: 2.522  loss_mask_8: 0.6206  loss_dice_8: 3.556  time: 1.7042  data_time: 0.3460  lr: 8.36e-06  max_mem: 17674M
[01/19 04:24:17] d2.utils.events INFO:  eta: 15:31:17  iter: 7239  total_loss: 68.61  loss_ce: 2.496  loss_mask: 0.6379  loss_dice: 3.507  loss_ce_0: 3.809  loss_mask_0: 0.6553  loss_dice_0: 3.779  loss_ce_1: 2.674  loss_mask_1: 0.653  loss_dice_1: 3.643  loss_ce_2: 2.549  loss_mask_2: 0.6414  loss_dice_2: 3.576  loss_ce_3: 2.522  loss_mask_3: 0.642  loss_dice_3: 3.527  loss_ce_4: 2.489  loss_mask_4: 0.6405  loss_dice_4: 3.526  loss_ce_5: 2.49  loss_mask_5: 0.6406  loss_dice_5: 3.516  loss_ce_6: 2.511  loss_mask_6: 0.6367  loss_dice_6: 3.509  loss_ce_7: 2.479  loss_mask_7: 0.6354  loss_dice_7: 3.511  loss_ce_8: 2.483  loss_mask_8: 0.6348  loss_dice_8: 3.51  time: 1.7042  data_time: 0.3384  lr: 8.3554e-06  max_mem: 17674M
[01/19 04:24:51] d2.utils.events INFO:  eta: 15:30:51  iter: 7259  total_loss: 69.32  loss_ce: 2.557  loss_mask: 0.6453  loss_dice: 3.473  loss_ce_0: 3.896  loss_mask_0: 0.6676  loss_dice_0: 3.756  loss_ce_1: 2.717  loss_mask_1: 0.6599  loss_dice_1: 3.616  loss_ce_2: 2.597  loss_mask_2: 0.6528  loss_dice_2: 3.542  loss_ce_3: 2.567  loss_mask_3: 0.6483  loss_dice_3: 3.499  loss_ce_4: 2.543  loss_mask_4: 0.6469  loss_dice_4: 3.49  loss_ce_5: 2.534  loss_mask_5: 0.6479  loss_dice_5: 3.492  loss_ce_6: 2.565  loss_mask_6: 0.6485  loss_dice_6: 3.477  loss_ce_7: 2.554  loss_mask_7: 0.6482  loss_dice_7: 3.482  loss_ce_8: 2.551  loss_mask_8: 0.647  loss_dice_8: 3.475  time: 1.7041  data_time: 0.3448  lr: 8.3508e-06  max_mem: 17674M
[01/19 04:25:24] d2.utils.events INFO:  eta: 15:30:45  iter: 7279  total_loss: 69.27  loss_ce: 2.488  loss_mask: 0.6286  loss_dice: 3.528  loss_ce_0: 3.847  loss_mask_0: 0.6412  loss_dice_0: 3.79  loss_ce_1: 2.645  loss_mask_1: 0.643  loss_dice_1: 3.671  loss_ce_2: 2.547  loss_mask_2: 0.6316  loss_dice_2: 3.606  loss_ce_3: 2.527  loss_mask_3: 0.6299  loss_dice_3: 3.564  loss_ce_4: 2.488  loss_mask_4: 0.629  loss_dice_4: 3.564  loss_ce_5: 2.489  loss_mask_5: 0.6288  loss_dice_5: 3.56  loss_ce_6: 2.502  loss_mask_6: 0.6251  loss_dice_6: 3.545  loss_ce_7: 2.489  loss_mask_7: 0.6262  loss_dice_7: 3.54  loss_ce_8: 2.495  loss_mask_8: 0.6272  loss_dice_8: 3.543  time: 1.7041  data_time: 0.3249  lr: 8.3462e-06  max_mem: 17674M
[01/19 04:25:58] d2.utils.events INFO:  eta: 15:29:28  iter: 7299  total_loss: 69.66  loss_ce: 2.646  loss_mask: 0.6377  loss_dice: 3.504  loss_ce_0: 3.927  loss_mask_0: 0.6634  loss_dice_0: 3.764  loss_ce_1: 2.781  loss_mask_1: 0.6546  loss_dice_1: 3.654  loss_ce_2: 2.696  loss_mask_2: 0.646  loss_dice_2: 3.567  loss_ce_3: 2.668  loss_mask_3: 0.6449  loss_dice_3: 3.527  loss_ce_4: 2.677  loss_mask_4: 0.645  loss_dice_4: 3.518  loss_ce_5: 2.66  loss_mask_5: 0.6455  loss_dice_5: 3.515  loss_ce_6: 2.673  loss_mask_6: 0.6391  loss_dice_6: 3.511  loss_ce_7: 2.645  loss_mask_7: 0.6374  loss_dice_7: 3.51  loss_ce_8: 2.657  loss_mask_8: 0.6374  loss_dice_8: 3.509  time: 1.7040  data_time: 0.3182  lr: 8.3416e-06  max_mem: 17674M
[01/19 04:26:31] d2.utils.events INFO:  eta: 15:27:33  iter: 7319  total_loss: 69.67  loss_ce: 2.643  loss_mask: 0.6383  loss_dice: 3.462  loss_ce_0: 3.867  loss_mask_0: 0.6571  loss_dice_0: 3.764  loss_ce_1: 2.796  loss_mask_1: 0.6494  loss_dice_1: 3.627  loss_ce_2: 2.653  loss_mask_2: 0.6446  loss_dice_2: 3.548  loss_ce_3: 2.644  loss_mask_3: 0.6354  loss_dice_3: 3.493  loss_ce_4: 2.619  loss_mask_4: 0.6362  loss_dice_4: 3.489  loss_ce_5: 2.639  loss_mask_5: 0.6376  loss_dice_5: 3.483  loss_ce_6: 2.638  loss_mask_6: 0.6382  loss_dice_6: 3.471  loss_ce_7: 2.627  loss_mask_7: 0.6374  loss_dice_7: 3.465  loss_ce_8: 2.632  loss_mask_8: 0.6366  loss_dice_8: 3.465  time: 1.7039  data_time: 0.3430  lr: 8.337e-06  max_mem: 17674M
[01/19 04:27:05] d2.utils.events INFO:  eta: 15:26:33  iter: 7339  total_loss: 69.4  loss_ce: 2.587  loss_mask: 0.6277  loss_dice: 3.517  loss_ce_0: 3.873  loss_mask_0: 0.6464  loss_dice_0: 3.777  loss_ce_1: 2.718  loss_mask_1: 0.6405  loss_dice_1: 3.651  loss_ce_2: 2.624  loss_mask_2: 0.6336  loss_dice_2: 3.582  loss_ce_3: 2.603  loss_mask_3: 0.6321  loss_dice_3: 3.541  loss_ce_4: 2.582  loss_mask_4: 0.6323  loss_dice_4: 3.534  loss_ce_5: 2.584  loss_mask_5: 0.6298  loss_dice_5: 3.525  loss_ce_6: 2.586  loss_mask_6: 0.6296  loss_dice_6: 3.516  loss_ce_7: 2.589  loss_mask_7: 0.6296  loss_dice_7: 3.517  loss_ce_8: 2.572  loss_mask_8: 0.6293  loss_dice_8: 3.513  time: 1.7038  data_time: 0.3585  lr: 8.3324e-06  max_mem: 17674M
[01/19 04:27:39] d2.utils.events INFO:  eta: 15:25:13  iter: 7359  total_loss: 68.83  loss_ce: 2.489  loss_mask: 0.6357  loss_dice: 3.492  loss_ce_0: 3.827  loss_mask_0: 0.6472  loss_dice_0: 3.787  loss_ce_1: 2.703  loss_mask_1: 0.6478  loss_dice_1: 3.645  loss_ce_2: 2.563  loss_mask_2: 0.6419  loss_dice_2: 3.574  loss_ce_3: 2.533  loss_mask_3: 0.639  loss_dice_3: 3.514  loss_ce_4: 2.5  loss_mask_4: 0.6401  loss_dice_4: 3.515  loss_ce_5: 2.487  loss_mask_5: 0.6381  loss_dice_5: 3.51  loss_ce_6: 2.476  loss_mask_6: 0.6378  loss_dice_6: 3.503  loss_ce_7: 2.487  loss_mask_7: 0.6364  loss_dice_7: 3.498  loss_ce_8: 2.489  loss_mask_8: 0.6336  loss_dice_8: 3.496  time: 1.7038  data_time: 0.3460  lr: 8.3279e-06  max_mem: 17674M
[01/19 04:28:13] d2.utils.events INFO:  eta: 15:23:31  iter: 7379  total_loss: 69.05  loss_ce: 2.507  loss_mask: 0.6196  loss_dice: 3.549  loss_ce_0: 3.81  loss_mask_0: 0.6461  loss_dice_0: 3.845  loss_ce_1: 2.659  loss_mask_1: 0.6353  loss_dice_1: 3.701  loss_ce_2: 2.545  loss_mask_2: 0.6294  loss_dice_2: 3.612  loss_ce_3: 2.525  loss_mask_3: 0.6247  loss_dice_3: 3.565  loss_ce_4: 2.488  loss_mask_4: 0.6204  loss_dice_4: 3.569  loss_ce_5: 2.488  loss_mask_5: 0.6221  loss_dice_5: 3.56  loss_ce_6: 2.488  loss_mask_6: 0.62  loss_dice_6: 3.56  loss_ce_7: 2.487  loss_mask_7: 0.6199  loss_dice_7: 3.556  loss_ce_8: 2.477  loss_mask_8: 0.6201  loss_dice_8: 3.557  time: 1.7038  data_time: 0.3651  lr: 8.3233e-06  max_mem: 17674M
[01/19 04:28:47] d2.utils.events INFO:  eta: 15:22:29  iter: 7399  total_loss: 69.05  loss_ce: 2.575  loss_mask: 0.627  loss_dice: 3.482  loss_ce_0: 3.86  loss_mask_0: 0.6503  loss_dice_0: 3.781  loss_ce_1: 2.708  loss_mask_1: 0.6425  loss_dice_1: 3.649  loss_ce_2: 2.623  loss_mask_2: 0.6312  loss_dice_2: 3.561  loss_ce_3: 2.586  loss_mask_3: 0.6306  loss_dice_3: 3.511  loss_ce_4: 2.549  loss_mask_4: 0.6278  loss_dice_4: 3.508  loss_ce_5: 2.557  loss_mask_5: 0.6292  loss_dice_5: 3.508  loss_ce_6: 2.549  loss_mask_6: 0.6299  loss_dice_6: 3.493  loss_ce_7: 2.552  loss_mask_7: 0.6279  loss_dice_7: 3.494  loss_ce_8: 2.544  loss_mask_8: 0.627  loss_dice_8: 3.495  time: 1.7037  data_time: 0.3541  lr: 8.3187e-06  max_mem: 17674M
[01/19 04:29:20] d2.utils.events INFO:  eta: 15:20:35  iter: 7419  total_loss: 69.09  loss_ce: 2.62  loss_mask: 0.6298  loss_dice: 3.503  loss_ce_0: 3.793  loss_mask_0: 0.6543  loss_dice_0: 3.784  loss_ce_1: 2.776  loss_mask_1: 0.6474  loss_dice_1: 3.657  loss_ce_2: 2.668  loss_mask_2: 0.6374  loss_dice_2: 3.579  loss_ce_3: 2.652  loss_mask_3: 0.6346  loss_dice_3: 3.525  loss_ce_4: 2.625  loss_mask_4: 0.6337  loss_dice_4: 3.525  loss_ce_5: 2.615  loss_mask_5: 0.632  loss_dice_5: 3.52  loss_ce_6: 2.622  loss_mask_6: 0.6299  loss_dice_6: 3.506  loss_ce_7: 2.622  loss_mask_7: 0.6293  loss_dice_7: 3.508  loss_ce_8: 2.596  loss_mask_8: 0.6321  loss_dice_8: 3.51  time: 1.7037  data_time: 0.3406  lr: 8.3141e-06  max_mem: 17674M
[01/19 04:29:54] d2.utils.events INFO:  eta: 15:19:10  iter: 7439  total_loss: 69.2  loss_ce: 2.552  loss_mask: 0.6202  loss_dice: 3.552  loss_ce_0: 3.858  loss_mask_0: 0.6377  loss_dice_0: 3.823  loss_ce_1: 2.672  loss_mask_1: 0.631  loss_dice_1: 3.688  loss_ce_2: 2.578  loss_mask_2: 0.6326  loss_dice_2: 3.61  loss_ce_3: 2.583  loss_mask_3: 0.6215  loss_dice_3: 3.566  loss_ce_4: 2.556  loss_mask_4: 0.6223  loss_dice_4: 3.565  loss_ce_5: 2.539  loss_mask_5: 0.6232  loss_dice_5: 3.563  loss_ce_6: 2.551  loss_mask_6: 0.6218  loss_dice_6: 3.558  loss_ce_7: 2.548  loss_mask_7: 0.6233  loss_dice_7: 3.555  loss_ce_8: 2.546  loss_mask_8: 0.6252  loss_dice_8: 3.551  time: 1.7036  data_time: 0.3433  lr: 8.3095e-06  max_mem: 17674M
[01/19 04:30:28] d2.utils.events INFO:  eta: 15:18:23  iter: 7459  total_loss: 69.56  loss_ce: 2.604  loss_mask: 0.6208  loss_dice: 3.545  loss_ce_0: 3.887  loss_mask_0: 0.6286  loss_dice_0: 3.817  loss_ce_1: 2.702  loss_mask_1: 0.6313  loss_dice_1: 3.695  loss_ce_2: 2.604  loss_mask_2: 0.6269  loss_dice_2: 3.621  loss_ce_3: 2.611  loss_mask_3: 0.6248  loss_dice_3: 3.565  loss_ce_4: 2.592  loss_mask_4: 0.6247  loss_dice_4: 3.569  loss_ce_5: 2.565  loss_mask_5: 0.624  loss_dice_5: 3.559  loss_ce_6: 2.587  loss_mask_6: 0.622  loss_dice_6: 3.551  loss_ce_7: 2.59  loss_mask_7: 0.6225  loss_dice_7: 3.552  loss_ce_8: 2.575  loss_mask_8: 0.6188  loss_dice_8: 3.551  time: 1.7036  data_time: 0.3512  lr: 8.3049e-06  max_mem: 17674M
[01/19 04:31:02] d2.utils.events INFO:  eta: 15:17:05  iter: 7479  total_loss: 70.17  loss_ce: 2.66  loss_mask: 0.6315  loss_dice: 3.551  loss_ce_0: 3.862  loss_mask_0: 0.6559  loss_dice_0: 3.796  loss_ce_1: 2.805  loss_mask_1: 0.6525  loss_dice_1: 3.688  loss_ce_2: 2.696  loss_mask_2: 0.6443  loss_dice_2: 3.625  loss_ce_3: 2.669  loss_mask_3: 0.6374  loss_dice_3: 3.583  loss_ce_4: 2.646  loss_mask_4: 0.6364  loss_dice_4: 3.581  loss_ce_5: 2.646  loss_mask_5: 0.6354  loss_dice_5: 3.572  loss_ce_6: 2.638  loss_mask_6: 0.6344  loss_dice_6: 3.559  loss_ce_7: 2.653  loss_mask_7: 0.6325  loss_dice_7: 3.551  loss_ce_8: 2.663  loss_mask_8: 0.631  loss_dice_8: 3.555  time: 1.7035  data_time: 0.3566  lr: 8.3003e-06  max_mem: 17674M
[01/19 04:31:36] d2.utils.events INFO:  eta: 15:15:46  iter: 7499  total_loss: 68.66  loss_ce: 2.522  loss_mask: 0.6215  loss_dice: 3.493  loss_ce_0: 3.808  loss_mask_0: 0.6559  loss_dice_0: 3.768  loss_ce_1: 2.705  loss_mask_1: 0.6454  loss_dice_1: 3.65  loss_ce_2: 2.583  loss_mask_2: 0.6354  loss_dice_2: 3.579  loss_ce_3: 2.559  loss_mask_3: 0.6263  loss_dice_3: 3.529  loss_ce_4: 2.522  loss_mask_4: 0.6235  loss_dice_4: 3.517  loss_ce_5: 2.519  loss_mask_5: 0.6259  loss_dice_5: 3.512  loss_ce_6: 2.522  loss_mask_6: 0.625  loss_dice_6: 3.496  loss_ce_7: 2.505  loss_mask_7: 0.6254  loss_dice_7: 3.496  loss_ce_8: 2.505  loss_mask_8: 0.6254  loss_dice_8: 3.502  time: 1.7035  data_time: 0.3344  lr: 8.2957e-06  max_mem: 17674M
[01/19 04:32:10] d2.utils.events INFO:  eta: 15:14:29  iter: 7519  total_loss: 68.8  loss_ce: 2.512  loss_mask: 0.6236  loss_dice: 3.51  loss_ce_0: 3.883  loss_mask_0: 0.6343  loss_dice_0: 3.774  loss_ce_1: 2.693  loss_mask_1: 0.6427  loss_dice_1: 3.647  loss_ce_2: 2.559  loss_mask_2: 0.6299  loss_dice_2: 3.581  loss_ce_3: 2.551  loss_mask_3: 0.6253  loss_dice_3: 3.534  loss_ce_4: 2.515  loss_mask_4: 0.6252  loss_dice_4: 3.535  loss_ce_5: 2.482  loss_mask_5: 0.628  loss_dice_5: 3.527  loss_ce_6: 2.511  loss_mask_6: 0.6248  loss_dice_6: 3.518  loss_ce_7: 2.509  loss_mask_7: 0.6249  loss_dice_7: 3.51  loss_ce_8: 2.51  loss_mask_8: 0.6246  loss_dice_8: 3.513  time: 1.7035  data_time: 0.3412  lr: 8.2911e-06  max_mem: 17674M
[01/19 04:32:44] d2.utils.events INFO:  eta: 15:13:22  iter: 7539  total_loss: 68.74  loss_ce: 2.538  loss_mask: 0.6384  loss_dice: 3.464  loss_ce_0: 3.796  loss_mask_0: 0.6541  loss_dice_0: 3.731  loss_ce_1: 2.708  loss_mask_1: 0.6506  loss_dice_1: 3.611  loss_ce_2: 2.577  loss_mask_2: 0.6422  loss_dice_2: 3.544  loss_ce_3: 2.542  loss_mask_3: 0.6389  loss_dice_3: 3.495  loss_ce_4: 2.531  loss_mask_4: 0.6377  loss_dice_4: 3.485  loss_ce_5: 2.521  loss_mask_5: 0.6386  loss_dice_5: 3.486  loss_ce_6: 2.522  loss_mask_6: 0.6398  loss_dice_6: 3.475  loss_ce_7: 2.513  loss_mask_7: 0.6404  loss_dice_7: 3.466  loss_ce_8: 2.522  loss_mask_8: 0.639  loss_dice_8: 3.47  time: 1.7034  data_time: 0.3422  lr: 8.2865e-06  max_mem: 17674M
[01/19 04:33:18] d2.utils.events INFO:  eta: 15:12:52  iter: 7559  total_loss: 68.93  loss_ce: 2.574  loss_mask: 0.6315  loss_dice: 3.47  loss_ce_0: 3.828  loss_mask_0: 0.6527  loss_dice_0: 3.762  loss_ce_1: 2.735  loss_mask_1: 0.6463  loss_dice_1: 3.624  loss_ce_2: 2.632  loss_mask_2: 0.639  loss_dice_2: 3.534  loss_ce_3: 2.602  loss_mask_3: 0.6333  loss_dice_3: 3.493  loss_ce_4: 2.572  loss_mask_4: 0.6315  loss_dice_4: 3.499  loss_ce_5: 2.549  loss_mask_5: 0.631  loss_dice_5: 3.486  loss_ce_6: 2.561  loss_mask_6: 0.6308  loss_dice_6: 3.48  loss_ce_7: 2.555  loss_mask_7: 0.631  loss_dice_7: 3.471  loss_ce_8: 2.555  loss_mask_8: 0.63  loss_dice_8: 3.469  time: 1.7034  data_time: 0.3510  lr: 8.2819e-06  max_mem: 17674M
[01/19 04:33:51] d2.utils.events INFO:  eta: 15:11:22  iter: 7579  total_loss: 68.77  loss_ce: 2.511  loss_mask: 0.6252  loss_dice: 3.504  loss_ce_0: 3.86  loss_mask_0: 0.6547  loss_dice_0: 3.765  loss_ce_1: 2.697  loss_mask_1: 0.6451  loss_dice_1: 3.638  loss_ce_2: 2.55  loss_mask_2: 0.6345  loss_dice_2: 3.568  loss_ce_3: 2.535  loss_mask_3: 0.6322  loss_dice_3: 3.524  loss_ce_4: 2.495  loss_mask_4: 0.6287  loss_dice_4: 3.522  loss_ce_5: 2.507  loss_mask_5: 0.6288  loss_dice_5: 3.513  loss_ce_6: 2.508  loss_mask_6: 0.6294  loss_dice_6: 3.502  loss_ce_7: 2.494  loss_mask_7: 0.6266  loss_dice_7: 3.508  loss_ce_8: 2.506  loss_mask_8: 0.6277  loss_dice_8: 3.504  time: 1.7034  data_time: 0.3450  lr: 8.2773e-06  max_mem: 17674M
[01/19 04:34:25] d2.utils.events INFO:  eta: 15:10:15  iter: 7599  total_loss: 69.16  loss_ce: 2.615  loss_mask: 0.64  loss_dice: 3.458  loss_ce_0: 3.855  loss_mask_0: 0.6611  loss_dice_0: 3.732  loss_ce_1: 2.751  loss_mask_1: 0.6517  loss_dice_1: 3.607  loss_ce_2: 2.643  loss_mask_2: 0.6459  loss_dice_2: 3.526  loss_ce_3: 2.649  loss_mask_3: 0.6405  loss_dice_3: 3.47  loss_ce_4: 2.625  loss_mask_4: 0.6404  loss_dice_4: 3.472  loss_ce_5: 2.608  loss_mask_5: 0.6418  loss_dice_5: 3.472  loss_ce_6: 2.606  loss_mask_6: 0.6412  loss_dice_6: 3.455  loss_ce_7: 2.597  loss_mask_7: 0.6423  loss_dice_7: 3.456  loss_ce_8: 2.634  loss_mask_8: 0.6421  loss_dice_8: 3.459  time: 1.7033  data_time: 0.3355  lr: 8.2727e-06  max_mem: 17674M
[01/19 04:34:59] d2.utils.events INFO:  eta: 15:09:34  iter: 7619  total_loss: 68.87  loss_ce: 2.477  loss_mask: 0.6278  loss_dice: 3.538  loss_ce_0: 3.856  loss_mask_0: 0.6381  loss_dice_0: 3.78  loss_ce_1: 2.694  loss_mask_1: 0.642  loss_dice_1: 3.667  loss_ce_2: 2.555  loss_mask_2: 0.6358  loss_dice_2: 3.601  loss_ce_3: 2.516  loss_mask_3: 0.6288  loss_dice_3: 3.565  loss_ce_4: 2.488  loss_mask_4: 0.628  loss_dice_4: 3.561  loss_ce_5: 2.481  loss_mask_5: 0.6284  loss_dice_5: 3.558  loss_ce_6: 2.477  loss_mask_6: 0.6278  loss_dice_6: 3.55  loss_ce_7: 2.473  loss_mask_7: 0.6268  loss_dice_7: 3.547  loss_ce_8: 2.484  loss_mask_8: 0.6279  loss_dice_8: 3.546  time: 1.7032  data_time: 0.3482  lr: 8.2681e-06  max_mem: 17674M
[01/19 04:35:33] d2.utils.events INFO:  eta: 15:08:20  iter: 7639  total_loss: 69.34  loss_ce: 2.547  loss_mask: 0.6251  loss_dice: 3.54  loss_ce_0: 3.838  loss_mask_0: 0.6483  loss_dice_0: 3.798  loss_ce_1: 2.675  loss_mask_1: 0.6413  loss_dice_1: 3.68  loss_ce_2: 2.558  loss_mask_2: 0.634  loss_dice_2: 3.614  loss_ce_3: 2.537  loss_mask_3: 0.6272  loss_dice_3: 3.564  loss_ce_4: 2.522  loss_mask_4: 0.6249  loss_dice_4: 3.566  loss_ce_5: 2.526  loss_mask_5: 0.6278  loss_dice_5: 3.561  loss_ce_6: 2.553  loss_mask_6: 0.6269  loss_dice_6: 3.551  loss_ce_7: 2.542  loss_mask_7: 0.6265  loss_dice_7: 3.543  loss_ce_8: 2.532  loss_mask_8: 0.6246  loss_dice_8: 3.548  time: 1.7032  data_time: 0.3597  lr: 8.2635e-06  max_mem: 17674M
[01/19 04:36:07] d2.utils.events INFO:  eta: 15:07:37  iter: 7659  total_loss: 68.76  loss_ce: 2.518  loss_mask: 0.6187  loss_dice: 3.525  loss_ce_0: 3.78  loss_mask_0: 0.6406  loss_dice_0: 3.818  loss_ce_1: 2.635  loss_mask_1: 0.6339  loss_dice_1: 3.666  loss_ce_2: 2.541  loss_mask_2: 0.6322  loss_dice_2: 3.589  loss_ce_3: 2.537  loss_mask_3: 0.6292  loss_dice_3: 3.545  loss_ce_4: 2.507  loss_mask_4: 0.6243  loss_dice_4: 3.544  loss_ce_5: 2.511  loss_mask_5: 0.6235  loss_dice_5: 3.542  loss_ce_6: 2.524  loss_mask_6: 0.6216  loss_dice_6: 3.529  loss_ce_7: 2.51  loss_mask_7: 0.6187  loss_dice_7: 3.537  loss_ce_8: 2.524  loss_mask_8: 0.6185  loss_dice_8: 3.525  time: 1.7032  data_time: 0.3411  lr: 8.2589e-06  max_mem: 17674M
[01/19 04:36:41] d2.utils.events INFO:  eta: 15:07:03  iter: 7679  total_loss: 68.76  loss_ce: 2.517  loss_mask: 0.6276  loss_dice: 3.523  loss_ce_0: 3.797  loss_mask_0: 0.6368  loss_dice_0: 3.786  loss_ce_1: 2.675  loss_mask_1: 0.6353  loss_dice_1: 3.669  loss_ce_2: 2.568  loss_mask_2: 0.6367  loss_dice_2: 3.593  loss_ce_3: 2.552  loss_mask_3: 0.6332  loss_dice_3: 3.553  loss_ce_4: 2.519  loss_mask_4: 0.6322  loss_dice_4: 3.545  loss_ce_5: 2.518  loss_mask_5: 0.6319  loss_dice_5: 3.54  loss_ce_6: 2.51  loss_mask_6: 0.6287  loss_dice_6: 3.53  loss_ce_7: 2.503  loss_mask_7: 0.6288  loss_dice_7: 3.526  loss_ce_8: 2.521  loss_mask_8: 0.6293  loss_dice_8: 3.526  time: 1.7032  data_time: 0.3373  lr: 8.2543e-06  max_mem: 17674M
[01/19 04:37:14] d2.utils.events INFO:  eta: 15:06:21  iter: 7699  total_loss: 69.41  loss_ce: 2.515  loss_mask: 0.6442  loss_dice: 3.512  loss_ce_0: 3.821  loss_mask_0: 0.6556  loss_dice_0: 3.772  loss_ce_1: 2.664  loss_mask_1: 0.6559  loss_dice_1: 3.636  loss_ce_2: 2.574  loss_mask_2: 0.6492  loss_dice_2: 3.578  loss_ce_3: 2.575  loss_mask_3: 0.6433  loss_dice_3: 3.544  loss_ce_4: 2.543  loss_mask_4: 0.6441  loss_dice_4: 3.539  loss_ce_5: 2.527  loss_mask_5: 0.6451  loss_dice_5: 3.531  loss_ce_6: 2.534  loss_mask_6: 0.6442  loss_dice_6: 3.512  loss_ce_7: 2.526  loss_mask_7: 0.6438  loss_dice_7: 3.507  loss_ce_8: 2.514  loss_mask_8: 0.6433  loss_dice_8: 3.516  time: 1.7031  data_time: 0.3246  lr: 8.2497e-06  max_mem: 17674M
[01/19 04:37:48] d2.utils.events INFO:  eta: 15:06:01  iter: 7719  total_loss: 69.22  loss_ce: 2.533  loss_mask: 0.6332  loss_dice: 3.52  loss_ce_0: 3.895  loss_mask_0: 0.6477  loss_dice_0: 3.788  loss_ce_1: 2.71  loss_mask_1: 0.6504  loss_dice_1: 3.666  loss_ce_2: 2.581  loss_mask_2: 0.6395  loss_dice_2: 3.593  loss_ce_3: 2.578  loss_mask_3: 0.6368  loss_dice_3: 3.55  loss_ce_4: 2.549  loss_mask_4: 0.6352  loss_dice_4: 3.552  loss_ce_5: 2.528  loss_mask_5: 0.6323  loss_dice_5: 3.545  loss_ce_6: 2.525  loss_mask_6: 0.6335  loss_dice_6: 3.533  loss_ce_7: 2.515  loss_mask_7: 0.6331  loss_dice_7: 3.525  loss_ce_8: 2.508  loss_mask_8: 0.6345  loss_dice_8: 3.531  time: 1.7031  data_time: 0.3516  lr: 8.2451e-06  max_mem: 17674M
[01/19 04:38:22] d2.utils.events INFO:  eta: 15:05:46  iter: 7739  total_loss: 69.53  loss_ce: 2.584  loss_mask: 0.6294  loss_dice: 3.567  loss_ce_0: 3.845  loss_mask_0: 0.6464  loss_dice_0: 3.796  loss_ce_1: 2.68  loss_mask_1: 0.6492  loss_dice_1: 3.701  loss_ce_2: 2.6  loss_mask_2: 0.6412  loss_dice_2: 3.638  loss_ce_3: 2.592  loss_mask_3: 0.6377  loss_dice_3: 3.598  loss_ce_4: 2.59  loss_mask_4: 0.6367  loss_dice_4: 3.591  loss_ce_5: 2.572  loss_mask_5: 0.6399  loss_dice_5: 3.582  loss_ce_6: 2.593  loss_mask_6: 0.6336  loss_dice_6: 3.576  loss_ce_7: 2.581  loss_mask_7: 0.6312  loss_dice_7: 3.57  loss_ce_8: 2.581  loss_mask_8: 0.6322  loss_dice_8: 3.576  time: 1.7031  data_time: 0.3394  lr: 8.2405e-06  max_mem: 17674M
[01/19 04:38:56] d2.utils.events INFO:  eta: 15:04:55  iter: 7759  total_loss: 68.7  loss_ce: 2.567  loss_mask: 0.6555  loss_dice: 3.451  loss_ce_0: 3.828  loss_mask_0: 0.6727  loss_dice_0: 3.726  loss_ce_1: 2.714  loss_mask_1: 0.671  loss_dice_1: 3.587  loss_ce_2: 2.593  loss_mask_2: 0.6675  loss_dice_2: 3.513  loss_ce_3: 2.577  loss_mask_3: 0.6572  loss_dice_3: 3.466  loss_ce_4: 2.541  loss_mask_4: 0.6565  loss_dice_4: 3.464  loss_ce_5: 2.551  loss_mask_5: 0.6545  loss_dice_5: 3.465  loss_ce_6: 2.535  loss_mask_6: 0.6536  loss_dice_6: 3.451  loss_ce_7: 2.526  loss_mask_7: 0.6575  loss_dice_7: 3.453  loss_ce_8: 2.549  loss_mask_8: 0.6553  loss_dice_8: 3.454  time: 1.7030  data_time: 0.3271  lr: 8.2359e-06  max_mem: 17674M
[01/19 04:39:29] d2.utils.events INFO:  eta: 15:04:30  iter: 7779  total_loss: 69.28  loss_ce: 2.563  loss_mask: 0.6377  loss_dice: 3.513  loss_ce_0: 3.895  loss_mask_0: 0.6528  loss_dice_0: 3.773  loss_ce_1: 2.707  loss_mask_1: 0.6491  loss_dice_1: 3.652  loss_ce_2: 2.62  loss_mask_2: 0.6405  loss_dice_2: 3.58  loss_ce_3: 2.61  loss_mask_3: 0.6382  loss_dice_3: 3.536  loss_ce_4: 2.591  loss_mask_4: 0.6373  loss_dice_4: 3.528  loss_ce_5: 2.585  loss_mask_5: 0.6357  loss_dice_5: 3.529  loss_ce_6: 2.564  loss_mask_6: 0.6348  loss_dice_6: 3.518  loss_ce_7: 2.562  loss_mask_7: 0.6385  loss_dice_7: 3.515  loss_ce_8: 2.554  loss_mask_8: 0.6412  loss_dice_8: 3.519  time: 1.7029  data_time: 0.3345  lr: 8.2314e-06  max_mem: 17674M
[01/19 04:40:03] d2.utils.events INFO:  eta: 15:03:47  iter: 7799  total_loss: 68.61  loss_ce: 2.507  loss_mask: 0.627  loss_dice: 3.488  loss_ce_0: 3.891  loss_mask_0: 0.647  loss_dice_0: 3.746  loss_ce_1: 2.725  loss_mask_1: 0.6402  loss_dice_1: 3.622  loss_ce_2: 2.582  loss_mask_2: 0.6334  loss_dice_2: 3.559  loss_ce_3: 2.544  loss_mask_3: 0.6261  loss_dice_3: 3.511  loss_ce_4: 2.512  loss_mask_4: 0.6276  loss_dice_4: 3.505  loss_ce_5: 2.517  loss_mask_5: 0.6273  loss_dice_5: 3.5  loss_ce_6: 2.503  loss_mask_6: 0.6274  loss_dice_6: 3.496  loss_ce_7: 2.51  loss_mask_7: 0.6279  loss_dice_7: 3.496  loss_ce_8: 2.504  loss_mask_8: 0.6293  loss_dice_8: 3.495  time: 1.7028  data_time: 0.3372  lr: 8.2268e-06  max_mem: 17674M
[01/19 04:40:37] d2.utils.events INFO:  eta: 15:03:07  iter: 7819  total_loss: 68.92  loss_ce: 2.503  loss_mask: 0.6429  loss_dice: 3.54  loss_ce_0: 3.767  loss_mask_0: 0.6623  loss_dice_0: 3.775  loss_ce_1: 2.67  loss_mask_1: 0.6572  loss_dice_1: 3.668  loss_ce_2: 2.565  loss_mask_2: 0.6505  loss_dice_2: 3.598  loss_ce_3: 2.529  loss_mask_3: 0.649  loss_dice_3: 3.555  loss_ce_4: 2.496  loss_mask_4: 0.6474  loss_dice_4: 3.553  loss_ce_5: 2.505  loss_mask_5: 0.65  loss_dice_5: 3.542  loss_ce_6: 2.492  loss_mask_6: 0.6498  loss_dice_6: 3.539  loss_ce_7: 2.485  loss_mask_7: 0.6483  loss_dice_7: 3.542  loss_ce_8: 2.497  loss_mask_8: 0.6493  loss_dice_8: 3.541  time: 1.7028  data_time: 0.3324  lr: 8.2222e-06  max_mem: 17674M
[01/19 04:41:10] d2.utils.events INFO:  eta: 15:02:29  iter: 7839  total_loss: 68.2  loss_ce: 2.515  loss_mask: 0.6468  loss_dice: 3.453  loss_ce_0: 3.847  loss_mask_0: 0.6606  loss_dice_0: 3.755  loss_ce_1: 2.67  loss_mask_1: 0.6614  loss_dice_1: 3.606  loss_ce_2: 2.566  loss_mask_2: 0.6545  loss_dice_2: 3.523  loss_ce_3: 2.517  loss_mask_3: 0.6488  loss_dice_3: 3.476  loss_ce_4: 2.52  loss_mask_4: 0.6461  loss_dice_4: 3.481  loss_ce_5: 2.517  loss_mask_5: 0.6481  loss_dice_5: 3.475  loss_ce_6: 2.504  loss_mask_6: 0.6472  loss_dice_6: 3.458  loss_ce_7: 2.505  loss_mask_7: 0.6495  loss_dice_7: 3.461  loss_ce_8: 2.52  loss_mask_8: 0.6474  loss_dice_8: 3.458  time: 1.7027  data_time: 0.3422  lr: 8.2176e-06  max_mem: 17674M
[01/19 04:41:44] d2.utils.events INFO:  eta: 15:01:56  iter: 7859  total_loss: 68.26  loss_ce: 2.454  loss_mask: 0.6275  loss_dice: 3.514  loss_ce_0: 3.819  loss_mask_0: 0.6461  loss_dice_0: 3.778  loss_ce_1: 2.623  loss_mask_1: 0.6453  loss_dice_1: 3.661  loss_ce_2: 2.496  loss_mask_2: 0.635  loss_dice_2: 3.589  loss_ce_3: 2.48  loss_mask_3: 0.6334  loss_dice_3: 3.542  loss_ce_4: 2.461  loss_mask_4: 0.6328  loss_dice_4: 3.536  loss_ce_5: 2.451  loss_mask_5: 0.6298  loss_dice_5: 3.53  loss_ce_6: 2.47  loss_mask_6: 0.6288  loss_dice_6: 3.518  loss_ce_7: 2.459  loss_mask_7: 0.6275  loss_dice_7: 3.519  loss_ce_8: 2.45  loss_mask_8: 0.6258  loss_dice_8: 3.521  time: 1.7027  data_time: 0.3444  lr: 8.213e-06  max_mem: 17674M
[01/19 04:42:19] d2.utils.events INFO:  eta: 15:01:29  iter: 7879  total_loss: 68.3  loss_ce: 2.443  loss_mask: 0.6331  loss_dice: 3.497  loss_ce_0: 3.822  loss_mask_0: 0.6423  loss_dice_0: 3.765  loss_ce_1: 2.615  loss_mask_1: 0.6435  loss_dice_1: 3.636  loss_ce_2: 2.515  loss_mask_2: 0.6348  loss_dice_2: 3.569  loss_ce_3: 2.496  loss_mask_3: 0.6334  loss_dice_3: 3.52  loss_ce_4: 2.449  loss_mask_4: 0.6316  loss_dice_4: 3.515  loss_ce_5: 2.448  loss_mask_5: 0.6317  loss_dice_5: 3.513  loss_ce_6: 2.453  loss_mask_6: 0.6329  loss_dice_6: 3.501  loss_ce_7: 2.452  loss_mask_7: 0.6356  loss_dice_7: 3.499  loss_ce_8: 2.446  loss_mask_8: 0.6355  loss_dice_8: 3.499  time: 1.7027  data_time: 0.3473  lr: 8.2084e-06  max_mem: 17674M
[01/19 04:42:53] d2.utils.events INFO:  eta: 15:00:59  iter: 7899  total_loss: 68.4  loss_ce: 2.488  loss_mask: 0.6256  loss_dice: 3.529  loss_ce_0: 3.815  loss_mask_0: 0.6384  loss_dice_0: 3.796  loss_ce_1: 2.648  loss_mask_1: 0.6394  loss_dice_1: 3.662  loss_ce_2: 2.519  loss_mask_2: 0.6316  loss_dice_2: 3.604  loss_ce_3: 2.487  loss_mask_3: 0.6247  loss_dice_3: 3.556  loss_ce_4: 2.496  loss_mask_4: 0.6262  loss_dice_4: 3.55  loss_ce_5: 2.468  loss_mask_5: 0.6247  loss_dice_5: 3.539  loss_ce_6: 2.468  loss_mask_6: 0.6272  loss_dice_6: 3.533  loss_ce_7: 2.477  loss_mask_7: 0.6251  loss_dice_7: 3.536  loss_ce_8: 2.465  loss_mask_8: 0.6267  loss_dice_8: 3.532  time: 1.7028  data_time: 0.3497  lr: 8.2038e-06  max_mem: 17674M
[01/19 04:43:27] d2.utils.events INFO:  eta: 15:00:25  iter: 7919  total_loss: 68.22  loss_ce: 2.457  loss_mask: 0.6184  loss_dice: 3.516  loss_ce_0: 3.736  loss_mask_0: 0.642  loss_dice_0: 3.78  loss_ce_1: 2.628  loss_mask_1: 0.6407  loss_dice_1: 3.654  loss_ce_2: 2.505  loss_mask_2: 0.6286  loss_dice_2: 3.579  loss_ce_3: 2.495  loss_mask_3: 0.6226  loss_dice_3: 3.541  loss_ce_4: 2.467  loss_mask_4: 0.6213  loss_dice_4: 3.536  loss_ce_5: 2.453  loss_mask_5: 0.6199  loss_dice_5: 3.53  loss_ce_6: 2.446  loss_mask_6: 0.6212  loss_dice_6: 3.517  loss_ce_7: 2.443  loss_mask_7: 0.6219  loss_dice_7: 3.521  loss_ce_8: 2.446  loss_mask_8: 0.6209  loss_dice_8: 3.515  time: 1.7028  data_time: 0.3594  lr: 8.1992e-06  max_mem: 17674M
[01/19 04:44:01] d2.utils.events INFO:  eta: 14:59:45  iter: 7939  total_loss: 68.45  loss_ce: 2.507  loss_mask: 0.6349  loss_dice: 3.484  loss_ce_0: 3.856  loss_mask_0: 0.6465  loss_dice_0: 3.77  loss_ce_1: 2.691  loss_mask_1: 0.646  loss_dice_1: 3.619  loss_ce_2: 2.559  loss_mask_2: 0.6431  loss_dice_2: 3.548  loss_ce_3: 2.533  loss_mask_3: 0.6395  loss_dice_3: 3.519  loss_ce_4: 2.505  loss_mask_4: 0.6395  loss_dice_4: 3.502  loss_ce_5: 2.496  loss_mask_5: 0.6394  loss_dice_5: 3.497  loss_ce_6: 2.484  loss_mask_6: 0.6392  loss_dice_6: 3.49  loss_ce_7: 2.497  loss_mask_7: 0.6342  loss_dice_7: 3.491  loss_ce_8: 2.507  loss_mask_8: 0.6345  loss_dice_8: 3.494  time: 1.7027  data_time: 0.3191  lr: 8.1946e-06  max_mem: 17674M
[01/19 04:44:34] d2.utils.events INFO:  eta: 14:59:11  iter: 7959  total_loss: 68.47  loss_ce: 2.56  loss_mask: 0.6484  loss_dice: 3.414  loss_ce_0: 3.858  loss_mask_0: 0.6636  loss_dice_0: 3.71  loss_ce_1: 2.744  loss_mask_1: 0.6596  loss_dice_1: 3.55  loss_ce_2: 2.643  loss_mask_2: 0.6574  loss_dice_2: 3.475  loss_ce_3: 2.585  loss_mask_3: 0.6525  loss_dice_3: 3.425  loss_ce_4: 2.576  loss_mask_4: 0.6486  loss_dice_4: 3.422  loss_ce_5: 2.56  loss_mask_5: 0.6498  loss_dice_5: 3.423  loss_ce_6: 2.574  loss_mask_6: 0.6496  loss_dice_6: 3.405  loss_ce_7: 2.537  loss_mask_7: 0.6488  loss_dice_7: 3.407  loss_ce_8: 2.566  loss_mask_8: 0.6477  loss_dice_8: 3.409  time: 1.7026  data_time: 0.3390  lr: 8.19e-06  max_mem: 17674M
[01/19 04:45:08] d2.utils.events INFO:  eta: 14:58:41  iter: 7979  total_loss: 68.17  loss_ce: 2.458  loss_mask: 0.62  loss_dice: 3.535  loss_ce_0: 3.823  loss_mask_0: 0.647  loss_dice_0: 3.772  loss_ce_1: 2.59  loss_mask_1: 0.6392  loss_dice_1: 3.652  loss_ce_2: 2.517  loss_mask_2: 0.6328  loss_dice_2: 3.599  loss_ce_3: 2.497  loss_mask_3: 0.6253  loss_dice_3: 3.559  loss_ce_4: 2.471  loss_mask_4: 0.6236  loss_dice_4: 3.555  loss_ce_5: 2.466  loss_mask_5: 0.6235  loss_dice_5: 3.548  loss_ce_6: 2.462  loss_mask_6: 0.6245  loss_dice_6: 3.537  loss_ce_7: 2.443  loss_mask_7: 0.6229  loss_dice_7: 3.529  loss_ce_8: 2.453  loss_mask_8: 0.6257  loss_dice_8: 3.536  time: 1.7026  data_time: 0.3257  lr: 8.1854e-06  max_mem: 17674M
[01/19 04:45:42] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 04:45:43] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 04:45:43] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 04:51:13] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.143559996577365, 'error_1pix': 0.543290986044032, 'error_3pix': 0.27549787344411064, 'mIoU': 4.718439744101692, 'fwIoU': 16.403924101306462, 'IoU-0': nan, 'IoU-1': 95.1311771531979, 'IoU-2': 9.712403125617014, 'IoU-3': 36.07302254074198, 'IoU-4': 17.483010097329647, 'IoU-5': 19.698231326138302, 'IoU-6': 14.406096158168685, 'IoU-7': 7.873033416224996, 'IoU-8': 3.821316545236992, 'IoU-9': 1.7311556887754258, 'IoU-10': 12.930708065899571, 'IoU-11': 15.807128836568236, 'IoU-12': 18.917843123953347, 'IoU-13': 6.724621383108323, 'IoU-14': 9.529398936982556, 'IoU-15': 9.467394667306527, 'IoU-16': 6.391218302664899, 'IoU-17': 5.707539772584293, 'IoU-18': 8.501287999159638, 'IoU-19': 6.868585722211291, 'IoU-20': 8.81135644086639, 'IoU-21': 9.449480029638183, 'IoU-22': 9.759071141228217, 'IoU-23': 7.949824466979239, 'IoU-24': 9.364454872148707, 'IoU-25': 9.24674419929063, 'IoU-26': 9.326310664053066, 'IoU-27': 10.878821924103327, 'IoU-28': 5.786732015268991, 'IoU-29': 7.3155309405028595, 'IoU-30': 11.837773233101373, 'IoU-31': 7.5047684631152825, 'IoU-32': 8.618335273702458, 'IoU-33': 7.685643431247498, 'IoU-34': 9.188900008394887, 'IoU-35': 6.792793897786602, 'IoU-36': 10.188605491495704, 'IoU-37': 6.88128006042238, 'IoU-38': 8.27246619075671, 'IoU-39': 7.5852990942467144, 'IoU-40': 9.070536280432027, 'IoU-41': 4.711028263111708, 'IoU-42': 7.02813210077833, 'IoU-43': 9.6246965471015, 'IoU-44': 6.031425163758451, 'IoU-45': 5.967003962787843, 'IoU-46': 9.4394225073018, 'IoU-47': 3.9014559464992384, 'IoU-48': 4.887687622673993, 'IoU-49': 7.066375283482143, 'IoU-50': 6.821888355773095, 'IoU-51': 8.26940256621553, 'IoU-52': 5.808459921344725, 'IoU-53': 7.126840614006897, 'IoU-54': 7.273313269944614, 'IoU-55': 5.156609672392961, 'IoU-56': 7.66246854946221, 'IoU-57': 6.228303743050997, 'IoU-58': 5.365121612983884, 'IoU-59': 5.345501399214608, 'IoU-60': 7.583285153781211, 'IoU-61': 4.349502969931067, 'IoU-62': 4.531365831702154, 'IoU-63': 5.242537468283111, 'IoU-64': 6.00280938943756, 'IoU-65': 5.894589325860979, 'IoU-66': 7.031705745015326, 'IoU-67': 5.499696408176168, 'IoU-68': 4.446302015709516, 'IoU-69': 5.497690575021346, 'IoU-70': 6.415541329460833, 'IoU-71': 4.435346628969889, 'IoU-72': 5.057365341248656, 'IoU-73': 5.32881437098236, 'IoU-74': 6.223294464787054, 'IoU-75': 4.579479919304827, 'IoU-76': 3.4834287377168476, 'IoU-77': 5.946859558722537, 'IoU-78': 4.682069100259098, 'IoU-79': 4.316218535033036, 'IoU-80': 5.111787111994792, 'IoU-81': 5.478592927190096, 'IoU-82': 5.5889733096516645, 'IoU-83': 3.078101277046994, 'IoU-84': 5.290558707678426, 'IoU-85': 4.028239185811879, 'IoU-86': 5.399202448030527, 'IoU-87': 2.274657074413708, 'IoU-88': 4.483363075660116, 'IoU-89': 5.038530790624127, 'IoU-90': 3.8161019585011857, 'IoU-91': 5.048916424511368, 'IoU-92': 4.223268840324076, 'IoU-93': 3.3183870238402866, 'IoU-94': 5.372734712131809, 'IoU-95': 4.170246582139657, 'IoU-96': 3.942035178261638, 'IoU-97': 2.8674987462295523, 'IoU-98': 3.7539898363505966, 'IoU-99': 3.6548408679726863, 'IoU-100': 2.9385315559674616, 'IoU-101': 4.047786790214154, 'IoU-102': 3.3509654185129536, 'IoU-103': 2.580293397616575, 'IoU-104': 2.3463563536253584, 'IoU-105': 2.2804628900403663, 'IoU-106': 3.0037148628337498, 'IoU-107': 2.19373731505561, 'IoU-108': 2.239097149111665, 'IoU-109': 1.1095323622470983, 'IoU-110': 1.7174388117111208, 'IoU-111': 1.5902593770494438, 'IoU-112': 2.3611844340282335, 'IoU-113': 1.4783542472947477, 'IoU-114': 2.8478625109005575, 'IoU-115': 1.3101951512797705, 'IoU-116': 2.2089161033776836, 'IoU-117': 1.818415370376438, 'IoU-118': 1.7328662079254202, 'IoU-119': 1.0956672681469144, 'IoU-120': 2.905804648382962, 'IoU-121': 1.2691113320250609, 'IoU-122': 1.1182965443411335, 'IoU-123': 1.2816292550476636, 'IoU-124': 1.0474499141735074, 'IoU-125': 2.4834864138909287, 'IoU-126': 1.1976046195318713, 'IoU-127': 1.5548535359292703, 'IoU-128': 1.1039287308797983, 'IoU-129': 0.599698615103642, 'IoU-130': 1.2955603528235242, 'IoU-131': 1.0956523472569, 'IoU-132': 2.3032292054520607, 'IoU-133': 1.0870513778803068, 'IoU-134': 0.6969103151566943, 'IoU-135': 0.58637697808365, 'IoU-136': 0.38579561109580396, 'IoU-137': 1.133213324413169, 'IoU-138': 0.6055795631595967, 'IoU-139': 0.18883183695641423, 'IoU-140': 0.6730455743699827, 'IoU-141': 0.6327850406228638, 'IoU-142': 0.4429203368808654, 'IoU-143': 0.5102893087140068, 'IoU-144': 1.1415558724287962, 'IoU-145': 1.1659705712266273, 'IoU-146': 0.40562558797032183, 'IoU-147': 1.562219854113895, 'IoU-148': 1.4004775598878398, 'IoU-149': 1.3584680148925368, 'IoU-150': 0.9600106638229805, 'IoU-151': 0.6223511173200823, 'IoU-152': 0.08920658612808434, 'IoU-153': 0.28280272383676114, 'IoU-154': 0.6660605482190666, 'IoU-155': 0.1527973267350584, 'IoU-156': 0.534172556871377, 'IoU-157': 0.43685986545676025, 'IoU-158': 0.8549511890784117, 'IoU-159': 0.518861018667634, 'IoU-160': 1.3762819586884298, 'IoU-161': 0.20724718695217342, 'IoU-162': 0.6045392008992864, 'IoU-163': 0.3852059000932171, 'IoU-164': 0.15504668209513384, 'IoU-165': 0.45471056087448264, 'IoU-166': 0.0771648682527984, 'IoU-167': 0.9687813768478146, 'IoU-168': 0.5757465909446898, 'IoU-169': 1.0051745816810136, 'IoU-170': 0.12426801034999319, 'IoU-171': 0.17662830834108698, 'IoU-172': 1.7987233407274816, 'IoU-173': 0.43301831133813146, 'IoU-174': 0.3512437651017139, 'IoU-175': 0.6780669874956471, 'IoU-176': 0.010938858951483471, 'IoU-177': 0.04250248968558828, 'IoU-178': 0.15201071759081386, 'IoU-179': 0.07284200760240532, 'IoU-180': 0.18810227593549417, 'IoU-181': 0.1493325981574655, 'IoU-182': 0.3237357336369862, 'IoU-183': 0.001852713878448074, 'IoU-184': 0.29408723079707333, 'IoU-185': 0.4785688321755703, 'IoU-186': 0.02886514522350032, 'IoU-187': 1.8523362968480384, 'IoU-188': 0.04663025605107807, 'IoU-189': 2.0171251532550603, 'IoU-190': 1.7925070587512244, 'IoU-191': 0.07637115888908387, 'IoU-192': 1.9446742629651779, 'mACC': 8.4333514315773, 'pACC': 22.9845629335434, 'ACC-0': nan, 'ACC-1': 98.49790934440404, 'ACC-2': 10.423027086513544, 'ACC-3': 54.788897079382835, 'ACC-4': 21.2328206861132, 'ACC-5': 34.720812823624655, 'ACC-6': 22.54909569413473, 'ACC-7': 10.285833050745484, 'ACC-8': 4.422158484599147, 'ACC-9': 1.8560233309056047, 'ACC-10': 19.75050216263461, 'ACC-11': 23.81523976198185, 'ACC-12': 67.30447555047218, 'ACC-13': 10.207488776411031, 'ACC-14': 16.16854504390802, 'ACC-15': 20.836644018815498, 'ACC-16': 10.728451903355056, 'ACC-17': 9.080394946670323, 'ACC-18': 15.577818068452325, 'ACC-19': 11.071611345527586, 'ACC-20': 16.22893909550254, 'ACC-21': 14.628399665778675, 'ACC-22': 15.732195501485318, 'ACC-23': 12.272454454315573, 'ACC-24': 16.864401328332914, 'ACC-25': 20.02505485702371, 'ACC-26': 17.233894872405013, 'ACC-27': 19.229539067771114, 'ACC-28': 7.926279085028217, 'ACC-29': 11.88164725919994, 'ACC-30': 33.64404333715055, 'ACC-31': 11.108716503948045, 'ACC-32': 14.473115417886618, 'ACC-33': 13.71723466020951, 'ACC-34': 18.31660407376793, 'ACC-35': 10.155286381687603, 'ACC-36': 21.22592649996065, 'ACC-37': 10.490292640004945, 'ACC-38': 15.392015577230827, 'ACC-39': 13.096572149272637, 'ACC-40': 18.61352562956999, 'ACC-41': 6.792093753277083, 'ACC-42': 13.752746390915958, 'ACC-43': 19.882250431397814, 'ACC-44': 10.436684710750676, 'ACC-45': 10.107312786312454, 'ACC-46': 23.996744862664894, 'ACC-47': 5.605664572197007, 'ACC-48': 7.367002483989971, 'ACC-49': 14.096144574407528, 'ACC-50': 15.481455708798714, 'ACC-51': 19.68180697454882, 'ACC-52': 9.75885669371006, 'ACC-53': 14.202687506309003, 'ACC-54': 14.174642300818649, 'ACC-55': 8.601229710795586, 'ACC-56': 17.298597542453837, 'ACC-57': 11.095100043007653, 'ACC-58': 9.045292298962643, 'ACC-59': 9.418217994514556, 'ACC-60': 18.89552699706069, 'ACC-61': 6.781339480319672, 'ACC-62': 8.37166663278475, 'ACC-63': 9.903241562596378, 'ACC-64': 12.177574424152507, 'ACC-65': 12.07592709187012, 'ACC-66': 17.899568729913888, 'ACC-67': 10.577172732414777, 'ACC-68': 7.622713917733454, 'ACC-69': 10.766495085975176, 'ACC-70': 13.491253925281033, 'ACC-71': 7.1122830442795575, 'ACC-72': 10.060998425760861, 'ACC-73': 9.944514399339866, 'ACC-74': 13.739494200998292, 'ACC-75': 8.838970492684052, 'ACC-76': 5.547658414807679, 'ACC-77': 13.375723936590719, 'ACC-78': 8.476757813669854, 'ACC-79': 6.464606839751649, 'ACC-80': 10.40268682730763, 'ACC-81': 13.267085273739996, 'ACC-82': 11.623926161833435, 'ACC-83': 4.732757497179491, 'ACC-84': 11.666774223878313, 'ACC-85': 6.895193338990026, 'ACC-86': 9.758488592643012, 'ACC-87': 2.918280416056158, 'ACC-88': 8.446924669632647, 'ACC-89': 9.747794481401865, 'ACC-90': 5.985556430954957, 'ACC-91': 9.559422066344963, 'ACC-92': 9.14667953283083, 'ACC-93': 5.234732747674506, 'ACC-94': 13.736221296140869, 'ACC-95': 8.884137262370581, 'ACC-96': 8.197847446796924, 'ACC-97': 4.500131744997157, 'ACC-98': 6.727091769044585, 'ACC-99': 6.7912893096072455, 'ACC-100': 4.741283885862756, 'ACC-101': 11.552501758168821, 'ACC-102': 9.083099229723606, 'ACC-103': 4.194035137432701, 'ACC-104': 3.682373773394653, 'ACC-105': 4.008145979965527, 'ACC-106': 8.429707119663451, 'ACC-107': 3.836773146395485, 'ACC-108': 4.372452449641792, 'ACC-109': 1.2122474956873517, 'ACC-110': 2.5963147313491124, 'ACC-111': 2.1695889003695217, 'ACC-112': 6.078186820629961, 'ACC-113': 2.4027769830825276, 'ACC-114': 6.355327647952969, 'ACC-115': 1.8994407108384828, 'ACC-116': 5.420136427020663, 'ACC-117': 3.077366319303527, 'ACC-118': 3.534832516478796, 'ACC-119': 1.7672891315900199, 'ACC-120': 5.757580549376795, 'ACC-121': 1.8085715700252587, 'ACC-122': 1.6789794974855408, 'ACC-123': 2.1496776001689466, 'ACC-124': 1.5977829642624453, 'ACC-125': 6.712963214747603, 'ACC-126': 2.3887398792338725, 'ACC-127': 3.600806941472213, 'ACC-128': 2.2844500061593553, 'ACC-129': 0.735209678461858, 'ACC-130': 3.3645648186604684, 'ACC-131': 2.0455063523741734, 'ACC-132': 6.873762202048839, 'ACC-133': 1.754475494498765, 'ACC-134': 1.0108056872037914, 'ACC-135': 0.9515563536856508, 'ACC-136': 0.5055703736489006, 'ACC-137': 2.2740507870070377, 'ACC-138': 0.947724446023809, 'ACC-139': 0.20348382008488602, 'ACC-140': 1.7765000737136958, 'ACC-141': 0.880265392441836, 'ACC-142': 0.5504510240065813, 'ACC-143': 0.6862541593543802, 'ACC-144': 2.0296028880866426, 'ACC-145': 1.6231132180952168, 'ACC-146': 0.5953713646021338, 'ACC-147': 5.881708439223274, 'ACC-148': 2.9681070594486387, 'ACC-149': 2.604990117324447, 'ACC-150': 1.5013409296764988, 'ACC-151': 1.1252468604887864, 'ACC-152': 0.09672769573133724, 'ACC-153': 0.36552520200076954, 'ACC-154': 0.934167931832512, 'ACC-155': 0.1641756827711672, 'ACC-156': 0.6387558416878357, 'ACC-157': 0.5203250704677754, 'ACC-158': 1.4089317494435827, 'ACC-159': 0.6732598593086788, 'ACC-160': 3.0309799574718364, 'ACC-161': 0.2295851739932655, 'ACC-162': 0.950458344366723, 'ACC-163': 0.4725093133710505, 'ACC-164': 0.18280753046527926, 'ACC-165': 0.5944534617424808, 'ACC-166': 0.08226238342664798, 'ACC-167': 1.9224655920870921, 'ACC-168': 0.9047753006540544, 'ACC-169': 2.188305524019421, 'ACC-170': 0.14250322983659156, 'ACC-171': 0.1886449342314326, 'ACC-172': 4.418268696521835, 'ACC-173': 0.5205961927052564, 'ACC-174': 0.6110188431649957, 'ACC-175': 0.8171883175349756, 'ACC-176': 0.011064836312978872, 'ACC-177': 0.044106601411042154, 'ACC-178': 0.17577374249339883, 'ACC-179': 0.07709771729890176, 'ACC-180': 0.23409190964814253, 'ACC-181': 0.1693586400145909, 'ACC-182': 0.3819099763320058, 'ACC-183': 0.001883456425058446, 'ACC-184': 0.32192105505203805, 'ACC-185': 0.5503743839178896, 'ACC-186': 0.029980194186675104, 'ACC-187': 3.4728614745285635, 'ACC-188': 0.062295710423308184, 'ACC-189': 3.6788773904359457, 'ACC-190': 6.495435823804982, 'ACC-191': 0.08065252854812398, 'ACC-192': 3.359075872100427})])
[01/19 04:51:13] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 04:51:13] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 04:51:13] d2.evaluation.testing INFO: copypaste: 4.1436,0.5433,0.2755,4.7184,16.4039,8.4334,22.9846
[01/19 04:51:13] d2.utils.events INFO:  eta: 14:58:07  iter: 7999  total_loss: 67.85  loss_ce: 2.482  loss_mask: 0.6282  loss_dice: 3.49  loss_ce_0: 3.846  loss_mask_0: 0.6497  loss_dice_0: 3.75  loss_ce_1: 2.676  loss_mask_1: 0.6416  loss_dice_1: 3.626  loss_ce_2: 2.541  loss_mask_2: 0.6364  loss_dice_2: 3.567  loss_ce_3: 2.483  loss_mask_3: 0.6347  loss_dice_3: 3.524  loss_ce_4: 2.451  loss_mask_4: 0.6308  loss_dice_4: 3.516  loss_ce_5: 2.462  loss_mask_5: 0.6312  loss_dice_5: 3.51  loss_ce_6: 2.47  loss_mask_6: 0.6328  loss_dice_6: 3.498  loss_ce_7: 2.476  loss_mask_7: 0.6319  loss_dice_7: 3.497  loss_ce_8: 2.468  loss_mask_8: 0.6274  loss_dice_8: 3.494  time: 1.7026  data_time: 0.3643  lr: 8.1808e-06  max_mem: 17674M
[01/19 04:51:46] d2.utils.events INFO:  eta: 14:57:23  iter: 8019  total_loss: 68.53  loss_ce: 2.567  loss_mask: 0.6472  loss_dice: 3.43  loss_ce_0: 3.795  loss_mask_0: 0.67  loss_dice_0: 3.708  loss_ce_1: 2.71  loss_mask_1: 0.6647  loss_dice_1: 3.582  loss_ce_2: 2.618  loss_mask_2: 0.6589  loss_dice_2: 3.503  loss_ce_3: 2.575  loss_mask_3: 0.6502  loss_dice_3: 3.461  loss_ce_4: 2.579  loss_mask_4: 0.6467  loss_dice_4: 3.451  loss_ce_5: 2.57  loss_mask_5: 0.6468  loss_dice_5: 3.453  loss_ce_6: 2.554  loss_mask_6: 0.647  loss_dice_6: 3.437  loss_ce_7: 2.537  loss_mask_7: 0.6481  loss_dice_7: 3.442  loss_ce_8: 2.543  loss_mask_8: 0.6494  loss_dice_8: 3.434  time: 1.7025  data_time: 0.3250  lr: 8.1761e-06  max_mem: 17674M
[01/19 04:52:20] d2.utils.events INFO:  eta: 14:56:49  iter: 8039  total_loss: 68.9  loss_ce: 2.563  loss_mask: 0.6258  loss_dice: 3.472  loss_ce_0: 3.854  loss_mask_0: 0.646  loss_dice_0: 3.757  loss_ce_1: 2.703  loss_mask_1: 0.6438  loss_dice_1: 3.615  loss_ce_2: 2.602  loss_mask_2: 0.6376  loss_dice_2: 3.543  loss_ce_3: 2.589  loss_mask_3: 0.6316  loss_dice_3: 3.495  loss_ce_4: 2.581  loss_mask_4: 0.6293  loss_dice_4: 3.491  loss_ce_5: 2.558  loss_mask_5: 0.6291  loss_dice_5: 3.491  loss_ce_6: 2.567  loss_mask_6: 0.6263  loss_dice_6: 3.481  loss_ce_7: 2.553  loss_mask_7: 0.6284  loss_dice_7: 3.474  loss_ce_8: 2.553  loss_mask_8: 0.6263  loss_dice_8: 3.469  time: 1.7025  data_time: 0.3373  lr: 8.1715e-06  max_mem: 17674M
[01/19 04:52:54] d2.utils.events INFO:  eta: 14:56:23  iter: 8059  total_loss: 67.78  loss_ce: 2.432  loss_mask: 0.6222  loss_dice: 3.468  loss_ce_0: 3.788  loss_mask_0: 0.6412  loss_dice_0: 3.767  loss_ce_1: 2.552  loss_mask_1: 0.6357  loss_dice_1: 3.617  loss_ce_2: 2.47  loss_mask_2: 0.6291  loss_dice_2: 3.543  loss_ce_3: 2.45  loss_mask_3: 0.625  loss_dice_3: 3.495  loss_ce_4: 2.414  loss_mask_4: 0.6234  loss_dice_4: 3.496  loss_ce_5: 2.415  loss_mask_5: 0.6207  loss_dice_5: 3.489  loss_ce_6: 2.41  loss_mask_6: 0.6212  loss_dice_6: 3.474  loss_ce_7: 2.406  loss_mask_7: 0.6232  loss_dice_7: 3.472  loss_ce_8: 2.395  loss_mask_8: 0.6198  loss_dice_8: 3.472  time: 1.7025  data_time: 0.3254  lr: 8.1669e-06  max_mem: 17674M
[01/19 04:53:28] d2.utils.events INFO:  eta: 14:55:49  iter: 8079  total_loss: 67.91  loss_ce: 2.426  loss_mask: 0.6223  loss_dice: 3.481  loss_ce_0: 3.79  loss_mask_0: 0.6387  loss_dice_0: 3.756  loss_ce_1: 2.617  loss_mask_1: 0.6326  loss_dice_1: 3.631  loss_ce_2: 2.516  loss_mask_2: 0.6273  loss_dice_2: 3.558  loss_ce_3: 2.449  loss_mask_3: 0.6244  loss_dice_3: 3.501  loss_ce_4: 2.428  loss_mask_4: 0.6239  loss_dice_4: 3.498  loss_ce_5: 2.418  loss_mask_5: 0.6238  loss_dice_5: 3.502  loss_ce_6: 2.412  loss_mask_6: 0.6229  loss_dice_6: 3.481  loss_ce_7: 2.415  loss_mask_7: 0.6233  loss_dice_7: 3.481  loss_ce_8: 2.417  loss_mask_8: 0.6293  loss_dice_8: 3.48  time: 1.7024  data_time: 0.3485  lr: 8.1623e-06  max_mem: 17674M
[01/19 04:54:02] d2.utils.events INFO:  eta: 14:55:19  iter: 8099  total_loss: 67.82  loss_ce: 2.432  loss_mask: 0.6214  loss_dice: 3.472  loss_ce_0: 3.794  loss_mask_0: 0.6404  loss_dice_0: 3.747  loss_ce_1: 2.63  loss_mask_1: 0.635  loss_dice_1: 3.621  loss_ce_2: 2.5  loss_mask_2: 0.6301  loss_dice_2: 3.544  loss_ce_3: 2.451  loss_mask_3: 0.6234  loss_dice_3: 3.492  loss_ce_4: 2.409  loss_mask_4: 0.6229  loss_dice_4: 3.481  loss_ce_5: 2.413  loss_mask_5: 0.6254  loss_dice_5: 3.484  loss_ce_6: 2.428  loss_mask_6: 0.6224  loss_dice_6: 3.466  loss_ce_7: 2.425  loss_mask_7: 0.6237  loss_dice_7: 3.467  loss_ce_8: 2.407  loss_mask_8: 0.6213  loss_dice_8: 3.467  time: 1.7024  data_time: 0.3336  lr: 8.1577e-06  max_mem: 17674M
[01/19 04:54:35] d2.utils.events INFO:  eta: 14:54:52  iter: 8119  total_loss: 68.42  loss_ce: 2.497  loss_mask: 0.653  loss_dice: 3.412  loss_ce_0: 3.813  loss_mask_0: 0.6693  loss_dice_0: 3.719  loss_ce_1: 2.659  loss_mask_1: 0.6651  loss_dice_1: 3.579  loss_ce_2: 2.534  loss_mask_2: 0.6566  loss_dice_2: 3.501  loss_ce_3: 2.548  loss_mask_3: 0.6526  loss_dice_3: 3.444  loss_ce_4: 2.52  loss_mask_4: 0.6556  loss_dice_4: 3.446  loss_ce_5: 2.511  loss_mask_5: 0.655  loss_dice_5: 3.432  loss_ce_6: 2.48  loss_mask_6: 0.6529  loss_dice_6: 3.416  loss_ce_7: 2.495  loss_mask_7: 0.6514  loss_dice_7: 3.425  loss_ce_8: 2.502  loss_mask_8: 0.6526  loss_dice_8: 3.427  time: 1.7023  data_time: 0.3434  lr: 8.1531e-06  max_mem: 17674M
[01/19 04:55:09] d2.utils.events INFO:  eta: 14:54:13  iter: 8139  total_loss: 68.39  loss_ce: 2.517  loss_mask: 0.6317  loss_dice: 3.526  loss_ce_0: 3.819  loss_mask_0: 0.654  loss_dice_0: 3.782  loss_ce_1: 2.636  loss_mask_1: 0.646  loss_dice_1: 3.668  loss_ce_2: 2.531  loss_mask_2: 0.6394  loss_dice_2: 3.602  loss_ce_3: 2.512  loss_mask_3: 0.6342  loss_dice_3: 3.55  loss_ce_4: 2.511  loss_mask_4: 0.6348  loss_dice_4: 3.545  loss_ce_5: 2.496  loss_mask_5: 0.6354  loss_dice_5: 3.544  loss_ce_6: 2.509  loss_mask_6: 0.6314  loss_dice_6: 3.536  loss_ce_7: 2.503  loss_mask_7: 0.6321  loss_dice_7: 3.54  loss_ce_8: 2.499  loss_mask_8: 0.632  loss_dice_8: 3.537  time: 1.7023  data_time: 0.3473  lr: 8.1485e-06  max_mem: 17674M
[01/19 04:55:43] d2.utils.events INFO:  eta: 14:53:18  iter: 8159  total_loss: 68.71  loss_ce: 2.58  loss_mask: 0.6258  loss_dice: 3.466  loss_ce_0: 3.837  loss_mask_0: 0.6432  loss_dice_0: 3.756  loss_ce_1: 2.719  loss_mask_1: 0.6422  loss_dice_1: 3.617  loss_ce_2: 2.604  loss_mask_2: 0.6311  loss_dice_2: 3.534  loss_ce_3: 2.581  loss_mask_3: 0.6266  loss_dice_3: 3.489  loss_ce_4: 2.552  loss_mask_4: 0.6254  loss_dice_4: 3.485  loss_ce_5: 2.561  loss_mask_5: 0.6252  loss_dice_5: 3.476  loss_ce_6: 2.567  loss_mask_6: 0.6237  loss_dice_6: 3.468  loss_ce_7: 2.562  loss_mask_7: 0.6256  loss_dice_7: 3.472  loss_ce_8: 2.563  loss_mask_8: 0.6251  loss_dice_8: 3.468  time: 1.7022  data_time: 0.3224  lr: 8.1439e-06  max_mem: 17674M
[01/19 04:56:17] d2.utils.events INFO:  eta: 14:52:58  iter: 8179  total_loss: 68.67  loss_ce: 2.535  loss_mask: 0.6299  loss_dice: 3.499  loss_ce_0: 3.816  loss_mask_0: 0.647  loss_dice_0: 3.778  loss_ce_1: 2.593  loss_mask_1: 0.6468  loss_dice_1: 3.649  loss_ce_2: 2.521  loss_mask_2: 0.6417  loss_dice_2: 3.577  loss_ce_3: 2.553  loss_mask_3: 0.6348  loss_dice_3: 3.527  loss_ce_4: 2.532  loss_mask_4: 0.633  loss_dice_4: 3.523  loss_ce_5: 2.513  loss_mask_5: 0.6341  loss_dice_5: 3.52  loss_ce_6: 2.513  loss_mask_6: 0.6326  loss_dice_6: 3.504  loss_ce_7: 2.501  loss_mask_7: 0.6317  loss_dice_7: 3.504  loss_ce_8: 2.521  loss_mask_8: 0.6313  loss_dice_8: 3.505  time: 1.7022  data_time: 0.3561  lr: 8.1393e-06  max_mem: 17674M
[01/19 04:56:50] d2.utils.events INFO:  eta: 14:52:24  iter: 8199  total_loss: 67.99  loss_ce: 2.424  loss_mask: 0.6329  loss_dice: 3.492  loss_ce_0: 3.837  loss_mask_0: 0.655  loss_dice_0: 3.761  loss_ce_1: 2.567  loss_mask_1: 0.6489  loss_dice_1: 3.632  loss_ce_2: 2.462  loss_mask_2: 0.6431  loss_dice_2: 3.552  loss_ce_3: 2.442  loss_mask_3: 0.6399  loss_dice_3: 3.511  loss_ce_4: 2.405  loss_mask_4: 0.6402  loss_dice_4: 3.51  loss_ce_5: 2.41  loss_mask_5: 0.6398  loss_dice_5: 3.507  loss_ce_6: 2.424  loss_mask_6: 0.6395  loss_dice_6: 3.49  loss_ce_7: 2.4  loss_mask_7: 0.6362  loss_dice_7: 3.491  loss_ce_8: 2.413  loss_mask_8: 0.6345  loss_dice_8: 3.494  time: 1.7022  data_time: 0.3414  lr: 8.1347e-06  max_mem: 17674M
[01/19 04:57:24] d2.utils.events INFO:  eta: 14:51:41  iter: 8219  total_loss: 68.85  loss_ce: 2.536  loss_mask: 0.6509  loss_dice: 3.515  loss_ce_0: 3.853  loss_mask_0: 0.6641  loss_dice_0: 3.767  loss_ce_1: 2.649  loss_mask_1: 0.6703  loss_dice_1: 3.65  loss_ce_2: 2.529  loss_mask_2: 0.6569  loss_dice_2: 3.588  loss_ce_3: 2.552  loss_mask_3: 0.6465  loss_dice_3: 3.543  loss_ce_4: 2.537  loss_mask_4: 0.6505  loss_dice_4: 3.533  loss_ce_5: 2.516  loss_mask_5: 0.6518  loss_dice_5: 3.531  loss_ce_6: 2.524  loss_mask_6: 0.6522  loss_dice_6: 3.52  loss_ce_7: 2.514  loss_mask_7: 0.6522  loss_dice_7: 3.514  loss_ce_8: 2.511  loss_mask_8: 0.6525  loss_dice_8: 3.519  time: 1.7021  data_time: 0.3465  lr: 8.1301e-06  max_mem: 17674M
[01/19 04:57:58] d2.utils.events INFO:  eta: 14:50:23  iter: 8239  total_loss: 67.32  loss_ce: 2.444  loss_mask: 0.6245  loss_dice: 3.47  loss_ce_0: 3.762  loss_mask_0: 0.6343  loss_dice_0: 3.758  loss_ce_1: 2.553  loss_mask_1: 0.6326  loss_dice_1: 3.625  loss_ce_2: 2.474  loss_mask_2: 0.6291  loss_dice_2: 3.553  loss_ce_3: 2.45  loss_mask_3: 0.6255  loss_dice_3: 3.501  loss_ce_4: 2.425  loss_mask_4: 0.621  loss_dice_4: 3.499  loss_ce_5: 2.447  loss_mask_5: 0.6232  loss_dice_5: 3.49  loss_ce_6: 2.443  loss_mask_6: 0.6199  loss_dice_6: 3.485  loss_ce_7: 2.419  loss_mask_7: 0.6207  loss_dice_7: 3.487  loss_ce_8: 2.411  loss_mask_8: 0.6262  loss_dice_8: 3.485  time: 1.7021  data_time: 0.3470  lr: 8.1255e-06  max_mem: 17674M
[01/19 04:58:32] d2.utils.events INFO:  eta: 14:50:08  iter: 8259  total_loss: 68.33  loss_ce: 2.482  loss_mask: 0.6333  loss_dice: 3.486  loss_ce_0: 3.823  loss_mask_0: 0.6484  loss_dice_0: 3.759  loss_ce_1: 2.692  loss_mask_1: 0.6448  loss_dice_1: 3.619  loss_ce_2: 2.545  loss_mask_2: 0.6406  loss_dice_2: 3.535  loss_ce_3: 2.504  loss_mask_3: 0.6378  loss_dice_3: 3.501  loss_ce_4: 2.497  loss_mask_4: 0.6365  loss_dice_4: 3.503  loss_ce_5: 2.479  loss_mask_5: 0.6383  loss_dice_5: 3.5  loss_ce_6: 2.483  loss_mask_6: 0.639  loss_dice_6: 3.488  loss_ce_7: 2.473  loss_mask_7: 0.6376  loss_dice_7: 3.49  loss_ce_8: 2.493  loss_mask_8: 0.6379  loss_dice_8: 3.491  time: 1.7021  data_time: 0.3427  lr: 8.1209e-06  max_mem: 17674M
[01/19 04:59:05] d2.utils.events INFO:  eta: 14:49:35  iter: 8279  total_loss: 68.56  loss_ce: 2.542  loss_mask: 0.6362  loss_dice: 3.424  loss_ce_0: 3.851  loss_mask_0: 0.6582  loss_dice_0: 3.718  loss_ce_1: 2.707  loss_mask_1: 0.6518  loss_dice_1: 3.587  loss_ce_2: 2.588  loss_mask_2: 0.6394  loss_dice_2: 3.512  loss_ce_3: 2.565  loss_mask_3: 0.6368  loss_dice_3: 3.46  loss_ce_4: 2.555  loss_mask_4: 0.6354  loss_dice_4: 3.463  loss_ce_5: 2.555  loss_mask_5: 0.6361  loss_dice_5: 3.457  loss_ce_6: 2.549  loss_mask_6: 0.6375  loss_dice_6: 3.44  loss_ce_7: 2.522  loss_mask_7: 0.6381  loss_dice_7: 3.425  loss_ce_8: 2.518  loss_mask_8: 0.6383  loss_dice_8: 3.435  time: 1.7020  data_time: 0.3453  lr: 8.1163e-06  max_mem: 17674M
[01/19 04:59:39] d2.utils.events INFO:  eta: 14:49:26  iter: 8299  total_loss: 67.91  loss_ce: 2.424  loss_mask: 0.6219  loss_dice: 3.519  loss_ce_0: 3.8  loss_mask_0: 0.644  loss_dice_0: 3.77  loss_ce_1: 2.623  loss_mask_1: 0.6398  loss_dice_1: 3.65  loss_ce_2: 2.476  loss_mask_2: 0.628  loss_dice_2: 3.58  loss_ce_3: 2.477  loss_mask_3: 0.6291  loss_dice_3: 3.523  loss_ce_4: 2.444  loss_mask_4: 0.6282  loss_dice_4: 3.532  loss_ce_5: 2.438  loss_mask_5: 0.6253  loss_dice_5: 3.525  loss_ce_6: 2.453  loss_mask_6: 0.6233  loss_dice_6: 3.52  loss_ce_7: 2.415  loss_mask_7: 0.6253  loss_dice_7: 3.518  loss_ce_8: 2.433  loss_mask_8: 0.6227  loss_dice_8: 3.52  time: 1.7020  data_time: 0.3461  lr: 8.1117e-06  max_mem: 17674M
[01/19 05:00:13] d2.utils.events INFO:  eta: 14:49:05  iter: 8319  total_loss: 67.36  loss_ce: 2.357  loss_mask: 0.6248  loss_dice: 3.515  loss_ce_0: 3.773  loss_mask_0: 0.6404  loss_dice_0: 3.769  loss_ce_1: 2.537  loss_mask_1: 0.6374  loss_dice_1: 3.644  loss_ce_2: 2.406  loss_mask_2: 0.6288  loss_dice_2: 3.581  loss_ce_3: 2.383  loss_mask_3: 0.6225  loss_dice_3: 3.537  loss_ce_4: 2.367  loss_mask_4: 0.6239  loss_dice_4: 3.531  loss_ce_5: 2.364  loss_mask_5: 0.6261  loss_dice_5: 3.526  loss_ce_6: 2.353  loss_mask_6: 0.6268  loss_dice_6: 3.516  loss_ce_7: 2.335  loss_mask_7: 0.6245  loss_dice_7: 3.515  loss_ce_8: 2.342  loss_mask_8: 0.627  loss_dice_8: 3.52  time: 1.7019  data_time: 0.3273  lr: 8.1071e-06  max_mem: 17674M
[01/19 05:00:47] d2.utils.events INFO:  eta: 14:48:33  iter: 8339  total_loss: 67.12  loss_ce: 2.45  loss_mask: 0.6323  loss_dice: 3.459  loss_ce_0: 3.823  loss_mask_0: 0.6511  loss_dice_0: 3.722  loss_ce_1: 2.645  loss_mask_1: 0.6443  loss_dice_1: 3.606  loss_ce_2: 2.516  loss_mask_2: 0.6347  loss_dice_2: 3.532  loss_ce_3: 2.481  loss_mask_3: 0.6333  loss_dice_3: 3.488  loss_ce_4: 2.456  loss_mask_4: 0.633  loss_dice_4: 3.48  loss_ce_5: 2.45  loss_mask_5: 0.6348  loss_dice_5: 3.475  loss_ce_6: 2.45  loss_mask_6: 0.6332  loss_dice_6: 3.46  loss_ce_7: 2.46  loss_mask_7: 0.6339  loss_dice_7: 3.459  loss_ce_8: 2.447  loss_mask_8: 0.6345  loss_dice_8: 3.462  time: 1.7019  data_time: 0.3518  lr: 8.1025e-06  max_mem: 17674M
[01/19 05:01:21] d2.utils.events INFO:  eta: 14:47:50  iter: 8359  total_loss: 67.5  loss_ce: 2.42  loss_mask: 0.6443  loss_dice: 3.52  loss_ce_0: 3.785  loss_mask_0: 0.6566  loss_dice_0: 3.769  loss_ce_1: 2.604  loss_mask_1: 0.6622  loss_dice_1: 3.656  loss_ce_2: 2.46  loss_mask_2: 0.6501  loss_dice_2: 3.593  loss_ce_3: 2.452  loss_mask_3: 0.6472  loss_dice_3: 3.544  loss_ce_4: 2.43  loss_mask_4: 0.6456  loss_dice_4: 3.536  loss_ce_5: 2.426  loss_mask_5: 0.6456  loss_dice_5: 3.539  loss_ce_6: 2.425  loss_mask_6: 0.6459  loss_dice_6: 3.524  loss_ce_7: 2.409  loss_mask_7: 0.6464  loss_dice_7: 3.523  loss_ce_8: 2.393  loss_mask_8: 0.6437  loss_dice_8: 3.527  time: 1.7019  data_time: 0.3488  lr: 8.0979e-06  max_mem: 17674M
[01/19 05:01:55] d2.utils.events INFO:  eta: 14:46:57  iter: 8379  total_loss: 67.7  loss_ce: 2.397  loss_mask: 0.6265  loss_dice: 3.49  loss_ce_0: 3.831  loss_mask_0: 0.6446  loss_dice_0: 3.765  loss_ce_1: 2.588  loss_mask_1: 0.6385  loss_dice_1: 3.626  loss_ce_2: 2.465  loss_mask_2: 0.6316  loss_dice_2: 3.557  loss_ce_3: 2.435  loss_mask_3: 0.6275  loss_dice_3: 3.508  loss_ce_4: 2.424  loss_mask_4: 0.624  loss_dice_4: 3.512  loss_ce_5: 2.392  loss_mask_5: 0.6259  loss_dice_5: 3.506  loss_ce_6: 2.394  loss_mask_6: 0.6288  loss_dice_6: 3.487  loss_ce_7: 2.389  loss_mask_7: 0.6286  loss_dice_7: 3.491  loss_ce_8: 2.409  loss_mask_8: 0.6245  loss_dice_8: 3.491  time: 1.7018  data_time: 0.3471  lr: 8.0933e-06  max_mem: 17674M
[01/19 05:02:29] d2.utils.events INFO:  eta: 14:46:38  iter: 8399  total_loss: 68.01  loss_ce: 2.442  loss_mask: 0.6179  loss_dice: 3.486  loss_ce_0: 3.783  loss_mask_0: 0.6381  loss_dice_0: 3.768  loss_ce_1: 2.594  loss_mask_1: 0.6362  loss_dice_1: 3.633  loss_ce_2: 2.49  loss_mask_2: 0.6276  loss_dice_2: 3.565  loss_ce_3: 2.487  loss_mask_3: 0.6249  loss_dice_3: 3.506  loss_ce_4: 2.461  loss_mask_4: 0.6271  loss_dice_4: 3.501  loss_ce_5: 2.455  loss_mask_5: 0.626  loss_dice_5: 3.494  loss_ce_6: 2.448  loss_mask_6: 0.6244  loss_dice_6: 3.494  loss_ce_7: 2.446  loss_mask_7: 0.6229  loss_dice_7: 3.495  loss_ce_8: 2.431  loss_mask_8: 0.6241  loss_dice_8: 3.489  time: 1.7018  data_time: 0.3478  lr: 8.0887e-06  max_mem: 17674M
[01/19 05:03:02] d2.utils.events INFO:  eta: 14:46:04  iter: 8419  total_loss: 67.09  loss_ce: 2.425  loss_mask: 0.6275  loss_dice: 3.495  loss_ce_0: 3.766  loss_mask_0: 0.6414  loss_dice_0: 3.761  loss_ce_1: 2.585  loss_mask_1: 0.6452  loss_dice_1: 3.633  loss_ce_2: 2.472  loss_mask_2: 0.6364  loss_dice_2: 3.562  loss_ce_3: 2.448  loss_mask_3: 0.6316  loss_dice_3: 3.525  loss_ce_4: 2.435  loss_mask_4: 0.6328  loss_dice_4: 3.518  loss_ce_5: 2.43  loss_mask_5: 0.6326  loss_dice_5: 3.513  loss_ce_6: 2.408  loss_mask_6: 0.6307  loss_dice_6: 3.5  loss_ce_7: 2.405  loss_mask_7: 0.6271  loss_dice_7: 3.492  loss_ce_8: 2.404  loss_mask_8: 0.6275  loss_dice_8: 3.496  time: 1.7018  data_time: 0.3383  lr: 8.0841e-06  max_mem: 17674M
[01/19 05:03:37] d2.utils.events INFO:  eta: 14:45:36  iter: 8439  total_loss: 67.11  loss_ce: 2.377  loss_mask: 0.6367  loss_dice: 3.471  loss_ce_0: 3.828  loss_mask_0: 0.6543  loss_dice_0: 3.749  loss_ce_1: 2.581  loss_mask_1: 0.6536  loss_dice_1: 3.62  loss_ce_2: 2.474  loss_mask_2: 0.6458  loss_dice_2: 3.552  loss_ce_3: 2.417  loss_mask_3: 0.6366  loss_dice_3: 3.508  loss_ce_4: 2.397  loss_mask_4: 0.6363  loss_dice_4: 3.496  loss_ce_5: 2.396  loss_mask_5: 0.6378  loss_dice_5: 3.497  loss_ce_6: 2.37  loss_mask_6: 0.6363  loss_dice_6: 3.48  loss_ce_7: 2.366  loss_mask_7: 0.6377  loss_dice_7: 3.48  loss_ce_8: 2.361  loss_mask_8: 0.6384  loss_dice_8: 3.482  time: 1.7018  data_time: 0.3356  lr: 8.0794e-06  max_mem: 17674M
[01/19 05:04:10] d2.utils.events INFO:  eta: 14:45:02  iter: 8459  total_loss: 67.93  loss_ce: 2.429  loss_mask: 0.6472  loss_dice: 3.494  loss_ce_0: 3.771  loss_mask_0: 0.6688  loss_dice_0: 3.738  loss_ce_1: 2.612  loss_mask_1: 0.6659  loss_dice_1: 3.624  loss_ce_2: 2.493  loss_mask_2: 0.6549  loss_dice_2: 3.562  loss_ce_3: 2.466  loss_mask_3: 0.6531  loss_dice_3: 3.508  loss_ce_4: 2.438  loss_mask_4: 0.6495  loss_dice_4: 3.505  loss_ce_5: 2.43  loss_mask_5: 0.6492  loss_dice_5: 3.507  loss_ce_6: 2.44  loss_mask_6: 0.6506  loss_dice_6: 3.497  loss_ce_7: 2.427  loss_mask_7: 0.6493  loss_dice_7: 3.491  loss_ce_8: 2.436  loss_mask_8: 0.6472  loss_dice_8: 3.497  time: 1.7017  data_time: 0.3409  lr: 8.0748e-06  max_mem: 17674M
[01/19 05:04:44] d2.utils.events INFO:  eta: 14:44:28  iter: 8479  total_loss: 67.94  loss_ce: 2.518  loss_mask: 0.6317  loss_dice: 3.464  loss_ce_0: 3.802  loss_mask_0: 0.6533  loss_dice_0: 3.748  loss_ce_1: 2.658  loss_mask_1: 0.6447  loss_dice_1: 3.614  loss_ce_2: 2.562  loss_mask_2: 0.6384  loss_dice_2: 3.535  loss_ce_3: 2.559  loss_mask_3: 0.6365  loss_dice_3: 3.486  loss_ce_4: 2.526  loss_mask_4: 0.6313  loss_dice_4: 3.486  loss_ce_5: 2.524  loss_mask_5: 0.6319  loss_dice_5: 3.476  loss_ce_6: 2.53  loss_mask_6: 0.6311  loss_dice_6: 3.464  loss_ce_7: 2.508  loss_mask_7: 0.6297  loss_dice_7: 3.474  loss_ce_8: 2.521  loss_mask_8: 0.63  loss_dice_8: 3.465  time: 1.7017  data_time: 0.3406  lr: 8.0702e-06  max_mem: 17674M
[01/19 05:05:18] d2.utils.events INFO:  eta: 14:43:50  iter: 8499  total_loss: 67.92  loss_ce: 2.452  loss_mask: 0.6361  loss_dice: 3.458  loss_ce_0: 3.827  loss_mask_0: 0.654  loss_dice_0: 3.743  loss_ce_1: 2.623  loss_mask_1: 0.6458  loss_dice_1: 3.599  loss_ce_2: 2.514  loss_mask_2: 0.6392  loss_dice_2: 3.529  loss_ce_3: 2.49  loss_mask_3: 0.6388  loss_dice_3: 3.485  loss_ce_4: 2.454  loss_mask_4: 0.6356  loss_dice_4: 3.476  loss_ce_5: 2.445  loss_mask_5: 0.6345  loss_dice_5: 3.473  loss_ce_6: 2.464  loss_mask_6: 0.6361  loss_dice_6: 3.459  loss_ce_7: 2.473  loss_mask_7: 0.6343  loss_dice_7: 3.46  loss_ce_8: 2.444  loss_mask_8: 0.6359  loss_dice_8: 3.459  time: 1.7017  data_time: 0.3433  lr: 8.0656e-06  max_mem: 17674M
[01/19 05:05:51] d2.utils.events INFO:  eta: 14:42:43  iter: 8519  total_loss: 68.37  loss_ce: 2.579  loss_mask: 0.6419  loss_dice: 3.431  loss_ce_0: 3.832  loss_mask_0: 0.6598  loss_dice_0: 3.721  loss_ce_1: 2.722  loss_mask_1: 0.6571  loss_dice_1: 3.583  loss_ce_2: 2.609  loss_mask_2: 0.6494  loss_dice_2: 3.507  loss_ce_3: 2.608  loss_mask_3: 0.6484  loss_dice_3: 3.464  loss_ce_4: 2.563  loss_mask_4: 0.6488  loss_dice_4: 3.459  loss_ce_5: 2.56  loss_mask_5: 0.6486  loss_dice_5: 3.458  loss_ce_6: 2.567  loss_mask_6: 0.6457  loss_dice_6: 3.447  loss_ce_7: 2.559  loss_mask_7: 0.6449  loss_dice_7: 3.444  loss_ce_8: 2.565  loss_mask_8: 0.6438  loss_dice_8: 3.443  time: 1.7016  data_time: 0.3422  lr: 8.061e-06  max_mem: 17674M
[01/19 05:06:25] d2.utils.events INFO:  eta: 14:42:27  iter: 8539  total_loss: 67.51  loss_ce: 2.43  loss_mask: 0.6352  loss_dice: 3.479  loss_ce_0: 3.812  loss_mask_0: 0.6547  loss_dice_0: 3.753  loss_ce_1: 2.615  loss_mask_1: 0.6425  loss_dice_1: 3.627  loss_ce_2: 2.482  loss_mask_2: 0.637  loss_dice_2: 3.543  loss_ce_3: 2.458  loss_mask_3: 0.6322  loss_dice_3: 3.502  loss_ce_4: 2.422  loss_mask_4: 0.6343  loss_dice_4: 3.505  loss_ce_5: 2.415  loss_mask_5: 0.6341  loss_dice_5: 3.496  loss_ce_6: 2.437  loss_mask_6: 0.6323  loss_dice_6: 3.478  loss_ce_7: 2.394  loss_mask_7: 0.6309  loss_dice_7: 3.479  loss_ce_8: 2.408  loss_mask_8: 0.6316  loss_dice_8: 3.477  time: 1.7015  data_time: 0.3271  lr: 8.0564e-06  max_mem: 17674M
[01/19 05:06:58] d2.utils.events INFO:  eta: 14:41:29  iter: 8559  total_loss: 67.27  loss_ce: 2.405  loss_mask: 0.625  loss_dice: 3.552  loss_ce_0: 3.785  loss_mask_0: 0.6477  loss_dice_0: 3.799  loss_ce_1: 2.59  loss_mask_1: 0.637  loss_dice_1: 3.692  loss_ce_2: 2.502  loss_mask_2: 0.6319  loss_dice_2: 3.618  loss_ce_3: 2.47  loss_mask_3: 0.6274  loss_dice_3: 3.573  loss_ce_4: 2.434  loss_mask_4: 0.6271  loss_dice_4: 3.563  loss_ce_5: 2.414  loss_mask_5: 0.6258  loss_dice_5: 3.561  loss_ce_6: 2.415  loss_mask_6: 0.6244  loss_dice_6: 3.55  loss_ce_7: 2.386  loss_mask_7: 0.6263  loss_dice_7: 3.552  loss_ce_8: 2.391  loss_mask_8: 0.623  loss_dice_8: 3.555  time: 1.7015  data_time: 0.3399  lr: 8.0518e-06  max_mem: 17674M
[01/19 05:07:32] d2.utils.events INFO:  eta: 14:41:17  iter: 8579  total_loss: 67.62  loss_ce: 2.443  loss_mask: 0.6259  loss_dice: 3.516  loss_ce_0: 3.792  loss_mask_0: 0.6443  loss_dice_0: 3.78  loss_ce_1: 2.541  loss_mask_1: 0.642  loss_dice_1: 3.664  loss_ce_2: 2.485  loss_mask_2: 0.6356  loss_dice_2: 3.577  loss_ce_3: 2.479  loss_mask_3: 0.6308  loss_dice_3: 3.542  loss_ce_4: 2.457  loss_mask_4: 0.627  loss_dice_4: 3.537  loss_ce_5: 2.423  loss_mask_5: 0.629  loss_dice_5: 3.524  loss_ce_6: 2.434  loss_mask_6: 0.6311  loss_dice_6: 3.516  loss_ce_7: 2.437  loss_mask_7: 0.6288  loss_dice_7: 3.518  loss_ce_8: 2.437  loss_mask_8: 0.6284  loss_dice_8: 3.516  time: 1.7015  data_time: 0.3538  lr: 8.0472e-06  max_mem: 17674M
[01/19 05:08:06] d2.utils.events INFO:  eta: 14:41:06  iter: 8599  total_loss: 67.98  loss_ce: 2.502  loss_mask: 0.6278  loss_dice: 3.435  loss_ce_0: 3.799  loss_mask_0: 0.6392  loss_dice_0: 3.726  loss_ce_1: 2.634  loss_mask_1: 0.6363  loss_dice_1: 3.587  loss_ce_2: 2.539  loss_mask_2: 0.6255  loss_dice_2: 3.513  loss_ce_3: 2.529  loss_mask_3: 0.6271  loss_dice_3: 3.464  loss_ce_4: 2.495  loss_mask_4: 0.6256  loss_dice_4: 3.457  loss_ce_5: 2.491  loss_mask_5: 0.6272  loss_dice_5: 3.465  loss_ce_6: 2.488  loss_mask_6: 0.6305  loss_dice_6: 3.443  loss_ce_7: 2.488  loss_mask_7: 0.6264  loss_dice_7: 3.445  loss_ce_8: 2.478  loss_mask_8: 0.6252  loss_dice_8: 3.444  time: 1.7014  data_time: 0.3292  lr: 8.0426e-06  max_mem: 17674M
[01/19 05:08:40] d2.utils.events INFO:  eta: 14:40:09  iter: 8619  total_loss: 67.43  loss_ce: 2.432  loss_mask: 0.6204  loss_dice: 3.479  loss_ce_0: 3.769  loss_mask_0: 0.6347  loss_dice_0: 3.752  loss_ce_1: 2.631  loss_mask_1: 0.6322  loss_dice_1: 3.616  loss_ce_2: 2.522  loss_mask_2: 0.6289  loss_dice_2: 3.547  loss_ce_3: 2.471  loss_mask_3: 0.6237  loss_dice_3: 3.499  loss_ce_4: 2.443  loss_mask_4: 0.6218  loss_dice_4: 3.496  loss_ce_5: 2.445  loss_mask_5: 0.6214  loss_dice_5: 3.49  loss_ce_6: 2.427  loss_mask_6: 0.6195  loss_dice_6: 3.475  loss_ce_7: 2.416  loss_mask_7: 0.6222  loss_dice_7: 3.476  loss_ce_8: 2.436  loss_mask_8: 0.623  loss_dice_8: 3.476  time: 1.7014  data_time: 0.3313  lr: 8.038e-06  max_mem: 17674M
[01/19 05:09:13] d2.utils.events INFO:  eta: 14:39:21  iter: 8639  total_loss: 67.69  loss_ce: 2.481  loss_mask: 0.6397  loss_dice: 3.455  loss_ce_0: 3.795  loss_mask_0: 0.6578  loss_dice_0: 3.72  loss_ce_1: 2.649  loss_mask_1: 0.6526  loss_dice_1: 3.593  loss_ce_2: 2.531  loss_mask_2: 0.6457  loss_dice_2: 3.516  loss_ce_3: 2.495  loss_mask_3: 0.6411  loss_dice_3: 3.471  loss_ce_4: 2.473  loss_mask_4: 0.6404  loss_dice_4: 3.464  loss_ce_5: 2.463  loss_mask_5: 0.6416  loss_dice_5: 3.464  loss_ce_6: 2.473  loss_mask_6: 0.639  loss_dice_6: 3.445  loss_ce_7: 2.465  loss_mask_7: 0.6396  loss_dice_7: 3.455  loss_ce_8: 2.461  loss_mask_8: 0.6407  loss_dice_8: 3.452  time: 1.7013  data_time: 0.3367  lr: 8.0334e-06  max_mem: 17674M
[01/19 05:09:47] d2.utils.events INFO:  eta: 14:38:44  iter: 8659  total_loss: 67.28  loss_ce: 2.386  loss_mask: 0.6231  loss_dice: 3.519  loss_ce_0: 3.741  loss_mask_0: 0.6367  loss_dice_0: 3.784  loss_ce_1: 2.542  loss_mask_1: 0.6387  loss_dice_1: 3.658  loss_ce_2: 2.435  loss_mask_2: 0.6311  loss_dice_2: 3.588  loss_ce_3: 2.411  loss_mask_3: 0.6281  loss_dice_3: 3.545  loss_ce_4: 2.397  loss_mask_4: 0.6279  loss_dice_4: 3.541  loss_ce_5: 2.387  loss_mask_5: 0.6261  loss_dice_5: 3.539  loss_ce_6: 2.38  loss_mask_6: 0.6236  loss_dice_6: 3.527  loss_ce_7: 2.381  loss_mask_7: 0.6243  loss_dice_7: 3.523  loss_ce_8: 2.38  loss_mask_8: 0.6223  loss_dice_8: 3.529  time: 1.7013  data_time: 0.3291  lr: 8.0287e-06  max_mem: 17674M
[01/19 05:10:21] d2.utils.events INFO:  eta: 14:38:11  iter: 8679  total_loss: 68.71  loss_ce: 2.515  loss_mask: 0.6305  loss_dice: 3.481  loss_ce_0: 3.819  loss_mask_0: 0.6556  loss_dice_0: 3.748  loss_ce_1: 2.641  loss_mask_1: 0.6427  loss_dice_1: 3.62  loss_ce_2: 2.539  loss_mask_2: 0.6367  loss_dice_2: 3.553  loss_ce_3: 2.517  loss_mask_3: 0.6313  loss_dice_3: 3.505  loss_ce_4: 2.523  loss_mask_4: 0.6305  loss_dice_4: 3.502  loss_ce_5: 2.491  loss_mask_5: 0.6325  loss_dice_5: 3.501  loss_ce_6: 2.514  loss_mask_6: 0.632  loss_dice_6: 3.487  loss_ce_7: 2.506  loss_mask_7: 0.6336  loss_dice_7: 3.487  loss_ce_8: 2.495  loss_mask_8: 0.6317  loss_dice_8: 3.485  time: 1.7012  data_time: 0.3434  lr: 8.0241e-06  max_mem: 17674M
[01/19 05:10:55] d2.utils.events INFO:  eta: 14:37:37  iter: 8699  total_loss: 67.47  loss_ce: 2.445  loss_mask: 0.6253  loss_dice: 3.449  loss_ce_0: 3.754  loss_mask_0: 0.6508  loss_dice_0: 3.737  loss_ce_1: 2.625  loss_mask_1: 0.6397  loss_dice_1: 3.602  loss_ce_2: 2.522  loss_mask_2: 0.6272  loss_dice_2: 3.526  loss_ce_3: 2.466  loss_mask_3: 0.6269  loss_dice_3: 3.478  loss_ce_4: 2.455  loss_mask_4: 0.631  loss_dice_4: 3.472  loss_ce_5: 2.458  loss_mask_5: 0.6309  loss_dice_5: 3.467  loss_ce_6: 2.46  loss_mask_6: 0.6291  loss_dice_6: 3.451  loss_ce_7: 2.453  loss_mask_7: 0.6278  loss_dice_7: 3.453  loss_ce_8: 2.439  loss_mask_8: 0.6257  loss_dice_8: 3.446  time: 1.7012  data_time: 0.3327  lr: 8.0195e-06  max_mem: 17674M
[01/19 05:11:28] d2.utils.events INFO:  eta: 14:36:48  iter: 8719  total_loss: 67.27  loss_ce: 2.424  loss_mask: 0.6229  loss_dice: 3.429  loss_ce_0: 3.909  loss_mask_0: 0.6392  loss_dice_0: 3.721  loss_ce_1: 2.565  loss_mask_1: 0.6394  loss_dice_1: 3.588  loss_ce_2: 2.479  loss_mask_2: 0.6276  loss_dice_2: 3.521  loss_ce_3: 2.452  loss_mask_3: 0.6213  loss_dice_3: 3.47  loss_ce_4: 2.376  loss_mask_4: 0.6222  loss_dice_4: 3.464  loss_ce_5: 2.38  loss_mask_5: 0.6251  loss_dice_5: 3.457  loss_ce_6: 2.425  loss_mask_6: 0.6227  loss_dice_6: 3.444  loss_ce_7: 2.415  loss_mask_7: 0.6238  loss_dice_7: 3.441  loss_ce_8: 2.417  loss_mask_8: 0.6221  loss_dice_8: 3.453  time: 1.7011  data_time: 0.3222  lr: 8.0149e-06  max_mem: 17674M
[01/19 05:12:02] d2.utils.events INFO:  eta: 14:35:36  iter: 8739  total_loss: 67.24  loss_ce: 2.404  loss_mask: 0.6236  loss_dice: 3.433  loss_ce_0: 3.815  loss_mask_0: 0.6422  loss_dice_0: 3.742  loss_ce_1: 2.598  loss_mask_1: 0.6389  loss_dice_1: 3.581  loss_ce_2: 2.471  loss_mask_2: 0.6332  loss_dice_2: 3.507  loss_ce_3: 2.442  loss_mask_3: 0.6268  loss_dice_3: 3.454  loss_ce_4: 2.435  loss_mask_4: 0.627  loss_dice_4: 3.455  loss_ce_5: 2.419  loss_mask_5: 0.6238  loss_dice_5: 3.454  loss_ce_6: 2.412  loss_mask_6: 0.6252  loss_dice_6: 3.44  loss_ce_7: 2.396  loss_mask_7: 0.6249  loss_dice_7: 3.438  loss_ce_8: 2.404  loss_mask_8: 0.6264  loss_dice_8: 3.433  time: 1.7010  data_time: 0.3310  lr: 8.0103e-06  max_mem: 17674M
[01/19 05:12:35] d2.utils.events INFO:  eta: 14:35:03  iter: 8759  total_loss: 67.2  loss_ce: 2.4  loss_mask: 0.6448  loss_dice: 3.496  loss_ce_0: 3.744  loss_mask_0: 0.6684  loss_dice_0: 3.76  loss_ce_1: 2.556  loss_mask_1: 0.6584  loss_dice_1: 3.634  loss_ce_2: 2.452  loss_mask_2: 0.6492  loss_dice_2: 3.558  loss_ce_3: 2.424  loss_mask_3: 0.6419  loss_dice_3: 3.52  loss_ce_4: 2.395  loss_mask_4: 0.6434  loss_dice_4: 3.514  loss_ce_5: 2.377  loss_mask_5: 0.646  loss_dice_5: 3.51  loss_ce_6: 2.394  loss_mask_6: 0.6511  loss_dice_6: 3.492  loss_ce_7: 2.399  loss_mask_7: 0.6497  loss_dice_7: 3.496  loss_ce_8: 2.384  loss_mask_8: 0.6486  loss_dice_8: 3.495  time: 1.7010  data_time: 0.3483  lr: 8.0057e-06  max_mem: 17674M
[01/19 05:13:09] d2.utils.events INFO:  eta: 14:34:11  iter: 8779  total_loss: 68.42  loss_ce: 2.466  loss_mask: 0.6279  loss_dice: 3.474  loss_ce_0: 3.858  loss_mask_0: 0.6452  loss_dice_0: 3.718  loss_ce_1: 2.639  loss_mask_1: 0.6408  loss_dice_1: 3.616  loss_ce_2: 2.502  loss_mask_2: 0.6349  loss_dice_2: 3.54  loss_ce_3: 2.496  loss_mask_3: 0.6299  loss_dice_3: 3.492  loss_ce_4: 2.481  loss_mask_4: 0.6285  loss_dice_4: 3.489  loss_ce_5: 2.459  loss_mask_5: 0.6277  loss_dice_5: 3.485  loss_ce_6: 2.465  loss_mask_6: 0.628  loss_dice_6: 3.477  loss_ce_7: 2.458  loss_mask_7: 0.6282  loss_dice_7: 3.472  loss_ce_8: 2.455  loss_mask_8: 0.629  loss_dice_8: 3.475  time: 1.7009  data_time: 0.3364  lr: 8.0011e-06  max_mem: 17674M
[01/19 05:13:43] d2.utils.events INFO:  eta: 14:33:38  iter: 8799  total_loss: 68.8  loss_ce: 2.537  loss_mask: 0.6534  loss_dice: 3.444  loss_ce_0: 3.86  loss_mask_0: 0.6558  loss_dice_0: 3.721  loss_ce_1: 2.653  loss_mask_1: 0.6604  loss_dice_1: 3.606  loss_ce_2: 2.569  loss_mask_2: 0.6606  loss_dice_2: 3.531  loss_ce_3: 2.561  loss_mask_3: 0.6558  loss_dice_3: 3.476  loss_ce_4: 2.522  loss_mask_4: 0.6541  loss_dice_4: 3.47  loss_ce_5: 2.524  loss_mask_5: 0.6536  loss_dice_5: 3.466  loss_ce_6: 2.535  loss_mask_6: 0.6507  loss_dice_6: 3.451  loss_ce_7: 2.511  loss_mask_7: 0.6528  loss_dice_7: 3.455  loss_ce_8: 2.526  loss_mask_8: 0.6512  loss_dice_8: 3.456  time: 1.7009  data_time: 0.3385  lr: 7.9965e-06  max_mem: 17674M
[01/19 05:14:16] d2.utils.events INFO:  eta: 14:33:22  iter: 8819  total_loss: 67.39  loss_ce: 2.375  loss_mask: 0.6236  loss_dice: 3.501  loss_ce_0: 3.789  loss_mask_0: 0.6388  loss_dice_0: 3.771  loss_ce_1: 2.536  loss_mask_1: 0.6354  loss_dice_1: 3.655  loss_ce_2: 2.421  loss_mask_2: 0.6291  loss_dice_2: 3.58  loss_ce_3: 2.389  loss_mask_3: 0.6248  loss_dice_3: 3.527  loss_ce_4: 2.385  loss_mask_4: 0.6221  loss_dice_4: 3.523  loss_ce_5: 2.371  loss_mask_5: 0.6222  loss_dice_5: 3.523  loss_ce_6: 2.379  loss_mask_6: 0.6246  loss_dice_6: 3.512  loss_ce_7: 2.368  loss_mask_7: 0.6232  loss_dice_7: 3.509  loss_ce_8: 2.382  loss_mask_8: 0.6247  loss_dice_8: 3.506  time: 1.7009  data_time: 0.3386  lr: 7.9918e-06  max_mem: 17674M
[01/19 05:14:50] d2.utils.events INFO:  eta: 14:33:26  iter: 8839  total_loss: 68.31  loss_ce: 2.502  loss_mask: 0.6367  loss_dice: 3.458  loss_ce_0: 3.824  loss_mask_0: 0.6477  loss_dice_0: 3.727  loss_ce_1: 2.723  loss_mask_1: 0.65  loss_dice_1: 3.591  loss_ce_2: 2.623  loss_mask_2: 0.646  loss_dice_2: 3.516  loss_ce_3: 2.562  loss_mask_3: 0.6414  loss_dice_3: 3.477  loss_ce_4: 2.533  loss_mask_4: 0.6428  loss_dice_4: 3.475  loss_ce_5: 2.539  loss_mask_5: 0.6417  loss_dice_5: 3.474  loss_ce_6: 2.55  loss_mask_6: 0.6382  loss_dice_6: 3.461  loss_ce_7: 2.524  loss_mask_7: 0.6379  loss_dice_7: 3.46  loss_ce_8: 2.499  loss_mask_8: 0.6365  loss_dice_8: 3.463  time: 1.7009  data_time: 0.3536  lr: 7.9872e-06  max_mem: 17674M
[01/19 05:15:24] d2.utils.events INFO:  eta: 14:32:49  iter: 8859  total_loss: 67.66  loss_ce: 2.463  loss_mask: 0.6362  loss_dice: 3.444  loss_ce_0: 3.833  loss_mask_0: 0.6631  loss_dice_0: 3.712  loss_ce_1: 2.667  loss_mask_1: 0.6529  loss_dice_1: 3.589  loss_ce_2: 2.525  loss_mask_2: 0.6417  loss_dice_2: 3.52  loss_ce_3: 2.506  loss_mask_3: 0.6366  loss_dice_3: 3.471  loss_ce_4: 2.459  loss_mask_4: 0.6358  loss_dice_4: 3.467  loss_ce_5: 2.459  loss_mask_5: 0.6364  loss_dice_5: 3.464  loss_ce_6: 2.437  loss_mask_6: 0.6388  loss_dice_6: 3.451  loss_ce_7: 2.457  loss_mask_7: 0.6387  loss_dice_7: 3.447  loss_ce_8: 2.449  loss_mask_8: 0.6354  loss_dice_8: 3.448  time: 1.7008  data_time: 0.3444  lr: 7.9826e-06  max_mem: 17674M
[01/19 05:15:58] d2.utils.events INFO:  eta: 14:32:00  iter: 8879  total_loss: 67.07  loss_ce: 2.378  loss_mask: 0.6379  loss_dice: 3.498  loss_ce_0: 3.843  loss_mask_0: 0.6453  loss_dice_0: 3.752  loss_ce_1: 2.552  loss_mask_1: 0.6517  loss_dice_1: 3.623  loss_ce_2: 2.446  loss_mask_2: 0.6477  loss_dice_2: 3.559  loss_ce_3: 2.414  loss_mask_3: 0.6417  loss_dice_3: 3.514  loss_ce_4: 2.405  loss_mask_4: 0.6398  loss_dice_4: 3.504  loss_ce_5: 2.374  loss_mask_5: 0.6397  loss_dice_5: 3.502  loss_ce_6: 2.383  loss_mask_6: 0.6386  loss_dice_6: 3.497  loss_ce_7: 2.374  loss_mask_7: 0.6378  loss_dice_7: 3.493  loss_ce_8: 2.375  loss_mask_8: 0.6405  loss_dice_8: 3.493  time: 1.7008  data_time: 0.3369  lr: 7.978e-06  max_mem: 17674M
[01/19 05:16:32] d2.utils.events INFO:  eta: 14:31:10  iter: 8899  total_loss: 68.07  loss_ce: 2.489  loss_mask: 0.6289  loss_dice: 3.448  loss_ce_0: 3.825  loss_mask_0: 0.6523  loss_dice_0: 3.728  loss_ce_1: 2.649  loss_mask_1: 0.6384  loss_dice_1: 3.605  loss_ce_2: 2.56  loss_mask_2: 0.6326  loss_dice_2: 3.515  loss_ce_3: 2.514  loss_mask_3: 0.634  loss_dice_3: 3.468  loss_ce_4: 2.494  loss_mask_4: 0.6308  loss_dice_4: 3.464  loss_ce_5: 2.496  loss_mask_5: 0.6309  loss_dice_5: 3.458  loss_ce_6: 2.502  loss_mask_6: 0.6325  loss_dice_6: 3.448  loss_ce_7: 2.484  loss_mask_7: 0.6319  loss_dice_7: 3.456  loss_ce_8: 2.511  loss_mask_8: 0.6301  loss_dice_8: 3.451  time: 1.7007  data_time: 0.3414  lr: 7.9734e-06  max_mem: 17674M
[01/19 05:17:05] d2.utils.events INFO:  eta: 14:30:16  iter: 8919  total_loss: 68.07  loss_ce: 2.524  loss_mask: 0.6446  loss_dice: 3.448  loss_ce_0: 3.861  loss_mask_0: 0.6489  loss_dice_0: 3.73  loss_ce_1: 2.662  loss_mask_1: 0.6495  loss_dice_1: 3.593  loss_ce_2: 2.542  loss_mask_2: 0.6456  loss_dice_2: 3.519  loss_ce_3: 2.549  loss_mask_3: 0.6475  loss_dice_3: 3.474  loss_ce_4: 2.546  loss_mask_4: 0.6467  loss_dice_4: 3.468  loss_ce_5: 2.502  loss_mask_5: 0.645  loss_dice_5: 3.462  loss_ce_6: 2.53  loss_mask_6: 0.6459  loss_dice_6: 3.45  loss_ce_7: 2.507  loss_mask_7: 0.6433  loss_dice_7: 3.453  loss_ce_8: 2.511  loss_mask_8: 0.6439  loss_dice_8: 3.453  time: 1.7007  data_time: 0.3467  lr: 7.9688e-06  max_mem: 17674M
[01/19 05:17:39] d2.utils.events INFO:  eta: 14:30:00  iter: 8939  total_loss: 67.86  loss_ce: 2.492  loss_mask: 0.632  loss_dice: 3.487  loss_ce_0: 3.805  loss_mask_0: 0.6486  loss_dice_0: 3.735  loss_ce_1: 2.617  loss_mask_1: 0.6404  loss_dice_1: 3.622  loss_ce_2: 2.52  loss_mask_2: 0.6333  loss_dice_2: 3.553  loss_ce_3: 2.536  loss_mask_3: 0.6314  loss_dice_3: 3.503  loss_ce_4: 2.509  loss_mask_4: 0.6321  loss_dice_4: 3.499  loss_ce_5: 2.492  loss_mask_5: 0.6294  loss_dice_5: 3.498  loss_ce_6: 2.498  loss_mask_6: 0.6345  loss_dice_6: 3.484  loss_ce_7: 2.481  loss_mask_7: 0.6339  loss_dice_7: 3.487  loss_ce_8: 2.483  loss_mask_8: 0.6334  loss_dice_8: 3.488  time: 1.7007  data_time: 0.3404  lr: 7.9642e-06  max_mem: 17674M
[01/19 05:18:13] d2.utils.events INFO:  eta: 14:29:26  iter: 8959  total_loss: 67.33  loss_ce: 2.445  loss_mask: 0.6378  loss_dice: 3.443  loss_ce_0: 3.789  loss_mask_0: 0.6548  loss_dice_0: 3.734  loss_ce_1: 2.599  loss_mask_1: 0.6559  loss_dice_1: 3.588  loss_ce_2: 2.506  loss_mask_2: 0.6491  loss_dice_2: 3.517  loss_ce_3: 2.478  loss_mask_3: 0.6417  loss_dice_3: 3.472  loss_ce_4: 2.454  loss_mask_4: 0.6405  loss_dice_4: 3.471  loss_ce_5: 2.444  loss_mask_5: 0.643  loss_dice_5: 3.463  loss_ce_6: 2.458  loss_mask_6: 0.6415  loss_dice_6: 3.453  loss_ce_7: 2.437  loss_mask_7: 0.6387  loss_dice_7: 3.452  loss_ce_8: 2.446  loss_mask_8: 0.6357  loss_dice_8: 3.456  time: 1.7007  data_time: 0.3398  lr: 7.9595e-06  max_mem: 17674M
[01/19 05:18:47] d2.utils.events INFO:  eta: 14:27:57  iter: 8979  total_loss: 67.95  loss_ce: 2.501  loss_mask: 0.6459  loss_dice: 3.452  loss_ce_0: 3.796  loss_mask_0: 0.6605  loss_dice_0: 3.724  loss_ce_1: 2.704  loss_mask_1: 0.6504  loss_dice_1: 3.594  loss_ce_2: 2.574  loss_mask_2: 0.6456  loss_dice_2: 3.524  loss_ce_3: 2.552  loss_mask_3: 0.6427  loss_dice_3: 3.475  loss_ce_4: 2.511  loss_mask_4: 0.6436  loss_dice_4: 3.46  loss_ce_5: 2.517  loss_mask_5: 0.645  loss_dice_5: 3.47  loss_ce_6: 2.5  loss_mask_6: 0.6434  loss_dice_6: 3.454  loss_ce_7: 2.491  loss_mask_7: 0.644  loss_dice_7: 3.461  loss_ce_8: 2.506  loss_mask_8: 0.645  loss_dice_8: 3.447  time: 1.7006  data_time: 0.3390  lr: 7.9549e-06  max_mem: 17674M
[01/19 05:19:20] d2.utils.events INFO:  eta: 14:26:59  iter: 8999  total_loss: 67.54  loss_ce: 2.456  loss_mask: 0.6316  loss_dice: 3.463  loss_ce_0: 3.758  loss_mask_0: 0.6528  loss_dice_0: 3.739  loss_ce_1: 2.626  loss_mask_1: 0.6458  loss_dice_1: 3.612  loss_ce_2: 2.502  loss_mask_2: 0.6362  loss_dice_2: 3.54  loss_ce_3: 2.487  loss_mask_3: 0.6352  loss_dice_3: 3.486  loss_ce_4: 2.458  loss_mask_4: 0.6358  loss_dice_4: 3.482  loss_ce_5: 2.454  loss_mask_5: 0.6302  loss_dice_5: 3.485  loss_ce_6: 2.461  loss_mask_6: 0.6328  loss_dice_6: 3.471  loss_ce_7: 2.438  loss_mask_7: 0.6321  loss_dice_7: 3.471  loss_ce_8: 2.471  loss_mask_8: 0.6336  loss_dice_8: 3.47  time: 1.7005  data_time: 0.3166  lr: 7.9503e-06  max_mem: 17674M
[01/19 05:19:54] d2.utils.events INFO:  eta: 14:26:32  iter: 9019  total_loss: 67.61  loss_ce: 2.396  loss_mask: 0.6238  loss_dice: 3.479  loss_ce_0: 3.839  loss_mask_0: 0.647  loss_dice_0: 3.737  loss_ce_1: 2.628  loss_mask_1: 0.6416  loss_dice_1: 3.615  loss_ce_2: 2.465  loss_mask_2: 0.6321  loss_dice_2: 3.551  loss_ce_3: 2.448  loss_mask_3: 0.6293  loss_dice_3: 3.505  loss_ce_4: 2.423  loss_mask_4: 0.6264  loss_dice_4: 3.497  loss_ce_5: 2.394  loss_mask_5: 0.6295  loss_dice_5: 3.489  loss_ce_6: 2.398  loss_mask_6: 0.6278  loss_dice_6: 3.484  loss_ce_7: 2.37  loss_mask_7: 0.6249  loss_dice_7: 3.481  loss_ce_8: 2.391  loss_mask_8: 0.6252  loss_dice_8: 3.482  time: 1.7005  data_time: 0.3281  lr: 7.9457e-06  max_mem: 17674M
[01/19 05:20:27] d2.utils.events INFO:  eta: 14:25:36  iter: 9039  total_loss: 67.26  loss_ce: 2.412  loss_mask: 0.6354  loss_dice: 3.437  loss_ce_0: 3.823  loss_mask_0: 0.658  loss_dice_0: 3.692  loss_ce_1: 2.528  loss_mask_1: 0.6531  loss_dice_1: 3.588  loss_ce_2: 2.436  loss_mask_2: 0.6405  loss_dice_2: 3.51  loss_ce_3: 2.433  loss_mask_3: 0.6412  loss_dice_3: 3.468  loss_ce_4: 2.419  loss_mask_4: 0.6414  loss_dice_4: 3.454  loss_ce_5: 2.401  loss_mask_5: 0.6372  loss_dice_5: 3.458  loss_ce_6: 2.378  loss_mask_6: 0.6371  loss_dice_6: 3.441  loss_ce_7: 2.392  loss_mask_7: 0.6394  loss_dice_7: 3.439  loss_ce_8: 2.386  loss_mask_8: 0.6413  loss_dice_8: 3.431  time: 1.7004  data_time: 0.3399  lr: 7.9411e-06  max_mem: 17674M
[01/19 05:21:01] d2.utils.events INFO:  eta: 14:25:04  iter: 9059  total_loss: 67.6  loss_ce: 2.45  loss_mask: 0.6392  loss_dice: 3.466  loss_ce_0: 3.803  loss_mask_0: 0.6665  loss_dice_0: 3.746  loss_ce_1: 2.633  loss_mask_1: 0.6491  loss_dice_1: 3.617  loss_ce_2: 2.533  loss_mask_2: 0.6435  loss_dice_2: 3.54  loss_ce_3: 2.521  loss_mask_3: 0.6395  loss_dice_3: 3.489  loss_ce_4: 2.481  loss_mask_4: 0.638  loss_dice_4: 3.492  loss_ce_5: 2.473  loss_mask_5: 0.6364  loss_dice_5: 3.484  loss_ce_6: 2.471  loss_mask_6: 0.6349  loss_dice_6: 3.474  loss_ce_7: 2.462  loss_mask_7: 0.6368  loss_dice_7: 3.473  loss_ce_8: 2.47  loss_mask_8: 0.638  loss_dice_8: 3.468  time: 1.7004  data_time: 0.3516  lr: 7.9365e-06  max_mem: 17674M
[01/19 05:21:35] d2.utils.events INFO:  eta: 14:24:19  iter: 9079  total_loss: 67.59  loss_ce: 2.413  loss_mask: 0.6332  loss_dice: 3.513  loss_ce_0: 3.807  loss_mask_0: 0.6559  loss_dice_0: 3.752  loss_ce_1: 2.582  loss_mask_1: 0.6438  loss_dice_1: 3.66  loss_ce_2: 2.495  loss_mask_2: 0.641  loss_dice_2: 3.582  loss_ce_3: 2.424  loss_mask_3: 0.6388  loss_dice_3: 3.539  loss_ce_4: 2.429  loss_mask_4: 0.6388  loss_dice_4: 3.528  loss_ce_5: 2.409  loss_mask_5: 0.6392  loss_dice_5: 3.526  loss_ce_6: 2.4  loss_mask_6: 0.6335  loss_dice_6: 3.517  loss_ce_7: 2.403  loss_mask_7: 0.6343  loss_dice_7: 3.519  loss_ce_8: 2.398  loss_mask_8: 0.6349  loss_dice_8: 3.519  time: 1.7003  data_time: 0.3418  lr: 7.9318e-06  max_mem: 17674M
[01/19 05:22:08] d2.utils.events INFO:  eta: 14:23:22  iter: 9099  total_loss: 67.43  loss_ce: 2.467  loss_mask: 0.6335  loss_dice: 3.425  loss_ce_0: 3.805  loss_mask_0: 0.6564  loss_dice_0: 3.688  loss_ce_1: 2.608  loss_mask_1: 0.65  loss_dice_1: 3.567  loss_ce_2: 2.482  loss_mask_2: 0.6456  loss_dice_2: 3.501  loss_ce_3: 2.481  loss_mask_3: 0.6389  loss_dice_3: 3.445  loss_ce_4: 2.468  loss_mask_4: 0.6359  loss_dice_4: 3.45  loss_ce_5: 2.439  loss_mask_5: 0.6367  loss_dice_5: 3.44  loss_ce_6: 2.454  loss_mask_6: 0.6375  loss_dice_6: 3.428  loss_ce_7: 2.447  loss_mask_7: 0.6329  loss_dice_7: 3.429  loss_ce_8: 2.418  loss_mask_8: 0.634  loss_dice_8: 3.426  time: 1.7003  data_time: 0.3282  lr: 7.9272e-06  max_mem: 17674M
[01/19 05:22:42] d2.utils.events INFO:  eta: 14:22:55  iter: 9119  total_loss: 66.92  loss_ce: 2.325  loss_mask: 0.6296  loss_dice: 3.509  loss_ce_0: 3.754  loss_mask_0: 0.6585  loss_dice_0: 3.772  loss_ce_1: 2.5  loss_mask_1: 0.6528  loss_dice_1: 3.634  loss_ce_2: 2.419  loss_mask_2: 0.6434  loss_dice_2: 3.569  loss_ce_3: 2.355  loss_mask_3: 0.6385  loss_dice_3: 3.526  loss_ce_4: 2.348  loss_mask_4: 0.6379  loss_dice_4: 3.513  loss_ce_5: 2.343  loss_mask_5: 0.6381  loss_dice_5: 3.511  loss_ce_6: 2.33  loss_mask_6: 0.6344  loss_dice_6: 3.507  loss_ce_7: 2.318  loss_mask_7: 0.6334  loss_dice_7: 3.517  loss_ce_8: 2.316  loss_mask_8: 0.6333  loss_dice_8: 3.511  time: 1.7002  data_time: 0.3574  lr: 7.9226e-06  max_mem: 17674M
[01/19 05:23:15] d2.utils.events INFO:  eta: 14:22:20  iter: 9139  total_loss: 67.61  loss_ce: 2.424  loss_mask: 0.6346  loss_dice: 3.476  loss_ce_0: 3.797  loss_mask_0: 0.647  loss_dice_0: 3.732  loss_ce_1: 2.637  loss_mask_1: 0.6502  loss_dice_1: 3.621  loss_ce_2: 2.523  loss_mask_2: 0.638  loss_dice_2: 3.55  loss_ce_3: 2.496  loss_mask_3: 0.6346  loss_dice_3: 3.501  loss_ce_4: 2.478  loss_mask_4: 0.6364  loss_dice_4: 3.502  loss_ce_5: 2.448  loss_mask_5: 0.6342  loss_dice_5: 3.489  loss_ce_6: 2.457  loss_mask_6: 0.6356  loss_dice_6: 3.48  loss_ce_7: 2.455  loss_mask_7: 0.637  loss_dice_7: 3.474  loss_ce_8: 2.436  loss_mask_8: 0.6352  loss_dice_8: 3.481  time: 1.7002  data_time: 0.3256  lr: 7.918e-06  max_mem: 17674M
[01/19 05:23:49] d2.utils.events INFO:  eta: 14:22:00  iter: 9159  total_loss: 68.02  loss_ce: 2.507  loss_mask: 0.6525  loss_dice: 3.445  loss_ce_0: 3.777  loss_mask_0: 0.6619  loss_dice_0: 3.721  loss_ce_1: 2.6  loss_mask_1: 0.6639  loss_dice_1: 3.593  loss_ce_2: 2.523  loss_mask_2: 0.6567  loss_dice_2: 3.516  loss_ce_3: 2.538  loss_mask_3: 0.6528  loss_dice_3: 3.467  loss_ce_4: 2.515  loss_mask_4: 0.6509  loss_dice_4: 3.464  loss_ce_5: 2.522  loss_mask_5: 0.6526  loss_dice_5: 3.465  loss_ce_6: 2.533  loss_mask_6: 0.6532  loss_dice_6: 3.454  loss_ce_7: 2.503  loss_mask_7: 0.6518  loss_dice_7: 3.454  loss_ce_8: 2.495  loss_mask_8: 0.6534  loss_dice_8: 3.451  time: 1.7001  data_time: 0.3411  lr: 7.9134e-06  max_mem: 17674M
[01/19 05:24:23] d2.utils.events INFO:  eta: 14:21:13  iter: 9179  total_loss: 67.14  loss_ce: 2.423  loss_mask: 0.6332  loss_dice: 3.423  loss_ce_0: 3.766  loss_mask_0: 0.6523  loss_dice_0: 3.705  loss_ce_1: 2.594  loss_mask_1: 0.6451  loss_dice_1: 3.581  loss_ce_2: 2.483  loss_mask_2: 0.641  loss_dice_2: 3.505  loss_ce_3: 2.49  loss_mask_3: 0.6352  loss_dice_3: 3.454  loss_ce_4: 2.458  loss_mask_4: 0.6332  loss_dice_4: 3.445  loss_ce_5: 2.439  loss_mask_5: 0.6364  loss_dice_5: 3.448  loss_ce_6: 2.438  loss_mask_6: 0.6365  loss_dice_6: 3.432  loss_ce_7: 2.426  loss_mask_7: 0.6357  loss_dice_7: 3.426  loss_ce_8: 2.426  loss_mask_8: 0.636  loss_dice_8: 3.432  time: 1.7001  data_time: 0.3584  lr: 7.9088e-06  max_mem: 17674M
[01/19 05:24:56] d2.utils.events INFO:  eta: 14:20:29  iter: 9199  total_loss: 66.53  loss_ce: 2.343  loss_mask: 0.6346  loss_dice: 3.448  loss_ce_0: 3.706  loss_mask_0: 0.6569  loss_dice_0: 3.717  loss_ce_1: 2.547  loss_mask_1: 0.6501  loss_dice_1: 3.586  loss_ce_2: 2.423  loss_mask_2: 0.6411  loss_dice_2: 3.508  loss_ce_3: 2.392  loss_mask_3: 0.635  loss_dice_3: 3.462  loss_ce_4: 2.352  loss_mask_4: 0.6353  loss_dice_4: 3.465  loss_ce_5: 2.357  loss_mask_5: 0.636  loss_dice_5: 3.46  loss_ce_6: 2.354  loss_mask_6: 0.6374  loss_dice_6: 3.451  loss_ce_7: 2.335  loss_mask_7: 0.6385  loss_dice_7: 3.45  loss_ce_8: 2.33  loss_mask_8: 0.6358  loss_dice_8: 3.451  time: 1.7000  data_time: 0.3259  lr: 7.9041e-06  max_mem: 17674M
[01/19 05:25:29] d2.utils.events INFO:  eta: 14:19:55  iter: 9219  total_loss: 67.14  loss_ce: 2.465  loss_mask: 0.6339  loss_dice: 3.459  loss_ce_0: 3.749  loss_mask_0: 0.6457  loss_dice_0: 3.725  loss_ce_1: 2.649  loss_mask_1: 0.6451  loss_dice_1: 3.594  loss_ce_2: 2.495  loss_mask_2: 0.6385  loss_dice_2: 3.523  loss_ce_3: 2.482  loss_mask_3: 0.636  loss_dice_3: 3.478  loss_ce_4: 2.446  loss_mask_4: 0.6347  loss_dice_4: 3.477  loss_ce_5: 2.455  loss_mask_5: 0.6366  loss_dice_5: 3.478  loss_ce_6: 2.449  loss_mask_6: 0.637  loss_dice_6: 3.46  loss_ce_7: 2.442  loss_mask_7: 0.637  loss_dice_7: 3.463  loss_ce_8: 2.448  loss_mask_8: 0.6363  loss_dice_8: 3.454  time: 1.6999  data_time: 0.3284  lr: 7.8995e-06  max_mem: 17674M
[01/19 05:26:03] d2.utils.events INFO:  eta: 14:19:49  iter: 9239  total_loss: 67.35  loss_ce: 2.472  loss_mask: 0.6259  loss_dice: 3.447  loss_ce_0: 3.735  loss_mask_0: 0.6418  loss_dice_0: 3.741  loss_ce_1: 2.611  loss_mask_1: 0.6438  loss_dice_1: 3.6  loss_ce_2: 2.499  loss_mask_2: 0.6367  loss_dice_2: 3.525  loss_ce_3: 2.483  loss_mask_3: 0.6323  loss_dice_3: 3.465  loss_ce_4: 2.437  loss_mask_4: 0.6309  loss_dice_4: 3.46  loss_ce_5: 2.451  loss_mask_5: 0.6301  loss_dice_5: 3.462  loss_ce_6: 2.462  loss_mask_6: 0.631  loss_dice_6: 3.451  loss_ce_7: 2.436  loss_mask_7: 0.6275  loss_dice_7: 3.447  loss_ce_8: 2.463  loss_mask_8: 0.6292  loss_dice_8: 3.445  time: 1.6999  data_time: 0.3266  lr: 7.8949e-06  max_mem: 17674M
[01/19 05:26:37] d2.utils.events INFO:  eta: 14:18:59  iter: 9259  total_loss: 67.19  loss_ce: 2.361  loss_mask: 0.6143  loss_dice: 3.478  loss_ce_0: 3.766  loss_mask_0: 0.6428  loss_dice_0: 3.732  loss_ce_1: 2.544  loss_mask_1: 0.6333  loss_dice_1: 3.624  loss_ce_2: 2.427  loss_mask_2: 0.6238  loss_dice_2: 3.552  loss_ce_3: 2.401  loss_mask_3: 0.6184  loss_dice_3: 3.504  loss_ce_4: 2.354  loss_mask_4: 0.6168  loss_dice_4: 3.501  loss_ce_5: 2.354  loss_mask_5: 0.6157  loss_dice_5: 3.497  loss_ce_6: 2.357  loss_mask_6: 0.6137  loss_dice_6: 3.481  loss_ce_7: 2.349  loss_mask_7: 0.6188  loss_dice_7: 3.483  loss_ce_8: 2.341  loss_mask_8: 0.616  loss_dice_8: 3.488  time: 1.6999  data_time: 0.3485  lr: 7.8903e-06  max_mem: 17674M
[01/19 05:27:10] d2.utils.events INFO:  eta: 14:18:25  iter: 9279  total_loss: 67.01  loss_ce: 2.363  loss_mask: 0.6305  loss_dice: 3.488  loss_ce_0: 3.747  loss_mask_0: 0.648  loss_dice_0: 3.742  loss_ce_1: 2.57  loss_mask_1: 0.6446  loss_dice_1: 3.624  loss_ce_2: 2.44  loss_mask_2: 0.6391  loss_dice_2: 3.551  loss_ce_3: 2.422  loss_mask_3: 0.6342  loss_dice_3: 3.505  loss_ce_4: 2.381  loss_mask_4: 0.6352  loss_dice_4: 3.504  loss_ce_5: 2.358  loss_mask_5: 0.6322  loss_dice_5: 3.493  loss_ce_6: 2.367  loss_mask_6: 0.6284  loss_dice_6: 3.492  loss_ce_7: 2.335  loss_mask_7: 0.6303  loss_dice_7: 3.492  loss_ce_8: 2.343  loss_mask_8: 0.6295  loss_dice_8: 3.492  time: 1.6998  data_time: 0.3358  lr: 7.8857e-06  max_mem: 17674M
[01/19 05:27:44] d2.utils.events INFO:  eta: 14:17:48  iter: 9299  total_loss: 66.56  loss_ce: 2.302  loss_mask: 0.6257  loss_dice: 3.474  loss_ce_0: 3.783  loss_mask_0: 0.6436  loss_dice_0: 3.752  loss_ce_1: 2.503  loss_mask_1: 0.641  loss_dice_1: 3.632  loss_ce_2: 2.36  loss_mask_2: 0.6297  loss_dice_2: 3.561  loss_ce_3: 2.33  loss_mask_3: 0.6291  loss_dice_3: 3.504  loss_ce_4: 2.319  loss_mask_4: 0.6281  loss_dice_4: 3.499  loss_ce_5: 2.302  loss_mask_5: 0.6288  loss_dice_5: 3.491  loss_ce_6: 2.297  loss_mask_6: 0.6257  loss_dice_6: 3.483  loss_ce_7: 2.29  loss_mask_7: 0.6248  loss_dice_7: 3.485  loss_ce_8: 2.296  loss_mask_8: 0.625  loss_dice_8: 3.481  time: 1.6998  data_time: 0.3310  lr: 7.881e-06  max_mem: 17674M
[01/19 05:28:18] d2.utils.events INFO:  eta: 14:17:02  iter: 9319  total_loss: 67.59  loss_ce: 2.42  loss_mask: 0.626  loss_dice: 3.444  loss_ce_0: 3.772  loss_mask_0: 0.6405  loss_dice_0: 3.736  loss_ce_1: 2.597  loss_mask_1: 0.6346  loss_dice_1: 3.612  loss_ce_2: 2.493  loss_mask_2: 0.6241  loss_dice_2: 3.528  loss_ce_3: 2.49  loss_mask_3: 0.6241  loss_dice_3: 3.466  loss_ce_4: 2.476  loss_mask_4: 0.6256  loss_dice_4: 3.461  loss_ce_5: 2.442  loss_mask_5: 0.6291  loss_dice_5: 3.463  loss_ce_6: 2.431  loss_mask_6: 0.6272  loss_dice_6: 3.442  loss_ce_7: 2.415  loss_mask_7: 0.6258  loss_dice_7: 3.45  loss_ce_8: 2.438  loss_mask_8: 0.6267  loss_dice_8: 3.45  time: 1.6998  data_time: 0.3453  lr: 7.8764e-06  max_mem: 17674M
[01/19 05:28:52] d2.utils.events INFO:  eta: 14:16:28  iter: 9339  total_loss: 66.88  loss_ce: 2.408  loss_mask: 0.6326  loss_dice: 3.447  loss_ce_0: 3.739  loss_mask_0: 0.6601  loss_dice_0: 3.721  loss_ce_1: 2.607  loss_mask_1: 0.6428  loss_dice_1: 3.594  loss_ce_2: 2.496  loss_mask_2: 0.638  loss_dice_2: 3.522  loss_ce_3: 2.466  loss_mask_3: 0.6363  loss_dice_3: 3.468  loss_ce_4: 2.421  loss_mask_4: 0.6331  loss_dice_4: 3.459  loss_ce_5: 2.41  loss_mask_5: 0.6322  loss_dice_5: 3.461  loss_ce_6: 2.408  loss_mask_6: 0.634  loss_dice_6: 3.45  loss_ce_7: 2.404  loss_mask_7: 0.6329  loss_dice_7: 3.45  loss_ce_8: 2.397  loss_mask_8: 0.6331  loss_dice_8: 3.45  time: 1.6997  data_time: 0.3496  lr: 7.8718e-06  max_mem: 17674M
[01/19 05:29:25] d2.utils.events INFO:  eta: 14:15:47  iter: 9359  total_loss: 66.72  loss_ce: 2.423  loss_mask: 0.6429  loss_dice: 3.369  loss_ce_0: 3.735  loss_mask_0: 0.6597  loss_dice_0: 3.657  loss_ce_1: 2.638  loss_mask_1: 0.6544  loss_dice_1: 3.51  loss_ce_2: 2.52  loss_mask_2: 0.6487  loss_dice_2: 3.443  loss_ce_3: 2.468  loss_mask_3: 0.6458  loss_dice_3: 3.387  loss_ce_4: 2.453  loss_mask_4: 0.6456  loss_dice_4: 3.385  loss_ce_5: 2.432  loss_mask_5: 0.6456  loss_dice_5: 3.386  loss_ce_6: 2.424  loss_mask_6: 0.6468  loss_dice_6: 3.371  loss_ce_7: 2.405  loss_mask_7: 0.6404  loss_dice_7: 3.375  loss_ce_8: 2.417  loss_mask_8: 0.6432  loss_dice_8: 3.377  time: 1.6997  data_time: 0.3273  lr: 7.8672e-06  max_mem: 17674M
[01/19 05:29:59] d2.utils.events INFO:  eta: 14:15:21  iter: 9379  total_loss: 67.68  loss_ce: 2.429  loss_mask: 0.6265  loss_dice: 3.447  loss_ce_0: 3.801  loss_mask_0: 0.6419  loss_dice_0: 3.753  loss_ce_1: 2.543  loss_mask_1: 0.6422  loss_dice_1: 3.602  loss_ce_2: 2.436  loss_mask_2: 0.6351  loss_dice_2: 3.527  loss_ce_3: 2.437  loss_mask_3: 0.6264  loss_dice_3: 3.487  loss_ce_4: 2.437  loss_mask_4: 0.6256  loss_dice_4: 3.476  loss_ce_5: 2.393  loss_mask_5: 0.626  loss_dice_5: 3.48  loss_ce_6: 2.421  loss_mask_6: 0.6267  loss_dice_6: 3.453  loss_ce_7: 2.414  loss_mask_7: 0.6272  loss_dice_7: 3.453  loss_ce_8: 2.406  loss_mask_8: 0.6276  loss_dice_8: 3.451  time: 1.6997  data_time: 0.3379  lr: 7.8626e-06  max_mem: 17674M
[01/19 05:30:33] d2.utils.events INFO:  eta: 14:14:40  iter: 9399  total_loss: 67.04  loss_ce: 2.38  loss_mask: 0.622  loss_dice: 3.488  loss_ce_0: 3.769  loss_mask_0: 0.6399  loss_dice_0: 3.733  loss_ce_1: 2.548  loss_mask_1: 0.6347  loss_dice_1: 3.621  loss_ce_2: 2.422  loss_mask_2: 0.625  loss_dice_2: 3.544  loss_ce_3: 2.406  loss_mask_3: 0.6217  loss_dice_3: 3.501  loss_ce_4: 2.375  loss_mask_4: 0.6231  loss_dice_4: 3.509  loss_ce_5: 2.389  loss_mask_5: 0.6239  loss_dice_5: 3.501  loss_ce_6: 2.388  loss_mask_6: 0.6232  loss_dice_6: 3.494  loss_ce_7: 2.36  loss_mask_7: 0.6217  loss_dice_7: 3.499  loss_ce_8: 2.367  loss_mask_8: 0.6227  loss_dice_8: 3.494  time: 1.6996  data_time: 0.3351  lr: 7.8579e-06  max_mem: 17674M
[01/19 05:31:07] d2.utils.events INFO:  eta: 14:14:06  iter: 9419  total_loss: 67.06  loss_ce: 2.418  loss_mask: 0.6329  loss_dice: 3.435  loss_ce_0: 3.782  loss_mask_0: 0.6561  loss_dice_0: 3.719  loss_ce_1: 2.579  loss_mask_1: 0.6484  loss_dice_1: 3.585  loss_ce_2: 2.471  loss_mask_2: 0.64  loss_dice_2: 3.51  loss_ce_3: 2.483  loss_mask_3: 0.6374  loss_dice_3: 3.467  loss_ce_4: 2.432  loss_mask_4: 0.6363  loss_dice_4: 3.46  loss_ce_5: 2.425  loss_mask_5: 0.6343  loss_dice_5: 3.459  loss_ce_6: 2.428  loss_mask_6: 0.63  loss_dice_6: 3.443  loss_ce_7: 2.419  loss_mask_7: 0.6328  loss_dice_7: 3.435  loss_ce_8: 2.421  loss_mask_8: 0.6308  loss_dice_8: 3.44  time: 1.6996  data_time: 0.3284  lr: 7.8533e-06  max_mem: 17674M
[01/19 05:31:41] d2.utils.events INFO:  eta: 14:13:29  iter: 9439  total_loss: 67.77  loss_ce: 2.517  loss_mask: 0.6252  loss_dice: 3.411  loss_ce_0: 3.78  loss_mask_0: 0.6489  loss_dice_0: 3.677  loss_ce_1: 2.711  loss_mask_1: 0.6422  loss_dice_1: 3.545  loss_ce_2: 2.599  loss_mask_2: 0.6333  loss_dice_2: 3.467  loss_ce_3: 2.575  loss_mask_3: 0.6299  loss_dice_3: 3.428  loss_ce_4: 2.545  loss_mask_4: 0.6302  loss_dice_4: 3.431  loss_ce_5: 2.523  loss_mask_5: 0.6256  loss_dice_5: 3.427  loss_ce_6: 2.53  loss_mask_6: 0.6255  loss_dice_6: 3.405  loss_ce_7: 2.522  loss_mask_7: 0.6242  loss_dice_7: 3.412  loss_ce_8: 2.511  loss_mask_8: 0.6258  loss_dice_8: 3.41  time: 1.6996  data_time: 0.3471  lr: 7.8487e-06  max_mem: 17674M
[01/19 05:32:15] d2.utils.events INFO:  eta: 14:12:59  iter: 9459  total_loss: 67.17  loss_ce: 2.438  loss_mask: 0.6266  loss_dice: 3.483  loss_ce_0: 3.738  loss_mask_0: 0.6449  loss_dice_0: 3.754  loss_ce_1: 2.572  loss_mask_1: 0.6382  loss_dice_1: 3.624  loss_ce_2: 2.496  loss_mask_2: 0.6356  loss_dice_2: 3.544  loss_ce_3: 2.461  loss_mask_3: 0.6323  loss_dice_3: 3.506  loss_ce_4: 2.446  loss_mask_4: 0.631  loss_dice_4: 3.5  loss_ce_5: 2.429  loss_mask_5: 0.6294  loss_dice_5: 3.496  loss_ce_6: 2.414  loss_mask_6: 0.626  loss_dice_6: 3.492  loss_ce_7: 2.427  loss_mask_7: 0.6289  loss_dice_7: 3.484  loss_ce_8: 2.428  loss_mask_8: 0.628  loss_dice_8: 3.482  time: 1.6996  data_time: 0.3445  lr: 7.8441e-06  max_mem: 17674M
[01/19 05:32:48] d2.utils.events INFO:  eta: 14:12:23  iter: 9479  total_loss: 66.68  loss_ce: 2.378  loss_mask: 0.6273  loss_dice: 3.442  loss_ce_0: 3.708  loss_mask_0: 0.6399  loss_dice_0: 3.717  loss_ce_1: 2.565  loss_mask_1: 0.6389  loss_dice_1: 3.586  loss_ce_2: 2.402  loss_mask_2: 0.6402  loss_dice_2: 3.513  loss_ce_3: 2.407  loss_mask_3: 0.6348  loss_dice_3: 3.463  loss_ce_4: 2.371  loss_mask_4: 0.6342  loss_dice_4: 3.461  loss_ce_5: 2.379  loss_mask_5: 0.6342  loss_dice_5: 3.455  loss_ce_6: 2.377  loss_mask_6: 0.6312  loss_dice_6: 3.448  loss_ce_7: 2.368  loss_mask_7: 0.6316  loss_dice_7: 3.449  loss_ce_8: 2.359  loss_mask_8: 0.631  loss_dice_8: 3.452  time: 1.6995  data_time: 0.3406  lr: 7.8394e-06  max_mem: 17674M
[01/19 05:33:22] d2.utils.events INFO:  eta: 14:11:49  iter: 9499  total_loss: 67.34  loss_ce: 2.465  loss_mask: 0.6377  loss_dice: 3.414  loss_ce_0: 3.858  loss_mask_0: 0.6618  loss_dice_0: 3.686  loss_ce_1: 2.635  loss_mask_1: 0.6471  loss_dice_1: 3.568  loss_ce_2: 2.521  loss_mask_2: 0.6395  loss_dice_2: 3.496  loss_ce_3: 2.514  loss_mask_3: 0.6354  loss_dice_3: 3.447  loss_ce_4: 2.467  loss_mask_4: 0.6356  loss_dice_4: 3.441  loss_ce_5: 2.461  loss_mask_5: 0.6344  loss_dice_5: 3.437  loss_ce_6: 2.461  loss_mask_6: 0.6373  loss_dice_6: 3.427  loss_ce_7: 2.464  loss_mask_7: 0.636  loss_dice_7: 3.421  loss_ce_8: 2.441  loss_mask_8: 0.638  loss_dice_8: 3.419  time: 1.6995  data_time: 0.3619  lr: 7.8348e-06  max_mem: 17674M
[01/19 05:33:56] d2.utils.events INFO:  eta: 14:11:26  iter: 9519  total_loss: 66.06  loss_ce: 2.287  loss_mask: 0.6156  loss_dice: 3.478  loss_ce_0: 3.754  loss_mask_0: 0.6382  loss_dice_0: 3.743  loss_ce_1: 2.447  loss_mask_1: 0.6296  loss_dice_1: 3.613  loss_ce_2: 2.353  loss_mask_2: 0.6241  loss_dice_2: 3.541  loss_ce_3: 2.316  loss_mask_3: 0.6184  loss_dice_3: 3.501  loss_ce_4: 2.28  loss_mask_4: 0.6206  loss_dice_4: 3.494  loss_ce_5: 2.277  loss_mask_5: 0.6197  loss_dice_5: 3.496  loss_ce_6: 2.269  loss_mask_6: 0.6202  loss_dice_6: 3.486  loss_ce_7: 2.264  loss_mask_7: 0.6171  loss_dice_7: 3.485  loss_ce_8: 2.271  loss_mask_8: 0.6176  loss_dice_8: 3.482  time: 1.6995  data_time: 0.3466  lr: 7.8302e-06  max_mem: 17674M
[01/19 05:34:29] d2.utils.events INFO:  eta: 14:10:45  iter: 9539  total_loss: 67.11  loss_ce: 2.401  loss_mask: 0.6314  loss_dice: 3.482  loss_ce_0: 3.75  loss_mask_0: 0.656  loss_dice_0: 3.738  loss_ce_1: 2.542  loss_mask_1: 0.6483  loss_dice_1: 3.614  loss_ce_2: 2.422  loss_mask_2: 0.6355  loss_dice_2: 3.55  loss_ce_3: 2.414  loss_mask_3: 0.634  loss_dice_3: 3.508  loss_ce_4: 2.406  loss_mask_4: 0.6341  loss_dice_4: 3.502  loss_ce_5: 2.379  loss_mask_5: 0.6323  loss_dice_5: 3.495  loss_ce_6: 2.385  loss_mask_6: 0.6308  loss_dice_6: 3.488  loss_ce_7: 2.378  loss_mask_7: 0.6318  loss_dice_7: 3.487  loss_ce_8: 2.374  loss_mask_8: 0.6293  loss_dice_8: 3.484  time: 1.6994  data_time: 0.3152  lr: 7.8256e-06  max_mem: 17674M
[01/19 05:35:03] d2.utils.events INFO:  eta: 14:10:15  iter: 9559  total_loss: 67.28  loss_ce: 2.385  loss_mask: 0.6322  loss_dice: 3.459  loss_ce_0: 3.806  loss_mask_0: 0.6458  loss_dice_0: 3.715  loss_ce_1: 2.606  loss_mask_1: 0.6453  loss_dice_1: 3.604  loss_ce_2: 2.452  loss_mask_2: 0.6356  loss_dice_2: 3.529  loss_ce_3: 2.424  loss_mask_3: 0.6363  loss_dice_3: 3.485  loss_ce_4: 2.42  loss_mask_4: 0.6364  loss_dice_4: 3.485  loss_ce_5: 2.389  loss_mask_5: 0.6348  loss_dice_5: 3.476  loss_ce_6: 2.389  loss_mask_6: 0.6301  loss_dice_6: 3.458  loss_ce_7: 2.356  loss_mask_7: 0.6356  loss_dice_7: 3.464  loss_ce_8: 2.379  loss_mask_8: 0.635  loss_dice_8: 3.461  time: 1.6994  data_time: 0.3363  lr: 7.8209e-06  max_mem: 17674M
[01/19 05:35:37] d2.utils.events INFO:  eta: 14:09:38  iter: 9579  total_loss: 67.09  loss_ce: 2.421  loss_mask: 0.6222  loss_dice: 3.498  loss_ce_0: 3.748  loss_mask_0: 0.6393  loss_dice_0: 3.762  loss_ce_1: 2.618  loss_mask_1: 0.6384  loss_dice_1: 3.634  loss_ce_2: 2.488  loss_mask_2: 0.629  loss_dice_2: 3.565  loss_ce_3: 2.434  loss_mask_3: 0.6268  loss_dice_3: 3.527  loss_ce_4: 2.426  loss_mask_4: 0.6252  loss_dice_4: 3.515  loss_ce_5: 2.412  loss_mask_5: 0.6251  loss_dice_5: 3.516  loss_ce_6: 2.41  loss_mask_6: 0.6255  loss_dice_6: 3.505  loss_ce_7: 2.404  loss_mask_7: 0.6215  loss_dice_7: 3.503  loss_ce_8: 2.418  loss_mask_8: 0.6212  loss_dice_8: 3.501  time: 1.6994  data_time: 0.3421  lr: 7.8163e-06  max_mem: 17674M
[01/19 05:36:11] d2.utils.events INFO:  eta: 14:09:02  iter: 9599  total_loss: 67.43  loss_ce: 2.413  loss_mask: 0.6269  loss_dice: 3.46  loss_ce_0: 3.794  loss_mask_0: 0.6481  loss_dice_0: 3.722  loss_ce_1: 2.578  loss_mask_1: 0.6373  loss_dice_1: 3.598  loss_ce_2: 2.498  loss_mask_2: 0.6304  loss_dice_2: 3.533  loss_ce_3: 2.457  loss_mask_3: 0.627  loss_dice_3: 3.485  loss_ce_4: 2.421  loss_mask_4: 0.6279  loss_dice_4: 3.487  loss_ce_5: 2.425  loss_mask_5: 0.6307  loss_dice_5: 3.477  loss_ce_6: 2.427  loss_mask_6: 0.6271  loss_dice_6: 3.467  loss_ce_7: 2.416  loss_mask_7: 0.6299  loss_dice_7: 3.47  loss_ce_8: 2.4  loss_mask_8: 0.6287  loss_dice_8: 3.467  time: 1.6994  data_time: 0.3417  lr: 7.8117e-06  max_mem: 17674M
[01/19 05:36:45] d2.utils.events INFO:  eta: 14:08:28  iter: 9619  total_loss: 67.03  loss_ce: 2.388  loss_mask: 0.639  loss_dice: 3.42  loss_ce_0: 3.789  loss_mask_0: 0.6579  loss_dice_0: 3.699  loss_ce_1: 2.572  loss_mask_1: 0.6491  loss_dice_1: 3.576  loss_ce_2: 2.452  loss_mask_2: 0.6424  loss_dice_2: 3.492  loss_ce_3: 2.432  loss_mask_3: 0.6373  loss_dice_3: 3.446  loss_ce_4: 2.411  loss_mask_4: 0.6393  loss_dice_4: 3.443  loss_ce_5: 2.388  loss_mask_5: 0.6385  loss_dice_5: 3.433  loss_ce_6: 2.38  loss_mask_6: 0.6368  loss_dice_6: 3.425  loss_ce_7: 2.38  loss_mask_7: 0.636  loss_dice_7: 3.429  loss_ce_8: 2.384  loss_mask_8: 0.638  loss_dice_8: 3.429  time: 1.6993  data_time: 0.3241  lr: 7.8071e-06  max_mem: 17674M
[01/19 05:37:18] d2.utils.events INFO:  eta: 14:08:09  iter: 9639  total_loss: 66.9  loss_ce: 2.373  loss_mask: 0.6236  loss_dice: 3.46  loss_ce_0: 3.755  loss_mask_0: 0.6453  loss_dice_0: 3.731  loss_ce_1: 2.542  loss_mask_1: 0.6382  loss_dice_1: 3.602  loss_ce_2: 2.443  loss_mask_2: 0.6297  loss_dice_2: 3.522  loss_ce_3: 2.416  loss_mask_3: 0.6224  loss_dice_3: 3.481  loss_ce_4: 2.377  loss_mask_4: 0.6229  loss_dice_4: 3.476  loss_ce_5: 2.389  loss_mask_5: 0.6263  loss_dice_5: 3.473  loss_ce_6: 2.382  loss_mask_6: 0.6251  loss_dice_6: 3.459  loss_ce_7: 2.376  loss_mask_7: 0.6233  loss_dice_7: 3.461  loss_ce_8: 2.363  loss_mask_8: 0.6226  loss_dice_8: 3.459  time: 1.6993  data_time: 0.3341  lr: 7.8024e-06  max_mem: 17674M
[01/19 05:37:53] d2.utils.events INFO:  eta: 14:08:14  iter: 9659  total_loss: 66.84  loss_ce: 2.35  loss_mask: 0.6182  loss_dice: 3.492  loss_ce_0: 3.785  loss_mask_0: 0.6334  loss_dice_0: 3.757  loss_ce_1: 2.533  loss_mask_1: 0.6262  loss_dice_1: 3.626  loss_ce_2: 2.405  loss_mask_2: 0.6237  loss_dice_2: 3.558  loss_ce_3: 2.381  loss_mask_3: 0.6201  loss_dice_3: 3.513  loss_ce_4: 2.364  loss_mask_4: 0.6201  loss_dice_4: 3.506  loss_ce_5: 2.351  loss_mask_5: 0.618  loss_dice_5: 3.504  loss_ce_6: 2.364  loss_mask_6: 0.6176  loss_dice_6: 3.499  loss_ce_7: 2.348  loss_mask_7: 0.6196  loss_dice_7: 3.495  loss_ce_8: 2.36  loss_mask_8: 0.6176  loss_dice_8: 3.494  time: 1.6993  data_time: 0.3415  lr: 7.7978e-06  max_mem: 17674M
[01/19 05:38:26] d2.utils.events INFO:  eta: 14:07:16  iter: 9679  total_loss: 66.29  loss_ce: 2.331  loss_mask: 0.6146  loss_dice: 3.442  loss_ce_0: 3.772  loss_mask_0: 0.6328  loss_dice_0: 3.742  loss_ce_1: 2.539  loss_mask_1: 0.629  loss_dice_1: 3.587  loss_ce_2: 2.418  loss_mask_2: 0.6263  loss_dice_2: 3.505  loss_ce_3: 2.389  loss_mask_3: 0.6143  loss_dice_3: 3.471  loss_ce_4: 2.351  loss_mask_4: 0.6165  loss_dice_4: 3.462  loss_ce_5: 2.357  loss_mask_5: 0.6189  loss_dice_5: 3.453  loss_ce_6: 2.347  loss_mask_6: 0.6176  loss_dice_6: 3.441  loss_ce_7: 2.342  loss_mask_7: 0.6169  loss_dice_7: 3.444  loss_ce_8: 2.329  loss_mask_8: 0.6158  loss_dice_8: 3.447  time: 1.6993  data_time: 0.3449  lr: 7.7932e-06  max_mem: 17674M
[01/19 05:39:00] d2.utils.events INFO:  eta: 14:07:18  iter: 9699  total_loss: 66.76  loss_ce: 2.35  loss_mask: 0.6359  loss_dice: 3.456  loss_ce_0: 3.737  loss_mask_0: 0.6565  loss_dice_0: 3.726  loss_ce_1: 2.528  loss_mask_1: 0.6511  loss_dice_1: 3.592  loss_ce_2: 2.397  loss_mask_2: 0.6386  loss_dice_2: 3.525  loss_ce_3: 2.409  loss_mask_3: 0.6365  loss_dice_3: 3.479  loss_ce_4: 2.358  loss_mask_4: 0.6346  loss_dice_4: 3.484  loss_ce_5: 2.353  loss_mask_5: 0.6369  loss_dice_5: 3.478  loss_ce_6: 2.361  loss_mask_6: 0.6354  loss_dice_6: 3.467  loss_ce_7: 2.376  loss_mask_7: 0.6363  loss_dice_7: 3.46  loss_ce_8: 2.353  loss_mask_8: 0.635  loss_dice_8: 3.461  time: 1.6993  data_time: 0.3468  lr: 7.7886e-06  max_mem: 17674M
[01/19 05:39:34] d2.utils.events INFO:  eta: 14:06:58  iter: 9719  total_loss: 66.7  loss_ce: 2.371  loss_mask: 0.6271  loss_dice: 3.434  loss_ce_0: 3.731  loss_mask_0: 0.6498  loss_dice_0: 3.724  loss_ce_1: 2.554  loss_mask_1: 0.6415  loss_dice_1: 3.586  loss_ce_2: 2.465  loss_mask_2: 0.6318  loss_dice_2: 3.516  loss_ce_3: 2.425  loss_mask_3: 0.6328  loss_dice_3: 3.46  loss_ce_4: 2.375  loss_mask_4: 0.6321  loss_dice_4: 3.457  loss_ce_5: 2.384  loss_mask_5: 0.6292  loss_dice_5: 3.448  loss_ce_6: 2.353  loss_mask_6: 0.6289  loss_dice_6: 3.438  loss_ce_7: 2.354  loss_mask_7: 0.6271  loss_dice_7: 3.434  loss_ce_8: 2.358  loss_mask_8: 0.6296  loss_dice_8: 3.437  time: 1.6992  data_time: 0.3320  lr: 7.7839e-06  max_mem: 17674M
[01/19 05:40:07] d2.utils.events INFO:  eta: 14:06:30  iter: 9739  total_loss: 66.18  loss_ce: 2.33  loss_mask: 0.6294  loss_dice: 3.434  loss_ce_0: 3.716  loss_mask_0: 0.6418  loss_dice_0: 3.714  loss_ce_1: 2.506  loss_mask_1: 0.6363  loss_dice_1: 3.589  loss_ce_2: 2.424  loss_mask_2: 0.6346  loss_dice_2: 3.51  loss_ce_3: 2.395  loss_mask_3: 0.6316  loss_dice_3: 3.46  loss_ce_4: 2.381  loss_mask_4: 0.6315  loss_dice_4: 3.453  loss_ce_5: 2.365  loss_mask_5: 0.6308  loss_dice_5: 3.454  loss_ce_6: 2.362  loss_mask_6: 0.6296  loss_dice_6: 3.438  loss_ce_7: 2.347  loss_mask_7: 0.6325  loss_dice_7: 3.441  loss_ce_8: 2.345  loss_mask_8: 0.6307  loss_dice_8: 3.432  time: 1.6992  data_time: 0.3255  lr: 7.7793e-06  max_mem: 17674M
[01/19 05:40:41] d2.utils.events INFO:  eta: 14:06:00  iter: 9759  total_loss: 66.58  loss_ce: 2.343  loss_mask: 0.6213  loss_dice: 3.464  loss_ce_0: 3.722  loss_mask_0: 0.6395  loss_dice_0: 3.736  loss_ce_1: 2.533  loss_mask_1: 0.6344  loss_dice_1: 3.604  loss_ce_2: 2.445  loss_mask_2: 0.6304  loss_dice_2: 3.535  loss_ce_3: 2.396  loss_mask_3: 0.6237  loss_dice_3: 3.492  loss_ce_4: 2.36  loss_mask_4: 0.6257  loss_dice_4: 3.486  loss_ce_5: 2.362  loss_mask_5: 0.6276  loss_dice_5: 3.483  loss_ce_6: 2.338  loss_mask_6: 0.6236  loss_dice_6: 3.476  loss_ce_7: 2.338  loss_mask_7: 0.6254  loss_dice_7: 3.471  loss_ce_8: 2.333  loss_mask_8: 0.6218  loss_dice_8: 3.467  time: 1.6991  data_time: 0.3288  lr: 7.7747e-06  max_mem: 17674M
[01/19 05:41:15] d2.utils.events INFO:  eta: 14:05:26  iter: 9779  total_loss: 66.68  loss_ce: 2.401  loss_mask: 0.6247  loss_dice: 3.454  loss_ce_0: 3.737  loss_mask_0: 0.6408  loss_dice_0: 3.737  loss_ce_1: 2.55  loss_mask_1: 0.6362  loss_dice_1: 3.607  loss_ce_2: 2.461  loss_mask_2: 0.6306  loss_dice_2: 3.528  loss_ce_3: 2.442  loss_mask_3: 0.6275  loss_dice_3: 3.475  loss_ce_4: 2.422  loss_mask_4: 0.6247  loss_dice_4: 3.479  loss_ce_5: 2.418  loss_mask_5: 0.625  loss_dice_5: 3.478  loss_ce_6: 2.425  loss_mask_6: 0.6246  loss_dice_6: 3.462  loss_ce_7: 2.411  loss_mask_7: 0.6248  loss_dice_7: 3.465  loss_ce_8: 2.414  loss_mask_8: 0.6255  loss_dice_8: 3.461  time: 1.6991  data_time: 0.3244  lr: 7.7701e-06  max_mem: 17674M
[01/19 05:41:48] d2.utils.events INFO:  eta: 14:04:33  iter: 9799  total_loss: 66.74  loss_ce: 2.345  loss_mask: 0.633  loss_dice: 3.457  loss_ce_0: 3.741  loss_mask_0: 0.6474  loss_dice_0: 3.718  loss_ce_1: 2.529  loss_mask_1: 0.6474  loss_dice_1: 3.589  loss_ce_2: 2.422  loss_mask_2: 0.6375  loss_dice_2: 3.519  loss_ce_3: 2.371  loss_mask_3: 0.6337  loss_dice_3: 3.479  loss_ce_4: 2.358  loss_mask_4: 0.6356  loss_dice_4: 3.475  loss_ce_5: 2.344  loss_mask_5: 0.6321  loss_dice_5: 3.468  loss_ce_6: 2.364  loss_mask_6: 0.6346  loss_dice_6: 3.454  loss_ce_7: 2.342  loss_mask_7: 0.6347  loss_dice_7: 3.46  loss_ce_8: 2.332  loss_mask_8: 0.6348  loss_dice_8: 3.458  time: 1.6990  data_time: 0.3117  lr: 7.7654e-06  max_mem: 17674M
[01/19 05:42:21] d2.utils.events INFO:  eta: 14:03:45  iter: 9819  total_loss: 66.39  loss_ce: 2.419  loss_mask: 0.634  loss_dice: 3.462  loss_ce_0: 3.721  loss_mask_0: 0.6576  loss_dice_0: 3.717  loss_ce_1: 2.522  loss_mask_1: 0.6454  loss_dice_1: 3.594  loss_ce_2: 2.443  loss_mask_2: 0.6413  loss_dice_2: 3.537  loss_ce_3: 2.418  loss_mask_3: 0.6365  loss_dice_3: 3.487  loss_ce_4: 2.417  loss_mask_4: 0.6394  loss_dice_4: 3.486  loss_ce_5: 2.404  loss_mask_5: 0.6341  loss_dice_5: 3.475  loss_ce_6: 2.404  loss_mask_6: 0.6332  loss_dice_6: 3.459  loss_ce_7: 2.406  loss_mask_7: 0.6299  loss_dice_7: 3.476  loss_ce_8: 2.412  loss_mask_8: 0.633  loss_dice_8: 3.469  time: 1.6990  data_time: 0.3278  lr: 7.7608e-06  max_mem: 17674M
[01/19 05:42:55] d2.utils.events INFO:  eta: 14:02:21  iter: 9839  total_loss: 66.63  loss_ce: 2.419  loss_mask: 0.6422  loss_dice: 3.428  loss_ce_0: 3.781  loss_mask_0: 0.6648  loss_dice_0: 3.69  loss_ce_1: 2.593  loss_mask_1: 0.6596  loss_dice_1: 3.571  loss_ce_2: 2.479  loss_mask_2: 0.6499  loss_dice_2: 3.487  loss_ce_3: 2.457  loss_mask_3: 0.6466  loss_dice_3: 3.44  loss_ce_4: 2.44  loss_mask_4: 0.6443  loss_dice_4: 3.45  loss_ce_5: 2.416  loss_mask_5: 0.6468  loss_dice_5: 3.447  loss_ce_6: 2.416  loss_mask_6: 0.6458  loss_dice_6: 3.432  loss_ce_7: 2.399  loss_mask_7: 0.6463  loss_dice_7: 3.429  loss_ce_8: 2.405  loss_mask_8: 0.6442  loss_dice_8: 3.423  time: 1.6989  data_time: 0.3391  lr: 7.7562e-06  max_mem: 17674M
[01/19 05:43:28] d2.utils.events INFO:  eta: 14:01:39  iter: 9859  total_loss: 66.49  loss_ce: 2.339  loss_mask: 0.632  loss_dice: 3.457  loss_ce_0: 3.734  loss_mask_0: 0.6454  loss_dice_0: 3.727  loss_ce_1: 2.533  loss_mask_1: 0.6388  loss_dice_1: 3.595  loss_ce_2: 2.423  loss_mask_2: 0.6335  loss_dice_2: 3.531  loss_ce_3: 2.409  loss_mask_3: 0.6314  loss_dice_3: 3.476  loss_ce_4: 2.368  loss_mask_4: 0.6315  loss_dice_4: 3.467  loss_ce_5: 2.35  loss_mask_5: 0.6337  loss_dice_5: 3.471  loss_ce_6: 2.337  loss_mask_6: 0.6311  loss_dice_6: 3.462  loss_ce_7: 2.337  loss_mask_7: 0.6303  loss_dice_7: 3.456  loss_ce_8: 2.337  loss_mask_8: 0.6334  loss_dice_8: 3.456  time: 1.6989  data_time: 0.3396  lr: 7.7515e-06  max_mem: 17674M
[01/19 05:44:02] d2.utils.events INFO:  eta: 14:00:54  iter: 9879  total_loss: 66.96  loss_ce: 2.358  loss_mask: 0.6341  loss_dice: 3.45  loss_ce_0: 3.741  loss_mask_0: 0.6572  loss_dice_0: 3.712  loss_ce_1: 2.553  loss_mask_1: 0.6531  loss_dice_1: 3.592  loss_ce_2: 2.425  loss_mask_2: 0.6485  loss_dice_2: 3.521  loss_ce_3: 2.404  loss_mask_3: 0.6388  loss_dice_3: 3.481  loss_ce_4: 2.38  loss_mask_4: 0.6388  loss_dice_4: 3.479  loss_ce_5: 2.369  loss_mask_5: 0.6343  loss_dice_5: 3.47  loss_ce_6: 2.362  loss_mask_6: 0.6361  loss_dice_6: 3.455  loss_ce_7: 2.346  loss_mask_7: 0.6365  loss_dice_7: 3.463  loss_ce_8: 2.346  loss_mask_8: 0.6334  loss_dice_8: 3.457  time: 1.6988  data_time: 0.3185  lr: 7.7469e-06  max_mem: 17674M
[01/19 05:44:36] d2.utils.events INFO:  eta: 14:00:21  iter: 9899  total_loss: 66.46  loss_ce: 2.409  loss_mask: 0.6338  loss_dice: 3.469  loss_ce_0: 3.746  loss_mask_0: 0.6593  loss_dice_0: 3.728  loss_ce_1: 2.569  loss_mask_1: 0.6458  loss_dice_1: 3.613  loss_ce_2: 2.469  loss_mask_2: 0.6406  loss_dice_2: 3.532  loss_ce_3: 2.447  loss_mask_3: 0.6369  loss_dice_3: 3.49  loss_ce_4: 2.422  loss_mask_4: 0.6353  loss_dice_4: 3.486  loss_ce_5: 2.405  loss_mask_5: 0.6351  loss_dice_5: 3.48  loss_ce_6: 2.413  loss_mask_6: 0.6347  loss_dice_6: 3.473  loss_ce_7: 2.388  loss_mask_7: 0.6323  loss_dice_7: 3.469  loss_ce_8: 2.401  loss_mask_8: 0.6328  loss_dice_8: 3.47  time: 1.6988  data_time: 0.3468  lr: 7.7423e-06  max_mem: 17674M
[01/19 05:45:09] d2.utils.events INFO:  eta: 14:00:08  iter: 9919  total_loss: 66.14  loss_ce: 2.265  loss_mask: 0.6234  loss_dice: 3.456  loss_ce_0: 3.677  loss_mask_0: 0.6358  loss_dice_0: 3.741  loss_ce_1: 2.457  loss_mask_1: 0.6329  loss_dice_1: 3.604  loss_ce_2: 2.353  loss_mask_2: 0.6251  loss_dice_2: 3.533  loss_ce_3: 2.306  loss_mask_3: 0.6229  loss_dice_3: 3.489  loss_ce_4: 2.291  loss_mask_4: 0.624  loss_dice_4: 3.482  loss_ce_5: 2.279  loss_mask_5: 0.6251  loss_dice_5: 3.474  loss_ce_6: 2.27  loss_mask_6: 0.623  loss_dice_6: 3.469  loss_ce_7: 2.26  loss_mask_7: 0.6249  loss_dice_7: 3.464  loss_ce_8: 2.261  loss_mask_8: 0.6231  loss_dice_8: 3.462  time: 1.6988  data_time: 0.3563  lr: 7.7376e-06  max_mem: 17674M
[01/19 05:45:43] d2.utils.events INFO:  eta: 13:59:25  iter: 9939  total_loss: 66.99  loss_ce: 2.42  loss_mask: 0.627  loss_dice: 3.415  loss_ce_0: 3.851  loss_mask_0: 0.6532  loss_dice_0: 3.683  loss_ce_1: 2.63  loss_mask_1: 0.6432  loss_dice_1: 3.541  loss_ce_2: 2.49  loss_mask_2: 0.6375  loss_dice_2: 3.475  loss_ce_3: 2.456  loss_mask_3: 0.6288  loss_dice_3: 3.43  loss_ce_4: 2.42  loss_mask_4: 0.6282  loss_dice_4: 3.432  loss_ce_5: 2.429  loss_mask_5: 0.6296  loss_dice_5: 3.431  loss_ce_6: 2.418  loss_mask_6: 0.6258  loss_dice_6: 3.418  loss_ce_7: 2.42  loss_mask_7: 0.6279  loss_dice_7: 3.417  loss_ce_8: 2.405  loss_mask_8: 0.6291  loss_dice_8: 3.424  time: 1.6987  data_time: 0.3287  lr: 7.733e-06  max_mem: 17674M
[01/19 05:46:17] d2.utils.events INFO:  eta: 13:59:00  iter: 9959  total_loss: 67.31  loss_ce: 2.398  loss_mask: 0.6293  loss_dice: 3.419  loss_ce_0: 3.764  loss_mask_0: 0.6487  loss_dice_0: 3.714  loss_ce_1: 2.577  loss_mask_1: 0.6435  loss_dice_1: 3.57  loss_ce_2: 2.44  loss_mask_2: 0.6394  loss_dice_2: 3.491  loss_ce_3: 2.441  loss_mask_3: 0.6305  loss_dice_3: 3.447  loss_ce_4: 2.405  loss_mask_4: 0.6275  loss_dice_4: 3.436  loss_ce_5: 2.393  loss_mask_5: 0.63  loss_dice_5: 3.44  loss_ce_6: 2.4  loss_mask_6: 0.6263  loss_dice_6: 3.425  loss_ce_7: 2.393  loss_mask_7: 0.6289  loss_dice_7: 3.429  loss_ce_8: 2.392  loss_mask_8: 0.6308  loss_dice_8: 3.421  time: 1.6987  data_time: 0.3538  lr: 7.7284e-06  max_mem: 17674M
[01/19 05:46:50] d2.utils.events INFO:  eta: 13:58:29  iter: 9979  total_loss: 66.37  loss_ce: 2.377  loss_mask: 0.6279  loss_dice: 3.424  loss_ce_0: 3.75  loss_mask_0: 0.654  loss_dice_0: 3.691  loss_ce_1: 2.515  loss_mask_1: 0.647  loss_dice_1: 3.571  loss_ce_2: 2.408  loss_mask_2: 0.636  loss_dice_2: 3.5  loss_ce_3: 2.394  loss_mask_3: 0.6329  loss_dice_3: 3.453  loss_ce_4: 2.392  loss_mask_4: 0.6359  loss_dice_4: 3.443  loss_ce_5: 2.362  loss_mask_5: 0.6351  loss_dice_5: 3.446  loss_ce_6: 2.353  loss_mask_6: 0.6293  loss_dice_6: 3.429  loss_ce_7: 2.372  loss_mask_7: 0.6292  loss_dice_7: 3.424  loss_ce_8: 2.36  loss_mask_8: 0.6283  loss_dice_8: 3.426  time: 1.6986  data_time: 0.3268  lr: 7.7238e-06  max_mem: 17674M
[01/19 05:47:24] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/sceneflow_crop192x384/model_0009999.pth
[01/19 05:47:25] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 05:47:25] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 05:47:25] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 05:52:46] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.8436896292549667, 'error_1pix': 0.51024813068069, 'error_3pix': 0.24332759925166395, 'mIoU': 5.13699321637688, 'fwIoU': 17.219895059733346, 'IoU-0': nan, 'IoU-1': 94.99533837056546, 'IoU-2': 8.842482482625043, 'IoU-3': 32.09364438767547, 'IoU-4': 20.96705822692612, 'IoU-5': 13.369495274482205, 'IoU-6': 12.695925380847306, 'IoU-7': 9.365083625779452, 'IoU-8': 4.519503915918953, 'IoU-9': 10.555548295957031, 'IoU-10': 17.98652722206381, 'IoU-11': 20.257211117560274, 'IoU-12': 17.244364372241357, 'IoU-13': 9.320587799401448, 'IoU-14': 6.531426468982128, 'IoU-15': 10.030566416857841, 'IoU-16': 5.030264629017195, 'IoU-17': 5.844330385558864, 'IoU-18': 6.153898685718856, 'IoU-19': 8.621459450817733, 'IoU-20': 10.299117194322402, 'IoU-21': 13.693533539403527, 'IoU-22': 11.164387408848961, 'IoU-23': 12.09653026870761, 'IoU-24': 6.08299104535032, 'IoU-25': 12.041174613710414, 'IoU-26': 11.141359925061959, 'IoU-27': 10.102076965042297, 'IoU-28': 8.487804868169892, 'IoU-29': 13.060946615176269, 'IoU-30': 10.114105500213128, 'IoU-31': 11.259594621191741, 'IoU-32': 6.138797378984026, 'IoU-33': 9.88404855740957, 'IoU-34': 10.70741628017139, 'IoU-35': 8.282156018586047, 'IoU-36': 10.893399326176635, 'IoU-37': 7.080477404004096, 'IoU-38': 9.908763080743904, 'IoU-39': 8.291385478764976, 'IoU-40': 10.487247510585576, 'IoU-41': 8.719175889882827, 'IoU-42': 9.979831767337966, 'IoU-43': 9.027372740546904, 'IoU-44': 6.013700336917623, 'IoU-45': 10.852113833066976, 'IoU-46': 9.346641674928255, 'IoU-47': 7.315700060263892, 'IoU-48': 3.376546246760348, 'IoU-49': 6.976755963941411, 'IoU-50': 7.23905006719185, 'IoU-51': 7.483809515712618, 'IoU-52': 6.135714426299647, 'IoU-53': 8.164135993103331, 'IoU-54': 7.446309622226513, 'IoU-55': 6.945232174949638, 'IoU-56': 6.437179368889312, 'IoU-57': 5.981644368350596, 'IoU-58': 5.179233210743891, 'IoU-59': 5.2201635664595365, 'IoU-60': 7.931113095908239, 'IoU-61': 5.632138393191884, 'IoU-62': 6.388536056377197, 'IoU-63': 7.2521182828369986, 'IoU-64': 6.78100230362944, 'IoU-65': 7.9134129234725, 'IoU-66': 5.469061655004509, 'IoU-67': 6.394913778197833, 'IoU-68': 7.312119202230571, 'IoU-69': 4.821556118075482, 'IoU-70': 7.2554563946000075, 'IoU-71': 6.3930809424745, 'IoU-72': 4.689966857565801, 'IoU-73': 6.876863642559769, 'IoU-74': 6.771360397589267, 'IoU-75': 6.251131567078054, 'IoU-76': 5.565521385052505, 'IoU-77': 5.532391198923227, 'IoU-78': 5.951467144136078, 'IoU-79': 7.2622436743347745, 'IoU-80': 4.359015917218733, 'IoU-81': 4.997139040526753, 'IoU-82': 6.179350647859582, 'IoU-83': 5.013197718613447, 'IoU-84': 5.781969405702554, 'IoU-85': 5.241793246980013, 'IoU-86': 4.879956598745559, 'IoU-87': 5.98306425991365, 'IoU-88': 5.584754735992962, 'IoU-89': 4.944609202291293, 'IoU-90': 4.911497735962237, 'IoU-91': 4.172919973700724, 'IoU-92': 4.877161391357994, 'IoU-93': 4.432869822962422, 'IoU-94': 5.040103880890597, 'IoU-95': 4.036119251204142, 'IoU-96': 4.289979589522827, 'IoU-97': 3.399980702443204, 'IoU-98': 4.956853426392795, 'IoU-99': 3.522698738357118, 'IoU-100': 3.005356695821565, 'IoU-101': 4.3998888643969, 'IoU-102': 3.2691816530958935, 'IoU-103': 3.7871236897603704, 'IoU-104': 2.891131416592336, 'IoU-105': 1.4140429873135816, 'IoU-106': 2.9101775900858757, 'IoU-107': 1.835206082838315, 'IoU-108': 1.5881973169217154, 'IoU-109': 2.3641645756801632, 'IoU-110': 1.514167531275102, 'IoU-111': 1.3456774786686694, 'IoU-112': 0.6996714750533755, 'IoU-113': 1.440521651466321, 'IoU-114': 2.681177688834625, 'IoU-115': 0.992418351735491, 'IoU-116': 1.8462795447468205, 'IoU-117': 1.5789023311715369, 'IoU-118': 1.0139580948986913, 'IoU-119': 1.1232382420798728, 'IoU-120': 2.6835194104085422, 'IoU-121': 1.3702739246114461, 'IoU-122': 0.1898625624833395, 'IoU-123': 0.39870933352227295, 'IoU-124': 1.0985821139276302, 'IoU-125': 2.390942639795853, 'IoU-126': 0.4646020129092726, 'IoU-127': 1.4525816018770847, 'IoU-128': 0.62982041041069, 'IoU-129': 0.6129244290588817, 'IoU-130': 0.7709278712362424, 'IoU-131': 0.7154242031214346, 'IoU-132': 1.905983209785564, 'IoU-133': 0.4630858347022582, 'IoU-134': 1.121221447134455, 'IoU-135': 0.41996200930612804, 'IoU-136': 0.23480436387498974, 'IoU-137': 0.5470740403467105, 'IoU-138': 0.8098464792698857, 'IoU-139': 0.6057429985049091, 'IoU-140': 1.069768792658313, 'IoU-141': 1.6374542130076064, 'IoU-142': 1.0875974623402875, 'IoU-143': 0.5403542628713213, 'IoU-144': 0.8025586299656816, 'IoU-145': 0.836404330252646, 'IoU-146': 0.4885303128859972, 'IoU-147': 1.8670052349478716, 'IoU-148': 0.7469715752062147, 'IoU-149': 0.46354401568937775, 'IoU-150': 1.257733821072122, 'IoU-151': 1.0850856601108734, 'IoU-152': 0.7006541299513358, 'IoU-153': 0.27001080646377323, 'IoU-154': 0.49100869291504656, 'IoU-155': 0.49853781443811596, 'IoU-156': 1.1211137040445063, 'IoU-157': 1.1068442668824963, 'IoU-158': 0.8309270338534513, 'IoU-159': 0.9160911128253355, 'IoU-160': 1.4106096049593606, 'IoU-161': 0.17512125588637936, 'IoU-162': 0.2808156918345063, 'IoU-163': 0.28198113856376295, 'IoU-164': 0.2833818988623989, 'IoU-165': 0.48844401705410245, 'IoU-166': 0.14448776901242083, 'IoU-167': 0.7605727819219948, 'IoU-168': 0.2314430289168019, 'IoU-169': 0.612415758691328, 'IoU-170': 0.04955637984882835, 'IoU-171': 0.0025017065212341277, 'IoU-172': 0.1511778498209736, 'IoU-173': 0.21036335640490525, 'IoU-174': 0.27910885687746045, 'IoU-175': 0.09720580947661342, 'IoU-176': 0.3655329348783717, 'IoU-177': 0.03668019322983346, 'IoU-178': 0.19047171142359967, 'IoU-179': 0.07035039910322567, 'IoU-180': 0.4178011368713606, 'IoU-181': 0.3804637083361054, 'IoU-182': 0.6857510223761987, 'IoU-183': 0.32623470774807434, 'IoU-184': 0.20704663740198584, 'IoU-185': 0.26007097226378223, 'IoU-186': 0.8447131009218845, 'IoU-187': 2.4387240455232493, 'IoU-188': 0.8852444264470991, 'IoU-189': 2.3024867772589044, 'IoU-190': 2.6350951202435913, 'IoU-191': 0.37811567976577837, 'IoU-192': 1.4813267977360571, 'mACC': 9.22079738304505, 'pACC': 24.34016151093223, 'ACC-0': nan, 'ACC-1': 97.74417788677215, 'ACC-2': 9.183910060705031, 'ACC-3': 46.56523035186516, 'ACC-4': 28.71950835214023, 'ACC-5': 20.985476048816132, 'ACC-6': 22.286780595236248, 'ACC-7': 14.629846381599338, 'ACC-8': 5.437685369328435, 'ACC-9': 13.97208853241018, 'ACC-10': 37.28810357704378, 'ACC-11': 42.143250967304844, 'ACC-12': 43.927138039678475, 'ACC-13': 19.507091498414518, 'ACC-14': 8.692408795348621, 'ACC-15': 24.761935005884062, 'ACC-16': 7.220063965676504, 'ACC-17': 8.415326881110488, 'ACC-18': 7.6492739395927405, 'ACC-19': 13.484425983806911, 'ACC-20': 18.04384478915817, 'ACC-21': 32.7881793929015, 'ACC-22': 18.34775574797694, 'ACC-23': 23.307743635015672, 'ACC-24': 7.633907542588786, 'ACC-25': 32.502379869604745, 'ACC-26': 25.307112127130477, 'ACC-27': 18.189120904310343, 'ACC-28': 12.0785677292145, 'ACC-29': 28.62452365335917, 'ACC-30': 17.834167151917523, 'ACC-31': 24.595344276001235, 'ACC-32': 8.199682639208334, 'ACC-33': 17.53047459787705, 'ACC-34': 26.022554177298474, 'ACC-35': 13.228063549790123, 'ACC-36': 24.36197867284812, 'ACC-37': 10.098905928353613, 'ACC-38': 17.03246108925097, 'ACC-39': 12.244200029830111, 'ACC-40': 19.909357231581836, 'ACC-41': 14.6393314079905, 'ACC-42': 19.748508700585514, 'ACC-43': 16.06527764281837, 'ACC-44': 8.435639150059972, 'ACC-45': 20.098084642741203, 'ACC-46': 20.81058680949216, 'ACC-47': 11.80172600022297, 'ACC-48': 4.0288699907219785, 'ACC-49': 10.320069204545005, 'ACC-50': 11.42767085480785, 'ACC-51': 12.126540144822783, 'ACC-52': 9.954443972932916, 'ACC-53': 16.035461566025987, 'ACC-54': 12.223838485958224, 'ACC-55': 12.937325413932374, 'ACC-56': 10.982045781749832, 'ACC-57': 11.241195190347417, 'ACC-58': 9.052031894564742, 'ACC-59': 9.59184381538423, 'ACC-60': 20.49723766500677, 'ACC-61': 10.620929980982092, 'ACC-62': 12.838576735180576, 'ACC-63': 14.596927768358206, 'ACC-64': 13.107300428323823, 'ACC-65': 16.79496430809437, 'ACC-66': 9.68244065590338, 'ACC-67': 13.238193443866923, 'ACC-68': 16.620607293349575, 'ACC-69': 7.7599721810279565, 'ACC-70': 16.507043160405633, 'ACC-71': 11.69080884521643, 'ACC-72': 8.007794577383164, 'ACC-73': 15.552111338924913, 'ACC-74': 12.849391309879527, 'ACC-75': 12.642128379374473, 'ACC-76': 9.814116063186729, 'ACC-77': 13.354950365027568, 'ACC-78': 11.521398703972006, 'ACC-79': 15.147570213094417, 'ACC-80': 6.6736877560686, 'ACC-81': 10.528178416583843, 'ACC-82': 10.89994822219407, 'ACC-83': 9.571290358159343, 'ACC-84': 12.970072744590485, 'ACC-85': 8.804755232324805, 'ACC-86': 8.148195142023507, 'ACC-87': 11.356562515599169, 'ACC-88': 11.045333557218889, 'ACC-89': 9.29801001380335, 'ACC-90': 9.032076614121861, 'ACC-91': 6.860002487480273, 'ACC-92': 9.469940485458803, 'ACC-93': 7.166240099494528, 'ACC-94': 10.618953000965817, 'ACC-95': 7.172733253795617, 'ACC-96': 7.901454636229367, 'ACC-97': 5.7554330044587845, 'ACC-98': 10.473590134602494, 'ACC-99': 6.471193074397161, 'ACC-100': 5.055074536936797, 'ACC-101': 9.850409494283587, 'ACC-102': 6.3217263253285, 'ACC-103': 9.57155001416832, 'ACC-104': 6.049580679274981, 'ACC-105': 1.9887111673427316, 'ACC-106': 9.216535725233555, 'ACC-107': 3.7250499327702573, 'ACC-108': 2.920633744994717, 'ACC-109': 4.485295889482808, 'ACC-110': 2.4598868651369443, 'ACC-111': 2.1522896027774148, 'ACC-112': 0.8889658527405694, 'ACC-113': 2.8501528415701327, 'ACC-114': 7.503506745816413, 'ACC-115': 1.4051012584006135, 'ACC-116': 3.8029542942755046, 'ACC-117': 2.6098043359984957, 'ACC-118': 1.3953076314913275, 'ACC-119': 2.5802721552349372, 'ACC-120': 6.420582127157148, 'ACC-121': 2.19937346335233, 'ACC-122': 0.21672469265098548, 'ACC-123': 0.47758003746035377, 'ACC-124': 2.10894352514862, 'ACC-125': 7.690868568780776, 'ACC-126': 0.7945769087150157, 'ACC-127': 4.864719322673794, 'ACC-128': 0.9626279590823659, 'ACC-129': 0.7835291947144725, 'ACC-130': 1.2692090402767495, 'ACC-131': 1.121011116405587, 'ACC-132': 5.103195906344562, 'ACC-133': 0.6327951172712242, 'ACC-134': 2.260336062042223, 'ACC-135': 0.5827774927313153, 'ACC-136': 0.26672568020872156, 'ACC-137': 0.7253760254980663, 'ACC-138': 1.7540992969007791, 'ACC-139': 0.8054909477574559, 'ACC-140': 4.179649387845026, 'ACC-141': 3.192434766948475, 'ACC-142': 1.4029820245384306, 'ACC-143': 0.7044955623069713, 'ACC-144': 1.4793321299638988, 'ACC-145': 1.1451955544623091, 'ACC-146': 0.5634781019396404, 'ACC-147': 3.8012670580686976, 'ACC-148': 1.6025839051528872, 'ACC-149': 0.7389949384880774, 'ACC-150': 2.9608852950097404, 'ACC-151': 2.1419976702125054, 'ACC-152': 0.7934199878616224, 'ACC-153': 0.3075816706059107, 'ACC-154': 0.7216435531727776, 'ACC-155': 0.8106482474369119, 'ACC-156': 2.1594368709883844, 'ACC-157': 1.7496151663257267, 'ACC-158': 1.4003226302693808, 'ACC-159': 2.166793785991545, 'ACC-160': 3.934562050400398, 'ACC-161': 0.20908399026053354, 'ACC-162': 0.36536636308728626, 'ACC-163': 0.30710812376656116, 'ACC-164': 0.3308927286045428, 'ACC-165': 0.5896889402751352, 'ACC-166': 0.16099923613501105, 'ACC-167': 1.4013309778048768, 'ACC-168': 0.2547647513889866, 'ACC-169': 0.9049067105579468, 'ACC-170': 0.05341652824509845, 'ACC-171': 0.0025715959875755178, 'ACC-172': 0.16538874689780345, 'ACC-173': 0.23725037911143054, 'ACC-174': 0.35285499393268355, 'ACC-175': 0.1037200556871315, 'ACC-176': 0.4041386115625725, 'ACC-177': 0.0380165685802288, 'ACC-178': 0.234686919922505, 'ACC-179': 0.07385149762315853, 'ACC-180': 0.484904669985438, 'ACC-181': 0.43346337234503685, 'ACC-182': 1.0007368114307647, 'ACC-183': 0.3644488182488093, 'ACC-184': 0.2492824580146551, 'ACC-185': 0.299091408801371, 'ACC-186': 1.051667441745178, 'ACC-187': 7.847159303688134, 'ACC-188': 1.389421330858319, 'ACC-189': 4.391034116260741, 'ACC-190': 10.876992569458272, 'ACC-191': 0.45102773246329525, 'ACC-192': 4.456506051713355})])
[01/19 05:52:46] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 05:52:46] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 05:52:46] d2.evaluation.testing INFO: copypaste: 3.8437,0.5102,0.2433,5.1370,17.2199,9.2208,24.3402
[01/19 05:52:46] d2.utils.events INFO:  eta: 13:57:57  iter: 9999  total_loss: 66.57  loss_ce: 2.359  loss_mask: 0.6315  loss_dice: 3.441  loss_ce_0: 3.89  loss_mask_0: 0.6462  loss_dice_0: 3.7  loss_ce_1: 2.591  loss_mask_1: 0.6387  loss_dice_1: 3.584  loss_ce_2: 2.442  loss_mask_2: 0.6319  loss_dice_2: 3.513  loss_ce_3: 2.407  loss_mask_3: 0.6289  loss_dice_3: 3.46  loss_ce_4: 2.368  loss_mask_4: 0.632  loss_dice_4: 3.452  loss_ce_5: 2.361  loss_mask_5: 0.632  loss_dice_5: 3.456  loss_ce_6: 2.352  loss_mask_6: 0.6318  loss_dice_6: 3.445  loss_ce_7: 2.33  loss_mask_7: 0.6332  loss_dice_7: 3.445  loss_ce_8: 2.34  loss_mask_8: 0.6322  loss_dice_8: 3.443  time: 1.6986  data_time: 0.3401  lr: 7.7191e-06  max_mem: 17674M
[01/19 05:53:20] d2.utils.events INFO:  eta: 13:57:24  iter: 10019  total_loss: 66.47  loss_ce: 2.36  loss_mask: 0.6237  loss_dice: 3.391  loss_ce_0: 3.746  loss_mask_0: 0.6567  loss_dice_0: 3.678  loss_ce_1: 2.535  loss_mask_1: 0.6467  loss_dice_1: 3.539  loss_ce_2: 2.395  loss_mask_2: 0.6391  loss_dice_2: 3.467  loss_ce_3: 2.39  loss_mask_3: 0.6332  loss_dice_3: 3.428  loss_ce_4: 2.363  loss_mask_4: 0.6309  loss_dice_4: 3.413  loss_ce_5: 2.361  loss_mask_5: 0.6322  loss_dice_5: 3.413  loss_ce_6: 2.371  loss_mask_6: 0.6271  loss_dice_6: 3.399  loss_ce_7: 2.345  loss_mask_7: 0.6275  loss_dice_7: 3.396  loss_ce_8: 2.343  loss_mask_8: 0.626  loss_dice_8: 3.399  time: 1.6986  data_time: 0.3527  lr: 7.7145e-06  max_mem: 17674M
[01/19 05:53:54] d2.utils.events INFO:  eta: 13:57:23  iter: 10039  total_loss: 66.08  loss_ce: 2.302  loss_mask: 0.6286  loss_dice: 3.434  loss_ce_0: 3.743  loss_mask_0: 0.657  loss_dice_0: 3.721  loss_ce_1: 2.516  loss_mask_1: 0.6517  loss_dice_1: 3.575  loss_ce_2: 2.4  loss_mask_2: 0.6383  loss_dice_2: 3.504  loss_ce_3: 2.347  loss_mask_3: 0.63  loss_dice_3: 3.458  loss_ce_4: 2.325  loss_mask_4: 0.6311  loss_dice_4: 3.448  loss_ce_5: 2.292  loss_mask_5: 0.6315  loss_dice_5: 3.446  loss_ce_6: 2.322  loss_mask_6: 0.6287  loss_dice_6: 3.439  loss_ce_7: 2.292  loss_mask_7: 0.6328  loss_dice_7: 3.426  loss_ce_8: 2.312  loss_mask_8: 0.6284  loss_dice_8: 3.436  time: 1.6986  data_time: 0.3396  lr: 7.7099e-06  max_mem: 17674M
[01/19 05:54:28] d2.utils.events INFO:  eta: 13:56:57  iter: 10059  total_loss: 66.2  loss_ce: 2.35  loss_mask: 0.6293  loss_dice: 3.413  loss_ce_0: 3.757  loss_mask_0: 0.6535  loss_dice_0: 3.689  loss_ce_1: 2.591  loss_mask_1: 0.6452  loss_dice_1: 3.555  loss_ce_2: 2.438  loss_mask_2: 0.6365  loss_dice_2: 3.485  loss_ce_3: 2.407  loss_mask_3: 0.6315  loss_dice_3: 3.43  loss_ce_4: 2.396  loss_mask_4: 0.6314  loss_dice_4: 3.427  loss_ce_5: 2.351  loss_mask_5: 0.6323  loss_dice_5: 3.426  loss_ce_6: 2.371  loss_mask_6: 0.6306  loss_dice_6: 3.42  loss_ce_7: 2.36  loss_mask_7: 0.6269  loss_dice_7: 3.414  loss_ce_8: 2.367  loss_mask_8: 0.629  loss_dice_8: 3.413  time: 1.6986  data_time: 0.3555  lr: 7.7052e-06  max_mem: 17674M
[01/19 05:55:02] d2.utils.events INFO:  eta: 13:56:46  iter: 10079  total_loss: 66.54  loss_ce: 2.399  loss_mask: 0.6423  loss_dice: 3.4  loss_ce_0: 3.749  loss_mask_0: 0.6634  loss_dice_0: 3.682  loss_ce_1: 2.553  loss_mask_1: 0.66  loss_dice_1: 3.553  loss_ce_2: 2.465  loss_mask_2: 0.6476  loss_dice_2: 3.48  loss_ce_3: 2.447  loss_mask_3: 0.6405  loss_dice_3: 3.426  loss_ce_4: 2.425  loss_mask_4: 0.6428  loss_dice_4: 3.42  loss_ce_5: 2.408  loss_mask_5: 0.6422  loss_dice_5: 3.412  loss_ce_6: 2.411  loss_mask_6: 0.6416  loss_dice_6: 3.399  loss_ce_7: 2.407  loss_mask_7: 0.6409  loss_dice_7: 3.396  loss_ce_8: 2.395  loss_mask_8: 0.6423  loss_dice_8: 3.405  time: 1.6985  data_time: 0.3406  lr: 7.7006e-06  max_mem: 17674M
[01/19 05:55:36] d2.utils.events INFO:  eta: 13:56:38  iter: 10099  total_loss: 66.57  loss_ce: 2.359  loss_mask: 0.624  loss_dice: 3.472  loss_ce_0: 3.737  loss_mask_0: 0.6416  loss_dice_0: 3.736  loss_ce_1: 2.491  loss_mask_1: 0.6354  loss_dice_1: 3.608  loss_ce_2: 2.412  loss_mask_2: 0.6331  loss_dice_2: 3.533  loss_ce_3: 2.401  loss_mask_3: 0.6315  loss_dice_3: 3.493  loss_ce_4: 2.392  loss_mask_4: 0.6273  loss_dice_4: 3.486  loss_ce_5: 2.348  loss_mask_5: 0.6259  loss_dice_5: 3.489  loss_ce_6: 2.362  loss_mask_6: 0.6268  loss_dice_6: 3.466  loss_ce_7: 2.348  loss_mask_7: 0.6278  loss_dice_7: 3.464  loss_ce_8: 2.351  loss_mask_8: 0.6266  loss_dice_8: 3.473  time: 1.6985  data_time: 0.3445  lr: 7.696e-06  max_mem: 17674M
[01/19 05:56:09] d2.utils.events INFO:  eta: 13:55:17  iter: 10119  total_loss: 66.84  loss_ce: 2.372  loss_mask: 0.627  loss_dice: 3.4  loss_ce_0: 3.74  loss_mask_0: 0.6522  loss_dice_0: 3.676  loss_ce_1: 2.546  loss_mask_1: 0.6471  loss_dice_1: 3.542  loss_ce_2: 2.459  loss_mask_2: 0.6387  loss_dice_2: 3.472  loss_ce_3: 2.425  loss_mask_3: 0.6319  loss_dice_3: 3.43  loss_ce_4: 2.401  loss_mask_4: 0.6321  loss_dice_4: 3.41  loss_ce_5: 2.396  loss_mask_5: 0.6269  loss_dice_5: 3.416  loss_ce_6: 2.371  loss_mask_6: 0.6327  loss_dice_6: 3.401  loss_ce_7: 2.356  loss_mask_7: 0.6279  loss_dice_7: 3.402  loss_ce_8: 2.36  loss_mask_8: 0.627  loss_dice_8: 3.397  time: 1.6984  data_time: 0.3442  lr: 7.6913e-06  max_mem: 17674M
[01/19 05:56:42] d2.utils.events INFO:  eta: 13:54:22  iter: 10139  total_loss: 66.48  loss_ce: 2.347  loss_mask: 0.6397  loss_dice: 3.407  loss_ce_0: 3.787  loss_mask_0: 0.6657  loss_dice_0: 3.677  loss_ce_1: 2.503  loss_mask_1: 0.6601  loss_dice_1: 3.556  loss_ce_2: 2.378  loss_mask_2: 0.6511  loss_dice_2: 3.493  loss_ce_3: 2.384  loss_mask_3: 0.646  loss_dice_3: 3.444  loss_ce_4: 2.355  loss_mask_4: 0.645  loss_dice_4: 3.43  loss_ce_5: 2.366  loss_mask_5: 0.6436  loss_dice_5: 3.435  loss_ce_6: 2.372  loss_mask_6: 0.6442  loss_dice_6: 3.42  loss_ce_7: 2.352  loss_mask_7: 0.6442  loss_dice_7: 3.416  loss_ce_8: 2.336  loss_mask_8: 0.6431  loss_dice_8: 3.418  time: 1.6984  data_time: 0.3280  lr: 7.6867e-06  max_mem: 17674M
[01/19 05:57:16] d2.utils.events INFO:  eta: 13:53:48  iter: 10159  total_loss: 65.88  loss_ce: 2.356  loss_mask: 0.6186  loss_dice: 3.431  loss_ce_0: 3.733  loss_mask_0: 0.6384  loss_dice_0: 3.693  loss_ce_1: 2.485  loss_mask_1: 0.6251  loss_dice_1: 3.576  loss_ce_2: 2.382  loss_mask_2: 0.6176  loss_dice_2: 3.502  loss_ce_3: 2.378  loss_mask_3: 0.6155  loss_dice_3: 3.456  loss_ce_4: 2.328  loss_mask_4: 0.6139  loss_dice_4: 3.445  loss_ce_5: 2.338  loss_mask_5: 0.617  loss_dice_5: 3.447  loss_ce_6: 2.332  loss_mask_6: 0.6161  loss_dice_6: 3.434  loss_ce_7: 2.322  loss_mask_7: 0.6175  loss_dice_7: 3.432  loss_ce_8: 2.344  loss_mask_8: 0.6178  loss_dice_8: 3.435  time: 1.6984  data_time: 0.3367  lr: 7.6821e-06  max_mem: 17674M
[01/19 05:57:50] d2.utils.events INFO:  eta: 13:53:41  iter: 10179  total_loss: 66.33  loss_ce: 2.36  loss_mask: 0.6244  loss_dice: 3.455  loss_ce_0: 3.758  loss_mask_0: 0.6402  loss_dice_0: 3.721  loss_ce_1: 2.497  loss_mask_1: 0.6426  loss_dice_1: 3.6  loss_ce_2: 2.389  loss_mask_2: 0.6314  loss_dice_2: 3.534  loss_ce_3: 2.393  loss_mask_3: 0.6272  loss_dice_3: 3.468  loss_ce_4: 2.361  loss_mask_4: 0.6271  loss_dice_4: 3.472  loss_ce_5: 2.348  loss_mask_5: 0.6254  loss_dice_5: 3.469  loss_ce_6: 2.341  loss_mask_6: 0.6248  loss_dice_6: 3.463  loss_ce_7: 2.364  loss_mask_7: 0.6228  loss_dice_7: 3.465  loss_ce_8: 2.352  loss_mask_8: 0.624  loss_dice_8: 3.466  time: 1.6984  data_time: 0.3605  lr: 7.6774e-06  max_mem: 17674M
[01/19 05:58:24] d2.utils.events INFO:  eta: 13:53:24  iter: 10199  total_loss: 66.43  loss_ce: 2.377  loss_mask: 0.6248  loss_dice: 3.441  loss_ce_0: 3.676  loss_mask_0: 0.6417  loss_dice_0: 3.699  loss_ce_1: 2.549  loss_mask_1: 0.6391  loss_dice_1: 3.585  loss_ce_2: 2.455  loss_mask_2: 0.6317  loss_dice_2: 3.512  loss_ce_3: 2.427  loss_mask_3: 0.6309  loss_dice_3: 3.462  loss_ce_4: 2.392  loss_mask_4: 0.6269  loss_dice_4: 3.455  loss_ce_5: 2.342  loss_mask_5: 0.6297  loss_dice_5: 3.451  loss_ce_6: 2.379  loss_mask_6: 0.63  loss_dice_6: 3.446  loss_ce_7: 2.359  loss_mask_7: 0.627  loss_dice_7: 3.443  loss_ce_8: 2.358  loss_mask_8: 0.6276  loss_dice_8: 3.441  time: 1.6984  data_time: 0.3439  lr: 7.6728e-06  max_mem: 17674M
[01/19 05:58:58] d2.utils.events INFO:  eta: 13:53:17  iter: 10219  total_loss: 65.63  loss_ce: 2.269  loss_mask: 0.6257  loss_dice: 3.448  loss_ce_0: 3.781  loss_mask_0: 0.6422  loss_dice_0: 3.71  loss_ce_1: 2.432  loss_mask_1: 0.6381  loss_dice_1: 3.595  loss_ce_2: 2.299  loss_mask_2: 0.6311  loss_dice_2: 3.523  loss_ce_3: 2.275  loss_mask_3: 0.6294  loss_dice_3: 3.477  loss_ce_4: 2.276  loss_mask_4: 0.6321  loss_dice_4: 3.48  loss_ce_5: 2.227  loss_mask_5: 0.6307  loss_dice_5: 3.48  loss_ce_6: 2.245  loss_mask_6: 0.6293  loss_dice_6: 3.458  loss_ce_7: 2.254  loss_mask_7: 0.6275  loss_dice_7: 3.461  loss_ce_8: 2.235  loss_mask_8: 0.6316  loss_dice_8: 3.458  time: 1.6983  data_time: 0.3518  lr: 7.6682e-06  max_mem: 17674M
[01/19 05:59:31] d2.utils.events INFO:  eta: 13:52:02  iter: 10239  total_loss: 66.64  loss_ce: 2.391  loss_mask: 0.6322  loss_dice: 3.443  loss_ce_0: 3.718  loss_mask_0: 0.6483  loss_dice_0: 3.716  loss_ce_1: 2.545  loss_mask_1: 0.644  loss_dice_1: 3.6  loss_ce_2: 2.422  loss_mask_2: 0.6384  loss_dice_2: 3.514  loss_ce_3: 2.414  loss_mask_3: 0.6328  loss_dice_3: 3.462  loss_ce_4: 2.38  loss_mask_4: 0.6331  loss_dice_4: 3.463  loss_ce_5: 2.376  loss_mask_5: 0.6345  loss_dice_5: 3.457  loss_ce_6: 2.378  loss_mask_6: 0.6347  loss_dice_6: 3.435  loss_ce_7: 2.374  loss_mask_7: 0.6314  loss_dice_7: 3.442  loss_ce_8: 2.38  loss_mask_8: 0.6297  loss_dice_8: 3.44  time: 1.6983  data_time: 0.3301  lr: 7.6635e-06  max_mem: 17674M
[01/19 06:00:05] d2.utils.events INFO:  eta: 13:51:28  iter: 10259  total_loss: 67.11  loss_ce: 2.426  loss_mask: 0.6435  loss_dice: 3.422  loss_ce_0: 3.763  loss_mask_0: 0.656  loss_dice_0: 3.696  loss_ce_1: 2.58  loss_mask_1: 0.6474  loss_dice_1: 3.557  loss_ce_2: 2.484  loss_mask_2: 0.6434  loss_dice_2: 3.486  loss_ce_3: 2.462  loss_mask_3: 0.6374  loss_dice_3: 3.447  loss_ce_4: 2.425  loss_mask_4: 0.6396  loss_dice_4: 3.444  loss_ce_5: 2.433  loss_mask_5: 0.6423  loss_dice_5: 3.436  loss_ce_6: 2.433  loss_mask_6: 0.643  loss_dice_6: 3.429  loss_ce_7: 2.41  loss_mask_7: 0.6447  loss_dice_7: 3.427  loss_ce_8: 2.41  loss_mask_8: 0.6459  loss_dice_8: 3.425  time: 1.6982  data_time: 0.3192  lr: 7.6589e-06  max_mem: 17674M
[01/19 06:00:39] d2.utils.events INFO:  eta: 13:51:33  iter: 10279  total_loss: 66  loss_ce: 2.368  loss_mask: 0.6095  loss_dice: 3.425  loss_ce_0: 3.724  loss_mask_0: 0.6359  loss_dice_0: 3.696  loss_ce_1: 2.499  loss_mask_1: 0.6246  loss_dice_1: 3.576  loss_ce_2: 2.435  loss_mask_2: 0.6193  loss_dice_2: 3.498  loss_ce_3: 2.43  loss_mask_3: 0.6184  loss_dice_3: 3.454  loss_ce_4: 2.382  loss_mask_4: 0.6147  loss_dice_4: 3.444  loss_ce_5: 2.377  loss_mask_5: 0.6154  loss_dice_5: 3.444  loss_ce_6: 2.382  loss_mask_6: 0.6132  loss_dice_6: 3.432  loss_ce_7: 2.376  loss_mask_7: 0.6129  loss_dice_7: 3.433  loss_ce_8: 2.377  loss_mask_8: 0.6113  loss_dice_8: 3.429  time: 1.6982  data_time: 0.3514  lr: 7.6543e-06  max_mem: 17674M
[01/19 06:01:13] d2.utils.events INFO:  eta: 13:51:10  iter: 10299  total_loss: 66.25  loss_ce: 2.343  loss_mask: 0.6244  loss_dice: 3.402  loss_ce_0: 3.733  loss_mask_0: 0.6467  loss_dice_0: 3.691  loss_ce_1: 2.528  loss_mask_1: 0.6348  loss_dice_1: 3.551  loss_ce_2: 2.392  loss_mask_2: 0.6293  loss_dice_2: 3.473  loss_ce_3: 2.382  loss_mask_3: 0.624  loss_dice_3: 3.433  loss_ce_4: 2.366  loss_mask_4: 0.624  loss_dice_4: 3.42  loss_ce_5: 2.357  loss_mask_5: 0.6257  loss_dice_5: 3.42  loss_ce_6: 2.337  loss_mask_6: 0.6246  loss_dice_6: 3.41  loss_ce_7: 2.34  loss_mask_7: 0.6257  loss_dice_7: 3.414  loss_ce_8: 2.327  loss_mask_8: 0.6235  loss_dice_8: 3.411  time: 1.6983  data_time: 0.3418  lr: 7.6496e-06  max_mem: 17674M
[01/19 06:01:47] d2.utils.events INFO:  eta: 13:50:39  iter: 10319  total_loss: 65.82  loss_ce: 2.32  loss_mask: 0.6376  loss_dice: 3.42  loss_ce_0: 3.719  loss_mask_0: 0.6573  loss_dice_0: 3.694  loss_ce_1: 2.489  loss_mask_1: 0.6532  loss_dice_1: 3.565  loss_ce_2: 2.335  loss_mask_2: 0.6412  loss_dice_2: 3.495  loss_ce_3: 2.322  loss_mask_3: 0.6411  loss_dice_3: 3.449  loss_ce_4: 2.31  loss_mask_4: 0.6396  loss_dice_4: 3.442  loss_ce_5: 2.269  loss_mask_5: 0.6393  loss_dice_5: 3.442  loss_ce_6: 2.284  loss_mask_6: 0.636  loss_dice_6: 3.432  loss_ce_7: 2.281  loss_mask_7: 0.6358  loss_dice_7: 3.424  loss_ce_8: 2.295  loss_mask_8: 0.6384  loss_dice_8: 3.416  time: 1.6982  data_time: 0.3422  lr: 7.645e-06  max_mem: 17674M
[01/19 06:02:20] d2.utils.events INFO:  eta: 13:49:58  iter: 10339  total_loss: 65.68  loss_ce: 2.314  loss_mask: 0.6442  loss_dice: 3.411  loss_ce_0: 3.685  loss_mask_0: 0.6658  loss_dice_0: 3.685  loss_ce_1: 2.436  loss_mask_1: 0.6622  loss_dice_1: 3.561  loss_ce_2: 2.367  loss_mask_2: 0.6546  loss_dice_2: 3.488  loss_ce_3: 2.349  loss_mask_3: 0.6519  loss_dice_3: 3.433  loss_ce_4: 2.342  loss_mask_4: 0.6464  loss_dice_4: 3.427  loss_ce_5: 2.304  loss_mask_5: 0.6496  loss_dice_5: 3.429  loss_ce_6: 2.307  loss_mask_6: 0.6489  loss_dice_6: 3.414  loss_ce_7: 2.309  loss_mask_7: 0.6475  loss_dice_7: 3.412  loss_ce_8: 2.3  loss_mask_8: 0.6466  loss_dice_8: 3.415  time: 1.6982  data_time: 0.3461  lr: 7.6403e-06  max_mem: 17674M
[01/19 06:02:54] d2.utils.events INFO:  eta: 13:49:34  iter: 10359  total_loss: 67.6  loss_ce: 2.414  loss_mask: 0.6368  loss_dice: 3.443  loss_ce_0: 3.746  loss_mask_0: 0.6487  loss_dice_0: 3.702  loss_ce_1: 2.541  loss_mask_1: 0.6494  loss_dice_1: 3.598  loss_ce_2: 2.43  loss_mask_2: 0.6453  loss_dice_2: 3.526  loss_ce_3: 2.459  loss_mask_3: 0.639  loss_dice_3: 3.479  loss_ce_4: 2.434  loss_mask_4: 0.6362  loss_dice_4: 3.47  loss_ce_5: 2.427  loss_mask_5: 0.6387  loss_dice_5: 3.454  loss_ce_6: 2.43  loss_mask_6: 0.6424  loss_dice_6: 3.443  loss_ce_7: 2.423  loss_mask_7: 0.6409  loss_dice_7: 3.449  loss_ce_8: 2.419  loss_mask_8: 0.6389  loss_dice_8: 3.447  time: 1.6981  data_time: 0.3505  lr: 7.6357e-06  max_mem: 17674M
[01/19 06:03:28] d2.utils.events INFO:  eta: 13:48:56  iter: 10379  total_loss: 65.19  loss_ce: 2.28  loss_mask: 0.6258  loss_dice: 3.43  loss_ce_0: 3.717  loss_mask_0: 0.6411  loss_dice_0: 3.717  loss_ce_1: 2.495  loss_mask_1: 0.6361  loss_dice_1: 3.577  loss_ce_2: 2.375  loss_mask_2: 0.6294  loss_dice_2: 3.506  loss_ce_3: 2.352  loss_mask_3: 0.6213  loss_dice_3: 3.462  loss_ce_4: 2.32  loss_mask_4: 0.6225  loss_dice_4: 3.457  loss_ce_5: 2.292  loss_mask_5: 0.6215  loss_dice_5: 3.451  loss_ce_6: 2.289  loss_mask_6: 0.6232  loss_dice_6: 3.438  loss_ce_7: 2.284  loss_mask_7: 0.6208  loss_dice_7: 3.437  loss_ce_8: 2.271  loss_mask_8: 0.6253  loss_dice_8: 3.431  time: 1.6981  data_time: 0.3352  lr: 7.6311e-06  max_mem: 17674M
[01/19 06:04:02] d2.utils.events INFO:  eta: 13:48:29  iter: 10399  total_loss: 65.96  loss_ce: 2.329  loss_mask: 0.6367  loss_dice: 3.366  loss_ce_0: 3.771  loss_mask_0: 0.6603  loss_dice_0: 3.649  loss_ce_1: 2.558  loss_mask_1: 0.6546  loss_dice_1: 3.512  loss_ce_2: 2.419  loss_mask_2: 0.6461  loss_dice_2: 3.434  loss_ce_3: 2.402  loss_mask_3: 0.6422  loss_dice_3: 3.395  loss_ce_4: 2.374  loss_mask_4: 0.6395  loss_dice_4: 3.382  loss_ce_5: 2.347  loss_mask_5: 0.6406  loss_dice_5: 3.379  loss_ce_6: 2.334  loss_mask_6: 0.6397  loss_dice_6: 3.365  loss_ce_7: 2.319  loss_mask_7: 0.6397  loss_dice_7: 3.368  loss_ce_8: 2.331  loss_mask_8: 0.6394  loss_dice_8: 3.367  time: 1.6981  data_time: 0.3539  lr: 7.6264e-06  max_mem: 17674M
[01/19 06:04:36] d2.utils.events INFO:  eta: 13:48:00  iter: 10419  total_loss: 66.35  loss_ce: 2.349  loss_mask: 0.6328  loss_dice: 3.434  loss_ce_0: 3.811  loss_mask_0: 0.6495  loss_dice_0: 3.672  loss_ce_1: 2.521  loss_mask_1: 0.64  loss_dice_1: 3.585  loss_ce_2: 2.407  loss_mask_2: 0.6343  loss_dice_2: 3.509  loss_ce_3: 2.386  loss_mask_3: 0.6337  loss_dice_3: 3.465  loss_ce_4: 2.369  loss_mask_4: 0.633  loss_dice_4: 3.455  loss_ce_5: 2.35  loss_mask_5: 0.6341  loss_dice_5: 3.457  loss_ce_6: 2.365  loss_mask_6: 0.6348  loss_dice_6: 3.437  loss_ce_7: 2.359  loss_mask_7: 0.6347  loss_dice_7: 3.437  loss_ce_8: 2.339  loss_mask_8: 0.6366  loss_dice_8: 3.439  time: 1.6981  data_time: 0.3491  lr: 7.6218e-06  max_mem: 17674M
[01/19 06:05:09] d2.utils.events INFO:  eta: 13:47:31  iter: 10439  total_loss: 66.55  loss_ce: 2.423  loss_mask: 0.6345  loss_dice: 3.372  loss_ce_0: 3.787  loss_mask_0: 0.6586  loss_dice_0: 3.662  loss_ce_1: 2.612  loss_mask_1: 0.6544  loss_dice_1: 3.522  loss_ce_2: 2.475  loss_mask_2: 0.6493  loss_dice_2: 3.448  loss_ce_3: 2.46  loss_mask_3: 0.6452  loss_dice_3: 3.395  loss_ce_4: 2.431  loss_mask_4: 0.641  loss_dice_4: 3.388  loss_ce_5: 2.396  loss_mask_5: 0.6407  loss_dice_5: 3.387  loss_ce_6: 2.397  loss_mask_6: 0.6388  loss_dice_6: 3.374  loss_ce_7: 2.385  loss_mask_7: 0.6358  loss_dice_7: 3.374  loss_ce_8: 2.397  loss_mask_8: 0.6346  loss_dice_8: 3.374  time: 1.6981  data_time: 0.3356  lr: 7.6172e-06  max_mem: 17674M
[01/19 06:05:43] d2.utils.events INFO:  eta: 13:46:44  iter: 10459  total_loss: 66.34  loss_ce: 2.376  loss_mask: 0.6289  loss_dice: 3.436  loss_ce_0: 3.761  loss_mask_0: 0.647  loss_dice_0: 3.709  loss_ce_1: 2.531  loss_mask_1: 0.6461  loss_dice_1: 3.584  loss_ce_2: 2.425  loss_mask_2: 0.6324  loss_dice_2: 3.509  loss_ce_3: 2.419  loss_mask_3: 0.6334  loss_dice_3: 3.461  loss_ce_4: 2.391  loss_mask_4: 0.6317  loss_dice_4: 3.454  loss_ce_5: 2.396  loss_mask_5: 0.6296  loss_dice_5: 3.454  loss_ce_6: 2.383  loss_mask_6: 0.6302  loss_dice_6: 3.442  loss_ce_7: 2.376  loss_mask_7: 0.6304  loss_dice_7: 3.437  loss_ce_8: 2.355  loss_mask_8: 0.6319  loss_dice_8: 3.44  time: 1.6980  data_time: 0.3250  lr: 7.6125e-06  max_mem: 17674M
[01/19 06:06:17] d2.utils.events INFO:  eta: 13:46:19  iter: 10479  total_loss: 66.28  loss_ce: 2.392  loss_mask: 0.6249  loss_dice: 3.409  loss_ce_0: 3.757  loss_mask_0: 0.6518  loss_dice_0: 3.691  loss_ce_1: 2.551  loss_mask_1: 0.6489  loss_dice_1: 3.565  loss_ce_2: 2.449  loss_mask_2: 0.6356  loss_dice_2: 3.491  loss_ce_3: 2.445  loss_mask_3: 0.6291  loss_dice_3: 3.443  loss_ce_4: 2.425  loss_mask_4: 0.6306  loss_dice_4: 3.43  loss_ce_5: 2.406  loss_mask_5: 0.6303  loss_dice_5: 3.428  loss_ce_6: 2.405  loss_mask_6: 0.6279  loss_dice_6: 3.416  loss_ce_7: 2.4  loss_mask_7: 0.6285  loss_dice_7: 3.414  loss_ce_8: 2.386  loss_mask_8: 0.6268  loss_dice_8: 3.412  time: 1.6980  data_time: 0.3481  lr: 7.6079e-06  max_mem: 17674M
[01/19 06:06:51] d2.utils.events INFO:  eta: 13:45:50  iter: 10499  total_loss: 66.21  loss_ce: 2.306  loss_mask: 0.6413  loss_dice: 3.495  loss_ce_0: 3.734  loss_mask_0: 0.6687  loss_dice_0: 3.735  loss_ce_1: 2.486  loss_mask_1: 0.6591  loss_dice_1: 3.623  loss_ce_2: 2.384  loss_mask_2: 0.6499  loss_dice_2: 3.551  loss_ce_3: 2.346  loss_mask_3: 0.6414  loss_dice_3: 3.506  loss_ce_4: 2.323  loss_mask_4: 0.6434  loss_dice_4: 3.506  loss_ce_5: 2.301  loss_mask_5: 0.6433  loss_dice_5: 3.499  loss_ce_6: 2.312  loss_mask_6: 0.6429  loss_dice_6: 3.488  loss_ce_7: 2.303  loss_mask_7: 0.641  loss_dice_7: 3.493  loss_ce_8: 2.306  loss_mask_8: 0.6412  loss_dice_8: 3.492  time: 1.6980  data_time: 0.3594  lr: 7.6032e-06  max_mem: 17674M
[01/19 06:07:24] d2.utils.events INFO:  eta: 13:45:16  iter: 10519  total_loss: 66.31  loss_ce: 2.352  loss_mask: 0.6291  loss_dice: 3.412  loss_ce_0: 3.738  loss_mask_0: 0.6569  loss_dice_0: 3.691  loss_ce_1: 2.51  loss_mask_1: 0.6485  loss_dice_1: 3.563  loss_ce_2: 2.415  loss_mask_2: 0.6416  loss_dice_2: 3.494  loss_ce_3: 2.388  loss_mask_3: 0.6316  loss_dice_3: 3.441  loss_ce_4: 2.367  loss_mask_4: 0.6318  loss_dice_4: 3.433  loss_ce_5: 2.365  loss_mask_5: 0.6316  loss_dice_5: 3.424  loss_ce_6: 2.353  loss_mask_6: 0.6279  loss_dice_6: 3.417  loss_ce_7: 2.356  loss_mask_7: 0.6291  loss_dice_7: 3.414  loss_ce_8: 2.335  loss_mask_8: 0.6291  loss_dice_8: 3.404  time: 1.6980  data_time: 0.3460  lr: 7.5986e-06  max_mem: 17674M
[01/19 06:07:58] d2.utils.events INFO:  eta: 13:44:41  iter: 10539  total_loss: 66.06  loss_ce: 2.397  loss_mask: 0.6388  loss_dice: 3.41  loss_ce_0: 3.746  loss_mask_0: 0.651  loss_dice_0: 3.69  loss_ce_1: 2.483  loss_mask_1: 0.6447  loss_dice_1: 3.565  loss_ce_2: 2.414  loss_mask_2: 0.6386  loss_dice_2: 3.486  loss_ce_3: 2.415  loss_mask_3: 0.6363  loss_dice_3: 3.434  loss_ce_4: 2.383  loss_mask_4: 0.6393  loss_dice_4: 3.434  loss_ce_5: 2.393  loss_mask_5: 0.638  loss_dice_5: 3.431  loss_ce_6: 2.401  loss_mask_6: 0.6392  loss_dice_6: 3.415  loss_ce_7: 2.391  loss_mask_7: 0.6395  loss_dice_7: 3.421  loss_ce_8: 2.394  loss_mask_8: 0.6383  loss_dice_8: 3.42  time: 1.6979  data_time: 0.3240  lr: 7.594e-06  max_mem: 17674M
[01/19 06:08:32] d2.utils.events INFO:  eta: 13:44:12  iter: 10559  total_loss: 65.9  loss_ce: 2.229  loss_mask: 0.6124  loss_dice: 3.52  loss_ce_0: 3.731  loss_mask_0: 0.6277  loss_dice_0: 3.763  loss_ce_1: 2.396  loss_mask_1: 0.6262  loss_dice_1: 3.643  loss_ce_2: 2.284  loss_mask_2: 0.6207  loss_dice_2: 3.579  loss_ce_3: 2.269  loss_mask_3: 0.6146  loss_dice_3: 3.536  loss_ce_4: 2.225  loss_mask_4: 0.6174  loss_dice_4: 3.535  loss_ce_5: 2.217  loss_mask_5: 0.6146  loss_dice_5: 3.535  loss_ce_6: 2.225  loss_mask_6: 0.615  loss_dice_6: 3.519  loss_ce_7: 2.2  loss_mask_7: 0.6136  loss_dice_7: 3.522  loss_ce_8: 2.204  loss_mask_8: 0.6127  loss_dice_8: 3.516  time: 1.6979  data_time: 0.3301  lr: 7.5893e-06  max_mem: 17674M
[01/19 06:09:06] d2.utils.events INFO:  eta: 13:43:37  iter: 10579  total_loss: 65.13  loss_ce: 2.25  loss_mask: 0.6319  loss_dice: 3.409  loss_ce_0: 3.75  loss_mask_0: 0.6498  loss_dice_0: 3.685  loss_ce_1: 2.488  loss_mask_1: 0.6455  loss_dice_1: 3.546  loss_ce_2: 2.357  loss_mask_2: 0.6421  loss_dice_2: 3.472  loss_ce_3: 2.315  loss_mask_3: 0.6373  loss_dice_3: 3.426  loss_ce_4: 2.292  loss_mask_4: 0.6337  loss_dice_4: 3.429  loss_ce_5: 2.248  loss_mask_5: 0.6341  loss_dice_5: 3.426  loss_ce_6: 2.256  loss_mask_6: 0.6319  loss_dice_6: 3.414  loss_ce_7: 2.258  loss_mask_7: 0.6341  loss_dice_7: 3.411  loss_ce_8: 2.262  loss_mask_8: 0.6319  loss_dice_8: 3.407  time: 1.6979  data_time: 0.3355  lr: 7.5847e-06  max_mem: 17674M
[01/19 06:09:39] d2.utils.events INFO:  eta: 13:43:07  iter: 10599  total_loss: 65.54  loss_ce: 2.214  loss_mask: 0.6221  loss_dice: 3.418  loss_ce_0: 3.699  loss_mask_0: 0.6377  loss_dice_0: 3.698  loss_ce_1: 2.406  loss_mask_1: 0.6296  loss_dice_1: 3.557  loss_ce_2: 2.289  loss_mask_2: 0.626  loss_dice_2: 3.485  loss_ce_3: 2.272  loss_mask_3: 0.6236  loss_dice_3: 3.439  loss_ce_4: 2.242  loss_mask_4: 0.6256  loss_dice_4: 3.435  loss_ce_5: 2.222  loss_mask_5: 0.6247  loss_dice_5: 3.428  loss_ce_6: 2.229  loss_mask_6: 0.6234  loss_dice_6: 3.416  loss_ce_7: 2.217  loss_mask_7: 0.6235  loss_dice_7: 3.416  loss_ce_8: 2.218  loss_mask_8: 0.6233  loss_dice_8: 3.417  time: 1.6979  data_time: 0.3228  lr: 7.58e-06  max_mem: 17674M
[01/19 06:10:13] d2.utils.events INFO:  eta: 13:42:32  iter: 10619  total_loss: 66.43  loss_ce: 2.394  loss_mask: 0.6365  loss_dice: 3.399  loss_ce_0: 3.698  loss_mask_0: 0.6545  loss_dice_0: 3.669  loss_ce_1: 2.54  loss_mask_1: 0.646  loss_dice_1: 3.552  loss_ce_2: 2.417  loss_mask_2: 0.6421  loss_dice_2: 3.47  loss_ce_3: 2.416  loss_mask_3: 0.64  loss_dice_3: 3.423  loss_ce_4: 2.388  loss_mask_4: 0.6391  loss_dice_4: 3.425  loss_ce_5: 2.393  loss_mask_5: 0.6347  loss_dice_5: 3.425  loss_ce_6: 2.395  loss_mask_6: 0.6389  loss_dice_6: 3.403  loss_ce_7: 2.405  loss_mask_7: 0.6358  loss_dice_7: 3.405  loss_ce_8: 2.4  loss_mask_8: 0.6375  loss_dice_8: 3.4  time: 1.6978  data_time: 0.3386  lr: 7.5754e-06  max_mem: 17674M
[01/19 06:10:47] d2.utils.events INFO:  eta: 13:41:53  iter: 10639  total_loss: 66.5  loss_ce: 2.395  loss_mask: 0.6209  loss_dice: 3.416  loss_ce_0: 3.756  loss_mask_0: 0.6447  loss_dice_0: 3.693  loss_ce_1: 2.544  loss_mask_1: 0.6388  loss_dice_1: 3.574  loss_ce_2: 2.436  loss_mask_2: 0.6332  loss_dice_2: 3.498  loss_ce_3: 2.453  loss_mask_3: 0.6239  loss_dice_3: 3.443  loss_ce_4: 2.405  loss_mask_4: 0.6247  loss_dice_4: 3.439  loss_ce_5: 2.395  loss_mask_5: 0.623  loss_dice_5: 3.434  loss_ce_6: 2.394  loss_mask_6: 0.6218  loss_dice_6: 3.422  loss_ce_7: 2.387  loss_mask_7: 0.6199  loss_dice_7: 3.418  loss_ce_8: 2.393  loss_mask_8: 0.6213  loss_dice_8: 3.424  time: 1.6978  data_time: 0.3394  lr: 7.5708e-06  max_mem: 17674M
[01/19 06:11:20] d2.utils.events INFO:  eta: 13:41:08  iter: 10659  total_loss: 65.89  loss_ce: 2.283  loss_mask: 0.6201  loss_dice: 3.389  loss_ce_0: 3.709  loss_mask_0: 0.6456  loss_dice_0: 3.669  loss_ce_1: 2.467  loss_mask_1: 0.6381  loss_dice_1: 3.539  loss_ce_2: 2.357  loss_mask_2: 0.631  loss_dice_2: 3.459  loss_ce_3: 2.331  loss_mask_3: 0.6256  loss_dice_3: 3.414  loss_ce_4: 2.311  loss_mask_4: 0.6263  loss_dice_4: 3.403  loss_ce_5: 2.282  loss_mask_5: 0.6256  loss_dice_5: 3.402  loss_ce_6: 2.293  loss_mask_6: 0.6253  loss_dice_6: 3.395  loss_ce_7: 2.275  loss_mask_7: 0.623  loss_dice_7: 3.4  loss_ce_8: 2.301  loss_mask_8: 0.6214  loss_dice_8: 3.398  time: 1.6978  data_time: 0.3322  lr: 7.5661e-06  max_mem: 17674M
[01/19 06:11:54] d2.utils.events INFO:  eta: 13:40:46  iter: 10679  total_loss: 66.5  loss_ce: 2.354  loss_mask: 0.6237  loss_dice: 3.437  loss_ce_0: 3.767  loss_mask_0: 0.6466  loss_dice_0: 3.676  loss_ce_1: 2.509  loss_mask_1: 0.6342  loss_dice_1: 3.582  loss_ce_2: 2.422  loss_mask_2: 0.6309  loss_dice_2: 3.502  loss_ce_3: 2.399  loss_mask_3: 0.6256  loss_dice_3: 3.463  loss_ce_4: 2.384  loss_mask_4: 0.6257  loss_dice_4: 3.458  loss_ce_5: 2.378  loss_mask_5: 0.6248  loss_dice_5: 3.448  loss_ce_6: 2.367  loss_mask_6: 0.6237  loss_dice_6: 3.432  loss_ce_7: 2.36  loss_mask_7: 0.6258  loss_dice_7: 3.43  loss_ce_8: 2.364  loss_mask_8: 0.6249  loss_dice_8: 3.434  time: 1.6977  data_time: 0.3390  lr: 7.5615e-06  max_mem: 17674M
[01/19 06:12:27] d2.utils.events INFO:  eta: 13:39:22  iter: 10699  total_loss: 66.91  loss_ce: 2.443  loss_mask: 0.6353  loss_dice: 3.376  loss_ce_0: 3.768  loss_mask_0: 0.6553  loss_dice_0: 3.669  loss_ce_1: 2.642  loss_mask_1: 0.6525  loss_dice_1: 3.524  loss_ce_2: 2.499  loss_mask_2: 0.6457  loss_dice_2: 3.449  loss_ce_3: 2.484  loss_mask_3: 0.6394  loss_dice_3: 3.413  loss_ce_4: 2.454  loss_mask_4: 0.6395  loss_dice_4: 3.402  loss_ce_5: 2.431  loss_mask_5: 0.6382  loss_dice_5: 3.398  loss_ce_6: 2.466  loss_mask_6: 0.6361  loss_dice_6: 3.383  loss_ce_7: 2.457  loss_mask_7: 0.6371  loss_dice_7: 3.386  loss_ce_8: 2.444  loss_mask_8: 0.6359  loss_dice_8: 3.384  time: 1.6977  data_time: 0.3502  lr: 7.5568e-06  max_mem: 17674M
[01/19 06:13:01] d2.utils.events INFO:  eta: 13:38:49  iter: 10719  total_loss: 66.26  loss_ce: 2.393  loss_mask: 0.6101  loss_dice: 3.405  loss_ce_0: 3.817  loss_mask_0: 0.6437  loss_dice_0: 3.673  loss_ce_1: 2.537  loss_mask_1: 0.629  loss_dice_1: 3.543  loss_ce_2: 2.435  loss_mask_2: 0.6136  loss_dice_2: 3.485  loss_ce_3: 2.439  loss_mask_3: 0.6115  loss_dice_3: 3.43  loss_ce_4: 2.399  loss_mask_4: 0.6122  loss_dice_4: 3.43  loss_ce_5: 2.376  loss_mask_5: 0.6113  loss_dice_5: 3.42  loss_ce_6: 2.389  loss_mask_6: 0.6091  loss_dice_6: 3.409  loss_ce_7: 2.363  loss_mask_7: 0.6074  loss_dice_7: 3.409  loss_ce_8: 2.364  loss_mask_8: 0.6111  loss_dice_8: 3.398  time: 1.6976  data_time: 0.3580  lr: 7.5522e-06  max_mem: 17674M
[01/19 06:13:35] d2.utils.events INFO:  eta: 13:38:41  iter: 10739  total_loss: 65.27  loss_ce: 2.24  loss_mask: 0.616  loss_dice: 3.371  loss_ce_0: 3.758  loss_mask_0: 0.6418  loss_dice_0: 3.665  loss_ce_1: 2.5  loss_mask_1: 0.626  loss_dice_1: 3.531  loss_ce_2: 2.362  loss_mask_2: 0.6188  loss_dice_2: 3.451  loss_ce_3: 2.307  loss_mask_3: 0.6149  loss_dice_3: 3.401  loss_ce_4: 2.286  loss_mask_4: 0.6131  loss_dice_4: 3.398  loss_ce_5: 2.248  loss_mask_5: 0.6159  loss_dice_5: 3.397  loss_ce_6: 2.264  loss_mask_6: 0.6149  loss_dice_6: 3.379  loss_ce_7: 2.239  loss_mask_7: 0.6141  loss_dice_7: 3.376  loss_ce_8: 2.228  loss_mask_8: 0.615  loss_dice_8: 3.38  time: 1.6976  data_time: 0.3419  lr: 7.5476e-06  max_mem: 17674M
[01/19 06:14:09] d2.utils.events INFO:  eta: 13:38:12  iter: 10759  total_loss: 66.14  loss_ce: 2.265  loss_mask: 0.6229  loss_dice: 3.464  loss_ce_0: 3.752  loss_mask_0: 0.6436  loss_dice_0: 3.718  loss_ce_1: 2.434  loss_mask_1: 0.6346  loss_dice_1: 3.599  loss_ce_2: 2.339  loss_mask_2: 0.6277  loss_dice_2: 3.52  loss_ce_3: 2.33  loss_mask_3: 0.6246  loss_dice_3: 3.472  loss_ce_4: 2.281  loss_mask_4: 0.6274  loss_dice_4: 3.47  loss_ce_5: 2.269  loss_mask_5: 0.6303  loss_dice_5: 3.472  loss_ce_6: 2.277  loss_mask_6: 0.629  loss_dice_6: 3.464  loss_ce_7: 2.257  loss_mask_7: 0.6255  loss_dice_7: 3.464  loss_ce_8: 2.265  loss_mask_8: 0.6256  loss_dice_8: 3.464  time: 1.6976  data_time: 0.3436  lr: 7.5429e-06  max_mem: 17674M
[01/19 06:14:42] d2.utils.events INFO:  eta: 13:37:33  iter: 10779  total_loss: 66.21  loss_ce: 2.333  loss_mask: 0.6164  loss_dice: 3.423  loss_ce_0: 3.741  loss_mask_0: 0.6548  loss_dice_0: 3.694  loss_ce_1: 2.529  loss_mask_1: 0.6377  loss_dice_1: 3.561  loss_ce_2: 2.397  loss_mask_2: 0.6311  loss_dice_2: 3.488  loss_ce_3: 2.378  loss_mask_3: 0.6236  loss_dice_3: 3.442  loss_ce_4: 2.357  loss_mask_4: 0.6251  loss_dice_4: 3.442  loss_ce_5: 2.349  loss_mask_5: 0.6222  loss_dice_5: 3.438  loss_ce_6: 2.339  loss_mask_6: 0.621  loss_dice_6: 3.429  loss_ce_7: 2.323  loss_mask_7: 0.6212  loss_dice_7: 3.423  loss_ce_8: 2.327  loss_mask_8: 0.621  loss_dice_8: 3.419  time: 1.6976  data_time: 0.3368  lr: 7.5383e-06  max_mem: 17674M
[01/19 06:15:16] d2.utils.events INFO:  eta: 13:37:05  iter: 10799  total_loss: 66.46  loss_ce: 2.404  loss_mask: 0.6393  loss_dice: 3.405  loss_ce_0: 3.718  loss_mask_0: 0.6473  loss_dice_0: 3.675  loss_ce_1: 2.563  loss_mask_1: 0.6449  loss_dice_1: 3.548  loss_ce_2: 2.457  loss_mask_2: 0.6396  loss_dice_2: 3.474  loss_ce_3: 2.416  loss_mask_3: 0.6429  loss_dice_3: 3.433  loss_ce_4: 2.379  loss_mask_4: 0.639  loss_dice_4: 3.43  loss_ce_5: 2.392  loss_mask_5: 0.6387  loss_dice_5: 3.419  loss_ce_6: 2.401  loss_mask_6: 0.6399  loss_dice_6: 3.404  loss_ce_7: 2.364  loss_mask_7: 0.6403  loss_dice_7: 3.414  loss_ce_8: 2.386  loss_mask_8: 0.6392  loss_dice_8: 3.406  time: 1.6975  data_time: 0.3272  lr: 7.5336e-06  max_mem: 17674M
[01/19 06:15:49] d2.utils.events INFO:  eta: 13:36:31  iter: 10819  total_loss: 66.45  loss_ce: 2.452  loss_mask: 0.6415  loss_dice: 3.367  loss_ce_0: 3.695  loss_mask_0: 0.6716  loss_dice_0: 3.666  loss_ce_1: 2.568  loss_mask_1: 0.6562  loss_dice_1: 3.513  loss_ce_2: 2.469  loss_mask_2: 0.6494  loss_dice_2: 3.439  loss_ce_3: 2.463  loss_mask_3: 0.6431  loss_dice_3: 3.402  loss_ce_4: 2.429  loss_mask_4: 0.6418  loss_dice_4: 3.387  loss_ce_5: 2.426  loss_mask_5: 0.6413  loss_dice_5: 3.389  loss_ce_6: 2.439  loss_mask_6: 0.6427  loss_dice_6: 3.374  loss_ce_7: 2.431  loss_mask_7: 0.6421  loss_dice_7: 3.374  loss_ce_8: 2.439  loss_mask_8: 0.6439  loss_dice_8: 3.373  time: 1.6974  data_time: 0.3603  lr: 7.529e-06  max_mem: 17674M
[01/19 06:16:23] d2.utils.events INFO:  eta: 13:36:23  iter: 10839  total_loss: 66.38  loss_ce: 2.236  loss_mask: 0.6293  loss_dice: 3.45  loss_ce_0: 3.722  loss_mask_0: 0.6418  loss_dice_0: 3.702  loss_ce_1: 2.43  loss_mask_1: 0.6387  loss_dice_1: 3.588  loss_ce_2: 2.326  loss_mask_2: 0.6352  loss_dice_2: 3.51  loss_ce_3: 2.308  loss_mask_3: 0.6324  loss_dice_3: 3.468  loss_ce_4: 2.271  loss_mask_4: 0.6302  loss_dice_4: 3.466  loss_ce_5: 2.261  loss_mask_5: 0.6302  loss_dice_5: 3.46  loss_ce_6: 2.269  loss_mask_6: 0.6295  loss_dice_6: 3.454  loss_ce_7: 2.231  loss_mask_7: 0.6293  loss_dice_7: 3.456  loss_ce_8: 2.231  loss_mask_8: 0.6301  loss_dice_8: 3.458  time: 1.6975  data_time: 0.3417  lr: 7.5243e-06  max_mem: 17674M
[01/19 06:16:57] d2.utils.events INFO:  eta: 13:35:46  iter: 10859  total_loss: 65.94  loss_ce: 2.365  loss_mask: 0.6403  loss_dice: 3.365  loss_ce_0: 3.705  loss_mask_0: 0.6617  loss_dice_0: 3.646  loss_ce_1: 2.492  loss_mask_1: 0.6526  loss_dice_1: 3.509  loss_ce_2: 2.41  loss_mask_2: 0.6434  loss_dice_2: 3.433  loss_ce_3: 2.408  loss_mask_3: 0.6342  loss_dice_3: 3.386  loss_ce_4: 2.385  loss_mask_4: 0.637  loss_dice_4: 3.381  loss_ce_5: 2.372  loss_mask_5: 0.6384  loss_dice_5: 3.38  loss_ce_6: 2.374  loss_mask_6: 0.639  loss_dice_6: 3.37  loss_ce_7: 2.376  loss_mask_7: 0.6385  loss_dice_7: 3.376  loss_ce_8: 2.357  loss_mask_8: 0.6371  loss_dice_8: 3.363  time: 1.6974  data_time: 0.3360  lr: 7.5197e-06  max_mem: 17674M
[01/19 06:17:30] d2.utils.events INFO:  eta: 13:35:13  iter: 10879  total_loss: 65.73  loss_ce: 2.353  loss_mask: 0.6331  loss_dice: 3.403  loss_ce_0: 3.64  loss_mask_0: 0.6589  loss_dice_0: 3.691  loss_ce_1: 2.53  loss_mask_1: 0.6457  loss_dice_1: 3.551  loss_ce_2: 2.403  loss_mask_2: 0.6369  loss_dice_2: 3.484  loss_ce_3: 2.385  loss_mask_3: 0.6353  loss_dice_3: 3.428  loss_ce_4: 2.358  loss_mask_4: 0.6359  loss_dice_4: 3.423  loss_ce_5: 2.353  loss_mask_5: 0.6348  loss_dice_5: 3.42  loss_ce_6: 2.361  loss_mask_6: 0.634  loss_dice_6: 3.41  loss_ce_7: 2.343  loss_mask_7: 0.6338  loss_dice_7: 3.409  loss_ce_8: 2.335  loss_mask_8: 0.6349  loss_dice_8: 3.407  time: 1.6974  data_time: 0.3367  lr: 7.515e-06  max_mem: 17674M
[01/19 06:18:04] d2.utils.events INFO:  eta: 13:34:39  iter: 10899  total_loss: 67.11  loss_ce: 2.438  loss_mask: 0.6314  loss_dice: 3.392  loss_ce_0: 3.798  loss_mask_0: 0.6636  loss_dice_0: 3.672  loss_ce_1: 2.608  loss_mask_1: 0.6469  loss_dice_1: 3.533  loss_ce_2: 2.506  loss_mask_2: 0.6424  loss_dice_2: 3.455  loss_ce_3: 2.482  loss_mask_3: 0.6343  loss_dice_3: 3.412  loss_ce_4: 2.458  loss_mask_4: 0.6356  loss_dice_4: 3.404  loss_ce_5: 2.44  loss_mask_5: 0.6353  loss_dice_5: 3.409  loss_ce_6: 2.448  loss_mask_6: 0.6355  loss_dice_6: 3.401  loss_ce_7: 2.439  loss_mask_7: 0.6374  loss_dice_7: 3.396  loss_ce_8: 2.456  loss_mask_8: 0.6336  loss_dice_8: 3.391  time: 1.6973  data_time: 0.3362  lr: 7.5104e-06  max_mem: 17674M
[01/19 06:18:37] d2.utils.events INFO:  eta: 13:34:05  iter: 10919  total_loss: 65.08  loss_ce: 2.224  loss_mask: 0.6192  loss_dice: 3.455  loss_ce_0: 3.754  loss_mask_0: 0.6318  loss_dice_0: 3.715  loss_ce_1: 2.425  loss_mask_1: 0.6334  loss_dice_1: 3.588  loss_ce_2: 2.292  loss_mask_2: 0.6252  loss_dice_2: 3.523  loss_ce_3: 2.271  loss_mask_3: 0.6189  loss_dice_3: 3.486  loss_ce_4: 2.272  loss_mask_4: 0.62  loss_dice_4: 3.484  loss_ce_5: 2.244  loss_mask_5: 0.6217  loss_dice_5: 3.475  loss_ce_6: 2.245  loss_mask_6: 0.6201  loss_dice_6: 3.466  loss_ce_7: 2.217  loss_mask_7: 0.6188  loss_dice_7: 3.459  loss_ce_8: 2.227  loss_mask_8: 0.6229  loss_dice_8: 3.459  time: 1.6973  data_time: 0.3370  lr: 7.5058e-06  max_mem: 17674M
[01/19 06:19:12] d2.utils.events INFO:  eta: 13:33:43  iter: 10939  total_loss: 65.6  loss_ce: 2.303  loss_mask: 0.6148  loss_dice: 3.436  loss_ce_0: 3.673  loss_mask_0: 0.629  loss_dice_0: 3.715  loss_ce_1: 2.481  loss_mask_1: 0.623  loss_dice_1: 3.589  loss_ce_2: 2.359  loss_mask_2: 0.6168  loss_dice_2: 3.511  loss_ce_3: 2.333  loss_mask_3: 0.6149  loss_dice_3: 3.47  loss_ce_4: 2.314  loss_mask_4: 0.6163  loss_dice_4: 3.459  loss_ce_5: 2.311  loss_mask_5: 0.6146  loss_dice_5: 3.457  loss_ce_6: 2.317  loss_mask_6: 0.6148  loss_dice_6: 3.44  loss_ce_7: 2.3  loss_mask_7: 0.6153  loss_dice_7: 3.442  loss_ce_8: 2.29  loss_mask_8: 0.6146  loss_dice_8: 3.44  time: 1.6973  data_time: 0.3493  lr: 7.5011e-06  max_mem: 17674M
[01/19 06:19:45] d2.utils.events INFO:  eta: 13:33:10  iter: 10959  total_loss: 65.47  loss_ce: 2.273  loss_mask: 0.6281  loss_dice: 3.424  loss_ce_0: 3.78  loss_mask_0: 0.649  loss_dice_0: 3.698  loss_ce_1: 2.482  loss_mask_1: 0.6389  loss_dice_1: 3.58  loss_ce_2: 2.305  loss_mask_2: 0.6344  loss_dice_2: 3.506  loss_ce_3: 2.288  loss_mask_3: 0.6267  loss_dice_3: 3.456  loss_ce_4: 2.269  loss_mask_4: 0.6277  loss_dice_4: 3.452  loss_ce_5: 2.247  loss_mask_5: 0.6271  loss_dice_5: 3.446  loss_ce_6: 2.257  loss_mask_6: 0.6284  loss_dice_6: 3.439  loss_ce_7: 2.246  loss_mask_7: 0.6299  loss_dice_7: 3.441  loss_ce_8: 2.253  loss_mask_8: 0.6285  loss_dice_8: 3.435  time: 1.6973  data_time: 0.3445  lr: 7.4965e-06  max_mem: 17674M
[01/19 06:20:19] d2.utils.events INFO:  eta: 13:32:40  iter: 10979  total_loss: 65.87  loss_ce: 2.322  loss_mask: 0.6345  loss_dice: 3.411  loss_ce_0: 3.757  loss_mask_0: 0.6514  loss_dice_0: 3.687  loss_ce_1: 2.427  loss_mask_1: 0.6459  loss_dice_1: 3.554  loss_ce_2: 2.342  loss_mask_2: 0.6384  loss_dice_2: 3.48  loss_ce_3: 2.363  loss_mask_3: 0.6329  loss_dice_3: 3.431  loss_ce_4: 2.316  loss_mask_4: 0.6325  loss_dice_4: 3.426  loss_ce_5: 2.32  loss_mask_5: 0.6331  loss_dice_5: 3.423  loss_ce_6: 2.32  loss_mask_6: 0.6341  loss_dice_6: 3.407  loss_ce_7: 2.317  loss_mask_7: 0.6359  loss_dice_7: 3.408  loss_ce_8: 2.309  loss_mask_8: 0.6362  loss_dice_8: 3.406  time: 1.6972  data_time: 0.3357  lr: 7.4918e-06  max_mem: 17674M
[01/19 06:20:54] d2.utils.events INFO:  eta: 13:32:48  iter: 10999  total_loss: 65.86  loss_ce: 2.298  loss_mask: 0.6125  loss_dice: 3.453  loss_ce_0: 3.766  loss_mask_0: 0.6411  loss_dice_0: 3.722  loss_ce_1: 2.449  loss_mask_1: 0.6316  loss_dice_1: 3.601  loss_ce_2: 2.342  loss_mask_2: 0.6248  loss_dice_2: 3.524  loss_ce_3: 2.33  loss_mask_3: 0.616  loss_dice_3: 3.477  loss_ce_4: 2.318  loss_mask_4: 0.6162  loss_dice_4: 3.468  loss_ce_5: 2.309  loss_mask_5: 0.6161  loss_dice_5: 3.462  loss_ce_6: 2.289  loss_mask_6: 0.6141  loss_dice_6: 3.455  loss_ce_7: 2.291  loss_mask_7: 0.6143  loss_dice_7: 3.455  loss_ce_8: 2.287  loss_mask_8: 0.6168  loss_dice_8: 3.457  time: 1.6973  data_time: 0.3530  lr: 7.4872e-06  max_mem: 17674M
[01/19 06:21:28] d2.utils.events INFO:  eta: 13:32:27  iter: 11019  total_loss: 65.08  loss_ce: 2.187  loss_mask: 0.628  loss_dice: 3.413  loss_ce_0: 3.689  loss_mask_0: 0.6487  loss_dice_0: 3.695  loss_ce_1: 2.362  loss_mask_1: 0.6419  loss_dice_1: 3.561  loss_ce_2: 2.251  loss_mask_2: 0.6355  loss_dice_2: 3.485  loss_ce_3: 2.225  loss_mask_3: 0.6292  loss_dice_3: 3.442  loss_ce_4: 2.192  loss_mask_4: 0.6278  loss_dice_4: 3.432  loss_ce_5: 2.185  loss_mask_5: 0.627  loss_dice_5: 3.428  loss_ce_6: 2.179  loss_mask_6: 0.6265  loss_dice_6: 3.42  loss_ce_7: 2.173  loss_mask_7: 0.6296  loss_dice_7: 3.411  loss_ce_8: 2.172  loss_mask_8: 0.6284  loss_dice_8: 3.411  time: 1.6973  data_time: 0.3537  lr: 7.4825e-06  max_mem: 17674M
[01/19 06:22:02] d2.utils.events INFO:  eta: 13:31:53  iter: 11039  total_loss: 65.42  loss_ce: 2.271  loss_mask: 0.6323  loss_dice: 3.408  loss_ce_0: 3.779  loss_mask_0: 0.6529  loss_dice_0: 3.664  loss_ce_1: 2.489  loss_mask_1: 0.6484  loss_dice_1: 3.548  loss_ce_2: 2.352  loss_mask_2: 0.6358  loss_dice_2: 3.48  loss_ce_3: 2.303  loss_mask_3: 0.6316  loss_dice_3: 3.433  loss_ce_4: 2.293  loss_mask_4: 0.6366  loss_dice_4: 3.424  loss_ce_5: 2.286  loss_mask_5: 0.6355  loss_dice_5: 3.417  loss_ce_6: 2.282  loss_mask_6: 0.6355  loss_dice_6: 3.406  loss_ce_7: 2.27  loss_mask_7: 0.6332  loss_dice_7: 3.409  loss_ce_8: 2.26  loss_mask_8: 0.6349  loss_dice_8: 3.413  time: 1.6973  data_time: 0.3536  lr: 7.4779e-06  max_mem: 17674M
[01/19 06:22:35] d2.utils.events INFO:  eta: 13:31:07  iter: 11059  total_loss: 65.38  loss_ce: 2.34  loss_mask: 0.6283  loss_dice: 3.347  loss_ce_0: 3.748  loss_mask_0: 0.6615  loss_dice_0: 3.65  loss_ce_1: 2.584  loss_mask_1: 0.6529  loss_dice_1: 3.502  loss_ce_2: 2.433  loss_mask_2: 0.6457  loss_dice_2: 3.42  loss_ce_3: 2.396  loss_mask_3: 0.6337  loss_dice_3: 3.365  loss_ce_4: 2.373  loss_mask_4: 0.6343  loss_dice_4: 3.366  loss_ce_5: 2.364  loss_mask_5: 0.6343  loss_dice_5: 3.358  loss_ce_6: 2.345  loss_mask_6: 0.6285  loss_dice_6: 3.351  loss_ce_7: 2.332  loss_mask_7: 0.6305  loss_dice_7: 3.349  loss_ce_8: 2.336  loss_mask_8: 0.6298  loss_dice_8: 3.348  time: 1.6973  data_time: 0.3428  lr: 7.4732e-06  max_mem: 17674M
[01/19 06:23:09] d2.utils.events INFO:  eta: 13:30:19  iter: 11079  total_loss: 65.43  loss_ce: 2.301  loss_mask: 0.6259  loss_dice: 3.422  loss_ce_0: 3.693  loss_mask_0: 0.6406  loss_dice_0: 3.678  loss_ce_1: 2.473  loss_mask_1: 0.6416  loss_dice_1: 3.555  loss_ce_2: 2.386  loss_mask_2: 0.6333  loss_dice_2: 3.476  loss_ce_3: 2.332  loss_mask_3: 0.624  loss_dice_3: 3.439  loss_ce_4: 2.306  loss_mask_4: 0.627  loss_dice_4: 3.435  loss_ce_5: 2.295  loss_mask_5: 0.6289  loss_dice_5: 3.433  loss_ce_6: 2.306  loss_mask_6: 0.6246  loss_dice_6: 3.425  loss_ce_7: 2.291  loss_mask_7: 0.6289  loss_dice_7: 3.427  loss_ce_8: 2.272  loss_mask_8: 0.6264  loss_dice_8: 3.423  time: 1.6972  data_time: 0.3367  lr: 7.4686e-06  max_mem: 17674M
[01/19 06:23:43] d2.utils.events INFO:  eta: 13:29:56  iter: 11099  total_loss: 65.62  loss_ce: 2.271  loss_mask: 0.6311  loss_dice: 3.42  loss_ce_0: 3.678  loss_mask_0: 0.6479  loss_dice_0: 3.689  loss_ce_1: 2.432  loss_mask_1: 0.6386  loss_dice_1: 3.553  loss_ce_2: 2.332  loss_mask_2: 0.633  loss_dice_2: 3.496  loss_ce_3: 2.306  loss_mask_3: 0.6304  loss_dice_3: 3.45  loss_ce_4: 2.283  loss_mask_4: 0.6306  loss_dice_4: 3.443  loss_ce_5: 2.262  loss_mask_5: 0.6346  loss_dice_5: 3.436  loss_ce_6: 2.252  loss_mask_6: 0.6319  loss_dice_6: 3.43  loss_ce_7: 2.244  loss_mask_7: 0.6325  loss_dice_7: 3.426  loss_ce_8: 2.255  loss_mask_8: 0.6304  loss_dice_8: 3.419  time: 1.6972  data_time: 0.3335  lr: 7.4639e-06  max_mem: 17674M
[01/19 06:24:16] d2.utils.events INFO:  eta: 13:29:42  iter: 11119  total_loss: 65.25  loss_ce: 2.305  loss_mask: 0.6213  loss_dice: 3.367  loss_ce_0: 3.717  loss_mask_0: 0.6468  loss_dice_0: 3.668  loss_ce_1: 2.522  loss_mask_1: 0.6425  loss_dice_1: 3.511  loss_ce_2: 2.392  loss_mask_2: 0.6347  loss_dice_2: 3.441  loss_ce_3: 2.359  loss_mask_3: 0.6255  loss_dice_3: 3.392  loss_ce_4: 2.325  loss_mask_4: 0.6269  loss_dice_4: 3.385  loss_ce_5: 2.311  loss_mask_5: 0.6245  loss_dice_5: 3.383  loss_ce_6: 2.321  loss_mask_6: 0.6225  loss_dice_6: 3.371  loss_ce_7: 2.299  loss_mask_7: 0.6219  loss_dice_7: 3.372  loss_ce_8: 2.296  loss_mask_8: 0.6207  loss_dice_8: 3.377  time: 1.6972  data_time: 0.3521  lr: 7.4593e-06  max_mem: 17674M
[01/19 06:24:50] d2.utils.events INFO:  eta: 13:29:07  iter: 11139  total_loss: 66.66  loss_ce: 2.37  loss_mask: 0.6416  loss_dice: 3.376  loss_ce_0: 3.768  loss_mask_0: 0.6642  loss_dice_0: 3.634  loss_ce_1: 2.565  loss_mask_1: 0.6542  loss_dice_1: 3.534  loss_ce_2: 2.462  loss_mask_2: 0.6494  loss_dice_2: 3.442  loss_ce_3: 2.419  loss_mask_3: 0.6442  loss_dice_3: 3.409  loss_ce_4: 2.384  loss_mask_4: 0.6419  loss_dice_4: 3.404  loss_ce_5: 2.381  loss_mask_5: 0.6432  loss_dice_5: 3.405  loss_ce_6: 2.366  loss_mask_6: 0.6425  loss_dice_6: 3.389  loss_ce_7: 2.385  loss_mask_7: 0.6437  loss_dice_7: 3.391  loss_ce_8: 2.378  loss_mask_8: 0.6446  loss_dice_8: 3.381  time: 1.6971  data_time: 0.3311  lr: 7.4546e-06  max_mem: 17674M
[01/19 06:25:24] d2.utils.events INFO:  eta: 13:28:38  iter: 11159  total_loss: 65.19  loss_ce: 2.228  loss_mask: 0.6264  loss_dice: 3.417  loss_ce_0: 3.74  loss_mask_0: 0.6561  loss_dice_0: 3.687  loss_ce_1: 2.476  loss_mask_1: 0.6471  loss_dice_1: 3.565  loss_ce_2: 2.347  loss_mask_2: 0.6394  loss_dice_2: 3.487  loss_ce_3: 2.297  loss_mask_3: 0.6313  loss_dice_3: 3.442  loss_ce_4: 2.27  loss_mask_4: 0.6321  loss_dice_4: 3.436  loss_ce_5: 2.283  loss_mask_5: 0.6324  loss_dice_5: 3.433  loss_ce_6: 2.244  loss_mask_6: 0.6295  loss_dice_6: 3.412  loss_ce_7: 2.242  loss_mask_7: 0.6272  loss_dice_7: 3.417  loss_ce_8: 2.24  loss_mask_8: 0.6267  loss_dice_8: 3.417  time: 1.6971  data_time: 0.3319  lr: 7.45e-06  max_mem: 17674M
[01/19 06:25:57] d2.utils.events INFO:  eta: 13:27:57  iter: 11179  total_loss: 65.37  loss_ce: 2.28  loss_mask: 0.6162  loss_dice: 3.391  loss_ce_0: 3.711  loss_mask_0: 0.6428  loss_dice_0: 3.67  loss_ce_1: 2.476  loss_mask_1: 0.6295  loss_dice_1: 3.536  loss_ce_2: 2.381  loss_mask_2: 0.6242  loss_dice_2: 3.457  loss_ce_3: 2.336  loss_mask_3: 0.6188  loss_dice_3: 3.419  loss_ce_4: 2.333  loss_mask_4: 0.6177  loss_dice_4: 3.407  loss_ce_5: 2.306  loss_mask_5: 0.6171  loss_dice_5: 3.41  loss_ce_6: 2.292  loss_mask_6: 0.6158  loss_dice_6: 3.396  loss_ce_7: 2.283  loss_mask_7: 0.6126  loss_dice_7: 3.393  loss_ce_8: 2.284  loss_mask_8: 0.6145  loss_dice_8: 3.394  time: 1.6971  data_time: 0.3410  lr: 7.4453e-06  max_mem: 17674M
[01/19 06:26:31] d2.utils.events INFO:  eta: 13:27:26  iter: 11199  total_loss: 66.08  loss_ce: 2.362  loss_mask: 0.6363  loss_dice: 3.379  loss_ce_0: 3.746  loss_mask_0: 0.6585  loss_dice_0: 3.667  loss_ce_1: 2.523  loss_mask_1: 0.6489  loss_dice_1: 3.536  loss_ce_2: 2.421  loss_mask_2: 0.635  loss_dice_2: 3.46  loss_ce_3: 2.413  loss_mask_3: 0.6338  loss_dice_3: 3.409  loss_ce_4: 2.379  loss_mask_4: 0.6375  loss_dice_4: 3.401  loss_ce_5: 2.371  loss_mask_5: 0.6343  loss_dice_5: 3.394  loss_ce_6: 2.35  loss_mask_6: 0.6373  loss_dice_6: 3.381  loss_ce_7: 2.337  loss_mask_7: 0.6403  loss_dice_7: 3.386  loss_ce_8: 2.334  loss_mask_8: 0.6388  loss_dice_8: 3.38  time: 1.6970  data_time: 0.3454  lr: 7.4407e-06  max_mem: 17674M
[01/19 06:27:05] d2.utils.events INFO:  eta: 13:26:57  iter: 11219  total_loss: 65.04  loss_ce: 2.273  loss_mask: 0.6358  loss_dice: 3.392  loss_ce_0: 3.67  loss_mask_0: 0.6529  loss_dice_0: 3.652  loss_ce_1: 2.443  loss_mask_1: 0.6513  loss_dice_1: 3.532  loss_ce_2: 2.357  loss_mask_2: 0.6409  loss_dice_2: 3.455  loss_ce_3: 2.343  loss_mask_3: 0.6385  loss_dice_3: 3.409  loss_ce_4: 2.29  loss_mask_4: 0.6393  loss_dice_4: 3.406  loss_ce_5: 2.276  loss_mask_5: 0.6366  loss_dice_5: 3.401  loss_ce_6: 2.276  loss_mask_6: 0.6394  loss_dice_6: 3.398  loss_ce_7: 2.285  loss_mask_7: 0.6353  loss_dice_7: 3.393  loss_ce_8: 2.273  loss_mask_8: 0.6373  loss_dice_8: 3.389  time: 1.6970  data_time: 0.3440  lr: 7.436e-06  max_mem: 17674M
[01/19 06:27:39] d2.utils.events INFO:  eta: 13:26:37  iter: 11239  total_loss: 65.1  loss_ce: 2.259  loss_mask: 0.6321  loss_dice: 3.396  loss_ce_0: 3.669  loss_mask_0: 0.6454  loss_dice_0: 3.688  loss_ce_1: 2.441  loss_mask_1: 0.6398  loss_dice_1: 3.543  loss_ce_2: 2.315  loss_mask_2: 0.6345  loss_dice_2: 3.47  loss_ce_3: 2.285  loss_mask_3: 0.6317  loss_dice_3: 3.428  loss_ce_4: 2.271  loss_mask_4: 0.6345  loss_dice_4: 3.418  loss_ce_5: 2.256  loss_mask_5: 0.6336  loss_dice_5: 3.415  loss_ce_6: 2.264  loss_mask_6: 0.6317  loss_dice_6: 3.402  loss_ce_7: 2.257  loss_mask_7: 0.6305  loss_dice_7: 3.406  loss_ce_8: 2.242  loss_mask_8: 0.631  loss_dice_8: 3.406  time: 1.6970  data_time: 0.3550  lr: 7.4314e-06  max_mem: 17674M
[01/19 06:28:13] d2.utils.events INFO:  eta: 13:26:15  iter: 11259  total_loss: 65.39  loss_ce: 2.228  loss_mask: 0.6284  loss_dice: 3.407  loss_ce_0: 3.699  loss_mask_0: 0.6476  loss_dice_0: 3.687  loss_ce_1: 2.445  loss_mask_1: 0.6347  loss_dice_1: 3.561  loss_ce_2: 2.353  loss_mask_2: 0.635  loss_dice_2: 3.481  loss_ce_3: 2.294  loss_mask_3: 0.6325  loss_dice_3: 3.432  loss_ce_4: 2.265  loss_mask_4: 0.6291  loss_dice_4: 3.426  loss_ce_5: 2.226  loss_mask_5: 0.6306  loss_dice_5: 3.423  loss_ce_6: 2.263  loss_mask_6: 0.6312  loss_dice_6: 3.404  loss_ce_7: 2.228  loss_mask_7: 0.6288  loss_dice_7: 3.413  loss_ce_8: 2.234  loss_mask_8: 0.63  loss_dice_8: 3.408  time: 1.6970  data_time: 0.3507  lr: 7.4267e-06  max_mem: 17674M
[01/19 06:28:47] d2.utils.events INFO:  eta: 13:25:45  iter: 11279  total_loss: 65.89  loss_ce: 2.32  loss_mask: 0.6332  loss_dice: 3.413  loss_ce_0: 3.79  loss_mask_0: 0.6566  loss_dice_0: 3.673  loss_ce_1: 2.453  loss_mask_1: 0.6577  loss_dice_1: 3.564  loss_ce_2: 2.385  loss_mask_2: 0.6447  loss_dice_2: 3.483  loss_ce_3: 2.357  loss_mask_3: 0.6374  loss_dice_3: 3.436  loss_ce_4: 2.332  loss_mask_4: 0.6351  loss_dice_4: 3.431  loss_ce_5: 2.322  loss_mask_5: 0.6356  loss_dice_5: 3.433  loss_ce_6: 2.33  loss_mask_6: 0.6331  loss_dice_6: 3.413  loss_ce_7: 2.328  loss_mask_7: 0.6359  loss_dice_7: 3.414  loss_ce_8: 2.312  loss_mask_8: 0.6338  loss_dice_8: 3.414  time: 1.6971  data_time: 0.3447  lr: 7.4221e-06  max_mem: 17674M
[01/19 06:29:21] d2.utils.events INFO:  eta: 13:25:11  iter: 11299  total_loss: 66.26  loss_ce: 2.335  loss_mask: 0.6357  loss_dice: 3.379  loss_ce_0: 3.727  loss_mask_0: 0.6595  loss_dice_0: 3.651  loss_ce_1: 2.516  loss_mask_1: 0.6498  loss_dice_1: 3.532  loss_ce_2: 2.4  loss_mask_2: 0.6386  loss_dice_2: 3.456  loss_ce_3: 2.384  loss_mask_3: 0.6331  loss_dice_3: 3.407  loss_ce_4: 2.357  loss_mask_4: 0.6344  loss_dice_4: 3.404  loss_ce_5: 2.336  loss_mask_5: 0.6334  loss_dice_5: 3.4  loss_ce_6: 2.354  loss_mask_6: 0.6356  loss_dice_6: 3.389  loss_ce_7: 2.342  loss_mask_7: 0.6367  loss_dice_7: 3.389  loss_ce_8: 2.32  loss_mask_8: 0.6369  loss_dice_8: 3.387  time: 1.6971  data_time: 0.3440  lr: 7.4174e-06  max_mem: 17674M
[01/19 06:29:55] d2.utils.events INFO:  eta: 13:24:35  iter: 11319  total_loss: 65.74  loss_ce: 2.301  loss_mask: 0.6353  loss_dice: 3.392  loss_ce_0: 3.734  loss_mask_0: 0.6546  loss_dice_0: 3.668  loss_ce_1: 2.476  loss_mask_1: 0.6475  loss_dice_1: 3.536  loss_ce_2: 2.382  loss_mask_2: 0.6379  loss_dice_2: 3.459  loss_ce_3: 2.329  loss_mask_3: 0.638  loss_dice_3: 3.418  loss_ce_4: 2.329  loss_mask_4: 0.6385  loss_dice_4: 3.401  loss_ce_5: 2.303  loss_mask_5: 0.6366  loss_dice_5: 3.402  loss_ce_6: 2.288  loss_mask_6: 0.6369  loss_dice_6: 3.392  loss_ce_7: 2.3  loss_mask_7: 0.6378  loss_dice_7: 3.394  loss_ce_8: 2.291  loss_mask_8: 0.6371  loss_dice_8: 3.384  time: 1.6970  data_time: 0.3351  lr: 7.4128e-06  max_mem: 17674M
[01/19 06:30:28] d2.utils.events INFO:  eta: 13:24:12  iter: 11339  total_loss: 65.3  loss_ce: 2.283  loss_mask: 0.6253  loss_dice: 3.354  loss_ce_0: 3.721  loss_mask_0: 0.6527  loss_dice_0: 3.647  loss_ce_1: 2.486  loss_mask_1: 0.6378  loss_dice_1: 3.488  loss_ce_2: 2.359  loss_mask_2: 0.6312  loss_dice_2: 3.417  loss_ce_3: 2.339  loss_mask_3: 0.6259  loss_dice_3: 3.368  loss_ce_4: 2.301  loss_mask_4: 0.6264  loss_dice_4: 3.365  loss_ce_5: 2.292  loss_mask_5: 0.6274  loss_dice_5: 3.36  loss_ce_6: 2.31  loss_mask_6: 0.6255  loss_dice_6: 3.349  loss_ce_7: 2.287  loss_mask_7: 0.6269  loss_dice_7: 3.358  loss_ce_8: 2.3  loss_mask_8: 0.6259  loss_dice_8: 3.351  time: 1.6970  data_time: 0.3316  lr: 7.4081e-06  max_mem: 17674M
[01/19 06:31:03] d2.utils.events INFO:  eta: 13:23:47  iter: 11359  total_loss: 64.81  loss_ce: 2.169  loss_mask: 0.6058  loss_dice: 3.439  loss_ce_0: 3.7  loss_mask_0: 0.6189  loss_dice_0: 3.715  loss_ce_1: 2.291  loss_mask_1: 0.6153  loss_dice_1: 3.594  loss_ce_2: 2.199  loss_mask_2: 0.6135  loss_dice_2: 3.508  loss_ce_3: 2.183  loss_mask_3: 0.6098  loss_dice_3: 3.457  loss_ce_4: 2.189  loss_mask_4: 0.6103  loss_dice_4: 3.447  loss_ce_5: 2.171  loss_mask_5: 0.61  loss_dice_5: 3.452  loss_ce_6: 2.175  loss_mask_6: 0.6087  loss_dice_6: 3.436  loss_ce_7: 2.178  loss_mask_7: 0.6084  loss_dice_7: 3.44  loss_ce_8: 2.175  loss_mask_8: 0.6051  loss_dice_8: 3.436  time: 1.6970  data_time: 0.3313  lr: 7.4035e-06  max_mem: 17674M
[01/19 06:31:37] d2.utils.events INFO:  eta: 13:23:29  iter: 11379  total_loss: 65.27  loss_ce: 2.245  loss_mask: 0.614  loss_dice: 3.45  loss_ce_0: 3.724  loss_mask_0: 0.6299  loss_dice_0: 3.716  loss_ce_1: 2.399  loss_mask_1: 0.6198  loss_dice_1: 3.611  loss_ce_2: 2.322  loss_mask_2: 0.6175  loss_dice_2: 3.525  loss_ce_3: 2.296  loss_mask_3: 0.6162  loss_dice_3: 3.479  loss_ce_4: 2.268  loss_mask_4: 0.6154  loss_dice_4: 3.463  loss_ce_5: 2.255  loss_mask_5: 0.618  loss_dice_5: 3.456  loss_ce_6: 2.253  loss_mask_6: 0.6147  loss_dice_6: 3.445  loss_ce_7: 2.241  loss_mask_7: 0.6153  loss_dice_7: 3.448  loss_ce_8: 2.24  loss_mask_8: 0.6159  loss_dice_8: 3.452  time: 1.6970  data_time: 0.3419  lr: 7.3988e-06  max_mem: 17674M
[01/19 06:32:11] d2.utils.events INFO:  eta: 13:22:31  iter: 11399  total_loss: 64.69  loss_ce: 2.275  loss_mask: 0.6354  loss_dice: 3.337  loss_ce_0: 3.702  loss_mask_0: 0.6576  loss_dice_0: 3.629  loss_ce_1: 2.489  loss_mask_1: 0.6472  loss_dice_1: 3.476  loss_ce_2: 2.374  loss_mask_2: 0.6403  loss_dice_2: 3.405  loss_ce_3: 2.33  loss_mask_3: 0.6334  loss_dice_3: 3.366  loss_ce_4: 2.313  loss_mask_4: 0.6357  loss_dice_4: 3.358  loss_ce_5: 2.307  loss_mask_5: 0.6364  loss_dice_5: 3.358  loss_ce_6: 2.294  loss_mask_6: 0.6327  loss_dice_6: 3.345  loss_ce_7: 2.284  loss_mask_7: 0.6356  loss_dice_7: 3.344  loss_ce_8: 2.294  loss_mask_8: 0.6316  loss_dice_8: 3.343  time: 1.6970  data_time: 0.3457  lr: 7.3942e-06  max_mem: 17674M
[01/19 06:32:44] d2.utils.events INFO:  eta: 13:21:49  iter: 11419  total_loss: 65.8  loss_ce: 2.289  loss_mask: 0.6514  loss_dice: 3.374  loss_ce_0: 3.685  loss_mask_0: 0.6681  loss_dice_0: 3.645  loss_ce_1: 2.463  loss_mask_1: 0.6645  loss_dice_1: 3.517  loss_ce_2: 2.358  loss_mask_2: 0.6564  loss_dice_2: 3.446  loss_ce_3: 2.325  loss_mask_3: 0.6522  loss_dice_3: 3.396  loss_ce_4: 2.321  loss_mask_4: 0.6528  loss_dice_4: 3.387  loss_ce_5: 2.299  loss_mask_5: 0.6522  loss_dice_5: 3.387  loss_ce_6: 2.276  loss_mask_6: 0.6521  loss_dice_6: 3.378  loss_ce_7: 2.283  loss_mask_7: 0.6498  loss_dice_7: 3.383  loss_ce_8: 2.288  loss_mask_8: 0.6537  loss_dice_8: 3.381  time: 1.6970  data_time: 0.3182  lr: 7.3895e-06  max_mem: 17674M
[01/19 06:33:18] d2.utils.events INFO:  eta: 13:21:19  iter: 11439  total_loss: 65.96  loss_ce: 2.26  loss_mask: 0.6266  loss_dice: 3.41  loss_ce_0: 3.719  loss_mask_0: 0.6488  loss_dice_0: 3.701  loss_ce_1: 2.45  loss_mask_1: 0.6352  loss_dice_1: 3.545  loss_ce_2: 2.345  loss_mask_2: 0.6326  loss_dice_2: 3.476  loss_ce_3: 2.305  loss_mask_3: 0.6247  loss_dice_3: 3.439  loss_ce_4: 2.267  loss_mask_4: 0.6295  loss_dice_4: 3.431  loss_ce_5: 2.258  loss_mask_5: 0.626  loss_dice_5: 3.427  loss_ce_6: 2.247  loss_mask_6: 0.6262  loss_dice_6: 3.419  loss_ce_7: 2.252  loss_mask_7: 0.6294  loss_dice_7: 3.415  loss_ce_8: 2.241  loss_mask_8: 0.6254  loss_dice_8: 3.415  time: 1.6970  data_time: 0.3360  lr: 7.3849e-06  max_mem: 17674M
[01/19 06:33:52] d2.utils.events INFO:  eta: 13:20:45  iter: 11459  total_loss: 65.63  loss_ce: 2.289  loss_mask: 0.6334  loss_dice: 3.39  loss_ce_0: 3.717  loss_mask_0: 0.6556  loss_dice_0: 3.655  loss_ce_1: 2.493  loss_mask_1: 0.6465  loss_dice_1: 3.545  loss_ce_2: 2.36  loss_mask_2: 0.6397  loss_dice_2: 3.462  loss_ce_3: 2.336  loss_mask_3: 0.6355  loss_dice_3: 3.411  loss_ce_4: 2.319  loss_mask_4: 0.6327  loss_dice_4: 3.408  loss_ce_5: 2.294  loss_mask_5: 0.6309  loss_dice_5: 3.407  loss_ce_6: 2.295  loss_mask_6: 0.6338  loss_dice_6: 3.391  loss_ce_7: 2.288  loss_mask_7: 0.6324  loss_dice_7: 3.391  loss_ce_8: 2.302  loss_mask_8: 0.6326  loss_dice_8: 3.39  time: 1.6969  data_time: 0.3475  lr: 7.3802e-06  max_mem: 17674M
[01/19 06:34:26] d2.utils.events INFO:  eta: 13:20:12  iter: 11479  total_loss: 65.21  loss_ce: 2.226  loss_mask: 0.6176  loss_dice: 3.428  loss_ce_0: 3.789  loss_mask_0: 0.6363  loss_dice_0: 3.677  loss_ce_1: 2.41  loss_mask_1: 0.6272  loss_dice_1: 3.557  loss_ce_2: 2.275  loss_mask_2: 0.6232  loss_dice_2: 3.484  loss_ce_3: 2.249  loss_mask_3: 0.6148  loss_dice_3: 3.448  loss_ce_4: 2.23  loss_mask_4: 0.6178  loss_dice_4: 3.444  loss_ce_5: 2.215  loss_mask_5: 0.6172  loss_dice_5: 3.439  loss_ce_6: 2.225  loss_mask_6: 0.6163  loss_dice_6: 3.426  loss_ce_7: 2.212  loss_mask_7: 0.6202  loss_dice_7: 3.433  loss_ce_8: 2.221  loss_mask_8: 0.6189  loss_dice_8: 3.435  time: 1.6969  data_time: 0.3412  lr: 7.3755e-06  max_mem: 17674M
[01/19 06:35:00] d2.utils.events INFO:  eta: 13:19:38  iter: 11499  total_loss: 64.92  loss_ce: 2.136  loss_mask: 0.6321  loss_dice: 3.418  loss_ce_0: 3.689  loss_mask_0: 0.6505  loss_dice_0: 3.672  loss_ce_1: 2.304  loss_mask_1: 0.6397  loss_dice_1: 3.551  loss_ce_2: 2.201  loss_mask_2: 0.633  loss_dice_2: 3.485  loss_ce_3: 2.196  loss_mask_3: 0.6322  loss_dice_3: 3.445  loss_ce_4: 2.159  loss_mask_4: 0.6331  loss_dice_4: 3.438  loss_ce_5: 2.166  loss_mask_5: 0.6336  loss_dice_5: 3.436  loss_ce_6: 2.165  loss_mask_6: 0.635  loss_dice_6: 3.423  loss_ce_7: 2.135  loss_mask_7: 0.6334  loss_dice_7: 3.424  loss_ce_8: 2.152  loss_mask_8: 0.6324  loss_dice_8: 3.422  time: 1.6969  data_time: 0.3376  lr: 7.3709e-06  max_mem: 17674M
[01/19 06:35:33] d2.utils.events INFO:  eta: 13:18:33  iter: 11519  total_loss: 64.73  loss_ce: 2.282  loss_mask: 0.6189  loss_dice: 3.358  loss_ce_0: 3.685  loss_mask_0: 0.6445  loss_dice_0: 3.653  loss_ce_1: 2.453  loss_mask_1: 0.637  loss_dice_1: 3.506  loss_ce_2: 2.323  loss_mask_2: 0.6289  loss_dice_2: 3.428  loss_ce_3: 2.298  loss_mask_3: 0.6218  loss_dice_3: 3.381  loss_ce_4: 2.273  loss_mask_4: 0.6207  loss_dice_4: 3.387  loss_ce_5: 2.252  loss_mask_5: 0.6204  loss_dice_5: 3.378  loss_ce_6: 2.253  loss_mask_6: 0.6211  loss_dice_6: 3.366  loss_ce_7: 2.263  loss_mask_7: 0.6218  loss_dice_7: 3.362  loss_ce_8: 2.264  loss_mask_8: 0.6194  loss_dice_8: 3.367  time: 1.6968  data_time: 0.3064  lr: 7.3662e-06  max_mem: 17674M
[01/19 06:36:06] d2.utils.events INFO:  eta: 13:17:39  iter: 11539  total_loss: 65.23  loss_ce: 2.285  loss_mask: 0.6336  loss_dice: 3.387  loss_ce_0: 3.714  loss_mask_0: 0.6574  loss_dice_0: 3.67  loss_ce_1: 2.455  loss_mask_1: 0.6438  loss_dice_1: 3.544  loss_ce_2: 2.344  loss_mask_2: 0.6432  loss_dice_2: 3.469  loss_ce_3: 2.342  loss_mask_3: 0.6364  loss_dice_3: 3.423  loss_ce_4: 2.328  loss_mask_4: 0.6349  loss_dice_4: 3.419  loss_ce_5: 2.287  loss_mask_5: 0.6388  loss_dice_5: 3.411  loss_ce_6: 2.29  loss_mask_6: 0.6358  loss_dice_6: 3.395  loss_ce_7: 2.295  loss_mask_7: 0.6373  loss_dice_7: 3.395  loss_ce_8: 2.272  loss_mask_8: 0.6369  loss_dice_8: 3.397  time: 1.6968  data_time: 0.3243  lr: 7.3616e-06  max_mem: 17674M
[01/19 06:36:40] d2.utils.events INFO:  eta: 13:17:05  iter: 11559  total_loss: 64.8  loss_ce: 2.211  loss_mask: 0.6177  loss_dice: 3.417  loss_ce_0: 3.67  loss_mask_0: 0.633  loss_dice_0: 3.712  loss_ce_1: 2.397  loss_mask_1: 0.6271  loss_dice_1: 3.57  loss_ce_2: 2.274  loss_mask_2: 0.6219  loss_dice_2: 3.496  loss_ce_3: 2.222  loss_mask_3: 0.6208  loss_dice_3: 3.449  loss_ce_4: 2.204  loss_mask_4: 0.6226  loss_dice_4: 3.449  loss_ce_5: 2.21  loss_mask_5: 0.6235  loss_dice_5: 3.446  loss_ce_6: 2.202  loss_mask_6: 0.6229  loss_dice_6: 3.431  loss_ce_7: 2.196  loss_mask_7: 0.6191  loss_dice_7: 3.432  loss_ce_8: 2.198  loss_mask_8: 0.6178  loss_dice_8: 3.421  time: 1.6968  data_time: 0.3396  lr: 7.3569e-06  max_mem: 17674M
[01/19 06:37:14] d2.utils.events INFO:  eta: 13:16:31  iter: 11579  total_loss: 64.8  loss_ce: 2.207  loss_mask: 0.6391  loss_dice: 3.391  loss_ce_0: 3.694  loss_mask_0: 0.658  loss_dice_0: 3.665  loss_ce_1: 2.416  loss_mask_1: 0.6514  loss_dice_1: 3.541  loss_ce_2: 2.305  loss_mask_2: 0.6446  loss_dice_2: 3.467  loss_ce_3: 2.274  loss_mask_3: 0.6416  loss_dice_3: 3.416  loss_ce_4: 2.235  loss_mask_4: 0.6391  loss_dice_4: 3.413  loss_ce_5: 2.221  loss_mask_5: 0.6424  loss_dice_5: 3.41  loss_ce_6: 2.228  loss_mask_6: 0.6405  loss_dice_6: 3.398  loss_ce_7: 2.223  loss_mask_7: 0.6419  loss_dice_7: 3.391  loss_ce_8: 2.217  loss_mask_8: 0.6411  loss_dice_8: 3.393  time: 1.6967  data_time: 0.3176  lr: 7.3523e-06  max_mem: 17674M
[01/19 06:37:48] d2.utils.events INFO:  eta: 13:15:58  iter: 11599  total_loss: 64.6  loss_ce: 2.274  loss_mask: 0.6346  loss_dice: 3.338  loss_ce_0: 3.698  loss_mask_0: 0.6514  loss_dice_0: 3.631  loss_ce_1: 2.422  loss_mask_1: 0.6453  loss_dice_1: 3.486  loss_ce_2: 2.318  loss_mask_2: 0.6338  loss_dice_2: 3.418  loss_ce_3: 2.301  loss_mask_3: 0.6304  loss_dice_3: 3.368  loss_ce_4: 2.283  loss_mask_4: 0.6335  loss_dice_4: 3.357  loss_ce_5: 2.273  loss_mask_5: 0.631  loss_dice_5: 3.349  loss_ce_6: 2.264  loss_mask_6: 0.6302  loss_dice_6: 3.347  loss_ce_7: 2.273  loss_mask_7: 0.6298  loss_dice_7: 3.349  loss_ce_8: 2.269  loss_mask_8: 0.6329  loss_dice_8: 3.343  time: 1.6967  data_time: 0.3412  lr: 7.3476e-06  max_mem: 17674M
[01/19 06:38:21] d2.utils.events INFO:  eta: 13:15:27  iter: 11619  total_loss: 65.56  loss_ce: 2.345  loss_mask: 0.636  loss_dice: 3.365  loss_ce_0: 3.693  loss_mask_0: 0.6469  loss_dice_0: 3.649  loss_ce_1: 2.534  loss_mask_1: 0.6461  loss_dice_1: 3.506  loss_ce_2: 2.435  loss_mask_2: 0.636  loss_dice_2: 3.434  loss_ce_3: 2.382  loss_mask_3: 0.6339  loss_dice_3: 3.393  loss_ce_4: 2.361  loss_mask_4: 0.6389  loss_dice_4: 3.384  loss_ce_5: 2.342  loss_mask_5: 0.6371  loss_dice_5: 3.38  loss_ce_6: 2.347  loss_mask_6: 0.6383  loss_dice_6: 3.369  loss_ce_7: 2.334  loss_mask_7: 0.6391  loss_dice_7: 3.368  loss_ce_8: 2.32  loss_mask_8: 0.6378  loss_dice_8: 3.368  time: 1.6967  data_time: 0.3323  lr: 7.343e-06  max_mem: 17674M
[01/19 06:38:55] d2.utils.events INFO:  eta: 13:14:50  iter: 11639  total_loss: 65.45  loss_ce: 2.325  loss_mask: 0.6243  loss_dice: 3.382  loss_ce_0: 3.713  loss_mask_0: 0.6524  loss_dice_0: 3.661  loss_ce_1: 2.516  loss_mask_1: 0.6393  loss_dice_1: 3.523  loss_ce_2: 2.407  loss_mask_2: 0.6325  loss_dice_2: 3.459  loss_ce_3: 2.385  loss_mask_3: 0.6256  loss_dice_3: 3.408  loss_ce_4: 2.364  loss_mask_4: 0.6268  loss_dice_4: 3.402  loss_ce_5: 2.311  loss_mask_5: 0.6275  loss_dice_5: 3.397  loss_ce_6: 2.333  loss_mask_6: 0.628  loss_dice_6: 3.389  loss_ce_7: 2.307  loss_mask_7: 0.6266  loss_dice_7: 3.387  loss_ce_8: 2.316  loss_mask_8: 0.6284  loss_dice_8: 3.387  time: 1.6967  data_time: 0.3425  lr: 7.3383e-06  max_mem: 17674M
[01/19 06:39:28] d2.utils.events INFO:  eta: 13:14:20  iter: 11659  total_loss: 64.81  loss_ce: 2.175  loss_mask: 0.6197  loss_dice: 3.392  loss_ce_0: 3.667  loss_mask_0: 0.6512  loss_dice_0: 3.659  loss_ce_1: 2.388  loss_mask_1: 0.6359  loss_dice_1: 3.535  loss_ce_2: 2.276  loss_mask_2: 0.632  loss_dice_2: 3.456  loss_ce_3: 2.223  loss_mask_3: 0.6242  loss_dice_3: 3.409  loss_ce_4: 2.198  loss_mask_4: 0.6227  loss_dice_4: 3.413  loss_ce_5: 2.189  loss_mask_5: 0.6215  loss_dice_5: 3.403  loss_ce_6: 2.173  loss_mask_6: 0.6216  loss_dice_6: 3.393  loss_ce_7: 2.16  loss_mask_7: 0.621  loss_dice_7: 3.399  loss_ce_8: 2.162  loss_mask_8: 0.6229  loss_dice_8: 3.391  time: 1.6966  data_time: 0.3379  lr: 7.3336e-06  max_mem: 17674M
[01/19 06:40:02] d2.utils.events INFO:  eta: 13:13:36  iter: 11679  total_loss: 65.45  loss_ce: 2.357  loss_mask: 0.6375  loss_dice: 3.345  loss_ce_0: 3.7  loss_mask_0: 0.6739  loss_dice_0: 3.616  loss_ce_1: 2.56  loss_mask_1: 0.6509  loss_dice_1: 3.498  loss_ce_2: 2.458  loss_mask_2: 0.6445  loss_dice_2: 3.419  loss_ce_3: 2.402  loss_mask_3: 0.646  loss_dice_3: 3.366  loss_ce_4: 2.386  loss_mask_4: 0.6438  loss_dice_4: 3.357  loss_ce_5: 2.361  loss_mask_5: 0.6413  loss_dice_5: 3.356  loss_ce_6: 2.349  loss_mask_6: 0.6415  loss_dice_6: 3.341  loss_ce_7: 2.342  loss_mask_7: 0.6404  loss_dice_7: 3.347  loss_ce_8: 2.365  loss_mask_8: 0.6399  loss_dice_8: 3.345  time: 1.6966  data_time: 0.3308  lr: 7.329e-06  max_mem: 17674M
[01/19 06:40:36] d2.utils.events INFO:  eta: 13:13:27  iter: 11699  total_loss: 64.87  loss_ce: 2.225  loss_mask: 0.6187  loss_dice: 3.406  loss_ce_0: 3.706  loss_mask_0: 0.6424  loss_dice_0: 3.68  loss_ce_1: 2.427  loss_mask_1: 0.6304  loss_dice_1: 3.537  loss_ce_2: 2.325  loss_mask_2: 0.6234  loss_dice_2: 3.471  loss_ce_3: 2.286  loss_mask_3: 0.6194  loss_dice_3: 3.428  loss_ce_4: 2.246  loss_mask_4: 0.619  loss_dice_4: 3.424  loss_ce_5: 2.237  loss_mask_5: 0.6172  loss_dice_5: 3.417  loss_ce_6: 2.231  loss_mask_6: 0.6172  loss_dice_6: 3.408  loss_ce_7: 2.231  loss_mask_7: 0.6182  loss_dice_7: 3.413  loss_ce_8: 2.237  loss_mask_8: 0.6204  loss_dice_8: 3.408  time: 1.6966  data_time: 0.3615  lr: 7.3243e-06  max_mem: 17674M
[01/19 06:41:10] d2.utils.events INFO:  eta: 13:12:59  iter: 11719  total_loss: 65.36  loss_ce: 2.274  loss_mask: 0.6075  loss_dice: 3.434  loss_ce_0: 3.708  loss_mask_0: 0.6285  loss_dice_0: 3.675  loss_ce_1: 2.442  loss_mask_1: 0.6214  loss_dice_1: 3.577  loss_ce_2: 2.344  loss_mask_2: 0.6083  loss_dice_2: 3.505  loss_ce_3: 2.304  loss_mask_3: 0.6075  loss_dice_3: 3.455  loss_ce_4: 2.275  loss_mask_4: 0.6087  loss_dice_4: 3.45  loss_ce_5: 2.264  loss_mask_5: 0.6105  loss_dice_5: 3.449  loss_ce_6: 2.259  loss_mask_6: 0.6104  loss_dice_6: 3.443  loss_ce_7: 2.237  loss_mask_7: 0.6128  loss_dice_7: 3.437  loss_ce_8: 2.25  loss_mask_8: 0.6097  loss_dice_8: 3.438  time: 1.6966  data_time: 0.3565  lr: 7.3197e-06  max_mem: 17674M
[01/19 06:41:43] d2.utils.events INFO:  eta: 13:12:36  iter: 11739  total_loss: 65.29  loss_ce: 2.329  loss_mask: 0.6266  loss_dice: 3.369  loss_ce_0: 3.698  loss_mask_0: 0.6619  loss_dice_0: 3.648  loss_ce_1: 2.542  loss_mask_1: 0.6506  loss_dice_1: 3.503  loss_ce_2: 2.412  loss_mask_2: 0.6348  loss_dice_2: 3.429  loss_ce_3: 2.385  loss_mask_3: 0.629  loss_dice_3: 3.392  loss_ce_4: 2.377  loss_mask_4: 0.6268  loss_dice_4: 3.384  loss_ce_5: 2.357  loss_mask_5: 0.6256  loss_dice_5: 3.375  loss_ce_6: 2.325  loss_mask_6: 0.6253  loss_dice_6: 3.368  loss_ce_7: 2.319  loss_mask_7: 0.6257  loss_dice_7: 3.374  loss_ce_8: 2.313  loss_mask_8: 0.6255  loss_dice_8: 3.369  time: 1.6965  data_time: 0.3247  lr: 7.315e-06  max_mem: 17674M
[01/19 06:42:17] d2.utils.events INFO:  eta: 13:12:09  iter: 11759  total_loss: 64.11  loss_ce: 2.09  loss_mask: 0.6246  loss_dice: 3.424  loss_ce_0: 3.642  loss_mask_0: 0.6441  loss_dice_0: 3.681  loss_ce_1: 2.301  loss_mask_1: 0.641  loss_dice_1: 3.553  loss_ce_2: 2.178  loss_mask_2: 0.6357  loss_dice_2: 3.482  loss_ce_3: 2.139  loss_mask_3: 0.6297  loss_dice_3: 3.439  loss_ce_4: 2.088  loss_mask_4: 0.6245  loss_dice_4: 3.439  loss_ce_5: 2.084  loss_mask_5: 0.6256  loss_dice_5: 3.436  loss_ce_6: 2.094  loss_mask_6: 0.6245  loss_dice_6: 3.425  loss_ce_7: 2.086  loss_mask_7: 0.6235  loss_dice_7: 3.431  loss_ce_8: 2.076  loss_mask_8: 0.6256  loss_dice_8: 3.428  time: 1.6965  data_time: 0.3409  lr: 7.3103e-06  max_mem: 17674M
[01/19 06:42:51] d2.utils.events INFO:  eta: 13:11:24  iter: 11779  total_loss: 65.43  loss_ce: 2.3  loss_mask: 0.6256  loss_dice: 3.422  loss_ce_0: 3.704  loss_mask_0: 0.6469  loss_dice_0: 3.689  loss_ce_1: 2.423  loss_mask_1: 0.6376  loss_dice_1: 3.566  loss_ce_2: 2.322  loss_mask_2: 0.6321  loss_dice_2: 3.489  loss_ce_3: 2.316  loss_mask_3: 0.6296  loss_dice_3: 3.45  loss_ce_4: 2.27  loss_mask_4: 0.6288  loss_dice_4: 3.443  loss_ce_5: 2.284  loss_mask_5: 0.6278  loss_dice_5: 3.437  loss_ce_6: 2.296  loss_mask_6: 0.6299  loss_dice_6: 3.423  loss_ce_7: 2.282  loss_mask_7: 0.6279  loss_dice_7: 3.416  loss_ce_8: 2.279  loss_mask_8: 0.6273  loss_dice_8: 3.42  time: 1.6965  data_time: 0.3462  lr: 7.3057e-06  max_mem: 17674M
[01/19 06:43:25] d2.utils.events INFO:  eta: 13:11:07  iter: 11799  total_loss: 65.07  loss_ce: 2.246  loss_mask: 0.6212  loss_dice: 3.382  loss_ce_0: 3.67  loss_mask_0: 0.6439  loss_dice_0: 3.674  loss_ce_1: 2.419  loss_mask_1: 0.6319  loss_dice_1: 3.516  loss_ce_2: 2.325  loss_mask_2: 0.6268  loss_dice_2: 3.445  loss_ce_3: 2.291  loss_mask_3: 0.6235  loss_dice_3: 3.411  loss_ce_4: 2.261  loss_mask_4: 0.6236  loss_dice_4: 3.404  loss_ce_5: 2.228  loss_mask_5: 0.6258  loss_dice_5: 3.399  loss_ce_6: 2.244  loss_mask_6: 0.6227  loss_dice_6: 3.39  loss_ce_7: 2.228  loss_mask_7: 0.6242  loss_dice_7: 3.394  loss_ce_8: 2.217  loss_mask_8: 0.6213  loss_dice_8: 3.385  time: 1.6965  data_time: 0.3280  lr: 7.301e-06  max_mem: 17674M
[01/19 06:43:58] d2.utils.events INFO:  eta: 13:10:30  iter: 11819  total_loss: 65.06  loss_ce: 2.196  loss_mask: 0.6292  loss_dice: 3.411  loss_ce_0: 3.696  loss_mask_0: 0.6466  loss_dice_0: 3.674  loss_ce_1: 2.407  loss_mask_1: 0.6333  loss_dice_1: 3.561  loss_ce_2: 2.289  loss_mask_2: 0.6286  loss_dice_2: 3.487  loss_ce_3: 2.266  loss_mask_3: 0.628  loss_dice_3: 3.433  loss_ce_4: 2.246  loss_mask_4: 0.6255  loss_dice_4: 3.43  loss_ce_5: 2.228  loss_mask_5: 0.6286  loss_dice_5: 3.43  loss_ce_6: 2.22  loss_mask_6: 0.626  loss_dice_6: 3.422  loss_ce_7: 2.207  loss_mask_7: 0.6306  loss_dice_7: 3.415  loss_ce_8: 2.201  loss_mask_8: 0.6288  loss_dice_8: 3.415  time: 1.6964  data_time: 0.3279  lr: 7.2964e-06  max_mem: 17674M
[01/19 06:44:32] d2.utils.events INFO:  eta: 13:09:29  iter: 11839  total_loss: 65.09  loss_ce: 2.34  loss_mask: 0.6316  loss_dice: 3.362  loss_ce_0: 3.737  loss_mask_0: 0.6586  loss_dice_0: 3.629  loss_ce_1: 2.522  loss_mask_1: 0.6427  loss_dice_1: 3.505  loss_ce_2: 2.424  loss_mask_2: 0.6369  loss_dice_2: 3.437  loss_ce_3: 2.37  loss_mask_3: 0.6377  loss_dice_3: 3.387  loss_ce_4: 2.341  loss_mask_4: 0.6359  loss_dice_4: 3.384  loss_ce_5: 2.349  loss_mask_5: 0.6355  loss_dice_5: 3.385  loss_ce_6: 2.332  loss_mask_6: 0.6308  loss_dice_6: 3.371  loss_ce_7: 2.321  loss_mask_7: 0.6326  loss_dice_7: 3.373  loss_ce_8: 2.311  loss_mask_8: 0.6331  loss_dice_8: 3.363  time: 1.6964  data_time: 0.3446  lr: 7.2917e-06  max_mem: 17674M
[01/19 06:45:05] d2.utils.events INFO:  eta: 13:09:02  iter: 11859  total_loss: 65.54  loss_ce: 2.243  loss_mask: 0.608  loss_dice: 3.443  loss_ce_0: 3.789  loss_mask_0: 0.6288  loss_dice_0: 3.682  loss_ce_1: 2.394  loss_mask_1: 0.624  loss_dice_1: 3.577  loss_ce_2: 2.294  loss_mask_2: 0.6112  loss_dice_2: 3.511  loss_ce_3: 2.274  loss_mask_3: 0.6088  loss_dice_3: 3.469  loss_ce_4: 2.243  loss_mask_4: 0.6068  loss_dice_4: 3.457  loss_ce_5: 2.218  loss_mask_5: 0.6094  loss_dice_5: 3.454  loss_ce_6: 2.235  loss_mask_6: 0.6086  loss_dice_6: 3.442  loss_ce_7: 2.238  loss_mask_7: 0.6105  loss_dice_7: 3.451  loss_ce_8: 2.23  loss_mask_8: 0.6105  loss_dice_8: 3.442  time: 1.6964  data_time: 0.3332  lr: 7.287e-06  max_mem: 17674M
[01/19 06:45:39] d2.utils.events INFO:  eta: 13:08:34  iter: 11879  total_loss: 64.44  loss_ce: 2.225  loss_mask: 0.6168  loss_dice: 3.368  loss_ce_0: 3.683  loss_mask_0: 0.6445  loss_dice_0: 3.638  loss_ce_1: 2.431  loss_mask_1: 0.6254  loss_dice_1: 3.516  loss_ce_2: 2.292  loss_mask_2: 0.6221  loss_dice_2: 3.455  loss_ce_3: 2.276  loss_mask_3: 0.6178  loss_dice_3: 3.389  loss_ce_4: 2.249  loss_mask_4: 0.6165  loss_dice_4: 3.396  loss_ce_5: 2.232  loss_mask_5: 0.6154  loss_dice_5: 3.384  loss_ce_6: 2.225  loss_mask_6: 0.6161  loss_dice_6: 3.368  loss_ce_7: 2.217  loss_mask_7: 0.6169  loss_dice_7: 3.362  loss_ce_8: 2.213  loss_mask_8: 0.6171  loss_dice_8: 3.369  time: 1.6964  data_time: 0.3533  lr: 7.2824e-06  max_mem: 17674M
[01/19 06:46:13] d2.utils.events INFO:  eta: 13:08:02  iter: 11899  total_loss: 64.62  loss_ce: 2.262  loss_mask: 0.6296  loss_dice: 3.346  loss_ce_0: 3.677  loss_mask_0: 0.6568  loss_dice_0: 3.628  loss_ce_1: 2.442  loss_mask_1: 0.6484  loss_dice_1: 3.497  loss_ce_2: 2.365  loss_mask_2: 0.6413  loss_dice_2: 3.419  loss_ce_3: 2.311  loss_mask_3: 0.6345  loss_dice_3: 3.375  loss_ce_4: 2.283  loss_mask_4: 0.6343  loss_dice_4: 3.362  loss_ce_5: 2.253  loss_mask_5: 0.6333  loss_dice_5: 3.362  loss_ce_6: 2.259  loss_mask_6: 0.6343  loss_dice_6: 3.344  loss_ce_7: 2.247  loss_mask_7: 0.6335  loss_dice_7: 3.349  loss_ce_8: 2.26  loss_mask_8: 0.63  loss_dice_8: 3.351  time: 1.6963  data_time: 0.3430  lr: 7.2777e-06  max_mem: 17674M
[01/19 06:46:47] d2.utils.events INFO:  eta: 13:07:27  iter: 11919  total_loss: 65.05  loss_ce: 2.223  loss_mask: 0.6228  loss_dice: 3.425  loss_ce_0: 3.687  loss_mask_0: 0.6402  loss_dice_0: 3.686  loss_ce_1: 2.376  loss_mask_1: 0.633  loss_dice_1: 3.566  loss_ce_2: 2.271  loss_mask_2: 0.6272  loss_dice_2: 3.497  loss_ce_3: 2.256  loss_mask_3: 0.6241  loss_dice_3: 3.45  loss_ce_4: 2.219  loss_mask_4: 0.6223  loss_dice_4: 3.443  loss_ce_5: 2.222  loss_mask_5: 0.6223  loss_dice_5: 3.441  loss_ce_6: 2.239  loss_mask_6: 0.6194  loss_dice_6: 3.434  loss_ce_7: 2.217  loss_mask_7: 0.6215  loss_dice_7: 3.434  loss_ce_8: 2.232  loss_mask_8: 0.6211  loss_dice_8: 3.429  time: 1.6963  data_time: 0.3302  lr: 7.2731e-06  max_mem: 17674M
[01/19 06:47:20] d2.utils.events INFO:  eta: 13:06:29  iter: 11939  total_loss: 64.78  loss_ce: 2.236  loss_mask: 0.6377  loss_dice: 3.358  loss_ce_0: 3.685  loss_mask_0: 0.6572  loss_dice_0: 3.643  loss_ce_1: 2.42  loss_mask_1: 0.6533  loss_dice_1: 3.522  loss_ce_2: 2.313  loss_mask_2: 0.6437  loss_dice_2: 3.431  loss_ce_3: 2.273  loss_mask_3: 0.6356  loss_dice_3: 3.379  loss_ce_4: 2.241  loss_mask_4: 0.6373  loss_dice_4: 3.374  loss_ce_5: 2.245  loss_mask_5: 0.639  loss_dice_5: 3.371  loss_ce_6: 2.252  loss_mask_6: 0.6346  loss_dice_6: 3.358  loss_ce_7: 2.215  loss_mask_7: 0.6371  loss_dice_7: 3.36  loss_ce_8: 2.214  loss_mask_8: 0.6383  loss_dice_8: 3.352  time: 1.6963  data_time: 0.3343  lr: 7.2684e-06  max_mem: 17674M
[01/19 06:47:54] d2.utils.events INFO:  eta: 13:05:52  iter: 11959  total_loss: 64.63  loss_ce: 2.285  loss_mask: 0.624  loss_dice: 3.402  loss_ce_0: 3.636  loss_mask_0: 0.6516  loss_dice_0: 3.662  loss_ce_1: 2.464  loss_mask_1: 0.6347  loss_dice_1: 3.539  loss_ce_2: 2.342  loss_mask_2: 0.6289  loss_dice_2: 3.467  loss_ce_3: 2.318  loss_mask_3: 0.6261  loss_dice_3: 3.411  loss_ce_4: 2.296  loss_mask_4: 0.6267  loss_dice_4: 3.41  loss_ce_5: 2.268  loss_mask_5: 0.6266  loss_dice_5: 3.414  loss_ce_6: 2.296  loss_mask_6: 0.6256  loss_dice_6: 3.41  loss_ce_7: 2.277  loss_mask_7: 0.6245  loss_dice_7: 3.407  loss_ce_8: 2.276  loss_mask_8: 0.6227  loss_dice_8: 3.413  time: 1.6962  data_time: 0.3217  lr: 7.2637e-06  max_mem: 17674M
[01/19 06:48:27] d2.utils.events INFO:  eta: 13:05:03  iter: 11979  total_loss: 65.05  loss_ce: 2.234  loss_mask: 0.6385  loss_dice: 3.364  loss_ce_0: 3.717  loss_mask_0: 0.6661  loss_dice_0: 3.624  loss_ce_1: 2.42  loss_mask_1: 0.6542  loss_dice_1: 3.52  loss_ce_2: 2.299  loss_mask_2: 0.6472  loss_dice_2: 3.433  loss_ce_3: 2.284  loss_mask_3: 0.6428  loss_dice_3: 3.389  loss_ce_4: 2.252  loss_mask_4: 0.6423  loss_dice_4: 3.38  loss_ce_5: 2.246  loss_mask_5: 0.6436  loss_dice_5: 3.375  loss_ce_6: 2.248  loss_mask_6: 0.6438  loss_dice_6: 3.368  loss_ce_7: 2.233  loss_mask_7: 0.6405  loss_dice_7: 3.371  loss_ce_8: 2.229  loss_mask_8: 0.6418  loss_dice_8: 3.366  time: 1.6962  data_time: 0.3222  lr: 7.2591e-06  max_mem: 17674M
[01/19 06:49:00] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 06:49:01] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 06:49:01] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 06:54:29] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.5090296051930743, 'error_1pix': 0.476137349569149, 'error_3pix': 0.2105579739805707, 'mIoU': 6.0487932777518925, 'fwIoU': 18.318554809515792, 'IoU-0': nan, 'IoU-1': 95.44790013200682, 'IoU-2': 11.963993542933709, 'IoU-3': 30.817005474092348, 'IoU-4': 26.251657477842137, 'IoU-5': 21.35417843809649, 'IoU-6': 18.298376492038045, 'IoU-7': 17.780148900950138, 'IoU-8': 6.384354007649426, 'IoU-9': 5.771170044776477, 'IoU-10': 18.863409012874506, 'IoU-11': 19.496030143567612, 'IoU-12': 22.275849953532393, 'IoU-13': 18.11301617065696, 'IoU-14': 9.241967546072004, 'IoU-15': 13.795692908891805, 'IoU-16': 10.204986311874483, 'IoU-17': 6.149804733678746, 'IoU-18': 14.867799433339265, 'IoU-19': 9.208310414707812, 'IoU-20': 9.08585468945033, 'IoU-21': 16.632731304407542, 'IoU-22': 11.296637827821579, 'IoU-23': 11.826856096640089, 'IoU-24': 13.14136556653573, 'IoU-25': 13.92426088124197, 'IoU-26': 12.49604238834879, 'IoU-27': 13.368953746113487, 'IoU-28': 9.970215670942165, 'IoU-29': 10.11150621222554, 'IoU-30': 14.4453713818051, 'IoU-31': 9.081714825761091, 'IoU-32': 9.381156938138872, 'IoU-33': 10.90708565228778, 'IoU-34': 11.437688118543853, 'IoU-35': 4.21170450627406, 'IoU-36': 10.97800798747359, 'IoU-37': 7.248448547432501, 'IoU-38': 7.471652560755369, 'IoU-39': 7.559882161552245, 'IoU-40': 10.611949425023559, 'IoU-41': 6.680510650184786, 'IoU-42': 6.922656853445125, 'IoU-43': 9.536725800304845, 'IoU-44': 6.856709980496628, 'IoU-45': 7.172765760560094, 'IoU-46': 11.343420209326611, 'IoU-47': 8.103518688004336, 'IoU-48': 6.729089290234591, 'IoU-49': 6.08703964575387, 'IoU-50': 9.984536815344219, 'IoU-51': 8.540403494246194, 'IoU-52': 5.2710212843202395, 'IoU-53': 9.236366119301593, 'IoU-54': 9.14933955485458, 'IoU-55': 9.332296148898616, 'IoU-56': 7.494207926564451, 'IoU-57': 9.982567737023327, 'IoU-58': 8.643336799883972, 'IoU-59': 7.282309578918111, 'IoU-60': 9.684561354325044, 'IoU-61': 6.54579219895788, 'IoU-62': 8.15516733274822, 'IoU-63': 8.650891813550649, 'IoU-64': 7.424272560193831, 'IoU-65': 7.737824312361971, 'IoU-66': 5.76608179680919, 'IoU-67': 7.853065536283507, 'IoU-68': 4.7423301260346395, 'IoU-69': 5.954087710724833, 'IoU-70': 6.456681806929912, 'IoU-71': 5.145108849965089, 'IoU-72': 4.9711801156691156, 'IoU-73': 6.977565063046034, 'IoU-74': 6.153352175241192, 'IoU-75': 5.199133150291255, 'IoU-76': 4.459702461565272, 'IoU-77': 5.693295691277505, 'IoU-78': 6.749332793673157, 'IoU-79': 6.486800655526345, 'IoU-80': 5.2194006238810395, 'IoU-81': 5.315955352113809, 'IoU-82': 4.605384097996737, 'IoU-83': 4.714426181374869, 'IoU-84': 4.2682975229079485, 'IoU-85': 6.281305199652702, 'IoU-86': 4.967256000034424, 'IoU-87': 5.658598059437288, 'IoU-88': 4.705593355998458, 'IoU-89': 5.939427426864503, 'IoU-90': 4.260200423009732, 'IoU-91': 6.189701771792933, 'IoU-92': 4.619659757445995, 'IoU-93': 4.2328293844983715, 'IoU-94': 5.634108764688241, 'IoU-95': 5.392281768659441, 'IoU-96': 5.128164558491949, 'IoU-97': 3.9435311813681375, 'IoU-98': 4.384925549643322, 'IoU-99': 5.108146500596863, 'IoU-100': 4.384408005966087, 'IoU-101': 5.290755337210628, 'IoU-102': 5.275038072784724, 'IoU-103': 5.38979533113206, 'IoU-104': 2.104172452278527, 'IoU-105': 2.4259732491713053, 'IoU-106': 4.535927209244258, 'IoU-107': 3.9046809905100046, 'IoU-108': 3.379922099902772, 'IoU-109': 4.478533965899805, 'IoU-110': 3.3874353914317283, 'IoU-111': 3.265891311667276, 'IoU-112': 2.571842716622083, 'IoU-113': 3.109040627926643, 'IoU-114': 3.296065237447017, 'IoU-115': 3.9881113066075455, 'IoU-116': 2.752511009492874, 'IoU-117': 2.484238410731967, 'IoU-118': 1.15077764369898, 'IoU-119': 2.768908642078837, 'IoU-120': 3.187184937070874, 'IoU-121': 3.571212697973261, 'IoU-122': 1.9288777357771354, 'IoU-123': 2.6779005133472826, 'IoU-124': 2.8782921064346825, 'IoU-125': 2.099712569661712, 'IoU-126': 1.3473828299179378, 'IoU-127': 3.4521279300731096, 'IoU-128': 3.0983977903504134, 'IoU-129': 2.680866716709976, 'IoU-130': 2.027333296481399, 'IoU-131': 1.3505573791039631, 'IoU-132': 1.954729605212315, 'IoU-133': 1.9690448099786138, 'IoU-134': 2.303647110927567, 'IoU-135': 2.5349914665596716, 'IoU-136': 1.3994391688158159, 'IoU-137': 1.2476617364895766, 'IoU-138': 0.8413006477315752, 'IoU-139': 1.7938831061442204, 'IoU-140': 2.2637080501707896, 'IoU-141': 1.550331720531834, 'IoU-142': 2.131578883077096, 'IoU-143': 1.8927518132207142, 'IoU-144': 0.5442708296209919, 'IoU-145': 0.5295462219989009, 'IoU-146': 0.6306992504217712, 'IoU-147': 2.722117761660622, 'IoU-148': 1.4514759943251667, 'IoU-149': 2.184563818890259, 'IoU-150': 2.659643937461597, 'IoU-151': 1.427561808833565, 'IoU-152': 0.6364847972059557, 'IoU-153': 1.003118139523185, 'IoU-154': 1.2772416740413128, 'IoU-155': 0.876065504105878, 'IoU-156': 1.388902299682969, 'IoU-157': 0.7585519555405613, 'IoU-158': 1.2601805698874207, 'IoU-159': 1.3710503021206173, 'IoU-160': 1.618584713106197, 'IoU-161': 0.1855315536992093, 'IoU-162': 1.419743925599482, 'IoU-163': 0.4288627333892031, 'IoU-164': 1.0398048224408067, 'IoU-165': 0.6983138021513919, 'IoU-166': 0.640007826080413, 'IoU-167': 1.290795593578633, 'IoU-168': 1.1090195493719879, 'IoU-169': 0.8344243052426599, 'IoU-170': 1.6379096548009782, 'IoU-171': 0.35751539279279576, 'IoU-172': 0.4109391206165399, 'IoU-173': 0.8026471249295369, 'IoU-174': 0.3796253918014259, 'IoU-175': 0.8519522108634069, 'IoU-176': 0.2593103448275862, 'IoU-177': 0.026332677632221434, 'IoU-178': 0.6720815036381764, 'IoU-179': 0.05281883140826964, 'IoU-180': 1.3374355516219216, 'IoU-181': 0.7534738078152521, 'IoU-182': 0.9833480564819131, 'IoU-183': 0.5473580982302573, 'IoU-184': 0.26888171965363955, 'IoU-185': 0.19294752337919827, 'IoU-186': 1.3606695606008556, 'IoU-187': 2.2983348451470778, 'IoU-188': 1.9922778943631165, 'IoU-189': 2.1436978214974287, 'IoU-190': 1.6745217738591098, 'IoU-191': 1.3015971343927362, 'IoU-192': 1.7501450128083085, 'mACC': 10.742514806174182, 'pACC': 26.03456646892574, 'ACC-0': nan, 'ACC-1': 98.67141680764891, 'ACC-2': 12.93326662288331, 'ACC-3': 44.373323227444885, 'ACC-4': 40.353100355755444, 'ACC-5': 32.804276224940544, 'ACC-6': 27.382350557139333, 'ACC-7': 28.37510164046804, 'ACC-8': 7.4744022377013595, 'ACC-9': 6.315847508983523, 'ACC-10': 31.345502854627817, 'ACC-11': 29.31212966583075, 'ACC-12': 44.82050799975353, 'ACC-13': 48.749279218824796, 'ACC-14': 12.289173109371077, 'ACC-15': 29.033336555399764, 'ACC-16': 17.842441348973413, 'ACC-17': 7.6259304663211624, 'ACC-18': 27.728826216643476, 'ACC-19': 14.829839883842148, 'ACC-20': 12.191427172957697, 'ACC-21': 31.445774816765514, 'ACC-22': 15.30044337226231, 'ACC-23': 19.904440349908484, 'ACC-24': 23.638396557756515, 'ACC-25': 31.58041830704303, 'ACC-26': 21.219866912275073, 'ACC-27': 22.451432256092694, 'ACC-28': 16.034035598810238, 'ACC-29': 15.419423496163501, 'ACC-30': 33.050109410751766, 'ACC-31': 12.66044289988208, 'ACC-32': 14.592939120290957, 'ACC-33': 23.13158655695881, 'ACC-34': 22.052662352202894, 'ACC-35': 5.127696847287802, 'ACC-36': 24.636706657725366, 'ACC-37': 11.075159242260769, 'ACC-38': 13.673405171509598, 'ACC-39': 13.770843226060927, 'ACC-40': 24.774144962771576, 'ACC-41': 9.834008341045394, 'ACC-42': 13.473288046318846, 'ACC-43': 21.529300482937646, 'ACC-44': 11.068072296413229, 'ACC-45': 13.952217461939254, 'ACC-46': 30.87319161894729, 'ACC-47': 14.167207086329958, 'ACC-48': 10.338424831476402, 'ACC-49': 8.878566645401575, 'ACC-50': 22.141974397574614, 'ACC-51': 15.604850111273741, 'ACC-52': 7.815249588704906, 'ACC-53': 19.977873933115177, 'ACC-54': 17.791814774383326, 'ACC-55': 21.02613025968359, 'ACC-56': 12.969022752791954, 'ACC-57': 22.692679537518053, 'ACC-58': 15.747816661942714, 'ACC-59': 13.826586520828918, 'ACC-60': 21.34603562223344, 'ACC-61': 12.276307547865294, 'ACC-62': 15.55534856430636, 'ACC-63': 17.75685919485529, 'ACC-64': 12.881218709315394, 'ACC-65': 16.10336284866563, 'ACC-66': 10.172326107068962, 'ACC-67': 19.562564024323795, 'ACC-68': 8.311096502899966, 'ACC-69': 11.2198350202769, 'ACC-70': 12.681617717764404, 'ACC-71': 8.473400234962432, 'ACC-72': 9.66313999681054, 'ACC-73': 15.518852684713705, 'ACC-74': 11.592088569780008, 'ACC-75': 9.476499308208998, 'ACC-76': 6.873213082155541, 'ACC-77': 11.588017830121307, 'ACC-78': 13.875998192455565, 'ACC-79': 12.32418811349754, 'ACC-80': 10.01750369972856, 'ACC-81': 11.786492664404106, 'ACC-82': 7.461100826307175, 'ACC-83': 7.519811456304391, 'ACC-84': 7.806487299043338, 'ACC-85': 12.37328569120662, 'ACC-86': 7.802621507221389, 'ACC-87': 9.564297452551608, 'ACC-88': 8.202669885524266, 'ACC-89': 10.696052482713139, 'ACC-90': 6.802713112857742, 'ACC-91': 11.811557856641123, 'ACC-92': 8.328750971041318, 'ACC-93': 6.952507185200277, 'ACC-94': 11.00292299495683, 'ACC-95': 9.376331968180716, 'ACC-96': 9.715482552575253, 'ACC-97': 6.287703338002191, 'ACC-98': 6.995704613609297, 'ACC-99': 9.364323858171083, 'ACC-100': 7.07387278240145, 'ACC-101': 12.37035116950467, 'ACC-102': 10.394494789306751, 'ACC-103': 12.530768867478983, 'ACC-104': 3.1603748063254713, 'ACC-105': 3.2442432750844006, 'ACC-106': 9.298585538831798, 'ACC-107': 7.207071959757886, 'ACC-108': 5.544315250798206, 'ACC-109': 8.035969683181593, 'ACC-110': 5.892563732830217, 'ACC-111': 6.487079900503967, 'ACC-112': 4.6046182314908055, 'ACC-113': 4.8880520025453364, 'ACC-114': 6.1442122567918265, 'ACC-115': 9.395418940658217, 'ACC-116': 4.121815903699313, 'ACC-117': 3.8903760828142437, 'ACC-118': 1.4098350881745243, 'ACC-119': 4.531817423442132, 'ACC-120': 5.032205694768025, 'ACC-121': 7.030982087338137, 'ACC-122': 2.864643777066999, 'ACC-123': 4.178023522260095, 'ACC-124': 5.077031017510512, 'ACC-125': 4.2383150072387075, 'ACC-126': 2.0193148389329596, 'ACC-127': 10.784314870711809, 'ACC-128': 7.073562217416705, 'ACC-129': 4.834147966909289, 'ACC-130': 4.02096774609628, 'ACC-131': 1.947746846076295, 'ACC-132': 3.5260528194147036, 'ACC-133': 3.8258248450332384, 'ACC-134': 4.406790176647997, 'ACC-135': 4.970568952739296, 'ACC-136': 2.316378587402162, 'ACC-137': 2.3757896592701817, 'ACC-138': 1.1738679341066578, 'ACC-139': 3.315261368490178, 'ACC-140': 6.2013924434350916, 'ACC-141': 2.6064607776968014, 'ACC-142': 3.80984069844314, 'ACC-143': 3.6579853763255343, 'ACC-144': 0.6891696750902527, 'ACC-145': 0.6438426619557682, 'ACC-146': 0.7287016517785748, 'ACC-147': 8.37051281217995, 'ACC-148': 3.002040775589777, 'ACC-149': 5.283808739550681, 'ACC-150': 12.65070475678256, 'ACC-151': 3.756649113327216, 'ACC-152': 0.8433643536313978, 'ACC-153': 1.4614137305557082, 'ACC-154': 2.2318582262785807, 'ACC-155': 1.3416308610842003, 'ACC-156': 2.231443955347851, 'ACC-157': 1.0680070175152063, 'ACC-158': 2.297505754702202, 'ACC-159': 2.525185220889911, 'ACC-160': 3.2222718635479346, 'ACC-161': 0.22467050666007635, 'ACC-162': 4.909982415999952, 'ACC-163': 0.5796684944364359, 'ACC-164': 2.001528416820195, 'ACC-165': 1.060900113395611, 'ACC-166': 0.8567039645432339, 'ACC-167': 2.9084522823090433, 'ACC-168': 2.510900907236796, 'ACC-169': 1.5143193546858797, 'ACC-170': 4.301361500347829, 'ACC-171': 0.39473998409284194, 'ACC-172': 0.5217246360706745, 'ACC-173': 1.2564298427487177, 'ACC-174': 0.5303076903003089, 'ACC-175': 1.2788442516718157, 'ACC-176': 0.2898624332482006, 'ACC-177': 0.027866513862206548, 'ACC-178': 0.9791176930758667, 'ACC-179': 0.053765513379497275, 'ACC-180': 2.4179620034542317, 'ACC-181': 1.4226125761225636, 'ACC-182': 1.8645356784943459, 'ACC-183': 0.7095922081407695, 'ACC-184': 0.29857293457573636, 'ACC-185': 0.20947946546937718, 'ACC-186': 2.0570662373439905, 'ACC-187': 6.85632829582382, 'ACC-188': 3.962713369113434, 'ACC-189': 6.008661920666665, 'ACC-190': 4.580944695389711, 'ACC-191': 2.369200652528548, 'ACC-192': 8.922633719235591})])
[01/19 06:54:29] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 06:54:29] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 06:54:29] d2.evaluation.testing INFO: copypaste: 3.5090,0.4761,0.2106,6.0488,18.3186,10.7425,26.0346
[01/19 06:54:29] d2.utils.events INFO:  eta: 13:04:17  iter: 11999  total_loss: 64.95  loss_ce: 2.298  loss_mask: 0.6393  loss_dice: 3.359  loss_ce_0: 3.683  loss_mask_0: 0.6692  loss_dice_0: 3.636  loss_ce_1: 2.531  loss_mask_1: 0.6536  loss_dice_1: 3.492  loss_ce_2: 2.384  loss_mask_2: 0.6478  loss_dice_2: 3.425  loss_ce_3: 2.343  loss_mask_3: 0.6408  loss_dice_3: 3.379  loss_ce_4: 2.332  loss_mask_4: 0.6418  loss_dice_4: 3.374  loss_ce_5: 2.314  loss_mask_5: 0.6446  loss_dice_5: 3.375  loss_ce_6: 2.315  loss_mask_6: 0.639  loss_dice_6: 3.362  loss_ce_7: 2.298  loss_mask_7: 0.6398  loss_dice_7: 3.368  loss_ce_8: 2.309  loss_mask_8: 0.64  loss_dice_8: 3.362  time: 1.6961  data_time: 0.3383  lr: 7.2544e-06  max_mem: 17674M
[01/19 06:55:03] d2.utils.events INFO:  eta: 13:03:31  iter: 12019  total_loss: 65.49  loss_ce: 2.279  loss_mask: 0.6305  loss_dice: 3.397  loss_ce_0: 3.727  loss_mask_0: 0.6549  loss_dice_0: 3.673  loss_ce_1: 2.475  loss_mask_1: 0.6442  loss_dice_1: 3.553  loss_ce_2: 2.384  loss_mask_2: 0.6378  loss_dice_2: 3.476  loss_ce_3: 2.348  loss_mask_3: 0.6309  loss_dice_3: 3.428  loss_ce_4: 2.319  loss_mask_4: 0.6299  loss_dice_4: 3.419  loss_ce_5: 2.293  loss_mask_5: 0.6294  loss_dice_5: 3.415  loss_ce_6: 2.288  loss_mask_6: 0.6301  loss_dice_6: 3.397  loss_ce_7: 2.275  loss_mask_7: 0.6288  loss_dice_7: 3.395  loss_ce_8: 2.284  loss_mask_8: 0.6275  loss_dice_8: 3.401  time: 1.6961  data_time: 0.3370  lr: 7.2497e-06  max_mem: 17674M
[01/19 06:55:36] d2.utils.events INFO:  eta: 13:02:41  iter: 12039  total_loss: 64.81  loss_ce: 2.274  loss_mask: 0.634  loss_dice: 3.406  loss_ce_0: 3.675  loss_mask_0: 0.6539  loss_dice_0: 3.677  loss_ce_1: 2.443  loss_mask_1: 0.6386  loss_dice_1: 3.555  loss_ce_2: 2.342  loss_mask_2: 0.6372  loss_dice_2: 3.478  loss_ce_3: 2.328  loss_mask_3: 0.6332  loss_dice_3: 3.429  loss_ce_4: 2.292  loss_mask_4: 0.6363  loss_dice_4: 3.424  loss_ce_5: 2.277  loss_mask_5: 0.6369  loss_dice_5: 3.421  loss_ce_6: 2.265  loss_mask_6: 0.6326  loss_dice_6: 3.406  loss_ce_7: 2.257  loss_mask_7: 0.6316  loss_dice_7: 3.409  loss_ce_8: 2.27  loss_mask_8: 0.6319  loss_dice_8: 3.408  time: 1.6960  data_time: 0.3455  lr: 7.2451e-06  max_mem: 17674M
[01/19 06:56:10] d2.utils.events INFO:  eta: 13:02:12  iter: 12059  total_loss: 64.38  loss_ce: 2.163  loss_mask: 0.6079  loss_dice: 3.443  loss_ce_0: 3.678  loss_mask_0: 0.6231  loss_dice_0: 3.698  loss_ce_1: 2.323  loss_mask_1: 0.6205  loss_dice_1: 3.582  loss_ce_2: 2.208  loss_mask_2: 0.6146  loss_dice_2: 3.51  loss_ce_3: 2.195  loss_mask_3: 0.6071  loss_dice_3: 3.465  loss_ce_4: 2.16  loss_mask_4: 0.6089  loss_dice_4: 3.467  loss_ce_5: 2.146  loss_mask_5: 0.6096  loss_dice_5: 3.453  loss_ce_6: 2.143  loss_mask_6: 0.6087  loss_dice_6: 3.447  loss_ce_7: 2.132  loss_mask_7: 0.6096  loss_dice_7: 3.439  loss_ce_8: 2.15  loss_mask_8: 0.6092  loss_dice_8: 3.448  time: 1.6960  data_time: 0.3448  lr: 7.2404e-06  max_mem: 17674M
[01/19 06:56:44] d2.utils.events INFO:  eta: 13:01:33  iter: 12079  total_loss: 63.94  loss_ce: 2.149  loss_mask: 0.6258  loss_dice: 3.354  loss_ce_0: 3.703  loss_mask_0: 0.6515  loss_dice_0: 3.626  loss_ce_1: 2.353  loss_mask_1: 0.6507  loss_dice_1: 3.509  loss_ce_2: 2.238  loss_mask_2: 0.6355  loss_dice_2: 3.432  loss_ce_3: 2.201  loss_mask_3: 0.6275  loss_dice_3: 3.388  loss_ce_4: 2.172  loss_mask_4: 0.6284  loss_dice_4: 3.381  loss_ce_5: 2.158  loss_mask_5: 0.6301  loss_dice_5: 3.377  loss_ce_6: 2.143  loss_mask_6: 0.629  loss_dice_6: 3.362  loss_ce_7: 2.128  loss_mask_7: 0.6291  loss_dice_7: 3.357  loss_ce_8: 2.129  loss_mask_8: 0.6298  loss_dice_8: 3.367  time: 1.6960  data_time: 0.3379  lr: 7.2358e-06  max_mem: 17674M
[01/19 06:57:17] d2.utils.events INFO:  eta: 13:00:56  iter: 12099  total_loss: 64.89  loss_ce: 2.226  loss_mask: 0.6195  loss_dice: 3.363  loss_ce_0: 3.691  loss_mask_0: 0.6422  loss_dice_0: 3.649  loss_ce_1: 2.426  loss_mask_1: 0.6338  loss_dice_1: 3.528  loss_ce_2: 2.32  loss_mask_2: 0.6311  loss_dice_2: 3.439  loss_ce_3: 2.277  loss_mask_3: 0.6272  loss_dice_3: 3.399  loss_ce_4: 2.24  loss_mask_4: 0.623  loss_dice_4: 3.397  loss_ce_5: 2.223  loss_mask_5: 0.6206  loss_dice_5: 3.389  loss_ce_6: 2.222  loss_mask_6: 0.6218  loss_dice_6: 3.375  loss_ce_7: 2.229  loss_mask_7: 0.6224  loss_dice_7: 3.371  loss_ce_8: 2.227  loss_mask_8: 0.6208  loss_dice_8: 3.373  time: 1.6960  data_time: 0.3262  lr: 7.2311e-06  max_mem: 17674M
[01/19 06:57:51] d2.utils.events INFO:  eta: 13:00:16  iter: 12119  total_loss: 64.93  loss_ce: 2.272  loss_mask: 0.6176  loss_dice: 3.33  loss_ce_0: 3.784  loss_mask_0: 0.6341  loss_dice_0: 3.62  loss_ce_1: 2.501  loss_mask_1: 0.6295  loss_dice_1: 3.498  loss_ce_2: 2.369  loss_mask_2: 0.6217  loss_dice_2: 3.414  loss_ce_3: 2.323  loss_mask_3: 0.621  loss_dice_3: 3.348  loss_ce_4: 2.292  loss_mask_4: 0.6195  loss_dice_4: 3.346  loss_ce_5: 2.257  loss_mask_5: 0.6197  loss_dice_5: 3.35  loss_ce_6: 2.254  loss_mask_6: 0.6192  loss_dice_6: 3.334  loss_ce_7: 2.255  loss_mask_7: 0.6224  loss_dice_7: 3.335  loss_ce_8: 2.26  loss_mask_8: 0.6187  loss_dice_8: 3.336  time: 1.6959  data_time: 0.3323  lr: 7.2264e-06  max_mem: 17674M
[01/19 06:58:24] d2.utils.events INFO:  eta: 12:59:38  iter: 12139  total_loss: 64.78  loss_ce: 2.188  loss_mask: 0.6311  loss_dice: 3.367  loss_ce_0: 3.641  loss_mask_0: 0.6641  loss_dice_0: 3.637  loss_ce_1: 2.341  loss_mask_1: 0.6433  loss_dice_1: 3.506  loss_ce_2: 2.252  loss_mask_2: 0.6344  loss_dice_2: 3.432  loss_ce_3: 2.206  loss_mask_3: 0.636  loss_dice_3: 3.39  loss_ce_4: 2.206  loss_mask_4: 0.6351  loss_dice_4: 3.382  loss_ce_5: 2.175  loss_mask_5: 0.6331  loss_dice_5: 3.384  loss_ce_6: 2.194  loss_mask_6: 0.6309  loss_dice_6: 3.366  loss_ce_7: 2.19  loss_mask_7: 0.6294  loss_dice_7: 3.366  loss_ce_8: 2.19  loss_mask_8: 0.6315  loss_dice_8: 3.367  time: 1.6959  data_time: 0.3218  lr: 7.2218e-06  max_mem: 17674M
[01/19 06:58:58] d2.utils.events INFO:  eta: 12:58:57  iter: 12159  total_loss: 65.29  loss_ce: 2.366  loss_mask: 0.6359  loss_dice: 3.381  loss_ce_0: 3.706  loss_mask_0: 0.6552  loss_dice_0: 3.639  loss_ce_1: 2.493  loss_mask_1: 0.646  loss_dice_1: 3.531  loss_ce_2: 2.392  loss_mask_2: 0.6419  loss_dice_2: 3.454  loss_ce_3: 2.381  loss_mask_3: 0.6334  loss_dice_3: 3.409  loss_ce_4: 2.366  loss_mask_4: 0.6349  loss_dice_4: 3.405  loss_ce_5: 2.368  loss_mask_5: 0.6384  loss_dice_5: 3.403  loss_ce_6: 2.374  loss_mask_6: 0.6345  loss_dice_6: 3.392  loss_ce_7: 2.352  loss_mask_7: 0.635  loss_dice_7: 3.39  loss_ce_8: 2.371  loss_mask_8: 0.6336  loss_dice_8: 3.389  time: 1.6958  data_time: 0.3601  lr: 7.2171e-06  max_mem: 17674M
[01/19 06:59:31] d2.utils.events INFO:  eta: 12:58:20  iter: 12179  total_loss: 64.17  loss_ce: 2.125  loss_mask: 0.6366  loss_dice: 3.386  loss_ce_0: 3.658  loss_mask_0: 0.6478  loss_dice_0: 3.657  loss_ce_1: 2.346  loss_mask_1: 0.6503  loss_dice_1: 3.522  loss_ce_2: 2.223  loss_mask_2: 0.6426  loss_dice_2: 3.447  loss_ce_3: 2.172  loss_mask_3: 0.6404  loss_dice_3: 3.414  loss_ce_4: 2.13  loss_mask_4: 0.641  loss_dice_4: 3.409  loss_ce_5: 2.132  loss_mask_5: 0.6386  loss_dice_5: 3.405  loss_ce_6: 2.12  loss_mask_6: 0.6356  loss_dice_6: 3.392  loss_ce_7: 2.099  loss_mask_7: 0.6368  loss_dice_7: 3.398  loss_ce_8: 2.097  loss_mask_8: 0.6347  loss_dice_8: 3.389  time: 1.6958  data_time: 0.3307  lr: 7.2124e-06  max_mem: 17674M
[01/19 07:00:05] d2.utils.events INFO:  eta: 12:57:51  iter: 12199  total_loss: 65.35  loss_ce: 2.231  loss_mask: 0.6277  loss_dice: 3.375  loss_ce_0: 3.751  loss_mask_0: 0.6534  loss_dice_0: 3.642  loss_ce_1: 2.434  loss_mask_1: 0.642  loss_dice_1: 3.532  loss_ce_2: 2.318  loss_mask_2: 0.6307  loss_dice_2: 3.459  loss_ce_3: 2.256  loss_mask_3: 0.6316  loss_dice_3: 3.41  loss_ce_4: 2.238  loss_mask_4: 0.6331  loss_dice_4: 3.398  loss_ce_5: 2.22  loss_mask_5: 0.6305  loss_dice_5: 3.401  loss_ce_6: 2.222  loss_mask_6: 0.6318  loss_dice_6: 3.384  loss_ce_7: 2.217  loss_mask_7: 0.6321  loss_dice_7: 3.388  loss_ce_8: 2.201  loss_mask_8: 0.6323  loss_dice_8: 3.382  time: 1.6958  data_time: 0.3608  lr: 7.2078e-06  max_mem: 17674M
[01/19 07:00:39] d2.utils.events INFO:  eta: 12:57:14  iter: 12219  total_loss: 65.72  loss_ce: 2.329  loss_mask: 0.6347  loss_dice: 3.361  loss_ce_0: 3.739  loss_mask_0: 0.6582  loss_dice_0: 3.638  loss_ce_1: 2.483  loss_mask_1: 0.6512  loss_dice_1: 3.515  loss_ce_2: 2.432  loss_mask_2: 0.6438  loss_dice_2: 3.435  loss_ce_3: 2.363  loss_mask_3: 0.6379  loss_dice_3: 3.386  loss_ce_4: 2.339  loss_mask_4: 0.6382  loss_dice_4: 3.385  loss_ce_5: 2.316  loss_mask_5: 0.6396  loss_dice_5: 3.378  loss_ce_6: 2.336  loss_mask_6: 0.6376  loss_dice_6: 3.363  loss_ce_7: 2.315  loss_mask_7: 0.6375  loss_dice_7: 3.365  loss_ce_8: 2.315  loss_mask_8: 0.6379  loss_dice_8: 3.361  time: 1.6958  data_time: 0.3518  lr: 7.2031e-06  max_mem: 17674M
[01/19 07:01:13] d2.utils.events INFO:  eta: 12:56:29  iter: 12239  total_loss: 65.49  loss_ce: 2.306  loss_mask: 0.6337  loss_dice: 3.351  loss_ce_0: 3.71  loss_mask_0: 0.6533  loss_dice_0: 3.62  loss_ce_1: 2.464  loss_mask_1: 0.6494  loss_dice_1: 3.484  loss_ce_2: 2.373  loss_mask_2: 0.6402  loss_dice_2: 3.408  loss_ce_3: 2.328  loss_mask_3: 0.6363  loss_dice_3: 3.374  loss_ce_4: 2.317  loss_mask_4: 0.6344  loss_dice_4: 3.363  loss_ce_5: 2.288  loss_mask_5: 0.6347  loss_dice_5: 3.364  loss_ce_6: 2.302  loss_mask_6: 0.6334  loss_dice_6: 3.343  loss_ce_7: 2.302  loss_mask_7: 0.6328  loss_dice_7: 3.35  loss_ce_8: 2.296  loss_mask_8: 0.6335  loss_dice_8: 3.354  time: 1.6958  data_time: 0.3271  lr: 7.1984e-06  max_mem: 17674M
[01/19 07:01:46] d2.utils.events INFO:  eta: 12:55:15  iter: 12259  total_loss: 64.61  loss_ce: 2.21  loss_mask: 0.6316  loss_dice: 3.327  loss_ce_0: 3.611  loss_mask_0: 0.6585  loss_dice_0: 3.63  loss_ce_1: 2.363  loss_mask_1: 0.6449  loss_dice_1: 3.494  loss_ce_2: 2.275  loss_mask_2: 0.6346  loss_dice_2: 3.417  loss_ce_3: 2.249  loss_mask_3: 0.6338  loss_dice_3: 3.363  loss_ce_4: 2.235  loss_mask_4: 0.6348  loss_dice_4: 3.353  loss_ce_5: 2.201  loss_mask_5: 0.6337  loss_dice_5: 3.349  loss_ce_6: 2.213  loss_mask_6: 0.6315  loss_dice_6: 3.335  loss_ce_7: 2.21  loss_mask_7: 0.6335  loss_dice_7: 3.337  loss_ce_8: 2.184  loss_mask_8: 0.6316  loss_dice_8: 3.333  time: 1.6957  data_time: 0.3233  lr: 7.1938e-06  max_mem: 17674M
[01/19 07:02:20] d2.utils.events INFO:  eta: 12:54:26  iter: 12279  total_loss: 64.78  loss_ce: 2.253  loss_mask: 0.635  loss_dice: 3.369  loss_ce_0: 3.683  loss_mask_0: 0.6573  loss_dice_0: 3.641  loss_ce_1: 2.464  loss_mask_1: 0.6503  loss_dice_1: 3.521  loss_ce_2: 2.311  loss_mask_2: 0.6415  loss_dice_2: 3.456  loss_ce_3: 2.283  loss_mask_3: 0.6412  loss_dice_3: 3.403  loss_ce_4: 2.261  loss_mask_4: 0.6406  loss_dice_4: 3.393  loss_ce_5: 2.238  loss_mask_5: 0.6378  loss_dice_5: 3.382  loss_ce_6: 2.239  loss_mask_6: 0.6388  loss_dice_6: 3.376  loss_ce_7: 2.248  loss_mask_7: 0.638  loss_dice_7: 3.362  loss_ce_8: 2.236  loss_mask_8: 0.6342  loss_dice_8: 3.374  time: 1.6957  data_time: 0.3442  lr: 7.1891e-06  max_mem: 17674M
[01/19 07:02:53] d2.utils.events INFO:  eta: 12:53:42  iter: 12299  total_loss: 64.93  loss_ce: 2.252  loss_mask: 0.6334  loss_dice: 3.351  loss_ce_0: 3.702  loss_mask_0: 0.6563  loss_dice_0: 3.627  loss_ce_1: 2.455  loss_mask_1: 0.6488  loss_dice_1: 3.514  loss_ce_2: 2.328  loss_mask_2: 0.6406  loss_dice_2: 3.435  loss_ce_3: 2.285  loss_mask_3: 0.6299  loss_dice_3: 3.388  loss_ce_4: 2.271  loss_mask_4: 0.6303  loss_dice_4: 3.381  loss_ce_5: 2.243  loss_mask_5: 0.6333  loss_dice_5: 3.38  loss_ce_6: 2.257  loss_mask_6: 0.6328  loss_dice_6: 3.362  loss_ce_7: 2.259  loss_mask_7: 0.6318  loss_dice_7: 3.359  loss_ce_8: 2.246  loss_mask_8: 0.6323  loss_dice_8: 3.353  time: 1.6956  data_time: 0.3378  lr: 7.1844e-06  max_mem: 17674M
[01/19 07:03:27] d2.utils.events INFO:  eta: 12:53:27  iter: 12319  total_loss: 64.52  loss_ce: 2.173  loss_mask: 0.617  loss_dice: 3.342  loss_ce_0: 3.688  loss_mask_0: 0.6544  loss_dice_0: 3.63  loss_ce_1: 2.363  loss_mask_1: 0.635  loss_dice_1: 3.496  loss_ce_2: 2.274  loss_mask_2: 0.6285  loss_dice_2: 3.418  loss_ce_3: 2.259  loss_mask_3: 0.6228  loss_dice_3: 3.371  loss_ce_4: 2.221  loss_mask_4: 0.6228  loss_dice_4: 3.365  loss_ce_5: 2.188  loss_mask_5: 0.619  loss_dice_5: 3.366  loss_ce_6: 2.175  loss_mask_6: 0.6203  loss_dice_6: 3.342  loss_ce_7: 2.179  loss_mask_7: 0.6188  loss_dice_7: 3.345  loss_ce_8: 2.155  loss_mask_8: 0.6179  loss_dice_8: 3.346  time: 1.6956  data_time: 0.3348  lr: 7.1798e-06  max_mem: 17674M
[01/19 07:04:00] d2.utils.events INFO:  eta: 12:52:40  iter: 12339  total_loss: 64.8  loss_ce: 2.24  loss_mask: 0.6232  loss_dice: 3.336  loss_ce_0: 3.69  loss_mask_0: 0.652  loss_dice_0: 3.637  loss_ce_1: 2.426  loss_mask_1: 0.6529  loss_dice_1: 3.492  loss_ce_2: 2.331  loss_mask_2: 0.6386  loss_dice_2: 3.407  loss_ce_3: 2.293  loss_mask_3: 0.6309  loss_dice_3: 3.363  loss_ce_4: 2.259  loss_mask_4: 0.6295  loss_dice_4: 3.353  loss_ce_5: 2.241  loss_mask_5: 0.6294  loss_dice_5: 3.349  loss_ce_6: 2.247  loss_mask_6: 0.6288  loss_dice_6: 3.341  loss_ce_7: 2.237  loss_mask_7: 0.6261  loss_dice_7: 3.337  loss_ce_8: 2.246  loss_mask_8: 0.6262  loss_dice_8: 3.336  time: 1.6956  data_time: 0.3285  lr: 7.1751e-06  max_mem: 17674M
[01/19 07:04:35] d2.utils.events INFO:  eta: 12:52:09  iter: 12359  total_loss: 64.72  loss_ce: 2.244  loss_mask: 0.6352  loss_dice: 3.369  loss_ce_0: 3.653  loss_mask_0: 0.6549  loss_dice_0: 3.651  loss_ce_1: 2.385  loss_mask_1: 0.642  loss_dice_1: 3.519  loss_ce_2: 2.309  loss_mask_2: 0.6393  loss_dice_2: 3.442  loss_ce_3: 2.274  loss_mask_3: 0.634  loss_dice_3: 3.404  loss_ce_4: 2.265  loss_mask_4: 0.6338  loss_dice_4: 3.396  loss_ce_5: 2.252  loss_mask_5: 0.6351  loss_dice_5: 3.393  loss_ce_6: 2.257  loss_mask_6: 0.6365  loss_dice_6: 3.375  loss_ce_7: 2.245  loss_mask_7: 0.6348  loss_dice_7: 3.379  loss_ce_8: 2.226  loss_mask_8: 0.6326  loss_dice_8: 3.375  time: 1.6956  data_time: 0.3586  lr: 7.1704e-06  max_mem: 17674M
[01/19 07:05:08] d2.utils.events INFO:  eta: 12:51:00  iter: 12379  total_loss: 64.91  loss_ce: 2.292  loss_mask: 0.641  loss_dice: 3.33  loss_ce_0: 3.75  loss_mask_0: 0.6631  loss_dice_0: 3.601  loss_ce_1: 2.493  loss_mask_1: 0.6501  loss_dice_1: 3.47  loss_ce_2: 2.368  loss_mask_2: 0.6427  loss_dice_2: 3.403  loss_ce_3: 2.347  loss_mask_3: 0.6387  loss_dice_3: 3.352  loss_ce_4: 2.31  loss_mask_4: 0.641  loss_dice_4: 3.352  loss_ce_5: 2.296  loss_mask_5: 0.6415  loss_dice_5: 3.341  loss_ce_6: 2.303  loss_mask_6: 0.639  loss_dice_6: 3.331  loss_ce_7: 2.284  loss_mask_7: 0.6413  loss_dice_7: 3.332  loss_ce_8: 2.282  loss_mask_8: 0.6412  loss_dice_8: 3.334  time: 1.6956  data_time: 0.3276  lr: 7.1657e-06  max_mem: 17674M
[01/19 07:05:42] d2.utils.events INFO:  eta: 12:50:36  iter: 12399  total_loss: 65.14  loss_ce: 2.255  loss_mask: 0.6246  loss_dice: 3.342  loss_ce_0: 3.754  loss_mask_0: 0.6511  loss_dice_0: 3.631  loss_ce_1: 2.482  loss_mask_1: 0.6354  loss_dice_1: 3.486  loss_ce_2: 2.362  loss_mask_2: 0.6281  loss_dice_2: 3.415  loss_ce_3: 2.32  loss_mask_3: 0.6242  loss_dice_3: 3.362  loss_ce_4: 2.304  loss_mask_4: 0.6217  loss_dice_4: 3.35  loss_ce_5: 2.265  loss_mask_5: 0.6215  loss_dice_5: 3.359  loss_ce_6: 2.278  loss_mask_6: 0.6241  loss_dice_6: 3.346  loss_ce_7: 2.253  loss_mask_7: 0.6247  loss_dice_7: 3.339  loss_ce_8: 2.257  loss_mask_8: 0.6262  loss_dice_8: 3.343  time: 1.6956  data_time: 0.3341  lr: 7.1611e-06  max_mem: 17674M
[01/19 07:06:16] d2.utils.events INFO:  eta: 12:50:03  iter: 12419  total_loss: 64.6  loss_ce: 2.255  loss_mask: 0.6392  loss_dice: 3.325  loss_ce_0: 3.712  loss_mask_0: 0.6637  loss_dice_0: 3.629  loss_ce_1: 2.465  loss_mask_1: 0.6476  loss_dice_1: 3.493  loss_ce_2: 2.36  loss_mask_2: 0.6405  loss_dice_2: 3.418  loss_ce_3: 2.333  loss_mask_3: 0.6403  loss_dice_3: 3.357  loss_ce_4: 2.293  loss_mask_4: 0.643  loss_dice_4: 3.347  loss_ce_5: 2.279  loss_mask_5: 0.6421  loss_dice_5: 3.35  loss_ce_6: 2.271  loss_mask_6: 0.6403  loss_dice_6: 3.327  loss_ce_7: 2.258  loss_mask_7: 0.6377  loss_dice_7: 3.333  loss_ce_8: 2.276  loss_mask_8: 0.6422  loss_dice_8: 3.329  time: 1.6956  data_time: 0.3338  lr: 7.1564e-06  max_mem: 17674M
[01/19 07:06:50] d2.utils.events INFO:  eta: 12:49:29  iter: 12439  total_loss: 63.86  loss_ce: 2.191  loss_mask: 0.6154  loss_dice: 3.377  loss_ce_0: 3.634  loss_mask_0: 0.6327  loss_dice_0: 3.668  loss_ce_1: 2.373  loss_mask_1: 0.6232  loss_dice_1: 3.526  loss_ce_2: 2.236  loss_mask_2: 0.6178  loss_dice_2: 3.455  loss_ce_3: 2.242  loss_mask_3: 0.6127  loss_dice_3: 3.403  loss_ce_4: 2.199  loss_mask_4: 0.6149  loss_dice_4: 3.403  loss_ce_5: 2.173  loss_mask_5: 0.6158  loss_dice_5: 3.4  loss_ce_6: 2.196  loss_mask_6: 0.6138  loss_dice_6: 3.385  loss_ce_7: 2.181  loss_mask_7: 0.6161  loss_dice_7: 3.381  loss_ce_8: 2.167  loss_mask_8: 0.6172  loss_dice_8: 3.386  time: 1.6956  data_time: 0.3256  lr: 7.1517e-06  max_mem: 17674M
[01/19 07:07:23] d2.utils.events INFO:  eta: 12:48:56  iter: 12459  total_loss: 64.86  loss_ce: 2.2  loss_mask: 0.6271  loss_dice: 3.379  loss_ce_0: 3.713  loss_mask_0: 0.648  loss_dice_0: 3.632  loss_ce_1: 2.371  loss_mask_1: 0.6402  loss_dice_1: 3.516  loss_ce_2: 2.238  loss_mask_2: 0.6365  loss_dice_2: 3.439  loss_ce_3: 2.237  loss_mask_3: 0.6297  loss_dice_3: 3.399  loss_ce_4: 2.229  loss_mask_4: 0.6306  loss_dice_4: 3.396  loss_ce_5: 2.2  loss_mask_5: 0.632  loss_dice_5: 3.396  loss_ce_6: 2.204  loss_mask_6: 0.6302  loss_dice_6: 3.381  loss_ce_7: 2.176  loss_mask_7: 0.629  loss_dice_7: 3.377  loss_ce_8: 2.183  loss_mask_8: 0.6279  loss_dice_8: 3.377  time: 1.6956  data_time: 0.3501  lr: 7.1471e-06  max_mem: 17674M
[01/19 07:07:58] d2.utils.events INFO:  eta: 12:48:46  iter: 12479  total_loss: 64.52  loss_ce: 2.291  loss_mask: 0.6104  loss_dice: 3.32  loss_ce_0: 3.719  loss_mask_0: 0.6412  loss_dice_0: 3.608  loss_ce_1: 2.471  loss_mask_1: 0.6228  loss_dice_1: 3.472  loss_ce_2: 2.369  loss_mask_2: 0.6219  loss_dice_2: 3.387  loss_ce_3: 2.331  loss_mask_3: 0.6219  loss_dice_3: 3.337  loss_ce_4: 2.299  loss_mask_4: 0.6201  loss_dice_4: 3.337  loss_ce_5: 2.298  loss_mask_5: 0.6205  loss_dice_5: 3.337  loss_ce_6: 2.294  loss_mask_6: 0.6142  loss_dice_6: 3.318  loss_ce_7: 2.282  loss_mask_7: 0.6161  loss_dice_7: 3.32  loss_ce_8: 2.267  loss_mask_8: 0.6134  loss_dice_8: 3.319  time: 1.6956  data_time: 0.3652  lr: 7.1424e-06  max_mem: 17674M
[01/19 07:08:31] d2.utils.events INFO:  eta: 12:48:12  iter: 12499  total_loss: 64.78  loss_ce: 2.211  loss_mask: 0.6219  loss_dice: 3.375  loss_ce_0: 3.691  loss_mask_0: 0.6461  loss_dice_0: 3.647  loss_ce_1: 2.403  loss_mask_1: 0.6382  loss_dice_1: 3.518  loss_ce_2: 2.257  loss_mask_2: 0.6269  loss_dice_2: 3.452  loss_ce_3: 2.253  loss_mask_3: 0.6196  loss_dice_3: 3.413  loss_ce_4: 2.223  loss_mask_4: 0.6209  loss_dice_4: 3.409  loss_ce_5: 2.207  loss_mask_5: 0.6231  loss_dice_5: 3.402  loss_ce_6: 2.224  loss_mask_6: 0.621  loss_dice_6: 3.382  loss_ce_7: 2.193  loss_mask_7: 0.6233  loss_dice_7: 3.373  loss_ce_8: 2.203  loss_mask_8: 0.622  loss_dice_8: 3.381  time: 1.6955  data_time: 0.3269  lr: 7.1377e-06  max_mem: 17674M
[01/19 07:09:05] d2.utils.events INFO:  eta: 12:47:53  iter: 12519  total_loss: 64.87  loss_ce: 2.345  loss_mask: 0.636  loss_dice: 3.315  loss_ce_0: 3.68  loss_mask_0: 0.6589  loss_dice_0: 3.606  loss_ce_1: 2.46  loss_mask_1: 0.6537  loss_dice_1: 3.47  loss_ce_2: 2.391  loss_mask_2: 0.6444  loss_dice_2: 3.396  loss_ce_3: 2.384  loss_mask_3: 0.6412  loss_dice_3: 3.342  loss_ce_4: 2.348  loss_mask_4: 0.6404  loss_dice_4: 3.336  loss_ce_5: 2.326  loss_mask_5: 0.6419  loss_dice_5: 3.333  loss_ce_6: 2.343  loss_mask_6: 0.6391  loss_dice_6: 3.317  loss_ce_7: 2.342  loss_mask_7: 0.6369  loss_dice_7: 3.321  loss_ce_8: 2.336  loss_mask_8: 0.6366  loss_dice_8: 3.318  time: 1.6955  data_time: 0.3392  lr: 7.1331e-06  max_mem: 17674M
[01/19 07:09:39] d2.utils.events INFO:  eta: 12:47:59  iter: 12539  total_loss: 64.58  loss_ce: 2.245  loss_mask: 0.6307  loss_dice: 3.351  loss_ce_0: 3.658  loss_mask_0: 0.6504  loss_dice_0: 3.639  loss_ce_1: 2.416  loss_mask_1: 0.6462  loss_dice_1: 3.507  loss_ce_2: 2.314  loss_mask_2: 0.637  loss_dice_2: 3.434  loss_ce_3: 2.274  loss_mask_3: 0.6383  loss_dice_3: 3.375  loss_ce_4: 2.271  loss_mask_4: 0.6358  loss_dice_4: 3.368  loss_ce_5: 2.258  loss_mask_5: 0.6329  loss_dice_5: 3.366  loss_ce_6: 2.233  loss_mask_6: 0.6312  loss_dice_6: 3.354  loss_ce_7: 2.235  loss_mask_7: 0.6292  loss_dice_7: 3.352  loss_ce_8: 2.236  loss_mask_8: 0.6317  loss_dice_8: 3.35  time: 1.6955  data_time: 0.3535  lr: 7.1284e-06  max_mem: 17674M
[01/19 07:10:12] d2.utils.events INFO:  eta: 12:46:52  iter: 12559  total_loss: 63.96  loss_ce: 2.15  loss_mask: 0.6179  loss_dice: 3.377  loss_ce_0: 3.678  loss_mask_0: 0.6358  loss_dice_0: 3.651  loss_ce_1: 2.342  loss_mask_1: 0.631  loss_dice_1: 3.524  loss_ce_2: 2.228  loss_mask_2: 0.6225  loss_dice_2: 3.447  loss_ce_3: 2.186  loss_mask_3: 0.6202  loss_dice_3: 3.398  loss_ce_4: 2.161  loss_mask_4: 0.6221  loss_dice_4: 3.388  loss_ce_5: 2.157  loss_mask_5: 0.6151  loss_dice_5: 3.39  loss_ce_6: 2.146  loss_mask_6: 0.6159  loss_dice_6: 3.385  loss_ce_7: 2.139  loss_mask_7: 0.6182  loss_dice_7: 3.378  loss_ce_8: 2.145  loss_mask_8: 0.6149  loss_dice_8: 3.382  time: 1.6955  data_time: 0.3364  lr: 7.1237e-06  max_mem: 17674M
[01/19 07:10:46] d2.utils.events INFO:  eta: 12:46:19  iter: 12579  total_loss: 64.06  loss_ce: 2.114  loss_mask: 0.6242  loss_dice: 3.362  loss_ce_0: 3.668  loss_mask_0: 0.6455  loss_dice_0: 3.62  loss_ce_1: 2.374  loss_mask_1: 0.6296  loss_dice_1: 3.507  loss_ce_2: 2.243  loss_mask_2: 0.6305  loss_dice_2: 3.436  loss_ce_3: 2.182  loss_mask_3: 0.6237  loss_dice_3: 3.394  loss_ce_4: 2.152  loss_mask_4: 0.625  loss_dice_4: 3.379  loss_ce_5: 2.16  loss_mask_5: 0.6263  loss_dice_5: 3.386  loss_ce_6: 2.135  loss_mask_6: 0.628  loss_dice_6: 3.369  loss_ce_7: 2.107  loss_mask_7: 0.626  loss_dice_7: 3.365  loss_ce_8: 2.105  loss_mask_8: 0.6242  loss_dice_8: 3.372  time: 1.6954  data_time: 0.3289  lr: 7.119e-06  max_mem: 17674M
[01/19 07:11:20] d2.utils.events INFO:  eta: 12:45:39  iter: 12599  total_loss: 64.66  loss_ce: 2.215  loss_mask: 0.6306  loss_dice: 3.369  loss_ce_0: 3.675  loss_mask_0: 0.6466  loss_dice_0: 3.653  loss_ce_1: 2.424  loss_mask_1: 0.6419  loss_dice_1: 3.525  loss_ce_2: 2.319  loss_mask_2: 0.6365  loss_dice_2: 3.452  loss_ce_3: 2.281  loss_mask_3: 0.6332  loss_dice_3: 3.392  loss_ce_4: 2.239  loss_mask_4: 0.6327  loss_dice_4: 3.385  loss_ce_5: 2.225  loss_mask_5: 0.6345  loss_dice_5: 3.386  loss_ce_6: 2.225  loss_mask_6: 0.6337  loss_dice_6: 3.369  loss_ce_7: 2.203  loss_mask_7: 0.6353  loss_dice_7: 3.376  loss_ce_8: 2.2  loss_mask_8: 0.6318  loss_dice_8: 3.371  time: 1.6955  data_time: 0.3577  lr: 7.1144e-06  max_mem: 17674M
[01/19 07:11:53] d2.utils.events INFO:  eta: 12:44:58  iter: 12619  total_loss: 63.77  loss_ce: 2.205  loss_mask: 0.6324  loss_dice: 3.349  loss_ce_0: 3.63  loss_mask_0: 0.6575  loss_dice_0: 3.623  loss_ce_1: 2.362  loss_mask_1: 0.6448  loss_dice_1: 3.49  loss_ce_2: 2.266  loss_mask_2: 0.637  loss_dice_2: 3.426  loss_ce_3: 2.237  loss_mask_3: 0.6336  loss_dice_3: 3.378  loss_ce_4: 2.223  loss_mask_4: 0.6326  loss_dice_4: 3.364  loss_ce_5: 2.198  loss_mask_5: 0.6349  loss_dice_5: 3.365  loss_ce_6: 2.196  loss_mask_6: 0.6339  loss_dice_6: 3.356  loss_ce_7: 2.181  loss_mask_7: 0.6337  loss_dice_7: 3.357  loss_ce_8: 2.197  loss_mask_8: 0.6329  loss_dice_8: 3.357  time: 1.6954  data_time: 0.3195  lr: 7.1097e-06  max_mem: 17674M
[01/19 07:12:27] d2.utils.events INFO:  eta: 12:44:24  iter: 12639  total_loss: 64.91  loss_ce: 2.263  loss_mask: 0.6208  loss_dice: 3.36  loss_ce_0: 3.722  loss_mask_0: 0.6433  loss_dice_0: 3.623  loss_ce_1: 2.378  loss_mask_1: 0.6342  loss_dice_1: 3.502  loss_ce_2: 2.36  loss_mask_2: 0.6258  loss_dice_2: 3.438  loss_ce_3: 2.317  loss_mask_3: 0.6183  loss_dice_3: 3.392  loss_ce_4: 2.289  loss_mask_4: 0.6189  loss_dice_4: 3.381  loss_ce_5: 2.268  loss_mask_5: 0.6202  loss_dice_5: 3.375  loss_ce_6: 2.28  loss_mask_6: 0.6185  loss_dice_6: 3.366  loss_ce_7: 2.251  loss_mask_7: 0.6187  loss_dice_7: 3.36  loss_ce_8: 2.254  loss_mask_8: 0.6191  loss_dice_8: 3.365  time: 1.6954  data_time: 0.3298  lr: 7.105e-06  max_mem: 17674M
[01/19 07:13:00] d2.utils.events INFO:  eta: 12:43:55  iter: 12659  total_loss: 64.88  loss_ce: 2.306  loss_mask: 0.6306  loss_dice: 3.377  loss_ce_0: 3.667  loss_mask_0: 0.6448  loss_dice_0: 3.659  loss_ce_1: 2.451  loss_mask_1: 0.6413  loss_dice_1: 3.533  loss_ce_2: 2.347  loss_mask_2: 0.6353  loss_dice_2: 3.455  loss_ce_3: 2.347  loss_mask_3: 0.6317  loss_dice_3: 3.397  loss_ce_4: 2.307  loss_mask_4: 0.6351  loss_dice_4: 3.395  loss_ce_5: 2.294  loss_mask_5: 0.6339  loss_dice_5: 3.395  loss_ce_6: 2.288  loss_mask_6: 0.6315  loss_dice_6: 3.378  loss_ce_7: 2.302  loss_mask_7: 0.6311  loss_dice_7: 3.379  loss_ce_8: 2.289  loss_mask_8: 0.6311  loss_dice_8: 3.378  time: 1.6953  data_time: 0.3435  lr: 7.1003e-06  max_mem: 17674M
[01/19 07:13:34] d2.utils.events INFO:  eta: 12:43:13  iter: 12679  total_loss: 65.2  loss_ce: 2.293  loss_mask: 0.6499  loss_dice: 3.352  loss_ce_0: 3.688  loss_mask_0: 0.6685  loss_dice_0: 3.634  loss_ce_1: 2.482  loss_mask_1: 0.6731  loss_dice_1: 3.502  loss_ce_2: 2.371  loss_mask_2: 0.6594  loss_dice_2: 3.432  loss_ce_3: 2.33  loss_mask_3: 0.6484  loss_dice_3: 3.385  loss_ce_4: 2.314  loss_mask_4: 0.648  loss_dice_4: 3.374  loss_ce_5: 2.321  loss_mask_5: 0.6492  loss_dice_5: 3.375  loss_ce_6: 2.307  loss_mask_6: 0.6482  loss_dice_6: 3.359  loss_ce_7: 2.282  loss_mask_7: 0.6496  loss_dice_7: 3.36  loss_ce_8: 2.29  loss_mask_8: 0.648  loss_dice_8: 3.362  time: 1.6953  data_time: 0.3349  lr: 7.0957e-06  max_mem: 17674M
[01/19 07:14:07] d2.utils.events INFO:  eta: 12:42:37  iter: 12699  total_loss: 64.02  loss_ce: 2.169  loss_mask: 0.6093  loss_dice: 3.395  loss_ce_0: 3.637  loss_mask_0: 0.6299  loss_dice_0: 3.672  loss_ce_1: 2.39  loss_mask_1: 0.6139  loss_dice_1: 3.544  loss_ce_2: 2.24  loss_mask_2: 0.6114  loss_dice_2: 3.465  loss_ce_3: 2.216  loss_mask_3: 0.6071  loss_dice_3: 3.415  loss_ce_4: 2.18  loss_mask_4: 0.6091  loss_dice_4: 3.408  loss_ce_5: 2.162  loss_mask_5: 0.6105  loss_dice_5: 3.405  loss_ce_6: 2.153  loss_mask_6: 0.6084  loss_dice_6: 3.396  loss_ce_7: 2.139  loss_mask_7: 0.6073  loss_dice_7: 3.398  loss_ce_8: 2.147  loss_mask_8: 0.6078  loss_dice_8: 3.397  time: 1.6953  data_time: 0.3361  lr: 7.091e-06  max_mem: 17674M
[01/19 07:14:41] d2.utils.events INFO:  eta: 12:42:04  iter: 12719  total_loss: 64.07  loss_ce: 2.176  loss_mask: 0.6427  loss_dice: 3.351  loss_ce_0: 3.635  loss_mask_0: 0.6593  loss_dice_0: 3.618  loss_ce_1: 2.383  loss_mask_1: 0.6554  loss_dice_1: 3.506  loss_ce_2: 2.284  loss_mask_2: 0.6501  loss_dice_2: 3.43  loss_ce_3: 2.247  loss_mask_3: 0.6452  loss_dice_3: 3.381  loss_ce_4: 2.2  loss_mask_4: 0.6449  loss_dice_4: 3.381  loss_ce_5: 2.197  loss_mask_5: 0.6423  loss_dice_5: 3.371  loss_ce_6: 2.187  loss_mask_6: 0.6433  loss_dice_6: 3.367  loss_ce_7: 2.174  loss_mask_7: 0.6429  loss_dice_7: 3.359  loss_ce_8: 2.178  loss_mask_8: 0.6416  loss_dice_8: 3.36  time: 1.6953  data_time: 0.3385  lr: 7.0863e-06  max_mem: 17674M
[01/19 07:15:15] d2.utils.events INFO:  eta: 12:41:30  iter: 12739  total_loss: 64.38  loss_ce: 2.229  loss_mask: 0.6349  loss_dice: 3.311  loss_ce_0: 3.654  loss_mask_0: 0.6589  loss_dice_0: 3.606  loss_ce_1: 2.419  loss_mask_1: 0.6511  loss_dice_1: 3.465  loss_ce_2: 2.308  loss_mask_2: 0.6422  loss_dice_2: 3.383  loss_ce_3: 2.267  loss_mask_3: 0.6369  loss_dice_3: 3.333  loss_ce_4: 2.249  loss_mask_4: 0.6379  loss_dice_4: 3.334  loss_ce_5: 2.263  loss_mask_5: 0.64  loss_dice_5: 3.329  loss_ce_6: 2.236  loss_mask_6: 0.6383  loss_dice_6: 3.314  loss_ce_7: 2.214  loss_mask_7: 0.6382  loss_dice_7: 3.32  loss_ce_8: 2.215  loss_mask_8: 0.6383  loss_dice_8: 3.325  time: 1.6952  data_time: 0.3259  lr: 7.0816e-06  max_mem: 17674M
[01/19 07:15:48] d2.utils.events INFO:  eta: 12:40:51  iter: 12759  total_loss: 64.37  loss_ce: 2.188  loss_mask: 0.6318  loss_dice: 3.355  loss_ce_0: 3.686  loss_mask_0: 0.641  loss_dice_0: 3.635  loss_ce_1: 2.379  loss_mask_1: 0.6352  loss_dice_1: 3.509  loss_ce_2: 2.285  loss_mask_2: 0.6308  loss_dice_2: 3.436  loss_ce_3: 2.247  loss_mask_3: 0.6297  loss_dice_3: 3.382  loss_ce_4: 2.218  loss_mask_4: 0.6286  loss_dice_4: 3.376  loss_ce_5: 2.205  loss_mask_5: 0.6289  loss_dice_5: 3.381  loss_ce_6: 2.172  loss_mask_6: 0.6294  loss_dice_6: 3.364  loss_ce_7: 2.196  loss_mask_7: 0.6293  loss_dice_7: 3.364  loss_ce_8: 2.19  loss_mask_8: 0.633  loss_dice_8: 3.361  time: 1.6952  data_time: 0.3356  lr: 7.077e-06  max_mem: 17674M
[01/19 07:16:22] d2.utils.events INFO:  eta: 12:40:34  iter: 12779  total_loss: 64.66  loss_ce: 2.22  loss_mask: 0.6395  loss_dice: 3.386  loss_ce_0: 3.673  loss_mask_0: 0.6532  loss_dice_0: 3.646  loss_ce_1: 2.406  loss_mask_1: 0.6543  loss_dice_1: 3.527  loss_ce_2: 2.328  loss_mask_2: 0.6484  loss_dice_2: 3.458  loss_ce_3: 2.306  loss_mask_3: 0.6467  loss_dice_3: 3.404  loss_ce_4: 2.254  loss_mask_4: 0.6454  loss_dice_4: 3.404  loss_ce_5: 2.242  loss_mask_5: 0.6451  loss_dice_5: 3.398  loss_ce_6: 2.222  loss_mask_6: 0.6437  loss_dice_6: 3.387  loss_ce_7: 2.232  loss_mask_7: 0.6467  loss_dice_7: 3.387  loss_ce_8: 2.224  loss_mask_8: 0.6417  loss_dice_8: 3.382  time: 1.6952  data_time: 0.3285  lr: 7.0723e-06  max_mem: 17674M
[01/19 07:16:55] d2.utils.events INFO:  eta: 12:39:49  iter: 12799  total_loss: 64.02  loss_ce: 2.218  loss_mask: 0.6365  loss_dice: 3.305  loss_ce_0: 3.589  loss_mask_0: 0.6636  loss_dice_0: 3.59  loss_ce_1: 2.425  loss_mask_1: 0.6527  loss_dice_1: 3.444  loss_ce_2: 2.319  loss_mask_2: 0.6426  loss_dice_2: 3.378  loss_ce_3: 2.297  loss_mask_3: 0.6359  loss_dice_3: 3.33  loss_ce_4: 2.235  loss_mask_4: 0.6375  loss_dice_4: 3.325  loss_ce_5: 2.236  loss_mask_5: 0.6373  loss_dice_5: 3.326  loss_ce_6: 2.214  loss_mask_6: 0.6332  loss_dice_6: 3.305  loss_ce_7: 2.2  loss_mask_7: 0.6324  loss_dice_7: 3.308  loss_ce_8: 2.205  loss_mask_8: 0.6317  loss_dice_8: 3.31  time: 1.6951  data_time: 0.3243  lr: 7.0676e-06  max_mem: 17674M
[01/19 07:17:29] d2.utils.events INFO:  eta: 12:39:27  iter: 12819  total_loss: 64.27  loss_ce: 2.244  loss_mask: 0.6238  loss_dice: 3.371  loss_ce_0: 3.719  loss_mask_0: 0.6389  loss_dice_0: 3.629  loss_ce_1: 2.448  loss_mask_1: 0.6326  loss_dice_1: 3.517  loss_ce_2: 2.31  loss_mask_2: 0.6259  loss_dice_2: 3.443  loss_ce_3: 2.302  loss_mask_3: 0.6235  loss_dice_3: 3.389  loss_ce_4: 2.298  loss_mask_4: 0.6297  loss_dice_4: 3.39  loss_ce_5: 2.268  loss_mask_5: 0.6283  loss_dice_5: 3.377  loss_ce_6: 2.231  loss_mask_6: 0.6262  loss_dice_6: 3.38  loss_ce_7: 2.251  loss_mask_7: 0.6234  loss_dice_7: 3.368  loss_ce_8: 2.237  loss_mask_8: 0.6249  loss_dice_8: 3.362  time: 1.6951  data_time: 0.3426  lr: 7.0629e-06  max_mem: 17674M
[01/19 07:18:04] d2.utils.events INFO:  eta: 12:39:05  iter: 12839  total_loss: 65.65  loss_ce: 2.316  loss_mask: 0.6262  loss_dice: 3.4  loss_ce_0: 3.669  loss_mask_0: 0.6435  loss_dice_0: 3.671  loss_ce_1: 2.409  loss_mask_1: 0.628  loss_dice_1: 3.556  loss_ce_2: 2.345  loss_mask_2: 0.6284  loss_dice_2: 3.479  loss_ce_3: 2.335  loss_mask_3: 0.623  loss_dice_3: 3.434  loss_ce_4: 2.304  loss_mask_4: 0.6214  loss_dice_4: 3.427  loss_ce_5: 2.308  loss_mask_5: 0.6209  loss_dice_5: 3.425  loss_ce_6: 2.324  loss_mask_6: 0.6229  loss_dice_6: 3.409  loss_ce_7: 2.306  loss_mask_7: 0.6229  loss_dice_7: 3.411  loss_ce_8: 2.315  loss_mask_8: 0.6243  loss_dice_8: 3.407  time: 1.6952  data_time: 0.3615  lr: 7.0583e-06  max_mem: 17674M
[01/19 07:18:37] d2.utils.events INFO:  eta: 12:38:27  iter: 12859  total_loss: 63.89  loss_ce: 2.214  loss_mask: 0.6223  loss_dice: 3.339  loss_ce_0: 3.677  loss_mask_0: 0.6481  loss_dice_0: 3.623  loss_ce_1: 2.355  loss_mask_1: 0.6359  loss_dice_1: 3.501  loss_ce_2: 2.297  loss_mask_2: 0.629  loss_dice_2: 3.418  loss_ce_3: 2.264  loss_mask_3: 0.6253  loss_dice_3: 3.364  loss_ce_4: 2.23  loss_mask_4: 0.6238  loss_dice_4: 3.36  loss_ce_5: 2.229  loss_mask_5: 0.623  loss_dice_5: 3.354  loss_ce_6: 2.247  loss_mask_6: 0.6245  loss_dice_6: 3.338  loss_ce_7: 2.21  loss_mask_7: 0.6231  loss_dice_7: 3.339  loss_ce_8: 2.222  loss_mask_8: 0.6235  loss_dice_8: 3.332  time: 1.6951  data_time: 0.3327  lr: 7.0536e-06  max_mem: 17674M
[01/19 07:19:11] d2.utils.events INFO:  eta: 12:37:42  iter: 12879  total_loss: 64.97  loss_ce: 2.313  loss_mask: 0.6456  loss_dice: 3.31  loss_ce_0: 3.686  loss_mask_0: 0.6703  loss_dice_0: 3.607  loss_ce_1: 2.495  loss_mask_1: 0.6588  loss_dice_1: 3.464  loss_ce_2: 2.381  loss_mask_2: 0.6571  loss_dice_2: 3.387  loss_ce_3: 2.344  loss_mask_3: 0.6511  loss_dice_3: 3.333  loss_ce_4: 2.328  loss_mask_4: 0.6492  loss_dice_4: 3.333  loss_ce_5: 2.318  loss_mask_5: 0.6498  loss_dice_5: 3.331  loss_ce_6: 2.329  loss_mask_6: 0.6482  loss_dice_6: 3.314  loss_ce_7: 2.312  loss_mask_7: 0.6498  loss_dice_7: 3.312  loss_ce_8: 2.296  loss_mask_8: 0.6493  loss_dice_8: 3.315  time: 1.6951  data_time: 0.3359  lr: 7.0489e-06  max_mem: 17674M
[01/19 07:19:44] d2.utils.events INFO:  eta: 12:37:01  iter: 12899  total_loss: 64.1  loss_ce: 2.221  loss_mask: 0.6154  loss_dice: 3.358  loss_ce_0: 3.727  loss_mask_0: 0.6364  loss_dice_0: 3.625  loss_ce_1: 2.382  loss_mask_1: 0.6287  loss_dice_1: 3.504  loss_ce_2: 2.263  loss_mask_2: 0.6223  loss_dice_2: 3.437  loss_ce_3: 2.236  loss_mask_3: 0.6178  loss_dice_3: 3.388  loss_ce_4: 2.208  loss_mask_4: 0.6177  loss_dice_4: 3.376  loss_ce_5: 2.196  loss_mask_5: 0.6194  loss_dice_5: 3.374  loss_ce_6: 2.181  loss_mask_6: 0.6171  loss_dice_6: 3.368  loss_ce_7: 2.197  loss_mask_7: 0.6162  loss_dice_7: 3.363  loss_ce_8: 2.197  loss_mask_8: 0.6169  loss_dice_8: 3.366  time: 1.6951  data_time: 0.3397  lr: 7.0442e-06  max_mem: 17674M
[01/19 07:20:18] d2.utils.events INFO:  eta: 12:36:14  iter: 12919  total_loss: 64.26  loss_ce: 2.23  loss_mask: 0.6341  loss_dice: 3.342  loss_ce_0: 3.735  loss_mask_0: 0.6588  loss_dice_0: 3.623  loss_ce_1: 2.413  loss_mask_1: 0.6479  loss_dice_1: 3.486  loss_ce_2: 2.316  loss_mask_2: 0.6374  loss_dice_2: 3.416  loss_ce_3: 2.303  loss_mask_3: 0.6364  loss_dice_3: 3.373  loss_ce_4: 2.268  loss_mask_4: 0.6337  loss_dice_4: 3.371  loss_ce_5: 2.269  loss_mask_5: 0.636  loss_dice_5: 3.359  loss_ce_6: 2.251  loss_mask_6: 0.6336  loss_dice_6: 3.352  loss_ce_7: 2.242  loss_mask_7: 0.6333  loss_dice_7: 3.355  loss_ce_8: 2.232  loss_mask_8: 0.6324  loss_dice_8: 3.358  time: 1.6950  data_time: 0.3407  lr: 7.0395e-06  max_mem: 17674M
[01/19 07:20:52] d2.utils.events INFO:  eta: 12:36:09  iter: 12939  total_loss: 64.79  loss_ce: 2.23  loss_mask: 0.6183  loss_dice: 3.369  loss_ce_0: 3.677  loss_mask_0: 0.6351  loss_dice_0: 3.614  loss_ce_1: 2.441  loss_mask_1: 0.633  loss_dice_1: 3.501  loss_ce_2: 2.316  loss_mask_2: 0.6245  loss_dice_2: 3.426  loss_ce_3: 2.283  loss_mask_3: 0.6234  loss_dice_3: 3.376  loss_ce_4: 2.241  loss_mask_4: 0.6233  loss_dice_4: 3.383  loss_ce_5: 2.25  loss_mask_5: 0.622  loss_dice_5: 3.382  loss_ce_6: 2.243  loss_mask_6: 0.6207  loss_dice_6: 3.373  loss_ce_7: 2.238  loss_mask_7: 0.6186  loss_dice_7: 3.367  loss_ce_8: 2.207  loss_mask_8: 0.6199  loss_dice_8: 3.368  time: 1.6950  data_time: 0.3447  lr: 7.0349e-06  max_mem: 17674M
[01/19 07:21:26] d2.utils.events INFO:  eta: 12:35:33  iter: 12959  total_loss: 63.73  loss_ce: 2.18  loss_mask: 0.6102  loss_dice: 3.341  loss_ce_0: 3.654  loss_mask_0: 0.6399  loss_dice_0: 3.616  loss_ce_1: 2.379  loss_mask_1: 0.6283  loss_dice_1: 3.479  loss_ce_2: 2.276  loss_mask_2: 0.6181  loss_dice_2: 3.401  loss_ce_3: 2.234  loss_mask_3: 0.6163  loss_dice_3: 3.362  loss_ce_4: 2.212  loss_mask_4: 0.614  loss_dice_4: 3.356  loss_ce_5: 2.204  loss_mask_5: 0.6141  loss_dice_5: 3.355  loss_ce_6: 2.198  loss_mask_6: 0.6124  loss_dice_6: 3.344  loss_ce_7: 2.177  loss_mask_7: 0.6097  loss_dice_7: 3.343  loss_ce_8: 2.168  loss_mask_8: 0.6121  loss_dice_8: 3.347  time: 1.6950  data_time: 0.3502  lr: 7.0302e-06  max_mem: 17674M
[01/19 07:21:59] d2.utils.events INFO:  eta: 12:35:06  iter: 12979  total_loss: 64.43  loss_ce: 2.197  loss_mask: 0.6275  loss_dice: 3.344  loss_ce_0: 3.669  loss_mask_0: 0.6532  loss_dice_0: 3.625  loss_ce_1: 2.38  loss_mask_1: 0.643  loss_dice_1: 3.498  loss_ce_2: 2.277  loss_mask_2: 0.6306  loss_dice_2: 3.422  loss_ce_3: 2.234  loss_mask_3: 0.6333  loss_dice_3: 3.377  loss_ce_4: 2.199  loss_mask_4: 0.6314  loss_dice_4: 3.365  loss_ce_5: 2.186  loss_mask_5: 0.631  loss_dice_5: 3.36  loss_ce_6: 2.189  loss_mask_6: 0.63  loss_dice_6: 3.352  loss_ce_7: 2.184  loss_mask_7: 0.6295  loss_dice_7: 3.353  loss_ce_8: 2.199  loss_mask_8: 0.6292  loss_dice_8: 3.348  time: 1.6950  data_time: 0.3244  lr: 7.0255e-06  max_mem: 17674M
[01/19 07:22:33] d2.utils.events INFO:  eta: 12:34:25  iter: 12999  total_loss: 64.47  loss_ce: 2.206  loss_mask: 0.6096  loss_dice: 3.349  loss_ce_0: 3.715  loss_mask_0: 0.6416  loss_dice_0: 3.625  loss_ce_1: 2.385  loss_mask_1: 0.6282  loss_dice_1: 3.495  loss_ce_2: 2.304  loss_mask_2: 0.6195  loss_dice_2: 3.423  loss_ce_3: 2.257  loss_mask_3: 0.6131  loss_dice_3: 3.381  loss_ce_4: 2.223  loss_mask_4: 0.6146  loss_dice_4: 3.369  loss_ce_5: 2.217  loss_mask_5: 0.6118  loss_dice_5: 3.37  loss_ce_6: 2.22  loss_mask_6: 0.6098  loss_dice_6: 3.364  loss_ce_7: 2.199  loss_mask_7: 0.6126  loss_dice_7: 3.353  loss_ce_8: 2.202  loss_mask_8: 0.6138  loss_dice_8: 3.356  time: 1.6950  data_time: 0.3346  lr: 7.0208e-06  max_mem: 17674M
[01/19 07:23:06] d2.utils.events INFO:  eta: 12:33:59  iter: 13019  total_loss: 63.22  loss_ce: 2.078  loss_mask: 0.623  loss_dice: 3.391  loss_ce_0: 3.636  loss_mask_0: 0.6486  loss_dice_0: 3.65  loss_ce_1: 2.326  loss_mask_1: 0.6337  loss_dice_1: 3.523  loss_ce_2: 2.186  loss_mask_2: 0.6282  loss_dice_2: 3.448  loss_ce_3: 2.136  loss_mask_3: 0.6236  loss_dice_3: 3.405  loss_ce_4: 2.095  loss_mask_4: 0.6284  loss_dice_4: 3.397  loss_ce_5: 2.072  loss_mask_5: 0.6282  loss_dice_5: 3.401  loss_ce_6: 2.072  loss_mask_6: 0.6285  loss_dice_6: 3.39  loss_ce_7: 2.069  loss_mask_7: 0.6305  loss_dice_7: 3.391  loss_ce_8: 2.081  loss_mask_8: 0.6283  loss_dice_8: 3.39  time: 1.6949  data_time: 0.3292  lr: 7.0161e-06  max_mem: 17674M
[01/19 07:23:41] d2.utils.events INFO:  eta: 12:33:34  iter: 13039  total_loss: 64.03  loss_ce: 2.169  loss_mask: 0.6238  loss_dice: 3.346  loss_ce_0: 3.697  loss_mask_0: 0.6507  loss_dice_0: 3.64  loss_ce_1: 2.33  loss_mask_1: 0.6365  loss_dice_1: 3.502  loss_ce_2: 2.228  loss_mask_2: 0.6269  loss_dice_2: 3.428  loss_ce_3: 2.187  loss_mask_3: 0.6197  loss_dice_3: 3.369  loss_ce_4: 2.166  loss_mask_4: 0.6247  loss_dice_4: 3.37  loss_ce_5: 2.157  loss_mask_5: 0.6224  loss_dice_5: 3.369  loss_ce_6: 2.156  loss_mask_6: 0.6239  loss_dice_6: 3.359  loss_ce_7: 2.144  loss_mask_7: 0.6254  loss_dice_7: 3.353  loss_ce_8: 2.154  loss_mask_8: 0.6252  loss_dice_8: 3.357  time: 1.6950  data_time: 0.3536  lr: 7.0115e-06  max_mem: 17674M
[01/19 07:24:15] d2.utils.events INFO:  eta: 12:33:11  iter: 13059  total_loss: 64.42  loss_ce: 2.162  loss_mask: 0.6231  loss_dice: 3.373  loss_ce_0: 3.617  loss_mask_0: 0.642  loss_dice_0: 3.636  loss_ce_1: 2.351  loss_mask_1: 0.6362  loss_dice_1: 3.518  loss_ce_2: 2.24  loss_mask_2: 0.6289  loss_dice_2: 3.442  loss_ce_3: 2.209  loss_mask_3: 0.624  loss_dice_3: 3.396  loss_ce_4: 2.179  loss_mask_4: 0.6264  loss_dice_4: 3.389  loss_ce_5: 2.162  loss_mask_5: 0.6256  loss_dice_5: 3.391  loss_ce_6: 2.169  loss_mask_6: 0.6229  loss_dice_6: 3.378  loss_ce_7: 2.15  loss_mask_7: 0.6241  loss_dice_7: 3.382  loss_ce_8: 2.14  loss_mask_8: 0.6227  loss_dice_8: 3.379  time: 1.6950  data_time: 0.3636  lr: 7.0068e-06  max_mem: 17674M
[01/19 07:24:49] d2.utils.events INFO:  eta: 12:33:01  iter: 13079  total_loss: 64.38  loss_ce: 2.24  loss_mask: 0.6338  loss_dice: 3.325  loss_ce_0: 3.659  loss_mask_0: 0.6653  loss_dice_0: 3.602  loss_ce_1: 2.445  loss_mask_1: 0.65  loss_dice_1: 3.478  loss_ce_2: 2.343  loss_mask_2: 0.6441  loss_dice_2: 3.41  loss_ce_3: 2.312  loss_mask_3: 0.6377  loss_dice_3: 3.353  loss_ce_4: 2.259  loss_mask_4: 0.6358  loss_dice_4: 3.343  loss_ce_5: 2.245  loss_mask_5: 0.6363  loss_dice_5: 3.352  loss_ce_6: 2.242  loss_mask_6: 0.6349  loss_dice_6: 3.332  loss_ce_7: 2.232  loss_mask_7: 0.6322  loss_dice_7: 3.332  loss_ce_8: 2.226  loss_mask_8: 0.6363  loss_dice_8: 3.334  time: 1.6950  data_time: 0.3616  lr: 7.0021e-06  max_mem: 17674M
[01/19 07:25:22] d2.utils.events INFO:  eta: 12:32:27  iter: 13099  total_loss: 63.96  loss_ce: 2.188  loss_mask: 0.6152  loss_dice: 3.365  loss_ce_0: 3.63  loss_mask_0: 0.633  loss_dice_0: 3.633  loss_ce_1: 2.378  loss_mask_1: 0.6278  loss_dice_1: 3.507  loss_ce_2: 2.273  loss_mask_2: 0.6239  loss_dice_2: 3.442  loss_ce_3: 2.235  loss_mask_3: 0.6167  loss_dice_3: 3.394  loss_ce_4: 2.214  loss_mask_4: 0.618  loss_dice_4: 3.385  loss_ce_5: 2.215  loss_mask_5: 0.621  loss_dice_5: 3.374  loss_ce_6: 2.198  loss_mask_6: 0.6173  loss_dice_6: 3.367  loss_ce_7: 2.191  loss_mask_7: 0.6176  loss_dice_7: 3.369  loss_ce_8: 2.18  loss_mask_8: 0.6141  loss_dice_8: 3.365  time: 1.6950  data_time: 0.3478  lr: 6.9974e-06  max_mem: 17674M
[01/19 07:25:56] d2.utils.events INFO:  eta: 12:32:06  iter: 13119  total_loss: 64.18  loss_ce: 2.173  loss_mask: 0.6077  loss_dice: 3.329  loss_ce_0: 3.661  loss_mask_0: 0.6267  loss_dice_0: 3.615  loss_ce_1: 2.403  loss_mask_1: 0.6198  loss_dice_1: 3.486  loss_ce_2: 2.301  loss_mask_2: 0.6136  loss_dice_2: 3.405  loss_ce_3: 2.256  loss_mask_3: 0.6065  loss_dice_3: 3.359  loss_ce_4: 2.196  loss_mask_4: 0.6065  loss_dice_4: 3.351  loss_ce_5: 2.191  loss_mask_5: 0.6069  loss_dice_5: 3.351  loss_ce_6: 2.203  loss_mask_6: 0.6051  loss_dice_6: 3.34  loss_ce_7: 2.169  loss_mask_7: 0.6056  loss_dice_7: 3.34  loss_ce_8: 2.174  loss_mask_8: 0.6092  loss_dice_8: 3.332  time: 1.6950  data_time: 0.3492  lr: 6.9927e-06  max_mem: 17674M
[01/19 07:26:31] d2.utils.events INFO:  eta: 12:31:58  iter: 13139  total_loss: 64.31  loss_ce: 2.181  loss_mask: 0.6211  loss_dice: 3.386  loss_ce_0: 3.689  loss_mask_0: 0.6398  loss_dice_0: 3.644  loss_ce_1: 2.359  loss_mask_1: 0.6371  loss_dice_1: 3.515  loss_ce_2: 2.237  loss_mask_2: 0.6294  loss_dice_2: 3.447  loss_ce_3: 2.223  loss_mask_3: 0.6206  loss_dice_3: 3.407  loss_ce_4: 2.211  loss_mask_4: 0.6255  loss_dice_4: 3.402  loss_ce_5: 2.179  loss_mask_5: 0.6217  loss_dice_5: 3.398  loss_ce_6: 2.18  loss_mask_6: 0.6229  loss_dice_6: 3.391  loss_ce_7: 2.175  loss_mask_7: 0.6203  loss_dice_7: 3.389  loss_ce_8: 2.181  loss_mask_8: 0.6221  loss_dice_8: 3.385  time: 1.6950  data_time: 0.3602  lr: 6.988e-06  max_mem: 17674M
[01/19 07:27:04] d2.utils.events INFO:  eta: 12:31:31  iter: 13159  total_loss: 63.97  loss_ce: 2.17  loss_mask: 0.6283  loss_dice: 3.325  loss_ce_0: 3.681  loss_mask_0: 0.6597  loss_dice_0: 3.618  loss_ce_1: 2.362  loss_mask_1: 0.6426  loss_dice_1: 3.491  loss_ce_2: 2.241  loss_mask_2: 0.636  loss_dice_2: 3.417  loss_ce_3: 2.223  loss_mask_3: 0.6356  loss_dice_3: 3.361  loss_ce_4: 2.193  loss_mask_4: 0.6328  loss_dice_4: 3.353  loss_ce_5: 2.19  loss_mask_5: 0.6325  loss_dice_5: 3.345  loss_ce_6: 2.186  loss_mask_6: 0.6317  loss_dice_6: 3.336  loss_ce_7: 2.152  loss_mask_7: 0.6303  loss_dice_7: 3.333  loss_ce_8: 2.171  loss_mask_8: 0.6306  loss_dice_8: 3.324  time: 1.6950  data_time: 0.3590  lr: 6.9834e-06  max_mem: 17674M
[01/19 07:27:38] d2.utils.events INFO:  eta: 12:31:07  iter: 13179  total_loss: 64.23  loss_ce: 2.151  loss_mask: 0.6285  loss_dice: 3.353  loss_ce_0: 3.673  loss_mask_0: 0.6488  loss_dice_0: 3.641  loss_ce_1: 2.354  loss_mask_1: 0.6364  loss_dice_1: 3.504  loss_ce_2: 2.209  loss_mask_2: 0.6296  loss_dice_2: 3.427  loss_ce_3: 2.221  loss_mask_3: 0.6285  loss_dice_3: 3.375  loss_ce_4: 2.191  loss_mask_4: 0.6295  loss_dice_4: 3.376  loss_ce_5: 2.166  loss_mask_5: 0.6291  loss_dice_5: 3.371  loss_ce_6: 2.183  loss_mask_6: 0.6283  loss_dice_6: 3.358  loss_ce_7: 2.144  loss_mask_7: 0.6289  loss_dice_7: 3.359  loss_ce_8: 2.166  loss_mask_8: 0.6259  loss_dice_8: 3.362  time: 1.6950  data_time: 0.3418  lr: 6.9787e-06  max_mem: 17674M
[01/19 07:28:12] d2.utils.events INFO:  eta: 12:30:38  iter: 13199  total_loss: 64.6  loss_ce: 2.211  loss_mask: 0.6277  loss_dice: 3.379  loss_ce_0: 3.646  loss_mask_0: 0.6453  loss_dice_0: 3.651  loss_ce_1: 2.453  loss_mask_1: 0.6342  loss_dice_1: 3.513  loss_ce_2: 2.309  loss_mask_2: 0.6323  loss_dice_2: 3.435  loss_ce_3: 2.307  loss_mask_3: 0.6265  loss_dice_3: 3.399  loss_ce_4: 2.259  loss_mask_4: 0.6268  loss_dice_4: 3.399  loss_ce_5: 2.23  loss_mask_5: 0.6259  loss_dice_5: 3.392  loss_ce_6: 2.238  loss_mask_6: 0.6277  loss_dice_6: 3.383  loss_ce_7: 2.226  loss_mask_7: 0.6289  loss_dice_7: 3.387  loss_ce_8: 2.207  loss_mask_8: 0.6269  loss_dice_8: 3.378  time: 1.6950  data_time: 0.3402  lr: 6.974e-06  max_mem: 17674M
[01/19 07:28:46] d2.utils.events INFO:  eta: 12:30:05  iter: 13219  total_loss: 63.33  loss_ce: 2.069  loss_mask: 0.618  loss_dice: 3.358  loss_ce_0: 3.571  loss_mask_0: 0.6336  loss_dice_0: 3.628  loss_ce_1: 2.317  loss_mask_1: 0.6296  loss_dice_1: 3.509  loss_ce_2: 2.213  loss_mask_2: 0.6241  loss_dice_2: 3.432  loss_ce_3: 2.141  loss_mask_3: 0.6188  loss_dice_3: 3.394  loss_ce_4: 2.125  loss_mask_4: 0.6209  loss_dice_4: 3.38  loss_ce_5: 2.103  loss_mask_5: 0.6199  loss_dice_5: 3.38  loss_ce_6: 2.099  loss_mask_6: 0.6179  loss_dice_6: 3.359  loss_ce_7: 2.079  loss_mask_7: 0.6172  loss_dice_7: 3.361  loss_ce_8: 2.07  loss_mask_8: 0.6193  loss_dice_8: 3.354  time: 1.6950  data_time: 0.3523  lr: 6.9693e-06  max_mem: 17674M
[01/19 07:29:20] d2.utils.events INFO:  eta: 12:29:53  iter: 13239  total_loss: 63.8  loss_ce: 2.158  loss_mask: 0.6224  loss_dice: 3.328  loss_ce_0: 3.646  loss_mask_0: 0.6406  loss_dice_0: 3.617  loss_ce_1: 2.367  loss_mask_1: 0.6283  loss_dice_1: 3.466  loss_ce_2: 2.243  loss_mask_2: 0.6256  loss_dice_2: 3.399  loss_ce_3: 2.229  loss_mask_3: 0.6227  loss_dice_3: 3.344  loss_ce_4: 2.185  loss_mask_4: 0.6241  loss_dice_4: 3.346  loss_ce_5: 2.176  loss_mask_5: 0.6229  loss_dice_5: 3.339  loss_ce_6: 2.174  loss_mask_6: 0.6257  loss_dice_6: 3.321  loss_ce_7: 2.148  loss_mask_7: 0.6227  loss_dice_7: 3.326  loss_ce_8: 2.136  loss_mask_8: 0.6234  loss_dice_8: 3.321  time: 1.6950  data_time: 0.3490  lr: 6.9646e-06  max_mem: 17674M
[01/19 07:29:54] d2.utils.events INFO:  eta: 12:29:28  iter: 13259  total_loss: 64.27  loss_ce: 2.2  loss_mask: 0.6234  loss_dice: 3.393  loss_ce_0: 3.639  loss_mask_0: 0.6445  loss_dice_0: 3.656  loss_ce_1: 2.382  loss_mask_1: 0.6307  loss_dice_1: 3.531  loss_ce_2: 2.257  loss_mask_2: 0.6278  loss_dice_2: 3.455  loss_ce_3: 2.234  loss_mask_3: 0.6236  loss_dice_3: 3.413  loss_ce_4: 2.182  loss_mask_4: 0.6255  loss_dice_4: 3.407  loss_ce_5: 2.181  loss_mask_5: 0.6265  loss_dice_5: 3.402  loss_ce_6: 2.176  loss_mask_6: 0.6239  loss_dice_6: 3.391  loss_ce_7: 2.167  loss_mask_7: 0.6237  loss_dice_7: 3.394  loss_ce_8: 2.176  loss_mask_8: 0.6225  loss_dice_8: 3.395  time: 1.6950  data_time: 0.3522  lr: 6.9599e-06  max_mem: 17674M
[01/19 07:30:28] d2.utils.events INFO:  eta: 12:28:55  iter: 13279  total_loss: 63.93  loss_ce: 2.216  loss_mask: 0.6241  loss_dice: 3.34  loss_ce_0: 3.656  loss_mask_0: 0.6452  loss_dice_0: 3.605  loss_ce_1: 2.365  loss_mask_1: 0.6385  loss_dice_1: 3.501  loss_ce_2: 2.283  loss_mask_2: 0.6335  loss_dice_2: 3.416  loss_ce_3: 2.271  loss_mask_3: 0.6275  loss_dice_3: 3.375  loss_ce_4: 2.257  loss_mask_4: 0.6276  loss_dice_4: 3.371  loss_ce_5: 2.207  loss_mask_5: 0.6278  loss_dice_5: 3.362  loss_ce_6: 2.198  loss_mask_6: 0.6262  loss_dice_6: 3.355  loss_ce_7: 2.216  loss_mask_7: 0.6231  loss_dice_7: 3.352  loss_ce_8: 2.188  loss_mask_8: 0.6258  loss_dice_8: 3.355  time: 1.6950  data_time: 0.3393  lr: 6.9553e-06  max_mem: 17674M
[01/19 07:31:02] d2.utils.events INFO:  eta: 12:28:28  iter: 13299  total_loss: 64.25  loss_ce: 2.25  loss_mask: 0.6159  loss_dice: 3.297  loss_ce_0: 3.638  loss_mask_0: 0.6431  loss_dice_0: 3.609  loss_ce_1: 2.42  loss_mask_1: 0.6185  loss_dice_1: 3.463  loss_ce_2: 2.31  loss_mask_2: 0.6185  loss_dice_2: 3.386  loss_ce_3: 2.295  loss_mask_3: 0.6167  loss_dice_3: 3.333  loss_ce_4: 2.259  loss_mask_4: 0.614  loss_dice_4: 3.328  loss_ce_5: 2.238  loss_mask_5: 0.6161  loss_dice_5: 3.325  loss_ce_6: 2.249  loss_mask_6: 0.6134  loss_dice_6: 3.31  loss_ce_7: 2.236  loss_mask_7: 0.617  loss_dice_7: 3.306  loss_ce_8: 2.24  loss_mask_8: 0.6161  loss_dice_8: 3.307  time: 1.6949  data_time: 0.3343  lr: 6.9506e-06  max_mem: 17674M
[01/19 07:31:36] d2.utils.events INFO:  eta: 12:27:54  iter: 13319  total_loss: 64.11  loss_ce: 2.201  loss_mask: 0.6281  loss_dice: 3.347  loss_ce_0: 3.561  loss_mask_0: 0.6424  loss_dice_0: 3.628  loss_ce_1: 2.381  loss_mask_1: 0.6419  loss_dice_1: 3.472  loss_ce_2: 2.264  loss_mask_2: 0.6391  loss_dice_2: 3.404  loss_ce_3: 2.248  loss_mask_3: 0.6323  loss_dice_3: 3.366  loss_ce_4: 2.207  loss_mask_4: 0.6316  loss_dice_4: 3.366  loss_ce_5: 2.199  loss_mask_5: 0.6292  loss_dice_5: 3.364  loss_ce_6: 2.2  loss_mask_6: 0.6264  loss_dice_6: 3.347  loss_ce_7: 2.193  loss_mask_7: 0.6276  loss_dice_7: 3.346  loss_ce_8: 2.184  loss_mask_8: 0.628  loss_dice_8: 3.347  time: 1.6949  data_time: 0.3431  lr: 6.9459e-06  max_mem: 17674M
[01/19 07:32:09] d2.utils.events INFO:  eta: 12:27:21  iter: 13339  total_loss: 64.56  loss_ce: 2.226  loss_mask: 0.6331  loss_dice: 3.327  loss_ce_0: 3.691  loss_mask_0: 0.6597  loss_dice_0: 3.604  loss_ce_1: 2.408  loss_mask_1: 0.6433  loss_dice_1: 3.474  loss_ce_2: 2.343  loss_mask_2: 0.6371  loss_dice_2: 3.404  loss_ce_3: 2.297  loss_mask_3: 0.6307  loss_dice_3: 3.352  loss_ce_4: 2.267  loss_mask_4: 0.6309  loss_dice_4: 3.348  loss_ce_5: 2.237  loss_mask_5: 0.6332  loss_dice_5: 3.344  loss_ce_6: 2.233  loss_mask_6: 0.6342  loss_dice_6: 3.328  loss_ce_7: 2.225  loss_mask_7: 0.6362  loss_dice_7: 3.327  loss_ce_8: 2.217  loss_mask_8: 0.6353  loss_dice_8: 3.332  time: 1.6949  data_time: 0.3424  lr: 6.9412e-06  max_mem: 17674M
[01/19 07:32:44] d2.utils.events INFO:  eta: 12:26:48  iter: 13359  total_loss: 63.46  loss_ce: 2.173  loss_mask: 0.6068  loss_dice: 3.369  loss_ce_0: 3.717  loss_mask_0: 0.626  loss_dice_0: 3.653  loss_ce_1: 2.337  loss_mask_1: 0.6161  loss_dice_1: 3.527  loss_ce_2: 2.202  loss_mask_2: 0.6096  loss_dice_2: 3.452  loss_ce_3: 2.196  loss_mask_3: 0.609  loss_dice_3: 3.406  loss_ce_4: 2.163  loss_mask_4: 0.6081  loss_dice_4: 3.392  loss_ce_5: 2.147  loss_mask_5: 0.6086  loss_dice_5: 3.39  loss_ce_6: 2.167  loss_mask_6: 0.6082  loss_dice_6: 3.377  loss_ce_7: 2.145  loss_mask_7: 0.6064  loss_dice_7: 3.376  loss_ce_8: 2.161  loss_mask_8: 0.6081  loss_dice_8: 3.381  time: 1.6950  data_time: 0.3663  lr: 6.9365e-06  max_mem: 17674M
[01/19 07:33:18] d2.utils.events INFO:  eta: 12:26:35  iter: 13379  total_loss: 64.28  loss_ce: 2.196  loss_mask: 0.6259  loss_dice: 3.373  loss_ce_0: 3.649  loss_mask_0: 0.6473  loss_dice_0: 3.647  loss_ce_1: 2.413  loss_mask_1: 0.6396  loss_dice_1: 3.518  loss_ce_2: 2.281  loss_mask_2: 0.6337  loss_dice_2: 3.435  loss_ce_3: 2.252  loss_mask_3: 0.6272  loss_dice_3: 3.399  loss_ce_4: 2.228  loss_mask_4: 0.6292  loss_dice_4: 3.391  loss_ce_5: 2.205  loss_mask_5: 0.6285  loss_dice_5: 3.392  loss_ce_6: 2.214  loss_mask_6: 0.6247  loss_dice_6: 3.375  loss_ce_7: 2.206  loss_mask_7: 0.6271  loss_dice_7: 3.383  loss_ce_8: 2.182  loss_mask_8: 0.6269  loss_dice_8: 3.384  time: 1.6950  data_time: 0.3298  lr: 6.9318e-06  max_mem: 17674M
[01/19 07:33:51] d2.utils.events INFO:  eta: 12:25:45  iter: 13399  total_loss: 64.32  loss_ce: 2.193  loss_mask: 0.6269  loss_dice: 3.349  loss_ce_0: 3.653  loss_mask_0: 0.6558  loss_dice_0: 3.621  loss_ce_1: 2.394  loss_mask_1: 0.6406  loss_dice_1: 3.506  loss_ce_2: 2.237  loss_mask_2: 0.6313  loss_dice_2: 3.429  loss_ce_3: 2.239  loss_mask_3: 0.6264  loss_dice_3: 3.373  loss_ce_4: 2.227  loss_mask_4: 0.6262  loss_dice_4: 3.365  loss_ce_5: 2.197  loss_mask_5: 0.6288  loss_dice_5: 3.367  loss_ce_6: 2.183  loss_mask_6: 0.6258  loss_dice_6: 3.353  loss_ce_7: 2.185  loss_mask_7: 0.6279  loss_dice_7: 3.348  loss_ce_8: 2.22  loss_mask_8: 0.6258  loss_dice_8: 3.353  time: 1.6949  data_time: 0.3351  lr: 6.9271e-06  max_mem: 17674M
[01/19 07:34:25] d2.utils.events INFO:  eta: 12:25:10  iter: 13419  total_loss: 63.87  loss_ce: 2.17  loss_mask: 0.631  loss_dice: 3.351  loss_ce_0: 3.605  loss_mask_0: 0.6513  loss_dice_0: 3.633  loss_ce_1: 2.364  loss_mask_1: 0.6364  loss_dice_1: 3.507  loss_ce_2: 2.233  loss_mask_2: 0.6332  loss_dice_2: 3.432  loss_ce_3: 2.219  loss_mask_3: 0.6296  loss_dice_3: 3.385  loss_ce_4: 2.171  loss_mask_4: 0.632  loss_dice_4: 3.373  loss_ce_5: 2.158  loss_mask_5: 0.6294  loss_dice_5: 3.373  loss_ce_6: 2.171  loss_mask_6: 0.631  loss_dice_6: 3.362  loss_ce_7: 2.164  loss_mask_7: 0.63  loss_dice_7: 3.362  loss_ce_8: 2.164  loss_mask_8: 0.6335  loss_dice_8: 3.355  time: 1.6949  data_time: 0.3289  lr: 6.9225e-06  max_mem: 17674M
[01/19 07:34:59] d2.utils.events INFO:  eta: 12:24:51  iter: 13439  total_loss: 64.28  loss_ce: 2.221  loss_mask: 0.6272  loss_dice: 3.346  loss_ce_0: 3.678  loss_mask_0: 0.647  loss_dice_0: 3.623  loss_ce_1: 2.427  loss_mask_1: 0.6375  loss_dice_1: 3.479  loss_ce_2: 2.295  loss_mask_2: 0.633  loss_dice_2: 3.412  loss_ce_3: 2.278  loss_mask_3: 0.6261  loss_dice_3: 3.366  loss_ce_4: 2.26  loss_mask_4: 0.6231  loss_dice_4: 3.365  loss_ce_5: 2.232  loss_mask_5: 0.6247  loss_dice_5: 3.362  loss_ce_6: 2.232  loss_mask_6: 0.6253  loss_dice_6: 3.355  loss_ce_7: 2.221  loss_mask_7: 0.6278  loss_dice_7: 3.348  loss_ce_8: 2.226  loss_mask_8: 0.6278  loss_dice_8: 3.349  time: 1.6949  data_time: 0.3532  lr: 6.9178e-06  max_mem: 17674M
[01/19 07:35:33] d2.utils.events INFO:  eta: 12:24:22  iter: 13459  total_loss: 63.6  loss_ce: 2.136  loss_mask: 0.6126  loss_dice: 3.353  loss_ce_0: 3.607  loss_mask_0: 0.6403  loss_dice_0: 3.624  loss_ce_1: 2.261  loss_mask_1: 0.6329  loss_dice_1: 3.486  loss_ce_2: 2.183  loss_mask_2: 0.6216  loss_dice_2: 3.422  loss_ce_3: 2.186  loss_mask_3: 0.6147  loss_dice_3: 3.376  loss_ce_4: 2.156  loss_mask_4: 0.6136  loss_dice_4: 3.369  loss_ce_5: 2.155  loss_mask_5: 0.6149  loss_dice_5: 3.37  loss_ce_6: 2.149  loss_mask_6: 0.6122  loss_dice_6: 3.35  loss_ce_7: 2.127  loss_mask_7: 0.6141  loss_dice_7: 3.355  loss_ce_8: 2.13  loss_mask_8: 0.6164  loss_dice_8: 3.349  time: 1.6949  data_time: 0.3334  lr: 6.9131e-06  max_mem: 17674M
[01/19 07:36:07] d2.utils.events INFO:  eta: 12:23:46  iter: 13479  total_loss: 63.39  loss_ce: 2.108  loss_mask: 0.6252  loss_dice: 3.324  loss_ce_0: 3.629  loss_mask_0: 0.6448  loss_dice_0: 3.601  loss_ce_1: 2.326  loss_mask_1: 0.6336  loss_dice_1: 3.457  loss_ce_2: 2.2  loss_mask_2: 0.6313  loss_dice_2: 3.396  loss_ce_3: 2.214  loss_mask_3: 0.6262  loss_dice_3: 3.351  loss_ce_4: 2.162  loss_mask_4: 0.6286  loss_dice_4: 3.343  loss_ce_5: 2.153  loss_mask_5: 0.6276  loss_dice_5: 3.346  loss_ce_6: 2.13  loss_mask_6: 0.6281  loss_dice_6: 3.33  loss_ce_7: 2.111  loss_mask_7: 0.6272  loss_dice_7: 3.326  loss_ce_8: 2.128  loss_mask_8: 0.6257  loss_dice_8: 3.332  time: 1.6949  data_time: 0.3445  lr: 6.9084e-06  max_mem: 17674M
[01/19 07:36:41] d2.utils.events INFO:  eta: 12:23:13  iter: 13499  total_loss: 63.75  loss_ce: 2.152  loss_mask: 0.624  loss_dice: 3.341  loss_ce_0: 3.667  loss_mask_0: 0.6551  loss_dice_0: 3.604  loss_ce_1: 2.402  loss_mask_1: 0.6376  loss_dice_1: 3.471  loss_ce_2: 2.28  loss_mask_2: 0.6327  loss_dice_2: 3.405  loss_ce_3: 2.242  loss_mask_3: 0.6295  loss_dice_3: 3.362  loss_ce_4: 2.199  loss_mask_4: 0.6291  loss_dice_4: 3.357  loss_ce_5: 2.185  loss_mask_5: 0.6273  loss_dice_5: 3.351  loss_ce_6: 2.187  loss_mask_6: 0.6242  loss_dice_6: 3.341  loss_ce_7: 2.167  loss_mask_7: 0.6236  loss_dice_7: 3.342  loss_ce_8: 2.15  loss_mask_8: 0.6242  loss_dice_8: 3.335  time: 1.6949  data_time: 0.3658  lr: 6.9037e-06  max_mem: 17674M
[01/19 07:37:15] d2.utils.events INFO:  eta: 12:22:54  iter: 13519  total_loss: 63.64  loss_ce: 2.076  loss_mask: 0.6227  loss_dice: 3.344  loss_ce_0: 3.637  loss_mask_0: 0.6403  loss_dice_0: 3.621  loss_ce_1: 2.328  loss_mask_1: 0.6301  loss_dice_1: 3.492  loss_ce_2: 2.207  loss_mask_2: 0.6297  loss_dice_2: 3.413  loss_ce_3: 2.156  loss_mask_3: 0.6188  loss_dice_3: 3.371  loss_ce_4: 2.123  loss_mask_4: 0.6166  loss_dice_4: 3.367  loss_ce_5: 2.099  loss_mask_5: 0.6226  loss_dice_5: 3.365  loss_ce_6: 2.098  loss_mask_6: 0.6201  loss_dice_6: 3.349  loss_ce_7: 2.086  loss_mask_7: 0.6211  loss_dice_7: 3.349  loss_ce_8: 2.093  loss_mask_8: 0.6227  loss_dice_8: 3.344  time: 1.6949  data_time: 0.3516  lr: 6.899e-06  max_mem: 17674M
[01/19 07:37:49] d2.utils.events INFO:  eta: 12:22:32  iter: 13539  total_loss: 63.51  loss_ce: 2.167  loss_mask: 0.6219  loss_dice: 3.363  loss_ce_0: 3.731  loss_mask_0: 0.6379  loss_dice_0: 3.609  loss_ce_1: 2.32  loss_mask_1: 0.6319  loss_dice_1: 3.505  loss_ce_2: 2.181  loss_mask_2: 0.6247  loss_dice_2: 3.432  loss_ce_3: 2.175  loss_mask_3: 0.62  loss_dice_3: 3.394  loss_ce_4: 2.165  loss_mask_4: 0.6202  loss_dice_4: 3.385  loss_ce_5: 2.144  loss_mask_5: 0.622  loss_dice_5: 3.383  loss_ce_6: 2.141  loss_mask_6: 0.6207  loss_dice_6: 3.372  loss_ce_7: 2.145  loss_mask_7: 0.6229  loss_dice_7: 3.368  loss_ce_8: 2.149  loss_mask_8: 0.6237  loss_dice_8: 3.367  time: 1.6949  data_time: 0.3333  lr: 6.8943e-06  max_mem: 17674M
[01/19 07:38:23] d2.utils.events INFO:  eta: 12:22:08  iter: 13559  total_loss: 63.68  loss_ce: 2.173  loss_mask: 0.6378  loss_dice: 3.322  loss_ce_0: 3.682  loss_mask_0: 0.6571  loss_dice_0: 3.602  loss_ce_1: 2.378  loss_mask_1: 0.6523  loss_dice_1: 3.463  loss_ce_2: 2.265  loss_mask_2: 0.6425  loss_dice_2: 3.394  loss_ce_3: 2.224  loss_mask_3: 0.6358  loss_dice_3: 3.353  loss_ce_4: 2.199  loss_mask_4: 0.6361  loss_dice_4: 3.344  loss_ce_5: 2.171  loss_mask_5: 0.6349  loss_dice_5: 3.344  loss_ce_6: 2.177  loss_mask_6: 0.6341  loss_dice_6: 3.329  loss_ce_7: 2.151  loss_mask_7: 0.636  loss_dice_7: 3.328  loss_ce_8: 2.158  loss_mask_8: 0.638  loss_dice_8: 3.325  time: 1.6950  data_time: 0.3742  lr: 6.8896e-06  max_mem: 17674M
[01/19 07:38:57] d2.utils.events INFO:  eta: 12:21:36  iter: 13579  total_loss: 63.96  loss_ce: 2.182  loss_mask: 0.6114  loss_dice: 3.356  loss_ce_0: 3.602  loss_mask_0: 0.6325  loss_dice_0: 3.638  loss_ce_1: 2.367  loss_mask_1: 0.6193  loss_dice_1: 3.521  loss_ce_2: 2.274  loss_mask_2: 0.6168  loss_dice_2: 3.435  loss_ce_3: 2.223  loss_mask_3: 0.6161  loss_dice_3: 3.383  loss_ce_4: 2.194  loss_mask_4: 0.6146  loss_dice_4: 3.382  loss_ce_5: 2.183  loss_mask_5: 0.6173  loss_dice_5: 3.381  loss_ce_6: 2.17  loss_mask_6: 0.615  loss_dice_6: 3.365  loss_ce_7: 2.16  loss_mask_7: 0.6145  loss_dice_7: 3.362  loss_ce_8: 2.169  loss_mask_8: 0.6134  loss_dice_8: 3.363  time: 1.6949  data_time: 0.3374  lr: 6.8849e-06  max_mem: 17674M
[01/19 07:39:31] d2.utils.events INFO:  eta: 12:21:01  iter: 13599  total_loss: 63.05  loss_ce: 2.142  loss_mask: 0.6209  loss_dice: 3.299  loss_ce_0: 3.625  loss_mask_0: 0.6485  loss_dice_0: 3.594  loss_ce_1: 2.401  loss_mask_1: 0.636  loss_dice_1: 3.436  loss_ce_2: 2.266  loss_mask_2: 0.6206  loss_dice_2: 3.37  loss_ce_3: 2.221  loss_mask_3: 0.6182  loss_dice_3: 3.324  loss_ce_4: 2.185  loss_mask_4: 0.6181  loss_dice_4: 3.319  loss_ce_5: 2.165  loss_mask_5: 0.6192  loss_dice_5: 3.321  loss_ce_6: 2.161  loss_mask_6: 0.6205  loss_dice_6: 3.305  loss_ce_7: 2.133  loss_mask_7: 0.6214  loss_dice_7: 3.302  loss_ce_8: 2.131  loss_mask_8: 0.6221  loss_dice_8: 3.302  time: 1.6949  data_time: 0.3450  lr: 6.8803e-06  max_mem: 17674M
[01/19 07:40:04] d2.utils.events INFO:  eta: 12:20:43  iter: 13619  total_loss: 64.07  loss_ce: 2.221  loss_mask: 0.6345  loss_dice: 3.339  loss_ce_0: 3.633  loss_mask_0: 0.6578  loss_dice_0: 3.588  loss_ce_1: 2.404  loss_mask_1: 0.6432  loss_dice_1: 3.489  loss_ce_2: 2.288  loss_mask_2: 0.6355  loss_dice_2: 3.416  loss_ce_3: 2.241  loss_mask_3: 0.6304  loss_dice_3: 3.367  loss_ce_4: 2.229  loss_mask_4: 0.6348  loss_dice_4: 3.362  loss_ce_5: 2.207  loss_mask_5: 0.6344  loss_dice_5: 3.364  loss_ce_6: 2.202  loss_mask_6: 0.6342  loss_dice_6: 3.345  loss_ce_7: 2.204  loss_mask_7: 0.6362  loss_dice_7: 3.343  loss_ce_8: 2.189  loss_mask_8: 0.635  loss_dice_8: 3.349  time: 1.6949  data_time: 0.3262  lr: 6.8756e-06  max_mem: 17674M
[01/19 07:40:38] d2.utils.events INFO:  eta: 12:20:03  iter: 13639  total_loss: 63.44  loss_ce: 2.078  loss_mask: 0.6123  loss_dice: 3.361  loss_ce_0: 3.636  loss_mask_0: 0.6337  loss_dice_0: 3.618  loss_ce_1: 2.339  loss_mask_1: 0.625  loss_dice_1: 3.497  loss_ce_2: 2.21  loss_mask_2: 0.6192  loss_dice_2: 3.43  loss_ce_3: 2.145  loss_mask_3: 0.6158  loss_dice_3: 3.381  loss_ce_4: 2.139  loss_mask_4: 0.6171  loss_dice_4: 3.38  loss_ce_5: 2.105  loss_mask_5: 0.6182  loss_dice_5: 3.374  loss_ce_6: 2.111  loss_mask_6: 0.6123  loss_dice_6: 3.365  loss_ce_7: 2.089  loss_mask_7: 0.6157  loss_dice_7: 3.369  loss_ce_8: 2.083  loss_mask_8: 0.6134  loss_dice_8: 3.365  time: 1.6949  data_time: 0.3352  lr: 6.8709e-06  max_mem: 17674M
[01/19 07:41:11] d2.utils.events INFO:  eta: 12:19:35  iter: 13659  total_loss: 63.23  loss_ce: 2.134  loss_mask: 0.6361  loss_dice: 3.353  loss_ce_0: 3.583  loss_mask_0: 0.656  loss_dice_0: 3.615  loss_ce_1: 2.358  loss_mask_1: 0.6455  loss_dice_1: 3.473  loss_ce_2: 2.248  loss_mask_2: 0.6405  loss_dice_2: 3.417  loss_ce_3: 2.199  loss_mask_3: 0.6366  loss_dice_3: 3.372  loss_ce_4: 2.163  loss_mask_4: 0.6398  loss_dice_4: 3.368  loss_ce_5: 2.138  loss_mask_5: 0.6369  loss_dice_5: 3.367  loss_ce_6: 2.147  loss_mask_6: 0.6351  loss_dice_6: 3.358  loss_ce_7: 2.138  loss_mask_7: 0.6371  loss_dice_7: 3.355  loss_ce_8: 2.145  loss_mask_8: 0.6357  loss_dice_8: 3.358  time: 1.6949  data_time: 0.3314  lr: 6.8662e-06  max_mem: 17674M
[01/19 07:41:45] d2.utils.events INFO:  eta: 12:19:15  iter: 13679  total_loss: 62.88  loss_ce: 2.143  loss_mask: 0.6316  loss_dice: 3.333  loss_ce_0: 3.601  loss_mask_0: 0.6506  loss_dice_0: 3.611  loss_ce_1: 2.377  loss_mask_1: 0.6464  loss_dice_1: 3.479  loss_ce_2: 2.237  loss_mask_2: 0.6384  loss_dice_2: 3.4  loss_ce_3: 2.196  loss_mask_3: 0.6357  loss_dice_3: 3.343  loss_ce_4: 2.168  loss_mask_4: 0.6348  loss_dice_4: 3.335  loss_ce_5: 2.154  loss_mask_5: 0.6384  loss_dice_5: 3.343  loss_ce_6: 2.149  loss_mask_6: 0.6339  loss_dice_6: 3.331  loss_ce_7: 2.146  loss_mask_7: 0.6345  loss_dice_7: 3.331  loss_ce_8: 2.132  loss_mask_8: 0.6352  loss_dice_8: 3.327  time: 1.6948  data_time: 0.3406  lr: 6.8615e-06  max_mem: 17674M
[01/19 07:42:19] d2.utils.events INFO:  eta: 12:18:30  iter: 13699  total_loss: 64.18  loss_ce: 2.179  loss_mask: 0.6333  loss_dice: 3.35  loss_ce_0: 3.622  loss_mask_0: 0.657  loss_dice_0: 3.607  loss_ce_1: 2.416  loss_mask_1: 0.6476  loss_dice_1: 3.484  loss_ce_2: 2.285  loss_mask_2: 0.6402  loss_dice_2: 3.413  loss_ce_3: 2.235  loss_mask_3: 0.6369  loss_dice_3: 3.37  loss_ce_4: 2.213  loss_mask_4: 0.6331  loss_dice_4: 3.367  loss_ce_5: 2.204  loss_mask_5: 0.6343  loss_dice_5: 3.366  loss_ce_6: 2.181  loss_mask_6: 0.6342  loss_dice_6: 3.355  loss_ce_7: 2.183  loss_mask_7: 0.6336  loss_dice_7: 3.354  loss_ce_8: 2.167  loss_mask_8: 0.6339  loss_dice_8: 3.356  time: 1.6948  data_time: 0.3503  lr: 6.8568e-06  max_mem: 17674M
[01/19 07:42:53] d2.utils.events INFO:  eta: 12:18:18  iter: 13719  total_loss: 63.8  loss_ce: 2.181  loss_mask: 0.6238  loss_dice: 3.323  loss_ce_0: 3.635  loss_mask_0: 0.651  loss_dice_0: 3.588  loss_ce_1: 2.342  loss_mask_1: 0.639  loss_dice_1: 3.466  loss_ce_2: 2.209  loss_mask_2: 0.6344  loss_dice_2: 3.393  loss_ce_3: 2.212  loss_mask_3: 0.6281  loss_dice_3: 3.352  loss_ce_4: 2.19  loss_mask_4: 0.6274  loss_dice_4: 3.344  loss_ce_5: 2.176  loss_mask_5: 0.6275  loss_dice_5: 3.342  loss_ce_6: 2.18  loss_mask_6: 0.6251  loss_dice_6: 3.33  loss_ce_7: 2.167  loss_mask_7: 0.6256  loss_dice_7: 3.33  loss_ce_8: 2.167  loss_mask_8: 0.6236  loss_dice_8: 3.322  time: 1.6948  data_time: 0.3497  lr: 6.8521e-06  max_mem: 17674M
[01/19 07:43:27] d2.utils.events INFO:  eta: 12:18:01  iter: 13739  total_loss: 63.89  loss_ce: 2.2  loss_mask: 0.6215  loss_dice: 3.355  loss_ce_0: 3.654  loss_mask_0: 0.6471  loss_dice_0: 3.619  loss_ce_1: 2.389  loss_mask_1: 0.6283  loss_dice_1: 3.491  loss_ce_2: 2.273  loss_mask_2: 0.6232  loss_dice_2: 3.422  loss_ce_3: 2.25  loss_mask_3: 0.6184  loss_dice_3: 3.374  loss_ce_4: 2.223  loss_mask_4: 0.6214  loss_dice_4: 3.368  loss_ce_5: 2.185  loss_mask_5: 0.6225  loss_dice_5: 3.369  loss_ce_6: 2.215  loss_mask_6: 0.621  loss_dice_6: 3.354  loss_ce_7: 2.205  loss_mask_7: 0.622  loss_dice_7: 3.355  loss_ce_8: 2.194  loss_mask_8: 0.6217  loss_dice_8: 3.358  time: 1.6948  data_time: 0.3507  lr: 6.8474e-06  max_mem: 17674M
[01/19 07:44:01] d2.utils.events INFO:  eta: 12:17:24  iter: 13759  total_loss: 63.93  loss_ce: 2.191  loss_mask: 0.6297  loss_dice: 3.297  loss_ce_0: 3.67  loss_mask_0: 0.6562  loss_dice_0: 3.596  loss_ce_1: 2.388  loss_mask_1: 0.6437  loss_dice_1: 3.451  loss_ce_2: 2.284  loss_mask_2: 0.6371  loss_dice_2: 3.378  loss_ce_3: 2.263  loss_mask_3: 0.6316  loss_dice_3: 3.331  loss_ce_4: 2.219  loss_mask_4: 0.6342  loss_dice_4: 3.319  loss_ce_5: 2.196  loss_mask_5: 0.6329  loss_dice_5: 3.323  loss_ce_6: 2.209  loss_mask_6: 0.6321  loss_dice_6: 3.302  loss_ce_7: 2.187  loss_mask_7: 0.6302  loss_dice_7: 3.296  loss_ce_8: 2.183  loss_mask_8: 0.6301  loss_dice_8: 3.303  time: 1.6948  data_time: 0.3545  lr: 6.8427e-06  max_mem: 17674M
[01/19 07:44:35] d2.utils.events INFO:  eta: 12:16:43  iter: 13779  total_loss: 63.94  loss_ce: 2.204  loss_mask: 0.6212  loss_dice: 3.315  loss_ce_0: 3.619  loss_mask_0: 0.6629  loss_dice_0: 3.601  loss_ce_1: 2.419  loss_mask_1: 0.6475  loss_dice_1: 3.46  loss_ce_2: 2.296  loss_mask_2: 0.6321  loss_dice_2: 3.388  loss_ce_3: 2.275  loss_mask_3: 0.6291  loss_dice_3: 3.337  loss_ce_4: 2.232  loss_mask_4: 0.6259  loss_dice_4: 3.335  loss_ce_5: 2.223  loss_mask_5: 0.628  loss_dice_5: 3.329  loss_ce_6: 2.225  loss_mask_6: 0.6239  loss_dice_6: 3.322  loss_ce_7: 2.214  loss_mask_7: 0.6235  loss_dice_7: 3.316  loss_ce_8: 2.192  loss_mask_8: 0.6206  loss_dice_8: 3.322  time: 1.6948  data_time: 0.3307  lr: 6.838e-06  max_mem: 17674M
[01/19 07:45:08] d2.utils.events INFO:  eta: 12:16:09  iter: 13799  total_loss: 63.52  loss_ce: 2.079  loss_mask: 0.6276  loss_dice: 3.365  loss_ce_0: 3.661  loss_mask_0: 0.6475  loss_dice_0: 3.624  loss_ce_1: 2.274  loss_mask_1: 0.6385  loss_dice_1: 3.503  loss_ce_2: 2.173  loss_mask_2: 0.632  loss_dice_2: 3.432  loss_ce_3: 2.121  loss_mask_3: 0.6309  loss_dice_3: 3.389  loss_ce_4: 2.092  loss_mask_4: 0.6304  loss_dice_4: 3.389  loss_ce_5: 2.078  loss_mask_5: 0.6317  loss_dice_5: 3.39  loss_ce_6: 2.083  loss_mask_6: 0.6326  loss_dice_6: 3.374  loss_ce_7: 2.082  loss_mask_7: 0.6312  loss_dice_7: 3.371  loss_ce_8: 2.085  loss_mask_8: 0.6333  loss_dice_8: 3.369  time: 1.6948  data_time: 0.3472  lr: 6.8333e-06  max_mem: 17674M
[01/19 07:45:42] d2.utils.events INFO:  eta: 12:15:34  iter: 13819  total_loss: 64.24  loss_ce: 2.223  loss_mask: 0.6316  loss_dice: 3.363  loss_ce_0: 3.662  loss_mask_0: 0.6461  loss_dice_0: 3.626  loss_ce_1: 2.391  loss_mask_1: 0.6418  loss_dice_1: 3.502  loss_ce_2: 2.292  loss_mask_2: 0.6373  loss_dice_2: 3.432  loss_ce_3: 2.286  loss_mask_3: 0.6338  loss_dice_3: 3.383  loss_ce_4: 2.269  loss_mask_4: 0.6326  loss_dice_4: 3.379  loss_ce_5: 2.232  loss_mask_5: 0.6331  loss_dice_5: 3.376  loss_ce_6: 2.221  loss_mask_6: 0.6322  loss_dice_6: 3.362  loss_ce_7: 2.22  loss_mask_7: 0.6324  loss_dice_7: 3.37  loss_ce_8: 2.224  loss_mask_8: 0.6328  loss_dice_8: 3.365  time: 1.6948  data_time: 0.3350  lr: 6.8286e-06  max_mem: 17674M
[01/19 07:46:16] d2.utils.events INFO:  eta: 12:15:37  iter: 13839  total_loss: 63.63  loss_ce: 2.099  loss_mask: 0.6106  loss_dice: 3.347  loss_ce_0: 3.576  loss_mask_0: 0.634  loss_dice_0: 3.637  loss_ce_1: 2.272  loss_mask_1: 0.6298  loss_dice_1: 3.504  loss_ce_2: 2.192  loss_mask_2: 0.6199  loss_dice_2: 3.428  loss_ce_3: 2.152  loss_mask_3: 0.6152  loss_dice_3: 3.374  loss_ce_4: 2.141  loss_mask_4: 0.6177  loss_dice_4: 3.361  loss_ce_5: 2.121  loss_mask_5: 0.6155  loss_dice_5: 3.365  loss_ce_6: 2.116  loss_mask_6: 0.6172  loss_dice_6: 3.349  loss_ce_7: 2.109  loss_mask_7: 0.6109  loss_dice_7: 3.356  loss_ce_8: 2.11  loss_mask_8: 0.611  loss_dice_8: 3.347  time: 1.6948  data_time: 0.3562  lr: 6.8239e-06  max_mem: 17674M
[01/19 07:46:50] d2.utils.events INFO:  eta: 12:14:41  iter: 13859  total_loss: 63.74  loss_ce: 2.236  loss_mask: 0.6361  loss_dice: 3.31  loss_ce_0: 3.614  loss_mask_0: 0.6569  loss_dice_0: 3.596  loss_ce_1: 2.379  loss_mask_1: 0.6463  loss_dice_1: 3.448  loss_ce_2: 2.298  loss_mask_2: 0.6396  loss_dice_2: 3.374  loss_ce_3: 2.26  loss_mask_3: 0.6383  loss_dice_3: 3.329  loss_ce_4: 2.271  loss_mask_4: 0.6385  loss_dice_4: 3.326  loss_ce_5: 2.249  loss_mask_5: 0.6368  loss_dice_5: 3.317  loss_ce_6: 2.233  loss_mask_6: 0.6343  loss_dice_6: 3.305  loss_ce_7: 2.23  loss_mask_7: 0.6358  loss_dice_7: 3.305  loss_ce_8: 2.235  loss_mask_8: 0.6377  loss_dice_8: 3.317  time: 1.6948  data_time: 0.3371  lr: 6.8192e-06  max_mem: 17674M
[01/19 07:47:24] d2.utils.events INFO:  eta: 12:14:09  iter: 13879  total_loss: 63.1  loss_ce: 2.05  loss_mask: 0.6274  loss_dice: 3.354  loss_ce_0: 3.575  loss_mask_0: 0.6433  loss_dice_0: 3.62  loss_ce_1: 2.237  loss_mask_1: 0.6409  loss_dice_1: 3.505  loss_ce_2: 2.15  loss_mask_2: 0.6319  loss_dice_2: 3.429  loss_ce_3: 2.1  loss_mask_3: 0.6299  loss_dice_3: 3.373  loss_ce_4: 2.076  loss_mask_4: 0.6276  loss_dice_4: 3.374  loss_ce_5: 2.06  loss_mask_5: 0.6277  loss_dice_5: 3.372  loss_ce_6: 2.062  loss_mask_6: 0.6264  loss_dice_6: 3.364  loss_ce_7: 2.052  loss_mask_7: 0.6261  loss_dice_7: 3.357  loss_ce_8: 2.034  loss_mask_8: 0.6261  loss_dice_8: 3.362  time: 1.6948  data_time: 0.3308  lr: 6.8145e-06  max_mem: 17674M
[01/19 07:47:58] d2.utils.events INFO:  eta: 12:14:14  iter: 13899  total_loss: 63.97  loss_ce: 2.121  loss_mask: 0.6237  loss_dice: 3.371  loss_ce_0: 3.573  loss_mask_0: 0.6372  loss_dice_0: 3.621  loss_ce_1: 2.279  loss_mask_1: 0.628  loss_dice_1: 3.526  loss_ce_2: 2.173  loss_mask_2: 0.6251  loss_dice_2: 3.447  loss_ce_3: 2.143  loss_mask_3: 0.6215  loss_dice_3: 3.402  loss_ce_4: 2.11  loss_mask_4: 0.6237  loss_dice_4: 3.39  loss_ce_5: 2.121  loss_mask_5: 0.6227  loss_dice_5: 3.393  loss_ce_6: 2.117  loss_mask_6: 0.6228  loss_dice_6: 3.381  loss_ce_7: 2.104  loss_mask_7: 0.6227  loss_dice_7: 3.383  loss_ce_8: 2.109  loss_mask_8: 0.621  loss_dice_8: 3.38  time: 1.6948  data_time: 0.3401  lr: 6.8098e-06  max_mem: 17674M
[01/19 07:48:31] d2.utils.events INFO:  eta: 12:13:40  iter: 13919  total_loss: 63.52  loss_ce: 2.147  loss_mask: 0.6227  loss_dice: 3.322  loss_ce_0: 3.586  loss_mask_0: 0.6532  loss_dice_0: 3.603  loss_ce_1: 2.34  loss_mask_1: 0.6459  loss_dice_1: 3.474  loss_ce_2: 2.239  loss_mask_2: 0.6361  loss_dice_2: 3.4  loss_ce_3: 2.2  loss_mask_3: 0.6262  loss_dice_3: 3.354  loss_ce_4: 2.179  loss_mask_4: 0.6261  loss_dice_4: 3.346  loss_ce_5: 2.158  loss_mask_5: 0.628  loss_dice_5: 3.339  loss_ce_6: 2.166  loss_mask_6: 0.626  loss_dice_6: 3.336  loss_ce_7: 2.163  loss_mask_7: 0.6233  loss_dice_7: 3.342  loss_ce_8: 2.135  loss_mask_8: 0.6255  loss_dice_8: 3.332  time: 1.6948  data_time: 0.3208  lr: 6.8052e-06  max_mem: 17674M
[01/19 07:49:05] d2.utils.events INFO:  eta: 12:13:06  iter: 13939  total_loss: 63.27  loss_ce: 2.141  loss_mask: 0.6215  loss_dice: 3.311  loss_ce_0: 3.544  loss_mask_0: 0.6516  loss_dice_0: 3.62  loss_ce_1: 2.348  loss_mask_1: 0.6388  loss_dice_1: 3.469  loss_ce_2: 2.208  loss_mask_2: 0.6351  loss_dice_2: 3.394  loss_ce_3: 2.195  loss_mask_3: 0.6244  loss_dice_3: 3.341  loss_ce_4: 2.167  loss_mask_4: 0.6244  loss_dice_4: 3.333  loss_ce_5: 2.169  loss_mask_5: 0.6259  loss_dice_5: 3.319  loss_ce_6: 2.163  loss_mask_6: 0.6223  loss_dice_6: 3.317  loss_ce_7: 2.158  loss_mask_7: 0.6229  loss_dice_7: 3.315  loss_ce_8: 2.153  loss_mask_8: 0.6271  loss_dice_8: 3.308  time: 1.6948  data_time: 0.3317  lr: 6.8005e-06  max_mem: 17674M
[01/19 07:49:39] d2.utils.events INFO:  eta: 12:12:15  iter: 13959  total_loss: 63.82  loss_ce: 2.179  loss_mask: 0.6193  loss_dice: 3.333  loss_ce_0: 3.617  loss_mask_0: 0.6416  loss_dice_0: 3.618  loss_ce_1: 2.362  loss_mask_1: 0.6371  loss_dice_1: 3.475  loss_ce_2: 2.264  loss_mask_2: 0.6297  loss_dice_2: 3.407  loss_ce_3: 2.213  loss_mask_3: 0.6195  loss_dice_3: 3.361  loss_ce_4: 2.197  loss_mask_4: 0.623  loss_dice_4: 3.359  loss_ce_5: 2.183  loss_mask_5: 0.6241  loss_dice_5: 3.351  loss_ce_6: 2.176  loss_mask_6: 0.6209  loss_dice_6: 3.342  loss_ce_7: 2.177  loss_mask_7: 0.6183  loss_dice_7: 3.334  loss_ce_8: 2.174  loss_mask_8: 0.6172  loss_dice_8: 3.334  time: 1.6948  data_time: 0.3387  lr: 6.7958e-06  max_mem: 17674M
[01/19 07:50:13] d2.utils.events INFO:  eta: 12:12:07  iter: 13979  total_loss: 63.91  loss_ce: 2.147  loss_mask: 0.6177  loss_dice: 3.328  loss_ce_0: 3.624  loss_mask_0: 0.6375  loss_dice_0: 3.602  loss_ce_1: 2.279  loss_mask_1: 0.6311  loss_dice_1: 3.478  loss_ce_2: 2.219  loss_mask_2: 0.624  loss_dice_2: 3.404  loss_ce_3: 2.186  loss_mask_3: 0.6217  loss_dice_3: 3.351  loss_ce_4: 2.166  loss_mask_4: 0.6218  loss_dice_4: 3.346  loss_ce_5: 2.144  loss_mask_5: 0.6199  loss_dice_5: 3.346  loss_ce_6: 2.154  loss_mask_6: 0.6191  loss_dice_6: 3.329  loss_ce_7: 2.149  loss_mask_7: 0.6177  loss_dice_7: 3.332  loss_ce_8: 2.141  loss_mask_8: 0.6183  loss_dice_8: 3.334  time: 1.6948  data_time: 0.3415  lr: 6.7911e-06  max_mem: 17674M
[01/19 07:50:47] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 07:50:47] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 07:50:47] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 07:56:11] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.439364801580494, 'error_1pix': 0.4408117733512428, 'error_3pix': 0.19532943707202272, 'mIoU': 6.487648701405709, 'fwIoU': 19.699563027175817, 'IoU-0': nan, 'IoU-1': 95.20508068491417, 'IoU-2': 11.510131647485775, 'IoU-3': 30.37497241374698, 'IoU-4': 25.038083998417104, 'IoU-5': 20.66436830115264, 'IoU-6': 20.270393099440646, 'IoU-7': 12.72861206085188, 'IoU-8': 8.5935447442505, 'IoU-9': 7.453832028541768, 'IoU-10': 20.37086319926647, 'IoU-11': 22.86200403802864, 'IoU-12': 23.730230546101847, 'IoU-13': 19.026583349034116, 'IoU-14': 18.702503874616212, 'IoU-15': 17.486070440691527, 'IoU-16': 19.63494495955643, 'IoU-17': 9.156037955709584, 'IoU-18': 19.189378589330815, 'IoU-19': 13.531404300054625, 'IoU-20': 15.075050992121538, 'IoU-21': 17.74363694942079, 'IoU-22': 13.173515038128134, 'IoU-23': 14.946927729875103, 'IoU-24': 11.15221294976117, 'IoU-25': 14.800895430874682, 'IoU-26': 9.978377707161725, 'IoU-27': 13.222983521819092, 'IoU-28': 10.908787773020302, 'IoU-29': 13.53184689707686, 'IoU-30': 10.931313353773362, 'IoU-31': 9.815537994665739, 'IoU-32': 11.456820200620271, 'IoU-33': 11.699478876042663, 'IoU-34': 12.062450053300564, 'IoU-35': 9.193977737023902, 'IoU-36': 13.581195919248376, 'IoU-37': 10.721058511533744, 'IoU-38': 10.105031204510674, 'IoU-39': 12.283961611029387, 'IoU-40': 12.07210320870669, 'IoU-41': 9.767933986712178, 'IoU-42': 9.739739812814753, 'IoU-43': 12.494206119799735, 'IoU-44': 6.0236986955210385, 'IoU-45': 13.337195823004617, 'IoU-46': 9.847255369240365, 'IoU-47': 8.353707629858294, 'IoU-48': 6.658338883576456, 'IoU-49': 9.03875853823577, 'IoU-50': 10.192659474138702, 'IoU-51': 7.480225699090494, 'IoU-52': 8.667261386689749, 'IoU-53': 9.893774296503025, 'IoU-54': 9.943874925190576, 'IoU-55': 10.153514117667168, 'IoU-56': 9.037834229257566, 'IoU-57': 10.450288755732538, 'IoU-58': 9.952515019788336, 'IoU-59': 7.650961679804573, 'IoU-60': 10.686650370262733, 'IoU-61': 8.74976561274794, 'IoU-62': 7.767314262519517, 'IoU-63': 10.731707141796875, 'IoU-64': 5.902742145020862, 'IoU-65': 7.590130724520233, 'IoU-66': 6.61649860320724, 'IoU-67': 5.231534699523426, 'IoU-68': 4.071101030565113, 'IoU-69': 4.953809762536331, 'IoU-70': 5.275605901743006, 'IoU-71': 3.3989284023655886, 'IoU-72': 3.7080332456585032, 'IoU-73': 5.035485780658246, 'IoU-74': 5.048592124128973, 'IoU-75': 3.528907444128294, 'IoU-76': 3.77908176820619, 'IoU-77': 5.387139610063257, 'IoU-78': 2.7496185002251825, 'IoU-79': 4.546039992827408, 'IoU-80': 4.533264627056477, 'IoU-81': 4.216240841886747, 'IoU-82': 3.9848263346080484, 'IoU-83': 3.7313038591519536, 'IoU-84': 3.9163045951497653, 'IoU-85': 5.146237713915585, 'IoU-86': 3.9590615195191985, 'IoU-87': 5.189835935814029, 'IoU-88': 4.844845736502282, 'IoU-89': 4.078755396025616, 'IoU-90': 6.121450874490201, 'IoU-91': 4.297777757286449, 'IoU-92': 4.61664045898473, 'IoU-93': 4.666240323405063, 'IoU-94': 6.1545546061642105, 'IoU-95': 5.399151411432448, 'IoU-96': 4.806463416034217, 'IoU-97': 4.5062101663358884, 'IoU-98': 5.49369420497777, 'IoU-99': 4.145643292600075, 'IoU-100': 4.588596759984583, 'IoU-101': 5.465302284985626, 'IoU-102': 3.5961525247046335, 'IoU-103': 5.614410432328812, 'IoU-104': 4.001354078410016, 'IoU-105': 3.3495367441836956, 'IoU-106': 4.200753369701815, 'IoU-107': 3.567815615156268, 'IoU-108': 2.7024675638980407, 'IoU-109': 2.2966456945434874, 'IoU-110': 3.070745578671969, 'IoU-111': 4.6565536439669595, 'IoU-112': 3.4680629535451257, 'IoU-113': 3.2159411047979716, 'IoU-114': 4.319574872746144, 'IoU-115': 4.351036461213535, 'IoU-116': 3.3157698810814598, 'IoU-117': 2.9749598006633904, 'IoU-118': 3.0724836386887016, 'IoU-119': 2.9968747477196325, 'IoU-120': 2.387145551464467, 'IoU-121': 3.0696902080367763, 'IoU-122': 2.798328032777018, 'IoU-123': 2.907099932769943, 'IoU-124': 2.510290083655452, 'IoU-125': 2.3723373212722496, 'IoU-126': 1.9298629319403775, 'IoU-127': 3.4445706292890668, 'IoU-128': 2.3237334667401224, 'IoU-129': 1.9124944646220454, 'IoU-130': 1.5756552671208897, 'IoU-131': 1.1021756017930968, 'IoU-132': 2.6083110526489, 'IoU-133': 2.6116588205049784, 'IoU-134': 2.8460400922993174, 'IoU-135': 2.0013509932261355, 'IoU-136': 1.0185768351145597, 'IoU-137': 0.544803278290175, 'IoU-138': 1.9538456744678805, 'IoU-139': 1.8212746807240097, 'IoU-140': 2.72581094317532, 'IoU-141': 1.6938099883191085, 'IoU-142': 1.0709331577833683, 'IoU-143': 2.2092709513787705, 'IoU-144': 1.1975713226313034, 'IoU-145': 2.2524368846546365, 'IoU-146': 0.5028211231244148, 'IoU-147': 2.3959900668547385, 'IoU-148': 1.3565609323417158, 'IoU-149': 2.3494599186516623, 'IoU-150': 1.8377353130483332, 'IoU-151': 2.011541685421033, 'IoU-152': 0.6083336403492613, 'IoU-153': 1.1139571523583265, 'IoU-154': 1.3470396917227718, 'IoU-155': 1.6432746826150986, 'IoU-156': 1.0567336204950282, 'IoU-157': 1.178567042706711, 'IoU-158': 0.8559049278406852, 'IoU-159': 1.0080121085303357, 'IoU-160': 1.8251741698842436, 'IoU-161': 0.497505422324377, 'IoU-162': 1.5727201500092436, 'IoU-163': 0.31028570968633373, 'IoU-164': 1.4079499638662867, 'IoU-165': 1.4534987186788155, 'IoU-166': 0.42181281527090614, 'IoU-167': 0.6776031160624839, 'IoU-168': 1.120132750599965, 'IoU-169': 0.8974668629977599, 'IoU-170': 1.424462923803415, 'IoU-171': 0.06621070019521917, 'IoU-172': 1.1092868616268503, 'IoU-173': 0.6372712264318054, 'IoU-174': 0.1461539935979759, 'IoU-175': 0.4409836488886466, 'IoU-176': 0.6519801538964319, 'IoU-177': 0.15597030409813292, 'IoU-178': 0.18182060589092097, 'IoU-179': 0.10103021853669135, 'IoU-180': 0.9935373861883595, 'IoU-181': 1.5475006173134316, 'IoU-182': 1.3699685444765866, 'IoU-183': 0.9487968949979595, 'IoU-184': 0.7197245792820175, 'IoU-185': 0.6709323942303742, 'IoU-186': 1.625773963980166, 'IoU-187': 1.769589440877887, 'IoU-188': 2.1405326987186815, 'IoU-189': 1.76408304284137, 'IoU-190': 2.205202607136087, 'IoU-191': 1.984826976627567, 'IoU-192': 2.5715748555488163, 'mACC': 11.4107341366888, 'pACC': 28.079190923131698, 'ACC-0': nan, 'ACC-1': 98.96121827461538, 'ACC-2': 12.399915835374586, 'ACC-3': 41.98257196401626, 'ACC-4': 38.34971310260856, 'ACC-5': 36.47574422821683, 'ACC-6': 34.230482014773116, 'ACC-7': 17.9251853229341, 'ACC-8': 10.714527625373792, 'ACC-9': 8.145709437316723, 'ACC-10': 33.72833469030499, 'ACC-11': 36.33474135767333, 'ACC-12': 48.0354062296298, 'ACC-13': 35.417804171478714, 'ACC-14': 29.67054588445159, 'ACC-15': 29.236893902535083, 'ACC-16': 35.40126874712552, 'ACC-17': 12.20149249649769, 'ACC-18': 39.07464700598485, 'ACC-19': 22.796123822452543, 'ACC-20': 26.31979369070751, 'ACC-21': 32.46692416889742, 'ACC-22': 19.544133797325554, 'ACC-23': 26.50870327308611, 'ACC-24': 16.44021047309863, 'ACC-25': 30.60891257476954, 'ACC-26': 14.33925738174647, 'ACC-27': 23.591434630099073, 'ACC-28': 18.762093439881017, 'ACC-29': 25.805781705826508, 'ACC-30': 18.35178325486618, 'ACC-31': 14.907798602245565, 'ACC-32': 22.33942901151441, 'ACC-33': 23.220761063767483, 'ACC-34': 23.075469942046855, 'ACC-35': 13.977972897888517, 'ACC-36': 29.336367610245784, 'ACC-37': 18.125434074461765, 'ACC-38': 16.42918822707561, 'ACC-39': 23.753707999102897, 'ACC-40': 23.438172096552833, 'ACC-41': 16.53509465034901, 'ACC-42': 18.299908238877567, 'ACC-43': 26.317609641233787, 'ACC-44': 8.161747708256014, 'ACC-45': 31.894877644321756, 'ACC-46': 16.868014674866924, 'ACC-47': 13.40242610976099, 'ACC-48': 9.74410850914769, 'ACC-49': 16.087455141607933, 'ACC-50': 21.33325565946293, 'ACC-51': 12.472362562952219, 'ACC-52': 16.893112401148073, 'ACC-53': 18.755035979346466, 'ACC-54': 20.41658152153455, 'ACC-55': 20.844554240192085, 'ACC-56': 15.664189861786074, 'ACC-57': 23.122561706394432, 'ACC-58': 17.863003762259762, 'ACC-59': 14.923392446025971, 'ACC-60': 24.812136907744613, 'ACC-61': 17.137910207166975, 'ACC-62': 13.910501267767852, 'ACC-63': 24.791223049078678, 'ACC-64': 10.178954972794596, 'ACC-65': 16.32788578194528, 'ACC-66': 13.620657301563227, 'ACC-67': 11.568572391685287, 'ACC-68': 6.899877145040156, 'ACC-69': 9.260707428493834, 'ACC-70': 12.002114663744319, 'ACC-71': 5.217180373635473, 'ACC-72': 6.429501793848619, 'ACC-73': 11.0591212908866, 'ACC-74': 9.575005661587705, 'ACC-75': 6.370068327329075, 'ACC-76': 6.185356942995282, 'ACC-77': 13.263057603378265, 'ACC-78': 4.282602517917384, 'ACC-79': 8.279327116227838, 'ACC-80': 8.245570637308724, 'ACC-81': 8.105077245082363, 'ACC-82': 7.076311395010205, 'ACC-83': 6.508768592908309, 'ACC-84': 7.060735875063358, 'ACC-85': 9.775604749955214, 'ACC-86': 5.753050391115312, 'ACC-87': 8.397283811414237, 'ACC-88': 9.132796225852598, 'ACC-89': 5.9776078984940595, 'ACC-90': 12.292288043920038, 'ACC-91': 6.976497665878058, 'ACC-92': 7.718077429906921, 'ACC-93': 7.561059654435658, 'ACC-94': 12.995634969869919, 'ACC-95': 9.583749122514314, 'ACC-96': 8.645301004901189, 'ACC-97': 6.964884607989721, 'ACC-98': 10.513325121556385, 'ACC-99': 7.060282766137487, 'ACC-100': 7.648378498265009, 'ACC-101': 12.554249610107796, 'ACC-102': 5.572496601721794, 'ACC-103': 11.381009728912819, 'ACC-104': 7.1395932220063445, 'ACC-105': 5.4161470505683615, 'ACC-106': 8.131584930210458, 'ACC-107': 5.614009895173818, 'ACC-108': 3.8544373010703272, 'ACC-109': 2.9892428307981906, 'ACC-110': 4.270484278276715, 'ACC-111': 9.297777008920107, 'ACC-112': 6.599361111055502, 'ACC-113': 5.131072699877414, 'ACC-114': 9.124463328494894, 'ACC-115': 10.338881120983867, 'ACC-116': 5.289612649762377, 'ACC-117': 4.864235847972438, 'ACC-118': 5.088388657331306, 'ACC-119': 5.206436783975549, 'ACC-120': 3.841666754516352, 'ACC-121': 6.040532751460624, 'ACC-122': 5.198184683027163, 'ACC-123': 5.558017167026205, 'ACC-124': 4.909325603683552, 'ACC-125': 4.642616681332618, 'ACC-126': 3.445557336587765, 'ACC-127': 9.245542431010476, 'ACC-128': 4.617199115492181, 'ACC-129': 3.1573352477065484, 'ACC-130': 2.6498608255534086, 'ACC-131': 1.4879249398390257, 'ACC-132': 7.011624828677035, 'ACC-133': 4.845645621125831, 'ACC-134': 6.790107712193021, 'ACC-135': 3.2451114531668663, 'ACC-136': 1.4398382174804323, 'ACC-137': 0.667370366893423, 'ACC-138': 6.664847577226693, 'ACC-139': 3.1055467787330713, 'ACC-140': 8.650260813964852, 'ACC-141': 2.6492958718414377, 'ACC-142': 1.51162252491352, 'ACC-143': 5.150365771579894, 'ACC-144': 2.378610108303249, 'ACC-145': 4.605738053176502, 'ACC-146': 0.574718420872267, 'ACC-147': 4.610193475663032, 'ACC-148': 2.3470345068822707, 'ACC-149': 6.627629506657243, 'ACC-150': 4.086057145596925, 'ACC-151': 5.325045855035207, 'ACC-152': 0.8699170544203925, 'ACC-153': 1.6897524688982941, 'ACC-154': 2.457768118290365, 'ACC-155': 3.59793720403389, 'ACC-156': 1.5308938832761285, 'ACC-157': 1.8156255401622086, 'ACC-158': 1.3616521605360798, 'ACC-159': 1.9846209245024626, 'ACC-160': 4.0480930190471875, 'ACC-161': 0.7926656313100818, 'ACC-162': 3.720756558296465, 'ACC-163': 0.3535794376665286, 'ACC-164': 3.2650090848842113, 'ACC-165': 3.113138326763588, 'ACC-166': 0.585405981650452, 'ACC-167': 0.9552397479793004, 'ACC-168': 1.9867782544482733, 'ACC-169': 1.2844516426767831, 'ACC-170': 3.984411601856978, 'ACC-171': 0.07126994594137863, 'ACC-172': 1.8494647553431862, 'ACC-173': 0.8460864035401293, 'ACC-174': 0.17055590039535418, 'ACC-175': 0.5683341375797545, 'ACC-176': 0.7961240422567912, 'ACC-177': 0.16369270063428615, 'ACC-178': 0.21073533303329464, 'ACC-179': 0.11321191119154522, 'ACC-180': 1.6155728267127232, 'ACC-181': 3.607220599695391, 'ACC-182': 3.7496831237013994, 'ACC-183': 1.6091780831593097, 'ACC-184': 1.1108045196301093, 'ACC-185': 0.8677115234492284, 'ACC-186': 2.9876325797366934, 'ACC-187': 3.6888582853139082, 'ACC-188': 5.433093902586659, 'ACC-189': 6.00096015362458, 'ACC-190': 7.924950480522338, 'ACC-191': 4.091092985318108, 'ACC-192': 11.854113665241348})])
[01/19 07:56:11] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 07:56:11] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 07:56:11] d2.evaluation.testing INFO: copypaste: 3.4394,0.4408,0.1953,6.4876,19.6996,11.4107,28.0792
[01/19 07:56:11] d2.utils.events INFO:  eta: 12:11:16  iter: 13999  total_loss: 63.64  loss_ce: 2.137  loss_mask: 0.6218  loss_dice: 3.327  loss_ce_0: 3.618  loss_mask_0: 0.6431  loss_dice_0: 3.602  loss_ce_1: 2.339  loss_mask_1: 0.6368  loss_dice_1: 3.475  loss_ce_2: 2.23  loss_mask_2: 0.6282  loss_dice_2: 3.396  loss_ce_3: 2.195  loss_mask_3: 0.621  loss_dice_3: 3.359  loss_ce_4: 2.169  loss_mask_4: 0.6232  loss_dice_4: 3.351  loss_ce_5: 2.163  loss_mask_5: 0.6233  loss_dice_5: 3.345  loss_ce_6: 2.151  loss_mask_6: 0.6223  loss_dice_6: 3.333  loss_ce_7: 2.133  loss_mask_7: 0.6201  loss_dice_7: 3.334  loss_ce_8: 2.155  loss_mask_8: 0.6224  loss_dice_8: 3.33  time: 1.6947  data_time: 0.3160  lr: 6.7864e-06  max_mem: 17674M
[01/19 07:56:44] d2.utils.events INFO:  eta: 12:10:36  iter: 14019  total_loss: 62.88  loss_ce: 2.107  loss_mask: 0.6277  loss_dice: 3.302  loss_ce_0: 3.564  loss_mask_0: 0.6471  loss_dice_0: 3.582  loss_ce_1: 2.288  loss_mask_1: 0.6428  loss_dice_1: 3.452  loss_ce_2: 2.186  loss_mask_2: 0.6333  loss_dice_2: 3.382  loss_ce_3: 2.164  loss_mask_3: 0.6291  loss_dice_3: 3.33  loss_ce_4: 2.127  loss_mask_4: 0.6273  loss_dice_4: 3.327  loss_ce_5: 2.101  loss_mask_5: 0.6293  loss_dice_5: 3.324  loss_ce_6: 2.108  loss_mask_6: 0.627  loss_dice_6: 3.313  loss_ce_7: 2.087  loss_mask_7: 0.6293  loss_dice_7: 3.312  loss_ce_8: 2.09  loss_mask_8: 0.6286  loss_dice_8: 3.309  time: 1.6947  data_time: 0.3303  lr: 6.7817e-06  max_mem: 17674M
[01/19 07:57:18] d2.utils.events INFO:  eta: 12:10:02  iter: 14039  total_loss: 64.26  loss_ce: 2.187  loss_mask: 0.6224  loss_dice: 3.334  loss_ce_0: 3.7  loss_mask_0: 0.6464  loss_dice_0: 3.595  loss_ce_1: 2.445  loss_mask_1: 0.6311  loss_dice_1: 3.473  loss_ce_2: 2.309  loss_mask_2: 0.6235  loss_dice_2: 3.403  loss_ce_3: 2.281  loss_mask_3: 0.6207  loss_dice_3: 3.359  loss_ce_4: 2.238  loss_mask_4: 0.6215  loss_dice_4: 3.36  loss_ce_5: 2.197  loss_mask_5: 0.6217  loss_dice_5: 3.354  loss_ce_6: 2.208  loss_mask_6: 0.6223  loss_dice_6: 3.338  loss_ce_7: 2.178  loss_mask_7: 0.6234  loss_dice_7: 3.334  loss_ce_8: 2.177  loss_mask_8: 0.6254  loss_dice_8: 3.34  time: 1.6947  data_time: 0.3461  lr: 6.777e-06  max_mem: 17674M
[01/19 07:57:52] d2.utils.events INFO:  eta: 12:09:05  iter: 14059  total_loss: 63.63  loss_ce: 2.116  loss_mask: 0.6175  loss_dice: 3.372  loss_ce_0: 3.603  loss_mask_0: 0.6457  loss_dice_0: 3.615  loss_ce_1: 2.318  loss_mask_1: 0.6309  loss_dice_1: 3.516  loss_ce_2: 2.221  loss_mask_2: 0.6237  loss_dice_2: 3.439  loss_ce_3: 2.172  loss_mask_3: 0.6219  loss_dice_3: 3.395  loss_ce_4: 2.149  loss_mask_4: 0.6218  loss_dice_4: 3.392  loss_ce_5: 2.12  loss_mask_5: 0.6185  loss_dice_5: 3.397  loss_ce_6: 2.114  loss_mask_6: 0.618  loss_dice_6: 3.379  loss_ce_7: 2.114  loss_mask_7: 0.6163  loss_dice_7: 3.377  loss_ce_8: 2.1  loss_mask_8: 0.6175  loss_dice_8: 3.375  time: 1.6947  data_time: 0.3263  lr: 6.7723e-06  max_mem: 17674M
[01/19 07:58:25] d2.utils.events INFO:  eta: 12:08:30  iter: 14079  total_loss: 63.7  loss_ce: 2.167  loss_mask: 0.6292  loss_dice: 3.383  loss_ce_0: 3.607  loss_mask_0: 0.6509  loss_dice_0: 3.629  loss_ce_1: 2.34  loss_mask_1: 0.6437  loss_dice_1: 3.525  loss_ce_2: 2.212  loss_mask_2: 0.6334  loss_dice_2: 3.46  loss_ce_3: 2.184  loss_mask_3: 0.629  loss_dice_3: 3.409  loss_ce_4: 2.177  loss_mask_4: 0.6301  loss_dice_4: 3.401  loss_ce_5: 2.16  loss_mask_5: 0.6263  loss_dice_5: 3.392  loss_ce_6: 2.166  loss_mask_6: 0.6262  loss_dice_6: 3.384  loss_ce_7: 2.163  loss_mask_7: 0.6275  loss_dice_7: 3.387  loss_ce_8: 2.157  loss_mask_8: 0.6305  loss_dice_8: 3.387  time: 1.6946  data_time: 0.3434  lr: 6.7676e-06  max_mem: 17674M
[01/19 07:59:00] d2.utils.events INFO:  eta: 12:08:45  iter: 14099  total_loss: 64.12  loss_ce: 2.166  loss_mask: 0.6182  loss_dice: 3.365  loss_ce_0: 3.634  loss_mask_0: 0.6485  loss_dice_0: 3.618  loss_ce_1: 2.345  loss_mask_1: 0.6296  loss_dice_1: 3.5  loss_ce_2: 2.244  loss_mask_2: 0.6221  loss_dice_2: 3.425  loss_ce_3: 2.193  loss_mask_3: 0.6186  loss_dice_3: 3.388  loss_ce_4: 2.191  loss_mask_4: 0.6158  loss_dice_4: 3.378  loss_ce_5: 2.15  loss_mask_5: 0.6173  loss_dice_5: 3.377  loss_ce_6: 2.171  loss_mask_6: 0.6149  loss_dice_6: 3.368  loss_ce_7: 2.182  loss_mask_7: 0.616  loss_dice_7: 3.367  loss_ce_8: 2.163  loss_mask_8: 0.6177  loss_dice_8: 3.368  time: 1.6947  data_time: 0.3646  lr: 6.7629e-06  max_mem: 17674M
[01/19 07:59:34] d2.utils.events INFO:  eta: 12:08:11  iter: 14119  total_loss: 63.68  loss_ce: 2.141  loss_mask: 0.6258  loss_dice: 3.338  loss_ce_0: 3.662  loss_mask_0: 0.6397  loss_dice_0: 3.599  loss_ce_1: 2.33  loss_mask_1: 0.6306  loss_dice_1: 3.476  loss_ce_2: 2.226  loss_mask_2: 0.6251  loss_dice_2: 3.402  loss_ce_3: 2.194  loss_mask_3: 0.6266  loss_dice_3: 3.358  loss_ce_4: 2.16  loss_mask_4: 0.6245  loss_dice_4: 3.357  loss_ce_5: 2.132  loss_mask_5: 0.6242  loss_dice_5: 3.352  loss_ce_6: 2.133  loss_mask_6: 0.6248  loss_dice_6: 3.344  loss_ce_7: 2.119  loss_mask_7: 0.6274  loss_dice_7: 3.343  loss_ce_8: 2.146  loss_mask_8: 0.6241  loss_dice_8: 3.343  time: 1.6947  data_time: 0.3425  lr: 6.7582e-06  max_mem: 17674M
[01/19 08:00:07] d2.utils.events INFO:  eta: 12:07:50  iter: 14139  total_loss: 63.03  loss_ce: 2.084  loss_mask: 0.6317  loss_dice: 3.353  loss_ce_0: 3.581  loss_mask_0: 0.652  loss_dice_0: 3.601  loss_ce_1: 2.313  loss_mask_1: 0.6393  loss_dice_1: 3.484  loss_ce_2: 2.197  loss_mask_2: 0.6313  loss_dice_2: 3.415  loss_ce_3: 2.142  loss_mask_3: 0.6304  loss_dice_3: 3.367  loss_ce_4: 2.114  loss_mask_4: 0.6307  loss_dice_4: 3.367  loss_ce_5: 2.096  loss_mask_5: 0.6312  loss_dice_5: 3.36  loss_ce_6: 2.091  loss_mask_6: 0.6294  loss_dice_6: 3.349  loss_ce_7: 2.07  loss_mask_7: 0.6285  loss_dice_7: 3.353  loss_ce_8: 2.059  loss_mask_8: 0.6318  loss_dice_8: 3.356  time: 1.6947  data_time: 0.3447  lr: 6.7535e-06  max_mem: 17674M
[01/19 08:00:41] d2.utils.events INFO:  eta: 12:07:25  iter: 14159  total_loss: 63.04  loss_ce: 2.11  loss_mask: 0.6188  loss_dice: 3.318  loss_ce_0: 3.676  loss_mask_0: 0.649  loss_dice_0: 3.603  loss_ce_1: 2.341  loss_mask_1: 0.629  loss_dice_1: 3.458  loss_ce_2: 2.229  loss_mask_2: 0.6223  loss_dice_2: 3.392  loss_ce_3: 2.187  loss_mask_3: 0.6194  loss_dice_3: 3.345  loss_ce_4: 2.171  loss_mask_4: 0.6191  loss_dice_4: 3.342  loss_ce_5: 2.118  loss_mask_5: 0.6201  loss_dice_5: 3.332  loss_ce_6: 2.121  loss_mask_6: 0.6176  loss_dice_6: 3.315  loss_ce_7: 2.12  loss_mask_7: 0.6188  loss_dice_7: 3.322  loss_ce_8: 2.109  loss_mask_8: 0.6193  loss_dice_8: 3.319  time: 1.6947  data_time: 0.3467  lr: 6.7488e-06  max_mem: 17674M
[01/19 08:01:15] d2.utils.events INFO:  eta: 12:06:56  iter: 14179  total_loss: 63.82  loss_ce: 2.183  loss_mask: 0.6339  loss_dice: 3.304  loss_ce_0: 3.574  loss_mask_0: 0.6616  loss_dice_0: 3.582  loss_ce_1: 2.404  loss_mask_1: 0.6533  loss_dice_1: 3.453  loss_ce_2: 2.262  loss_mask_2: 0.6413  loss_dice_2: 3.374  loss_ce_3: 2.265  loss_mask_3: 0.6353  loss_dice_3: 3.325  loss_ce_4: 2.211  loss_mask_4: 0.6347  loss_dice_4: 3.322  loss_ce_5: 2.196  loss_mask_5: 0.637  loss_dice_5: 3.319  loss_ce_6: 2.195  loss_mask_6: 0.6368  loss_dice_6: 3.312  loss_ce_7: 2.181  loss_mask_7: 0.6335  loss_dice_7: 3.307  loss_ce_8: 2.178  loss_mask_8: 0.6329  loss_dice_8: 3.305  time: 1.6946  data_time: 0.3442  lr: 6.7441e-06  max_mem: 17674M
[01/19 08:01:49] d2.utils.events INFO:  eta: 12:06:17  iter: 14199  total_loss: 62.92  loss_ce: 2.115  loss_mask: 0.6147  loss_dice: 3.322  loss_ce_0: 3.607  loss_mask_0: 0.6436  loss_dice_0: 3.616  loss_ce_1: 2.311  loss_mask_1: 0.6266  loss_dice_1: 3.473  loss_ce_2: 2.228  loss_mask_2: 0.6181  loss_dice_2: 3.401  loss_ce_3: 2.159  loss_mask_3: 0.6172  loss_dice_3: 3.354  loss_ce_4: 2.12  loss_mask_4: 0.6167  loss_dice_4: 3.346  loss_ce_5: 2.103  loss_mask_5: 0.6153  loss_dice_5: 3.345  loss_ce_6: 2.106  loss_mask_6: 0.6134  loss_dice_6: 3.33  loss_ce_7: 2.087  loss_mask_7: 0.6144  loss_dice_7: 3.328  loss_ce_8: 2.093  loss_mask_8: 0.6154  loss_dice_8: 3.33  time: 1.6947  data_time: 0.3608  lr: 6.7394e-06  max_mem: 17674M
[01/19 08:02:24] d2.utils.events INFO:  eta: 12:05:52  iter: 14219  total_loss: 63.66  loss_ce: 2.164  loss_mask: 0.6132  loss_dice: 3.33  loss_ce_0: 3.648  loss_mask_0: 0.6365  loss_dice_0: 3.606  loss_ce_1: 2.407  loss_mask_1: 0.6243  loss_dice_1: 3.47  loss_ce_2: 2.263  loss_mask_2: 0.6149  loss_dice_2: 3.399  loss_ce_3: 2.232  loss_mask_3: 0.6134  loss_dice_3: 3.355  loss_ce_4: 2.186  loss_mask_4: 0.6164  loss_dice_4: 3.349  loss_ce_5: 2.179  loss_mask_5: 0.6164  loss_dice_5: 3.345  loss_ce_6: 2.168  loss_mask_6: 0.6154  loss_dice_6: 3.336  loss_ce_7: 2.161  loss_mask_7: 0.6167  loss_dice_7: 3.335  loss_ce_8: 2.171  loss_mask_8: 0.6166  loss_dice_8: 3.33  time: 1.6947  data_time: 0.3500  lr: 6.7347e-06  max_mem: 17674M
[01/19 08:02:58] d2.utils.events INFO:  eta: 12:05:31  iter: 14239  total_loss: 63.15  loss_ce: 2.1  loss_mask: 0.6369  loss_dice: 3.344  loss_ce_0: 3.545  loss_mask_0: 0.6569  loss_dice_0: 3.591  loss_ce_1: 2.312  loss_mask_1: 0.6463  loss_dice_1: 3.474  loss_ce_2: 2.204  loss_mask_2: 0.6398  loss_dice_2: 3.417  loss_ce_3: 2.153  loss_mask_3: 0.6386  loss_dice_3: 3.369  loss_ce_4: 2.138  loss_mask_4: 0.6384  loss_dice_4: 3.363  loss_ce_5: 2.122  loss_mask_5: 0.6396  loss_dice_5: 3.37  loss_ce_6: 2.133  loss_mask_6: 0.6385  loss_dice_6: 3.346  loss_ce_7: 2.115  loss_mask_7: 0.64  loss_dice_7: 3.35  loss_ce_8: 2.095  loss_mask_8: 0.6396  loss_dice_8: 3.354  time: 1.6947  data_time: 0.3480  lr: 6.73e-06  max_mem: 17674M
[01/19 08:03:31] d2.utils.events INFO:  eta: 12:04:45  iter: 14259  total_loss: 64.01  loss_ce: 2.189  loss_mask: 0.6275  loss_dice: 3.337  loss_ce_0: 3.646  loss_mask_0: 0.6596  loss_dice_0: 3.602  loss_ce_1: 2.421  loss_mask_1: 0.6449  loss_dice_1: 3.472  loss_ce_2: 2.285  loss_mask_2: 0.6361  loss_dice_2: 3.398  loss_ce_3: 2.255  loss_mask_3: 0.6275  loss_dice_3: 3.36  loss_ce_4: 2.235  loss_mask_4: 0.6318  loss_dice_4: 3.355  loss_ce_5: 2.211  loss_mask_5: 0.6288  loss_dice_5: 3.353  loss_ce_6: 2.184  loss_mask_6: 0.6285  loss_dice_6: 3.344  loss_ce_7: 2.182  loss_mask_7: 0.6282  loss_dice_7: 3.341  loss_ce_8: 2.164  loss_mask_8: 0.6284  loss_dice_8: 3.342  time: 1.6947  data_time: 0.3297  lr: 6.7253e-06  max_mem: 17674M
[01/19 08:04:05] d2.utils.events INFO:  eta: 12:04:11  iter: 14279  total_loss: 64.08  loss_ce: 2.217  loss_mask: 0.6443  loss_dice: 3.321  loss_ce_0: 3.654  loss_mask_0: 0.6623  loss_dice_0: 3.575  loss_ce_1: 2.427  loss_mask_1: 0.6542  loss_dice_1: 3.457  loss_ce_2: 2.313  loss_mask_2: 0.6528  loss_dice_2: 3.385  loss_ce_3: 2.272  loss_mask_3: 0.6441  loss_dice_3: 3.347  loss_ce_4: 2.246  loss_mask_4: 0.6432  loss_dice_4: 3.341  loss_ce_5: 2.231  loss_mask_5: 0.6459  loss_dice_5: 3.335  loss_ce_6: 2.229  loss_mask_6: 0.6477  loss_dice_6: 3.323  loss_ce_7: 2.215  loss_mask_7: 0.6481  loss_dice_7: 3.319  loss_ce_8: 2.196  loss_mask_8: 0.6489  loss_dice_8: 3.328  time: 1.6946  data_time: 0.3356  lr: 6.7206e-06  max_mem: 17674M
[01/19 08:04:38] d2.utils.events INFO:  eta: 12:03:36  iter: 14299  total_loss: 63.42  loss_ce: 2.113  loss_mask: 0.6401  loss_dice: 3.344  loss_ce_0: 3.627  loss_mask_0: 0.6557  loss_dice_0: 3.604  loss_ce_1: 2.381  loss_mask_1: 0.6487  loss_dice_1: 3.484  loss_ce_2: 2.213  loss_mask_2: 0.639  loss_dice_2: 3.424  loss_ce_3: 2.179  loss_mask_3: 0.6379  loss_dice_3: 3.372  loss_ce_4: 2.139  loss_mask_4: 0.6399  loss_dice_4: 3.367  loss_ce_5: 2.139  loss_mask_5: 0.6406  loss_dice_5: 3.364  loss_ce_6: 2.116  loss_mask_6: 0.6411  loss_dice_6: 3.345  loss_ce_7: 2.119  loss_mask_7: 0.6379  loss_dice_7: 3.349  loss_ce_8: 2.113  loss_mask_8: 0.6387  loss_dice_8: 3.353  time: 1.6946  data_time: 0.3232  lr: 6.7159e-06  max_mem: 17674M
[01/19 08:05:12] d2.utils.events INFO:  eta: 12:02:41  iter: 14319  total_loss: 63.9  loss_ce: 2.187  loss_mask: 0.6364  loss_dice: 3.313  loss_ce_0: 3.571  loss_mask_0: 0.6525  loss_dice_0: 3.579  loss_ce_1: 2.395  loss_mask_1: 0.6469  loss_dice_1: 3.465  loss_ce_2: 2.274  loss_mask_2: 0.6392  loss_dice_2: 3.391  loss_ce_3: 2.256  loss_mask_3: 0.6357  loss_dice_3: 3.338  loss_ce_4: 2.215  loss_mask_4: 0.6371  loss_dice_4: 3.338  loss_ce_5: 2.211  loss_mask_5: 0.6363  loss_dice_5: 3.337  loss_ce_6: 2.188  loss_mask_6: 0.6348  loss_dice_6: 3.321  loss_ce_7: 2.185  loss_mask_7: 0.6332  loss_dice_7: 3.322  loss_ce_8: 2.184  loss_mask_8: 0.6374  loss_dice_8: 3.316  time: 1.6946  data_time: 0.3332  lr: 6.7111e-06  max_mem: 17674M
[01/19 08:05:46] d2.utils.events INFO:  eta: 12:02:26  iter: 14339  total_loss: 63.2  loss_ce: 2.12  loss_mask: 0.6154  loss_dice: 3.365  loss_ce_0: 3.621  loss_mask_0: 0.6404  loss_dice_0: 3.625  loss_ce_1: 2.333  loss_mask_1: 0.6335  loss_dice_1: 3.506  loss_ce_2: 2.227  loss_mask_2: 0.6231  loss_dice_2: 3.438  loss_ce_3: 2.161  loss_mask_3: 0.6173  loss_dice_3: 3.389  loss_ce_4: 2.149  loss_mask_4: 0.6175  loss_dice_4: 3.388  loss_ce_5: 2.152  loss_mask_5: 0.6171  loss_dice_5: 3.378  loss_ce_6: 2.121  loss_mask_6: 0.6161  loss_dice_6: 3.371  loss_ce_7: 2.086  loss_mask_7: 0.6175  loss_dice_7: 3.366  loss_ce_8: 2.109  loss_mask_8: 0.6133  loss_dice_8: 3.367  time: 1.6946  data_time: 0.3592  lr: 6.7064e-06  max_mem: 17674M
[01/19 08:06:20] d2.utils.events INFO:  eta: 12:01:15  iter: 14359  total_loss: 63.11  loss_ce: 2.099  loss_mask: 0.6194  loss_dice: 3.307  loss_ce_0: 3.63  loss_mask_0: 0.6487  loss_dice_0: 3.584  loss_ce_1: 2.356  loss_mask_1: 0.6312  loss_dice_1: 3.443  loss_ce_2: 2.226  loss_mask_2: 0.6272  loss_dice_2: 3.379  loss_ce_3: 2.171  loss_mask_3: 0.627  loss_dice_3: 3.327  loss_ce_4: 2.133  loss_mask_4: 0.6238  loss_dice_4: 3.324  loss_ce_5: 2.119  loss_mask_5: 0.6232  loss_dice_5: 3.326  loss_ce_6: 2.112  loss_mask_6: 0.6209  loss_dice_6: 3.314  loss_ce_7: 2.092  loss_mask_7: 0.6169  loss_dice_7: 3.31  loss_ce_8: 2.098  loss_mask_8: 0.6197  loss_dice_8: 3.308  time: 1.6946  data_time: 0.3374  lr: 6.7017e-06  max_mem: 17674M
[01/19 08:06:53] d2.utils.events INFO:  eta: 12:00:25  iter: 14379  total_loss: 63.91  loss_ce: 2.171  loss_mask: 0.6386  loss_dice: 3.336  loss_ce_0: 3.539  loss_mask_0: 0.6647  loss_dice_0: 3.6  loss_ce_1: 2.362  loss_mask_1: 0.6504  loss_dice_1: 3.481  loss_ce_2: 2.246  loss_mask_2: 0.646  loss_dice_2: 3.408  loss_ce_3: 2.217  loss_mask_3: 0.6406  loss_dice_3: 3.359  loss_ce_4: 2.175  loss_mask_4: 0.6404  loss_dice_4: 3.349  loss_ce_5: 2.182  loss_mask_5: 0.642  loss_dice_5: 3.347  loss_ce_6: 2.163  loss_mask_6: 0.6388  loss_dice_6: 3.337  loss_ce_7: 2.136  loss_mask_7: 0.6426  loss_dice_7: 3.334  loss_ce_8: 2.138  loss_mask_8: 0.6398  loss_dice_8: 3.335  time: 1.6946  data_time: 0.3222  lr: 6.697e-06  max_mem: 17674M
[01/19 08:07:27] d2.utils.events INFO:  eta: 11:59:32  iter: 14399  total_loss: 63.19  loss_ce: 2.159  loss_mask: 0.6366  loss_dice: 3.3  loss_ce_0: 3.616  loss_mask_0: 0.6625  loss_dice_0: 3.585  loss_ce_1: 2.419  loss_mask_1: 0.6489  loss_dice_1: 3.443  loss_ce_2: 2.282  loss_mask_2: 0.6385  loss_dice_2: 3.369  loss_ce_3: 2.226  loss_mask_3: 0.6348  loss_dice_3: 3.324  loss_ce_4: 2.158  loss_mask_4: 0.6347  loss_dice_4: 3.322  loss_ce_5: 2.168  loss_mask_5: 0.6334  loss_dice_5: 3.308  loss_ce_6: 2.158  loss_mask_6: 0.6339  loss_dice_6: 3.304  loss_ce_7: 2.157  loss_mask_7: 0.6338  loss_dice_7: 3.302  loss_ce_8: 2.152  loss_mask_8: 0.635  loss_dice_8: 3.302  time: 1.6945  data_time: 0.3264  lr: 6.6923e-06  max_mem: 17674M
[01/19 08:08:00] d2.utils.events INFO:  eta: 11:58:57  iter: 14419  total_loss: 63.24  loss_ce: 2.152  loss_mask: 0.6267  loss_dice: 3.282  loss_ce_0: 3.654  loss_mask_0: 0.6585  loss_dice_0: 3.575  loss_ce_1: 2.373  loss_mask_1: 0.6382  loss_dice_1: 3.423  loss_ce_2: 2.24  loss_mask_2: 0.6276  loss_dice_2: 3.351  loss_ce_3: 2.217  loss_mask_3: 0.6271  loss_dice_3: 3.312  loss_ce_4: 2.174  loss_mask_4: 0.6274  loss_dice_4: 3.293  loss_ce_5: 2.161  loss_mask_5: 0.627  loss_dice_5: 3.299  loss_ce_6: 2.162  loss_mask_6: 0.6262  loss_dice_6: 3.284  loss_ce_7: 2.152  loss_mask_7: 0.6248  loss_dice_7: 3.29  loss_ce_8: 2.138  loss_mask_8: 0.6273  loss_dice_8: 3.286  time: 1.6945  data_time: 0.3326  lr: 6.6876e-06  max_mem: 17674M
[01/19 08:08:34] d2.utils.events INFO:  eta: 11:58:04  iter: 14439  total_loss: 63.45  loss_ce: 2.095  loss_mask: 0.6212  loss_dice: 3.328  loss_ce_0: 3.623  loss_mask_0: 0.656  loss_dice_0: 3.592  loss_ce_1: 2.339  loss_mask_1: 0.6366  loss_dice_1: 3.474  loss_ce_2: 2.2  loss_mask_2: 0.6331  loss_dice_2: 3.403  loss_ce_3: 2.168  loss_mask_3: 0.6236  loss_dice_3: 3.357  loss_ce_4: 2.122  loss_mask_4: 0.6235  loss_dice_4: 3.353  loss_ce_5: 2.098  loss_mask_5: 0.6229  loss_dice_5: 3.347  loss_ce_6: 2.095  loss_mask_6: 0.6213  loss_dice_6: 3.331  loss_ce_7: 2.1  loss_mask_7: 0.6245  loss_dice_7: 3.329  loss_ce_8: 2.086  loss_mask_8: 0.6255  loss_dice_8: 3.327  time: 1.6945  data_time: 0.3518  lr: 6.6829e-06  max_mem: 17674M
[01/19 08:09:08] d2.utils.events INFO:  eta: 11:57:29  iter: 14459  total_loss: 63  loss_ce: 2.133  loss_mask: 0.6318  loss_dice: 3.307  loss_ce_0: 3.572  loss_mask_0: 0.6538  loss_dice_0: 3.578  loss_ce_1: 2.342  loss_mask_1: 0.6401  loss_dice_1: 3.455  loss_ce_2: 2.245  loss_mask_2: 0.6363  loss_dice_2: 3.383  loss_ce_3: 2.192  loss_mask_3: 0.6326  loss_dice_3: 3.341  loss_ce_4: 2.167  loss_mask_4: 0.6337  loss_dice_4: 3.331  loss_ce_5: 2.142  loss_mask_5: 0.6319  loss_dice_5: 3.328  loss_ce_6: 2.131  loss_mask_6: 0.6327  loss_dice_6: 3.318  loss_ce_7: 2.128  loss_mask_7: 0.6316  loss_dice_7: 3.317  loss_ce_8: 2.126  loss_mask_8: 0.6315  loss_dice_8: 3.313  time: 1.6945  data_time: 0.3392  lr: 6.6782e-06  max_mem: 17674M
[01/19 08:09:42] d2.utils.events INFO:  eta: 11:56:55  iter: 14479  total_loss: 63  loss_ce: 2.055  loss_mask: 0.619  loss_dice: 3.312  loss_ce_0: 3.552  loss_mask_0: 0.6406  loss_dice_0: 3.59  loss_ce_1: 2.28  loss_mask_1: 0.6373  loss_dice_1: 3.461  loss_ce_2: 2.14  loss_mask_2: 0.6266  loss_dice_2: 3.382  loss_ce_3: 2.121  loss_mask_3: 0.6221  loss_dice_3: 3.347  loss_ce_4: 2.11  loss_mask_4: 0.6232  loss_dice_4: 3.337  loss_ce_5: 2.082  loss_mask_5: 0.6219  loss_dice_5: 3.332  loss_ce_6: 2.067  loss_mask_6: 0.6215  loss_dice_6: 3.324  loss_ce_7: 2.048  loss_mask_7: 0.6207  loss_dice_7: 3.321  loss_ce_8: 2.052  loss_mask_8: 0.6218  loss_dice_8: 3.321  time: 1.6945  data_time: 0.3516  lr: 6.6735e-06  max_mem: 17674M
[01/19 08:10:16] d2.utils.events INFO:  eta: 11:56:22  iter: 14499  total_loss: 63.33  loss_ce: 2.127  loss_mask: 0.6283  loss_dice: 3.334  loss_ce_0: 3.613  loss_mask_0: 0.646  loss_dice_0: 3.592  loss_ce_1: 2.328  loss_mask_1: 0.6387  loss_dice_1: 3.481  loss_ce_2: 2.246  loss_mask_2: 0.6302  loss_dice_2: 3.408  loss_ce_3: 2.186  loss_mask_3: 0.6298  loss_dice_3: 3.359  loss_ce_4: 2.154  loss_mask_4: 0.6309  loss_dice_4: 3.355  loss_ce_5: 2.134  loss_mask_5: 0.6327  loss_dice_5: 3.348  loss_ce_6: 2.146  loss_mask_6: 0.6301  loss_dice_6: 3.333  loss_ce_7: 2.142  loss_mask_7: 0.6301  loss_dice_7: 3.339  loss_ce_8: 2.128  loss_mask_8: 0.6288  loss_dice_8: 3.334  time: 1.6945  data_time: 0.3537  lr: 6.6688e-06  max_mem: 17674M
[01/19 08:10:49] d2.utils.events INFO:  eta: 11:55:48  iter: 14519  total_loss: 62.82  loss_ce: 2.025  loss_mask: 0.622  loss_dice: 3.342  loss_ce_0: 3.636  loss_mask_0: 0.6413  loss_dice_0: 3.604  loss_ce_1: 2.292  loss_mask_1: 0.6341  loss_dice_1: 3.479  loss_ce_2: 2.139  loss_mask_2: 0.6339  loss_dice_2: 3.408  loss_ce_3: 2.105  loss_mask_3: 0.6255  loss_dice_3: 3.358  loss_ce_4: 2.065  loss_mask_4: 0.6227  loss_dice_4: 3.354  loss_ce_5: 2.054  loss_mask_5: 0.6235  loss_dice_5: 3.351  loss_ce_6: 2.043  loss_mask_6: 0.6182  loss_dice_6: 3.341  loss_ce_7: 2.026  loss_mask_7: 0.6198  loss_dice_7: 3.345  loss_ce_8: 2.033  loss_mask_8: 0.6211  loss_dice_8: 3.344  time: 1.6945  data_time: 0.3379  lr: 6.6641e-06  max_mem: 17674M
[01/19 08:11:23] d2.utils.events INFO:  eta: 11:55:10  iter: 14539  total_loss: 63.03  loss_ce: 2.117  loss_mask: 0.6259  loss_dice: 3.348  loss_ce_0: 3.614  loss_mask_0: 0.6505  loss_dice_0: 3.612  loss_ce_1: 2.255  loss_mask_1: 0.6412  loss_dice_1: 3.506  loss_ce_2: 2.206  loss_mask_2: 0.6324  loss_dice_2: 3.429  loss_ce_3: 2.173  loss_mask_3: 0.6254  loss_dice_3: 3.375  loss_ce_4: 2.143  loss_mask_4: 0.6222  loss_dice_4: 3.375  loss_ce_5: 2.122  loss_mask_5: 0.6274  loss_dice_5: 3.369  loss_ce_6: 2.118  loss_mask_6: 0.6246  loss_dice_6: 3.356  loss_ce_7: 2.11  loss_mask_7: 0.6227  loss_dice_7: 3.352  loss_ce_8: 2.112  loss_mask_8: 0.6243  loss_dice_8: 3.35  time: 1.6945  data_time: 0.3495  lr: 6.6594e-06  max_mem: 17674M
[01/19 08:11:57] d2.utils.events INFO:  eta: 11:54:25  iter: 14559  total_loss: 62.98  loss_ce: 2.14  loss_mask: 0.6148  loss_dice: 3.301  loss_ce_0: 3.53  loss_mask_0: 0.6224  loss_dice_0: 3.6  loss_ce_1: 2.344  loss_mask_1: 0.6163  loss_dice_1: 3.462  loss_ce_2: 2.213  loss_mask_2: 0.6157  loss_dice_2: 3.377  loss_ce_3: 2.174  loss_mask_3: 0.6142  loss_dice_3: 3.32  loss_ce_4: 2.151  loss_mask_4: 0.6147  loss_dice_4: 3.321  loss_ce_5: 2.147  loss_mask_5: 0.6156  loss_dice_5: 3.316  loss_ce_6: 2.139  loss_mask_6: 0.6143  loss_dice_6: 3.31  loss_ce_7: 2.131  loss_mask_7: 0.6153  loss_dice_7: 3.3  loss_ce_8: 2.133  loss_mask_8: 0.6131  loss_dice_8: 3.307  time: 1.6945  data_time: 0.3569  lr: 6.6547e-06  max_mem: 17674M
[01/19 08:12:32] d2.utils.events INFO:  eta: 11:53:59  iter: 14579  total_loss: 63.14  loss_ce: 2.098  loss_mask: 0.6177  loss_dice: 3.329  loss_ce_0: 3.592  loss_mask_0: 0.6414  loss_dice_0: 3.607  loss_ce_1: 2.321  loss_mask_1: 0.6336  loss_dice_1: 3.479  loss_ce_2: 2.198  loss_mask_2: 0.6217  loss_dice_2: 3.402  loss_ce_3: 2.15  loss_mask_3: 0.6123  loss_dice_3: 3.356  loss_ce_4: 2.124  loss_mask_4: 0.6119  loss_dice_4: 3.349  loss_ce_5: 2.108  loss_mask_5: 0.6127  loss_dice_5: 3.34  loss_ce_6: 2.103  loss_mask_6: 0.613  loss_dice_6: 3.336  loss_ce_7: 2.074  loss_mask_7: 0.6162  loss_dice_7: 3.334  loss_ce_8: 2.098  loss_mask_8: 0.6184  loss_dice_8: 3.336  time: 1.6945  data_time: 0.3517  lr: 6.65e-06  max_mem: 17674M
[01/19 08:13:06] d2.utils.events INFO:  eta: 11:53:24  iter: 14599  total_loss: 62.68  loss_ce: 2.029  loss_mask: 0.6194  loss_dice: 3.375  loss_ce_0: 3.555  loss_mask_0: 0.6387  loss_dice_0: 3.642  loss_ce_1: 2.194  loss_mask_1: 0.6273  loss_dice_1: 3.525  loss_ce_2: 2.108  loss_mask_2: 0.6217  loss_dice_2: 3.447  loss_ce_3: 2.086  loss_mask_3: 0.6226  loss_dice_3: 3.4  loss_ce_4: 2.031  loss_mask_4: 0.6206  loss_dice_4: 3.391  loss_ce_5: 2.014  loss_mask_5: 0.6234  loss_dice_5: 3.389  loss_ce_6: 2.011  loss_mask_6: 0.6202  loss_dice_6: 3.381  loss_ce_7: 2.019  loss_mask_7: 0.6185  loss_dice_7: 3.383  loss_ce_8: 2.017  loss_mask_8: 0.6207  loss_dice_8: 3.382  time: 1.6945  data_time: 0.3525  lr: 6.6453e-06  max_mem: 17674M
[01/19 08:13:39] d2.utils.events INFO:  eta: 11:52:51  iter: 14619  total_loss: 63.54  loss_ce: 2.09  loss_mask: 0.6213  loss_dice: 3.321  loss_ce_0: 3.597  loss_mask_0: 0.6513  loss_dice_0: 3.58  loss_ce_1: 2.332  loss_mask_1: 0.6384  loss_dice_1: 3.464  loss_ce_2: 2.205  loss_mask_2: 0.6289  loss_dice_2: 3.392  loss_ce_3: 2.168  loss_mask_3: 0.6223  loss_dice_3: 3.35  loss_ce_4: 2.143  loss_mask_4: 0.6221  loss_dice_4: 3.333  loss_ce_5: 2.117  loss_mask_5: 0.621  loss_dice_5: 3.339  loss_ce_6: 2.106  loss_mask_6: 0.6208  loss_dice_6: 3.324  loss_ce_7: 2.109  loss_mask_7: 0.6201  loss_dice_7: 3.319  loss_ce_8: 2.101  loss_mask_8: 0.6201  loss_dice_8: 3.32  time: 1.6945  data_time: 0.3362  lr: 6.6405e-06  max_mem: 17674M
[01/19 08:14:13] d2.utils.events INFO:  eta: 11:52:26  iter: 14639  total_loss: 63.15  loss_ce: 2.116  loss_mask: 0.6244  loss_dice: 3.288  loss_ce_0: 3.589  loss_mask_0: 0.6482  loss_dice_0: 3.566  loss_ce_1: 2.352  loss_mask_1: 0.633  loss_dice_1: 3.43  loss_ce_2: 2.263  loss_mask_2: 0.6299  loss_dice_2: 3.363  loss_ce_3: 2.211  loss_mask_3: 0.628  loss_dice_3: 3.317  loss_ce_4: 2.16  loss_mask_4: 0.6294  loss_dice_4: 3.312  loss_ce_5: 2.142  loss_mask_5: 0.6278  loss_dice_5: 3.31  loss_ce_6: 2.127  loss_mask_6: 0.6266  loss_dice_6: 3.296  loss_ce_7: 2.118  loss_mask_7: 0.625  loss_dice_7: 3.296  loss_ce_8: 2.108  loss_mask_8: 0.6233  loss_dice_8: 3.291  time: 1.6945  data_time: 0.3418  lr: 6.6358e-06  max_mem: 17674M
[01/19 08:14:47] d2.utils.events INFO:  eta: 11:51:53  iter: 14659  total_loss: 63.18  loss_ce: 2.037  loss_mask: 0.6404  loss_dice: 3.312  loss_ce_0: 3.538  loss_mask_0: 0.6585  loss_dice_0: 3.597  loss_ce_1: 2.257  loss_mask_1: 0.6491  loss_dice_1: 3.461  loss_ce_2: 2.131  loss_mask_2: 0.6464  loss_dice_2: 3.389  loss_ce_3: 2.1  loss_mask_3: 0.6411  loss_dice_3: 3.344  loss_ce_4: 2.079  loss_mask_4: 0.6388  loss_dice_4: 3.338  loss_ce_5: 2.055  loss_mask_5: 0.6391  loss_dice_5: 3.339  loss_ce_6: 2.042  loss_mask_6: 0.638  loss_dice_6: 3.327  loss_ce_7: 2.048  loss_mask_7: 0.6392  loss_dice_7: 3.327  loss_ce_8: 2.043  loss_mask_8: 0.6398  loss_dice_8: 3.322  time: 1.6944  data_time: 0.3410  lr: 6.6311e-06  max_mem: 17674M
[01/19 08:15:21] d2.utils.events INFO:  eta: 11:51:54  iter: 14679  total_loss: 62.61  loss_ce: 2.073  loss_mask: 0.6245  loss_dice: 3.293  loss_ce_0: 3.602  loss_mask_0: 0.6504  loss_dice_0: 3.585  loss_ce_1: 2.283  loss_mask_1: 0.6311  loss_dice_1: 3.452  loss_ce_2: 2.161  loss_mask_2: 0.6216  loss_dice_2: 3.373  loss_ce_3: 2.127  loss_mask_3: 0.6231  loss_dice_3: 3.329  loss_ce_4: 2.098  loss_mask_4: 0.6279  loss_dice_4: 3.312  loss_ce_5: 2.075  loss_mask_5: 0.6247  loss_dice_5: 3.307  loss_ce_6: 2.081  loss_mask_6: 0.625  loss_dice_6: 3.297  loss_ce_7: 2.065  loss_mask_7: 0.6243  loss_dice_7: 3.296  loss_ce_8: 2.074  loss_mask_8: 0.6257  loss_dice_8: 3.289  time: 1.6945  data_time: 0.3448  lr: 6.6264e-06  max_mem: 17674M
[01/19 08:15:54] d2.utils.events INFO:  eta: 11:51:34  iter: 14699  total_loss: 62.68  loss_ce: 2.099  loss_mask: 0.6336  loss_dice: 3.31  loss_ce_0: 3.55  loss_mask_0: 0.6462  loss_dice_0: 3.585  loss_ce_1: 2.238  loss_mask_1: 0.6423  loss_dice_1: 3.462  loss_ce_2: 2.146  loss_mask_2: 0.6333  loss_dice_2: 3.383  loss_ce_3: 2.11  loss_mask_3: 0.6341  loss_dice_3: 3.341  loss_ce_4: 2.081  loss_mask_4: 0.633  loss_dice_4: 3.337  loss_ce_5: 2.059  loss_mask_5: 0.6336  loss_dice_5: 3.331  loss_ce_6: 2.086  loss_mask_6: 0.6315  loss_dice_6: 3.315  loss_ce_7: 2.106  loss_mask_7: 0.6342  loss_dice_7: 3.317  loss_ce_8: 2.082  loss_mask_8: 0.6324  loss_dice_8: 3.315  time: 1.6944  data_time: 0.3462  lr: 6.6217e-06  max_mem: 17674M
[01/19 08:16:28] d2.utils.events INFO:  eta: 11:50:54  iter: 14719  total_loss: 63.12  loss_ce: 2.118  loss_mask: 0.6264  loss_dice: 3.304  loss_ce_0: 3.597  loss_mask_0: 0.6456  loss_dice_0: 3.589  loss_ce_1: 2.285  loss_mask_1: 0.6322  loss_dice_1: 3.454  loss_ce_2: 2.171  loss_mask_2: 0.6256  loss_dice_2: 3.387  loss_ce_3: 2.169  loss_mask_3: 0.6279  loss_dice_3: 3.333  loss_ce_4: 2.143  loss_mask_4: 0.6305  loss_dice_4: 3.324  loss_ce_5: 2.128  loss_mask_5: 0.6321  loss_dice_5: 3.323  loss_ce_6: 2.128  loss_mask_6: 0.6264  loss_dice_6: 3.308  loss_ce_7: 2.117  loss_mask_7: 0.6291  loss_dice_7: 3.314  loss_ce_8: 2.097  loss_mask_8: 0.6257  loss_dice_8: 3.31  time: 1.6944  data_time: 0.3275  lr: 6.617e-06  max_mem: 17674M
[01/19 08:17:02] d2.utils.events INFO:  eta: 11:50:04  iter: 14739  total_loss: 64.03  loss_ce: 2.166  loss_mask: 0.6259  loss_dice: 3.309  loss_ce_0: 3.641  loss_mask_0: 0.6538  loss_dice_0: 3.59  loss_ce_1: 2.379  loss_mask_1: 0.6432  loss_dice_1: 3.482  loss_ce_2: 2.217  loss_mask_2: 0.6339  loss_dice_2: 3.384  loss_ce_3: 2.211  loss_mask_3: 0.6299  loss_dice_3: 3.335  loss_ce_4: 2.181  loss_mask_4: 0.6265  loss_dice_4: 3.332  loss_ce_5: 2.183  loss_mask_5: 0.628  loss_dice_5: 3.326  loss_ce_6: 2.174  loss_mask_6: 0.6251  loss_dice_6: 3.315  loss_ce_7: 2.174  loss_mask_7: 0.6249  loss_dice_7: 3.313  loss_ce_8: 2.17  loss_mask_8: 0.624  loss_dice_8: 3.309  time: 1.6944  data_time: 0.3434  lr: 6.6123e-06  max_mem: 17674M
[01/19 08:17:36] d2.utils.events INFO:  eta: 11:49:46  iter: 14759  total_loss: 63.29  loss_ce: 2.13  loss_mask: 0.619  loss_dice: 3.306  loss_ce_0: 3.591  loss_mask_0: 0.6407  loss_dice_0: 3.585  loss_ce_1: 2.387  loss_mask_1: 0.6302  loss_dice_1: 3.449  loss_ce_2: 2.268  loss_mask_2: 0.6274  loss_dice_2: 3.375  loss_ce_3: 2.2  loss_mask_3: 0.6195  loss_dice_3: 3.335  loss_ce_4: 2.174  loss_mask_4: 0.6205  loss_dice_4: 3.322  loss_ce_5: 2.147  loss_mask_5: 0.6231  loss_dice_5: 3.318  loss_ce_6: 2.139  loss_mask_6: 0.6204  loss_dice_6: 3.311  loss_ce_7: 2.127  loss_mask_7: 0.6191  loss_dice_7: 3.314  loss_ce_8: 2.122  loss_mask_8: 0.6204  loss_dice_8: 3.312  time: 1.6945  data_time: 0.3473  lr: 6.6076e-06  max_mem: 17674M
[01/19 08:18:10] d2.utils.events INFO:  eta: 11:49:19  iter: 14779  total_loss: 62.99  loss_ce: 2.079  loss_mask: 0.621  loss_dice: 3.279  loss_ce_0: 3.636  loss_mask_0: 0.6401  loss_dice_0: 3.553  loss_ce_1: 2.236  loss_mask_1: 0.6324  loss_dice_1: 3.409  loss_ce_2: 2.148  loss_mask_2: 0.631  loss_dice_2: 3.338  loss_ce_3: 2.12  loss_mask_3: 0.6263  loss_dice_3: 3.292  loss_ce_4: 2.101  loss_mask_4: 0.6272  loss_dice_4: 3.292  loss_ce_5: 2.073  loss_mask_5: 0.6286  loss_dice_5: 3.292  loss_ce_6: 2.088  loss_mask_6: 0.6253  loss_dice_6: 3.282  loss_ce_7: 2.09  loss_mask_7: 0.6232  loss_dice_7: 3.287  loss_ce_8: 2.06  loss_mask_8: 0.6262  loss_dice_8: 3.283  time: 1.6945  data_time: 0.3289  lr: 6.6029e-06  max_mem: 17674M
[01/19 08:18:44] d2.utils.events INFO:  eta: 11:49:03  iter: 14799  total_loss: 62.85  loss_ce: 2.105  loss_mask: 0.6156  loss_dice: 3.288  loss_ce_0: 3.655  loss_mask_0: 0.6354  loss_dice_0: 3.572  loss_ce_1: 2.349  loss_mask_1: 0.6212  loss_dice_1: 3.442  loss_ce_2: 2.231  loss_mask_2: 0.6193  loss_dice_2: 3.372  loss_ce_3: 2.187  loss_mask_3: 0.6188  loss_dice_3: 3.312  loss_ce_4: 2.141  loss_mask_4: 0.6188  loss_dice_4: 3.307  loss_ce_5: 2.106  loss_mask_5: 0.6168  loss_dice_5: 3.309  loss_ce_6: 2.115  loss_mask_6: 0.6155  loss_dice_6: 3.297  loss_ce_7: 2.093  loss_mask_7: 0.6186  loss_dice_7: 3.298  loss_ce_8: 2.098  loss_mask_8: 0.615  loss_dice_8: 3.294  time: 1.6945  data_time: 0.3506  lr: 6.5981e-06  max_mem: 17674M
[01/19 08:19:19] d2.utils.events INFO:  eta: 11:48:55  iter: 14819  total_loss: 63.4  loss_ce: 2.136  loss_mask: 0.6279  loss_dice: 3.341  loss_ce_0: 3.604  loss_mask_0: 0.6476  loss_dice_0: 3.601  loss_ce_1: 2.301  loss_mask_1: 0.6395  loss_dice_1: 3.486  loss_ce_2: 2.21  loss_mask_2: 0.6373  loss_dice_2: 3.414  loss_ce_3: 2.162  loss_mask_3: 0.6357  loss_dice_3: 3.372  loss_ce_4: 2.148  loss_mask_4: 0.6373  loss_dice_4: 3.351  loss_ce_5: 2.148  loss_mask_5: 0.6368  loss_dice_5: 3.353  loss_ce_6: 2.165  loss_mask_6: 0.6342  loss_dice_6: 3.34  loss_ce_7: 2.142  loss_mask_7: 0.6341  loss_dice_7: 3.338  loss_ce_8: 2.132  loss_mask_8: 0.6334  loss_dice_8: 3.338  time: 1.6945  data_time: 0.3452  lr: 6.5934e-06  max_mem: 17674M
[01/19 08:19:53] d2.utils.events INFO:  eta: 11:47:42  iter: 14839  total_loss: 63.41  loss_ce: 2.167  loss_mask: 0.6315  loss_dice: 3.341  loss_ce_0: 3.586  loss_mask_0: 0.6553  loss_dice_0: 3.588  loss_ce_1: 2.316  loss_mask_1: 0.6428  loss_dice_1: 3.475  loss_ce_2: 2.243  loss_mask_2: 0.6305  loss_dice_2: 3.4  loss_ce_3: 2.214  loss_mask_3: 0.6275  loss_dice_3: 3.366  loss_ce_4: 2.18  loss_mask_4: 0.6295  loss_dice_4: 3.358  loss_ce_5: 2.19  loss_mask_5: 0.6301  loss_dice_5: 3.353  loss_ce_6: 2.162  loss_mask_6: 0.6296  loss_dice_6: 3.341  loss_ce_7: 2.171  loss_mask_7: 0.6316  loss_dice_7: 3.341  loss_ce_8: 2.169  loss_mask_8: 0.6301  loss_dice_8: 3.345  time: 1.6945  data_time: 0.3453  lr: 6.5887e-06  max_mem: 17674M
[01/19 08:20:26] d2.utils.events INFO:  eta: 11:47:13  iter: 14859  total_loss: 63.07  loss_ce: 2.125  loss_mask: 0.6313  loss_dice: 3.297  loss_ce_0: 3.656  loss_mask_0: 0.6575  loss_dice_0: 3.556  loss_ce_1: 2.326  loss_mask_1: 0.6486  loss_dice_1: 3.431  loss_ce_2: 2.245  loss_mask_2: 0.6352  loss_dice_2: 3.364  loss_ce_3: 2.225  loss_mask_3: 0.6357  loss_dice_3: 3.322  loss_ce_4: 2.184  loss_mask_4: 0.6361  loss_dice_4: 3.311  loss_ce_5: 2.154  loss_mask_5: 0.6354  loss_dice_5: 3.31  loss_ce_6: 2.15  loss_mask_6: 0.6324  loss_dice_6: 3.302  loss_ce_7: 2.129  loss_mask_7: 0.6319  loss_dice_7: 3.301  loss_ce_8: 2.115  loss_mask_8: 0.6312  loss_dice_8: 3.296  time: 1.6945  data_time: 0.3446  lr: 6.584e-06  max_mem: 17674M
[01/19 08:21:00] d2.utils.events INFO:  eta: 11:46:40  iter: 14879  total_loss: 62.87  loss_ce: 2.063  loss_mask: 0.6134  loss_dice: 3.352  loss_ce_0: 3.579  loss_mask_0: 0.6464  loss_dice_0: 3.613  loss_ce_1: 2.248  loss_mask_1: 0.6275  loss_dice_1: 3.504  loss_ce_2: 2.129  loss_mask_2: 0.6214  loss_dice_2: 3.424  loss_ce_3: 2.099  loss_mask_3: 0.6128  loss_dice_3: 3.379  loss_ce_4: 2.087  loss_mask_4: 0.6136  loss_dice_4: 3.369  loss_ce_5: 2.063  loss_mask_5: 0.6136  loss_dice_5: 3.364  loss_ce_6: 2.081  loss_mask_6: 0.6123  loss_dice_6: 3.366  loss_ce_7: 2.059  loss_mask_7: 0.6142  loss_dice_7: 3.363  loss_ce_8: 2.063  loss_mask_8: 0.6134  loss_dice_8: 3.362  time: 1.6944  data_time: 0.3278  lr: 6.5793e-06  max_mem: 17674M
[01/19 08:21:34] d2.utils.events INFO:  eta: 11:46:08  iter: 14899  total_loss: 63.47  loss_ce: 2.158  loss_mask: 0.6072  loss_dice: 3.358  loss_ce_0: 3.543  loss_mask_0: 0.6272  loss_dice_0: 3.642  loss_ce_1: 2.274  loss_mask_1: 0.6175  loss_dice_1: 3.509  loss_ce_2: 2.193  loss_mask_2: 0.6187  loss_dice_2: 3.436  loss_ce_3: 2.19  loss_mask_3: 0.6128  loss_dice_3: 3.382  loss_ce_4: 2.163  loss_mask_4: 0.6102  loss_dice_4: 3.37  loss_ce_5: 2.158  loss_mask_5: 0.6092  loss_dice_5: 3.374  loss_ce_6: 2.162  loss_mask_6: 0.6088  loss_dice_6: 3.355  loss_ce_7: 2.122  loss_mask_7: 0.6111  loss_dice_7: 3.363  loss_ce_8: 2.139  loss_mask_8: 0.6096  loss_dice_8: 3.36  time: 1.6944  data_time: 0.3495  lr: 6.5746e-06  max_mem: 17674M
[01/19 08:22:07] d2.utils.events INFO:  eta: 11:45:32  iter: 14919  total_loss: 63.65  loss_ce: 2.093  loss_mask: 0.6381  loss_dice: 3.324  loss_ce_0: 3.598  loss_mask_0: 0.6586  loss_dice_0: 3.588  loss_ce_1: 2.312  loss_mask_1: 0.6526  loss_dice_1: 3.458  loss_ce_2: 2.201  loss_mask_2: 0.646  loss_dice_2: 3.397  loss_ce_3: 2.169  loss_mask_3: 0.6398  loss_dice_3: 3.351  loss_ce_4: 2.161  loss_mask_4: 0.6384  loss_dice_4: 3.352  loss_ce_5: 2.109  loss_mask_5: 0.6383  loss_dice_5: 3.343  loss_ce_6: 2.125  loss_mask_6: 0.6391  loss_dice_6: 3.336  loss_ce_7: 2.092  loss_mask_7: 0.6379  loss_dice_7: 3.337  loss_ce_8: 2.107  loss_mask_8: 0.6382  loss_dice_8: 3.336  time: 1.6944  data_time: 0.3308  lr: 6.5699e-06  max_mem: 17674M
[01/19 08:22:41] d2.utils.events INFO:  eta: 11:44:53  iter: 14939  total_loss: 61.88  loss_ce: 1.976  loss_mask: 0.6206  loss_dice: 3.329  loss_ce_0: 3.575  loss_mask_0: 0.6403  loss_dice_0: 3.572  loss_ce_1: 2.229  loss_mask_1: 0.6291  loss_dice_1: 3.454  loss_ce_2: 2.101  loss_mask_2: 0.6267  loss_dice_2: 3.385  loss_ce_3: 2.053  loss_mask_3: 0.6182  loss_dice_3: 3.338  loss_ce_4: 1.996  loss_mask_4: 0.621  loss_dice_4: 3.342  loss_ce_5: 1.994  loss_mask_5: 0.6211  loss_dice_5: 3.332  loss_ce_6: 1.991  loss_mask_6: 0.6205  loss_dice_6: 3.325  loss_ce_7: 1.971  loss_mask_7: 0.6231  loss_dice_7: 3.329  loss_ce_8: 1.983  loss_mask_8: 0.623  loss_dice_8: 3.329  time: 1.6944  data_time: 0.3400  lr: 6.5651e-06  max_mem: 17674M
[01/19 08:23:15] d2.utils.events INFO:  eta: 11:44:26  iter: 14959  total_loss: 62.23  loss_ce: 2.013  loss_mask: 0.6257  loss_dice: 3.336  loss_ce_0: 3.544  loss_mask_0: 0.6327  loss_dice_0: 3.595  loss_ce_1: 2.239  loss_mask_1: 0.6282  loss_dice_1: 3.472  loss_ce_2: 2.126  loss_mask_2: 0.629  loss_dice_2: 3.407  loss_ce_3: 2.068  loss_mask_3: 0.6211  loss_dice_3: 3.372  loss_ce_4: 2.051  loss_mask_4: 0.6215  loss_dice_4: 3.363  loss_ce_5: 2.028  loss_mask_5: 0.6216  loss_dice_5: 3.358  loss_ce_6: 2.028  loss_mask_6: 0.6232  loss_dice_6: 3.342  loss_ce_7: 2.024  loss_mask_7: 0.6267  loss_dice_7: 3.343  loss_ce_8: 2.011  loss_mask_8: 0.6257  loss_dice_8: 3.342  time: 1.6944  data_time: 0.3277  lr: 6.5604e-06  max_mem: 17674M
[01/19 08:23:48] d2.utils.events INFO:  eta: 11:43:35  iter: 14979  total_loss: 62.93  loss_ce: 2.061  loss_mask: 0.6195  loss_dice: 3.355  loss_ce_0: 3.636  loss_mask_0: 0.6434  loss_dice_0: 3.604  loss_ce_1: 2.287  loss_mask_1: 0.631  loss_dice_1: 3.503  loss_ce_2: 2.148  loss_mask_2: 0.6288  loss_dice_2: 3.421  loss_ce_3: 2.137  loss_mask_3: 0.6246  loss_dice_3: 3.375  loss_ce_4: 2.099  loss_mask_4: 0.6224  loss_dice_4: 3.364  loss_ce_5: 2.079  loss_mask_5: 0.621  loss_dice_5: 3.366  loss_ce_6: 2.075  loss_mask_6: 0.6186  loss_dice_6: 3.358  loss_ce_7: 2.071  loss_mask_7: 0.6195  loss_dice_7: 3.366  loss_ce_8: 2.069  loss_mask_8: 0.6189  loss_dice_8: 3.356  time: 1.6944  data_time: 0.3374  lr: 6.5557e-06  max_mem: 17674M
[01/19 08:24:22] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/sceneflow_crop192x384/model_0014999.pth
[01/19 08:24:23] d2.utils.events INFO:  eta: 11:43:15  iter: 14999  total_loss: 62.29  loss_ce: 2.024  loss_mask: 0.6168  loss_dice: 3.321  loss_ce_0: 3.576  loss_mask_0: 0.6373  loss_dice_0: 3.595  loss_ce_1: 2.263  loss_mask_1: 0.6236  loss_dice_1: 3.458  loss_ce_2: 2.139  loss_mask_2: 0.6144  loss_dice_2: 3.393  loss_ce_3: 2.08  loss_mask_3: 0.6101  loss_dice_3: 3.356  loss_ce_4: 2.06  loss_mask_4: 0.6106  loss_dice_4: 3.357  loss_ce_5: 2.04  loss_mask_5: 0.6099  loss_dice_5: 3.349  loss_ce_6: 2.043  loss_mask_6: 0.6138  loss_dice_6: 3.329  loss_ce_7: 2.03  loss_mask_7: 0.6165  loss_dice_7: 3.328  loss_ce_8: 2.026  loss_mask_8: 0.6169  loss_dice_8: 3.328  time: 1.6944  data_time: 0.3378  lr: 6.551e-06  max_mem: 17674M
[01/19 08:24:57] d2.utils.events INFO:  eta: 11:43:05  iter: 15019  total_loss: 62.47  loss_ce: 2.084  loss_mask: 0.629  loss_dice: 3.348  loss_ce_0: 3.521  loss_mask_0: 0.65  loss_dice_0: 3.592  loss_ce_1: 2.312  loss_mask_1: 0.6345  loss_dice_1: 3.478  loss_ce_2: 2.176  loss_mask_2: 0.6322  loss_dice_2: 3.411  loss_ce_3: 2.13  loss_mask_3: 0.6277  loss_dice_3: 3.364  loss_ce_4: 2.104  loss_mask_4: 0.6301  loss_dice_4: 3.356  loss_ce_5: 2.075  loss_mask_5: 0.6334  loss_dice_5: 3.356  loss_ce_6: 2.068  loss_mask_6: 0.6316  loss_dice_6: 3.347  loss_ce_7: 2.08  loss_mask_7: 0.6299  loss_dice_7: 3.345  loss_ce_8: 2.065  loss_mask_8: 0.6291  loss_dice_8: 3.348  time: 1.6944  data_time: 0.3502  lr: 6.5463e-06  max_mem: 17674M
[01/19 08:25:31] d2.utils.events INFO:  eta: 11:42:15  iter: 15039  total_loss: 62.78  loss_ce: 2.058  loss_mask: 0.6206  loss_dice: 3.33  loss_ce_0: 3.571  loss_mask_0: 0.6377  loss_dice_0: 3.602  loss_ce_1: 2.262  loss_mask_1: 0.6323  loss_dice_1: 3.474  loss_ce_2: 2.143  loss_mask_2: 0.6253  loss_dice_2: 3.408  loss_ce_3: 2.106  loss_mask_3: 0.6198  loss_dice_3: 3.355  loss_ce_4: 2.042  loss_mask_4: 0.6208  loss_dice_4: 3.356  loss_ce_5: 2.039  loss_mask_5: 0.6235  loss_dice_5: 3.349  loss_ce_6: 2.049  loss_mask_6: 0.6233  loss_dice_6: 3.334  loss_ce_7: 2.028  loss_mask_7: 0.6235  loss_dice_7: 3.334  loss_ce_8: 2.027  loss_mask_8: 0.6245  loss_dice_8: 3.325  time: 1.6944  data_time: 0.3445  lr: 6.5416e-06  max_mem: 17674M
[01/19 08:26:05] d2.utils.events INFO:  eta: 11:41:45  iter: 15059  total_loss: 63.18  loss_ce: 2.096  loss_mask: 0.6156  loss_dice: 3.382  loss_ce_0: 3.579  loss_mask_0: 0.6313  loss_dice_0: 3.623  loss_ce_1: 2.293  loss_mask_1: 0.6199  loss_dice_1: 3.509  loss_ce_2: 2.197  loss_mask_2: 0.6156  loss_dice_2: 3.44  loss_ce_3: 2.158  loss_mask_3: 0.6213  loss_dice_3: 3.409  loss_ce_4: 2.1  loss_mask_4: 0.6181  loss_dice_4: 3.393  loss_ce_5: 2.115  loss_mask_5: 0.6165  loss_dice_5: 3.397  loss_ce_6: 2.135  loss_mask_6: 0.6162  loss_dice_6: 3.377  loss_ce_7: 2.111  loss_mask_7: 0.6179  loss_dice_7: 3.382  loss_ce_8: 2.112  loss_mask_8: 0.6137  loss_dice_8: 3.381  time: 1.6944  data_time: 0.3560  lr: 6.5368e-06  max_mem: 17674M
[01/19 08:26:39] d2.utils.events INFO:  eta: 11:41:43  iter: 15079  total_loss: 62.83  loss_ce: 2.098  loss_mask: 0.6172  loss_dice: 3.358  loss_ce_0: 3.583  loss_mask_0: 0.637  loss_dice_0: 3.624  loss_ce_1: 2.239  loss_mask_1: 0.6278  loss_dice_1: 3.502  loss_ce_2: 2.164  loss_mask_2: 0.6174  loss_dice_2: 3.43  loss_ce_3: 2.128  loss_mask_3: 0.6173  loss_dice_3: 3.383  loss_ce_4: 2.095  loss_mask_4: 0.6221  loss_dice_4: 3.377  loss_ce_5: 2.097  loss_mask_5: 0.6231  loss_dice_5: 3.377  loss_ce_6: 2.115  loss_mask_6: 0.6212  loss_dice_6: 3.363  loss_ce_7: 2.085  loss_mask_7: 0.6214  loss_dice_7: 3.362  loss_ce_8: 2.091  loss_mask_8: 0.6206  loss_dice_8: 3.36  time: 1.6944  data_time: 0.3406  lr: 6.5321e-06  max_mem: 17674M
[01/19 08:27:13] d2.utils.events INFO:  eta: 11:40:28  iter: 15099  total_loss: 63.18  loss_ce: 2.139  loss_mask: 0.6314  loss_dice: 3.288  loss_ce_0: 3.567  loss_mask_0: 0.6696  loss_dice_0: 3.569  loss_ce_1: 2.38  loss_mask_1: 0.6516  loss_dice_1: 3.44  loss_ce_2: 2.254  loss_mask_2: 0.6391  loss_dice_2: 3.365  loss_ce_3: 2.215  loss_mask_3: 0.6344  loss_dice_3: 3.318  loss_ce_4: 2.174  loss_mask_4: 0.634  loss_dice_4: 3.318  loss_ce_5: 2.159  loss_mask_5: 0.6353  loss_dice_5: 3.312  loss_ce_6: 2.157  loss_mask_6: 0.6333  loss_dice_6: 3.3  loss_ce_7: 2.134  loss_mask_7: 0.6321  loss_dice_7: 3.302  loss_ce_8: 2.142  loss_mask_8: 0.633  loss_dice_8: 3.293  time: 1.6944  data_time: 0.3325  lr: 6.5274e-06  max_mem: 17674M
[01/19 08:27:47] d2.utils.events INFO:  eta: 11:39:52  iter: 15119  total_loss: 62.03  loss_ce: 1.93  loss_mask: 0.6299  loss_dice: 3.334  loss_ce_0: 3.507  loss_mask_0: 0.642  loss_dice_0: 3.602  loss_ce_1: 2.169  loss_mask_1: 0.634  loss_dice_1: 3.483  loss_ce_2: 2.071  loss_mask_2: 0.6307  loss_dice_2: 3.407  loss_ce_3: 2.007  loss_mask_3: 0.6301  loss_dice_3: 3.355  loss_ce_4: 1.97  loss_mask_4: 0.6324  loss_dice_4: 3.349  loss_ce_5: 1.942  loss_mask_5: 0.6285  loss_dice_5: 3.347  loss_ce_6: 1.951  loss_mask_6: 0.6321  loss_dice_6: 3.342  loss_ce_7: 1.928  loss_mask_7: 0.6298  loss_dice_7: 3.336  loss_ce_8: 1.93  loss_mask_8: 0.6307  loss_dice_8: 3.341  time: 1.6944  data_time: 0.3361  lr: 6.5227e-06  max_mem: 17674M
[01/19 08:28:20] d2.utils.events INFO:  eta: 11:38:39  iter: 15139  total_loss: 62.82  loss_ce: 2.077  loss_mask: 0.6357  loss_dice: 3.267  loss_ce_0: 3.504  loss_mask_0: 0.6509  loss_dice_0: 3.554  loss_ce_1: 2.338  loss_mask_1: 0.645  loss_dice_1: 3.412  loss_ce_2: 2.193  loss_mask_2: 0.6382  loss_dice_2: 3.335  loss_ce_3: 2.144  loss_mask_3: 0.635  loss_dice_3: 3.291  loss_ce_4: 2.118  loss_mask_4: 0.6349  loss_dice_4: 3.278  loss_ce_5: 2.084  loss_mask_5: 0.6382  loss_dice_5: 3.28  loss_ce_6: 2.093  loss_mask_6: 0.6367  loss_dice_6: 3.264  loss_ce_7: 2.08  loss_mask_7: 0.6367  loss_dice_7: 3.267  loss_ce_8: 2.08  loss_mask_8: 0.6366  loss_dice_8: 3.27  time: 1.6943  data_time: 0.3393  lr: 6.518e-06  max_mem: 17674M
[01/19 08:28:53] d2.utils.events INFO:  eta: 11:37:57  iter: 15159  total_loss: 63.58  loss_ce: 2.221  loss_mask: 0.6327  loss_dice: 3.297  loss_ce_0: 3.644  loss_mask_0: 0.6574  loss_dice_0: 3.564  loss_ce_1: 2.365  loss_mask_1: 0.6481  loss_dice_1: 3.452  loss_ce_2: 2.277  loss_mask_2: 0.6384  loss_dice_2: 3.371  loss_ce_3: 2.253  loss_mask_3: 0.637  loss_dice_3: 3.322  loss_ce_4: 2.245  loss_mask_4: 0.6359  loss_dice_4: 3.319  loss_ce_5: 2.211  loss_mask_5: 0.6347  loss_dice_5: 3.312  loss_ce_6: 2.231  loss_mask_6: 0.6347  loss_dice_6: 3.303  loss_ce_7: 2.221  loss_mask_7: 0.6343  loss_dice_7: 3.303  loss_ce_8: 2.204  loss_mask_8: 0.6346  loss_dice_8: 3.301  time: 1.6943  data_time: 0.3423  lr: 6.5133e-06  max_mem: 17674M
[01/19 08:29:28] d2.utils.events INFO:  eta: 11:38:00  iter: 15179  total_loss: 62.7  loss_ce: 2.124  loss_mask: 0.6187  loss_dice: 3.314  loss_ce_0: 3.531  loss_mask_0: 0.6503  loss_dice_0: 3.601  loss_ce_1: 2.336  loss_mask_1: 0.6332  loss_dice_1: 3.456  loss_ce_2: 2.212  loss_mask_2: 0.6247  loss_dice_2: 3.391  loss_ce_3: 2.17  loss_mask_3: 0.6197  loss_dice_3: 3.34  loss_ce_4: 2.144  loss_mask_4: 0.6187  loss_dice_4: 3.336  loss_ce_5: 2.117  loss_mask_5: 0.6184  loss_dice_5: 3.339  loss_ce_6: 2.143  loss_mask_6: 0.6181  loss_dice_6: 3.319  loss_ce_7: 2.117  loss_mask_7: 0.6179  loss_dice_7: 3.317  loss_ce_8: 2.106  loss_mask_8: 0.6206  loss_dice_8: 3.319  time: 1.6943  data_time: 0.3515  lr: 6.5085e-06  max_mem: 17674M
[01/19 08:30:01] d2.utils.events INFO:  eta: 11:37:00  iter: 15199  total_loss: 63.18  loss_ce: 2.105  loss_mask: 0.6236  loss_dice: 3.318  loss_ce_0: 3.57  loss_mask_0: 0.6476  loss_dice_0: 3.599  loss_ce_1: 2.309  loss_mask_1: 0.6416  loss_dice_1: 3.462  loss_ce_2: 2.227  loss_mask_2: 0.6309  loss_dice_2: 3.398  loss_ce_3: 2.174  loss_mask_3: 0.6248  loss_dice_3: 3.347  loss_ce_4: 2.143  loss_mask_4: 0.6235  loss_dice_4: 3.337  loss_ce_5: 2.139  loss_mask_5: 0.6251  loss_dice_5: 3.337  loss_ce_6: 2.136  loss_mask_6: 0.6219  loss_dice_6: 3.32  loss_ce_7: 2.106  loss_mask_7: 0.6221  loss_dice_7: 3.323  loss_ce_8: 2.112  loss_mask_8: 0.6214  loss_dice_8: 3.321  time: 1.6943  data_time: 0.3493  lr: 6.5038e-06  max_mem: 17674M
[01/19 08:30:35] d2.utils.events INFO:  eta: 11:36:07  iter: 15219  total_loss: 62.92  loss_ce: 2.11  loss_mask: 0.6289  loss_dice: 3.308  loss_ce_0: 3.564  loss_mask_0: 0.6602  loss_dice_0: 3.582  loss_ce_1: 2.31  loss_mask_1: 0.6375  loss_dice_1: 3.457  loss_ce_2: 2.203  loss_mask_2: 0.6357  loss_dice_2: 3.379  loss_ce_3: 2.17  loss_mask_3: 0.6329  loss_dice_3: 3.332  loss_ce_4: 2.141  loss_mask_4: 0.6347  loss_dice_4: 3.326  loss_ce_5: 2.114  loss_mask_5: 0.6346  loss_dice_5: 3.322  loss_ce_6: 2.112  loss_mask_6: 0.6296  loss_dice_6: 3.311  loss_ce_7: 2.103  loss_mask_7: 0.6303  loss_dice_7: 3.31  loss_ce_8: 2.071  loss_mask_8: 0.6314  loss_dice_8: 3.312  time: 1.6943  data_time: 0.3354  lr: 6.4991e-06  max_mem: 17674M
[01/19 08:31:09] d2.utils.events INFO:  eta: 11:35:34  iter: 15239  total_loss: 62.41  loss_ce: 2.042  loss_mask: 0.6165  loss_dice: 3.331  loss_ce_0: 3.513  loss_mask_0: 0.6341  loss_dice_0: 3.61  loss_ce_1: 2.227  loss_mask_1: 0.6276  loss_dice_1: 3.484  loss_ce_2: 2.136  loss_mask_2: 0.6201  loss_dice_2: 3.402  loss_ce_3: 2.111  loss_mask_3: 0.6119  loss_dice_3: 3.356  loss_ce_4: 2.092  loss_mask_4: 0.6131  loss_dice_4: 3.347  loss_ce_5: 2.072  loss_mask_5: 0.6139  loss_dice_5: 3.349  loss_ce_6: 2.05  loss_mask_6: 0.6116  loss_dice_6: 3.337  loss_ce_7: 2.048  loss_mask_7: 0.6146  loss_dice_7: 3.332  loss_ce_8: 2.047  loss_mask_8: 0.6153  loss_dice_8: 3.336  time: 1.6943  data_time: 0.3409  lr: 6.4944e-06  max_mem: 17674M
[01/19 08:31:43] d2.utils.events INFO:  eta: 11:35:25  iter: 15259  total_loss: 62.28  loss_ce: 2.102  loss_mask: 0.6247  loss_dice: 3.258  loss_ce_0: 3.567  loss_mask_0: 0.6403  loss_dice_0: 3.567  loss_ce_1: 2.2  loss_mask_1: 0.6345  loss_dice_1: 3.43  loss_ce_2: 2.109  loss_mask_2: 0.6332  loss_dice_2: 3.352  loss_ce_3: 2.089  loss_mask_3: 0.6235  loss_dice_3: 3.301  loss_ce_4: 2.076  loss_mask_4: 0.6203  loss_dice_4: 3.29  loss_ce_5: 2.068  loss_mask_5: 0.6226  loss_dice_5: 3.289  loss_ce_6: 2.109  loss_mask_6: 0.6212  loss_dice_6: 3.264  loss_ce_7: 2.082  loss_mask_7: 0.621  loss_dice_7: 3.268  loss_ce_8: 2.058  loss_mask_8: 0.6241  loss_dice_8: 3.265  time: 1.6943  data_time: 0.3465  lr: 6.4897e-06  max_mem: 17674M
[01/19 08:32:17] d2.utils.events INFO:  eta: 11:35:12  iter: 15279  total_loss: 64.12  loss_ce: 2.244  loss_mask: 0.617  loss_dice: 3.361  loss_ce_0: 3.602  loss_mask_0: 0.6367  loss_dice_0: 3.612  loss_ce_1: 2.399  loss_mask_1: 0.626  loss_dice_1: 3.499  loss_ce_2: 2.312  loss_mask_2: 0.6274  loss_dice_2: 3.429  loss_ce_3: 2.303  loss_mask_3: 0.621  loss_dice_3: 3.388  loss_ce_4: 2.286  loss_mask_4: 0.6243  loss_dice_4: 3.376  loss_ce_5: 2.267  loss_mask_5: 0.6247  loss_dice_5: 3.379  loss_ce_6: 2.25  loss_mask_6: 0.6214  loss_dice_6: 3.368  loss_ce_7: 2.252  loss_mask_7: 0.6183  loss_dice_7: 3.365  loss_ce_8: 2.231  loss_mask_8: 0.6196  loss_dice_8: 3.366  time: 1.6943  data_time: 0.3503  lr: 6.4849e-06  max_mem: 17674M
[01/19 08:32:51] d2.utils.events INFO:  eta: 11:34:51  iter: 15299  total_loss: 62.59  loss_ce: 2.119  loss_mask: 0.6245  loss_dice: 3.291  loss_ce_0: 3.567  loss_mask_0: 0.6448  loss_dice_0: 3.564  loss_ce_1: 2.321  loss_mask_1: 0.6351  loss_dice_1: 3.426  loss_ce_2: 2.198  loss_mask_2: 0.6317  loss_dice_2: 3.365  loss_ce_3: 2.163  loss_mask_3: 0.6287  loss_dice_3: 3.321  loss_ce_4: 2.147  loss_mask_4: 0.6281  loss_dice_4: 3.312  loss_ce_5: 2.114  loss_mask_5: 0.6294  loss_dice_5: 3.313  loss_ce_6: 2.107  loss_mask_6: 0.6295  loss_dice_6: 3.291  loss_ce_7: 2.093  loss_mask_7: 0.6307  loss_dice_7: 3.288  loss_ce_8: 2.121  loss_mask_8: 0.6261  loss_dice_8: 3.293  time: 1.6943  data_time: 0.3483  lr: 6.4802e-06  max_mem: 17674M
[01/19 08:33:25] d2.utils.events INFO:  eta: 11:34:31  iter: 15319  total_loss: 62.13  loss_ce: 2.021  loss_mask: 0.6213  loss_dice: 3.293  loss_ce_0: 3.543  loss_mask_0: 0.6367  loss_dice_0: 3.587  loss_ce_1: 2.224  loss_mask_1: 0.6282  loss_dice_1: 3.446  loss_ce_2: 2.083  loss_mask_2: 0.625  loss_dice_2: 3.369  loss_ce_3: 2.065  loss_mask_3: 0.6192  loss_dice_3: 3.323  loss_ce_4: 2.041  loss_mask_4: 0.6175  loss_dice_4: 3.318  loss_ce_5: 2.018  loss_mask_5: 0.6205  loss_dice_5: 3.315  loss_ce_6: 2.028  loss_mask_6: 0.6174  loss_dice_6: 3.296  loss_ce_7: 2.016  loss_mask_7: 0.6195  loss_dice_7: 3.296  loss_ce_8: 2.015  loss_mask_8: 0.6186  loss_dice_8: 3.298  time: 1.6943  data_time: 0.3372  lr: 6.4755e-06  max_mem: 17674M
[01/19 08:33:59] d2.utils.events INFO:  eta: 11:33:46  iter: 15339  total_loss: 62.95  loss_ce: 2.091  loss_mask: 0.6158  loss_dice: 3.332  loss_ce_0: 3.647  loss_mask_0: 0.6386  loss_dice_0: 3.587  loss_ce_1: 2.253  loss_mask_1: 0.6278  loss_dice_1: 3.468  loss_ce_2: 2.178  loss_mask_2: 0.6224  loss_dice_2: 3.395  loss_ce_3: 2.158  loss_mask_3: 0.6151  loss_dice_3: 3.361  loss_ce_4: 2.127  loss_mask_4: 0.6158  loss_dice_4: 3.349  loss_ce_5: 2.121  loss_mask_5: 0.6148  loss_dice_5: 3.349  loss_ce_6: 2.095  loss_mask_6: 0.615  loss_dice_6: 3.339  loss_ce_7: 2.086  loss_mask_7: 0.6126  loss_dice_7: 3.337  loss_ce_8: 2.088  loss_mask_8: 0.617  loss_dice_8: 3.334  time: 1.6943  data_time: 0.3534  lr: 6.4708e-06  max_mem: 17674M
[01/19 08:34:33] d2.utils.events INFO:  eta: 11:33:11  iter: 15359  total_loss: 62.61  loss_ce: 2.092  loss_mask: 0.6372  loss_dice: 3.299  loss_ce_0: 3.518  loss_mask_0: 0.6676  loss_dice_0: 3.591  loss_ce_1: 2.295  loss_mask_1: 0.6472  loss_dice_1: 3.459  loss_ce_2: 2.188  loss_mask_2: 0.6367  loss_dice_2: 3.371  loss_ce_3: 2.154  loss_mask_3: 0.6363  loss_dice_3: 3.32  loss_ce_4: 2.112  loss_mask_4: 0.6369  loss_dice_4: 3.315  loss_ce_5: 2.108  loss_mask_5: 0.6395  loss_dice_5: 3.306  loss_ce_6: 2.105  loss_mask_6: 0.636  loss_dice_6: 3.299  loss_ce_7: 2.082  loss_mask_7: 0.6367  loss_dice_7: 3.302  loss_ce_8: 2.092  loss_mask_8: 0.6365  loss_dice_8: 3.3  time: 1.6943  data_time: 0.3498  lr: 6.466e-06  max_mem: 17674M
[01/19 08:35:06] d2.utils.events INFO:  eta: 11:32:37  iter: 15379  total_loss: 62.93  loss_ce: 2.166  loss_mask: 0.641  loss_dice: 3.284  loss_ce_0: 3.565  loss_mask_0: 0.6686  loss_dice_0: 3.563  loss_ce_1: 2.32  loss_mask_1: 0.6539  loss_dice_1: 3.425  loss_ce_2: 2.246  loss_mask_2: 0.6511  loss_dice_2: 3.358  loss_ce_3: 2.206  loss_mask_3: 0.6456  loss_dice_3: 3.299  loss_ce_4: 2.169  loss_mask_4: 0.647  loss_dice_4: 3.298  loss_ce_5: 2.159  loss_mask_5: 0.6451  loss_dice_5: 3.297  loss_ce_6: 2.172  loss_mask_6: 0.6423  loss_dice_6: 3.292  loss_ce_7: 2.167  loss_mask_7: 0.6426  loss_dice_7: 3.285  loss_ce_8: 2.163  loss_mask_8: 0.6434  loss_dice_8: 3.284  time: 1.6942  data_time: 0.3419  lr: 6.4613e-06  max_mem: 17674M
[01/19 08:35:40] d2.utils.events INFO:  eta: 11:32:08  iter: 15399  total_loss: 61.77  loss_ce: 1.961  loss_mask: 0.633  loss_dice: 3.282  loss_ce_0: 3.461  loss_mask_0: 0.6624  loss_dice_0: 3.562  loss_ce_1: 2.196  loss_mask_1: 0.6424  loss_dice_1: 3.446  loss_ce_2: 2.058  loss_mask_2: 0.6367  loss_dice_2: 3.366  loss_ce_3: 2.024  loss_mask_3: 0.6337  loss_dice_3: 3.309  loss_ce_4: 1.989  loss_mask_4: 0.6332  loss_dice_4: 3.304  loss_ce_5: 1.975  loss_mask_5: 0.6344  loss_dice_5: 3.301  loss_ce_6: 1.976  loss_mask_6: 0.6338  loss_dice_6: 3.289  loss_ce_7: 1.98  loss_mask_7: 0.6338  loss_dice_7: 3.287  loss_ce_8: 1.958  loss_mask_8: 0.6353  loss_dice_8: 3.284  time: 1.6942  data_time: 0.3243  lr: 6.4566e-06  max_mem: 17674M
[01/19 08:36:14] d2.utils.events INFO:  eta: 11:31:52  iter: 15419  total_loss: 61.77  loss_ce: 2.05  loss_mask: 0.609  loss_dice: 3.302  loss_ce_0: 3.599  loss_mask_0: 0.6237  loss_dice_0: 3.584  loss_ce_1: 2.248  loss_mask_1: 0.6223  loss_dice_1: 3.444  loss_ce_2: 2.165  loss_mask_2: 0.6232  loss_dice_2: 3.372  loss_ce_3: 2.118  loss_mask_3: 0.6143  loss_dice_3: 3.326  loss_ce_4: 2.081  loss_mask_4: 0.6119  loss_dice_4: 3.328  loss_ce_5: 2.071  loss_mask_5: 0.6123  loss_dice_5: 3.324  loss_ce_6: 2.078  loss_mask_6: 0.6078  loss_dice_6: 3.31  loss_ce_7: 2.051  loss_mask_7: 0.6104  loss_dice_7: 3.308  loss_ce_8: 2.046  loss_mask_8: 0.6083  loss_dice_8: 3.309  time: 1.6942  data_time: 0.3419  lr: 6.4519e-06  max_mem: 17674M
[01/19 08:36:48] d2.utils.events INFO:  eta: 11:31:10  iter: 15439  total_loss: 63.25  loss_ce: 2.088  loss_mask: 0.6273  loss_dice: 3.353  loss_ce_0: 3.536  loss_mask_0: 0.6587  loss_dice_0: 3.607  loss_ce_1: 2.262  loss_mask_1: 0.6358  loss_dice_1: 3.485  loss_ce_2: 2.18  loss_mask_2: 0.6327  loss_dice_2: 3.412  loss_ce_3: 2.152  loss_mask_3: 0.6296  loss_dice_3: 3.368  loss_ce_4: 2.135  loss_mask_4: 0.6291  loss_dice_4: 3.363  loss_ce_5: 2.116  loss_mask_5: 0.6312  loss_dice_5: 3.368  loss_ce_6: 2.105  loss_mask_6: 0.6275  loss_dice_6: 3.35  loss_ce_7: 2.083  loss_mask_7: 0.6301  loss_dice_7: 3.36  loss_ce_8: 2.095  loss_mask_8: 0.6289  loss_dice_8: 3.35  time: 1.6942  data_time: 0.3461  lr: 6.4471e-06  max_mem: 17674M
[01/19 08:37:21] d2.utils.events INFO:  eta: 11:30:08  iter: 15459  total_loss: 61.24  loss_ce: 2.037  loss_mask: 0.6372  loss_dice: 3.249  loss_ce_0: 3.54  loss_mask_0: 0.6457  loss_dice_0: 3.522  loss_ce_1: 2.275  loss_mask_1: 0.6451  loss_dice_1: 3.41  loss_ce_2: 2.13  loss_mask_2: 0.6408  loss_dice_2: 3.332  loss_ce_3: 2.088  loss_mask_3: 0.638  loss_dice_3: 3.287  loss_ce_4: 2.06  loss_mask_4: 0.6396  loss_dice_4: 3.275  loss_ce_5: 2.038  loss_mask_5: 0.6359  loss_dice_5: 3.274  loss_ce_6: 2.059  loss_mask_6: 0.6379  loss_dice_6: 3.262  loss_ce_7: 2.027  loss_mask_7: 0.6384  loss_dice_7: 3.264  loss_ce_8: 2.039  loss_mask_8: 0.6377  loss_dice_8: 3.265  time: 1.6942  data_time: 0.3218  lr: 6.4424e-06  max_mem: 17674M
[01/19 08:37:54] d2.utils.events INFO:  eta: 11:29:30  iter: 15479  total_loss: 62.6  loss_ce: 2.119  loss_mask: 0.6385  loss_dice: 3.252  loss_ce_0: 3.527  loss_mask_0: 0.6555  loss_dice_0: 3.529  loss_ce_1: 2.303  loss_mask_1: 0.6463  loss_dice_1: 3.407  loss_ce_2: 2.236  loss_mask_2: 0.6454  loss_dice_2: 3.324  loss_ce_3: 2.176  loss_mask_3: 0.6412  loss_dice_3: 3.282  loss_ce_4: 2.147  loss_mask_4: 0.639  loss_dice_4: 3.277  loss_ce_5: 2.122  loss_mask_5: 0.642  loss_dice_5: 3.265  loss_ce_6: 2.135  loss_mask_6: 0.6425  loss_dice_6: 3.247  loss_ce_7: 2.116  loss_mask_7: 0.6389  loss_dice_7: 3.254  loss_ce_8: 2.118  loss_mask_8: 0.6393  loss_dice_8: 3.258  time: 1.6942  data_time: 0.3418  lr: 6.4377e-06  max_mem: 17674M
[01/19 08:38:29] d2.utils.events INFO:  eta: 11:28:52  iter: 15499  total_loss: 62.36  loss_ce: 2.066  loss_mask: 0.6125  loss_dice: 3.36  loss_ce_0: 3.504  loss_mask_0: 0.6335  loss_dice_0: 3.625  loss_ce_1: 2.204  loss_mask_1: 0.6266  loss_dice_1: 3.492  loss_ce_2: 2.132  loss_mask_2: 0.6219  loss_dice_2: 3.437  loss_ce_3: 2.078  loss_mask_3: 0.6164  loss_dice_3: 3.376  loss_ce_4: 2.068  loss_mask_4: 0.6151  loss_dice_4: 3.375  loss_ce_5: 2.059  loss_mask_5: 0.6138  loss_dice_5: 3.374  loss_ce_6: 2.065  loss_mask_6: 0.6125  loss_dice_6: 3.358  loss_ce_7: 2.054  loss_mask_7: 0.6132  loss_dice_7: 3.355  loss_ce_8: 2.07  loss_mask_8: 0.6131  loss_dice_8: 3.356  time: 1.6942  data_time: 0.3466  lr: 6.433e-06  max_mem: 17674M
[01/19 08:39:03] d2.utils.events INFO:  eta: 11:28:18  iter: 15519  total_loss: 62.29  loss_ce: 2.04  loss_mask: 0.6247  loss_dice: 3.314  loss_ce_0: 3.55  loss_mask_0: 0.6471  loss_dice_0: 3.579  loss_ce_1: 2.274  loss_mask_1: 0.6295  loss_dice_1: 3.465  loss_ce_2: 2.159  loss_mask_2: 0.6184  loss_dice_2: 3.399  loss_ce_3: 2.115  loss_mask_3: 0.6199  loss_dice_3: 3.342  loss_ce_4: 2.09  loss_mask_4: 0.6219  loss_dice_4: 3.342  loss_ce_5: 2.065  loss_mask_5: 0.6195  loss_dice_5: 3.334  loss_ce_6: 2.049  loss_mask_6: 0.6225  loss_dice_6: 3.314  loss_ce_7: 2.03  loss_mask_7: 0.6232  loss_dice_7: 3.315  loss_ce_8: 2.028  loss_mask_8: 0.6264  loss_dice_8: 3.314  time: 1.6942  data_time: 0.3473  lr: 6.4282e-06  max_mem: 17674M
[01/19 08:39:36] d2.utils.events INFO:  eta: 11:27:25  iter: 15539  total_loss: 62.78  loss_ce: 2.109  loss_mask: 0.6341  loss_dice: 3.322  loss_ce_0: 3.564  loss_mask_0: 0.6598  loss_dice_0: 3.592  loss_ce_1: 2.335  loss_mask_1: 0.639  loss_dice_1: 3.466  loss_ce_2: 2.21  loss_mask_2: 0.6304  loss_dice_2: 3.403  loss_ce_3: 2.178  loss_mask_3: 0.6342  loss_dice_3: 3.351  loss_ce_4: 2.123  loss_mask_4: 0.6343  loss_dice_4: 3.344  loss_ce_5: 2.114  loss_mask_5: 0.6371  loss_dice_5: 3.337  loss_ce_6: 2.089  loss_mask_6: 0.6336  loss_dice_6: 3.321  loss_ce_7: 2.092  loss_mask_7: 0.6318  loss_dice_7: 3.334  loss_ce_8: 2.089  loss_mask_8: 0.6295  loss_dice_8: 3.329  time: 1.6942  data_time: 0.3432  lr: 6.4235e-06  max_mem: 17674M
[01/19 08:40:10] d2.utils.events INFO:  eta: 11:26:46  iter: 15559  total_loss: 61.65  loss_ce: 1.962  loss_mask: 0.6246  loss_dice: 3.284  loss_ce_0: 3.553  loss_mask_0: 0.6555  loss_dice_0: 3.559  loss_ce_1: 2.251  loss_mask_1: 0.6353  loss_dice_1: 3.429  loss_ce_2: 2.128  loss_mask_2: 0.6267  loss_dice_2: 3.357  loss_ce_3: 2.069  loss_mask_3: 0.6259  loss_dice_3: 3.314  loss_ce_4: 2.023  loss_mask_4: 0.6253  loss_dice_4: 3.305  loss_ce_5: 2.003  loss_mask_5: 0.6279  loss_dice_5: 3.305  loss_ce_6: 1.977  loss_mask_6: 0.625  loss_dice_6: 3.292  loss_ce_7: 1.968  loss_mask_7: 0.6252  loss_dice_7: 3.288  loss_ce_8: 1.963  loss_mask_8: 0.6239  loss_dice_8: 3.281  time: 1.6941  data_time: 0.3398  lr: 6.4188e-06  max_mem: 17674M
[01/19 08:40:43] d2.utils.events INFO:  eta: 11:26:13  iter: 15579  total_loss: 60.93  loss_ce: 1.907  loss_mask: 0.6143  loss_dice: 3.278  loss_ce_0: 3.493  loss_mask_0: 0.634  loss_dice_0: 3.604  loss_ce_1: 2.179  loss_mask_1: 0.62  loss_dice_1: 3.443  loss_ce_2: 2.046  loss_mask_2: 0.6137  loss_dice_2: 3.366  loss_ce_3: 1.99  loss_mask_3: 0.613  loss_dice_3: 3.307  loss_ce_4: 1.944  loss_mask_4: 0.614  loss_dice_4: 3.304  loss_ce_5: 1.927  loss_mask_5: 0.6142  loss_dice_5: 3.294  loss_ce_6: 1.919  loss_mask_6: 0.6165  loss_dice_6: 3.29  loss_ce_7: 1.914  loss_mask_7: 0.6161  loss_dice_7: 3.284  loss_ce_8: 1.915  loss_mask_8: 0.6179  loss_dice_8: 3.285  time: 1.6941  data_time: 0.3384  lr: 6.4141e-06  max_mem: 17674M
[01/19 08:41:18] d2.utils.events INFO:  eta: 11:26:08  iter: 15599  total_loss: 62.37  loss_ce: 2.057  loss_mask: 0.618  loss_dice: 3.301  loss_ce_0: 3.531  loss_mask_0: 0.6405  loss_dice_0: 3.591  loss_ce_1: 2.308  loss_mask_1: 0.6227  loss_dice_1: 3.452  loss_ce_2: 2.185  loss_mask_2: 0.6199  loss_dice_2: 3.378  loss_ce_3: 2.135  loss_mask_3: 0.6208  loss_dice_3: 3.328  loss_ce_4: 2.089  loss_mask_4: 0.6212  loss_dice_4: 3.325  loss_ce_5: 2.08  loss_mask_5: 0.6198  loss_dice_5: 3.325  loss_ce_6: 2.073  loss_mask_6: 0.619  loss_dice_6: 3.31  loss_ce_7: 2.056  loss_mask_7: 0.6161  loss_dice_7: 3.304  loss_ce_8: 2.056  loss_mask_8: 0.6179  loss_dice_8: 3.307  time: 1.6941  data_time: 0.3618  lr: 6.4093e-06  max_mem: 17674M
[01/19 08:41:52] d2.utils.events INFO:  eta: 11:25:32  iter: 15619  total_loss: 62.32  loss_ce: 2.039  loss_mask: 0.6142  loss_dice: 3.293  loss_ce_0: 3.575  loss_mask_0: 0.6435  loss_dice_0: 3.577  loss_ce_1: 2.261  loss_mask_1: 0.6369  loss_dice_1: 3.433  loss_ce_2: 2.157  loss_mask_2: 0.6198  loss_dice_2: 3.367  loss_ce_3: 2.109  loss_mask_3: 0.6142  loss_dice_3: 3.317  loss_ce_4: 2.074  loss_mask_4: 0.6153  loss_dice_4: 3.313  loss_ce_5: 2.056  loss_mask_5: 0.6151  loss_dice_5: 3.318  loss_ce_6: 2.045  loss_mask_6: 0.6102  loss_dice_6: 3.3  loss_ce_7: 2.038  loss_mask_7: 0.6131  loss_dice_7: 3.297  loss_ce_8: 2.05  loss_mask_8: 0.6147  loss_dice_8: 3.306  time: 1.6941  data_time: 0.3458  lr: 6.4046e-06  max_mem: 17674M
[01/19 08:42:26] d2.utils.events INFO:  eta: 11:25:09  iter: 15639  total_loss: 63.55  loss_ce: 2.13  loss_mask: 0.6308  loss_dice: 3.368  loss_ce_0: 3.654  loss_mask_0: 0.6521  loss_dice_0: 3.609  loss_ce_1: 2.273  loss_mask_1: 0.6471  loss_dice_1: 3.511  loss_ce_2: 2.191  loss_mask_2: 0.6366  loss_dice_2: 3.434  loss_ce_3: 2.188  loss_mask_3: 0.6353  loss_dice_3: 3.388  loss_ce_4: 2.125  loss_mask_4: 0.6322  loss_dice_4: 3.386  loss_ce_5: 2.127  loss_mask_5: 0.6348  loss_dice_5: 3.384  loss_ce_6: 2.131  loss_mask_6: 0.6322  loss_dice_6: 3.374  loss_ce_7: 2.13  loss_mask_7: 0.6315  loss_dice_7: 3.375  loss_ce_8: 2.13  loss_mask_8: 0.6327  loss_dice_8: 3.368  time: 1.6942  data_time: 0.3631  lr: 6.3999e-06  max_mem: 17674M
[01/19 08:43:00] d2.utils.events INFO:  eta: 11:24:35  iter: 15659  total_loss: 62.18  loss_ce: 2.075  loss_mask: 0.6158  loss_dice: 3.33  loss_ce_0: 3.525  loss_mask_0: 0.6364  loss_dice_0: 3.593  loss_ce_1: 2.263  loss_mask_1: 0.6294  loss_dice_1: 3.463  loss_ce_2: 2.137  loss_mask_2: 0.6208  loss_dice_2: 3.397  loss_ce_3: 2.111  loss_mask_3: 0.6198  loss_dice_3: 3.362  loss_ce_4: 2.082  loss_mask_4: 0.6173  loss_dice_4: 3.354  loss_ce_5: 2.067  loss_mask_5: 0.6186  loss_dice_5: 3.348  loss_ce_6: 2.078  loss_mask_6: 0.6151  loss_dice_6: 3.339  loss_ce_7: 2.066  loss_mask_7: 0.6144  loss_dice_7: 3.336  loss_ce_8: 2.078  loss_mask_8: 0.6171  loss_dice_8: 3.335  time: 1.6942  data_time: 0.3499  lr: 6.3951e-06  max_mem: 17674M
[01/19 08:43:34] d2.utils.events INFO:  eta: 11:24:10  iter: 15679  total_loss: 62.18  loss_ce: 2.08  loss_mask: 0.639  loss_dice: 3.253  loss_ce_0: 3.516  loss_mask_0: 0.6632  loss_dice_0: 3.549  loss_ce_1: 2.307  loss_mask_1: 0.6499  loss_dice_1: 3.414  loss_ce_2: 2.201  loss_mask_2: 0.6424  loss_dice_2: 3.333  loss_ce_3: 2.159  loss_mask_3: 0.6372  loss_dice_3: 3.288  loss_ce_4: 2.113  loss_mask_4: 0.6379  loss_dice_4: 3.28  loss_ce_5: 2.106  loss_mask_5: 0.6397  loss_dice_5: 3.276  loss_ce_6: 2.093  loss_mask_6: 0.6361  loss_dice_6: 3.255  loss_ce_7: 2.073  loss_mask_7: 0.6386  loss_dice_7: 3.256  loss_ce_8: 2.078  loss_mask_8: 0.638  loss_dice_8: 3.258  time: 1.6942  data_time: 0.3661  lr: 6.3904e-06  max_mem: 17674M
[01/19 08:44:09] d2.utils.events INFO:  eta: 11:23:38  iter: 15699  total_loss: 62.32  loss_ce: 2.042  loss_mask: 0.6302  loss_dice: 3.304  loss_ce_0: 3.594  loss_mask_0: 0.6336  loss_dice_0: 3.583  loss_ce_1: 2.241  loss_mask_1: 0.6369  loss_dice_1: 3.446  loss_ce_2: 2.13  loss_mask_2: 0.6307  loss_dice_2: 3.38  loss_ce_3: 2.083  loss_mask_3: 0.6318  loss_dice_3: 3.324  loss_ce_4: 2.071  loss_mask_4: 0.6341  loss_dice_4: 3.314  loss_ce_5: 2.067  loss_mask_5: 0.6322  loss_dice_5: 3.314  loss_ce_6: 2.035  loss_mask_6: 0.63  loss_dice_6: 3.303  loss_ce_7: 2.023  loss_mask_7: 0.6306  loss_dice_7: 3.308  loss_ce_8: 2.046  loss_mask_8: 0.6291  loss_dice_8: 3.302  time: 1.6942  data_time: 0.3552  lr: 6.3857e-06  max_mem: 17674M
[01/19 08:44:43] d2.utils.events INFO:  eta: 11:23:04  iter: 15719  total_loss: 61.85  loss_ce: 2.011  loss_mask: 0.6236  loss_dice: 3.323  loss_ce_0: 3.491  loss_mask_0: 0.6444  loss_dice_0: 3.596  loss_ce_1: 2.222  loss_mask_1: 0.6299  loss_dice_1: 3.454  loss_ce_2: 2.116  loss_mask_2: 0.626  loss_dice_2: 3.38  loss_ce_3: 2.074  loss_mask_3: 0.6238  loss_dice_3: 3.345  loss_ce_4: 2.049  loss_mask_4: 0.622  loss_dice_4: 3.346  loss_ce_5: 2.033  loss_mask_5: 0.6206  loss_dice_5: 3.334  loss_ce_6: 2.018  loss_mask_6: 0.6221  loss_dice_6: 3.328  loss_ce_7: 2.02  loss_mask_7: 0.6227  loss_dice_7: 3.325  loss_ce_8: 2.012  loss_mask_8: 0.6233  loss_dice_8: 3.323  time: 1.6942  data_time: 0.3314  lr: 6.381e-06  max_mem: 17674M
[01/19 08:45:16] d2.utils.events INFO:  eta: 11:22:29  iter: 15739  total_loss: 61.94  loss_ce: 2.081  loss_mask: 0.6362  loss_dice: 3.263  loss_ce_0: 3.554  loss_mask_0: 0.6475  loss_dice_0: 3.557  loss_ce_1: 2.271  loss_mask_1: 0.6349  loss_dice_1: 3.407  loss_ce_2: 2.184  loss_mask_2: 0.6307  loss_dice_2: 3.341  loss_ce_3: 2.15  loss_mask_3: 0.6297  loss_dice_3: 3.294  loss_ce_4: 2.121  loss_mask_4: 0.6292  loss_dice_4: 3.286  loss_ce_5: 2.085  loss_mask_5: 0.6358  loss_dice_5: 3.281  loss_ce_6: 2.078  loss_mask_6: 0.6353  loss_dice_6: 3.271  loss_ce_7: 2.068  loss_mask_7: 0.636  loss_dice_7: 3.267  loss_ce_8: 2.075  loss_mask_8: 0.6344  loss_dice_8: 3.264  time: 1.6942  data_time: 0.3107  lr: 6.3762e-06  max_mem: 17674M
[01/19 08:45:50] d2.utils.events INFO:  eta: 11:21:56  iter: 15759  total_loss: 62.32  loss_ce: 2.023  loss_mask: 0.6181  loss_dice: 3.313  loss_ce_0: 3.517  loss_mask_0: 0.6363  loss_dice_0: 3.583  loss_ce_1: 2.218  loss_mask_1: 0.6236  loss_dice_1: 3.462  loss_ce_2: 2.134  loss_mask_2: 0.6193  loss_dice_2: 3.385  loss_ce_3: 2.078  loss_mask_3: 0.6183  loss_dice_3: 3.341  loss_ce_4: 2.042  loss_mask_4: 0.6181  loss_dice_4: 3.334  loss_ce_5: 2.023  loss_mask_5: 0.62  loss_dice_5: 3.331  loss_ce_6: 2.043  loss_mask_6: 0.6192  loss_dice_6: 3.308  loss_ce_7: 2.016  loss_mask_7: 0.6186  loss_dice_7: 3.311  loss_ce_8: 2.021  loss_mask_8: 0.6177  loss_dice_8: 3.31  time: 1.6942  data_time: 0.3521  lr: 6.3715e-06  max_mem: 17674M
[01/19 08:46:24] d2.utils.events INFO:  eta: 11:21:23  iter: 15779  total_loss: 62.37  loss_ce: 2.091  loss_mask: 0.6466  loss_dice: 3.268  loss_ce_0: 3.489  loss_mask_0: 0.6655  loss_dice_0: 3.552  loss_ce_1: 2.3  loss_mask_1: 0.6541  loss_dice_1: 3.434  loss_ce_2: 2.194  loss_mask_2: 0.6483  loss_dice_2: 3.358  loss_ce_3: 2.136  loss_mask_3: 0.6445  loss_dice_3: 3.316  loss_ce_4: 2.116  loss_mask_4: 0.6444  loss_dice_4: 3.313  loss_ce_5: 2.098  loss_mask_5: 0.6452  loss_dice_5: 3.296  loss_ce_6: 2.105  loss_mask_6: 0.6453  loss_dice_6: 3.288  loss_ce_7: 2.099  loss_mask_7: 0.6472  loss_dice_7: 3.286  loss_ce_8: 2.091  loss_mask_8: 0.6489  loss_dice_8: 3.273  time: 1.6942  data_time: 0.3508  lr: 6.3668e-06  max_mem: 17674M
[01/19 08:46:57] d2.utils.events INFO:  eta: 11:20:30  iter: 15799  total_loss: 62.79  loss_ce: 2.108  loss_mask: 0.6318  loss_dice: 3.301  loss_ce_0: 3.5  loss_mask_0: 0.6568  loss_dice_0: 3.568  loss_ce_1: 2.28  loss_mask_1: 0.646  loss_dice_1: 3.46  loss_ce_2: 2.175  loss_mask_2: 0.6409  loss_dice_2: 3.389  loss_ce_3: 2.128  loss_mask_3: 0.6356  loss_dice_3: 3.337  loss_ce_4: 2.119  loss_mask_4: 0.6372  loss_dice_4: 3.327  loss_ce_5: 2.113  loss_mask_5: 0.6339  loss_dice_5: 3.317  loss_ce_6: 2.097  loss_mask_6: 0.6333  loss_dice_6: 3.297  loss_ce_7: 2.104  loss_mask_7: 0.6326  loss_dice_7: 3.304  loss_ce_8: 2.089  loss_mask_8: 0.6314  loss_dice_8: 3.304  time: 1.6942  data_time: 0.3319  lr: 6.362e-06  max_mem: 17674M
[01/19 08:47:31] d2.utils.events INFO:  eta: 11:19:49  iter: 15819  total_loss: 61.85  loss_ce: 1.964  loss_mask: 0.6166  loss_dice: 3.307  loss_ce_0: 3.487  loss_mask_0: 0.6439  loss_dice_0: 3.57  loss_ce_1: 2.17  loss_mask_1: 0.6322  loss_dice_1: 3.447  loss_ce_2: 2.061  loss_mask_2: 0.6269  loss_dice_2: 3.38  loss_ce_3: 2.025  loss_mask_3: 0.6202  loss_dice_3: 3.328  loss_ce_4: 1.991  loss_mask_4: 0.6182  loss_dice_4: 3.328  loss_ce_5: 1.974  loss_mask_5: 0.6182  loss_dice_5: 3.322  loss_ce_6: 1.98  loss_mask_6: 0.621  loss_dice_6: 3.313  loss_ce_7: 1.971  loss_mask_7: 0.618  loss_dice_7: 3.314  loss_ce_8: 1.963  loss_mask_8: 0.6191  loss_dice_8: 3.318  time: 1.6942  data_time: 0.3496  lr: 6.3573e-06  max_mem: 17674M
[01/19 08:48:05] d2.utils.events INFO:  eta: 11:19:08  iter: 15839  total_loss: 61.89  loss_ce: 2.054  loss_mask: 0.631  loss_dice: 3.295  loss_ce_0: 3.53  loss_mask_0: 0.6546  loss_dice_0: 3.573  loss_ce_1: 2.276  loss_mask_1: 0.6388  loss_dice_1: 3.439  loss_ce_2: 2.154  loss_mask_2: 0.6348  loss_dice_2: 3.361  loss_ce_3: 2.115  loss_mask_3: 0.6296  loss_dice_3: 3.313  loss_ce_4: 2.081  loss_mask_4: 0.6295  loss_dice_4: 3.307  loss_ce_5: 2.08  loss_mask_5: 0.6313  loss_dice_5: 3.315  loss_ce_6: 2.075  loss_mask_6: 0.6282  loss_dice_6: 3.302  loss_ce_7: 2.055  loss_mask_7: 0.6283  loss_dice_7: 3.305  loss_ce_8: 2.036  loss_mask_8: 0.6317  loss_dice_8: 3.302  time: 1.6942  data_time: 0.3364  lr: 6.3526e-06  max_mem: 17674M
[01/19 08:48:39] d2.utils.events INFO:  eta: 11:18:34  iter: 15859  total_loss: 62.97  loss_ce: 2.174  loss_mask: 0.6286  loss_dice: 3.31  loss_ce_0: 3.53  loss_mask_0: 0.662  loss_dice_0: 3.581  loss_ce_1: 2.356  loss_mask_1: 0.6498  loss_dice_1: 3.454  loss_ce_2: 2.231  loss_mask_2: 0.6401  loss_dice_2: 3.393  loss_ce_3: 2.247  loss_mask_3: 0.6287  loss_dice_3: 3.334  loss_ce_4: 2.207  loss_mask_4: 0.633  loss_dice_4: 3.328  loss_ce_5: 2.186  loss_mask_5: 0.6345  loss_dice_5: 3.328  loss_ce_6: 2.182  loss_mask_6: 0.6347  loss_dice_6: 3.307  loss_ce_7: 2.164  loss_mask_7: 0.6322  loss_dice_7: 3.313  loss_ce_8: 2.168  loss_mask_8: 0.6305  loss_dice_8: 3.312  time: 1.6942  data_time: 0.3415  lr: 6.3478e-06  max_mem: 17674M
[01/19 08:49:13] d2.utils.events INFO:  eta: 11:18:24  iter: 15879  total_loss: 62.02  loss_ce: 2.027  loss_mask: 0.6173  loss_dice: 3.315  loss_ce_0: 3.521  loss_mask_0: 0.6369  loss_dice_0: 3.582  loss_ce_1: 2.245  loss_mask_1: 0.629  loss_dice_1: 3.446  loss_ce_2: 2.13  loss_mask_2: 0.6234  loss_dice_2: 3.387  loss_ce_3: 2.08  loss_mask_3: 0.6223  loss_dice_3: 3.349  loss_ce_4: 2.064  loss_mask_4: 0.6215  loss_dice_4: 3.337  loss_ce_5: 2.018  loss_mask_5: 0.6217  loss_dice_5: 3.334  loss_ce_6: 2.034  loss_mask_6: 0.6193  loss_dice_6: 3.32  loss_ce_7: 2.021  loss_mask_7: 0.6184  loss_dice_7: 3.321  loss_ce_8: 2.007  loss_mask_8: 0.6212  loss_dice_8: 3.32  time: 1.6942  data_time: 0.3403  lr: 6.3431e-06  max_mem: 17674M
[01/19 08:49:47] d2.utils.events INFO:  eta: 11:17:41  iter: 15899  total_loss: 61.7  loss_ce: 2.025  loss_mask: 0.6319  loss_dice: 3.287  loss_ce_0: 3.448  loss_mask_0: 0.6408  loss_dice_0: 3.575  loss_ce_1: 2.187  loss_mask_1: 0.6392  loss_dice_1: 3.438  loss_ce_2: 2.084  loss_mask_2: 0.6297  loss_dice_2: 3.362  loss_ce_3: 2.073  loss_mask_3: 0.6277  loss_dice_3: 3.315  loss_ce_4: 2.06  loss_mask_4: 0.6271  loss_dice_4: 3.31  loss_ce_5: 2.041  loss_mask_5: 0.6303  loss_dice_5: 3.305  loss_ce_6: 2.031  loss_mask_6: 0.6307  loss_dice_6: 3.294  loss_ce_7: 2.035  loss_mask_7: 0.6292  loss_dice_7: 3.293  loss_ce_8: 2.03  loss_mask_8: 0.63  loss_dice_8: 3.292  time: 1.6942  data_time: 0.3480  lr: 6.3384e-06  max_mem: 17674M
[01/19 08:50:21] d2.utils.events INFO:  eta: 11:17:25  iter: 15919  total_loss: 63.17  loss_ce: 2.108  loss_mask: 0.6237  loss_dice: 3.305  loss_ce_0: 3.561  loss_mask_0: 0.6495  loss_dice_0: 3.574  loss_ce_1: 2.357  loss_mask_1: 0.6451  loss_dice_1: 3.446  loss_ce_2: 2.228  loss_mask_2: 0.6354  loss_dice_2: 3.369  loss_ce_3: 2.166  loss_mask_3: 0.63  loss_dice_3: 3.315  loss_ce_4: 2.144  loss_mask_4: 0.6278  loss_dice_4: 3.314  loss_ce_5: 2.11  loss_mask_5: 0.6292  loss_dice_5: 3.32  loss_ce_6: 2.112  loss_mask_6: 0.628  loss_dice_6: 3.309  loss_ce_7: 2.101  loss_mask_7: 0.6269  loss_dice_7: 3.313  loss_ce_8: 2.097  loss_mask_8: 0.6293  loss_dice_8: 3.304  time: 1.6942  data_time: 0.3398  lr: 6.3336e-06  max_mem: 17674M
[01/19 08:50:55] d2.utils.events INFO:  eta: 11:16:48  iter: 15939  total_loss: 61.86  loss_ce: 2.098  loss_mask: 0.6264  loss_dice: 3.284  loss_ce_0: 3.513  loss_mask_0: 0.6447  loss_dice_0: 3.583  loss_ce_1: 2.269  loss_mask_1: 0.6393  loss_dice_1: 3.429  loss_ce_2: 2.191  loss_mask_2: 0.6315  loss_dice_2: 3.352  loss_ce_3: 2.144  loss_mask_3: 0.6272  loss_dice_3: 3.309  loss_ce_4: 2.114  loss_mask_4: 0.6274  loss_dice_4: 3.309  loss_ce_5: 2.081  loss_mask_5: 0.6292  loss_dice_5: 3.299  loss_ce_6: 2.083  loss_mask_6: 0.627  loss_dice_6: 3.29  loss_ce_7: 2.072  loss_mask_7: 0.6257  loss_dice_7: 3.289  loss_ce_8: 2.075  loss_mask_8: 0.6278  loss_dice_8: 3.291  time: 1.6942  data_time: 0.3317  lr: 6.3289e-06  max_mem: 17674M
[01/19 08:51:29] d2.utils.events INFO:  eta: 11:16:07  iter: 15959  total_loss: 61.64  loss_ce: 2.02  loss_mask: 0.6102  loss_dice: 3.31  loss_ce_0: 3.487  loss_mask_0: 0.6315  loss_dice_0: 3.595  loss_ce_1: 2.26  loss_mask_1: 0.6144  loss_dice_1: 3.46  loss_ce_2: 2.123  loss_mask_2: 0.6104  loss_dice_2: 3.387  loss_ce_3: 2.103  loss_mask_3: 0.6096  loss_dice_3: 3.342  loss_ce_4: 2.068  loss_mask_4: 0.6086  loss_dice_4: 3.331  loss_ce_5: 2.042  loss_mask_5: 0.608  loss_dice_5: 3.33  loss_ce_6: 2.034  loss_mask_6: 0.6104  loss_dice_6: 3.313  loss_ce_7: 2.025  loss_mask_7: 0.6112  loss_dice_7: 3.321  loss_ce_8: 2.026  loss_mask_8: 0.6096  loss_dice_8: 3.31  time: 1.6942  data_time: 0.3435  lr: 6.3242e-06  max_mem: 17674M
[01/19 08:52:03] d2.utils.events INFO:  eta: 11:15:48  iter: 15979  total_loss: 62.51  loss_ce: 2.07  loss_mask: 0.6199  loss_dice: 3.32  loss_ce_0: 3.481  loss_mask_0: 0.6362  loss_dice_0: 3.61  loss_ce_1: 2.263  loss_mask_1: 0.6233  loss_dice_1: 3.464  loss_ce_2: 2.161  loss_mask_2: 0.6232  loss_dice_2: 3.391  loss_ce_3: 2.125  loss_mask_3: 0.62  loss_dice_3: 3.346  loss_ce_4: 2.104  loss_mask_4: 0.6205  loss_dice_4: 3.338  loss_ce_5: 2.074  loss_mask_5: 0.6209  loss_dice_5: 3.339  loss_ce_6: 2.081  loss_mask_6: 0.6206  loss_dice_6: 3.323  loss_ce_7: 2.064  loss_mask_7: 0.6185  loss_dice_7: 3.331  loss_ce_8: 2.051  loss_mask_8: 0.6206  loss_dice_8: 3.324  time: 1.6942  data_time: 0.3446  lr: 6.3194e-06  max_mem: 17674M
[01/19 08:52:37] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 08:52:37] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 08:52:37] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 08:58:08] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.0763584081554614, 'error_1pix': 0.4059317631668972, 'error_3pix': 0.169103878991261, 'mIoU': 7.328371001565108, 'fwIoU': 21.247732706766172, 'IoU-0': nan, 'IoU-1': 95.57346813726546, 'IoU-2': 12.154299933215093, 'IoU-3': 38.50700297764404, 'IoU-4': 24.461352666475843, 'IoU-5': 20.209018887904715, 'IoU-6': 20.56801760024157, 'IoU-7': 11.42486269037215, 'IoU-8': 5.781151116133483, 'IoU-9': 4.606767394268931, 'IoU-10': 17.62325984633833, 'IoU-11': 26.569217452592113, 'IoU-12': 28.395412935390397, 'IoU-13': 23.08923866079072, 'IoU-14': 23.237518838657234, 'IoU-15': 23.908531300707736, 'IoU-16': 22.16295548779573, 'IoU-17': 17.893684162240664, 'IoU-18': 20.023538949522514, 'IoU-19': 19.749448560944266, 'IoU-20': 13.985517900305581, 'IoU-21': 18.633184181589833, 'IoU-22': 17.39851033306863, 'IoU-23': 16.72030604898199, 'IoU-24': 14.597278738079677, 'IoU-25': 16.45264815567267, 'IoU-26': 14.454797200887793, 'IoU-27': 15.83447736684786, 'IoU-28': 15.514402595829868, 'IoU-29': 16.614758673152764, 'IoU-30': 13.525839285219105, 'IoU-31': 13.15601823712926, 'IoU-32': 12.953586091768344, 'IoU-33': 13.580465431466743, 'IoU-34': 11.351136146445777, 'IoU-35': 11.129279079360488, 'IoU-36': 12.710913399666634, 'IoU-37': 12.106200884921792, 'IoU-38': 10.739703830446777, 'IoU-39': 11.141610082095692, 'IoU-40': 12.683585293219362, 'IoU-41': 9.014316118388662, 'IoU-42': 9.505282698595801, 'IoU-43': 12.481594383439303, 'IoU-44': 7.160209290358813, 'IoU-45': 9.083567046947973, 'IoU-46': 10.88667761266141, 'IoU-47': 9.220737026990628, 'IoU-48': 7.977909566922698, 'IoU-49': 8.11347891503872, 'IoU-50': 9.0131358635767, 'IoU-51': 9.001331610963096, 'IoU-52': 7.381417998930874, 'IoU-53': 9.740058744353307, 'IoU-54': 7.9777206681545785, 'IoU-55': 10.008762524708082, 'IoU-56': 7.638098164498388, 'IoU-57': 8.091118820155895, 'IoU-58': 8.939195746655978, 'IoU-59': 6.9966689476523065, 'IoU-60': 9.634773548574374, 'IoU-61': 7.525487113695724, 'IoU-62': 8.235491457241825, 'IoU-63': 9.348893102512035, 'IoU-64': 7.647079950508916, 'IoU-65': 9.541674798615766, 'IoU-66': 6.872433175581684, 'IoU-67': 9.94275346143353, 'IoU-68': 7.709915751544061, 'IoU-69': 7.390973831942936, 'IoU-70': 8.857669826568445, 'IoU-71': 7.91546120339786, 'IoU-72': 6.000574300181874, 'IoU-73': 7.4998778065460385, 'IoU-74': 8.473405339879445, 'IoU-75': 8.45345529291622, 'IoU-76': 7.297103669909312, 'IoU-77': 6.068227273596632, 'IoU-78': 5.196091490458864, 'IoU-79': 9.06409659871777, 'IoU-80': 7.081025591999064, 'IoU-81': 6.526491828330501, 'IoU-82': 7.350005903552076, 'IoU-83': 4.872679786922142, 'IoU-84': 6.4705230624631085, 'IoU-85': 7.0025311399393635, 'IoU-86': 6.322892873848877, 'IoU-87': 6.427502521046683, 'IoU-88': 6.727214566292393, 'IoU-89': 4.98496940417514, 'IoU-90': 8.342303310109866, 'IoU-91': 7.016892183490846, 'IoU-92': 4.280886381985111, 'IoU-93': 3.4949103556324723, 'IoU-94': 7.467965290090321, 'IoU-95': 7.245750672347031, 'IoU-96': 5.516880911562674, 'IoU-97': 5.750638588342979, 'IoU-98': 5.583643952382171, 'IoU-99': 5.345988369673171, 'IoU-100': 5.736059967255123, 'IoU-101': 5.602182085842602, 'IoU-102': 5.2764571085873255, 'IoU-103': 7.0132470778043885, 'IoU-104': 4.724594166878795, 'IoU-105': 5.669259697030385, 'IoU-106': 5.237120243184234, 'IoU-107': 5.235154494020197, 'IoU-108': 3.294617641244814, 'IoU-109': 3.1714370212554894, 'IoU-110': 4.544370405958887, 'IoU-111': 5.33089170354545, 'IoU-112': 4.402640911656811, 'IoU-113': 2.6752310492183553, 'IoU-114': 4.605008403781216, 'IoU-115': 4.223812155278954, 'IoU-116': 2.1424867172886115, 'IoU-117': 3.9822177394423113, 'IoU-118': 2.609749138506863, 'IoU-119': 4.11769988147299, 'IoU-120': 2.4859418314910493, 'IoU-121': 3.454079947498969, 'IoU-122': 3.010859514554174, 'IoU-123': 2.9156954575669256, 'IoU-124': 3.2543981259526857, 'IoU-125': 2.324437822394658, 'IoU-126': 2.847049927660225, 'IoU-127': 3.1210970718997064, 'IoU-128': 2.7923639980818846, 'IoU-129': 2.7705929571640544, 'IoU-130': 1.9713328318957588, 'IoU-131': 1.89693112403224, 'IoU-132': 2.26916074130923, 'IoU-133': 2.502614716843362, 'IoU-134': 2.990345259118869, 'IoU-135': 1.804194411295522, 'IoU-136': 1.73957475207775, 'IoU-137': 0.8514033927205591, 'IoU-138': 0.3718929149532668, 'IoU-139': 2.402909641031038, 'IoU-140': 3.080921256989264, 'IoU-141': 1.7069579624499434, 'IoU-142': 1.0659806769421252, 'IoU-143': 1.8190000127842907, 'IoU-144': 1.2946344914420949, 'IoU-145': 2.947854659187861, 'IoU-146': 0.5451094348486628, 'IoU-147': 2.152549950432929, 'IoU-148': 1.9335292307283676, 'IoU-149': 2.3928880000350863, 'IoU-150': 2.5120649316362686, 'IoU-151': 1.29567761486381, 'IoU-152': 0.7726818611515467, 'IoU-153': 1.1185574656235109, 'IoU-154': 1.6561620409720015, 'IoU-155': 1.2028081169012141, 'IoU-156': 1.5063854199723947, 'IoU-157': 0.8510933554323777, 'IoU-158': 1.0811731392948511, 'IoU-159': 0.9162073335008526, 'IoU-160': 0.9737913549047784, 'IoU-161': 0.3991119214512844, 'IoU-162': 2.342415299102919, 'IoU-163': 0.19284017143006343, 'IoU-164': 1.3279732678188105, 'IoU-165': 1.474847006037217, 'IoU-166': 0.5280575823568501, 'IoU-167': 0.3237326411031668, 'IoU-168': 1.1382179708941043, 'IoU-169': 1.1799656937386487, 'IoU-170': 0.9960180560196309, 'IoU-171': 0.14099449739455366, 'IoU-172': 1.5557837136070858, 'IoU-173': 0.6844918426622093, 'IoU-174': 0.18000643925473758, 'IoU-175': 1.1127003420301325, 'IoU-176': 0.042561305304160114, 'IoU-177': 0.31032071330056915, 'IoU-178': 0.5134326640971063, 'IoU-179': 0.20977868897472038, 'IoU-180': 1.0765132498720051, 'IoU-181': 0.6436417061169282, 'IoU-182': 1.7446672986795289, 'IoU-183': 1.1260158331644283, 'IoU-184': 0.6937094830481448, 'IoU-185': 1.2131039212970889, 'IoU-186': 0.6876310272536688, 'IoU-187': 2.606848618550053, 'IoU-188': 0.999006883487288, 'IoU-189': 3.069439045989493, 'IoU-190': 1.7488900677190116, 'IoU-191': 2.2030285947148665, 'IoU-192': 2.442960403480093, 'mACC': 12.800417472101048, 'pACC': 30.14951669922684, 'ACC-0': nan, 'ACC-1': 98.51579389045396, 'ACC-2': 12.998812228572781, 'ACC-3': 56.479476650545, 'ACC-4': 33.46246733097593, 'ACC-5': 32.22619045740267, 'ACC-6': 32.89182994531222, 'ACC-7': 16.030388221009222, 'ACC-8': 6.7657931058988385, 'ACC-9': 4.885217232302754, 'ACC-10': 25.46806170833796, 'ACC-11': 41.32202022313952, 'ACC-12': 54.42287279028966, 'ACC-13': 36.98347323777547, 'ACC-14': 36.54491844736229, 'ACC-15': 42.70643214912369, 'ACC-16': 36.53868526226756, 'ACC-17': 26.845397458646158, 'ACC-18': 31.718534235938627, 'ACC-19': 36.48536564525425, 'ACC-20': 20.09312147989327, 'ACC-21': 31.578740214514156, 'ACC-22': 29.01447543341523, 'ACC-23': 29.598147900474736, 'ACC-24': 22.505722194105942, 'ACC-25': 33.9091714045247, 'ACC-26': 24.399007733927945, 'ACC-27': 25.86398465974596, 'ACC-28': 30.36005189878084, 'ACC-29': 27.889671405297662, 'ACC-30': 22.46991652008441, 'ACC-31': 19.7520140980314, 'ACC-32': 23.606024582116632, 'ACC-33': 26.335295974210066, 'ACC-34': 18.78032023512998, 'ACC-35': 17.97006944383412, 'ACC-36': 24.077029500375197, 'ACC-37': 22.656930490396704, 'ACC-38': 17.872734414938602, 'ACC-39': 19.336976283991227, 'ACC-40': 25.620268964215565, 'ACC-41': 14.351674475004003, 'ACC-42': 17.229915646015517, 'ACC-43': 29.08694752599901, 'ACC-44': 10.49660619403289, 'ACC-45': 15.653182245107772, 'ACC-46': 22.64229085948383, 'ACC-47': 17.420971531914763, 'ACC-48': 13.106984458826588, 'ACC-49': 13.959904823319421, 'ACC-50': 16.80123492035116, 'ACC-51': 17.26936088690783, 'ACC-52': 13.117214398150374, 'ACC-53': 20.07892138416887, 'ACC-54': 14.03844369934985, 'ACC-55': 20.700163285275604, 'ACC-56': 13.0944417538469, 'ACC-57': 15.65750072791653, 'ACC-58': 17.2566618097248, 'ACC-59': 12.639207777841147, 'ACC-60': 24.473724427048747, 'ACC-61': 12.696456045130134, 'ACC-62': 15.900821437859747, 'ACC-63': 19.419336857187968, 'ACC-64': 13.383067824800978, 'ACC-65': 21.15776994461115, 'ACC-66': 10.800547908019155, 'ACC-67': 24.600311527732252, 'ACC-68': 14.434395246487133, 'ACC-69': 12.337254406003408, 'ACC-70': 19.012837093370962, 'ACC-71': 15.121899854843715, 'ACC-72': 10.458300035547335, 'ACC-73': 14.6486692781524, 'ACC-74': 16.219482027086954, 'ACC-75': 19.742339247318284, 'ACC-76': 13.093455829742023, 'ACC-77': 11.983632652517642, 'ACC-78': 8.303224230678873, 'ACC-79': 18.90701552316055, 'ACC-80': 13.366771234750058, 'ACC-81': 15.424806402538676, 'ACC-82': 13.853758413893463, 'ACC-83': 7.382161024961495, 'ACC-84': 12.49897215757763, 'ACC-85': 12.229241396804941, 'ACC-86': 10.904519007913613, 'ACC-87': 10.634363783891185, 'ACC-88': 12.285359568832616, 'ACC-89': 7.765470406209035, 'ACC-90': 17.87803966809857, 'ACC-91': 13.628915298030888, 'ACC-92': 6.9933460828943295, 'ACC-93': 4.771099680004644, 'ACC-94': 15.559413552089643, 'ACC-95': 13.285731374480985, 'ACC-96': 8.695560219548502, 'ACC-97': 9.629146821452913, 'ACC-98': 8.508937844623384, 'ACC-99': 8.446247976137125, 'ACC-100': 10.087301027371433, 'ACC-101': 10.770525008984286, 'ACC-102': 8.407498867240598, 'ACC-103': 14.793662038348918, 'ACC-104': 7.974422665453383, 'ACC-105': 11.061406172464617, 'ACC-106': 10.289555339308363, 'ACC-107': 8.953195914868434, 'ACC-108': 5.025222285816461, 'ACC-109': 4.368581524997768, 'ACC-110': 8.393038716186982, 'ACC-111': 10.90407320110026, 'ACC-112': 8.863332886231188, 'ACC-113': 3.8705415429109427, 'ACC-114': 9.673334190963038, 'ACC-115': 9.782223024070483, 'ACC-116': 3.3383588197286236, 'ACC-117': 7.945017668185292, 'ACC-118': 3.9633085148950515, 'ACC-119': 10.069623600225945, 'ACC-120': 4.065815227513116, 'ACC-121': 7.267488997909273, 'ACC-122': 5.8818062592582105, 'ACC-123': 4.938924623373445, 'ACC-124': 7.21452921286601, 'ACC-125': 4.370362957830585, 'ACC-126': 7.051236805435386, 'ACC-127': 8.782263641375959, 'ACC-128': 6.015677693742217, 'ACC-129': 5.3606424362072564, 'ACC-130': 3.7591933815392, 'ACC-131': 3.052940992734163, 'ACC-132': 4.2941828941768625, 'ACC-133': 4.827410234950704, 'ACC-134': 6.378078414476519, 'ACC-135': 2.9433897725329228, 'ACC-136': 3.035970112746925, 'ACC-137': 1.1188986251895678, 'ACC-138': 0.45760146711678557, 'ACC-139': 4.6045387877709665, 'ACC-140': 13.809308466142223, 'ACC-141': 2.569853182504431, 'ACC-142': 1.5097885614827506, 'ACC-143': 3.1963790365843465, 'ACC-144': 2.219765342960289, 'ACC-145': 8.103401238847024, 'ACC-146': 0.6574215804985035, 'ACC-147': 3.7016368874903316, 'ACC-148': 3.1829255425830114, 'ACC-149': 7.193005763288371, 'ACC-150': 5.177041282706333, 'ACC-151': 3.1132398221005815, 'ACC-152': 1.091189560995347, 'ACC-153': 1.6234494952271021, 'ACC-154': 3.436437011179252, 'ACC-155': 2.021382280365722, 'ACC-156': 3.319823925226396, 'ACC-157': 1.18532854792149, 'ACC-158': 1.6306518514545885, 'ACC-159': 1.690308970843836, 'ACC-160': 1.3336707686739355, 'ACC-161': 0.5139337839849246, 'ACC-162': 8.046688346657701, 'ACC-163': 0.23709542058832073, 'ACC-164': 2.389340402525376, 'ACC-165': 3.0080012197174955, 'ACC-166': 0.6737121320227313, 'ACC-167': 0.4497391721255518, 'ACC-168': 2.3705956818341654, 'ACC-169': 1.8057775757905432, 'ACC-170': 1.6610588185186765, 'ACC-171': 0.14915256727938003, 'ACC-172': 3.0983072193206653, 'ACC-173': 1.013158835459995, 'ACC-174': 0.20634467949470717, 'ACC-175': 1.819445754041107, 'ACC-176': 0.04534768980729046, 'ACC-177': 0.3537755435354301, 'ACC-178': 0.6895739128587185, 'ACC-179': 0.232510484275109, 'ACC-180': 2.0160266179010464, 'ACC-181': 1.0459968591670397, 'ACC-182': 5.567783097877462, 'ACC-183': 1.7918733563899791, 'ACC-184': 1.1593874773888784, 'ACC-185': 2.56941461228977, 'ACC-186': 0.8710780830616623, 'ACC-187': 9.141690525374793, 'ACC-188': 2.138735321415601, 'ACC-189': 17.698660662711383, 'ACC-190': 3.8352704444700634, 'ACC-191': 4.41657422512235, 'ACC-192': 8.923482685336374})])
[01/19 08:58:08] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 08:58:08] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 08:58:08] d2.evaluation.testing INFO: copypaste: 3.0764,0.4059,0.1691,7.3284,21.2477,12.8004,30.1495
[01/19 08:58:08] d2.utils.events INFO:  eta: 11:15:12  iter: 15999  total_loss: 62.35  loss_ce: 2.049  loss_mask: 0.6323  loss_dice: 3.315  loss_ce_0: 3.527  loss_mask_0: 0.6636  loss_dice_0: 3.572  loss_ce_1: 2.26  loss_mask_1: 0.6417  loss_dice_1: 3.449  loss_ce_2: 2.13  loss_mask_2: 0.636  loss_dice_2: 3.384  loss_ce_3: 2.125  loss_mask_3: 0.6361  loss_dice_3: 3.332  loss_ce_4: 2.057  loss_mask_4: 0.6366  loss_dice_4: 3.334  loss_ce_5: 2.059  loss_mask_5: 0.6352  loss_dice_5: 3.323  loss_ce_6: 2.043  loss_mask_6: 0.6343  loss_dice_6: 3.314  loss_ce_7: 2.037  loss_mask_7: 0.6341  loss_dice_7: 3.314  loss_ce_8: 2.031  loss_mask_8: 0.6348  loss_dice_8: 3.319  time: 1.6942  data_time: 0.3394  lr: 6.3147e-06  max_mem: 17674M
[01/19 08:58:41] d2.utils.events INFO:  eta: 11:14:25  iter: 16019  total_loss: 62.57  loss_ce: 2.032  loss_mask: 0.6314  loss_dice: 3.327  loss_ce_0: 3.567  loss_mask_0: 0.6505  loss_dice_0: 3.588  loss_ce_1: 2.234  loss_mask_1: 0.6464  loss_dice_1: 3.454  loss_ce_2: 2.151  loss_mask_2: 0.6403  loss_dice_2: 3.391  loss_ce_3: 2.097  loss_mask_3: 0.638  loss_dice_3: 3.342  loss_ce_4: 2.052  loss_mask_4: 0.6369  loss_dice_4: 3.337  loss_ce_5: 2.045  loss_mask_5: 0.6352  loss_dice_5: 3.333  loss_ce_6: 2.065  loss_mask_6: 0.6348  loss_dice_6: 3.322  loss_ce_7: 2.033  loss_mask_7: 0.6359  loss_dice_7: 3.326  loss_ce_8: 2.032  loss_mask_8: 0.6338  loss_dice_8: 3.319  time: 1.6941  data_time: 0.3361  lr: 6.31e-06  max_mem: 17674M
[01/19 08:59:15] d2.utils.events INFO:  eta: 11:14:04  iter: 16039  total_loss: 62.26  loss_ce: 2.052  loss_mask: 0.6171  loss_dice: 3.297  loss_ce_0: 3.577  loss_mask_0: 0.6454  loss_dice_0: 3.568  loss_ce_1: 2.304  loss_mask_1: 0.6317  loss_dice_1: 3.441  loss_ce_2: 2.187  loss_mask_2: 0.6238  loss_dice_2: 3.364  loss_ce_3: 2.108  loss_mask_3: 0.6192  loss_dice_3: 3.313  loss_ce_4: 2.057  loss_mask_4: 0.6183  loss_dice_4: 3.318  loss_ce_5: 2.034  loss_mask_5: 0.6179  loss_dice_5: 3.319  loss_ce_6: 2.047  loss_mask_6: 0.617  loss_dice_6: 3.302  loss_ce_7: 2.034  loss_mask_7: 0.6188  loss_dice_7: 3.295  loss_ce_8: 2.041  loss_mask_8: 0.6167  loss_dice_8: 3.3  time: 1.6942  data_time: 0.3518  lr: 6.3052e-06  max_mem: 17674M
[01/19 08:59:49] d2.utils.events INFO:  eta: 11:13:21  iter: 16059  total_loss: 62.04  loss_ce: 1.97  loss_mask: 0.614  loss_dice: 3.29  loss_ce_0: 3.539  loss_mask_0: 0.6393  loss_dice_0: 3.579  loss_ce_1: 2.204  loss_mask_1: 0.6223  loss_dice_1: 3.451  loss_ce_2: 2.118  loss_mask_2: 0.619  loss_dice_2: 3.369  loss_ce_3: 2.053  loss_mask_3: 0.6131  loss_dice_3: 3.32  loss_ce_4: 2.024  loss_mask_4: 0.6151  loss_dice_4: 3.317  loss_ce_5: 1.994  loss_mask_5: 0.6136  loss_dice_5: 3.312  loss_ce_6: 1.99  loss_mask_6: 0.6123  loss_dice_6: 3.3  loss_ce_7: 1.983  loss_mask_7: 0.6143  loss_dice_7: 3.296  loss_ce_8: 1.971  loss_mask_8: 0.6164  loss_dice_8: 3.294  time: 1.6941  data_time: 0.3414  lr: 6.3005e-06  max_mem: 17674M
[01/19 09:00:23] d2.utils.events INFO:  eta: 11:12:38  iter: 16079  total_loss: 62.03  loss_ce: 2.067  loss_mask: 0.6238  loss_dice: 3.304  loss_ce_0: 3.576  loss_mask_0: 0.6359  loss_dice_0: 3.585  loss_ce_1: 2.288  loss_mask_1: 0.6355  loss_dice_1: 3.463  loss_ce_2: 2.197  loss_mask_2: 0.6273  loss_dice_2: 3.386  loss_ce_3: 2.151  loss_mask_3: 0.6241  loss_dice_3: 3.333  loss_ce_4: 2.122  loss_mask_4: 0.6233  loss_dice_4: 3.324  loss_ce_5: 2.087  loss_mask_5: 0.6254  loss_dice_5: 3.321  loss_ce_6: 2.067  loss_mask_6: 0.6233  loss_dice_6: 3.314  loss_ce_7: 2.05  loss_mask_7: 0.622  loss_dice_7: 3.306  loss_ce_8: 2.05  loss_mask_8: 0.6228  loss_dice_8: 3.307  time: 1.6941  data_time: 0.3367  lr: 6.2957e-06  max_mem: 17674M
[01/19 09:00:57] d2.utils.events INFO:  eta: 11:12:14  iter: 16099  total_loss: 62.46  loss_ce: 2.029  loss_mask: 0.6216  loss_dice: 3.337  loss_ce_0: 3.529  loss_mask_0: 0.6487  loss_dice_0: 3.599  loss_ce_1: 2.286  loss_mask_1: 0.6328  loss_dice_1: 3.484  loss_ce_2: 2.19  loss_mask_2: 0.6219  loss_dice_2: 3.412  loss_ce_3: 2.123  loss_mask_3: 0.6241  loss_dice_3: 3.362  loss_ce_4: 2.104  loss_mask_4: 0.6223  loss_dice_4: 3.355  loss_ce_5: 2.08  loss_mask_5: 0.6234  loss_dice_5: 3.348  loss_ce_6: 2.057  loss_mask_6: 0.6244  loss_dice_6: 3.335  loss_ce_7: 2.046  loss_mask_7: 0.6238  loss_dice_7: 3.335  loss_ce_8: 2.039  loss_mask_8: 0.6241  loss_dice_8: 3.339  time: 1.6941  data_time: 0.3497  lr: 6.291e-06  max_mem: 17674M
[01/19 09:01:31] d2.utils.events INFO:  eta: 11:11:40  iter: 16119  total_loss: 61.6  loss_ce: 1.99  loss_mask: 0.6406  loss_dice: 3.256  loss_ce_0: 3.44  loss_mask_0: 0.6561  loss_dice_0: 3.552  loss_ce_1: 2.222  loss_mask_1: 0.6471  loss_dice_1: 3.41  loss_ce_2: 2.111  loss_mask_2: 0.6421  loss_dice_2: 3.343  loss_ce_3: 2.061  loss_mask_3: 0.6368  loss_dice_3: 3.294  loss_ce_4: 2.06  loss_mask_4: 0.6378  loss_dice_4: 3.286  loss_ce_5: 2.02  loss_mask_5: 0.6391  loss_dice_5: 3.281  loss_ce_6: 2.025  loss_mask_6: 0.6358  loss_dice_6: 3.263  loss_ce_7: 2.013  loss_mask_7: 0.6376  loss_dice_7: 3.26  loss_ce_8: 1.982  loss_mask_8: 0.6413  loss_dice_8: 3.259  time: 1.6941  data_time: 0.3341  lr: 6.2863e-06  max_mem: 17674M
[01/19 09:02:04] d2.utils.events INFO:  eta: 11:11:21  iter: 16139  total_loss: 61.75  loss_ce: 2.025  loss_mask: 0.6289  loss_dice: 3.249  loss_ce_0: 3.532  loss_mask_0: 0.6642  loss_dice_0: 3.525  loss_ce_1: 2.299  loss_mask_1: 0.6395  loss_dice_1: 3.389  loss_ce_2: 2.169  loss_mask_2: 0.6322  loss_dice_2: 3.312  loss_ce_3: 2.11  loss_mask_3: 0.6328  loss_dice_3: 3.267  loss_ce_4: 2.069  loss_mask_4: 0.6278  loss_dice_4: 3.26  loss_ce_5: 2.041  loss_mask_5: 0.6298  loss_dice_5: 3.254  loss_ce_6: 2.048  loss_mask_6: 0.6294  loss_dice_6: 3.248  loss_ce_7: 2.022  loss_mask_7: 0.6311  loss_dice_7: 3.254  loss_ce_8: 2.031  loss_mask_8: 0.6318  loss_dice_8: 3.248  time: 1.6941  data_time: 0.3413  lr: 6.2815e-06  max_mem: 17674M
[01/19 09:02:38] d2.utils.events INFO:  eta: 11:10:44  iter: 16159  total_loss: 64.13  loss_ce: 2.263  loss_mask: 0.6381  loss_dice: 3.309  loss_ce_0: 3.547  loss_mask_0: 0.6684  loss_dice_0: 3.575  loss_ce_1: 2.419  loss_mask_1: 0.6573  loss_dice_1: 3.477  loss_ce_2: 2.299  loss_mask_2: 0.6493  loss_dice_2: 3.4  loss_ce_3: 2.298  loss_mask_3: 0.6417  loss_dice_3: 3.343  loss_ce_4: 2.273  loss_mask_4: 0.6392  loss_dice_4: 3.338  loss_ce_5: 2.267  loss_mask_5: 0.6383  loss_dice_5: 3.34  loss_ce_6: 2.25  loss_mask_6: 0.6369  loss_dice_6: 3.326  loss_ce_7: 2.26  loss_mask_7: 0.6391  loss_dice_7: 3.321  loss_ce_8: 2.24  loss_mask_8: 0.6353  loss_dice_8: 3.314  time: 1.6941  data_time: 0.3373  lr: 6.2768e-06  max_mem: 17674M
[01/19 09:03:12] d2.utils.events INFO:  eta: 11:10:14  iter: 16179  total_loss: 61.73  loss_ce: 2.023  loss_mask: 0.6314  loss_dice: 3.277  loss_ce_0: 3.548  loss_mask_0: 0.6724  loss_dice_0: 3.554  loss_ce_1: 2.227  loss_mask_1: 0.6417  loss_dice_1: 3.428  loss_ce_2: 2.114  loss_mask_2: 0.6343  loss_dice_2: 3.354  loss_ce_3: 2.063  loss_mask_3: 0.6326  loss_dice_3: 3.308  loss_ce_4: 2.055  loss_mask_4: 0.633  loss_dice_4: 3.296  loss_ce_5: 2.037  loss_mask_5: 0.6336  loss_dice_5: 3.293  loss_ce_6: 2.031  loss_mask_6: 0.6298  loss_dice_6: 3.281  loss_ce_7: 2.006  loss_mask_7: 0.6312  loss_dice_7: 3.279  loss_ce_8: 2.011  loss_mask_8: 0.632  loss_dice_8: 3.275  time: 1.6941  data_time: 0.3674  lr: 6.2721e-06  max_mem: 17674M
[01/19 09:03:46] d2.utils.events INFO:  eta: 11:09:42  iter: 16199  total_loss: 60.92  loss_ce: 1.935  loss_mask: 0.6062  loss_dice: 3.267  loss_ce_0: 3.481  loss_mask_0: 0.6271  loss_dice_0: 3.554  loss_ce_1: 2.145  loss_mask_1: 0.6162  loss_dice_1: 3.397  loss_ce_2: 2.062  loss_mask_2: 0.6063  loss_dice_2: 3.319  loss_ce_3: 1.984  loss_mask_3: 0.6067  loss_dice_3: 3.281  loss_ce_4: 1.958  loss_mask_4: 0.607  loss_dice_4: 3.278  loss_ce_5: 1.954  loss_mask_5: 0.6074  loss_dice_5: 3.274  loss_ce_6: 1.948  loss_mask_6: 0.608  loss_dice_6: 3.264  loss_ce_7: 1.952  loss_mask_7: 0.6073  loss_dice_7: 3.261  loss_ce_8: 1.936  loss_mask_8: 0.6052  loss_dice_8: 3.26  time: 1.6941  data_time: 0.3340  lr: 6.2673e-06  max_mem: 17674M
[01/19 09:04:19] d2.utils.events INFO:  eta: 11:09:00  iter: 16219  total_loss: 61.91  loss_ce: 2.066  loss_mask: 0.6249  loss_dice: 3.246  loss_ce_0: 3.495  loss_mask_0: 0.6531  loss_dice_0: 3.514  loss_ce_1: 2.322  loss_mask_1: 0.6364  loss_dice_1: 3.393  loss_ce_2: 2.215  loss_mask_2: 0.6292  loss_dice_2: 3.308  loss_ce_3: 2.149  loss_mask_3: 0.6297  loss_dice_3: 3.264  loss_ce_4: 2.107  loss_mask_4: 0.632  loss_dice_4: 3.261  loss_ce_5: 2.091  loss_mask_5: 0.6299  loss_dice_5: 3.258  loss_ce_6: 2.074  loss_mask_6: 0.6277  loss_dice_6: 3.247  loss_ce_7: 2.075  loss_mask_7: 0.628  loss_dice_7: 3.239  loss_ce_8: 2.05  loss_mask_8: 0.6279  loss_dice_8: 3.244  time: 1.6941  data_time: 0.3348  lr: 6.2626e-06  max_mem: 17674M
[01/19 09:04:53] d2.utils.events INFO:  eta: 11:08:08  iter: 16239  total_loss: 62.09  loss_ce: 2.079  loss_mask: 0.6214  loss_dice: 3.294  loss_ce_0: 3.556  loss_mask_0: 0.643  loss_dice_0: 3.553  loss_ce_1: 2.332  loss_mask_1: 0.6308  loss_dice_1: 3.443  loss_ce_2: 2.175  loss_mask_2: 0.6281  loss_dice_2: 3.383  loss_ce_3: 2.141  loss_mask_3: 0.6234  loss_dice_3: 3.326  loss_ce_4: 2.092  loss_mask_4: 0.6218  loss_dice_4: 3.319  loss_ce_5: 2.082  loss_mask_5: 0.6213  loss_dice_5: 3.318  loss_ce_6: 2.071  loss_mask_6: 0.6181  loss_dice_6: 3.308  loss_ce_7: 2.067  loss_mask_7: 0.6164  loss_dice_7: 3.303  loss_ce_8: 2.062  loss_mask_8: 0.6184  loss_dice_8: 3.297  time: 1.6941  data_time: 0.3439  lr: 6.2578e-06  max_mem: 17674M
[01/19 09:05:28] d2.utils.events INFO:  eta: 11:07:48  iter: 16259  total_loss: 61.82  loss_ce: 2.024  loss_mask: 0.6082  loss_dice: 3.275  loss_ce_0: 3.492  loss_mask_0: 0.6377  loss_dice_0: 3.562  loss_ce_1: 2.267  loss_mask_1: 0.6154  loss_dice_1: 3.426  loss_ce_2: 2.138  loss_mask_2: 0.6157  loss_dice_2: 3.347  loss_ce_3: 2.086  loss_mask_3: 0.6122  loss_dice_3: 3.295  loss_ce_4: 2.055  loss_mask_4: 0.6109  loss_dice_4: 3.3  loss_ce_5: 2.016  loss_mask_5: 0.6108  loss_dice_5: 3.299  loss_ce_6: 2.019  loss_mask_6: 0.6081  loss_dice_6: 3.275  loss_ce_7: 2.001  loss_mask_7: 0.6105  loss_dice_7: 3.272  loss_ce_8: 2.011  loss_mask_8: 0.6104  loss_dice_8: 3.269  time: 1.6941  data_time: 0.3572  lr: 6.2531e-06  max_mem: 17674M
[01/19 09:06:02] d2.utils.events INFO:  eta: 11:07:05  iter: 16279  total_loss: 62.61  loss_ce: 2.097  loss_mask: 0.6261  loss_dice: 3.311  loss_ce_0: 3.53  loss_mask_0: 0.6499  loss_dice_0: 3.57  loss_ce_1: 2.308  loss_mask_1: 0.6466  loss_dice_1: 3.451  loss_ce_2: 2.188  loss_mask_2: 0.6385  loss_dice_2: 3.382  loss_ce_3: 2.155  loss_mask_3: 0.6328  loss_dice_3: 3.334  loss_ce_4: 2.116  loss_mask_4: 0.6314  loss_dice_4: 3.328  loss_ce_5: 2.111  loss_mask_5: 0.6341  loss_dice_5: 3.327  loss_ce_6: 2.108  loss_mask_6: 0.6306  loss_dice_6: 3.309  loss_ce_7: 2.097  loss_mask_7: 0.6316  loss_dice_7: 3.317  loss_ce_8: 2.102  loss_mask_8: 0.6269  loss_dice_8: 3.311  time: 1.6941  data_time: 0.3426  lr: 6.2484e-06  max_mem: 17674M
[01/19 09:06:36] d2.utils.events INFO:  eta: 11:06:31  iter: 16299  total_loss: 61.86  loss_ce: 2.054  loss_mask: 0.6234  loss_dice: 3.274  loss_ce_0: 3.504  loss_mask_0: 0.6533  loss_dice_0: 3.575  loss_ce_1: 2.264  loss_mask_1: 0.6396  loss_dice_1: 3.426  loss_ce_2: 2.187  loss_mask_2: 0.631  loss_dice_2: 3.345  loss_ce_3: 2.139  loss_mask_3: 0.6184  loss_dice_3: 3.301  loss_ce_4: 2.121  loss_mask_4: 0.6207  loss_dice_4: 3.295  loss_ce_5: 2.071  loss_mask_5: 0.6223  loss_dice_5: 3.297  loss_ce_6: 2.071  loss_mask_6: 0.622  loss_dice_6: 3.283  loss_ce_7: 2.04  loss_mask_7: 0.6194  loss_dice_7: 3.285  loss_ce_8: 2.037  loss_mask_8: 0.6214  loss_dice_8: 3.282  time: 1.6941  data_time: 0.3480  lr: 6.2436e-06  max_mem: 17674M
[01/19 09:07:09] d2.utils.events INFO:  eta: 11:05:52  iter: 16319  total_loss: 61.93  loss_ce: 2.047  loss_mask: 0.6256  loss_dice: 3.287  loss_ce_0: 3.525  loss_mask_0: 0.6496  loss_dice_0: 3.575  loss_ce_1: 2.271  loss_mask_1: 0.6337  loss_dice_1: 3.438  loss_ce_2: 2.146  loss_mask_2: 0.6259  loss_dice_2: 3.362  loss_ce_3: 2.127  loss_mask_3: 0.6246  loss_dice_3: 3.314  loss_ce_4: 2.082  loss_mask_4: 0.6278  loss_dice_4: 3.304  loss_ce_5: 2.073  loss_mask_5: 0.6304  loss_dice_5: 3.301  loss_ce_6: 2.072  loss_mask_6: 0.6275  loss_dice_6: 3.289  loss_ce_7: 2.05  loss_mask_7: 0.6271  loss_dice_7: 3.294  loss_ce_8: 2.051  loss_mask_8: 0.6284  loss_dice_8: 3.291  time: 1.6941  data_time: 0.3589  lr: 6.2389e-06  max_mem: 17674M
[01/19 09:07:43] d2.utils.events INFO:  eta: 11:05:17  iter: 16339  total_loss: 62.21  loss_ce: 2.091  loss_mask: 0.6198  loss_dice: 3.218  loss_ce_0: 3.575  loss_mask_0: 0.6359  loss_dice_0: 3.525  loss_ce_1: 2.31  loss_mask_1: 0.6236  loss_dice_1: 3.378  loss_ce_2: 2.179  loss_mask_2: 0.619  loss_dice_2: 3.286  loss_ce_3: 2.155  loss_mask_3: 0.619  loss_dice_3: 3.242  loss_ce_4: 2.107  loss_mask_4: 0.6211  loss_dice_4: 3.236  loss_ce_5: 2.103  loss_mask_5: 0.6207  loss_dice_5: 3.232  loss_ce_6: 2.101  loss_mask_6: 0.6225  loss_dice_6: 3.218  loss_ce_7: 2.089  loss_mask_7: 0.6194  loss_dice_7: 3.223  loss_ce_8: 2.102  loss_mask_8: 0.6199  loss_dice_8: 3.226  time: 1.6941  data_time: 0.3409  lr: 6.2341e-06  max_mem: 17674M
[01/19 09:08:17] d2.utils.events INFO:  eta: 11:04:45  iter: 16359  total_loss: 62.21  loss_ce: 2.073  loss_mask: 0.6278  loss_dice: 3.303  loss_ce_0: 3.511  loss_mask_0: 0.6514  loss_dice_0: 3.58  loss_ce_1: 2.266  loss_mask_1: 0.6393  loss_dice_1: 3.441  loss_ce_2: 2.149  loss_mask_2: 0.6319  loss_dice_2: 3.374  loss_ce_3: 2.14  loss_mask_3: 0.6279  loss_dice_3: 3.324  loss_ce_4: 2.092  loss_mask_4: 0.6282  loss_dice_4: 3.31  loss_ce_5: 2.08  loss_mask_5: 0.6302  loss_dice_5: 3.311  loss_ce_6: 2.076  loss_mask_6: 0.6307  loss_dice_6: 3.301  loss_ce_7: 2.066  loss_mask_7: 0.628  loss_dice_7: 3.3  loss_ce_8: 2.066  loss_mask_8: 0.6292  loss_dice_8: 3.302  time: 1.6941  data_time: 0.3385  lr: 6.2294e-06  max_mem: 17674M
[01/19 09:08:50] d2.utils.events INFO:  eta: 11:04:09  iter: 16379  total_loss: 62.6  loss_ce: 2.087  loss_mask: 0.6168  loss_dice: 3.267  loss_ce_0: 3.604  loss_mask_0: 0.6458  loss_dice_0: 3.545  loss_ce_1: 2.337  loss_mask_1: 0.6288  loss_dice_1: 3.414  loss_ce_2: 2.209  loss_mask_2: 0.6215  loss_dice_2: 3.339  loss_ce_3: 2.167  loss_mask_3: 0.62  loss_dice_3: 3.288  loss_ce_4: 2.122  loss_mask_4: 0.6186  loss_dice_4: 3.287  loss_ce_5: 2.114  loss_mask_5: 0.6185  loss_dice_5: 3.281  loss_ce_6: 2.112  loss_mask_6: 0.6195  loss_dice_6: 3.27  loss_ce_7: 2.09  loss_mask_7: 0.6154  loss_dice_7: 3.274  loss_ce_8: 2.089  loss_mask_8: 0.6171  loss_dice_8: 3.272  time: 1.6940  data_time: 0.3369  lr: 6.2246e-06  max_mem: 17674M
[01/19 09:09:24] d2.utils.events INFO:  eta: 11:03:42  iter: 16399  total_loss: 61.86  loss_ce: 2.061  loss_mask: 0.6265  loss_dice: 3.303  loss_ce_0: 3.493  loss_mask_0: 0.6415  loss_dice_0: 3.58  loss_ce_1: 2.264  loss_mask_1: 0.6364  loss_dice_1: 3.449  loss_ce_2: 2.147  loss_mask_2: 0.6338  loss_dice_2: 3.377  loss_ce_3: 2.109  loss_mask_3: 0.6288  loss_dice_3: 3.323  loss_ce_4: 2.073  loss_mask_4: 0.6296  loss_dice_4: 3.319  loss_ce_5: 2.041  loss_mask_5: 0.6322  loss_dice_5: 3.308  loss_ce_6: 2.054  loss_mask_6: 0.6259  loss_dice_6: 3.296  loss_ce_7: 2.039  loss_mask_7: 0.6272  loss_dice_7: 3.3  loss_ce_8: 2.059  loss_mask_8: 0.6287  loss_dice_8: 3.302  time: 1.6940  data_time: 0.3434  lr: 6.2199e-06  max_mem: 17674M
[01/19 09:09:58] d2.utils.events INFO:  eta: 11:03:04  iter: 16419  total_loss: 61.37  loss_ce: 1.921  loss_mask: 0.6083  loss_dice: 3.325  loss_ce_0: 3.488  loss_mask_0: 0.6356  loss_dice_0: 3.611  loss_ce_1: 2.182  loss_mask_1: 0.6209  loss_dice_1: 3.474  loss_ce_2: 2.024  loss_mask_2: 0.6149  loss_dice_2: 3.398  loss_ce_3: 1.991  loss_mask_3: 0.6076  loss_dice_3: 3.351  loss_ce_4: 1.954  loss_mask_4: 0.6082  loss_dice_4: 3.353  loss_ce_5: 1.939  loss_mask_5: 0.6042  loss_dice_5: 3.351  loss_ce_6: 1.937  loss_mask_6: 0.607  loss_dice_6: 3.33  loss_ce_7: 1.926  loss_mask_7: 0.6079  loss_dice_7: 3.329  loss_ce_8: 1.916  loss_mask_8: 0.6097  loss_dice_8: 3.334  time: 1.6941  data_time: 0.3673  lr: 6.2152e-06  max_mem: 17674M
[01/19 09:10:32] d2.utils.events INFO:  eta: 11:02:35  iter: 16439  total_loss: 61.23  loss_ce: 1.944  loss_mask: 0.6251  loss_dice: 3.319  loss_ce_0: 3.471  loss_mask_0: 0.637  loss_dice_0: 3.588  loss_ce_1: 2.18  loss_mask_1: 0.6295  loss_dice_1: 3.457  loss_ce_2: 2.041  loss_mask_2: 0.6257  loss_dice_2: 3.384  loss_ce_3: 2.008  loss_mask_3: 0.6241  loss_dice_3: 3.338  loss_ce_4: 1.98  loss_mask_4: 0.6215  loss_dice_4: 3.326  loss_ce_5: 1.969  loss_mask_5: 0.6226  loss_dice_5: 3.335  loss_ce_6: 1.944  loss_mask_6: 0.6233  loss_dice_6: 3.324  loss_ce_7: 1.958  loss_mask_7: 0.6267  loss_dice_7: 3.315  loss_ce_8: 1.931  loss_mask_8: 0.6262  loss_dice_8: 3.319  time: 1.6940  data_time: 0.3384  lr: 6.2104e-06  max_mem: 17674M
[01/19 09:11:06] d2.utils.events INFO:  eta: 11:02:27  iter: 16459  total_loss: 61.49  loss_ce: 1.93  loss_mask: 0.624  loss_dice: 3.31  loss_ce_0: 3.527  loss_mask_0: 0.6402  loss_dice_0: 3.558  loss_ce_1: 2.153  loss_mask_1: 0.6265  loss_dice_1: 3.447  loss_ce_2: 2.033  loss_mask_2: 0.6242  loss_dice_2: 3.371  loss_ce_3: 1.983  loss_mask_3: 0.6244  loss_dice_3: 3.328  loss_ce_4: 1.956  loss_mask_4: 0.6299  loss_dice_4: 3.329  loss_ce_5: 1.941  loss_mask_5: 0.6268  loss_dice_5: 3.329  loss_ce_6: 1.944  loss_mask_6: 0.6298  loss_dice_6: 3.31  loss_ce_7: 1.928  loss_mask_7: 0.6274  loss_dice_7: 3.315  loss_ce_8: 1.917  loss_mask_8: 0.6267  loss_dice_8: 3.309  time: 1.6941  data_time: 0.3321  lr: 6.2057e-06  max_mem: 17674M
[01/19 09:11:40] d2.utils.events INFO:  eta: 11:02:04  iter: 16479  total_loss: 61.41  loss_ce: 2.003  loss_mask: 0.6205  loss_dice: 3.289  loss_ce_0: 3.421  loss_mask_0: 0.6406  loss_dice_0: 3.576  loss_ce_1: 2.23  loss_mask_1: 0.6352  loss_dice_1: 3.421  loss_ce_2: 2.117  loss_mask_2: 0.6276  loss_dice_2: 3.362  loss_ce_3: 2.08  loss_mask_3: 0.6208  loss_dice_3: 3.318  loss_ce_4: 2.03  loss_mask_4: 0.6231  loss_dice_4: 3.306  loss_ce_5: 1.999  loss_mask_5: 0.6232  loss_dice_5: 3.306  loss_ce_6: 2.015  loss_mask_6: 0.6219  loss_dice_6: 3.293  loss_ce_7: 2.007  loss_mask_7: 0.6249  loss_dice_7: 3.29  loss_ce_8: 1.993  loss_mask_8: 0.6234  loss_dice_8: 3.295  time: 1.6940  data_time: 0.3362  lr: 6.2009e-06  max_mem: 17674M
[01/19 09:12:14] d2.utils.events INFO:  eta: 11:01:30  iter: 16499  total_loss: 61.54  loss_ce: 1.945  loss_mask: 0.6299  loss_dice: 3.274  loss_ce_0: 3.467  loss_mask_0: 0.6493  loss_dice_0: 3.57  loss_ce_1: 2.221  loss_mask_1: 0.6395  loss_dice_1: 3.424  loss_ce_2: 2.065  loss_mask_2: 0.6348  loss_dice_2: 3.35  loss_ce_3: 2.014  loss_mask_3: 0.6294  loss_dice_3: 3.302  loss_ce_4: 1.961  loss_mask_4: 0.6294  loss_dice_4: 3.296  loss_ce_5: 1.965  loss_mask_5: 0.6296  loss_dice_5: 3.287  loss_ce_6: 1.962  loss_mask_6: 0.629  loss_dice_6: 3.279  loss_ce_7: 1.965  loss_mask_7: 0.6269  loss_dice_7: 3.284  loss_ce_8: 1.946  loss_mask_8: 0.6284  loss_dice_8: 3.286  time: 1.6940  data_time: 0.3416  lr: 6.1962e-06  max_mem: 17674M
[01/19 09:12:48] d2.utils.events INFO:  eta: 11:00:51  iter: 16519  total_loss: 61.93  loss_ce: 2.052  loss_mask: 0.6102  loss_dice: 3.281  loss_ce_0: 3.521  loss_mask_0: 0.6332  loss_dice_0: 3.561  loss_ce_1: 2.266  loss_mask_1: 0.6201  loss_dice_1: 3.439  loss_ce_2: 2.178  loss_mask_2: 0.6176  loss_dice_2: 3.355  loss_ce_3: 2.116  loss_mask_3: 0.6142  loss_dice_3: 3.31  loss_ce_4: 2.072  loss_mask_4: 0.6125  loss_dice_4: 3.31  loss_ce_5: 2.054  loss_mask_5: 0.6133  loss_dice_5: 3.3  loss_ce_6: 2.073  loss_mask_6: 0.6122  loss_dice_6: 3.29  loss_ce_7: 2.047  loss_mask_7: 0.6113  loss_dice_7: 3.286  loss_ce_8: 2.06  loss_mask_8: 0.6117  loss_dice_8: 3.289  time: 1.6941  data_time: 0.3492  lr: 6.1914e-06  max_mem: 17674M
[01/19 09:13:22] d2.utils.events INFO:  eta: 11:00:39  iter: 16539  total_loss: 61.52  loss_ce: 1.989  loss_mask: 0.608  loss_dice: 3.272  loss_ce_0: 3.516  loss_mask_0: 0.6328  loss_dice_0: 3.543  loss_ce_1: 2.217  loss_mask_1: 0.6296  loss_dice_1: 3.411  loss_ce_2: 2.122  loss_mask_2: 0.6214  loss_dice_2: 3.335  loss_ce_3: 2.072  loss_mask_3: 0.6126  loss_dice_3: 3.296  loss_ce_4: 2.043  loss_mask_4: 0.6124  loss_dice_4: 3.289  loss_ce_5: 2.022  loss_mask_5: 0.6097  loss_dice_5: 3.285  loss_ce_6: 2.013  loss_mask_6: 0.6092  loss_dice_6: 3.275  loss_ce_7: 1.998  loss_mask_7: 0.6093  loss_dice_7: 3.279  loss_ce_8: 1.987  loss_mask_8: 0.6088  loss_dice_8: 3.283  time: 1.6940  data_time: 0.3402  lr: 6.1867e-06  max_mem: 17674M
[01/19 09:13:56] d2.utils.events INFO:  eta: 11:00:14  iter: 16559  total_loss: 62.22  loss_ce: 2.026  loss_mask: 0.6306  loss_dice: 3.295  loss_ce_0: 3.494  loss_mask_0: 0.6523  loss_dice_0: 3.587  loss_ce_1: 2.239  loss_mask_1: 0.6468  loss_dice_1: 3.456  loss_ce_2: 2.141  loss_mask_2: 0.6365  loss_dice_2: 3.37  loss_ce_3: 2.094  loss_mask_3: 0.6289  loss_dice_3: 3.319  loss_ce_4: 2.075  loss_mask_4: 0.6269  loss_dice_4: 3.314  loss_ce_5: 2.05  loss_mask_5: 0.6298  loss_dice_5: 3.313  loss_ce_6: 2.035  loss_mask_6: 0.6323  loss_dice_6: 3.302  loss_ce_7: 2.015  loss_mask_7: 0.6302  loss_dice_7: 3.299  loss_ce_8: 2.031  loss_mask_8: 0.6324  loss_dice_8: 3.301  time: 1.6940  data_time: 0.3387  lr: 6.1819e-06  max_mem: 17674M
[01/19 09:14:30] d2.utils.events INFO:  eta: 10:59:47  iter: 16579  total_loss: 62.22  loss_ce: 2.026  loss_mask: 0.6324  loss_dice: 3.294  loss_ce_0: 3.483  loss_mask_0: 0.6567  loss_dice_0: 3.559  loss_ce_1: 2.224  loss_mask_1: 0.6518  loss_dice_1: 3.414  loss_ce_2: 2.106  loss_mask_2: 0.6437  loss_dice_2: 3.351  loss_ce_3: 2.075  loss_mask_3: 0.6412  loss_dice_3: 3.307  loss_ce_4: 2.046  loss_mask_4: 0.6393  loss_dice_4: 3.302  loss_ce_5: 2.042  loss_mask_5: 0.6421  loss_dice_5: 3.304  loss_ce_6: 2.026  loss_mask_6: 0.6385  loss_dice_6: 3.3  loss_ce_7: 2.026  loss_mask_7: 0.6373  loss_dice_7: 3.295  loss_ce_8: 2.002  loss_mask_8: 0.6368  loss_dice_8: 3.293  time: 1.6941  data_time: 0.3594  lr: 6.1772e-06  max_mem: 17674M
[01/19 09:15:04] d2.utils.events INFO:  eta: 10:58:52  iter: 16599  total_loss: 62.07  loss_ce: 2.025  loss_mask: 0.6264  loss_dice: 3.27  loss_ce_0: 3.488  loss_mask_0: 0.6548  loss_dice_0: 3.559  loss_ce_1: 2.312  loss_mask_1: 0.6378  loss_dice_1: 3.412  loss_ce_2: 2.149  loss_mask_2: 0.63  loss_dice_2: 3.344  loss_ce_3: 2.114  loss_mask_3: 0.6283  loss_dice_3: 3.293  loss_ce_4: 2.079  loss_mask_4: 0.628  loss_dice_4: 3.289  loss_ce_5: 2.049  loss_mask_5: 0.627  loss_dice_5: 3.283  loss_ce_6: 2.049  loss_mask_6: 0.6271  loss_dice_6: 3.273  loss_ce_7: 2.033  loss_mask_7: 0.6244  loss_dice_7: 3.267  loss_ce_8: 2.027  loss_mask_8: 0.6281  loss_dice_8: 3.262  time: 1.6940  data_time: 0.3287  lr: 6.1724e-06  max_mem: 17674M
[01/19 09:15:38] d2.utils.events INFO:  eta: 10:58:27  iter: 16619  total_loss: 62.59  loss_ce: 2.055  loss_mask: 0.6236  loss_dice: 3.308  loss_ce_0: 3.508  loss_mask_0: 0.6513  loss_dice_0: 3.585  loss_ce_1: 2.247  loss_mask_1: 0.6316  loss_dice_1: 3.452  loss_ce_2: 2.145  loss_mask_2: 0.6256  loss_dice_2: 3.381  loss_ce_3: 2.107  loss_mask_3: 0.6258  loss_dice_3: 3.323  loss_ce_4: 2.09  loss_mask_4: 0.6276  loss_dice_4: 3.325  loss_ce_5: 2.066  loss_mask_5: 0.6289  loss_dice_5: 3.319  loss_ce_6: 2.093  loss_mask_6: 0.6266  loss_dice_6: 3.31  loss_ce_7: 2.079  loss_mask_7: 0.6279  loss_dice_7: 3.308  loss_ce_8: 2.059  loss_mask_8: 0.6279  loss_dice_8: 3.308  time: 1.6941  data_time: 0.3400  lr: 6.1677e-06  max_mem: 17674M
[01/19 09:16:12] d2.utils.events INFO:  eta: 10:57:34  iter: 16639  total_loss: 63.27  loss_ce: 2.191  loss_mask: 0.644  loss_dice: 3.293  loss_ce_0: 3.507  loss_mask_0: 0.6632  loss_dice_0: 3.574  loss_ce_1: 2.331  loss_mask_1: 0.6533  loss_dice_1: 3.457  loss_ce_2: 2.261  loss_mask_2: 0.6492  loss_dice_2: 3.364  loss_ce_3: 2.243  loss_mask_3: 0.6454  loss_dice_3: 3.311  loss_ce_4: 2.202  loss_mask_4: 0.6423  loss_dice_4: 3.312  loss_ce_5: 2.184  loss_mask_5: 0.6412  loss_dice_5: 3.309  loss_ce_6: 2.2  loss_mask_6: 0.6417  loss_dice_6: 3.292  loss_ce_7: 2.183  loss_mask_7: 0.6452  loss_dice_7: 3.296  loss_ce_8: 2.179  loss_mask_8: 0.6444  loss_dice_8: 3.293  time: 1.6940  data_time: 0.3550  lr: 6.1629e-06  max_mem: 17674M
[01/19 09:16:45] d2.utils.events INFO:  eta: 10:56:48  iter: 16659  total_loss: 61.17  loss_ce: 1.947  loss_mask: 0.6111  loss_dice: 3.297  loss_ce_0: 3.479  loss_mask_0: 0.6232  loss_dice_0: 3.574  loss_ce_1: 2.198  loss_mask_1: 0.617  loss_dice_1: 3.443  loss_ce_2: 2.046  loss_mask_2: 0.606  loss_dice_2: 3.377  loss_ce_3: 2.021  loss_mask_3: 0.6052  loss_dice_3: 3.322  loss_ce_4: 1.977  loss_mask_4: 0.6065  loss_dice_4: 3.313  loss_ce_5: 1.954  loss_mask_5: 0.6103  loss_dice_5: 3.311  loss_ce_6: 1.956  loss_mask_6: 0.6102  loss_dice_6: 3.306  loss_ce_7: 1.935  loss_mask_7: 0.6102  loss_dice_7: 3.304  loss_ce_8: 1.912  loss_mask_8: 0.6118  loss_dice_8: 3.302  time: 1.6940  data_time: 0.3353  lr: 6.1582e-06  max_mem: 17674M
[01/19 09:17:19] d2.utils.events INFO:  eta: 10:56:01  iter: 16679  total_loss: 61.74  loss_ce: 2.014  loss_mask: 0.6285  loss_dice: 3.278  loss_ce_0: 3.428  loss_mask_0: 0.6499  loss_dice_0: 3.555  loss_ce_1: 2.26  loss_mask_1: 0.6358  loss_dice_1: 3.417  loss_ce_2: 2.11  loss_mask_2: 0.6291  loss_dice_2: 3.337  loss_ce_3: 2.054  loss_mask_3: 0.6252  loss_dice_3: 3.3  loss_ce_4: 2.023  loss_mask_4: 0.6261  loss_dice_4: 3.296  loss_ce_5: 2.012  loss_mask_5: 0.6287  loss_dice_5: 3.29  loss_ce_6: 2.011  loss_mask_6: 0.6281  loss_dice_6: 3.282  loss_ce_7: 2.009  loss_mask_7: 0.6291  loss_dice_7: 3.285  loss_ce_8: 2.011  loss_mask_8: 0.6281  loss_dice_8: 3.282  time: 1.6940  data_time: 0.3522  lr: 6.1534e-06  max_mem: 17674M
[01/19 09:17:53] d2.utils.events INFO:  eta: 10:54:58  iter: 16699  total_loss: 61.33  loss_ce: 1.973  loss_mask: 0.6079  loss_dice: 3.265  loss_ce_0: 3.527  loss_mask_0: 0.6318  loss_dice_0: 3.568  loss_ce_1: 2.202  loss_mask_1: 0.6165  loss_dice_1: 3.416  loss_ce_2: 2.087  loss_mask_2: 0.6128  loss_dice_2: 3.342  loss_ce_3: 2.044  loss_mask_3: 0.6117  loss_dice_3: 3.293  loss_ce_4: 2.01  loss_mask_4: 0.6087  loss_dice_4: 3.288  loss_ce_5: 2.018  loss_mask_5: 0.6095  loss_dice_5: 3.286  loss_ce_6: 1.977  loss_mask_6: 0.6075  loss_dice_6: 3.27  loss_ce_7: 1.991  loss_mask_7: 0.6087  loss_dice_7: 3.275  loss_ce_8: 1.983  loss_mask_8: 0.6069  loss_dice_8: 3.27  time: 1.6940  data_time: 0.3305  lr: 6.1487e-06  max_mem: 17674M
[01/19 09:18:27] d2.utils.events INFO:  eta: 10:54:38  iter: 16719  total_loss: 61.37  loss_ce: 1.998  loss_mask: 0.6161  loss_dice: 3.315  loss_ce_0: 3.44  loss_mask_0: 0.6364  loss_dice_0: 3.586  loss_ce_1: 2.238  loss_mask_1: 0.6304  loss_dice_1: 3.45  loss_ce_2: 2.109  loss_mask_2: 0.62  loss_dice_2: 3.384  loss_ce_3: 2.065  loss_mask_3: 0.6157  loss_dice_3: 3.342  loss_ce_4: 2.021  loss_mask_4: 0.6148  loss_dice_4: 3.329  loss_ce_5: 2.005  loss_mask_5: 0.6157  loss_dice_5: 3.329  loss_ce_6: 2.039  loss_mask_6: 0.613  loss_dice_6: 3.318  loss_ce_7: 1.986  loss_mask_7: 0.6159  loss_dice_7: 3.323  loss_ce_8: 2.002  loss_mask_8: 0.6157  loss_dice_8: 3.319  time: 1.6940  data_time: 0.3572  lr: 6.1439e-06  max_mem: 17674M
[01/19 09:19:01] d2.utils.events INFO:  eta: 10:53:48  iter: 16739  total_loss: 61.07  loss_ce: 2.006  loss_mask: 0.6301  loss_dice: 3.244  loss_ce_0: 3.52  loss_mask_0: 0.6516  loss_dice_0: 3.531  loss_ce_1: 2.226  loss_mask_1: 0.637  loss_dice_1: 3.404  loss_ce_2: 2.112  loss_mask_2: 0.6327  loss_dice_2: 3.327  loss_ce_3: 2.074  loss_mask_3: 0.6274  loss_dice_3: 3.283  loss_ce_4: 2.032  loss_mask_4: 0.6308  loss_dice_4: 3.269  loss_ce_5: 2.016  loss_mask_5: 0.6287  loss_dice_5: 3.264  loss_ce_6: 2.006  loss_mask_6: 0.6302  loss_dice_6: 3.246  loss_ce_7: 1.996  loss_mask_7: 0.6265  loss_dice_7: 3.246  loss_ce_8: 1.995  loss_mask_8: 0.6305  loss_dice_8: 3.248  time: 1.6940  data_time: 0.3190  lr: 6.1392e-06  max_mem: 17674M
[01/19 09:19:35] d2.utils.events INFO:  eta: 10:53:14  iter: 16759  total_loss: 62.04  loss_ce: 2.055  loss_mask: 0.6271  loss_dice: 3.312  loss_ce_0: 3.432  loss_mask_0: 0.6499  loss_dice_0: 3.596  loss_ce_1: 2.281  loss_mask_1: 0.6327  loss_dice_1: 3.45  loss_ce_2: 2.192  loss_mask_2: 0.6254  loss_dice_2: 3.381  loss_ce_3: 2.122  loss_mask_3: 0.6212  loss_dice_3: 3.337  loss_ce_4: 2.089  loss_mask_4: 0.6207  loss_dice_4: 3.331  loss_ce_5: 2.057  loss_mask_5: 0.6228  loss_dice_5: 3.333  loss_ce_6: 2.064  loss_mask_6: 0.6212  loss_dice_6: 3.316  loss_ce_7: 2.053  loss_mask_7: 0.623  loss_dice_7: 3.321  loss_ce_8: 2.04  loss_mask_8: 0.6246  loss_dice_8: 3.32  time: 1.6940  data_time: 0.3632  lr: 6.1344e-06  max_mem: 17674M
[01/19 09:20:09] d2.utils.events INFO:  eta: 10:52:40  iter: 16779  total_loss: 61.68  loss_ce: 1.958  loss_mask: 0.6232  loss_dice: 3.252  loss_ce_0: 3.47  loss_mask_0: 0.6484  loss_dice_0: 3.531  loss_ce_1: 2.187  loss_mask_1: 0.6406  loss_dice_1: 3.403  loss_ce_2: 2.081  loss_mask_2: 0.634  loss_dice_2: 3.33  loss_ce_3: 2.05  loss_mask_3: 0.6278  loss_dice_3: 3.276  loss_ce_4: 2.005  loss_mask_4: 0.6281  loss_dice_4: 3.278  loss_ce_5: 1.986  loss_mask_5: 0.6266  loss_dice_5: 3.271  loss_ce_6: 1.982  loss_mask_6: 0.6217  loss_dice_6: 3.264  loss_ce_7: 1.967  loss_mask_7: 0.6243  loss_dice_7: 3.259  loss_ce_8: 1.954  loss_mask_8: 0.6242  loss_dice_8: 3.255  time: 1.6940  data_time: 0.3254  lr: 6.1297e-06  max_mem: 17674M
[01/19 09:20:42] d2.utils.events INFO:  eta: 10:52:00  iter: 16799  total_loss: 61.53  loss_ce: 2.053  loss_mask: 0.6276  loss_dice: 3.261  loss_ce_0: 3.554  loss_mask_0: 0.6666  loss_dice_0: 3.547  loss_ce_1: 2.29  loss_mask_1: 0.6426  loss_dice_1: 3.421  loss_ce_2: 2.167  loss_mask_2: 0.636  loss_dice_2: 3.33  loss_ce_3: 2.099  loss_mask_3: 0.6301  loss_dice_3: 3.288  loss_ce_4: 2.075  loss_mask_4: 0.6321  loss_dice_4: 3.28  loss_ce_5: 2.056  loss_mask_5: 0.628  loss_dice_5: 3.283  loss_ce_6: 2.071  loss_mask_6: 0.6287  loss_dice_6: 3.271  loss_ce_7: 2.057  loss_mask_7: 0.6289  loss_dice_7: 3.268  loss_ce_8: 2.054  loss_mask_8: 0.6311  loss_dice_8: 3.265  time: 1.6940  data_time: 0.3162  lr: 6.1249e-06  max_mem: 17674M
[01/19 09:21:16] d2.utils.events INFO:  eta: 10:51:26  iter: 16819  total_loss: 61.02  loss_ce: 1.899  loss_mask: 0.6292  loss_dice: 3.313  loss_ce_0: 3.467  loss_mask_0: 0.6588  loss_dice_0: 3.575  loss_ce_1: 2.149  loss_mask_1: 0.6315  loss_dice_1: 3.45  loss_ce_2: 2.041  loss_mask_2: 0.6296  loss_dice_2: 3.384  loss_ce_3: 1.984  loss_mask_3: 0.6312  loss_dice_3: 3.338  loss_ce_4: 1.952  loss_mask_4: 0.6297  loss_dice_4: 3.327  loss_ce_5: 1.905  loss_mask_5: 0.6287  loss_dice_5: 3.329  loss_ce_6: 1.915  loss_mask_6: 0.6313  loss_dice_6: 3.311  loss_ce_7: 1.912  loss_mask_7: 0.6307  loss_dice_7: 3.318  loss_ce_8: 1.894  loss_mask_8: 0.632  loss_dice_8: 3.309  time: 1.6940  data_time: 0.3475  lr: 6.1202e-06  max_mem: 17674M
[01/19 09:21:50] d2.utils.events INFO:  eta: 10:50:59  iter: 16839  total_loss: 61.89  loss_ce: 2.034  loss_mask: 0.614  loss_dice: 3.271  loss_ce_0: 3.477  loss_mask_0: 0.6368  loss_dice_0: 3.554  loss_ce_1: 2.249  loss_mask_1: 0.621  loss_dice_1: 3.406  loss_ce_2: 2.132  loss_mask_2: 0.6237  loss_dice_2: 3.33  loss_ce_3: 2.094  loss_mask_3: 0.6185  loss_dice_3: 3.288  loss_ce_4: 2.045  loss_mask_4: 0.6173  loss_dice_4: 3.284  loss_ce_5: 2.04  loss_mask_5: 0.6133  loss_dice_5: 3.279  loss_ce_6: 2.035  loss_mask_6: 0.6156  loss_dice_6: 3.268  loss_ce_7: 2.03  loss_mask_7: 0.6147  loss_dice_7: 3.273  loss_ce_8: 2.034  loss_mask_8: 0.6144  loss_dice_8: 3.272  time: 1.6940  data_time: 0.3395  lr: 6.1154e-06  max_mem: 17674M
[01/19 09:22:24] d2.utils.events INFO:  eta: 10:50:41  iter: 16859  total_loss: 61.62  loss_ce: 1.98  loss_mask: 0.6155  loss_dice: 3.303  loss_ce_0: 3.49  loss_mask_0: 0.644  loss_dice_0: 3.573  loss_ce_1: 2.234  loss_mask_1: 0.627  loss_dice_1: 3.441  loss_ce_2: 2.112  loss_mask_2: 0.6242  loss_dice_2: 3.374  loss_ce_3: 2.054  loss_mask_3: 0.6218  loss_dice_3: 3.32  loss_ce_4: 2.015  loss_mask_4: 0.6177  loss_dice_4: 3.318  loss_ce_5: 2.003  loss_mask_5: 0.6201  loss_dice_5: 3.307  loss_ce_6: 2.013  loss_mask_6: 0.6152  loss_dice_6: 3.299  loss_ce_7: 1.992  loss_mask_7: 0.6172  loss_dice_7: 3.304  loss_ce_8: 1.993  loss_mask_8: 0.6166  loss_dice_8: 3.303  time: 1.6940  data_time: 0.3530  lr: 6.1107e-06  max_mem: 17674M
[01/19 09:22:58] d2.utils.events INFO:  eta: 10:50:29  iter: 16879  total_loss: 61.63  loss_ce: 2.011  loss_mask: 0.597  loss_dice: 3.257  loss_ce_0: 3.505  loss_mask_0: 0.6216  loss_dice_0: 3.542  loss_ce_1: 2.215  loss_mask_1: 0.6133  loss_dice_1: 3.398  loss_ce_2: 2.104  loss_mask_2: 0.6059  loss_dice_2: 3.336  loss_ce_3: 2.065  loss_mask_3: 0.5983  loss_dice_3: 3.292  loss_ce_4: 2.022  loss_mask_4: 0.6004  loss_dice_4: 3.283  loss_ce_5: 1.995  loss_mask_5: 0.5992  loss_dice_5: 3.283  loss_ce_6: 2.031  loss_mask_6: 0.5955  loss_dice_6: 3.267  loss_ce_7: 2  loss_mask_7: 0.5981  loss_dice_7: 3.263  loss_ce_8: 1.995  loss_mask_8: 0.5971  loss_dice_8: 3.262  time: 1.6940  data_time: 0.3557  lr: 6.1059e-06  max_mem: 17674M
[01/19 09:23:32] d2.utils.events INFO:  eta: 10:50:02  iter: 16899  total_loss: 61.98  loss_ce: 2.02  loss_mask: 0.6216  loss_dice: 3.284  loss_ce_0: 3.497  loss_mask_0: 0.6475  loss_dice_0: 3.558  loss_ce_1: 2.182  loss_mask_1: 0.6401  loss_dice_1: 3.449  loss_ce_2: 2.101  loss_mask_2: 0.6324  loss_dice_2: 3.364  loss_ce_3: 2.074  loss_mask_3: 0.6217  loss_dice_3: 3.314  loss_ce_4: 2.043  loss_mask_4: 0.6238  loss_dice_4: 3.308  loss_ce_5: 2.023  loss_mask_5: 0.6249  loss_dice_5: 3.298  loss_ce_6: 2.025  loss_mask_6: 0.6218  loss_dice_6: 3.287  loss_ce_7: 2.021  loss_mask_7: 0.6241  loss_dice_7: 3.282  loss_ce_8: 2.009  loss_mask_8: 0.6224  loss_dice_8: 3.29  time: 1.6940  data_time: 0.3435  lr: 6.1012e-06  max_mem: 17674M
[01/19 09:24:06] d2.utils.events INFO:  eta: 10:49:32  iter: 16919  total_loss: 61.24  loss_ce: 1.946  loss_mask: 0.6303  loss_dice: 3.297  loss_ce_0: 3.467  loss_mask_0: 0.6563  loss_dice_0: 3.57  loss_ce_1: 2.191  loss_mask_1: 0.6409  loss_dice_1: 3.441  loss_ce_2: 2.046  loss_mask_2: 0.6361  loss_dice_2: 3.363  loss_ce_3: 2.036  loss_mask_3: 0.632  loss_dice_3: 3.317  loss_ce_4: 1.982  loss_mask_4: 0.6334  loss_dice_4: 3.315  loss_ce_5: 1.954  loss_mask_5: 0.6339  loss_dice_5: 3.311  loss_ce_6: 1.965  loss_mask_6: 0.6292  loss_dice_6: 3.301  loss_ce_7: 1.939  loss_mask_7: 0.6307  loss_dice_7: 3.302  loss_ce_8: 1.941  loss_mask_8: 0.6319  loss_dice_8: 3.303  time: 1.6940  data_time: 0.3371  lr: 6.0964e-06  max_mem: 17674M
[01/19 09:24:39] d2.utils.events INFO:  eta: 10:48:41  iter: 16939  total_loss: 61.09  loss_ce: 1.957  loss_mask: 0.6357  loss_dice: 3.255  loss_ce_0: 3.455  loss_mask_0: 0.6541  loss_dice_0: 3.527  loss_ce_1: 2.215  loss_mask_1: 0.6443  loss_dice_1: 3.397  loss_ce_2: 2.107  loss_mask_2: 0.6418  loss_dice_2: 3.321  loss_ce_3: 2.037  loss_mask_3: 0.6323  loss_dice_3: 3.283  loss_ce_4: 2.011  loss_mask_4: 0.6352  loss_dice_4: 3.279  loss_ce_5: 1.994  loss_mask_5: 0.6363  loss_dice_5: 3.274  loss_ce_6: 1.974  loss_mask_6: 0.6318  loss_dice_6: 3.264  loss_ce_7: 1.951  loss_mask_7: 0.6346  loss_dice_7: 3.261  loss_ce_8: 1.971  loss_mask_8: 0.6365  loss_dice_8: 3.256  time: 1.6940  data_time: 0.3338  lr: 6.0917e-06  max_mem: 17674M
[01/19 09:25:13] d2.utils.events INFO:  eta: 10:48:14  iter: 16959  total_loss: 61.5  loss_ce: 1.911  loss_mask: 0.6191  loss_dice: 3.293  loss_ce_0: 3.464  loss_mask_0: 0.6382  loss_dice_0: 3.556  loss_ce_1: 2.14  loss_mask_1: 0.6187  loss_dice_1: 3.436  loss_ce_2: 2.071  loss_mask_2: 0.6139  loss_dice_2: 3.346  loss_ce_3: 2.019  loss_mask_3: 0.6138  loss_dice_3: 3.299  loss_ce_4: 1.983  loss_mask_4: 0.6145  loss_dice_4: 3.296  loss_ce_5: 1.946  loss_mask_5: 0.6151  loss_dice_5: 3.299  loss_ce_6: 1.951  loss_mask_6: 0.6153  loss_dice_6: 3.286  loss_ce_7: 1.947  loss_mask_7: 0.6167  loss_dice_7: 3.289  loss_ce_8: 1.938  loss_mask_8: 0.6169  loss_dice_8: 3.284  time: 1.6940  data_time: 0.3398  lr: 6.0869e-06  max_mem: 17674M
[01/19 09:25:47] d2.utils.events INFO:  eta: 10:47:40  iter: 16979  total_loss: 62.49  loss_ce: 2.096  loss_mask: 0.628  loss_dice: 3.303  loss_ce_0: 3.474  loss_mask_0: 0.6502  loss_dice_0: 3.567  loss_ce_1: 2.301  loss_mask_1: 0.6382  loss_dice_1: 3.442  loss_ce_2: 2.195  loss_mask_2: 0.6357  loss_dice_2: 3.368  loss_ce_3: 2.153  loss_mask_3: 0.6282  loss_dice_3: 3.325  loss_ce_4: 2.13  loss_mask_4: 0.6271  loss_dice_4: 3.32  loss_ce_5: 2.098  loss_mask_5: 0.6285  loss_dice_5: 3.32  loss_ce_6: 2.117  loss_mask_6: 0.6256  loss_dice_6: 3.309  loss_ce_7: 2.09  loss_mask_7: 0.6263  loss_dice_7: 3.31  loss_ce_8: 2.108  loss_mask_8: 0.6251  loss_dice_8: 3.306  time: 1.6940  data_time: 0.3451  lr: 6.0822e-06  max_mem: 17674M
[01/19 09:26:21] d2.utils.events INFO:  eta: 10:47:08  iter: 16999  total_loss: 61.77  loss_ce: 2.038  loss_mask: 0.6269  loss_dice: 3.317  loss_ce_0: 3.503  loss_mask_0: 0.6443  loss_dice_0: 3.569  loss_ce_1: 2.219  loss_mask_1: 0.6373  loss_dice_1: 3.453  loss_ce_2: 2.117  loss_mask_2: 0.6326  loss_dice_2: 3.372  loss_ce_3: 2.088  loss_mask_3: 0.6276  loss_dice_3: 3.332  loss_ce_4: 2.07  loss_mask_4: 0.6294  loss_dice_4: 3.33  loss_ce_5: 2.055  loss_mask_5: 0.6281  loss_dice_5: 3.326  loss_ce_6: 2.045  loss_mask_6: 0.6251  loss_dice_6: 3.308  loss_ce_7: 2.045  loss_mask_7: 0.627  loss_dice_7: 3.313  loss_ce_8: 2.015  loss_mask_8: 0.6286  loss_dice_8: 3.308  time: 1.6940  data_time: 0.3397  lr: 6.0774e-06  max_mem: 17674M
[01/19 09:26:55] d2.utils.events INFO:  eta: 10:46:43  iter: 17019  total_loss: 60.88  loss_ce: 1.952  loss_mask: 0.6122  loss_dice: 3.24  loss_ce_0: 3.447  loss_mask_0: 0.637  loss_dice_0: 3.522  loss_ce_1: 2.207  loss_mask_1: 0.6217  loss_dice_1: 3.388  loss_ce_2: 2.091  loss_mask_2: 0.6208  loss_dice_2: 3.322  loss_ce_3: 2.033  loss_mask_3: 0.6163  loss_dice_3: 3.274  loss_ce_4: 1.986  loss_mask_4: 0.6155  loss_dice_4: 3.267  loss_ce_5: 1.98  loss_mask_5: 0.6174  loss_dice_5: 3.258  loss_ce_6: 1.974  loss_mask_6: 0.6142  loss_dice_6: 3.247  loss_ce_7: 1.951  loss_mask_7: 0.6137  loss_dice_7: 3.254  loss_ce_8: 1.947  loss_mask_8: 0.6138  loss_dice_8: 3.251  time: 1.6940  data_time: 0.3338  lr: 6.0726e-06  max_mem: 17674M
[01/19 09:27:30] d2.utils.events INFO:  eta: 10:46:10  iter: 17039  total_loss: 61  loss_ce: 1.925  loss_mask: 0.6108  loss_dice: 3.298  loss_ce_0: 3.5  loss_mask_0: 0.6403  loss_dice_0: 3.578  loss_ce_1: 2.172  loss_mask_1: 0.6213  loss_dice_1: 3.44  loss_ce_2: 2.07  loss_mask_2: 0.6161  loss_dice_2: 3.36  loss_ce_3: 2.036  loss_mask_3: 0.609  loss_dice_3: 3.308  loss_ce_4: 1.991  loss_mask_4: 0.6122  loss_dice_4: 3.309  loss_ce_5: 1.956  loss_mask_5: 0.6116  loss_dice_5: 3.302  loss_ce_6: 1.945  loss_mask_6: 0.6097  loss_dice_6: 3.296  loss_ce_7: 1.915  loss_mask_7: 0.6112  loss_dice_7: 3.298  loss_ce_8: 1.929  loss_mask_8: 0.6117  loss_dice_8: 3.299  time: 1.6940  data_time: 0.3522  lr: 6.0679e-06  max_mem: 17674M
[01/19 09:28:04] d2.utils.events INFO:  eta: 10:45:50  iter: 17059  total_loss: 60.91  loss_ce: 1.878  loss_mask: 0.6147  loss_dice: 3.287  loss_ce_0: 3.419  loss_mask_0: 0.635  loss_dice_0: 3.557  loss_ce_1: 2.182  loss_mask_1: 0.6247  loss_dice_1: 3.422  loss_ce_2: 2.034  loss_mask_2: 0.6198  loss_dice_2: 3.345  loss_ce_3: 1.986  loss_mask_3: 0.6114  loss_dice_3: 3.297  loss_ce_4: 1.93  loss_mask_4: 0.6146  loss_dice_4: 3.298  loss_ce_5: 1.926  loss_mask_5: 0.6154  loss_dice_5: 3.296  loss_ce_6: 1.904  loss_mask_6: 0.6148  loss_dice_6: 3.285  loss_ce_7: 1.891  loss_mask_7: 0.6136  loss_dice_7: 3.292  loss_ce_8: 1.904  loss_mask_8: 0.6123  loss_dice_8: 3.286  time: 1.6940  data_time: 0.3549  lr: 6.0631e-06  max_mem: 17674M
[01/19 09:28:37] d2.utils.events INFO:  eta: 10:45:07  iter: 17079  total_loss: 60.58  loss_ce: 1.917  loss_mask: 0.6195  loss_dice: 3.244  loss_ce_0: 3.431  loss_mask_0: 0.6479  loss_dice_0: 3.529  loss_ce_1: 2.212  loss_mask_1: 0.6288  loss_dice_1: 3.389  loss_ce_2: 2.062  loss_mask_2: 0.6211  loss_dice_2: 3.315  loss_ce_3: 2.016  loss_mask_3: 0.6181  loss_dice_3: 3.265  loss_ce_4: 1.985  loss_mask_4: 0.6201  loss_dice_4: 3.258  loss_ce_5: 1.948  loss_mask_5: 0.6179  loss_dice_5: 3.256  loss_ce_6: 1.935  loss_mask_6: 0.6194  loss_dice_6: 3.246  loss_ce_7: 1.929  loss_mask_7: 0.6191  loss_dice_7: 3.244  loss_ce_8: 1.906  loss_mask_8: 0.6212  loss_dice_8: 3.252  time: 1.6940  data_time: 0.3255  lr: 6.0584e-06  max_mem: 17674M
[01/19 09:29:11] d2.utils.events INFO:  eta: 10:44:33  iter: 17099  total_loss: 61.26  loss_ce: 1.99  loss_mask: 0.6263  loss_dice: 3.244  loss_ce_0: 3.402  loss_mask_0: 0.6413  loss_dice_0: 3.519  loss_ce_1: 2.222  loss_mask_1: 0.6303  loss_dice_1: 3.373  loss_ce_2: 2.099  loss_mask_2: 0.6257  loss_dice_2: 3.299  loss_ce_3: 2.046  loss_mask_3: 0.6247  loss_dice_3: 3.26  loss_ce_4: 2.035  loss_mask_4: 0.6255  loss_dice_4: 3.254  loss_ce_5: 2.001  loss_mask_5: 0.6276  loss_dice_5: 3.258  loss_ce_6: 2.01  loss_mask_6: 0.6255  loss_dice_6: 3.245  loss_ce_7: 1.99  loss_mask_7: 0.6258  loss_dice_7: 3.252  loss_ce_8: 1.994  loss_mask_8: 0.6254  loss_dice_8: 3.249  time: 1.6940  data_time: 0.3311  lr: 6.0536e-06  max_mem: 17674M
[01/19 09:29:44] d2.utils.events INFO:  eta: 10:43:55  iter: 17119  total_loss: 61.21  loss_ce: 2.009  loss_mask: 0.6319  loss_dice: 3.255  loss_ce_0: 3.517  loss_mask_0: 0.6556  loss_dice_0: 3.544  loss_ce_1: 2.242  loss_mask_1: 0.6363  loss_dice_1: 3.407  loss_ce_2: 2.145  loss_mask_2: 0.6337  loss_dice_2: 3.327  loss_ce_3: 2.112  loss_mask_3: 0.631  loss_dice_3: 3.284  loss_ce_4: 2.069  loss_mask_4: 0.6289  loss_dice_4: 3.275  loss_ce_5: 2.036  loss_mask_5: 0.6302  loss_dice_5: 3.269  loss_ce_6: 2.031  loss_mask_6: 0.6304  loss_dice_6: 3.262  loss_ce_7: 2.017  loss_mask_7: 0.6316  loss_dice_7: 3.259  loss_ce_8: 2.016  loss_mask_8: 0.6314  loss_dice_8: 3.259  time: 1.6940  data_time: 0.3278  lr: 6.0489e-06  max_mem: 17674M
[01/19 09:30:18] d2.utils.events INFO:  eta: 10:43:34  iter: 17139  total_loss: 60.51  loss_ce: 1.913  loss_mask: 0.6198  loss_dice: 3.233  loss_ce_0: 3.506  loss_mask_0: 0.6401  loss_dice_0: 3.518  loss_ce_1: 2.209  loss_mask_1: 0.6235  loss_dice_1: 3.374  loss_ce_2: 2.063  loss_mask_2: 0.6223  loss_dice_2: 3.303  loss_ce_3: 2.008  loss_mask_3: 0.6185  loss_dice_3: 3.261  loss_ce_4: 1.98  loss_mask_4: 0.6226  loss_dice_4: 3.253  loss_ce_5: 1.949  loss_mask_5: 0.6198  loss_dice_5: 3.245  loss_ce_6: 1.933  loss_mask_6: 0.6199  loss_dice_6: 3.235  loss_ce_7: 1.901  loss_mask_7: 0.6197  loss_dice_7: 3.24  loss_ce_8: 1.903  loss_mask_8: 0.6221  loss_dice_8: 3.241  time: 1.6940  data_time: 0.3414  lr: 6.0441e-06  max_mem: 17674M
[01/19 09:30:52] d2.utils.events INFO:  eta: 10:43:00  iter: 17159  total_loss: 61.94  loss_ce: 1.962  loss_mask: 0.6157  loss_dice: 3.293  loss_ce_0: 3.533  loss_mask_0: 0.6427  loss_dice_0: 3.557  loss_ce_1: 2.196  loss_mask_1: 0.6286  loss_dice_1: 3.429  loss_ce_2: 2.066  loss_mask_2: 0.6214  loss_dice_2: 3.362  loss_ce_3: 2.025  loss_mask_3: 0.6179  loss_dice_3: 3.313  loss_ce_4: 2.014  loss_mask_4: 0.6199  loss_dice_4: 3.312  loss_ce_5: 1.982  loss_mask_5: 0.6193  loss_dice_5: 3.307  loss_ce_6: 1.994  loss_mask_6: 0.6117  loss_dice_6: 3.296  loss_ce_7: 1.978  loss_mask_7: 0.6151  loss_dice_7: 3.296  loss_ce_8: 1.97  loss_mask_8: 0.6157  loss_dice_8: 3.295  time: 1.6940  data_time: 0.3518  lr: 6.0393e-06  max_mem: 17674M
[01/19 09:31:26] d2.utils.events INFO:  eta: 10:42:03  iter: 17179  total_loss: 60.91  loss_ce: 1.939  loss_mask: 0.6345  loss_dice: 3.319  loss_ce_0: 3.423  loss_mask_0: 0.6585  loss_dice_0: 3.57  loss_ce_1: 2.185  loss_mask_1: 0.6406  loss_dice_1: 3.441  loss_ce_2: 2.05  loss_mask_2: 0.6333  loss_dice_2: 3.376  loss_ce_3: 1.992  loss_mask_3: 0.6276  loss_dice_3: 3.334  loss_ce_4: 1.982  loss_mask_4: 0.6301  loss_dice_4: 3.328  loss_ce_5: 1.975  loss_mask_5: 0.6302  loss_dice_5: 3.321  loss_ce_6: 1.975  loss_mask_6: 0.6303  loss_dice_6: 3.313  loss_ce_7: 1.954  loss_mask_7: 0.6331  loss_dice_7: 3.311  loss_ce_8: 1.938  loss_mask_8: 0.6346  loss_dice_8: 3.323  time: 1.6939  data_time: 0.3483  lr: 6.0346e-06  max_mem: 17674M
[01/19 09:31:58] d2.utils.events INFO:  eta: 10:40:55  iter: 17199  total_loss: 61.94  loss_ce: 2.048  loss_mask: 0.6362  loss_dice: 3.227  loss_ce_0: 3.475  loss_mask_0: 0.667  loss_dice_0: 3.515  loss_ce_1: 2.283  loss_mask_1: 0.654  loss_dice_1: 3.383  loss_ce_2: 2.151  loss_mask_2: 0.6473  loss_dice_2: 3.299  loss_ce_3: 2.145  loss_mask_3: 0.6419  loss_dice_3: 3.259  loss_ce_4: 2.102  loss_mask_4: 0.641  loss_dice_4: 3.253  loss_ce_5: 2.071  loss_mask_5: 0.6421  loss_dice_5: 3.253  loss_ce_6: 2.058  loss_mask_6: 0.6372  loss_dice_6: 3.23  loss_ce_7: 2.051  loss_mask_7: 0.6389  loss_dice_7: 3.232  loss_ce_8: 2.055  loss_mask_8: 0.6361  loss_dice_8: 3.241  time: 1.6939  data_time: 0.3058  lr: 6.0298e-06  max_mem: 17674M
[01/19 09:32:33] d2.utils.events INFO:  eta: 10:40:34  iter: 17219  total_loss: 60.83  loss_ce: 1.958  loss_mask: 0.6175  loss_dice: 3.285  loss_ce_0: 3.469  loss_mask_0: 0.6351  loss_dice_0: 3.558  loss_ce_1: 2.171  loss_mask_1: 0.6299  loss_dice_1: 3.424  loss_ce_2: 2.057  loss_mask_2: 0.6243  loss_dice_2: 3.353  loss_ce_3: 2.008  loss_mask_3: 0.6132  loss_dice_3: 3.313  loss_ce_4: 1.986  loss_mask_4: 0.6126  loss_dice_4: 3.302  loss_ce_5: 1.963  loss_mask_5: 0.6136  loss_dice_5: 3.303  loss_ce_6: 1.988  loss_mask_6: 0.6154  loss_dice_6: 3.285  loss_ce_7: 1.947  loss_mask_7: 0.6153  loss_dice_7: 3.286  loss_ce_8: 1.943  loss_mask_8: 0.6151  loss_dice_8: 3.287  time: 1.6939  data_time: 0.3360  lr: 6.0251e-06  max_mem: 17674M
[01/19 09:33:07] d2.utils.events INFO:  eta: 10:40:21  iter: 17239  total_loss: 61.46  loss_ce: 1.982  loss_mask: 0.6168  loss_dice: 3.271  loss_ce_0: 3.466  loss_mask_0: 0.646  loss_dice_0: 3.572  loss_ce_1: 2.253  loss_mask_1: 0.633  loss_dice_1: 3.409  loss_ce_2: 2.133  loss_mask_2: 0.6283  loss_dice_2: 3.345  loss_ce_3: 2.076  loss_mask_3: 0.6211  loss_dice_3: 3.292  loss_ce_4: 2.048  loss_mask_4: 0.6211  loss_dice_4: 3.291  loss_ce_5: 2.015  loss_mask_5: 0.6226  loss_dice_5: 3.289  loss_ce_6: 1.992  loss_mask_6: 0.6181  loss_dice_6: 3.283  loss_ce_7: 1.977  loss_mask_7: 0.6183  loss_dice_7: 3.275  loss_ce_8: 1.985  loss_mask_8: 0.6174  loss_dice_8: 3.28  time: 1.6939  data_time: 0.3552  lr: 6.0203e-06  max_mem: 17674M
[01/19 09:33:41] d2.utils.events INFO:  eta: 10:39:19  iter: 17259  total_loss: 61.05  loss_ce: 1.928  loss_mask: 0.6115  loss_dice: 3.238  loss_ce_0: 3.439  loss_mask_0: 0.6309  loss_dice_0: 3.537  loss_ce_1: 2.175  loss_mask_1: 0.6219  loss_dice_1: 3.391  loss_ce_2: 2.045  loss_mask_2: 0.6124  loss_dice_2: 3.318  loss_ce_3: 2.007  loss_mask_3: 0.6084  loss_dice_3: 3.259  loss_ce_4: 1.97  loss_mask_4: 0.6088  loss_dice_4: 3.258  loss_ce_5: 1.959  loss_mask_5: 0.6118  loss_dice_5: 3.249  loss_ce_6: 1.953  loss_mask_6: 0.6122  loss_dice_6: 3.243  loss_ce_7: 1.938  loss_mask_7: 0.614  loss_dice_7: 3.244  loss_ce_8: 1.911  loss_mask_8: 0.6144  loss_dice_8: 3.24  time: 1.6939  data_time: 0.3387  lr: 6.0155e-06  max_mem: 17674M
[01/19 09:34:15] d2.utils.events INFO:  eta: 10:39:05  iter: 17279  total_loss: 61.47  loss_ce: 1.962  loss_mask: 0.6247  loss_dice: 3.282  loss_ce_0: 3.479  loss_mask_0: 0.6567  loss_dice_0: 3.551  loss_ce_1: 2.168  loss_mask_1: 0.6393  loss_dice_1: 3.417  loss_ce_2: 2.058  loss_mask_2: 0.6334  loss_dice_2: 3.353  loss_ce_3: 2.026  loss_mask_3: 0.63  loss_dice_3: 3.306  loss_ce_4: 1.973  loss_mask_4: 0.6294  loss_dice_4: 3.303  loss_ce_5: 1.955  loss_mask_5: 0.629  loss_dice_5: 3.29  loss_ce_6: 1.946  loss_mask_6: 0.6257  loss_dice_6: 3.287  loss_ce_7: 1.947  loss_mask_7: 0.6246  loss_dice_7: 3.279  loss_ce_8: 1.929  loss_mask_8: 0.6241  loss_dice_8: 3.284  time: 1.6939  data_time: 0.3540  lr: 6.0108e-06  max_mem: 17674M
[01/19 09:34:48] d2.utils.events INFO:  eta: 10:38:15  iter: 17299  total_loss: 61.27  loss_ce: 1.983  loss_mask: 0.632  loss_dice: 3.26  loss_ce_0: 3.467  loss_mask_0: 0.6544  loss_dice_0: 3.531  loss_ce_1: 2.259  loss_mask_1: 0.6444  loss_dice_1: 3.394  loss_ce_2: 2.127  loss_mask_2: 0.6308  loss_dice_2: 3.327  loss_ce_3: 2.061  loss_mask_3: 0.6308  loss_dice_3: 3.28  loss_ce_4: 2.01  loss_mask_4: 0.6319  loss_dice_4: 3.269  loss_ce_5: 1.998  loss_mask_5: 0.6335  loss_dice_5: 3.264  loss_ce_6: 1.985  loss_mask_6: 0.6344  loss_dice_6: 3.253  loss_ce_7: 1.972  loss_mask_7: 0.6342  loss_dice_7: 3.261  loss_ce_8: 1.973  loss_mask_8: 0.6297  loss_dice_8: 3.259  time: 1.6939  data_time: 0.3487  lr: 6.006e-06  max_mem: 17674M
[01/19 09:35:22] d2.utils.events INFO:  eta: 10:37:34  iter: 17319  total_loss: 60.73  loss_ce: 1.984  loss_mask: 0.6289  loss_dice: 3.282  loss_ce_0: 3.418  loss_mask_0: 0.6473  loss_dice_0: 3.551  loss_ce_1: 2.209  loss_mask_1: 0.632  loss_dice_1: 3.418  loss_ce_2: 2.088  loss_mask_2: 0.6283  loss_dice_2: 3.356  loss_ce_3: 2.047  loss_mask_3: 0.6254  loss_dice_3: 3.308  loss_ce_4: 2.012  loss_mask_4: 0.6252  loss_dice_4: 3.305  loss_ce_5: 1.966  loss_mask_5: 0.6255  loss_dice_5: 3.302  loss_ce_6: 1.956  loss_mask_6: 0.626  loss_dice_6: 3.291  loss_ce_7: 1.947  loss_mask_7: 0.6265  loss_dice_7: 3.288  loss_ce_8: 1.974  loss_mask_8: 0.6281  loss_dice_8: 3.29  time: 1.6939  data_time: 0.3271  lr: 6.0013e-06  max_mem: 17674M
[01/19 09:35:56] d2.utils.events INFO:  eta: 10:37:00  iter: 17339  total_loss: 61.88  loss_ce: 1.978  loss_mask: 0.626  loss_dice: 3.276  loss_ce_0: 3.489  loss_mask_0: 0.6599  loss_dice_0: 3.555  loss_ce_1: 2.242  loss_mask_1: 0.6359  loss_dice_1: 3.413  loss_ce_2: 2.136  loss_mask_2: 0.6326  loss_dice_2: 3.347  loss_ce_3: 2.054  loss_mask_3: 0.6299  loss_dice_3: 3.294  loss_ce_4: 2.015  loss_mask_4: 0.628  loss_dice_4: 3.295  loss_ce_5: 1.995  loss_mask_5: 0.6289  loss_dice_5: 3.288  loss_ce_6: 2.016  loss_mask_6: 0.6267  loss_dice_6: 3.284  loss_ce_7: 1.983  loss_mask_7: 0.6287  loss_dice_7: 3.277  loss_ce_8: 1.969  loss_mask_8: 0.6258  loss_dice_8: 3.278  time: 1.6939  data_time: 0.3518  lr: 5.9965e-06  max_mem: 17674M
[01/19 09:36:30] d2.utils.events INFO:  eta: 10:36:52  iter: 17359  total_loss: 61.83  loss_ce: 2.009  loss_mask: 0.6273  loss_dice: 3.302  loss_ce_0: 3.454  loss_mask_0: 0.6468  loss_dice_0: 3.564  loss_ce_1: 2.249  loss_mask_1: 0.6373  loss_dice_1: 3.441  loss_ce_2: 2.133  loss_mask_2: 0.633  loss_dice_2: 3.378  loss_ce_3: 2.093  loss_mask_3: 0.631  loss_dice_3: 3.33  loss_ce_4: 2.057  loss_mask_4: 0.6318  loss_dice_4: 3.321  loss_ce_5: 2.026  loss_mask_5: 0.63  loss_dice_5: 3.324  loss_ce_6: 2.028  loss_mask_6: 0.6279  loss_dice_6: 3.311  loss_ce_7: 2.035  loss_mask_7: 0.6262  loss_dice_7: 3.314  loss_ce_8: 2.017  loss_mask_8: 0.6285  loss_dice_8: 3.305  time: 1.6939  data_time: 0.3499  lr: 5.9917e-06  max_mem: 17674M
[01/19 09:37:04] d2.utils.events INFO:  eta: 10:36:30  iter: 17379  total_loss: 61.23  loss_ce: 1.992  loss_mask: 0.6233  loss_dice: 3.282  loss_ce_0: 3.456  loss_mask_0: 0.6466  loss_dice_0: 3.561  loss_ce_1: 2.21  loss_mask_1: 0.6297  loss_dice_1: 3.431  loss_ce_2: 2.094  loss_mask_2: 0.6253  loss_dice_2: 3.354  loss_ce_3: 2.087  loss_mask_3: 0.6225  loss_dice_3: 3.304  loss_ce_4: 2.018  loss_mask_4: 0.6228  loss_dice_4: 3.301  loss_ce_5: 2.033  loss_mask_5: 0.6227  loss_dice_5: 3.296  loss_ce_6: 2.035  loss_mask_6: 0.6232  loss_dice_6: 3.285  loss_ce_7: 1.997  loss_mask_7: 0.6232  loss_dice_7: 3.284  loss_ce_8: 1.987  loss_mask_8: 0.6263  loss_dice_8: 3.289  time: 1.6939  data_time: 0.3511  lr: 5.987e-06  max_mem: 17674M
[01/19 09:37:38] d2.utils.events INFO:  eta: 10:35:51  iter: 17399  total_loss: 60.69  loss_ce: 1.875  loss_mask: 0.6289  loss_dice: 3.285  loss_ce_0: 3.421  loss_mask_0: 0.653  loss_dice_0: 3.562  loss_ce_1: 2.154  loss_mask_1: 0.6353  loss_dice_1: 3.421  loss_ce_2: 2.019  loss_mask_2: 0.6312  loss_dice_2: 3.353  loss_ce_3: 1.978  loss_mask_3: 0.6244  loss_dice_3: 3.309  loss_ce_4: 1.922  loss_mask_4: 0.6291  loss_dice_4: 3.302  loss_ce_5: 1.924  loss_mask_5: 0.6303  loss_dice_5: 3.293  loss_ce_6: 1.927  loss_mask_6: 0.6306  loss_dice_6: 3.281  loss_ce_7: 1.892  loss_mask_7: 0.6315  loss_dice_7: 3.286  loss_ce_8: 1.893  loss_mask_8: 0.6308  loss_dice_8: 3.289  time: 1.6939  data_time: 0.3451  lr: 5.9822e-06  max_mem: 17674M
[01/19 09:38:11] d2.utils.events INFO:  eta: 10:35:17  iter: 17419  total_loss: 60.73  loss_ce: 1.897  loss_mask: 0.6229  loss_dice: 3.256  loss_ce_0: 3.398  loss_mask_0: 0.6498  loss_dice_0: 3.541  loss_ce_1: 2.151  loss_mask_1: 0.6325  loss_dice_1: 3.397  loss_ce_2: 2.026  loss_mask_2: 0.6293  loss_dice_2: 3.334  loss_ce_3: 1.952  loss_mask_3: 0.6268  loss_dice_3: 3.279  loss_ce_4: 1.937  loss_mask_4: 0.6241  loss_dice_4: 3.275  loss_ce_5: 1.895  loss_mask_5: 0.6257  loss_dice_5: 3.278  loss_ce_6: 1.896  loss_mask_6: 0.6258  loss_dice_6: 3.262  loss_ce_7: 1.882  loss_mask_7: 0.6225  loss_dice_7: 3.259  loss_ce_8: 1.868  loss_mask_8: 0.6241  loss_dice_8: 3.26  time: 1.6939  data_time: 0.3388  lr: 5.9774e-06  max_mem: 17674M
[01/19 09:38:46] d2.utils.events INFO:  eta: 10:34:48  iter: 17439  total_loss: 61.53  loss_ce: 1.976  loss_mask: 0.6233  loss_dice: 3.287  loss_ce_0: 3.473  loss_mask_0: 0.653  loss_dice_0: 3.55  loss_ce_1: 2.188  loss_mask_1: 0.6348  loss_dice_1: 3.418  loss_ce_2: 2.12  loss_mask_2: 0.6316  loss_dice_2: 3.347  loss_ce_3: 2.046  loss_mask_3: 0.6278  loss_dice_3: 3.302  loss_ce_4: 2.018  loss_mask_4: 0.6288  loss_dice_4: 3.301  loss_ce_5: 1.994  loss_mask_5: 0.6252  loss_dice_5: 3.3  loss_ce_6: 1.993  loss_mask_6: 0.6247  loss_dice_6: 3.288  loss_ce_7: 1.979  loss_mask_7: 0.6234  loss_dice_7: 3.288  loss_ce_8: 1.973  loss_mask_8: 0.6249  loss_dice_8: 3.287  time: 1.6939  data_time: 0.3500  lr: 5.9727e-06  max_mem: 17674M
[01/19 09:39:20] d2.utils.events INFO:  eta: 10:34:15  iter: 17459  total_loss: 61.46  loss_ce: 1.989  loss_mask: 0.6305  loss_dice: 3.25  loss_ce_0: 3.49  loss_mask_0: 0.6481  loss_dice_0: 3.547  loss_ce_1: 2.221  loss_mask_1: 0.6328  loss_dice_1: 3.405  loss_ce_2: 2.099  loss_mask_2: 0.6305  loss_dice_2: 3.33  loss_ce_3: 2.071  loss_mask_3: 0.6287  loss_dice_3: 3.281  loss_ce_4: 2.058  loss_mask_4: 0.6292  loss_dice_4: 3.274  loss_ce_5: 2.025  loss_mask_5: 0.6284  loss_dice_5: 3.266  loss_ce_6: 2.018  loss_mask_6: 0.6278  loss_dice_6: 3.254  loss_ce_7: 1.991  loss_mask_7: 0.6275  loss_dice_7: 3.252  loss_ce_8: 1.99  loss_mask_8: 0.6297  loss_dice_8: 3.248  time: 1.6939  data_time: 0.3580  lr: 5.9679e-06  max_mem: 17674M
[01/19 09:39:53] d2.utils.events INFO:  eta: 10:33:15  iter: 17479  total_loss: 61.79  loss_ce: 1.926  loss_mask: 0.6381  loss_dice: 3.308  loss_ce_0: 3.425  loss_mask_0: 0.6552  loss_dice_0: 3.577  loss_ce_1: 2.213  loss_mask_1: 0.6489  loss_dice_1: 3.435  loss_ce_2: 2.066  loss_mask_2: 0.6421  loss_dice_2: 3.371  loss_ce_3: 2.024  loss_mask_3: 0.6334  loss_dice_3: 3.329  loss_ce_4: 1.985  loss_mask_4: 0.6366  loss_dice_4: 3.326  loss_ce_5: 1.956  loss_mask_5: 0.6381  loss_dice_5: 3.329  loss_ce_6: 1.956  loss_mask_6: 0.6342  loss_dice_6: 3.315  loss_ce_7: 1.927  loss_mask_7: 0.6353  loss_dice_7: 3.316  loss_ce_8: 1.924  loss_mask_8: 0.6378  loss_dice_8: 3.31  time: 1.6939  data_time: 0.3408  lr: 5.9631e-06  max_mem: 17674M
[01/19 09:40:27] d2.utils.events INFO:  eta: 10:33:03  iter: 17499  total_loss: 60.65  loss_ce: 1.894  loss_mask: 0.6226  loss_dice: 3.246  loss_ce_0: 3.411  loss_mask_0: 0.6487  loss_dice_0: 3.528  loss_ce_1: 2.138  loss_mask_1: 0.635  loss_dice_1: 3.393  loss_ce_2: 2.031  loss_mask_2: 0.6299  loss_dice_2: 3.324  loss_ce_3: 1.985  loss_mask_3: 0.6248  loss_dice_3: 3.275  loss_ce_4: 1.936  loss_mask_4: 0.6253  loss_dice_4: 3.274  loss_ce_5: 1.922  loss_mask_5: 0.6268  loss_dice_5: 3.269  loss_ce_6: 1.935  loss_mask_6: 0.6263  loss_dice_6: 3.255  loss_ce_7: 1.906  loss_mask_7: 0.6273  loss_dice_7: 3.252  loss_ce_8: 1.907  loss_mask_8: 0.6264  loss_dice_8: 3.252  time: 1.6939  data_time: 0.3565  lr: 5.9584e-06  max_mem: 17674M
[01/19 09:41:01] d2.utils.events INFO:  eta: 10:32:00  iter: 17519  total_loss: 59.95  loss_ce: 1.87  loss_mask: 0.6273  loss_dice: 3.235  loss_ce_0: 3.453  loss_mask_0: 0.6404  loss_dice_0: 3.514  loss_ce_1: 2.154  loss_mask_1: 0.6314  loss_dice_1: 3.383  loss_ce_2: 2.017  loss_mask_2: 0.6276  loss_dice_2: 3.303  loss_ce_3: 1.945  loss_mask_3: 0.6253  loss_dice_3: 3.267  loss_ce_4: 1.927  loss_mask_4: 0.6274  loss_dice_4: 3.256  loss_ce_5: 1.905  loss_mask_5: 0.6279  loss_dice_5: 3.259  loss_ce_6: 1.88  loss_mask_6: 0.6285  loss_dice_6: 3.248  loss_ce_7: 1.872  loss_mask_7: 0.6272  loss_dice_7: 3.25  loss_ce_8: 1.87  loss_mask_8: 0.626  loss_dice_8: 3.245  time: 1.6939  data_time: 0.3244  lr: 5.9536e-06  max_mem: 17674M
[01/19 09:41:35] d2.utils.events INFO:  eta: 10:31:30  iter: 17539  total_loss: 61.87  loss_ce: 2.037  loss_mask: 0.6117  loss_dice: 3.299  loss_ce_0: 3.44  loss_mask_0: 0.6362  loss_dice_0: 3.577  loss_ce_1: 2.206  loss_mask_1: 0.6182  loss_dice_1: 3.447  loss_ce_2: 2.126  loss_mask_2: 0.6227  loss_dice_2: 3.373  loss_ce_3: 2.069  loss_mask_3: 0.6152  loss_dice_3: 3.326  loss_ce_4: 2.043  loss_mask_4: 0.6158  loss_dice_4: 3.318  loss_ce_5: 2.039  loss_mask_5: 0.6165  loss_dice_5: 3.309  loss_ce_6: 2.034  loss_mask_6: 0.6118  loss_dice_6: 3.298  loss_ce_7: 2.026  loss_mask_7: 0.6139  loss_dice_7: 3.295  loss_ce_8: 2.041  loss_mask_8: 0.6128  loss_dice_8: 3.295  time: 1.6939  data_time: 0.3397  lr: 5.9488e-06  max_mem: 17674M
[01/19 09:42:09] d2.utils.events INFO:  eta: 10:30:56  iter: 17559  total_loss: 60.73  loss_ce: 1.931  loss_mask: 0.6359  loss_dice: 3.252  loss_ce_0: 3.478  loss_mask_0: 0.6605  loss_dice_0: 3.519  loss_ce_1: 2.179  loss_mask_1: 0.6445  loss_dice_1: 3.388  loss_ce_2: 2.031  loss_mask_2: 0.6355  loss_dice_2: 3.316  loss_ce_3: 1.988  loss_mask_3: 0.6303  loss_dice_3: 3.275  loss_ce_4: 1.975  loss_mask_4: 0.6317  loss_dice_4: 3.27  loss_ce_5: 1.942  loss_mask_5: 0.6323  loss_dice_5: 3.271  loss_ce_6: 1.947  loss_mask_6: 0.6309  loss_dice_6: 3.252  loss_ce_7: 1.94  loss_mask_7: 0.6331  loss_dice_7: 3.255  loss_ce_8: 1.935  loss_mask_8: 0.6352  loss_dice_8: 3.249  time: 1.6939  data_time: 0.3417  lr: 5.9441e-06  max_mem: 17674M
[01/19 09:42:43] d2.utils.events INFO:  eta: 10:30:41  iter: 17579  total_loss: 61.17  loss_ce: 1.985  loss_mask: 0.6261  loss_dice: 3.3  loss_ce_0: 3.455  loss_mask_0: 0.645  loss_dice_0: 3.563  loss_ce_1: 2.189  loss_mask_1: 0.6393  loss_dice_1: 3.435  loss_ce_2: 2.086  loss_mask_2: 0.6337  loss_dice_2: 3.361  loss_ce_3: 2.052  loss_mask_3: 0.6311  loss_dice_3: 3.319  loss_ce_4: 2.02  loss_mask_4: 0.6306  loss_dice_4: 3.313  loss_ce_5: 2.006  loss_mask_5: 0.6296  loss_dice_5: 3.319  loss_ce_6: 2.011  loss_mask_6: 0.6259  loss_dice_6: 3.299  loss_ce_7: 2.015  loss_mask_7: 0.6297  loss_dice_7: 3.294  loss_ce_8: 1.992  loss_mask_8: 0.6271  loss_dice_8: 3.301  time: 1.6939  data_time: 0.3457  lr: 5.9393e-06  max_mem: 17674M
[01/19 09:43:17] d2.utils.events INFO:  eta: 10:30:22  iter: 17599  total_loss: 61.09  loss_ce: 1.95  loss_mask: 0.632  loss_dice: 3.266  loss_ce_0: 3.453  loss_mask_0: 0.661  loss_dice_0: 3.546  loss_ce_1: 2.218  loss_mask_1: 0.6432  loss_dice_1: 3.409  loss_ce_2: 2.06  loss_mask_2: 0.6357  loss_dice_2: 3.342  loss_ce_3: 2.017  loss_mask_3: 0.6328  loss_dice_3: 3.299  loss_ce_4: 1.952  loss_mask_4: 0.633  loss_dice_4: 3.29  loss_ce_5: 1.957  loss_mask_5: 0.6349  loss_dice_5: 3.288  loss_ce_6: 1.933  loss_mask_6: 0.635  loss_dice_6: 3.274  loss_ce_7: 1.93  loss_mask_7: 0.6313  loss_dice_7: 3.279  loss_ce_8: 1.925  loss_mask_8: 0.6315  loss_dice_8: 3.277  time: 1.6939  data_time: 0.3489  lr: 5.9345e-06  max_mem: 17674M
[01/19 09:43:51] d2.utils.events INFO:  eta: 10:30:01  iter: 17619  total_loss: 60.82  loss_ce: 1.871  loss_mask: 0.6272  loss_dice: 3.29  loss_ce_0: 3.38  loss_mask_0: 0.6489  loss_dice_0: 3.574  loss_ce_1: 2.15  loss_mask_1: 0.6405  loss_dice_1: 3.414  loss_ce_2: 2.015  loss_mask_2: 0.6342  loss_dice_2: 3.341  loss_ce_3: 1.989  loss_mask_3: 0.6302  loss_dice_3: 3.305  loss_ce_4: 1.933  loss_mask_4: 0.6295  loss_dice_4: 3.314  loss_ce_5: 1.918  loss_mask_5: 0.6281  loss_dice_5: 3.305  loss_ce_6: 1.899  loss_mask_6: 0.6251  loss_dice_6: 3.293  loss_ce_7: 1.87  loss_mask_7: 0.6252  loss_dice_7: 3.293  loss_ce_8: 1.881  loss_mask_8: 0.6277  loss_dice_8: 3.299  time: 1.6939  data_time: 0.3430  lr: 5.9298e-06  max_mem: 17674M
[01/19 09:44:25] d2.utils.events INFO:  eta: 10:29:20  iter: 17639  total_loss: 61.64  loss_ce: 1.977  loss_mask: 0.6266  loss_dice: 3.24  loss_ce_0: 3.446  loss_mask_0: 0.6526  loss_dice_0: 3.515  loss_ce_1: 2.226  loss_mask_1: 0.6404  loss_dice_1: 3.383  loss_ce_2: 2.135  loss_mask_2: 0.6362  loss_dice_2: 3.305  loss_ce_3: 2.095  loss_mask_3: 0.6313  loss_dice_3: 3.245  loss_ce_4: 2.026  loss_mask_4: 0.6296  loss_dice_4: 3.247  loss_ce_5: 2.001  loss_mask_5: 0.6291  loss_dice_5: 3.245  loss_ce_6: 1.99  loss_mask_6: 0.6326  loss_dice_6: 3.235  loss_ce_7: 1.978  loss_mask_7: 0.6327  loss_dice_7: 3.239  loss_ce_8: 1.989  loss_mask_8: 0.6293  loss_dice_8: 3.24  time: 1.6939  data_time: 0.3396  lr: 5.925e-06  max_mem: 17674M
[01/19 09:44:58] d2.utils.events INFO:  eta: 10:28:33  iter: 17659  total_loss: 62.23  loss_ce: 2.025  loss_mask: 0.624  loss_dice: 3.277  loss_ce_0: 3.537  loss_mask_0: 0.6524  loss_dice_0: 3.553  loss_ce_1: 2.285  loss_mask_1: 0.6328  loss_dice_1: 3.432  loss_ce_2: 2.162  loss_mask_2: 0.628  loss_dice_2: 3.342  loss_ce_3: 2.078  loss_mask_3: 0.6235  loss_dice_3: 3.297  loss_ce_4: 2.041  loss_mask_4: 0.6213  loss_dice_4: 3.299  loss_ce_5: 2.035  loss_mask_5: 0.6247  loss_dice_5: 3.292  loss_ce_6: 2.051  loss_mask_6: 0.6237  loss_dice_6: 3.282  loss_ce_7: 2.02  loss_mask_7: 0.6228  loss_dice_7: 3.279  loss_ce_8: 2.034  loss_mask_8: 0.6235  loss_dice_8: 3.278  time: 1.6939  data_time: 0.3326  lr: 5.9202e-06  max_mem: 17674M
[01/19 09:45:32] d2.utils.events INFO:  eta: 10:28:20  iter: 17679  total_loss: 60.6  loss_ce: 1.921  loss_mask: 0.619  loss_dice: 3.28  loss_ce_0: 3.375  loss_mask_0: 0.6366  loss_dice_0: 3.55  loss_ce_1: 2.177  loss_mask_1: 0.6304  loss_dice_1: 3.415  loss_ce_2: 2.042  loss_mask_2: 0.6222  loss_dice_2: 3.342  loss_ce_3: 1.98  loss_mask_3: 0.6184  loss_dice_3: 3.297  loss_ce_4: 1.961  loss_mask_4: 0.617  loss_dice_4: 3.293  loss_ce_5: 1.951  loss_mask_5: 0.6208  loss_dice_5: 3.291  loss_ce_6: 1.941  loss_mask_6: 0.6187  loss_dice_6: 3.281  loss_ce_7: 1.94  loss_mask_7: 0.6204  loss_dice_7: 3.278  loss_ce_8: 1.928  loss_mask_8: 0.6205  loss_dice_8: 3.279  time: 1.6939  data_time: 0.3478  lr: 5.9155e-06  max_mem: 17674M
[01/19 09:46:06] d2.utils.events INFO:  eta: 10:27:39  iter: 17699  total_loss: 61.75  loss_ce: 1.996  loss_mask: 0.6112  loss_dice: 3.318  loss_ce_0: 3.474  loss_mask_0: 0.6303  loss_dice_0: 3.579  loss_ce_1: 2.244  loss_mask_1: 0.6177  loss_dice_1: 3.44  loss_ce_2: 2.123  loss_mask_2: 0.6096  loss_dice_2: 3.371  loss_ce_3: 2.059  loss_mask_3: 0.6092  loss_dice_3: 3.326  loss_ce_4: 2.005  loss_mask_4: 0.609  loss_dice_4: 3.319  loss_ce_5: 2  loss_mask_5: 0.6093  loss_dice_5: 3.32  loss_ce_6: 2.012  loss_mask_6: 0.6098  loss_dice_6: 3.318  loss_ce_7: 2.008  loss_mask_7: 0.6094  loss_dice_7: 3.311  loss_ce_8: 2.007  loss_mask_8: 0.6116  loss_dice_8: 3.312  time: 1.6939  data_time: 0.3359  lr: 5.9107e-06  max_mem: 17674M
[01/19 09:46:40] d2.utils.events INFO:  eta: 10:26:49  iter: 17719  total_loss: 62.19  loss_ce: 2.019  loss_mask: 0.635  loss_dice: 3.262  loss_ce_0: 3.449  loss_mask_0: 0.6607  loss_dice_0: 3.537  loss_ce_1: 2.264  loss_mask_1: 0.6491  loss_dice_1: 3.412  loss_ce_2: 2.123  loss_mask_2: 0.6416  loss_dice_2: 3.339  loss_ce_3: 2.097  loss_mask_3: 0.6391  loss_dice_3: 3.28  loss_ce_4: 2.05  loss_mask_4: 0.6368  loss_dice_4: 3.269  loss_ce_5: 2.041  loss_mask_5: 0.6369  loss_dice_5: 3.268  loss_ce_6: 2.041  loss_mask_6: 0.6344  loss_dice_6: 3.258  loss_ce_7: 2.011  loss_mask_7: 0.6348  loss_dice_7: 3.259  loss_ce_8: 2.019  loss_mask_8: 0.6337  loss_dice_8: 3.259  time: 1.6938  data_time: 0.3435  lr: 5.9059e-06  max_mem: 17674M
[01/19 09:47:14] d2.utils.events INFO:  eta: 10:26:34  iter: 17739  total_loss: 60.26  loss_ce: 1.86  loss_mask: 0.6178  loss_dice: 3.218  loss_ce_0: 3.38  loss_mask_0: 0.6376  loss_dice_0: 3.53  loss_ce_1: 2.128  loss_mask_1: 0.6202  loss_dice_1: 3.372  loss_ce_2: 2.018  loss_mask_2: 0.6201  loss_dice_2: 3.291  loss_ce_3: 1.957  loss_mask_3: 0.6182  loss_dice_3: 3.247  loss_ce_4: 1.945  loss_mask_4: 0.6185  loss_dice_4: 3.247  loss_ce_5: 1.901  loss_mask_5: 0.6177  loss_dice_5: 3.235  loss_ce_6: 1.895  loss_mask_6: 0.618  loss_dice_6: 3.218  loss_ce_7: 1.869  loss_mask_7: 0.6173  loss_dice_7: 3.225  loss_ce_8: 1.87  loss_mask_8: 0.616  loss_dice_8: 3.224  time: 1.6938  data_time: 0.3361  lr: 5.9011e-06  max_mem: 17674M
[01/19 09:47:47] d2.utils.events INFO:  eta: 10:25:40  iter: 17759  total_loss: 61.14  loss_ce: 1.96  loss_mask: 0.6242  loss_dice: 3.251  loss_ce_0: 3.397  loss_mask_0: 0.65  loss_dice_0: 3.526  loss_ce_1: 2.129  loss_mask_1: 0.6375  loss_dice_1: 3.384  loss_ce_2: 2.071  loss_mask_2: 0.6333  loss_dice_2: 3.314  loss_ce_3: 2.027  loss_mask_3: 0.6232  loss_dice_3: 3.269  loss_ce_4: 2.009  loss_mask_4: 0.6264  loss_dice_4: 3.265  loss_ce_5: 1.983  loss_mask_5: 0.6265  loss_dice_5: 3.258  loss_ce_6: 1.965  loss_mask_6: 0.625  loss_dice_6: 3.251  loss_ce_7: 1.976  loss_mask_7: 0.6263  loss_dice_7: 3.25  loss_ce_8: 1.965  loss_mask_8: 0.6217  loss_dice_8: 3.252  time: 1.6938  data_time: 0.3436  lr: 5.8964e-06  max_mem: 17674M
[01/19 09:48:21] d2.utils.events INFO:  eta: 10:25:08  iter: 17779  total_loss: 60.1  loss_ce: 1.93  loss_mask: 0.6292  loss_dice: 3.259  loss_ce_0: 3.356  loss_mask_0: 0.659  loss_dice_0: 3.555  loss_ce_1: 2.205  loss_mask_1: 0.6353  loss_dice_1: 3.397  loss_ce_2: 2.079  loss_mask_2: 0.6313  loss_dice_2: 3.331  loss_ce_3: 2.014  loss_mask_3: 0.6269  loss_dice_3: 3.282  loss_ce_4: 1.983  loss_mask_4: 0.6297  loss_dice_4: 3.276  loss_ce_5: 1.943  loss_mask_5: 0.631  loss_dice_5: 3.27  loss_ce_6: 1.933  loss_mask_6: 0.6311  loss_dice_6: 3.258  loss_ce_7: 1.923  loss_mask_7: 0.629  loss_dice_7: 3.254  loss_ce_8: 1.92  loss_mask_8: 0.6323  loss_dice_8: 3.255  time: 1.6938  data_time: 0.3415  lr: 5.8916e-06  max_mem: 17674M
[01/19 09:48:54] d2.utils.events INFO:  eta: 10:24:20  iter: 17799  total_loss: 60.97  loss_ce: 1.979  loss_mask: 0.6298  loss_dice: 3.211  loss_ce_0: 3.485  loss_mask_0: 0.6551  loss_dice_0: 3.513  loss_ce_1: 2.239  loss_mask_1: 0.6357  loss_dice_1: 3.356  loss_ce_2: 2.136  loss_mask_2: 0.6267  loss_dice_2: 3.284  loss_ce_3: 2.071  loss_mask_3: 0.6313  loss_dice_3: 3.243  loss_ce_4: 2.033  loss_mask_4: 0.6267  loss_dice_4: 3.233  loss_ce_5: 1.995  loss_mask_5: 0.6285  loss_dice_5: 3.237  loss_ce_6: 1.996  loss_mask_6: 0.6274  loss_dice_6: 3.223  loss_ce_7: 1.99  loss_mask_7: 0.629  loss_dice_7: 3.215  loss_ce_8: 1.98  loss_mask_8: 0.6318  loss_dice_8: 3.214  time: 1.6938  data_time: 0.3182  lr: 5.8868e-06  max_mem: 17674M
[01/19 09:49:27] d2.utils.events INFO:  eta: 10:23:46  iter: 17819  total_loss: 60.28  loss_ce: 1.913  loss_mask: 0.6207  loss_dice: 3.242  loss_ce_0: 3.375  loss_mask_0: 0.6455  loss_dice_0: 3.534  loss_ce_1: 2.149  loss_mask_1: 0.6301  loss_dice_1: 3.391  loss_ce_2: 2.017  loss_mask_2: 0.6203  loss_dice_2: 3.316  loss_ce_3: 1.972  loss_mask_3: 0.6212  loss_dice_3: 3.273  loss_ce_4: 1.93  loss_mask_4: 0.6207  loss_dice_4: 3.263  loss_ce_5: 1.917  loss_mask_5: 0.6247  loss_dice_5: 3.253  loss_ce_6: 1.926  loss_mask_6: 0.6207  loss_dice_6: 3.244  loss_ce_7: 1.89  loss_mask_7: 0.6183  loss_dice_7: 3.246  loss_ce_8: 1.899  loss_mask_8: 0.6202  loss_dice_8: 3.238  time: 1.6937  data_time: 0.3384  lr: 5.8821e-06  max_mem: 17674M
[01/19 09:50:02] d2.utils.events INFO:  eta: 10:23:12  iter: 17839  total_loss: 59.79  loss_ce: 1.813  loss_mask: 0.6108  loss_dice: 3.299  loss_ce_0: 3.346  loss_mask_0: 0.6379  loss_dice_0: 3.57  loss_ce_1: 2.078  loss_mask_1: 0.6206  loss_dice_1: 3.418  loss_ce_2: 1.937  loss_mask_2: 0.6149  loss_dice_2: 3.352  loss_ce_3: 1.888  loss_mask_3: 0.6146  loss_dice_3: 3.317  loss_ce_4: 1.838  loss_mask_4: 0.6171  loss_dice_4: 3.314  loss_ce_5: 1.828  loss_mask_5: 0.6151  loss_dice_5: 3.31  loss_ce_6: 1.832  loss_mask_6: 0.6126  loss_dice_6: 3.301  loss_ce_7: 1.814  loss_mask_7: 0.6128  loss_dice_7: 3.302  loss_ce_8: 1.797  loss_mask_8: 0.6128  loss_dice_8: 3.305  time: 1.6937  data_time: 0.3480  lr: 5.8773e-06  max_mem: 17674M
[01/19 09:50:35] d2.utils.events INFO:  eta: 10:22:24  iter: 17859  total_loss: 61.96  loss_ce: 2.018  loss_mask: 0.6372  loss_dice: 3.277  loss_ce_0: 3.427  loss_mask_0: 0.6585  loss_dice_0: 3.555  loss_ce_1: 2.229  loss_mask_1: 0.649  loss_dice_1: 3.42  loss_ce_2: 2.121  loss_mask_2: 0.6439  loss_dice_2: 3.348  loss_ce_3: 2.071  loss_mask_3: 0.6381  loss_dice_3: 3.309  loss_ce_4: 2.049  loss_mask_4: 0.6373  loss_dice_4: 3.302  loss_ce_5: 2.031  loss_mask_5: 0.6384  loss_dice_5: 3.303  loss_ce_6: 2.03  loss_mask_6: 0.6371  loss_dice_6: 3.284  loss_ce_7: 2.015  loss_mask_7: 0.6361  loss_dice_7: 3.28  loss_ce_8: 2.021  loss_mask_8: 0.6394  loss_dice_8: 3.284  time: 1.6937  data_time: 0.3447  lr: 5.8725e-06  max_mem: 17674M
[01/19 09:51:09] d2.utils.events INFO:  eta: 10:21:08  iter: 17879  total_loss: 61.31  loss_ce: 2.023  loss_mask: 0.636  loss_dice: 3.225  loss_ce_0: 3.431  loss_mask_0: 0.6638  loss_dice_0: 3.512  loss_ce_1: 2.289  loss_mask_1: 0.6449  loss_dice_1: 3.356  loss_ce_2: 2.184  loss_mask_2: 0.6396  loss_dice_2: 3.29  loss_ce_3: 2.133  loss_mask_3: 0.6364  loss_dice_3: 3.238  loss_ce_4: 2.084  loss_mask_4: 0.6382  loss_dice_4: 3.242  loss_ce_5: 2.078  loss_mask_5: 0.6342  loss_dice_5: 3.235  loss_ce_6: 2.066  loss_mask_6: 0.6355  loss_dice_6: 3.217  loss_ce_7: 2.046  loss_mask_7: 0.6335  loss_dice_7: 3.22  loss_ce_8: 2.031  loss_mask_8: 0.6365  loss_dice_8: 3.225  time: 1.6937  data_time: 0.3468  lr: 5.8677e-06  max_mem: 17674M
[01/19 09:51:43] d2.utils.events INFO:  eta: 10:20:28  iter: 17899  total_loss: 61.01  loss_ce: 1.9  loss_mask: 0.6199  loss_dice: 3.303  loss_ce_0: 3.441  loss_mask_0: 0.6451  loss_dice_0: 3.57  loss_ce_1: 2.135  loss_mask_1: 0.6221  loss_dice_1: 3.446  loss_ce_2: 2.021  loss_mask_2: 0.6216  loss_dice_2: 3.363  loss_ce_3: 1.961  loss_mask_3: 0.6177  loss_dice_3: 3.33  loss_ce_4: 1.934  loss_mask_4: 0.6175  loss_dice_4: 3.322  loss_ce_5: 1.913  loss_mask_5: 0.6172  loss_dice_5: 3.325  loss_ce_6: 1.923  loss_mask_6: 0.6173  loss_dice_6: 3.31  loss_ce_7: 1.912  loss_mask_7: 0.6213  loss_dice_7: 3.308  loss_ce_8: 1.899  loss_mask_8: 0.619  loss_dice_8: 3.307  time: 1.6937  data_time: 0.3631  lr: 5.863e-06  max_mem: 17674M
[01/19 09:52:17] d2.utils.events INFO:  eta: 10:19:39  iter: 17919  total_loss: 61.62  loss_ce: 2.022  loss_mask: 0.6287  loss_dice: 3.303  loss_ce_0: 3.46  loss_mask_0: 0.654  loss_dice_0: 3.547  loss_ce_1: 2.229  loss_mask_1: 0.6384  loss_dice_1: 3.431  loss_ce_2: 2.121  loss_mask_2: 0.6297  loss_dice_2: 3.379  loss_ce_3: 2.067  loss_mask_3: 0.6304  loss_dice_3: 3.326  loss_ce_4: 2.039  loss_mask_4: 0.6313  loss_dice_4: 3.325  loss_ce_5: 2.028  loss_mask_5: 0.6326  loss_dice_5: 3.32  loss_ce_6: 2.037  loss_mask_6: 0.6309  loss_dice_6: 3.309  loss_ce_7: 2.023  loss_mask_7: 0.6291  loss_dice_7: 3.298  loss_ce_8: 2.007  loss_mask_8: 0.6263  loss_dice_8: 3.309  time: 1.6937  data_time: 0.3233  lr: 5.8582e-06  max_mem: 17674M
[01/19 09:52:51] d2.utils.events INFO:  eta: 10:20:07  iter: 17939  total_loss: 60.42  loss_ce: 1.912  loss_mask: 0.615  loss_dice: 3.291  loss_ce_0: 3.458  loss_mask_0: 0.6415  loss_dice_0: 3.554  loss_ce_1: 2.155  loss_mask_1: 0.6215  loss_dice_1: 3.421  loss_ce_2: 2.014  loss_mask_2: 0.6109  loss_dice_2: 3.363  loss_ce_3: 1.971  loss_mask_3: 0.6105  loss_dice_3: 3.323  loss_ce_4: 1.944  loss_mask_4: 0.6121  loss_dice_4: 3.309  loss_ce_5: 1.945  loss_mask_5: 0.6117  loss_dice_5: 3.302  loss_ce_6: 1.918  loss_mask_6: 0.6115  loss_dice_6: 3.295  loss_ce_7: 1.902  loss_mask_7: 0.6115  loss_dice_7: 3.293  loss_ce_8: 1.906  loss_mask_8: 0.6139  loss_dice_8: 3.29  time: 1.6937  data_time: 0.3704  lr: 5.8534e-06  max_mem: 17674M
[01/19 09:53:25] d2.utils.events INFO:  eta: 10:19:33  iter: 17959  total_loss: 60.74  loss_ce: 1.941  loss_mask: 0.627  loss_dice: 3.257  loss_ce_0: 3.422  loss_mask_0: 0.6399  loss_dice_0: 3.535  loss_ce_1: 2.204  loss_mask_1: 0.6347  loss_dice_1: 3.401  loss_ce_2: 2.092  loss_mask_2: 0.6338  loss_dice_2: 3.326  loss_ce_3: 2.017  loss_mask_3: 0.6269  loss_dice_3: 3.285  loss_ce_4: 1.994  loss_mask_4: 0.6226  loss_dice_4: 3.274  loss_ce_5: 1.956  loss_mask_5: 0.626  loss_dice_5: 3.275  loss_ce_6: 1.954  loss_mask_6: 0.6251  loss_dice_6: 3.267  loss_ce_7: 1.952  loss_mask_7: 0.6235  loss_dice_7: 3.265  loss_ce_8: 1.948  loss_mask_8: 0.6256  loss_dice_8: 3.255  time: 1.6938  data_time: 0.3569  lr: 5.8486e-06  max_mem: 17674M
[01/19 09:53:59] d2.utils.events INFO:  eta: 10:18:56  iter: 17979  total_loss: 61.75  loss_ce: 2.024  loss_mask: 0.632  loss_dice: 3.28  loss_ce_0: 3.477  loss_mask_0: 0.6655  loss_dice_0: 3.562  loss_ce_1: 2.256  loss_mask_1: 0.6418  loss_dice_1: 3.415  loss_ce_2: 2.14  loss_mask_2: 0.6334  loss_dice_2: 3.345  loss_ce_3: 2.111  loss_mask_3: 0.6342  loss_dice_3: 3.305  loss_ce_4: 2.079  loss_mask_4: 0.6356  loss_dice_4: 3.294  loss_ce_5: 2.05  loss_mask_5: 0.6345  loss_dice_5: 3.294  loss_ce_6: 2.046  loss_mask_6: 0.6318  loss_dice_6: 3.286  loss_ce_7: 2.039  loss_mask_7: 0.6316  loss_dice_7: 3.28  loss_ce_8: 2.02  loss_mask_8: 0.6318  loss_dice_8: 3.281  time: 1.6937  data_time: 0.3502  lr: 5.8439e-06  max_mem: 17674M
[01/19 09:54:33] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 09:54:34] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 09:54:34] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 10:00:00] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.254303554093364, 'error_1pix': 0.38656454298570264, 'error_3pix': 0.17504794028748016, 'mIoU': 7.213823958827133, 'fwIoU': 22.24849306157709, 'IoU-0': nan, 'IoU-1': 95.3754507188609, 'IoU-2': 11.903718087788292, 'IoU-3': 29.297859229089106, 'IoU-4': 26.478238266829607, 'IoU-5': 16.097784243341074, 'IoU-6': 15.035769940960794, 'IoU-7': 16.57032382377862, 'IoU-8': 4.3233915459445065, 'IoU-9': 6.2026926586335716, 'IoU-10': 17.905408227738654, 'IoU-11': 27.228102275225197, 'IoU-12': 28.810528597555603, 'IoU-13': 25.646607029943407, 'IoU-14': 24.30679768532205, 'IoU-15': 24.977953826058183, 'IoU-16': 20.311882082507495, 'IoU-17': 20.568393820677603, 'IoU-18': 19.206172445799417, 'IoU-19': 17.225366172677507, 'IoU-20': 15.220600587204475, 'IoU-21': 21.42042145839779, 'IoU-22': 18.448606097465483, 'IoU-23': 17.18125801757132, 'IoU-24': 16.797808651841546, 'IoU-25': 17.28670338178732, 'IoU-26': 16.385474416294088, 'IoU-27': 16.217086631811274, 'IoU-28': 18.70279796374004, 'IoU-29': 16.91383984477, 'IoU-30': 15.78338079513226, 'IoU-31': 15.236552743149382, 'IoU-32': 15.03993873692154, 'IoU-33': 16.187934216180484, 'IoU-34': 15.722400232571202, 'IoU-35': 14.94079785683525, 'IoU-36': 16.25181796135823, 'IoU-37': 15.008174824090561, 'IoU-38': 14.994931486445795, 'IoU-39': 14.903848361560629, 'IoU-40': 12.831531505514851, 'IoU-41': 14.235586652258439, 'IoU-42': 10.90741561209562, 'IoU-43': 14.610620200661742, 'IoU-44': 10.70734255123819, 'IoU-45': 13.020049477090406, 'IoU-46': 14.02722907798005, 'IoU-47': 9.922331527506506, 'IoU-48': 12.247851760776923, 'IoU-49': 11.817929355322946, 'IoU-50': 13.585905453334469, 'IoU-51': 12.76129934870183, 'IoU-52': 11.498052031974243, 'IoU-53': 12.43979695638669, 'IoU-54': 12.371713773436245, 'IoU-55': 12.618640862891503, 'IoU-56': 10.410467132944866, 'IoU-57': 10.863880621841329, 'IoU-58': 11.576540897359871, 'IoU-59': 8.537260443735633, 'IoU-60': 11.068808474300509, 'IoU-61': 8.708644535004144, 'IoU-62': 8.036817182675705, 'IoU-63': 8.861415714266764, 'IoU-64': 6.991782284472567, 'IoU-65': 7.290758247342653, 'IoU-66': 4.325754384579269, 'IoU-67': 6.3001236942924015, 'IoU-68': 3.85915602667338, 'IoU-69': 4.512680112186971, 'IoU-70': 5.430735674486361, 'IoU-71': 5.611912010014689, 'IoU-72': 3.938782968704898, 'IoU-73': 5.068946242720451, 'IoU-74': 4.297068006191521, 'IoU-75': 4.255297451887037, 'IoU-76': 3.4422702155213076, 'IoU-77': 4.021764170147424, 'IoU-78': 3.671767297810703, 'IoU-79': 4.812106848858752, 'IoU-80': 3.6279587745331168, 'IoU-81': 4.4656344952701, 'IoU-82': 4.136729120726988, 'IoU-83': 2.589837333686661, 'IoU-84': 4.1447641699006805, 'IoU-85': 5.224948520284498, 'IoU-86': 3.0244621424746336, 'IoU-87': 4.217831362131373, 'IoU-88': 4.24428787530811, 'IoU-89': 4.5644756200142975, 'IoU-90': 4.444200977463912, 'IoU-91': 4.06578377171223, 'IoU-92': 4.265315210908873, 'IoU-93': 3.1866842376954043, 'IoU-94': 4.69791296929802, 'IoU-95': 3.901432149670779, 'IoU-96': 5.189529828007697, 'IoU-97': 4.376709485085857, 'IoU-98': 3.7331887484025272, 'IoU-99': 3.828110299209349, 'IoU-100': 4.596564982264801, 'IoU-101': 4.582752795827528, 'IoU-102': 4.1033618607846325, 'IoU-103': 4.833286353773495, 'IoU-104': 4.146879346765664, 'IoU-105': 3.9653930938127475, 'IoU-106': 4.260740562750654, 'IoU-107': 4.076616683367294, 'IoU-108': 4.916230953886166, 'IoU-109': 3.3591195227365866, 'IoU-110': 4.008518237524737, 'IoU-111': 3.914587502678258, 'IoU-112': 4.1208989056889775, 'IoU-113': 3.8774327118595653, 'IoU-114': 4.135395302633718, 'IoU-115': 4.263184231251386, 'IoU-116': 2.046885789511664, 'IoU-117': 4.746896034526699, 'IoU-118': 2.028403728728796, 'IoU-119': 3.967265824539701, 'IoU-120': 3.8798380726698265, 'IoU-121': 3.0767666235373476, 'IoU-122': 2.8097256025143635, 'IoU-123': 2.9495897537288505, 'IoU-124': 2.839043200067798, 'IoU-125': 2.5581932789474515, 'IoU-126': 2.0159824932846315, 'IoU-127': 2.2994041365347893, 'IoU-128': 2.5660092720745467, 'IoU-129': 2.6191372480980815, 'IoU-130': 2.2303974437971217, 'IoU-131': 1.9007462991471638, 'IoU-132': 2.173668054371779, 'IoU-133': 2.3011613553642087, 'IoU-134': 2.0026553270092937, 'IoU-135': 1.722985126109203, 'IoU-136': 0.8804037560405117, 'IoU-137': 0.9362506855538959, 'IoU-138': 1.41509478978284, 'IoU-139': 1.3462116350076907, 'IoU-140': 1.730157748154027, 'IoU-141': 0.9858742664582363, 'IoU-142': 1.1717857075281377, 'IoU-143': 1.6869207418065757, 'IoU-144': 0.9906859573597857, 'IoU-145': 1.6308032910546375, 'IoU-146': 0.4821340776806814, 'IoU-147': 1.342227653021783, 'IoU-148': 0.9825893947433724, 'IoU-149': 1.3634277307086269, 'IoU-150': 1.204272622313311, 'IoU-151': 1.0636263051624684, 'IoU-152': 0.7841093978845812, 'IoU-153': 0.46120911628228034, 'IoU-154': 1.004073683954129, 'IoU-155': 1.7990943397218602, 'IoU-156': 1.2136674902564177, 'IoU-157': 0.4184887336919134, 'IoU-158': 0.8616133289518881, 'IoU-159': 0.7029748690451443, 'IoU-160': 0.4812744232827631, 'IoU-161': 0.4622991269204957, 'IoU-162': 0.6186682022631592, 'IoU-163': 0.6683340756729594, 'IoU-164': 1.1197824601700348, 'IoU-165': 0.7560683248426731, 'IoU-166': 0.6860497941745282, 'IoU-167': 0.3406277520229965, 'IoU-168': 0.6929294840788044, 'IoU-169': 0.9922106304755858, 'IoU-170': 0.8330522887034462, 'IoU-171': 0.015350821086180239, 'IoU-172': 0.40495170328636215, 'IoU-173': 0.10202501289283224, 'IoU-174': 1.140118242811665, 'IoU-175': 0.6579734251612598, 'IoU-176': 0.3232558505531861, 'IoU-177': 0.380465644520159, 'IoU-178': 0.1849886608129325, 'IoU-179': 0.09085623626563132, 'IoU-180': 1.5446877765332707, 'IoU-181': 0.5074316068720376, 'IoU-182': 0.8749598718011385, 'IoU-183': 0.5918187150228787, 'IoU-184': 0.2917601591650193, 'IoU-185': 0.19108605760578057, 'IoU-186': 0.44051693810858705, 'IoU-187': 1.8950064020486557, 'IoU-188': 0.18912050721036655, 'IoU-189': 2.252576500007227, 'IoU-190': 1.0082249201982805, 'IoU-191': 1.4234791509755855, 'IoU-192': 2.994185474093432, 'mACC': 12.282839395223881, 'pACC': 31.83720805192453, 'ACC-0': nan, 'ACC-1': 98.52043189359333, 'ACC-2': 12.510779432473049, 'ACC-3': 37.13382522512946, 'ACC-4': 41.86730710692912, 'ACC-5': 23.645649048438948, 'ACC-6': 24.47756869603009, 'ACC-7': 28.095795457445917, 'ACC-8': 5.011787018622712, 'ACC-9': 6.782969081361036, 'ACC-10': 25.788161554852618, 'ACC-11': 42.24219658182024, 'ACC-12': 51.283844077133956, 'ACC-13': 48.73222614026716, 'ACC-14': 37.06063667643162, 'ACC-15': 49.23047128270954, 'ACC-16': 30.350892817490465, 'ACC-17': 36.573855605534625, 'ACC-18': 34.164901814736886, 'ACC-19': 30.899266103788957, 'ACC-20': 21.53542301386168, 'ACC-21': 45.101516315558285, 'ACC-22': 29.05034107304369, 'ACC-23': 29.31743255120327, 'ACC-24': 27.052939154680857, 'ACC-25': 32.19944076365886, 'ACC-26': 27.583321232836617, 'ACC-27': 23.810756730040232, 'ACC-28': 38.68084575496395, 'ACC-29': 27.667986102347996, 'ACC-30': 29.53144629233305, 'ACC-31': 23.81836526327204, 'ACC-32': 24.588407328153128, 'ACC-33': 30.30997153402804, 'ACC-34': 28.599972861820127, 'ACC-35': 22.92112850673286, 'ACC-36': 26.723588177226294, 'ACC-37': 26.117851825889876, 'ACC-38': 25.003909537806713, 'ACC-39': 24.78751542953474, 'ACC-40': 20.56836542232725, 'ACC-41': 27.856854775016032, 'ACC-42': 17.757652572530155, 'ACC-43': 28.187460732577335, 'ACC-44': 16.107008712671146, 'ACC-45': 21.17292289291384, 'ACC-46': 30.008403274890384, 'ACC-47': 14.86124182879292, 'ACC-48': 20.641497444075718, 'ACC-49': 19.759717337590043, 'ACC-50': 27.343188182093296, 'ACC-51': 22.72729969419329, 'ACC-52': 19.574338321832403, 'ACC-53': 24.014270388046917, 'ACC-54': 22.624579651926698, 'ACC-55': 25.2829266231689, 'ACC-56': 18.338199507504097, 'ACC-57': 21.00567548127042, 'ACC-58': 21.807073292167082, 'ACC-59': 15.334882663342661, 'ACC-60': 25.58389986697471, 'ACC-61': 16.861681455404074, 'ACC-62': 15.03734955552767, 'ACC-63': 16.942484288005762, 'ACC-64': 13.640216167405644, 'ACC-65': 15.775223837929616, 'ACC-66': 6.448610013528038, 'ACC-67': 16.43665345322418, 'ACC-68': 6.819415722133989, 'ACC-69': 7.184590594319121, 'ACC-70': 11.941040616200816, 'ACC-71': 11.17827981258135, 'ACC-72': 6.6467837679640995, 'ACC-73': 13.203553129208434, 'ACC-74': 6.964825827340693, 'ACC-75': 8.931322134363612, 'ACC-76': 5.900752745430213, 'ACC-77': 7.787000045193161, 'ACC-78': 6.104976892137204, 'ACC-79': 9.21322952110422, 'ACC-80': 6.394937826977991, 'ACC-81': 9.311392472385561, 'ACC-82': 8.470419256213281, 'ACC-83': 3.8961593993775683, 'ACC-84': 7.528048331107144, 'ACC-85': 11.060002601523049, 'ACC-86': 4.267517774060869, 'ACC-87': 6.968485517608587, 'ACC-88': 7.641653069724849, 'ACC-89': 7.825268267144605, 'ACC-90': 8.153498679605905, 'ACC-91': 7.2810234919923005, 'ACC-92': 8.151272417847736, 'ACC-93': 5.280210656857463, 'ACC-94': 8.102127229954434, 'ACC-95': 6.326380603710151, 'ACC-96': 9.728039029660764, 'ACC-97': 8.760708454227988, 'ACC-98': 5.852145770534692, 'ACC-99': 5.480609098840103, 'ACC-100': 7.659853204849057, 'ACC-101': 8.947230862611788, 'ACC-102': 6.528047122791119, 'ACC-103': 8.587961651081514, 'ACC-104': 7.46405646688473, 'ACC-105': 6.412047755220146, 'ACC-106': 7.402366884076383, 'ACC-107': 6.731595585899595, 'ACC-108': 9.651790681420406, 'ACC-109': 5.067932182632324, 'ACC-110': 7.085697837116991, 'ACC-111': 6.996876411248179, 'ACC-112': 8.0188103212529, 'ACC-113': 6.260141033843615, 'ACC-114': 7.629600178134306, 'ACC-115': 8.258611098582232, 'ACC-116': 2.8205083863786786, 'ACC-117': 10.17120097852092, 'ACC-118': 3.1675313862342693, 'ACC-119': 8.935178811230532, 'ACC-120': 8.284928156527057, 'ACC-121': 6.4038095463037115, 'ACC-122': 5.0056138960438545, 'ACC-123': 4.954023238050877, 'ACC-124': 4.854293935169179, 'ACC-125': 5.893863468510261, 'ACC-126': 4.098625670543448, 'ACC-127': 4.378136418432095, 'ACC-128': 5.277774728591971, 'ACC-129': 5.191273118849067, 'ACC-130': 4.741282571850904, 'ACC-131': 3.277236257013796, 'ACC-132': 5.739629305693787, 'ACC-133': 5.8272945627249655, 'ACC-134': 3.587419215855235, 'ACC-135': 3.8159169944700984, 'ACC-136': 1.4697575009317927, 'ACC-137': 2.0351590614379145, 'ACC-138': 2.3523364723202276, 'ACC-139': 2.354247130361639, 'ACC-140': 5.257939958952239, 'ACC-141': 1.697835018404784, 'ACC-142': 2.001116097745011, 'ACC-143': 3.2352880389413516, 'ACC-144': 1.469043321299639, 'ACC-145': 4.666204521568013, 'ACC-146': 0.5833999680153527, 'ACC-147': 2.4988323863979285, 'ACC-148': 1.904470410654997, 'ACC-149': 2.4491186722227347, 'ACC-150': 2.1080686130732564, 'ACC-151': 1.84315393117002, 'ACC-152': 1.0988814147953334, 'ACC-153': 0.5814965462906979, 'ACC-154': 1.9844610628332437, 'ACC-155': 3.373489817903038, 'ACC-156': 4.847744445952672, 'ACC-157': 0.5663281763579423, 'ACC-158': 1.143460386055485, 'ACC-159': 1.2560712473099378, 'ACC-160': 0.6954655476632131, 'ACC-161': 0.6161588645152594, 'ACC-162': 0.9973192581991722, 'ACC-163': 0.8945727925743732, 'ACC-164': 2.606394616928643, 'ACC-165': 1.2020887662112842, 'ACC-166': 1.0934181699137924, 'ACC-167': 0.3917195184021318, 'ACC-168': 1.377734017863422, 'ACC-169': 1.5518702633652282, 'ACC-170': 1.2317744935190313, 'ACC-171': 0.015429575925453106, 'ACC-172': 0.49412897729377336, 'ACC-173': 0.12022441891530856, 'ACC-174': 2.0794771855853234, 'ACC-175': 0.8746873145380021, 'ACC-176': 0.3725766194566984, 'ACC-177': 0.4080321996644946, 'ACC-178': 0.19663480204206593, 'ACC-179': 0.09353170440735188, 'ACC-180': 2.6416827525483426, 'ACC-181': 0.7584424689884197, 'ACC-182': 1.569100355612205, 'ACC-183': 0.6580325885047946, 'ACC-184': 0.32475113026128666, 'ACC-185': 0.19862441047813054, 'ACC-186': 0.47000446161944986, 'ACC-187': 3.128812863165779, 'ACC-188': 0.20252411121423672, 'ACC-189': 4.000811252795099, 'ACC-190': 1.9158011675068385, 'ACC-191': 2.362936378466558, 'ACC-192': 6.024263451160395})])
[01/19 10:00:00] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 10:00:00] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 10:00:00] d2.evaluation.testing INFO: copypaste: 3.2543,0.3866,0.1750,7.2138,22.2485,12.2828,31.8372
[01/19 10:00:00] d2.utils.events INFO:  eta: 10:18:38  iter: 17999  total_loss: 60.54  loss_ce: 1.93  loss_mask: 0.6211  loss_dice: 3.222  loss_ce_0: 3.355  loss_mask_0: 0.6424  loss_dice_0: 3.535  loss_ce_1: 2.141  loss_mask_1: 0.628  loss_dice_1: 3.367  loss_ce_2: 2.067  loss_mask_2: 0.6216  loss_dice_2: 3.299  loss_ce_3: 2.018  loss_mask_3: 0.6204  loss_dice_3: 3.257  loss_ce_4: 1.971  loss_mask_4: 0.6227  loss_dice_4: 3.249  loss_ce_5: 1.959  loss_mask_5: 0.6225  loss_dice_5: 3.243  loss_ce_6: 1.945  loss_mask_6: 0.6206  loss_dice_6: 3.231  loss_ce_7: 1.938  loss_mask_7: 0.6196  loss_dice_7: 3.226  loss_ce_8: 1.942  loss_mask_8: 0.6217  loss_dice_8: 3.224  time: 1.6938  data_time: 0.3462  lr: 5.8391e-06  max_mem: 17674M
[01/19 10:00:33] d2.utils.events INFO:  eta: 10:17:52  iter: 18019  total_loss: 60.75  loss_ce: 1.917  loss_mask: 0.6324  loss_dice: 3.257  loss_ce_0: 3.442  loss_mask_0: 0.6649  loss_dice_0: 3.515  loss_ce_1: 2.181  loss_mask_1: 0.6427  loss_dice_1: 3.392  loss_ce_2: 2.05  loss_mask_2: 0.6381  loss_dice_2: 3.327  loss_ce_3: 2.001  loss_mask_3: 0.6345  loss_dice_3: 3.278  loss_ce_4: 1.963  loss_mask_4: 0.6346  loss_dice_4: 3.269  loss_ce_5: 1.956  loss_mask_5: 0.6345  loss_dice_5: 3.272  loss_ce_6: 1.953  loss_mask_6: 0.6337  loss_dice_6: 3.263  loss_ce_7: 1.915  loss_mask_7: 0.6323  loss_dice_7: 3.264  loss_ce_8: 1.933  loss_mask_8: 0.6313  loss_dice_8: 3.262  time: 1.6938  data_time: 0.3496  lr: 5.8343e-06  max_mem: 17674M
[01/19 10:01:07] d2.utils.events INFO:  eta: 10:16:56  iter: 18039  total_loss: 60.43  loss_ce: 1.923  loss_mask: 0.62  loss_dice: 3.263  loss_ce_0: 3.432  loss_mask_0: 0.6387  loss_dice_0: 3.55  loss_ce_1: 2.167  loss_mask_1: 0.621  loss_dice_1: 3.398  loss_ce_2: 2.026  loss_mask_2: 0.6122  loss_dice_2: 3.326  loss_ce_3: 1.979  loss_mask_3: 0.6135  loss_dice_3: 3.285  loss_ce_4: 1.947  loss_mask_4: 0.6165  loss_dice_4: 3.278  loss_ce_5: 1.931  loss_mask_5: 0.6178  loss_dice_5: 3.28  loss_ce_6: 1.933  loss_mask_6: 0.6173  loss_dice_6: 3.266  loss_ce_7: 1.92  loss_mask_7: 0.6197  loss_dice_7: 3.264  loss_ce_8: 1.916  loss_mask_8: 0.6205  loss_dice_8: 3.27  time: 1.6938  data_time: 0.3299  lr: 5.8295e-06  max_mem: 17674M
[01/19 10:01:41] d2.utils.events INFO:  eta: 10:16:22  iter: 18059  total_loss: 59.77  loss_ce: 1.864  loss_mask: 0.6108  loss_dice: 3.257  loss_ce_0: 3.404  loss_mask_0: 0.6312  loss_dice_0: 3.549  loss_ce_1: 2.094  loss_mask_1: 0.6157  loss_dice_1: 3.411  loss_ce_2: 1.962  loss_mask_2: 0.6086  loss_dice_2: 3.336  loss_ce_3: 1.942  loss_mask_3: 0.6075  loss_dice_3: 3.283  loss_ce_4: 1.901  loss_mask_4: 0.6079  loss_dice_4: 3.284  loss_ce_5: 1.872  loss_mask_5: 0.6085  loss_dice_5: 3.271  loss_ce_6: 1.872  loss_mask_6: 0.606  loss_dice_6: 3.266  loss_ce_7: 1.858  loss_mask_7: 0.6099  loss_dice_7: 3.257  loss_ce_8: 1.85  loss_mask_8: 0.6086  loss_dice_8: 3.258  time: 1.6938  data_time: 0.3522  lr: 5.8247e-06  max_mem: 17674M
[01/19 10:02:15] d2.utils.events INFO:  eta: 10:16:03  iter: 18079  total_loss: 61.06  loss_ce: 1.943  loss_mask: 0.6233  loss_dice: 3.256  loss_ce_0: 3.44  loss_mask_0: 0.6392  loss_dice_0: 3.534  loss_ce_1: 2.233  loss_mask_1: 0.6257  loss_dice_1: 3.392  loss_ce_2: 2.1  loss_mask_2: 0.6207  loss_dice_2: 3.318  loss_ce_3: 2.041  loss_mask_3: 0.618  loss_dice_3: 3.271  loss_ce_4: 1.991  loss_mask_4: 0.6184  loss_dice_4: 3.267  loss_ce_5: 1.98  loss_mask_5: 0.6197  loss_dice_5: 3.259  loss_ce_6: 1.96  loss_mask_6: 0.6205  loss_dice_6: 3.259  loss_ce_7: 1.952  loss_mask_7: 0.6207  loss_dice_7: 3.258  loss_ce_8: 1.948  loss_mask_8: 0.6238  loss_dice_8: 3.258  time: 1.6938  data_time: 0.3396  lr: 5.82e-06  max_mem: 17674M
[01/19 10:02:49] d2.utils.events INFO:  eta: 10:15:15  iter: 18099  total_loss: 59.96  loss_ce: 1.837  loss_mask: 0.6147  loss_dice: 3.24  loss_ce_0: 3.386  loss_mask_0: 0.645  loss_dice_0: 3.526  loss_ce_1: 2.09  loss_mask_1: 0.6284  loss_dice_1: 3.383  loss_ce_2: 1.95  loss_mask_2: 0.622  loss_dice_2: 3.305  loss_ce_3: 1.905  loss_mask_3: 0.6125  loss_dice_3: 3.263  loss_ce_4: 1.883  loss_mask_4: 0.6118  loss_dice_4: 3.259  loss_ce_5: 1.862  loss_mask_5: 0.6148  loss_dice_5: 3.249  loss_ce_6: 1.867  loss_mask_6: 0.6146  loss_dice_6: 3.242  loss_ce_7: 1.864  loss_mask_7: 0.615  loss_dice_7: 3.24  loss_ce_8: 1.86  loss_mask_8: 0.6166  loss_dice_8: 3.238  time: 1.6938  data_time: 0.3271  lr: 5.8152e-06  max_mem: 17674M
[01/19 10:03:23] d2.utils.events INFO:  eta: 10:14:41  iter: 18119  total_loss: 60.38  loss_ce: 1.915  loss_mask: 0.6174  loss_dice: 3.262  loss_ce_0: 3.429  loss_mask_0: 0.6309  loss_dice_0: 3.535  loss_ce_1: 2.212  loss_mask_1: 0.6279  loss_dice_1: 3.395  loss_ce_2: 2.051  loss_mask_2: 0.6231  loss_dice_2: 3.329  loss_ce_3: 2.013  loss_mask_3: 0.6189  loss_dice_3: 3.293  loss_ce_4: 1.949  loss_mask_4: 0.6168  loss_dice_4: 3.279  loss_ce_5: 1.944  loss_mask_5: 0.6176  loss_dice_5: 3.283  loss_ce_6: 1.921  loss_mask_6: 0.6159  loss_dice_6: 3.266  loss_ce_7: 1.919  loss_mask_7: 0.6177  loss_dice_7: 3.269  loss_ce_8: 1.899  loss_mask_8: 0.6159  loss_dice_8: 3.267  time: 1.6937  data_time: 0.3216  lr: 5.8104e-06  max_mem: 17674M
[01/19 10:03:56] d2.utils.events INFO:  eta: 10:13:58  iter: 18139  total_loss: 61.7  loss_ce: 1.96  loss_mask: 0.6211  loss_dice: 3.285  loss_ce_0: 3.417  loss_mask_0: 0.65  loss_dice_0: 3.556  loss_ce_1: 2.185  loss_mask_1: 0.6272  loss_dice_1: 3.421  loss_ce_2: 2.089  loss_mask_2: 0.6254  loss_dice_2: 3.349  loss_ce_3: 2.026  loss_mask_3: 0.6267  loss_dice_3: 3.3  loss_ce_4: 1.999  loss_mask_4: 0.6267  loss_dice_4: 3.296  loss_ce_5: 1.983  loss_mask_5: 0.6298  loss_dice_5: 3.298  loss_ce_6: 1.984  loss_mask_6: 0.6204  loss_dice_6: 3.284  loss_ce_7: 1.981  loss_mask_7: 0.6196  loss_dice_7: 3.283  loss_ce_8: 1.959  loss_mask_8: 0.6212  loss_dice_8: 3.285  time: 1.6937  data_time: 0.3407  lr: 5.8056e-06  max_mem: 17674M
[01/19 10:04:30] d2.utils.events INFO:  eta: 10:13:17  iter: 18159  total_loss: 60.43  loss_ce: 1.908  loss_mask: 0.6231  loss_dice: 3.22  loss_ce_0: 3.396  loss_mask_0: 0.6493  loss_dice_0: 3.504  loss_ce_1: 2.154  loss_mask_1: 0.629  loss_dice_1: 3.35  loss_ce_2: 2.048  loss_mask_2: 0.6226  loss_dice_2: 3.284  loss_ce_3: 2.017  loss_mask_3: 0.619  loss_dice_3: 3.244  loss_ce_4: 1.986  loss_mask_4: 0.6217  loss_dice_4: 3.238  loss_ce_5: 1.95  loss_mask_5: 0.6224  loss_dice_5: 3.237  loss_ce_6: 1.945  loss_mask_6: 0.6216  loss_dice_6: 3.226  loss_ce_7: 1.931  loss_mask_7: 0.6223  loss_dice_7: 3.229  loss_ce_8: 1.924  loss_mask_8: 0.6241  loss_dice_8: 3.225  time: 1.6937  data_time: 0.3363  lr: 5.8008e-06  max_mem: 17674M
[01/19 10:05:04] d2.utils.events INFO:  eta: 10:13:00  iter: 18179  total_loss: 61.85  loss_ce: 1.999  loss_mask: 0.6267  loss_dice: 3.267  loss_ce_0: 3.455  loss_mask_0: 0.6625  loss_dice_0: 3.545  loss_ce_1: 2.318  loss_mask_1: 0.6397  loss_dice_1: 3.404  loss_ce_2: 2.144  loss_mask_2: 0.6302  loss_dice_2: 3.338  loss_ce_3: 2.126  loss_mask_3: 0.6308  loss_dice_3: 3.284  loss_ce_4: 2.054  loss_mask_4: 0.6303  loss_dice_4: 3.285  loss_ce_5: 2.035  loss_mask_5: 0.6313  loss_dice_5: 3.279  loss_ce_6: 2.021  loss_mask_6: 0.6298  loss_dice_6: 3.261  loss_ce_7: 2.011  loss_mask_7: 0.6311  loss_dice_7: 3.259  loss_ce_8: 2.003  loss_mask_8: 0.6302  loss_dice_8: 3.266  time: 1.6937  data_time: 0.3467  lr: 5.7961e-06  max_mem: 17674M
[01/19 10:05:38] d2.utils.events INFO:  eta: 10:13:13  iter: 18199  total_loss: 60.43  loss_ce: 1.895  loss_mask: 0.6109  loss_dice: 3.305  loss_ce_0: 3.359  loss_mask_0: 0.6245  loss_dice_0: 3.591  loss_ce_1: 2.11  loss_mask_1: 0.6201  loss_dice_1: 3.455  loss_ce_2: 2.009  loss_mask_2: 0.6148  loss_dice_2: 3.383  loss_ce_3: 1.985  loss_mask_3: 0.6193  loss_dice_3: 3.323  loss_ce_4: 1.936  loss_mask_4: 0.6177  loss_dice_4: 3.315  loss_ce_5: 1.9  loss_mask_5: 0.6168  loss_dice_5: 3.317  loss_ce_6: 1.899  loss_mask_6: 0.6125  loss_dice_6: 3.302  loss_ce_7: 1.878  loss_mask_7: 0.6135  loss_dice_7: 3.301  loss_ce_8: 1.875  loss_mask_8: 0.6087  loss_dice_8: 3.31  time: 1.6937  data_time: 0.3612  lr: 5.7913e-06  max_mem: 17674M
[01/19 10:06:12] d2.utils.events INFO:  eta: 10:12:51  iter: 18219  total_loss: 60.82  loss_ce: 1.9  loss_mask: 0.6187  loss_dice: 3.25  loss_ce_0: 3.424  loss_mask_0: 0.6443  loss_dice_0: 3.527  loss_ce_1: 2.178  loss_mask_1: 0.6203  loss_dice_1: 3.388  loss_ce_2: 2.03  loss_mask_2: 0.6172  loss_dice_2: 3.321  loss_ce_3: 1.967  loss_mask_3: 0.6146  loss_dice_3: 3.272  loss_ce_4: 1.924  loss_mask_4: 0.6172  loss_dice_4: 3.263  loss_ce_5: 1.903  loss_mask_5: 0.616  loss_dice_5: 3.264  loss_ce_6: 1.912  loss_mask_6: 0.6174  loss_dice_6: 3.24  loss_ce_7: 1.908  loss_mask_7: 0.6196  loss_dice_7: 3.246  loss_ce_8: 1.914  loss_mask_8: 0.6197  loss_dice_8: 3.255  time: 1.6937  data_time: 0.3267  lr: 5.7865e-06  max_mem: 17674M
[01/19 10:06:45] d2.utils.events INFO:  eta: 10:11:46  iter: 18239  total_loss: 61.24  loss_ce: 2.016  loss_mask: 0.6105  loss_dice: 3.27  loss_ce_0: 3.424  loss_mask_0: 0.633  loss_dice_0: 3.55  loss_ce_1: 2.206  loss_mask_1: 0.6201  loss_dice_1: 3.409  loss_ce_2: 2.098  loss_mask_2: 0.6176  loss_dice_2: 3.34  loss_ce_3: 2.09  loss_mask_3: 0.6127  loss_dice_3: 3.293  loss_ce_4: 2.029  loss_mask_4: 0.6131  loss_dice_4: 3.288  loss_ce_5: 2.005  loss_mask_5: 0.6122  loss_dice_5: 3.285  loss_ce_6: 2.022  loss_mask_6: 0.6095  loss_dice_6: 3.279  loss_ce_7: 2.021  loss_mask_7: 0.6119  loss_dice_7: 3.272  loss_ce_8: 2.008  loss_mask_8: 0.6102  loss_dice_8: 3.273  time: 1.6937  data_time: 0.3139  lr: 5.7817e-06  max_mem: 17674M
[01/19 10:07:19] d2.utils.events INFO:  eta: 10:11:25  iter: 18259  total_loss: 61.06  loss_ce: 1.929  loss_mask: 0.6294  loss_dice: 3.282  loss_ce_0: 3.421  loss_mask_0: 0.6383  loss_dice_0: 3.548  loss_ce_1: 2.181  loss_mask_1: 0.6284  loss_dice_1: 3.423  loss_ce_2: 2.064  loss_mask_2: 0.6273  loss_dice_2: 3.353  loss_ce_3: 2.004  loss_mask_3: 0.6258  loss_dice_3: 3.31  loss_ce_4: 1.962  loss_mask_4: 0.6265  loss_dice_4: 3.305  loss_ce_5: 1.963  loss_mask_5: 0.6273  loss_dice_5: 3.304  loss_ce_6: 1.951  loss_mask_6: 0.6273  loss_dice_6: 3.287  loss_ce_7: 1.92  loss_mask_7: 0.6313  loss_dice_7: 3.285  loss_ce_8: 1.93  loss_mask_8: 0.6285  loss_dice_8: 3.289  time: 1.6937  data_time: 0.3380  lr: 5.7769e-06  max_mem: 17674M
[01/19 10:07:52] d2.utils.events INFO:  eta: 10:10:45  iter: 18279  total_loss: 61.3  loss_ce: 2.008  loss_mask: 0.6301  loss_dice: 3.287  loss_ce_0: 3.426  loss_mask_0: 0.6465  loss_dice_0: 3.551  loss_ce_1: 2.205  loss_mask_1: 0.639  loss_dice_1: 3.409  loss_ce_2: 2.092  loss_mask_2: 0.6366  loss_dice_2: 3.353  loss_ce_3: 2.066  loss_mask_3: 0.6282  loss_dice_3: 3.307  loss_ce_4: 2.036  loss_mask_4: 0.6305  loss_dice_4: 3.303  loss_ce_5: 2.021  loss_mask_5: 0.6292  loss_dice_5: 3.303  loss_ce_6: 2.004  loss_mask_6: 0.6326  loss_dice_6: 3.296  loss_ce_7: 1.986  loss_mask_7: 0.6311  loss_dice_7: 3.293  loss_ce_8: 1.979  loss_mask_8: 0.6313  loss_dice_8: 3.287  time: 1.6936  data_time: 0.3462  lr: 5.7722e-06  max_mem: 17674M
[01/19 10:08:26] d2.utils.events INFO:  eta: 10:10:30  iter: 18299  total_loss: 61.59  loss_ce: 1.982  loss_mask: 0.6334  loss_dice: 3.235  loss_ce_0: 3.439  loss_mask_0: 0.6516  loss_dice_0: 3.512  loss_ce_1: 2.23  loss_mask_1: 0.6427  loss_dice_1: 3.37  loss_ce_2: 2.104  loss_mask_2: 0.6345  loss_dice_2: 3.305  loss_ce_3: 2.072  loss_mask_3: 0.6356  loss_dice_3: 3.255  loss_ce_4: 2.021  loss_mask_4: 0.6363  loss_dice_4: 3.26  loss_ce_5: 2.008  loss_mask_5: 0.6324  loss_dice_5: 3.257  loss_ce_6: 1.988  loss_mask_6: 0.6334  loss_dice_6: 3.244  loss_ce_7: 1.975  loss_mask_7: 0.6334  loss_dice_7: 3.246  loss_ce_8: 1.946  loss_mask_8: 0.6344  loss_dice_8: 3.24  time: 1.6937  data_time: 0.3318  lr: 5.7674e-06  max_mem: 17674M
[01/19 10:09:00] d2.utils.events INFO:  eta: 10:09:55  iter: 18319  total_loss: 61.53  loss_ce: 1.97  loss_mask: 0.6358  loss_dice: 3.279  loss_ce_0: 3.374  loss_mask_0: 0.6559  loss_dice_0: 3.559  loss_ce_1: 2.213  loss_mask_1: 0.6381  loss_dice_1: 3.425  loss_ce_2: 2.092  loss_mask_2: 0.6324  loss_dice_2: 3.351  loss_ce_3: 2.051  loss_mask_3: 0.6318  loss_dice_3: 3.302  loss_ce_4: 2  loss_mask_4: 0.6328  loss_dice_4: 3.299  loss_ce_5: 1.979  loss_mask_5: 0.6335  loss_dice_5: 3.296  loss_ce_6: 1.988  loss_mask_6: 0.6346  loss_dice_6: 3.288  loss_ce_7: 1.972  loss_mask_7: 0.6368  loss_dice_7: 3.282  loss_ce_8: 1.959  loss_mask_8: 0.6358  loss_dice_8: 3.276  time: 1.6936  data_time: 0.3357  lr: 5.7626e-06  max_mem: 17674M
[01/19 10:09:34] d2.utils.events INFO:  eta: 10:09:22  iter: 18339  total_loss: 60.18  loss_ce: 1.934  loss_mask: 0.6146  loss_dice: 3.219  loss_ce_0: 3.443  loss_mask_0: 0.6251  loss_dice_0: 3.535  loss_ce_1: 2.164  loss_mask_1: 0.6164  loss_dice_1: 3.369  loss_ce_2: 2.039  loss_mask_2: 0.6125  loss_dice_2: 3.293  loss_ce_3: 1.979  loss_mask_3: 0.6084  loss_dice_3: 3.252  loss_ce_4: 1.957  loss_mask_4: 0.608  loss_dice_4: 3.243  loss_ce_5: 1.948  loss_mask_5: 0.6091  loss_dice_5: 3.242  loss_ce_6: 1.939  loss_mask_6: 0.6112  loss_dice_6: 3.232  loss_ce_7: 1.929  loss_mask_7: 0.6112  loss_dice_7: 3.224  loss_ce_8: 1.936  loss_mask_8: 0.6159  loss_dice_8: 3.219  time: 1.6936  data_time: 0.3338  lr: 5.7578e-06  max_mem: 17674M
[01/19 10:10:08] d2.utils.events INFO:  eta: 10:08:31  iter: 18359  total_loss: 59.94  loss_ce: 1.936  loss_mask: 0.614  loss_dice: 3.247  loss_ce_0: 3.364  loss_mask_0: 0.6319  loss_dice_0: 3.533  loss_ce_1: 2.179  loss_mask_1: 0.6127  loss_dice_1: 3.373  loss_ce_2: 2.065  loss_mask_2: 0.6089  loss_dice_2: 3.307  loss_ce_3: 1.979  loss_mask_3: 0.6072  loss_dice_3: 3.262  loss_ce_4: 1.955  loss_mask_4: 0.609  loss_dice_4: 3.261  loss_ce_5: 1.949  loss_mask_5: 0.6136  loss_dice_5: 3.252  loss_ce_6: 1.943  loss_mask_6: 0.6099  loss_dice_6: 3.247  loss_ce_7: 1.924  loss_mask_7: 0.6133  loss_dice_7: 3.247  loss_ce_8: 1.911  loss_mask_8: 0.6128  loss_dice_8: 3.25  time: 1.6936  data_time: 0.3495  lr: 5.753e-06  max_mem: 17674M
[01/19 10:10:42] d2.utils.events INFO:  eta: 10:07:57  iter: 18379  total_loss: 61.23  loss_ce: 1.957  loss_mask: 0.6245  loss_dice: 3.287  loss_ce_0: 3.476  loss_mask_0: 0.6403  loss_dice_0: 3.549  loss_ce_1: 2.143  loss_mask_1: 0.6263  loss_dice_1: 3.425  loss_ce_2: 2.034  loss_mask_2: 0.6258  loss_dice_2: 3.351  loss_ce_3: 2.019  loss_mask_3: 0.6233  loss_dice_3: 3.306  loss_ce_4: 1.974  loss_mask_4: 0.6204  loss_dice_4: 3.301  loss_ce_5: 1.953  loss_mask_5: 0.6245  loss_dice_5: 3.302  loss_ce_6: 1.967  loss_mask_6: 0.6231  loss_dice_6: 3.286  loss_ce_7: 1.931  loss_mask_7: 0.6249  loss_dice_7: 3.277  loss_ce_8: 1.928  loss_mask_8: 0.6239  loss_dice_8: 3.286  time: 1.6936  data_time: 0.3345  lr: 5.7482e-06  max_mem: 17674M
[01/19 10:11:16] d2.utils.events INFO:  eta: 10:07:51  iter: 18399  total_loss: 60.16  loss_ce: 1.888  loss_mask: 0.6174  loss_dice: 3.264  loss_ce_0: 3.291  loss_mask_0: 0.6355  loss_dice_0: 3.538  loss_ce_1: 2.121  loss_mask_1: 0.6255  loss_dice_1: 3.395  loss_ce_2: 2.002  loss_mask_2: 0.6215  loss_dice_2: 3.325  loss_ce_3: 1.953  loss_mask_3: 0.6102  loss_dice_3: 3.288  loss_ce_4: 1.923  loss_mask_4: 0.6145  loss_dice_4: 3.28  loss_ce_5: 1.893  loss_mask_5: 0.6133  loss_dice_5: 3.272  loss_ce_6: 1.893  loss_mask_6: 0.6157  loss_dice_6: 3.266  loss_ce_7: 1.892  loss_mask_7: 0.6147  loss_dice_7: 3.262  loss_ce_8: 1.885  loss_mask_8: 0.6173  loss_dice_8: 3.265  time: 1.6936  data_time: 0.3416  lr: 5.7434e-06  max_mem: 17674M
[01/19 10:11:50] d2.utils.events INFO:  eta: 10:07:18  iter: 18419  total_loss: 60.07  loss_ce: 1.894  loss_mask: 0.6277  loss_dice: 3.236  loss_ce_0: 3.399  loss_mask_0: 0.6504  loss_dice_0: 3.528  loss_ce_1: 2.127  loss_mask_1: 0.64  loss_dice_1: 3.376  loss_ce_2: 2.015  loss_mask_2: 0.6304  loss_dice_2: 3.307  loss_ce_3: 1.972  loss_mask_3: 0.6275  loss_dice_3: 3.265  loss_ce_4: 1.945  loss_mask_4: 0.6298  loss_dice_4: 3.255  loss_ce_5: 1.914  loss_mask_5: 0.6307  loss_dice_5: 3.256  loss_ce_6: 1.888  loss_mask_6: 0.6305  loss_dice_6: 3.244  loss_ce_7: 1.888  loss_mask_7: 0.6301  loss_dice_7: 3.241  loss_ce_8: 1.886  loss_mask_8: 0.6297  loss_dice_8: 3.239  time: 1.6937  data_time: 0.3571  lr: 5.7387e-06  max_mem: 17674M
[01/19 10:12:24] d2.utils.events INFO:  eta: 10:06:47  iter: 18439  total_loss: 60.83  loss_ce: 1.965  loss_mask: 0.6221  loss_dice: 3.252  loss_ce_0: 3.406  loss_mask_0: 0.6468  loss_dice_0: 3.528  loss_ce_1: 2.199  loss_mask_1: 0.6217  loss_dice_1: 3.393  loss_ce_2: 2.089  loss_mask_2: 0.6246  loss_dice_2: 3.331  loss_ce_3: 2.06  loss_mask_3: 0.6231  loss_dice_3: 3.276  loss_ce_4: 2.019  loss_mask_4: 0.6239  loss_dice_4: 3.276  loss_ce_5: 1.989  loss_mask_5: 0.6234  loss_dice_5: 3.27  loss_ce_6: 1.98  loss_mask_6: 0.6205  loss_dice_6: 3.256  loss_ce_7: 1.979  loss_mask_7: 0.6201  loss_dice_7: 3.261  loss_ce_8: 1.952  loss_mask_8: 0.6194  loss_dice_8: 3.264  time: 1.6937  data_time: 0.3374  lr: 5.7339e-06  max_mem: 17674M
[01/19 10:12:58] d2.utils.events INFO:  eta: 10:06:16  iter: 18459  total_loss: 59.98  loss_ce: 1.897  loss_mask: 0.6136  loss_dice: 3.262  loss_ce_0: 3.414  loss_mask_0: 0.6336  loss_dice_0: 3.548  loss_ce_1: 2.125  loss_mask_1: 0.6218  loss_dice_1: 3.401  loss_ce_2: 2.046  loss_mask_2: 0.6167  loss_dice_2: 3.33  loss_ce_3: 1.981  loss_mask_3: 0.613  loss_dice_3: 3.283  loss_ce_4: 1.946  loss_mask_4: 0.6133  loss_dice_4: 3.275  loss_ce_5: 1.924  loss_mask_5: 0.6117  loss_dice_5: 3.274  loss_ce_6: 1.93  loss_mask_6: 0.6138  loss_dice_6: 3.261  loss_ce_7: 1.901  loss_mask_7: 0.6139  loss_dice_7: 3.263  loss_ce_8: 1.895  loss_mask_8: 0.6141  loss_dice_8: 3.261  time: 1.6937  data_time: 0.3484  lr: 5.7291e-06  max_mem: 17674M
[01/19 10:13:32] d2.utils.events INFO:  eta: 10:05:42  iter: 18479  total_loss: 60.07  loss_ce: 1.879  loss_mask: 0.6323  loss_dice: 3.263  loss_ce_0: 3.42  loss_mask_0: 0.6304  loss_dice_0: 3.532  loss_ce_1: 2.136  loss_mask_1: 0.637  loss_dice_1: 3.386  loss_ce_2: 2.007  loss_mask_2: 0.6356  loss_dice_2: 3.322  loss_ce_3: 1.985  loss_mask_3: 0.6296  loss_dice_3: 3.285  loss_ce_4: 1.927  loss_mask_4: 0.6316  loss_dice_4: 3.275  loss_ce_5: 1.897  loss_mask_5: 0.6305  loss_dice_5: 3.276  loss_ce_6: 1.899  loss_mask_6: 0.6286  loss_dice_6: 3.263  loss_ce_7: 1.893  loss_mask_7: 0.6325  loss_dice_7: 3.262  loss_ce_8: 1.881  loss_mask_8: 0.6316  loss_dice_8: 3.265  time: 1.6937  data_time: 0.3310  lr: 5.7243e-06  max_mem: 17674M
[01/19 10:14:07] d2.utils.events INFO:  eta: 10:05:02  iter: 18499  total_loss: 59.12  loss_ce: 1.841  loss_mask: 0.6173  loss_dice: 3.247  loss_ce_0: 3.355  loss_mask_0: 0.629  loss_dice_0: 3.523  loss_ce_1: 2.07  loss_mask_1: 0.6197  loss_dice_1: 3.39  loss_ce_2: 1.968  loss_mask_2: 0.6167  loss_dice_2: 3.324  loss_ce_3: 1.899  loss_mask_3: 0.6157  loss_dice_3: 3.27  loss_ce_4: 1.853  loss_mask_4: 0.6137  loss_dice_4: 3.265  loss_ce_5: 1.837  loss_mask_5: 0.6154  loss_dice_5: 3.265  loss_ce_6: 1.84  loss_mask_6: 0.6164  loss_dice_6: 3.243  loss_ce_7: 1.82  loss_mask_7: 0.6161  loss_dice_7: 3.251  loss_ce_8: 1.814  loss_mask_8: 0.6177  loss_dice_8: 3.247  time: 1.6937  data_time: 0.3500  lr: 5.7195e-06  max_mem: 17674M
[01/19 10:14:41] d2.utils.events INFO:  eta: 10:04:42  iter: 18519  total_loss: 60.16  loss_ce: 1.89  loss_mask: 0.6317  loss_dice: 3.259  loss_ce_0: 3.329  loss_mask_0: 0.6579  loss_dice_0: 3.529  loss_ce_1: 2.17  loss_mask_1: 0.6379  loss_dice_1: 3.407  loss_ce_2: 2.071  loss_mask_2: 0.6339  loss_dice_2: 3.322  loss_ce_3: 1.979  loss_mask_3: 0.6312  loss_dice_3: 3.281  loss_ce_4: 1.95  loss_mask_4: 0.6336  loss_dice_4: 3.285  loss_ce_5: 1.924  loss_mask_5: 0.6338  loss_dice_5: 3.272  loss_ce_6: 1.918  loss_mask_6: 0.6329  loss_dice_6: 3.266  loss_ce_7: 1.903  loss_mask_7: 0.6325  loss_dice_7: 3.263  loss_ce_8: 1.884  loss_mask_8: 0.633  loss_dice_8: 3.266  time: 1.6937  data_time: 0.3455  lr: 5.7147e-06  max_mem: 17674M
[01/19 10:15:15] d2.utils.events INFO:  eta: 10:04:10  iter: 18539  total_loss: 60.95  loss_ce: 1.905  loss_mask: 0.6191  loss_dice: 3.27  loss_ce_0: 3.348  loss_mask_0: 0.6467  loss_dice_0: 3.536  loss_ce_1: 2.098  loss_mask_1: 0.6374  loss_dice_1: 3.416  loss_ce_2: 1.993  loss_mask_2: 0.628  loss_dice_2: 3.335  loss_ce_3: 1.957  loss_mask_3: 0.6216  loss_dice_3: 3.29  loss_ce_4: 1.94  loss_mask_4: 0.6204  loss_dice_4: 3.293  loss_ce_5: 1.91  loss_mask_5: 0.623  loss_dice_5: 3.285  loss_ce_6: 1.889  loss_mask_6: 0.6172  loss_dice_6: 3.277  loss_ce_7: 1.891  loss_mask_7: 0.6175  loss_dice_7: 3.275  loss_ce_8: 1.902  loss_mask_8: 0.619  loss_dice_8: 3.275  time: 1.6937  data_time: 0.3335  lr: 5.7099e-06  max_mem: 17674M
[01/19 10:15:49] d2.utils.events INFO:  eta: 10:03:48  iter: 18559  total_loss: 60.06  loss_ce: 1.891  loss_mask: 0.6071  loss_dice: 3.244  loss_ce_0: 3.326  loss_mask_0: 0.632  loss_dice_0: 3.522  loss_ce_1: 2.096  loss_mask_1: 0.6182  loss_dice_1: 3.383  loss_ce_2: 2.016  loss_mask_2: 0.6121  loss_dice_2: 3.319  loss_ce_3: 1.978  loss_mask_3: 0.6102  loss_dice_3: 3.276  loss_ce_4: 1.925  loss_mask_4: 0.6116  loss_dice_4: 3.261  loss_ce_5: 1.924  loss_mask_5: 0.6108  loss_dice_5: 3.265  loss_ce_6: 1.915  loss_mask_6: 0.6069  loss_dice_6: 3.245  loss_ce_7: 1.892  loss_mask_7: 0.6105  loss_dice_7: 3.249  loss_ce_8: 1.884  loss_mask_8: 0.6082  loss_dice_8: 3.249  time: 1.6937  data_time: 0.3621  lr: 5.7051e-06  max_mem: 17674M
[01/19 10:16:22] d2.utils.events INFO:  eta: 10:02:53  iter: 18579  total_loss: 60.31  loss_ce: 1.909  loss_mask: 0.6407  loss_dice: 3.214  loss_ce_0: 3.372  loss_mask_0: 0.6719  loss_dice_0: 3.514  loss_ce_1: 2.169  loss_mask_1: 0.6523  loss_dice_1: 3.357  loss_ce_2: 2.052  loss_mask_2: 0.6466  loss_dice_2: 3.293  loss_ce_3: 1.986  loss_mask_3: 0.6379  loss_dice_3: 3.242  loss_ce_4: 1.958  loss_mask_4: 0.6351  loss_dice_4: 3.239  loss_ce_5: 1.933  loss_mask_5: 0.638  loss_dice_5: 3.233  loss_ce_6: 1.931  loss_mask_6: 0.6363  loss_dice_6: 3.214  loss_ce_7: 1.939  loss_mask_7: 0.637  loss_dice_7: 3.211  loss_ce_8: 1.922  loss_mask_8: 0.6382  loss_dice_8: 3.217  time: 1.6937  data_time: 0.3247  lr: 5.7004e-06  max_mem: 17674M
[01/19 10:16:56] d2.utils.events INFO:  eta: 10:02:13  iter: 18599  total_loss: 60.33  loss_ce: 1.888  loss_mask: 0.6226  loss_dice: 3.258  loss_ce_0: 3.318  loss_mask_0: 0.6456  loss_dice_0: 3.532  loss_ce_1: 2.107  loss_mask_1: 0.6318  loss_dice_1: 3.398  loss_ce_2: 2.015  loss_mask_2: 0.6239  loss_dice_2: 3.328  loss_ce_3: 1.949  loss_mask_3: 0.6215  loss_dice_3: 3.278  loss_ce_4: 1.936  loss_mask_4: 0.6216  loss_dice_4: 3.282  loss_ce_5: 1.893  loss_mask_5: 0.6234  loss_dice_5: 3.273  loss_ce_6: 1.907  loss_mask_6: 0.625  loss_dice_6: 3.254  loss_ce_7: 1.9  loss_mask_7: 0.6254  loss_dice_7: 3.255  loss_ce_8: 1.897  loss_mask_8: 0.6262  loss_dice_8: 3.252  time: 1.6937  data_time: 0.3231  lr: 5.6956e-06  max_mem: 17674M
[01/19 10:17:30] d2.utils.events INFO:  eta: 10:01:37  iter: 18619  total_loss: 60.21  loss_ce: 1.926  loss_mask: 0.6067  loss_dice: 3.227  loss_ce_0: 3.329  loss_mask_0: 0.6342  loss_dice_0: 3.557  loss_ce_1: 2.149  loss_mask_1: 0.6164  loss_dice_1: 3.39  loss_ce_2: 2.052  loss_mask_2: 0.607  loss_dice_2: 3.305  loss_ce_3: 2.028  loss_mask_3: 0.6075  loss_dice_3: 3.257  loss_ce_4: 1.983  loss_mask_4: 0.6081  loss_dice_4: 3.246  loss_ce_5: 1.959  loss_mask_5: 0.6106  loss_dice_5: 3.242  loss_ce_6: 1.945  loss_mask_6: 0.6096  loss_dice_6: 3.234  loss_ce_7: 1.916  loss_mask_7: 0.6095  loss_dice_7: 3.237  loss_ce_8: 1.918  loss_mask_8: 0.6097  loss_dice_8: 3.227  time: 1.6937  data_time: 0.3340  lr: 5.6908e-06  max_mem: 17674M
[01/19 10:18:04] d2.utils.events INFO:  eta: 10:01:06  iter: 18639  total_loss: 60.6  loss_ce: 1.928  loss_mask: 0.6243  loss_dice: 3.23  loss_ce_0: 3.373  loss_mask_0: 0.65  loss_dice_0: 3.526  loss_ce_1: 2.176  loss_mask_1: 0.6305  loss_dice_1: 3.38  loss_ce_2: 2.04  loss_mask_2: 0.6224  loss_dice_2: 3.296  loss_ce_3: 1.99  loss_mask_3: 0.6231  loss_dice_3: 3.25  loss_ce_4: 1.952  loss_mask_4: 0.6271  loss_dice_4: 3.242  loss_ce_5: 1.927  loss_mask_5: 0.6248  loss_dice_5: 3.24  loss_ce_6: 1.928  loss_mask_6: 0.6269  loss_dice_6: 3.231  loss_ce_7: 1.918  loss_mask_7: 0.6261  loss_dice_7: 3.235  loss_ce_8: 1.913  loss_mask_8: 0.6262  loss_dice_8: 3.229  time: 1.6937  data_time: 0.3469  lr: 5.686e-06  max_mem: 17674M
[01/19 10:18:37] d2.utils.events INFO:  eta: 10:00:35  iter: 18659  total_loss: 60.93  loss_ce: 1.963  loss_mask: 0.6352  loss_dice: 3.215  loss_ce_0: 3.365  loss_mask_0: 0.6655  loss_dice_0: 3.516  loss_ce_1: 2.17  loss_mask_1: 0.648  loss_dice_1: 3.377  loss_ce_2: 2.09  loss_mask_2: 0.6425  loss_dice_2: 3.28  loss_ce_3: 2.025  loss_mask_3: 0.6388  loss_dice_3: 3.227  loss_ce_4: 1.995  loss_mask_4: 0.6371  loss_dice_4: 3.225  loss_ce_5: 1.977  loss_mask_5: 0.6353  loss_dice_5: 3.221  loss_ce_6: 1.963  loss_mask_6: 0.6363  loss_dice_6: 3.217  loss_ce_7: 1.964  loss_mask_7: 0.6351  loss_dice_7: 3.22  loss_ce_8: 1.967  loss_mask_8: 0.6372  loss_dice_8: 3.214  time: 1.6937  data_time: 0.3175  lr: 5.6812e-06  max_mem: 17674M
[01/19 10:19:11] d2.utils.events INFO:  eta: 10:00:01  iter: 18679  total_loss: 61.32  loss_ce: 1.939  loss_mask: 0.6249  loss_dice: 3.296  loss_ce_0: 3.354  loss_mask_0: 0.646  loss_dice_0: 3.578  loss_ce_1: 2.224  loss_mask_1: 0.6314  loss_dice_1: 3.427  loss_ce_2: 2.105  loss_mask_2: 0.6284  loss_dice_2: 3.358  loss_ce_3: 2.035  loss_mask_3: 0.6261  loss_dice_3: 3.318  loss_ce_4: 1.979  loss_mask_4: 0.6258  loss_dice_4: 3.314  loss_ce_5: 1.953  loss_mask_5: 0.6271  loss_dice_5: 3.314  loss_ce_6: 1.96  loss_mask_6: 0.624  loss_dice_6: 3.3  loss_ce_7: 1.928  loss_mask_7: 0.6269  loss_dice_7: 3.302  loss_ce_8: 1.925  loss_mask_8: 0.6268  loss_dice_8: 3.3  time: 1.6937  data_time: 0.3448  lr: 5.6764e-06  max_mem: 17674M
[01/19 10:19:45] d2.utils.events INFO:  eta: 9:59:31  iter: 18699  total_loss: 60.42  loss_ce: 1.945  loss_mask: 0.627  loss_dice: 3.239  loss_ce_0: 3.362  loss_mask_0: 0.6376  loss_dice_0: 3.514  loss_ce_1: 2.123  loss_mask_1: 0.6257  loss_dice_1: 3.376  loss_ce_2: 2.035  loss_mask_2: 0.6235  loss_dice_2: 3.301  loss_ce_3: 2.002  loss_mask_3: 0.6213  loss_dice_3: 3.268  loss_ce_4: 1.97  loss_mask_4: 0.6268  loss_dice_4: 3.261  loss_ce_5: 1.959  loss_mask_5: 0.626  loss_dice_5: 3.257  loss_ce_6: 1.974  loss_mask_6: 0.6253  loss_dice_6: 3.241  loss_ce_7: 1.94  loss_mask_7: 0.627  loss_dice_7: 3.245  loss_ce_8: 1.928  loss_mask_8: 0.6258  loss_dice_8: 3.246  time: 1.6937  data_time: 0.3275  lr: 5.6716e-06  max_mem: 17674M
[01/19 10:20:19] d2.utils.events INFO:  eta: 9:58:58  iter: 18719  total_loss: 61.49  loss_ce: 1.928  loss_mask: 0.6296  loss_dice: 3.295  loss_ce_0: 3.353  loss_mask_0: 0.6375  loss_dice_0: 3.568  loss_ce_1: 2.245  loss_mask_1: 0.6321  loss_dice_1: 3.424  loss_ce_2: 2.095  loss_mask_2: 0.6293  loss_dice_2: 3.368  loss_ce_3: 2.041  loss_mask_3: 0.6262  loss_dice_3: 3.306  loss_ce_4: 1.999  loss_mask_4: 0.625  loss_dice_4: 3.304  loss_ce_5: 1.967  loss_mask_5: 0.6286  loss_dice_5: 3.309  loss_ce_6: 1.955  loss_mask_6: 0.6233  loss_dice_6: 3.299  loss_ce_7: 1.938  loss_mask_7: 0.6257  loss_dice_7: 3.296  loss_ce_8: 1.93  loss_mask_8: 0.6267  loss_dice_8: 3.303  time: 1.6937  data_time: 0.3416  lr: 5.6668e-06  max_mem: 17674M
[01/19 10:20:53] d2.utils.events INFO:  eta: 9:58:24  iter: 18739  total_loss: 61.67  loss_ce: 2.036  loss_mask: 0.6172  loss_dice: 3.291  loss_ce_0: 3.416  loss_mask_0: 0.6407  loss_dice_0: 3.541  loss_ce_1: 2.184  loss_mask_1: 0.6251  loss_dice_1: 3.421  loss_ce_2: 2.083  loss_mask_2: 0.6222  loss_dice_2: 3.354  loss_ce_3: 2.059  loss_mask_3: 0.6191  loss_dice_3: 3.315  loss_ce_4: 2.03  loss_mask_4: 0.6218  loss_dice_4: 3.313  loss_ce_5: 2.021  loss_mask_5: 0.6212  loss_dice_5: 3.307  loss_ce_6: 2.021  loss_mask_6: 0.6224  loss_dice_6: 3.296  loss_ce_7: 2.003  loss_mask_7: 0.6189  loss_dice_7: 3.303  loss_ce_8: 2.017  loss_mask_8: 0.6179  loss_dice_8: 3.294  time: 1.6937  data_time: 0.3391  lr: 5.662e-06  max_mem: 17674M
[01/19 10:21:27] d2.utils.events INFO:  eta: 9:58:06  iter: 18759  total_loss: 60.75  loss_ce: 1.95  loss_mask: 0.6245  loss_dice: 3.239  loss_ce_0: 3.366  loss_mask_0: 0.6532  loss_dice_0: 3.527  loss_ce_1: 2.169  loss_mask_1: 0.6295  loss_dice_1: 3.373  loss_ce_2: 2.065  loss_mask_2: 0.6272  loss_dice_2: 3.308  loss_ce_3: 2.021  loss_mask_3: 0.6257  loss_dice_3: 3.264  loss_ce_4: 1.978  loss_mask_4: 0.6243  loss_dice_4: 3.26  loss_ce_5: 1.987  loss_mask_5: 0.6262  loss_dice_5: 3.253  loss_ce_6: 1.965  loss_mask_6: 0.6242  loss_dice_6: 3.243  loss_ce_7: 1.959  loss_mask_7: 0.624  loss_dice_7: 3.239  loss_ce_8: 1.946  loss_mask_8: 0.6238  loss_dice_8: 3.243  time: 1.6937  data_time: 0.3374  lr: 5.6572e-06  max_mem: 17674M
[01/19 10:22:01] d2.utils.events INFO:  eta: 9:57:36  iter: 18779  total_loss: 60.59  loss_ce: 1.908  loss_mask: 0.6241  loss_dice: 3.268  loss_ce_0: 3.383  loss_mask_0: 0.6417  loss_dice_0: 3.554  loss_ce_1: 2.17  loss_mask_1: 0.638  loss_dice_1: 3.417  loss_ce_2: 2.071  loss_mask_2: 0.6344  loss_dice_2: 3.348  loss_ce_3: 2.007  loss_mask_3: 0.626  loss_dice_3: 3.298  loss_ce_4: 1.965  loss_mask_4: 0.6265  loss_dice_4: 3.29  loss_ce_5: 1.934  loss_mask_5: 0.6291  loss_dice_5: 3.29  loss_ce_6: 1.938  loss_mask_6: 0.6246  loss_dice_6: 3.271  loss_ce_7: 1.92  loss_mask_7: 0.6242  loss_dice_7: 3.27  loss_ce_8: 1.917  loss_mask_8: 0.6266  loss_dice_8: 3.269  time: 1.6937  data_time: 0.3337  lr: 5.6524e-06  max_mem: 17674M
[01/19 10:22:35] d2.utils.events INFO:  eta: 9:57:44  iter: 18799  total_loss: 61.66  loss_ce: 2.001  loss_mask: 0.6228  loss_dice: 3.27  loss_ce_0: 3.438  loss_mask_0: 0.6475  loss_dice_0: 3.555  loss_ce_1: 2.209  loss_mask_1: 0.6322  loss_dice_1: 3.414  loss_ce_2: 2.136  loss_mask_2: 0.6246  loss_dice_2: 3.329  loss_ce_3: 2.074  loss_mask_3: 0.6214  loss_dice_3: 3.292  loss_ce_4: 2.036  loss_mask_4: 0.6234  loss_dice_4: 3.286  loss_ce_5: 2.014  loss_mask_5: 0.6235  loss_dice_5: 3.281  loss_ce_6: 2.011  loss_mask_6: 0.6213  loss_dice_6: 3.272  loss_ce_7: 1.994  loss_mask_7: 0.6211  loss_dice_7: 3.269  loss_ce_8: 2.002  loss_mask_8: 0.6228  loss_dice_8: 3.269  time: 1.6937  data_time: 0.3464  lr: 5.6476e-06  max_mem: 17674M
[01/19 10:23:09] d2.utils.events INFO:  eta: 9:57:16  iter: 18819  total_loss: 60.01  loss_ce: 1.921  loss_mask: 0.6229  loss_dice: 3.202  loss_ce_0: 3.358  loss_mask_0: 0.6473  loss_dice_0: 3.51  loss_ce_1: 2.23  loss_mask_1: 0.6262  loss_dice_1: 3.354  loss_ce_2: 2.101  loss_mask_2: 0.6236  loss_dice_2: 3.269  loss_ce_3: 2.042  loss_mask_3: 0.62  loss_dice_3: 3.227  loss_ce_4: 1.985  loss_mask_4: 0.6218  loss_dice_4: 3.223  loss_ce_5: 1.961  loss_mask_5: 0.6248  loss_dice_5: 3.22  loss_ce_6: 1.941  loss_mask_6: 0.6215  loss_dice_6: 3.211  loss_ce_7: 1.93  loss_mask_7: 0.6236  loss_dice_7: 3.21  loss_ce_8: 1.922  loss_mask_8: 0.6241  loss_dice_8: 3.203  time: 1.6937  data_time: 0.3432  lr: 5.6428e-06  max_mem: 17674M
[01/19 10:23:42] d2.utils.events INFO:  eta: 9:56:38  iter: 18839  total_loss: 60.47  loss_ce: 1.922  loss_mask: 0.6333  loss_dice: 3.23  loss_ce_0: 3.376  loss_mask_0: 0.6511  loss_dice_0: 3.504  loss_ce_1: 2.224  loss_mask_1: 0.6378  loss_dice_1: 3.359  loss_ce_2: 2.09  loss_mask_2: 0.6346  loss_dice_2: 3.291  loss_ce_3: 2.009  loss_mask_3: 0.629  loss_dice_3: 3.251  loss_ce_4: 1.962  loss_mask_4: 0.6304  loss_dice_4: 3.244  loss_ce_5: 1.949  loss_mask_5: 0.6291  loss_dice_5: 3.241  loss_ce_6: 1.956  loss_mask_6: 0.6316  loss_dice_6: 3.226  loss_ce_7: 1.928  loss_mask_7: 0.6303  loss_dice_7: 3.23  loss_ce_8: 1.933  loss_mask_8: 0.6317  loss_dice_8: 3.227  time: 1.6937  data_time: 0.3402  lr: 5.638e-06  max_mem: 17674M
[01/19 10:24:16] d2.utils.events INFO:  eta: 9:56:04  iter: 18859  total_loss: 61.22  loss_ce: 1.946  loss_mask: 0.6306  loss_dice: 3.24  loss_ce_0: 3.422  loss_mask_0: 0.6538  loss_dice_0: 3.523  loss_ce_1: 2.214  loss_mask_1: 0.6383  loss_dice_1: 3.387  loss_ce_2: 2.099  loss_mask_2: 0.6332  loss_dice_2: 3.312  loss_ce_3: 2.042  loss_mask_3: 0.6315  loss_dice_3: 3.27  loss_ce_4: 1.996  loss_mask_4: 0.6326  loss_dice_4: 3.262  loss_ce_5: 1.98  loss_mask_5: 0.6307  loss_dice_5: 3.261  loss_ce_6: 1.967  loss_mask_6: 0.6293  loss_dice_6: 3.249  loss_ce_7: 1.952  loss_mask_7: 0.6296  loss_dice_7: 3.244  loss_ce_8: 1.94  loss_mask_8: 0.6305  loss_dice_8: 3.25  time: 1.6937  data_time: 0.3445  lr: 5.6332e-06  max_mem: 17674M
[01/19 10:24:50] d2.utils.events INFO:  eta: 9:55:47  iter: 18879  total_loss: 60.69  loss_ce: 1.935  loss_mask: 0.6257  loss_dice: 3.265  loss_ce_0: 3.432  loss_mask_0: 0.6429  loss_dice_0: 3.525  loss_ce_1: 2.196  loss_mask_1: 0.6308  loss_dice_1: 3.403  loss_ce_2: 2.061  loss_mask_2: 0.6249  loss_dice_2: 3.334  loss_ce_3: 2.001  loss_mask_3: 0.6221  loss_dice_3: 3.285  loss_ce_4: 1.97  loss_mask_4: 0.6234  loss_dice_4: 3.279  loss_ce_5: 1.944  loss_mask_5: 0.6243  loss_dice_5: 3.282  loss_ce_6: 1.957  loss_mask_6: 0.624  loss_dice_6: 3.263  loss_ce_7: 1.938  loss_mask_7: 0.6249  loss_dice_7: 3.267  loss_ce_8: 1.93  loss_mask_8: 0.6275  loss_dice_8: 3.266  time: 1.6937  data_time: 0.3537  lr: 5.6285e-06  max_mem: 17674M
[01/19 10:25:24] d2.utils.events INFO:  eta: 9:55:08  iter: 18899  total_loss: 59.88  loss_ce: 1.815  loss_mask: 0.606  loss_dice: 3.271  loss_ce_0: 3.342  loss_mask_0: 0.6238  loss_dice_0: 3.533  loss_ce_1: 2.097  loss_mask_1: 0.6171  loss_dice_1: 3.397  loss_ce_2: 1.967  loss_mask_2: 0.6141  loss_dice_2: 3.337  loss_ce_3: 1.888  loss_mask_3: 0.6071  loss_dice_3: 3.293  loss_ce_4: 1.855  loss_mask_4: 0.6059  loss_dice_4: 3.278  loss_ce_5: 1.843  loss_mask_5: 0.605  loss_dice_5: 3.28  loss_ce_6: 1.822  loss_mask_6: 0.6077  loss_dice_6: 3.271  loss_ce_7: 1.831  loss_mask_7: 0.6093  loss_dice_7: 3.271  loss_ce_8: 1.808  loss_mask_8: 0.6065  loss_dice_8: 3.268  time: 1.6937  data_time: 0.3582  lr: 5.6237e-06  max_mem: 17674M
[01/19 10:25:58] d2.utils.events INFO:  eta: 9:54:30  iter: 18919  total_loss: 60.7  loss_ce: 1.909  loss_mask: 0.6205  loss_dice: 3.255  loss_ce_0: 3.359  loss_mask_0: 0.6257  loss_dice_0: 3.536  loss_ce_1: 2.135  loss_mask_1: 0.6177  loss_dice_1: 3.409  loss_ce_2: 2.006  loss_mask_2: 0.6223  loss_dice_2: 3.331  loss_ce_3: 1.974  loss_mask_3: 0.6153  loss_dice_3: 3.289  loss_ce_4: 1.956  loss_mask_4: 0.614  loss_dice_4: 3.278  loss_ce_5: 1.93  loss_mask_5: 0.6154  loss_dice_5: 3.274  loss_ce_6: 1.919  loss_mask_6: 0.6157  loss_dice_6: 3.264  loss_ce_7: 1.913  loss_mask_7: 0.6189  loss_dice_7: 3.261  loss_ce_8: 1.924  loss_mask_8: 0.6183  loss_dice_8: 3.259  time: 1.6937  data_time: 0.3307  lr: 5.6189e-06  max_mem: 17674M
[01/19 10:26:32] d2.utils.events INFO:  eta: 9:53:47  iter: 18939  total_loss: 60.8  loss_ce: 1.944  loss_mask: 0.6118  loss_dice: 3.266  loss_ce_0: 3.454  loss_mask_0: 0.6392  loss_dice_0: 3.546  loss_ce_1: 2.161  loss_mask_1: 0.6223  loss_dice_1: 3.404  loss_ce_2: 2.077  loss_mask_2: 0.616  loss_dice_2: 3.335  loss_ce_3: 2.046  loss_mask_3: 0.6158  loss_dice_3: 3.29  loss_ce_4: 2.002  loss_mask_4: 0.6153  loss_dice_4: 3.285  loss_ce_5: 1.982  loss_mask_5: 0.6126  loss_dice_5: 3.287  loss_ce_6: 1.969  loss_mask_6: 0.6126  loss_dice_6: 3.264  loss_ce_7: 1.938  loss_mask_7: 0.6118  loss_dice_7: 3.271  loss_ce_8: 1.939  loss_mask_8: 0.6118  loss_dice_8: 3.269  time: 1.6937  data_time: 0.3375  lr: 5.6141e-06  max_mem: 17674M
[01/19 10:27:06] d2.utils.events INFO:  eta: 9:52:57  iter: 18959  total_loss: 60.36  loss_ce: 1.847  loss_mask: 0.6135  loss_dice: 3.254  loss_ce_0: 3.35  loss_mask_0: 0.6371  loss_dice_0: 3.543  loss_ce_1: 2.116  loss_mask_1: 0.6257  loss_dice_1: 3.4  loss_ce_2: 1.999  loss_mask_2: 0.6169  loss_dice_2: 3.329  loss_ce_3: 1.931  loss_mask_3: 0.6091  loss_dice_3: 3.281  loss_ce_4: 1.89  loss_mask_4: 0.613  loss_dice_4: 3.273  loss_ce_5: 1.861  loss_mask_5: 0.6128  loss_dice_5: 3.278  loss_ce_6: 1.869  loss_mask_6: 0.6162  loss_dice_6: 3.254  loss_ce_7: 1.848  loss_mask_7: 0.6177  loss_dice_7: 3.263  loss_ce_8: 1.843  loss_mask_8: 0.6168  loss_dice_8: 3.259  time: 1.6937  data_time: 0.3458  lr: 5.6093e-06  max_mem: 17674M
[01/19 10:27:40] d2.utils.events INFO:  eta: 9:52:16  iter: 18979  total_loss: 60.23  loss_ce: 1.89  loss_mask: 0.621  loss_dice: 3.203  loss_ce_0: 3.35  loss_mask_0: 0.6353  loss_dice_0: 3.516  loss_ce_1: 2.124  loss_mask_1: 0.6157  loss_dice_1: 3.348  loss_ce_2: 2.006  loss_mask_2: 0.616  loss_dice_2: 3.276  loss_ce_3: 1.973  loss_mask_3: 0.6129  loss_dice_3: 3.228  loss_ce_4: 1.938  loss_mask_4: 0.6145  loss_dice_4: 3.229  loss_ce_5: 1.904  loss_mask_5: 0.6199  loss_dice_5: 3.225  loss_ce_6: 1.909  loss_mask_6: 0.6185  loss_dice_6: 3.206  loss_ce_7: 1.898  loss_mask_7: 0.6217  loss_dice_7: 3.205  loss_ce_8: 1.899  loss_mask_8: 0.6224  loss_dice_8: 3.205  time: 1.6937  data_time: 0.3359  lr: 5.6045e-06  max_mem: 17674M
[01/19 10:28:13] d2.utils.events INFO:  eta: 9:51:25  iter: 18999  total_loss: 60.75  loss_ce: 1.914  loss_mask: 0.6129  loss_dice: 3.314  loss_ce_0: 3.373  loss_mask_0: 0.6276  loss_dice_0: 3.562  loss_ce_1: 2.144  loss_mask_1: 0.6268  loss_dice_1: 3.444  loss_ce_2: 2.051  loss_mask_2: 0.6256  loss_dice_2: 3.38  loss_ce_3: 2.034  loss_mask_3: 0.6173  loss_dice_3: 3.34  loss_ce_4: 2.003  loss_mask_4: 0.6174  loss_dice_4: 3.333  loss_ce_5: 1.967  loss_mask_5: 0.6171  loss_dice_5: 3.33  loss_ce_6: 1.964  loss_mask_6: 0.6145  loss_dice_6: 3.325  loss_ce_7: 1.933  loss_mask_7: 0.6149  loss_dice_7: 3.313  loss_ce_8: 1.933  loss_mask_8: 0.6148  loss_dice_8: 3.317  time: 1.6937  data_time: 0.3494  lr: 5.5997e-06  max_mem: 17674M
[01/19 10:28:47] d2.utils.events INFO:  eta: 9:50:51  iter: 19019  total_loss: 60.09  loss_ce: 1.847  loss_mask: 0.6196  loss_dice: 3.256  loss_ce_0: 3.364  loss_mask_0: 0.6468  loss_dice_0: 3.508  loss_ce_1: 2.122  loss_mask_1: 0.6265  loss_dice_1: 3.392  loss_ce_2: 2  loss_mask_2: 0.6195  loss_dice_2: 3.329  loss_ce_3: 1.948  loss_mask_3: 0.6209  loss_dice_3: 3.278  loss_ce_4: 1.882  loss_mask_4: 0.6239  loss_dice_4: 3.28  loss_ce_5: 1.856  loss_mask_5: 0.6261  loss_dice_5: 3.273  loss_ce_6: 1.867  loss_mask_6: 0.62  loss_dice_6: 3.255  loss_ce_7: 1.853  loss_mask_7: 0.62  loss_dice_7: 3.258  loss_ce_8: 1.855  loss_mask_8: 0.6207  loss_dice_8: 3.257  time: 1.6936  data_time: 0.3320  lr: 5.5949e-06  max_mem: 17674M
[01/19 10:29:20] d2.utils.events INFO:  eta: 9:50:05  iter: 19039  total_loss: 60.18  loss_ce: 1.909  loss_mask: 0.6254  loss_dice: 3.195  loss_ce_0: 3.348  loss_mask_0: 0.6461  loss_dice_0: 3.476  loss_ce_1: 2.179  loss_mask_1: 0.6308  loss_dice_1: 3.336  loss_ce_2: 2.053  loss_mask_2: 0.6263  loss_dice_2: 3.262  loss_ce_3: 1.991  loss_mask_3: 0.623  loss_dice_3: 3.225  loss_ce_4: 1.962  loss_mask_4: 0.6254  loss_dice_4: 3.214  loss_ce_5: 1.938  loss_mask_5: 0.6229  loss_dice_5: 3.214  loss_ce_6: 1.93  loss_mask_6: 0.6246  loss_dice_6: 3.202  loss_ce_7: 1.911  loss_mask_7: 0.6257  loss_dice_7: 3.201  loss_ce_8: 1.88  loss_mask_8: 0.6247  loss_dice_8: 3.197  time: 1.6936  data_time: 0.3288  lr: 5.5901e-06  max_mem: 17674M
[01/19 10:29:54] d2.utils.events INFO:  eta: 9:49:32  iter: 19059  total_loss: 60.88  loss_ce: 1.969  loss_mask: 0.6243  loss_dice: 3.265  loss_ce_0: 3.358  loss_mask_0: 0.6532  loss_dice_0: 3.54  loss_ce_1: 2.175  loss_mask_1: 0.6319  loss_dice_1: 3.402  loss_ce_2: 2.082  loss_mask_2: 0.626  loss_dice_2: 3.335  loss_ce_3: 2.054  loss_mask_3: 0.6229  loss_dice_3: 3.293  loss_ce_4: 1.998  loss_mask_4: 0.6207  loss_dice_4: 3.291  loss_ce_5: 1.966  loss_mask_5: 0.6229  loss_dice_5: 3.287  loss_ce_6: 1.976  loss_mask_6: 0.6189  loss_dice_6: 3.278  loss_ce_7: 1.953  loss_mask_7: 0.6201  loss_dice_7: 3.277  loss_ce_8: 1.97  loss_mask_8: 0.6221  loss_dice_8: 3.273  time: 1.6936  data_time: 0.3483  lr: 5.5853e-06  max_mem: 17674M
[01/19 10:30:28] d2.utils.events INFO:  eta: 9:48:53  iter: 19079  total_loss: 60.35  loss_ce: 1.878  loss_mask: 0.6267  loss_dice: 3.194  loss_ce_0: 3.366  loss_mask_0: 0.641  loss_dice_0: 3.49  loss_ce_1: 2.151  loss_mask_1: 0.6289  loss_dice_1: 3.331  loss_ce_2: 2.022  loss_mask_2: 0.6286  loss_dice_2: 3.262  loss_ce_3: 1.962  loss_mask_3: 0.6241  loss_dice_3: 3.215  loss_ce_4: 1.92  loss_mask_4: 0.6268  loss_dice_4: 3.218  loss_ce_5: 1.876  loss_mask_5: 0.6299  loss_dice_5: 3.212  loss_ce_6: 1.885  loss_mask_6: 0.6277  loss_dice_6: 3.196  loss_ce_7: 1.896  loss_mask_7: 0.6279  loss_dice_7: 3.199  loss_ce_8: 1.894  loss_mask_8: 0.6275  loss_dice_8: 3.2  time: 1.6936  data_time: 0.3291  lr: 5.5805e-06  max_mem: 17674M
[01/19 10:31:01] d2.utils.events INFO:  eta: 9:48:21  iter: 19099  total_loss: 60.96  loss_ce: 1.959  loss_mask: 0.6294  loss_dice: 3.229  loss_ce_0: 3.408  loss_mask_0: 0.6547  loss_dice_0: 3.503  loss_ce_1: 2.199  loss_mask_1: 0.6388  loss_dice_1: 3.358  loss_ce_2: 2.101  loss_mask_2: 0.6311  loss_dice_2: 3.296  loss_ce_3: 2.021  loss_mask_3: 0.6262  loss_dice_3: 3.252  loss_ce_4: 2.009  loss_mask_4: 0.6298  loss_dice_4: 3.252  loss_ce_5: 1.969  loss_mask_5: 0.6273  loss_dice_5: 3.249  loss_ce_6: 1.974  loss_mask_6: 0.6263  loss_dice_6: 3.23  loss_ce_7: 1.975  loss_mask_7: 0.627  loss_dice_7: 3.238  loss_ce_8: 1.982  loss_mask_8: 0.6293  loss_dice_8: 3.232  time: 1.6936  data_time: 0.3406  lr: 5.5757e-06  max_mem: 17674M
[01/19 10:31:35] d2.utils.events INFO:  eta: 9:47:51  iter: 19119  total_loss: 60.9  loss_ce: 1.942  loss_mask: 0.6286  loss_dice: 3.23  loss_ce_0: 3.328  loss_mask_0: 0.6462  loss_dice_0: 3.514  loss_ce_1: 2.131  loss_mask_1: 0.6354  loss_dice_1: 3.368  loss_ce_2: 2.047  loss_mask_2: 0.6359  loss_dice_2: 3.301  loss_ce_3: 2.01  loss_mask_3: 0.6297  loss_dice_3: 3.26  loss_ce_4: 1.964  loss_mask_4: 0.6307  loss_dice_4: 3.256  loss_ce_5: 1.96  loss_mask_5: 0.6314  loss_dice_5: 3.252  loss_ce_6: 1.943  loss_mask_6: 0.6299  loss_dice_6: 3.235  loss_ce_7: 1.944  loss_mask_7: 0.6286  loss_dice_7: 3.237  loss_ce_8: 1.92  loss_mask_8: 0.6306  loss_dice_8: 3.236  time: 1.6936  data_time: 0.3306  lr: 5.5709e-06  max_mem: 17674M
[01/19 10:32:08] d2.utils.events INFO:  eta: 9:47:17  iter: 19139  total_loss: 60.53  loss_ce: 1.944  loss_mask: 0.6367  loss_dice: 3.207  loss_ce_0: 3.369  loss_mask_0: 0.6625  loss_dice_0: 3.511  loss_ce_1: 2.192  loss_mask_1: 0.641  loss_dice_1: 3.339  loss_ce_2: 2.065  loss_mask_2: 0.6395  loss_dice_2: 3.271  loss_ce_3: 2.008  loss_mask_3: 0.6394  loss_dice_3: 3.23  loss_ce_4: 1.967  loss_mask_4: 0.6381  loss_dice_4: 3.226  loss_ce_5: 1.946  loss_mask_5: 0.6372  loss_dice_5: 3.228  loss_ce_6: 1.955  loss_mask_6: 0.636  loss_dice_6: 3.22  loss_ce_7: 1.931  loss_mask_7: 0.6356  loss_dice_7: 3.211  loss_ce_8: 1.941  loss_mask_8: 0.6376  loss_dice_8: 3.215  time: 1.6935  data_time: 0.3244  lr: 5.5661e-06  max_mem: 17674M
[01/19 10:32:42] d2.utils.events INFO:  eta: 9:46:44  iter: 19159  total_loss: 60.4  loss_ce: 1.91  loss_mask: 0.6128  loss_dice: 3.219  loss_ce_0: 3.373  loss_mask_0: 0.6404  loss_dice_0: 3.505  loss_ce_1: 2.116  loss_mask_1: 0.6271  loss_dice_1: 3.354  loss_ce_2: 2.066  loss_mask_2: 0.6201  loss_dice_2: 3.281  loss_ce_3: 1.994  loss_mask_3: 0.6148  loss_dice_3: 3.246  loss_ce_4: 1.951  loss_mask_4: 0.6169  loss_dice_4: 3.244  loss_ce_5: 1.938  loss_mask_5: 0.6122  loss_dice_5: 3.239  loss_ce_6: 1.92  loss_mask_6: 0.6121  loss_dice_6: 3.227  loss_ce_7: 1.91  loss_mask_7: 0.614  loss_dice_7: 3.229  loss_ce_8: 1.911  loss_mask_8: 0.6135  loss_dice_8: 3.228  time: 1.6935  data_time: 0.3363  lr: 5.5613e-06  max_mem: 17674M
[01/19 10:33:16] d2.utils.events INFO:  eta: 9:46:07  iter: 19179  total_loss: 60.02  loss_ce: 1.828  loss_mask: 0.6249  loss_dice: 3.258  loss_ce_0: 3.328  loss_mask_0: 0.6417  loss_dice_0: 3.564  loss_ce_1: 2.092  loss_mask_1: 0.6328  loss_dice_1: 3.398  loss_ce_2: 1.973  loss_mask_2: 0.6262  loss_dice_2: 3.332  loss_ce_3: 1.93  loss_mask_3: 0.6259  loss_dice_3: 3.285  loss_ce_4: 1.879  loss_mask_4: 0.6271  loss_dice_4: 3.278  loss_ce_5: 1.846  loss_mask_5: 0.6276  loss_dice_5: 3.281  loss_ce_6: 1.854  loss_mask_6: 0.6243  loss_dice_6: 3.262  loss_ce_7: 1.846  loss_mask_7: 0.623  loss_dice_7: 3.259  loss_ce_8: 1.837  loss_mask_8: 0.6244  loss_dice_8: 3.26  time: 1.6935  data_time: 0.3334  lr: 5.5565e-06  max_mem: 17674M
[01/19 10:33:50] d2.utils.events INFO:  eta: 9:45:34  iter: 19199  total_loss: 59.56  loss_ce: 1.916  loss_mask: 0.6163  loss_dice: 3.222  loss_ce_0: 3.364  loss_mask_0: 0.6313  loss_dice_0: 3.507  loss_ce_1: 2.171  loss_mask_1: 0.6265  loss_dice_1: 3.345  loss_ce_2: 2.052  loss_mask_2: 0.6259  loss_dice_2: 3.277  loss_ce_3: 2.01  loss_mask_3: 0.6156  loss_dice_3: 3.245  loss_ce_4: 1.97  loss_mask_4: 0.6182  loss_dice_4: 3.232  loss_ce_5: 1.949  loss_mask_5: 0.6143  loss_dice_5: 3.237  loss_ce_6: 1.949  loss_mask_6: 0.6166  loss_dice_6: 3.215  loss_ce_7: 1.93  loss_mask_7: 0.6152  loss_dice_7: 3.221  loss_ce_8: 1.908  loss_mask_8: 0.6154  loss_dice_8: 3.221  time: 1.6935  data_time: 0.3458  lr: 5.5516e-06  max_mem: 17674M
[01/19 10:34:24] d2.utils.events INFO:  eta: 9:45:01  iter: 19219  total_loss: 59.95  loss_ce: 1.894  loss_mask: 0.6288  loss_dice: 3.235  loss_ce_0: 3.353  loss_mask_0: 0.6424  loss_dice_0: 3.513  loss_ce_1: 2.163  loss_mask_1: 0.6333  loss_dice_1: 3.388  loss_ce_2: 1.995  loss_mask_2: 0.623  loss_dice_2: 3.318  loss_ce_3: 1.964  loss_mask_3: 0.6209  loss_dice_3: 3.274  loss_ce_4: 1.912  loss_mask_4: 0.6229  loss_dice_4: 3.265  loss_ce_5: 1.896  loss_mask_5: 0.6273  loss_dice_5: 3.263  loss_ce_6: 1.898  loss_mask_6: 0.625  loss_dice_6: 3.249  loss_ce_7: 1.889  loss_mask_7: 0.6244  loss_dice_7: 3.252  loss_ce_8: 1.891  loss_mask_8: 0.6269  loss_dice_8: 3.245  time: 1.6935  data_time: 0.3371  lr: 5.5468e-06  max_mem: 17674M
[01/19 10:34:58] d2.utils.events INFO:  eta: 9:44:28  iter: 19239  total_loss: 59.82  loss_ce: 1.837  loss_mask: 0.6182  loss_dice: 3.235  loss_ce_0: 3.345  loss_mask_0: 0.6512  loss_dice_0: 3.525  loss_ce_1: 2.082  loss_mask_1: 0.6318  loss_dice_1: 3.375  loss_ce_2: 1.985  loss_mask_2: 0.624  loss_dice_2: 3.314  loss_ce_3: 1.944  loss_mask_3: 0.6204  loss_dice_3: 3.263  loss_ce_4: 1.901  loss_mask_4: 0.6213  loss_dice_4: 3.251  loss_ce_5: 1.874  loss_mask_5: 0.6213  loss_dice_5: 3.252  loss_ce_6: 1.876  loss_mask_6: 0.621  loss_dice_6: 3.24  loss_ce_7: 1.841  loss_mask_7: 0.6202  loss_dice_7: 3.25  loss_ce_8: 1.822  loss_mask_8: 0.6206  loss_dice_8: 3.246  time: 1.6935  data_time: 0.3483  lr: 5.542e-06  max_mem: 17674M
[01/19 10:35:32] d2.utils.events INFO:  eta: 9:43:51  iter: 19259  total_loss: 59.83  loss_ce: 1.85  loss_mask: 0.6195  loss_dice: 3.252  loss_ce_0: 3.305  loss_mask_0: 0.6338  loss_dice_0: 3.532  loss_ce_1: 2.156  loss_mask_1: 0.6152  loss_dice_1: 3.382  loss_ce_2: 2.019  loss_mask_2: 0.6159  loss_dice_2: 3.313  loss_ce_3: 1.983  loss_mask_3: 0.6162  loss_dice_3: 3.263  loss_ce_4: 1.914  loss_mask_4: 0.6188  loss_dice_4: 3.256  loss_ce_5: 1.886  loss_mask_5: 0.6182  loss_dice_5: 3.262  loss_ce_6: 1.876  loss_mask_6: 0.6184  loss_dice_6: 3.252  loss_ce_7: 1.868  loss_mask_7: 0.6181  loss_dice_7: 3.243  loss_ce_8: 1.839  loss_mask_8: 0.6198  loss_dice_8: 3.245  time: 1.6935  data_time: 0.3387  lr: 5.5372e-06  max_mem: 17674M
[01/19 10:36:06] d2.utils.events INFO:  eta: 9:43:21  iter: 19279  total_loss: 59.73  loss_ce: 1.855  loss_mask: 0.6148  loss_dice: 3.253  loss_ce_0: 3.292  loss_mask_0: 0.6283  loss_dice_0: 3.528  loss_ce_1: 2.119  loss_mask_1: 0.6171  loss_dice_1: 3.371  loss_ce_2: 1.977  loss_mask_2: 0.614  loss_dice_2: 3.311  loss_ce_3: 1.929  loss_mask_3: 0.6091  loss_dice_3: 3.277  loss_ce_4: 1.875  loss_mask_4: 0.6104  loss_dice_4: 3.266  loss_ce_5: 1.854  loss_mask_5: 0.6128  loss_dice_5: 3.276  loss_ce_6: 1.85  loss_mask_6: 0.6131  loss_dice_6: 3.264  loss_ce_7: 1.865  loss_mask_7: 0.6144  loss_dice_7: 3.256  loss_ce_8: 1.848  loss_mask_8: 0.6164  loss_dice_8: 3.258  time: 1.6935  data_time: 0.3371  lr: 5.5324e-06  max_mem: 17674M
[01/19 10:36:40] d2.utils.events INFO:  eta: 9:42:35  iter: 19299  total_loss: 60.47  loss_ce: 1.965  loss_mask: 0.6289  loss_dice: 3.205  loss_ce_0: 3.361  loss_mask_0: 0.6577  loss_dice_0: 3.505  loss_ce_1: 2.214  loss_mask_1: 0.6372  loss_dice_1: 3.357  loss_ce_2: 2.093  loss_mask_2: 0.6337  loss_dice_2: 3.281  loss_ce_3: 2.065  loss_mask_3: 0.6277  loss_dice_3: 3.227  loss_ce_4: 2.01  loss_mask_4: 0.6294  loss_dice_4: 3.217  loss_ce_5: 1.994  loss_mask_5: 0.6306  loss_dice_5: 3.222  loss_ce_6: 2.002  loss_mask_6: 0.6273  loss_dice_6: 3.209  loss_ce_7: 1.974  loss_mask_7: 0.6285  loss_dice_7: 3.206  loss_ce_8: 1.967  loss_mask_8: 0.6288  loss_dice_8: 3.212  time: 1.6935  data_time: 0.3430  lr: 5.5276e-06  max_mem: 17674M
[01/19 10:37:13] d2.utils.events INFO:  eta: 9:42:06  iter: 19319  total_loss: 59.36  loss_ce: 1.871  loss_mask: 0.6108  loss_dice: 3.219  loss_ce_0: 3.302  loss_mask_0: 0.6313  loss_dice_0: 3.492  loss_ce_1: 2.163  loss_mask_1: 0.612  loss_dice_1: 3.338  loss_ce_2: 2.052  loss_mask_2: 0.6106  loss_dice_2: 3.276  loss_ce_3: 1.969  loss_mask_3: 0.6061  loss_dice_3: 3.234  loss_ce_4: 1.931  loss_mask_4: 0.6078  loss_dice_4: 3.225  loss_ce_5: 1.913  loss_mask_5: 0.61  loss_dice_5: 3.228  loss_ce_6: 1.886  loss_mask_6: 0.6085  loss_dice_6: 3.209  loss_ce_7: 1.876  loss_mask_7: 0.6092  loss_dice_7: 3.219  loss_ce_8: 1.868  loss_mask_8: 0.6113  loss_dice_8: 3.214  time: 1.6935  data_time: 0.3273  lr: 5.5228e-06  max_mem: 17674M
[01/19 10:37:47] d2.utils.events INFO:  eta: 9:41:32  iter: 19339  total_loss: 59.15  loss_ce: 1.792  loss_mask: 0.6174  loss_dice: 3.233  loss_ce_0: 3.315  loss_mask_0: 0.6442  loss_dice_0: 3.536  loss_ce_1: 2.086  loss_mask_1: 0.6249  loss_dice_1: 3.39  loss_ce_2: 1.945  loss_mask_2: 0.6191  loss_dice_2: 3.317  loss_ce_3: 1.884  loss_mask_3: 0.6166  loss_dice_3: 3.264  loss_ce_4: 1.846  loss_mask_4: 0.6206  loss_dice_4: 3.247  loss_ce_5: 1.827  loss_mask_5: 0.6174  loss_dice_5: 3.248  loss_ce_6: 1.815  loss_mask_6: 0.6213  loss_dice_6: 3.233  loss_ce_7: 1.799  loss_mask_7: 0.6184  loss_dice_7: 3.24  loss_ce_8: 1.792  loss_mask_8: 0.6175  loss_dice_8: 3.233  time: 1.6935  data_time: 0.3726  lr: 5.518e-06  max_mem: 17674M
[01/19 10:38:21] d2.utils.events INFO:  eta: 9:41:04  iter: 19359  total_loss: 59.72  loss_ce: 1.876  loss_mask: 0.6155  loss_dice: 3.227  loss_ce_0: 3.35  loss_mask_0: 0.6391  loss_dice_0: 3.522  loss_ce_1: 2.125  loss_mask_1: 0.6237  loss_dice_1: 3.365  loss_ce_2: 2.024  loss_mask_2: 0.6195  loss_dice_2: 3.299  loss_ce_3: 1.975  loss_mask_3: 0.6189  loss_dice_3: 3.253  loss_ce_4: 1.925  loss_mask_4: 0.6168  loss_dice_4: 3.244  loss_ce_5: 1.892  loss_mask_5: 0.617  loss_dice_5: 3.245  loss_ce_6: 1.898  loss_mask_6: 0.6166  loss_dice_6: 3.227  loss_ce_7: 1.879  loss_mask_7: 0.6136  loss_dice_7: 3.231  loss_ce_8: 1.876  loss_mask_8: 0.6137  loss_dice_8: 3.226  time: 1.6935  data_time: 0.3511  lr: 5.5132e-06  max_mem: 17674M
[01/19 10:38:55] d2.utils.events INFO:  eta: 9:40:32  iter: 19379  total_loss: 60.49  loss_ce: 1.869  loss_mask: 0.6247  loss_dice: 3.268  loss_ce_0: 3.256  loss_mask_0: 0.6484  loss_dice_0: 3.519  loss_ce_1: 2.103  loss_mask_1: 0.6311  loss_dice_1: 3.391  loss_ce_2: 1.98  loss_mask_2: 0.6279  loss_dice_2: 3.331  loss_ce_3: 1.951  loss_mask_3: 0.6229  loss_dice_3: 3.283  loss_ce_4: 1.94  loss_mask_4: 0.6253  loss_dice_4: 3.282  loss_ce_5: 1.904  loss_mask_5: 0.6259  loss_dice_5: 3.281  loss_ce_6: 1.887  loss_mask_6: 0.6238  loss_dice_6: 3.263  loss_ce_7: 1.873  loss_mask_7: 0.625  loss_dice_7: 3.263  loss_ce_8: 1.872  loss_mask_8: 0.6248  loss_dice_8: 3.269  time: 1.6935  data_time: 0.3342  lr: 5.5084e-06  max_mem: 17674M
[01/19 10:39:29] d2.utils.events INFO:  eta: 9:39:57  iter: 19399  total_loss: 59.14  loss_ce: 1.833  loss_mask: 0.6237  loss_dice: 3.203  loss_ce_0: 3.316  loss_mask_0: 0.6547  loss_dice_0: 3.498  loss_ce_1: 2.122  loss_mask_1: 0.6401  loss_dice_1: 3.332  loss_ce_2: 2.02  loss_mask_2: 0.6289  loss_dice_2: 3.258  loss_ce_3: 1.94  loss_mask_3: 0.6218  loss_dice_3: 3.217  loss_ce_4: 1.88  loss_mask_4: 0.6225  loss_dice_4: 3.225  loss_ce_5: 1.864  loss_mask_5: 0.6256  loss_dice_5: 3.215  loss_ce_6: 1.855  loss_mask_6: 0.6238  loss_dice_6: 3.205  loss_ce_7: 1.82  loss_mask_7: 0.6231  loss_dice_7: 3.21  loss_ce_8: 1.842  loss_mask_8: 0.6245  loss_dice_8: 3.205  time: 1.6935  data_time: 0.3389  lr: 5.5036e-06  max_mem: 17674M
[01/19 10:40:03] d2.utils.events INFO:  eta: 9:39:24  iter: 19419  total_loss: 60.24  loss_ce: 1.834  loss_mask: 0.6244  loss_dice: 3.233  loss_ce_0: 3.416  loss_mask_0: 0.6454  loss_dice_0: 3.507  loss_ce_1: 2.112  loss_mask_1: 0.6318  loss_dice_1: 3.365  loss_ce_2: 1.985  loss_mask_2: 0.6281  loss_dice_2: 3.295  loss_ce_3: 1.915  loss_mask_3: 0.621  loss_dice_3: 3.256  loss_ce_4: 1.892  loss_mask_4: 0.6215  loss_dice_4: 3.251  loss_ce_5: 1.853  loss_mask_5: 0.6239  loss_dice_5: 3.244  loss_ce_6: 1.828  loss_mask_6: 0.6228  loss_dice_6: 3.233  loss_ce_7: 1.83  loss_mask_7: 0.6252  loss_dice_7: 3.238  loss_ce_8: 1.84  loss_mask_8: 0.6269  loss_dice_8: 3.233  time: 1.6935  data_time: 0.3398  lr: 5.4988e-06  max_mem: 17674M
[01/19 10:40:37] d2.utils.events INFO:  eta: 9:38:47  iter: 19439  total_loss: 60.41  loss_ce: 1.885  loss_mask: 0.6151  loss_dice: 3.254  loss_ce_0: 3.342  loss_mask_0: 0.647  loss_dice_0: 3.526  loss_ce_1: 2.162  loss_mask_1: 0.6342  loss_dice_1: 3.391  loss_ce_2: 2.018  loss_mask_2: 0.6244  loss_dice_2: 3.321  loss_ce_3: 1.986  loss_mask_3: 0.6197  loss_dice_3: 3.268  loss_ce_4: 1.951  loss_mask_4: 0.618  loss_dice_4: 3.266  loss_ce_5: 1.924  loss_mask_5: 0.6192  loss_dice_5: 3.268  loss_ce_6: 1.908  loss_mask_6: 0.6163  loss_dice_6: 3.259  loss_ce_7: 1.889  loss_mask_7: 0.6165  loss_dice_7: 3.258  loss_ce_8: 1.897  loss_mask_8: 0.6155  loss_dice_8: 3.254  time: 1.6935  data_time: 0.3356  lr: 5.494e-06  max_mem: 17674M
[01/19 10:41:11] d2.utils.events INFO:  eta: 9:38:04  iter: 19459  total_loss: 60.35  loss_ce: 1.866  loss_mask: 0.6148  loss_dice: 3.273  loss_ce_0: 3.393  loss_mask_0: 0.6341  loss_dice_0: 3.562  loss_ce_1: 2.12  loss_mask_1: 0.6178  loss_dice_1: 3.401  loss_ce_2: 2.005  loss_mask_2: 0.6135  loss_dice_2: 3.331  loss_ce_3: 1.941  loss_mask_3: 0.6154  loss_dice_3: 3.291  loss_ce_4: 1.921  loss_mask_4: 0.6165  loss_dice_4: 3.289  loss_ce_5: 1.902  loss_mask_5: 0.6182  loss_dice_5: 3.287  loss_ce_6: 1.901  loss_mask_6: 0.6159  loss_dice_6: 3.278  loss_ce_7: 1.864  loss_mask_7: 0.6193  loss_dice_7: 3.279  loss_ce_8: 1.861  loss_mask_8: 0.6172  loss_dice_8: 3.274  time: 1.6935  data_time: 0.3440  lr: 5.4892e-06  max_mem: 17674M
[01/19 10:41:45] d2.utils.events INFO:  eta: 9:37:37  iter: 19479  total_loss: 59.84  loss_ce: 1.882  loss_mask: 0.633  loss_dice: 3.203  loss_ce_0: 3.334  loss_mask_0: 0.654  loss_dice_0: 3.497  loss_ce_1: 2.14  loss_mask_1: 0.6394  loss_dice_1: 3.337  loss_ce_2: 2.025  loss_mask_2: 0.6351  loss_dice_2: 3.269  loss_ce_3: 1.964  loss_mask_3: 0.633  loss_dice_3: 3.238  loss_ce_4: 1.918  loss_mask_4: 0.6341  loss_dice_4: 3.234  loss_ce_5: 1.903  loss_mask_5: 0.632  loss_dice_5: 3.223  loss_ce_6: 1.909  loss_mask_6: 0.6323  loss_dice_6: 3.21  loss_ce_7: 1.893  loss_mask_7: 0.6307  loss_dice_7: 3.209  loss_ce_8: 1.892  loss_mask_8: 0.6328  loss_dice_8: 3.202  time: 1.6935  data_time: 0.3351  lr: 5.4843e-06  max_mem: 17674M
[01/19 10:42:19] d2.utils.events INFO:  eta: 9:37:05  iter: 19499  total_loss: 59.35  loss_ce: 1.847  loss_mask: 0.6068  loss_dice: 3.229  loss_ce_0: 3.229  loss_mask_0: 0.6371  loss_dice_0: 3.53  loss_ce_1: 2.12  loss_mask_1: 0.6236  loss_dice_1: 3.373  loss_ce_2: 1.999  loss_mask_2: 0.6165  loss_dice_2: 3.292  loss_ce_3: 1.93  loss_mask_3: 0.6073  loss_dice_3: 3.25  loss_ce_4: 1.887  loss_mask_4: 0.6064  loss_dice_4: 3.253  loss_ce_5: 1.867  loss_mask_5: 0.6076  loss_dice_5: 3.248  loss_ce_6: 1.878  loss_mask_6: 0.605  loss_dice_6: 3.24  loss_ce_7: 1.868  loss_mask_7: 0.605  loss_dice_7: 3.237  loss_ce_8: 1.869  loss_mask_8: 0.6077  loss_dice_8: 3.232  time: 1.6935  data_time: 0.3420  lr: 5.4795e-06  max_mem: 17674M
[01/19 10:42:52] d2.utils.events INFO:  eta: 9:36:17  iter: 19519  total_loss: 59.58  loss_ce: 1.839  loss_mask: 0.625  loss_dice: 3.214  loss_ce_0: 3.266  loss_mask_0: 0.6361  loss_dice_0: 3.511  loss_ce_1: 2.173  loss_mask_1: 0.6277  loss_dice_1: 3.356  loss_ce_2: 2.023  loss_mask_2: 0.6234  loss_dice_2: 3.285  loss_ce_3: 1.952  loss_mask_3: 0.6229  loss_dice_3: 3.238  loss_ce_4: 1.903  loss_mask_4: 0.624  loss_dice_4: 3.235  loss_ce_5: 1.878  loss_mask_5: 0.6255  loss_dice_5: 3.225  loss_ce_6: 1.86  loss_mask_6: 0.6249  loss_dice_6: 3.22  loss_ce_7: 1.852  loss_mask_7: 0.6267  loss_dice_7: 3.212  loss_ce_8: 1.84  loss_mask_8: 0.6256  loss_dice_8: 3.214  time: 1.6935  data_time: 0.3349  lr: 5.4747e-06  max_mem: 17674M
[01/19 10:43:27] d2.utils.events INFO:  eta: 9:35:41  iter: 19539  total_loss: 60.03  loss_ce: 1.892  loss_mask: 0.6259  loss_dice: 3.219  loss_ce_0: 3.294  loss_mask_0: 0.6463  loss_dice_0: 3.517  loss_ce_1: 2.147  loss_mask_1: 0.6315  loss_dice_1: 3.351  loss_ce_2: 2.062  loss_mask_2: 0.6282  loss_dice_2: 3.286  loss_ce_3: 2.001  loss_mask_3: 0.6246  loss_dice_3: 3.243  loss_ce_4: 1.937  loss_mask_4: 0.6255  loss_dice_4: 3.238  loss_ce_5: 1.926  loss_mask_5: 0.6261  loss_dice_5: 3.241  loss_ce_6: 1.923  loss_mask_6: 0.6236  loss_dice_6: 3.228  loss_ce_7: 1.891  loss_mask_7: 0.6273  loss_dice_7: 3.232  loss_ce_8: 1.897  loss_mask_8: 0.6268  loss_dice_8: 3.231  time: 1.6935  data_time: 0.3416  lr: 5.4699e-06  max_mem: 17674M
[01/19 10:44:00] d2.utils.events INFO:  eta: 9:34:52  iter: 19559  total_loss: 60.48  loss_ce: 1.887  loss_mask: 0.6332  loss_dice: 3.227  loss_ce_0: 3.349  loss_mask_0: 0.6567  loss_dice_0: 3.503  loss_ce_1: 2.147  loss_mask_1: 0.6338  loss_dice_1: 3.361  loss_ce_2: 2.008  loss_mask_2: 0.6318  loss_dice_2: 3.285  loss_ce_3: 1.959  loss_mask_3: 0.6302  loss_dice_3: 3.246  loss_ce_4: 1.918  loss_mask_4: 0.6321  loss_dice_4: 3.241  loss_ce_5: 1.92  loss_mask_5: 0.6316  loss_dice_5: 3.245  loss_ce_6: 1.914  loss_mask_6: 0.6331  loss_dice_6: 3.241  loss_ce_7: 1.893  loss_mask_7: 0.6339  loss_dice_7: 3.227  loss_ce_8: 1.906  loss_mask_8: 0.6328  loss_dice_8: 3.229  time: 1.6935  data_time: 0.3383  lr: 5.4651e-06  max_mem: 17674M
[01/19 10:44:34] d2.utils.events INFO:  eta: 9:34:18  iter: 19579  total_loss: 60.9  loss_ce: 1.941  loss_mask: 0.6186  loss_dice: 3.29  loss_ce_0: 3.358  loss_mask_0: 0.6452  loss_dice_0: 3.542  loss_ce_1: 2.135  loss_mask_1: 0.636  loss_dice_1: 3.421  loss_ce_2: 2.008  loss_mask_2: 0.6251  loss_dice_2: 3.353  loss_ce_3: 1.985  loss_mask_3: 0.624  loss_dice_3: 3.313  loss_ce_4: 1.948  loss_mask_4: 0.6245  loss_dice_4: 3.296  loss_ce_5: 1.915  loss_mask_5: 0.6248  loss_dice_5: 3.302  loss_ce_6: 1.944  loss_mask_6: 0.6208  loss_dice_6: 3.295  loss_ce_7: 1.946  loss_mask_7: 0.6208  loss_dice_7: 3.288  loss_ce_8: 1.94  loss_mask_8: 0.6194  loss_dice_8: 3.282  time: 1.6935  data_time: 0.3402  lr: 5.4603e-06  max_mem: 17674M
[01/19 10:45:08] d2.utils.events INFO:  eta: 9:33:44  iter: 19599  total_loss: 59.86  loss_ce: 1.858  loss_mask: 0.6179  loss_dice: 3.214  loss_ce_0: 3.356  loss_mask_0: 0.6416  loss_dice_0: 3.501  loss_ce_1: 2.09  loss_mask_1: 0.6312  loss_dice_1: 3.352  loss_ce_2: 2.009  loss_mask_2: 0.6255  loss_dice_2: 3.289  loss_ce_3: 1.945  loss_mask_3: 0.6175  loss_dice_3: 3.243  loss_ce_4: 1.902  loss_mask_4: 0.6182  loss_dice_4: 3.234  loss_ce_5: 1.895  loss_mask_5: 0.6184  loss_dice_5: 3.233  loss_ce_6: 1.88  loss_mask_6: 0.6177  loss_dice_6: 3.211  loss_ce_7: 1.866  loss_mask_7: 0.6166  loss_dice_7: 3.214  loss_ce_8: 1.853  loss_mask_8: 0.6161  loss_dice_8: 3.22  time: 1.6935  data_time: 0.3391  lr: 5.4555e-06  max_mem: 17674M
[01/19 10:45:41] d2.utils.events INFO:  eta: 9:33:14  iter: 19619  total_loss: 60.22  loss_ce: 1.879  loss_mask: 0.6251  loss_dice: 3.258  loss_ce_0: 3.337  loss_mask_0: 0.6535  loss_dice_0: 3.526  loss_ce_1: 2.131  loss_mask_1: 0.6382  loss_dice_1: 3.388  loss_ce_2: 2.004  loss_mask_2: 0.624  loss_dice_2: 3.313  loss_ce_3: 1.949  loss_mask_3: 0.6236  loss_dice_3: 3.262  loss_ce_4: 1.891  loss_mask_4: 0.6267  loss_dice_4: 3.259  loss_ce_5: 1.88  loss_mask_5: 0.6254  loss_dice_5: 3.267  loss_ce_6: 1.87  loss_mask_6: 0.626  loss_dice_6: 3.25  loss_ce_7: 1.869  loss_mask_7: 0.6261  loss_dice_7: 3.251  loss_ce_8: 1.856  loss_mask_8: 0.6272  loss_dice_8: 3.251  time: 1.6935  data_time: 0.3484  lr: 5.4507e-06  max_mem: 17674M
[01/19 10:46:15] d2.utils.events INFO:  eta: 9:32:36  iter: 19639  total_loss: 59.09  loss_ce: 1.784  loss_mask: 0.6052  loss_dice: 3.213  loss_ce_0: 3.254  loss_mask_0: 0.6283  loss_dice_0: 3.507  loss_ce_1: 2.057  loss_mask_1: 0.6059  loss_dice_1: 3.356  loss_ce_2: 1.962  loss_mask_2: 0.6103  loss_dice_2: 3.28  loss_ce_3: 1.886  loss_mask_3: 0.6049  loss_dice_3: 3.242  loss_ce_4: 1.851  loss_mask_4: 0.6024  loss_dice_4: 3.232  loss_ce_5: 1.803  loss_mask_5: 0.6027  loss_dice_5: 3.236  loss_ce_6: 1.808  loss_mask_6: 0.6019  loss_dice_6: 3.222  loss_ce_7: 1.787  loss_mask_7: 0.6031  loss_dice_7: 3.224  loss_ce_8: 1.791  loss_mask_8: 0.6071  loss_dice_8: 3.226  time: 1.6935  data_time: 0.3281  lr: 5.4458e-06  max_mem: 17674M
[01/19 10:46:49] d2.utils.events INFO:  eta: 9:32:20  iter: 19659  total_loss: 59.38  loss_ce: 1.824  loss_mask: 0.6263  loss_dice: 3.222  loss_ce_0: 3.295  loss_mask_0: 0.6392  loss_dice_0: 3.518  loss_ce_1: 2.059  loss_mask_1: 0.631  loss_dice_1: 3.365  loss_ce_2: 1.919  loss_mask_2: 0.6276  loss_dice_2: 3.288  loss_ce_3: 1.889  loss_mask_3: 0.6247  loss_dice_3: 3.245  loss_ce_4: 1.852  loss_mask_4: 0.6243  loss_dice_4: 3.245  loss_ce_5: 1.866  loss_mask_5: 0.6256  loss_dice_5: 3.236  loss_ce_6: 1.846  loss_mask_6: 0.6261  loss_dice_6: 3.226  loss_ce_7: 1.826  loss_mask_7: 0.6238  loss_dice_7: 3.233  loss_ce_8: 1.829  loss_mask_8: 0.6256  loss_dice_8: 3.222  time: 1.6935  data_time: 0.3533  lr: 5.441e-06  max_mem: 17674M
[01/19 10:47:23] d2.utils.events INFO:  eta: 9:31:28  iter: 19679  total_loss: 59.36  loss_ce: 1.801  loss_mask: 0.628  loss_dice: 3.235  loss_ce_0: 3.296  loss_mask_0: 0.6476  loss_dice_0: 3.504  loss_ce_1: 2.063  loss_mask_1: 0.6329  loss_dice_1: 3.363  loss_ce_2: 1.948  loss_mask_2: 0.6256  loss_dice_2: 3.287  loss_ce_3: 1.91  loss_mask_3: 0.6214  loss_dice_3: 3.244  loss_ce_4: 1.849  loss_mask_4: 0.6238  loss_dice_4: 3.239  loss_ce_5: 1.827  loss_mask_5: 0.6265  loss_dice_5: 3.244  loss_ce_6: 1.822  loss_mask_6: 0.6255  loss_dice_6: 3.227  loss_ce_7: 1.805  loss_mask_7: 0.6281  loss_dice_7: 3.227  loss_ce_8: 1.802  loss_mask_8: 0.6282  loss_dice_8: 3.237  time: 1.6935  data_time: 0.3543  lr: 5.4362e-06  max_mem: 17674M
[01/19 10:47:57] d2.utils.events INFO:  eta: 9:30:52  iter: 19699  total_loss: 60.23  loss_ce: 1.885  loss_mask: 0.6224  loss_dice: 3.257  loss_ce_0: 3.389  loss_mask_0: 0.6428  loss_dice_0: 3.538  loss_ce_1: 2.167  loss_mask_1: 0.6302  loss_dice_1: 3.393  loss_ce_2: 2.037  loss_mask_2: 0.6286  loss_dice_2: 3.325  loss_ce_3: 1.962  loss_mask_3: 0.6246  loss_dice_3: 3.278  loss_ce_4: 1.924  loss_mask_4: 0.6231  loss_dice_4: 3.267  loss_ce_5: 1.889  loss_mask_5: 0.6277  loss_dice_5: 3.268  loss_ce_6: 1.887  loss_mask_6: 0.6248  loss_dice_6: 3.258  loss_ce_7: 1.874  loss_mask_7: 0.6242  loss_dice_7: 3.26  loss_ce_8: 1.866  loss_mask_8: 0.6248  loss_dice_8: 3.254  time: 1.6935  data_time: 0.3377  lr: 5.4314e-06  max_mem: 17674M
[01/19 10:48:30] d2.utils.events INFO:  eta: 9:30:16  iter: 19719  total_loss: 60.11  loss_ce: 1.886  loss_mask: 0.6108  loss_dice: 3.203  loss_ce_0: 3.296  loss_mask_0: 0.6333  loss_dice_0: 3.508  loss_ce_1: 2.15  loss_mask_1: 0.6157  loss_dice_1: 3.362  loss_ce_2: 2.035  loss_mask_2: 0.607  loss_dice_2: 3.29  loss_ce_3: 1.989  loss_mask_3: 0.6119  loss_dice_3: 3.244  loss_ce_4: 1.929  loss_mask_4: 0.6152  loss_dice_4: 3.23  loss_ce_5: 1.915  loss_mask_5: 0.6171  loss_dice_5: 3.221  loss_ce_6: 1.908  loss_mask_6: 0.613  loss_dice_6: 3.211  loss_ce_7: 1.883  loss_mask_7: 0.6124  loss_dice_7: 3.212  loss_ce_8: 1.877  loss_mask_8: 0.6125  loss_dice_8: 3.205  time: 1.6934  data_time: 0.3363  lr: 5.4266e-06  max_mem: 17674M
[01/19 10:49:04] d2.utils.events INFO:  eta: 9:29:44  iter: 19739  total_loss: 59.05  loss_ce: 1.839  loss_mask: 0.6199  loss_dice: 3.215  loss_ce_0: 3.245  loss_mask_0: 0.6401  loss_dice_0: 3.509  loss_ce_1: 2.126  loss_mask_1: 0.6243  loss_dice_1: 3.362  loss_ce_2: 1.965  loss_mask_2: 0.6204  loss_dice_2: 3.284  loss_ce_3: 1.931  loss_mask_3: 0.6169  loss_dice_3: 3.236  loss_ce_4: 1.878  loss_mask_4: 0.6196  loss_dice_4: 3.229  loss_ce_5: 1.858  loss_mask_5: 0.6177  loss_dice_5: 3.224  loss_ce_6: 1.849  loss_mask_6: 0.6159  loss_dice_6: 3.218  loss_ce_7: 1.835  loss_mask_7: 0.6171  loss_dice_7: 3.219  loss_ce_8: 1.831  loss_mask_8: 0.6183  loss_dice_8: 3.216  time: 1.6934  data_time: 0.3571  lr: 5.4218e-06  max_mem: 17674M
[01/19 10:49:38] d2.utils.events INFO:  eta: 9:29:10  iter: 19759  total_loss: 59.01  loss_ce: 1.803  loss_mask: 0.6259  loss_dice: 3.247  loss_ce_0: 3.321  loss_mask_0: 0.6447  loss_dice_0: 3.524  loss_ce_1: 2.065  loss_mask_1: 0.6279  loss_dice_1: 3.367  loss_ce_2: 1.909  loss_mask_2: 0.623  loss_dice_2: 3.306  loss_ce_3: 1.879  loss_mask_3: 0.6207  loss_dice_3: 3.267  loss_ce_4: 1.838  loss_mask_4: 0.6237  loss_dice_4: 3.259  loss_ce_5: 1.812  loss_mask_5: 0.6247  loss_dice_5: 3.261  loss_ce_6: 1.814  loss_mask_6: 0.6263  loss_dice_6: 3.247  loss_ce_7: 1.803  loss_mask_7: 0.627  loss_dice_7: 3.245  loss_ce_8: 1.783  loss_mask_8: 0.6257  loss_dice_8: 3.25  time: 1.6935  data_time: 0.3613  lr: 5.4169e-06  max_mem: 17674M
[01/19 10:50:13] d2.utils.events INFO:  eta: 9:28:36  iter: 19779  total_loss: 60.56  loss_ce: 1.854  loss_mask: 0.613  loss_dice: 3.243  loss_ce_0: 3.254  loss_mask_0: 0.6381  loss_dice_0: 3.535  loss_ce_1: 2.116  loss_mask_1: 0.628  loss_dice_1: 3.394  loss_ce_2: 2.004  loss_mask_2: 0.6264  loss_dice_2: 3.317  loss_ce_3: 1.97  loss_mask_3: 0.6172  loss_dice_3: 3.269  loss_ce_4: 1.923  loss_mask_4: 0.6149  loss_dice_4: 3.255  loss_ce_5: 1.905  loss_mask_5: 0.6164  loss_dice_5: 3.255  loss_ce_6: 1.886  loss_mask_6: 0.6156  loss_dice_6: 3.247  loss_ce_7: 1.866  loss_mask_7: 0.614  loss_dice_7: 3.239  loss_ce_8: 1.871  loss_mask_8: 0.6144  loss_dice_8: 3.241  time: 1.6935  data_time: 0.3500  lr: 5.4121e-06  max_mem: 17674M
[01/19 10:50:46] d2.utils.events INFO:  eta: 9:28:03  iter: 19799  total_loss: 59.71  loss_ce: 1.828  loss_mask: 0.6178  loss_dice: 3.231  loss_ce_0: 3.206  loss_mask_0: 0.6378  loss_dice_0: 3.531  loss_ce_1: 2.068  loss_mask_1: 0.6221  loss_dice_1: 3.375  loss_ce_2: 1.939  loss_mask_2: 0.6168  loss_dice_2: 3.308  loss_ce_3: 1.922  loss_mask_3: 0.6165  loss_dice_3: 3.249  loss_ce_4: 1.86  loss_mask_4: 0.6192  loss_dice_4: 3.242  loss_ce_5: 1.843  loss_mask_5: 0.6186  loss_dice_5: 3.242  loss_ce_6: 1.842  loss_mask_6: 0.619  loss_dice_6: 3.234  loss_ce_7: 1.832  loss_mask_7: 0.6211  loss_dice_7: 3.239  loss_ce_8: 1.816  loss_mask_8: 0.6208  loss_dice_8: 3.236  time: 1.6935  data_time: 0.3326  lr: 5.4073e-06  max_mem: 17674M
[01/19 10:51:21] d2.utils.events INFO:  eta: 9:27:29  iter: 19819  total_loss: 59.39  loss_ce: 1.808  loss_mask: 0.6268  loss_dice: 3.264  loss_ce_0: 3.265  loss_mask_0: 0.6356  loss_dice_0: 3.507  loss_ce_1: 2.114  loss_mask_1: 0.6306  loss_dice_1: 3.375  loss_ce_2: 1.964  loss_mask_2: 0.629  loss_dice_2: 3.32  loss_ce_3: 1.882  loss_mask_3: 0.6279  loss_dice_3: 3.283  loss_ce_4: 1.844  loss_mask_4: 0.6253  loss_dice_4: 3.288  loss_ce_5: 1.835  loss_mask_5: 0.6259  loss_dice_5: 3.282  loss_ce_6: 1.835  loss_mask_6: 0.6247  loss_dice_6: 3.273  loss_ce_7: 1.801  loss_mask_7: 0.6242  loss_dice_7: 3.269  loss_ce_8: 1.801  loss_mask_8: 0.6258  loss_dice_8: 3.27  time: 1.6935  data_time: 0.3428  lr: 5.4025e-06  max_mem: 17674M
[01/19 10:51:55] d2.utils.events INFO:  eta: 9:26:57  iter: 19839  total_loss: 59.88  loss_ce: 1.821  loss_mask: 0.6111  loss_dice: 3.221  loss_ce_0: 3.248  loss_mask_0: 0.6309  loss_dice_0: 3.508  loss_ce_1: 2.083  loss_mask_1: 0.6177  loss_dice_1: 3.347  loss_ce_2: 1.975  loss_mask_2: 0.6118  loss_dice_2: 3.275  loss_ce_3: 1.922  loss_mask_3: 0.6088  loss_dice_3: 3.236  loss_ce_4: 1.904  loss_mask_4: 0.6113  loss_dice_4: 3.235  loss_ce_5: 1.859  loss_mask_5: 0.6115  loss_dice_5: 3.234  loss_ce_6: 1.856  loss_mask_6: 0.6115  loss_dice_6: 3.22  loss_ce_7: 1.839  loss_mask_7: 0.6103  loss_dice_7: 3.226  loss_ce_8: 1.82  loss_mask_8: 0.6096  loss_dice_8: 3.225  time: 1.6935  data_time: 0.3466  lr: 5.3977e-06  max_mem: 17674M
[01/19 10:52:28] d2.utils.events INFO:  eta: 9:26:29  iter: 19859  total_loss: 60.19  loss_ce: 1.869  loss_mask: 0.6455  loss_dice: 3.229  loss_ce_0: 3.378  loss_mask_0: 0.6696  loss_dice_0: 3.5  loss_ce_1: 2.206  loss_mask_1: 0.652  loss_dice_1: 3.368  loss_ce_2: 2.066  loss_mask_2: 0.6459  loss_dice_2: 3.29  loss_ce_3: 1.982  loss_mask_3: 0.6381  loss_dice_3: 3.236  loss_ce_4: 1.926  loss_mask_4: 0.6449  loss_dice_4: 3.235  loss_ce_5: 1.908  loss_mask_5: 0.6433  loss_dice_5: 3.234  loss_ce_6: 1.9  loss_mask_6: 0.6419  loss_dice_6: 3.23  loss_ce_7: 1.873  loss_mask_7: 0.6438  loss_dice_7: 3.231  loss_ce_8: 1.858  loss_mask_8: 0.6444  loss_dice_8: 3.229  time: 1.6935  data_time: 0.3411  lr: 5.3929e-06  max_mem: 17674M
[01/19 10:53:02] d2.utils.events INFO:  eta: 9:25:48  iter: 19879  total_loss: 60.7  loss_ce: 1.898  loss_mask: 0.6343  loss_dice: 3.233  loss_ce_0: 3.286  loss_mask_0: 0.6585  loss_dice_0: 3.527  loss_ce_1: 2.145  loss_mask_1: 0.6446  loss_dice_1: 3.375  loss_ce_2: 2.038  loss_mask_2: 0.6399  loss_dice_2: 3.307  loss_ce_3: 1.983  loss_mask_3: 0.6375  loss_dice_3: 3.258  loss_ce_4: 1.939  loss_mask_4: 0.6377  loss_dice_4: 3.254  loss_ce_5: 1.921  loss_mask_5: 0.6378  loss_dice_5: 3.257  loss_ce_6: 1.898  loss_mask_6: 0.6321  loss_dice_6: 3.244  loss_ce_7: 1.905  loss_mask_7: 0.6352  loss_dice_7: 3.242  loss_ce_8: 1.896  loss_mask_8: 0.6363  loss_dice_8: 3.24  time: 1.6935  data_time: 0.3263  lr: 5.388e-06  max_mem: 17674M
[01/19 10:53:36] d2.utils.events INFO:  eta: 9:25:03  iter: 19899  total_loss: 59.43  loss_ce: 1.846  loss_mask: 0.6182  loss_dice: 3.231  loss_ce_0: 3.311  loss_mask_0: 0.6324  loss_dice_0: 3.516  loss_ce_1: 2.104  loss_mask_1: 0.622  loss_dice_1: 3.377  loss_ce_2: 1.965  loss_mask_2: 0.6185  loss_dice_2: 3.312  loss_ce_3: 1.924  loss_mask_3: 0.6125  loss_dice_3: 3.262  loss_ce_4: 1.91  loss_mask_4: 0.6169  loss_dice_4: 3.258  loss_ce_5: 1.879  loss_mask_5: 0.6196  loss_dice_5: 3.255  loss_ce_6: 1.886  loss_mask_6: 0.6198  loss_dice_6: 3.241  loss_ce_7: 1.869  loss_mask_7: 0.6186  loss_dice_7: 3.242  loss_ce_8: 1.852  loss_mask_8: 0.6202  loss_dice_8: 3.236  time: 1.6935  data_time: 0.3232  lr: 5.3832e-06  max_mem: 17674M
[01/19 10:54:10] d2.utils.events INFO:  eta: 9:24:36  iter: 19919  total_loss: 59.26  loss_ce: 1.815  loss_mask: 0.6183  loss_dice: 3.226  loss_ce_0: 3.224  loss_mask_0: 0.6455  loss_dice_0: 3.514  loss_ce_1: 2.094  loss_mask_1: 0.6306  loss_dice_1: 3.361  loss_ce_2: 1.969  loss_mask_2: 0.6255  loss_dice_2: 3.292  loss_ce_3: 1.908  loss_mask_3: 0.6228  loss_dice_3: 3.257  loss_ce_4: 1.883  loss_mask_4: 0.6232  loss_dice_4: 3.247  loss_ce_5: 1.845  loss_mask_5: 0.6237  loss_dice_5: 3.241  loss_ce_6: 1.847  loss_mask_6: 0.6199  loss_dice_6: 3.231  loss_ce_7: 1.818  loss_mask_7: 0.6172  loss_dice_7: 3.233  loss_ce_8: 1.821  loss_mask_8: 0.6199  loss_dice_8: 3.234  time: 1.6935  data_time: 0.3372  lr: 5.3784e-06  max_mem: 17674M
[01/19 10:54:43] d2.utils.events INFO:  eta: 9:23:56  iter: 19939  total_loss: 59.88  loss_ce: 1.896  loss_mask: 0.6367  loss_dice: 3.225  loss_ce_0: 3.286  loss_mask_0: 0.6534  loss_dice_0: 3.506  loss_ce_1: 2.21  loss_mask_1: 0.6343  loss_dice_1: 3.362  loss_ce_2: 2.074  loss_mask_2: 0.6303  loss_dice_2: 3.287  loss_ce_3: 2.015  loss_mask_3: 0.6244  loss_dice_3: 3.242  loss_ce_4: 1.963  loss_mask_4: 0.6277  loss_dice_4: 3.237  loss_ce_5: 1.929  loss_mask_5: 0.6285  loss_dice_5: 3.235  loss_ce_6: 1.925  loss_mask_6: 0.631  loss_dice_6: 3.226  loss_ce_7: 1.901  loss_mask_7: 0.635  loss_dice_7: 3.226  loss_ce_8: 1.895  loss_mask_8: 0.6356  loss_dice_8: 3.224  time: 1.6935  data_time: 0.3304  lr: 5.3736e-06  max_mem: 17674M
[01/19 10:55:17] d2.utils.events INFO:  eta: 9:23:35  iter: 19959  total_loss: 59.27  loss_ce: 1.832  loss_mask: 0.6159  loss_dice: 3.236  loss_ce_0: 3.29  loss_mask_0: 0.6346  loss_dice_0: 3.525  loss_ce_1: 2.088  loss_mask_1: 0.6149  loss_dice_1: 3.369  loss_ce_2: 1.962  loss_mask_2: 0.6139  loss_dice_2: 3.3  loss_ce_3: 1.922  loss_mask_3: 0.6149  loss_dice_3: 3.259  loss_ce_4: 1.869  loss_mask_4: 0.6126  loss_dice_4: 3.25  loss_ce_5: 1.85  loss_mask_5: 0.6171  loss_dice_5: 3.247  loss_ce_6: 1.836  loss_mask_6: 0.6157  loss_dice_6: 3.238  loss_ce_7: 1.837  loss_mask_7: 0.6191  loss_dice_7: 3.234  loss_ce_8: 1.819  loss_mask_8: 0.6162  loss_dice_8: 3.238  time: 1.6935  data_time: 0.3587  lr: 5.3688e-06  max_mem: 17674M
[01/19 10:55:51] d2.utils.events INFO:  eta: 9:22:57  iter: 19979  total_loss: 59.44  loss_ce: 1.799  loss_mask: 0.615  loss_dice: 3.206  loss_ce_0: 3.305  loss_mask_0: 0.6282  loss_dice_0: 3.526  loss_ce_1: 2.066  loss_mask_1: 0.6223  loss_dice_1: 3.344  loss_ce_2: 1.917  loss_mask_2: 0.6183  loss_dice_2: 3.285  loss_ce_3: 1.861  loss_mask_3: 0.6152  loss_dice_3: 3.234  loss_ce_4: 1.82  loss_mask_4: 0.6132  loss_dice_4: 3.231  loss_ce_5: 1.792  loss_mask_5: 0.6198  loss_dice_5: 3.223  loss_ce_6: 1.824  loss_mask_6: 0.6165  loss_dice_6: 3.216  loss_ce_7: 1.807  loss_mask_7: 0.6146  loss_dice_7: 3.214  loss_ce_8: 1.799  loss_mask_8: 0.6172  loss_dice_8: 3.21  time: 1.6935  data_time: 0.3243  lr: 5.3639e-06  max_mem: 17674M
[01/19 10:56:25] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/sceneflow_crop192x384/model_0019999.pth
[01/19 10:56:26] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 10:56:27] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 10:56:27] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 11:02:06] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.0499771589765645, 'error_1pix': 0.3651642974911897, 'error_3pix': 0.16140471041219948, 'mIoU': 8.033282909865065, 'fwIoU': 23.326756995764455, 'IoU-0': nan, 'IoU-1': 95.48039254463781, 'IoU-2': 13.19977865954986, 'IoU-3': 38.66204099023655, 'IoU-4': 32.52811305760879, 'IoU-5': 18.583406346920363, 'IoU-6': 22.45179638570601, 'IoU-7': 16.45477049002577, 'IoU-8': 4.60576330161003, 'IoU-9': 6.014800847840377, 'IoU-10': 20.073748119208044, 'IoU-11': 30.073822766592155, 'IoU-12': 30.932268269868008, 'IoU-13': 27.631511660840253, 'IoU-14': 23.9950598584487, 'IoU-15': 26.125748591716956, 'IoU-16': 20.582467581643762, 'IoU-17': 22.568874957830165, 'IoU-18': 22.51316682755534, 'IoU-19': 19.17303537941186, 'IoU-20': 20.877066771568362, 'IoU-21': 23.560108565098787, 'IoU-22': 21.844403800582704, 'IoU-23': 20.51739589596517, 'IoU-24': 19.786302591826477, 'IoU-25': 20.28725461923985, 'IoU-26': 19.688561876805284, 'IoU-27': 21.415629026107013, 'IoU-28': 18.329739212441563, 'IoU-29': 20.60602767432973, 'IoU-30': 20.72428774620497, 'IoU-31': 16.777836316242986, 'IoU-32': 12.706738744077473, 'IoU-33': 18.400344664612415, 'IoU-34': 18.492065701036417, 'IoU-35': 12.311090781861225, 'IoU-36': 17.251266841936268, 'IoU-37': 15.262930019006236, 'IoU-38': 14.2974088871943, 'IoU-39': 15.832277678654721, 'IoU-40': 14.21119702657446, 'IoU-41': 11.691341755766253, 'IoU-42': 12.952806420139328, 'IoU-43': 14.622866888836871, 'IoU-44': 10.701036576922268, 'IoU-45': 10.539863794050001, 'IoU-46': 12.711017135439631, 'IoU-47': 10.72933776714999, 'IoU-48': 10.038785690860953, 'IoU-49': 11.151987004715378, 'IoU-50': 10.873891155735674, 'IoU-51': 13.047497403310397, 'IoU-52': 9.633382651949024, 'IoU-53': 12.717934076047937, 'IoU-54': 13.263574094769293, 'IoU-55': 13.536441976977942, 'IoU-56': 11.26067790217798, 'IoU-57': 10.517544747996212, 'IoU-58': 13.241801811919519, 'IoU-59': 9.138562066258416, 'IoU-60': 11.709222260478564, 'IoU-61': 9.857343810011217, 'IoU-62': 11.429379941939754, 'IoU-63': 11.135567873518932, 'IoU-64': 10.895652346107246, 'IoU-65': 10.080164564940933, 'IoU-66': 9.279942528409084, 'IoU-67': 7.892100399660087, 'IoU-68': 7.336780499833104, 'IoU-69': 6.847938930372627, 'IoU-70': 7.753244104096637, 'IoU-71': 7.3365441329594026, 'IoU-72': 3.6002824732351475, 'IoU-73': 7.610015469693692, 'IoU-74': 4.814936663779974, 'IoU-75': 6.081656694236502, 'IoU-76': 5.607741601390762, 'IoU-77': 4.986734382695944, 'IoU-78': 4.966159635207434, 'IoU-79': 6.09095779252711, 'IoU-80': 4.791494027741858, 'IoU-81': 4.382871722889988, 'IoU-82': 4.130472202907449, 'IoU-83': 2.8833671361431685, 'IoU-84': 4.194167962619768, 'IoU-85': 4.75100078193831, 'IoU-86': 2.9269543740216037, 'IoU-87': 4.8390490523320455, 'IoU-88': 4.299271096288644, 'IoU-89': 3.771938203855432, 'IoU-90': 3.9600251633580843, 'IoU-91': 4.253514494783108, 'IoU-92': 3.0598687008005223, 'IoU-93': 4.821976978786104, 'IoU-94': 3.9043871257709304, 'IoU-95': 3.6657888924316895, 'IoU-96': 7.25083447050672, 'IoU-97': 5.347876387449711, 'IoU-98': 4.497306488898407, 'IoU-99': 4.186063252408095, 'IoU-100': 6.609994006371712, 'IoU-101': 5.037593781166848, 'IoU-102': 4.715912770034642, 'IoU-103': 5.174735833567989, 'IoU-104': 5.589052552426657, 'IoU-105': 5.250361303738103, 'IoU-106': 4.688938259350777, 'IoU-107': 5.050511426616403, 'IoU-108': 4.205832084986101, 'IoU-109': 3.939658459778993, 'IoU-110': 4.778489091690553, 'IoU-111': 5.140512879246017, 'IoU-112': 4.182600594927453, 'IoU-113': 3.350488522868628, 'IoU-114': 4.364076043501983, 'IoU-115': 4.284660180402033, 'IoU-116': 3.4917945090886895, 'IoU-117': 3.4533328299857917, 'IoU-118': 2.4426007676078236, 'IoU-119': 4.712949748576835, 'IoU-120': 3.0170671433492857, 'IoU-121': 3.1441065997684703, 'IoU-122': 3.440408065466618, 'IoU-123': 2.737975055894768, 'IoU-124': 3.574688515603382, 'IoU-125': 2.159534358086883, 'IoU-126': 2.832197017959807, 'IoU-127': 3.7703567085983103, 'IoU-128': 2.892840059811219, 'IoU-129': 3.004788563977685, 'IoU-130': 2.1529631011478734, 'IoU-131': 2.474320811401224, 'IoU-132': 2.2988031744286213, 'IoU-133': 2.8268872829663607, 'IoU-134': 2.3191432859850774, 'IoU-135': 2.9608394063195207, 'IoU-136': 1.7017177970202992, 'IoU-137': 0.8105633188651777, 'IoU-138': 1.0997923636825204, 'IoU-139': 2.425375974258385, 'IoU-140': 2.4528268433495986, 'IoU-141': 2.0775097964532643, 'IoU-142': 1.4986270106234747, 'IoU-143': 2.201053031536666, 'IoU-144': 1.2368485133467122, 'IoU-145': 2.60799957054372, 'IoU-146': 0.9806628982422624, 'IoU-147': 2.758499573366287, 'IoU-148': 0.956588893916805, 'IoU-149': 2.231054996027148, 'IoU-150': 1.8486093224389415, 'IoU-151': 0.6009113896985346, 'IoU-152': 0.958328485013365, 'IoU-153': 0.5481075408058509, 'IoU-154': 1.3862952223358744, 'IoU-155': 0.8875732604872849, 'IoU-156': 1.918549001951977, 'IoU-157': 0.4033031141299882, 'IoU-158': 0.39158823516449126, 'IoU-159': 1.256112073825083, 'IoU-160': 1.992529960793136, 'IoU-161': 0.5467013435804213, 'IoU-162': 1.574567299725195, 'IoU-163': 0.7237617491747791, 'IoU-164': 1.0943794644827805, 'IoU-165': 0.7273616628364626, 'IoU-166': 0.7470791740859554, 'IoU-167': 0.8488647533335949, 'IoU-168': 1.5248907322521785, 'IoU-169': 0.5820675601057972, 'IoU-170': 1.0610971714989001, 'IoU-171': 0.16256755028422357, 'IoU-172': 0.9839540927872027, 'IoU-173': 0.1076695348783227, 'IoU-174': 0.3028173830857527, 'IoU-175': 0.5513616987621801, 'IoU-176': 0.2673632808938851, 'IoU-177': 0.2598325601687416, 'IoU-178': 0.06338828731134126, 'IoU-179': 0.03354219198224604, 'IoU-180': 0.5589440687974292, 'IoU-181': 0.8315314194461811, 'IoU-182': 1.9370808564554838, 'IoU-183': 0.396237488047212, 'IoU-184': 0.340852884884196, 'IoU-185': 0.4834068297665466, 'IoU-186': 0.12412014276123483, 'IoU-187': 1.6495779564028126, 'IoU-188': 2.7476944041668134, 'IoU-189': 3.4156903265262843, 'IoU-190': 1.618115629422761, 'IoU-191': 1.5172760616249876, 'IoU-192': 2.87303352931829, 'mACC': 13.657137268201389, 'pACC': 33.38360524772064, 'ACC-0': nan, 'ACC-1': 98.92609322914558, 'ACC-2': 14.201985486409411, 'ACC-3': 51.581163301760135, 'ACC-4': 47.69845133069702, 'ACC-5': 24.8035565768106, 'ACC-6': 36.16154195058267, 'ACC-7': 26.00756241545154, 'ACC-8': 5.2002793795464415, 'ACC-9': 6.540335199533976, 'ACC-10': 29.98762516660827, 'ACC-11': 47.710137615623346, 'ACC-12': 61.05784551396093, 'ACC-13': 52.02508649627266, 'ACC-14': 34.74187540557941, 'ACC-15': 47.20081634157777, 'ACC-16': 29.66049877295972, 'ACC-17': 35.152619525904605, 'ACC-18': 37.55344438257742, 'ACC-19': 28.324576201439612, 'ACC-20': 31.83632008682766, 'ACC-21': 43.03015762014686, 'ACC-22': 32.26752514750789, 'ACC-23': 33.56096472935078, 'ACC-24': 31.211508077798328, 'ACC-25': 33.78324146086317, 'ACC-26': 32.15719039390348, 'ACC-27': 35.49410487976729, 'ACC-28': 30.856575135231967, 'ACC-29': 33.30601572236267, 'ACC-30': 37.962636991723365, 'ACC-31': 24.078879198122078, 'ACC-32': 18.591716494635232, 'ACC-33': 36.308006884073116, 'ACC-34': 33.61566370588663, 'ACC-35': 16.739496391016036, 'ACC-36': 31.330225361566978, 'ACC-37': 26.36666123891444, 'ACC-38': 24.318141261184426, 'ACC-39': 30.033680567762307, 'ACC-40': 24.589715434845388, 'ACC-41': 19.66073324227284, 'ACC-42': 24.131948513515418, 'ACC-43': 28.299980773366485, 'ACC-44': 15.894325807667311, 'ACC-45': 16.479980316926397, 'ACC-46': 27.39899300618723, 'ACC-47': 18.81311360067915, 'ACC-48': 16.657071001199967, 'ACC-49': 19.60160712690946, 'ACC-50': 20.099305446781266, 'ACC-51': 26.257385233996633, 'ACC-52': 15.73925458904983, 'ACC-53': 25.42225226056192, 'ACC-54': 25.101462748556564, 'ACC-55': 27.21736658497077, 'ACC-56': 18.46521421867993, 'ACC-57': 18.54447534355263, 'ACC-58': 26.72242729617953, 'ACC-59': 16.946282166379696, 'ACC-60': 23.854547440897207, 'ACC-61': 17.215521029210652, 'ACC-62': 23.308825024202203, 'ACC-63': 22.01180668381373, 'ACC-64': 23.073866959728164, 'ACC-65': 20.583267017395137, 'ACC-66': 19.196608710192145, 'ACC-67': 16.945303627387272, 'ACC-68': 15.290755479796136, 'ACC-69': 11.491828388803393, 'ACC-70': 18.073374849988923, 'ACC-71': 15.56874746059197, 'ACC-72': 4.838435578695475, 'ACC-73': 21.439909677892697, 'ACC-74': 7.2839988553734765, 'ACC-75': 13.080484723267219, 'ACC-76': 10.40898575295089, 'ACC-77': 9.971248852977913, 'ACC-78': 8.908634041687549, 'ACC-79': 12.899329960917264, 'ACC-80': 9.073615392551622, 'ACC-81': 9.189123307372604, 'ACC-82': 8.544868135362172, 'ACC-83': 4.434718937919188, 'ACC-84': 8.0422474141753, 'ACC-85': 9.320870556637981, 'ACC-86': 4.078959460733422, 'ACC-87': 8.53117974256354, 'ACC-88': 8.194399861445675, 'ACC-89': 6.339444537195692, 'ACC-90': 7.165365552199858, 'ACC-91': 7.832596387819403, 'ACC-92': 4.628235684579331, 'ACC-93': 8.629547441031564, 'ACC-94': 5.943864021739395, 'ACC-95': 5.370779018412247, 'ACC-96': 13.765829029742363, 'ACC-97': 9.846050962971182, 'ACC-98': 6.7781099758286345, 'ACC-99': 6.324692014159133, 'ACC-100': 12.263460885036414, 'ACC-101': 9.187807679543857, 'ACC-102': 7.556864521975533, 'ACC-103': 8.193043355058089, 'ACC-104': 10.295221465286145, 'ACC-105': 10.138292158625951, 'ACC-106': 9.498609820751707, 'ACC-107': 8.703967207550619, 'ACC-108': 7.13611190719061, 'ACC-109': 6.402450519714862, 'ACC-110': 8.904515247492675, 'ACC-111': 10.240212656003154, 'ACC-112': 8.161382519907722, 'ACC-113': 5.779821444981369, 'ACC-114': 8.216955047691378, 'ACC-115': 9.354487092748785, 'ACC-116': 5.733731494393098, 'ACC-117': 5.770910701125991, 'ACC-118': 3.4264644075211916, 'ACC-119': 9.373602048777267, 'ACC-120': 4.970139891839467, 'ACC-121': 5.346455144309186, 'ACC-122': 6.015077320803495, 'ACC-123': 4.082892381416665, 'ACC-124': 7.281281081838431, 'ACC-125': 4.3949995812317875, 'ACC-126': 5.807657628940154, 'ACC-127': 8.45226803352989, 'ACC-128': 6.4359164815810885, 'ACC-129': 6.137268842885642, 'ACC-130': 4.387671130395751, 'ACC-131': 3.819399446937722, 'ACC-132': 4.034944858300409, 'ACC-133': 5.854307429559016, 'ACC-134': 3.8408961654459284, 'ACC-135': 7.393036314919332, 'ACC-136': 3.1433446701453596, 'ACC-137': 1.106610584353584, 'ACC-138': 2.3985804756707365, 'ACC-139': 5.094474045155044, 'ACC-140': 6.645662404524198, 'ACC-141': 4.333161095299248, 'ACC-142': 2.4073826634563575, 'ACC-143': 4.591172418998736, 'ACC-144': 2.1270758122743683, 'ACC-145': 7.387463941501375, 'ACC-146': 1.3078065385757693, 'ACC-147': 5.5713042824259995, 'ACC-148': 1.5411800378498761, 'ACC-149': 4.772485495436932, 'ACC-150': 3.3783297842734434, 'ACC-151': 0.8626395234699978, 'ACC-152': 1.232277125901949, 'ACC-153': 0.6853597537514429, 'ACC-154': 3.122229697757457, 'ACC-155': 1.379223641298319, 'ACC-156': 4.941470004589321, 'ACC-157': 0.48099105389304686, 'ACC-158': 0.5015870417231787, 'ACC-159': 2.1323439763869945, 'ACC-160': 4.157382482016016, 'ACC-161': 0.8530458299749774, 'ACC-162': 5.286506139523536, 'ACC-163': 1.3189292642398653, 'ACC-164': 2.397743524047197, 'ACC-165': 1.0721761475349953, 'ACC-166': 1.2460232852909823, 'ACC-167': 1.2406478050678604, 'ACC-168': 4.277375342851115, 'ACC-169': 0.6695993809364214, 'ACC-170': 1.8979726564163721, 'ACC-171': 0.19378812620658364, 'ACC-172': 1.4836833722265437, 'ACC-173': 0.11345121221585457, 'ACC-174': 0.36310698794551904, 'ACC-175': 0.63156454585961, 'ACC-176': 0.292583294636638, 'ACC-177': 0.27257510579125216, 'ACC-178': 0.07011633903857557, 'ACC-179': 0.03489686151423975, 'ACC-180': 0.6751837177012429, 'ACC-181': 1.2506484185692865, 'ACC-182': 4.686926216982674, 'ACC-183': 0.45461929459848244, 'ACC-184': 0.37380576722159725, 'ACC-185': 0.5683891560310224, 'ACC-186': 0.12700271238134808, 'ACC-187': 2.6124983389507, 'ACC-188': 5.3193474839594845, 'ACC-189': 7.1118116866613095, 'ACC-190': 3.9212090088768248, 'ACC-191': 3.0869820554649268, 'ACC-192': 9.46540604633657})])
[01/19 11:02:06] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 11:02:06] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 11:02:06] d2.evaluation.testing INFO: copypaste: 3.0500,0.3652,0.1614,8.0333,23.3268,13.6571,33.3836
[01/19 11:02:06] d2.utils.events INFO:  eta: 9:22:22  iter: 19999  total_loss: 59.15  loss_ce: 1.845  loss_mask: 0.6126  loss_dice: 3.201  loss_ce_0: 3.224  loss_mask_0: 0.6288  loss_dice_0: 3.483  loss_ce_1: 2.129  loss_mask_1: 0.6162  loss_dice_1: 3.317  loss_ce_2: 1.981  loss_mask_2: 0.6117  loss_dice_2: 3.246  loss_ce_3: 1.955  loss_mask_3: 0.6082  loss_dice_3: 3.209  loss_ce_4: 1.903  loss_mask_4: 0.6071  loss_dice_4: 3.209  loss_ce_5: 1.874  loss_mask_5: 0.6077  loss_dice_5: 3.208  loss_ce_6: 1.862  loss_mask_6: 0.6077  loss_dice_6: 3.19  loss_ce_7: 1.849  loss_mask_7: 0.6092  loss_dice_7: 3.196  loss_ce_8: 1.846  loss_mask_8: 0.6117  loss_dice_8: 3.2  time: 1.6935  data_time: 0.3328  lr: 5.3591e-06  max_mem: 17674M
[01/19 11:02:40] d2.utils.events INFO:  eta: 9:21:54  iter: 20019  total_loss: 59.52  loss_ce: 1.842  loss_mask: 0.6148  loss_dice: 3.232  loss_ce_0: 3.31  loss_mask_0: 0.6335  loss_dice_0: 3.515  loss_ce_1: 2.156  loss_mask_1: 0.6283  loss_dice_1: 3.359  loss_ce_2: 1.991  loss_mask_2: 0.6174  loss_dice_2: 3.295  loss_ce_3: 1.953  loss_mask_3: 0.6136  loss_dice_3: 3.248  loss_ce_4: 1.891  loss_mask_4: 0.6137  loss_dice_4: 3.235  loss_ce_5: 1.858  loss_mask_5: 0.6169  loss_dice_5: 3.234  loss_ce_6: 1.861  loss_mask_6: 0.6178  loss_dice_6: 3.227  loss_ce_7: 1.834  loss_mask_7: 0.6182  loss_dice_7: 3.224  loss_ce_8: 1.844  loss_mask_8: 0.6149  loss_dice_8: 3.224  time: 1.6935  data_time: 0.3436  lr: 5.3543e-06  max_mem: 17674M
[01/19 11:03:14] d2.utils.events INFO:  eta: 9:21:34  iter: 20039  total_loss: 60.16  loss_ce: 1.854  loss_mask: 0.6281  loss_dice: 3.221  loss_ce_0: 3.345  loss_mask_0: 0.6551  loss_dice_0: 3.506  loss_ce_1: 2.138  loss_mask_1: 0.6384  loss_dice_1: 3.364  loss_ce_2: 2.019  loss_mask_2: 0.6263  loss_dice_2: 3.294  loss_ce_3: 1.982  loss_mask_3: 0.6262  loss_dice_3: 3.243  loss_ce_4: 1.918  loss_mask_4: 0.6317  loss_dice_4: 3.241  loss_ce_5: 1.873  loss_mask_5: 0.6307  loss_dice_5: 3.242  loss_ce_6: 1.883  loss_mask_6: 0.6267  loss_dice_6: 3.23  loss_ce_7: 1.867  loss_mask_7: 0.6272  loss_dice_7: 3.222  loss_ce_8: 1.857  loss_mask_8: 0.6287  loss_dice_8: 3.227  time: 1.6935  data_time: 0.3401  lr: 5.3495e-06  max_mem: 17674M
[01/19 11:03:48] d2.utils.events INFO:  eta: 9:20:42  iter: 20059  total_loss: 59.86  loss_ce: 1.885  loss_mask: 0.629  loss_dice: 3.258  loss_ce_0: 3.293  loss_mask_0: 0.6482  loss_dice_0: 3.532  loss_ce_1: 2.124  loss_mask_1: 0.6364  loss_dice_1: 3.4  loss_ce_2: 1.982  loss_mask_2: 0.6306  loss_dice_2: 3.326  loss_ce_3: 1.948  loss_mask_3: 0.6302  loss_dice_3: 3.282  loss_ce_4: 1.919  loss_mask_4: 0.6312  loss_dice_4: 3.282  loss_ce_5: 1.889  loss_mask_5: 0.628  loss_dice_5: 3.283  loss_ce_6: 1.892  loss_mask_6: 0.6297  loss_dice_6: 3.266  loss_ce_7: 1.876  loss_mask_7: 0.6281  loss_dice_7: 3.27  loss_ce_8: 1.878  loss_mask_8: 0.6327  loss_dice_8: 3.266  time: 1.6935  data_time: 0.3466  lr: 5.3446e-06  max_mem: 17674M
[01/19 11:04:12] detectron2 INFO: Rank of current process: 0. World size: 1
[01/19 11:04:15] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5,6,7     Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/19 11:04:15] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/19 11:04:16] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/19 11:04:16] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m192[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop192x384[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/19 11:04:16] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop192x384/config.yaml
[01/19 11:04:16] d2.utils.env INFO: Using a generated random seed 16748507
[01/19 11:04:22] d2.utils.events INFO:  eta: 9:20:33  iter: 20079  total_loss: 59.4  loss_ce: 1.791  loss_mask: 0.6198  loss_dice: 3.189  loss_ce_0: 3.278  loss_mask_0: 0.6384  loss_dice_0: 3.508  loss_ce_1: 2.038  loss_mask_1: 0.6194  loss_dice_1: 3.334  loss_ce_2: 1.931  loss_mask_2: 0.6171  loss_dice_2: 3.263  loss_ce_3: 1.908  loss_mask_3: 0.618  loss_dice_3: 3.224  loss_ce_4: 1.861  loss_mask_4: 0.6239  loss_dice_4: 3.209  loss_ce_5: 1.82  loss_mask_5: 0.6238  loss_dice_5: 3.205  loss_ce_6: 1.827  loss_mask_6: 0.6191  loss_dice_6: 3.196  loss_ce_7: 1.798  loss_mask_7: 0.622  loss_dice_7: 3.198  loss_ce_8: 1.8  loss_mask_8: 0.6216  loss_dice_8: 3.191  time: 1.6935  data_time: 0.3546  lr: 5.3398e-06  max_mem: 17674M
[01/19 11:04:23] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/19 11:04:23] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 11:04:37] d2.data.build INFO: Using training sampler TrainingSampler
[01/19 11:04:37] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/19 11:04:37] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/19 11:04:37] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/19 11:04:37] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/19 11:04:37] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/19 11:04:38] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/19 11:04:38] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/19 11:04:38] d2.engine.train_loop INFO: Starting training from iteration 0
[01/19 11:04:41] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 395, in run_step
    loss_dict = self.model(data)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 241, in forward
    features_left = self.backbone(images_left.tensor)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/detectron2/detectron2/modeling/backbone/resnet.py", line 445, in forward
    x = self.stem(x)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/detectron2/detectron2/modeling/backbone/resnet.py", line 356, in forward
    x = self.conv1(x)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/detectron2/detectron2/layers/wrappers.py", line 110, in forward
    x = self.norm(x)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py", line 731, in forward
    world_size = torch.distributed.get_world_size(process_group)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 748, in get_world_size
    return _get_group_size(group)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 274, in _get_group_size
    default_pg = _get_default_group()
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 358, in _get_default_group
    raise RuntimeError("Default process group has not been initialized, "
RuntimeError: Default process group has not been initialized, please make sure to call init_process_group.
[01/19 11:04:41] d2.engine.hooks INFO: Total training time: 0:00:03 (0:00:00 on hooks)
[01/19 11:04:41] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 636M
[01/19 11:04:57] d2.utils.events INFO:  eta: 9:20:24  iter: 20099  total_loss: 59.72  loss_ce: 1.875  loss_mask: 0.6179  loss_dice: 3.234  loss_ce_0: 3.302  loss_mask_0: 0.6357  loss_dice_0: 3.527  loss_ce_1: 2.137  loss_mask_1: 0.6225  loss_dice_1: 3.373  loss_ce_2: 1.996  loss_mask_2: 0.618  loss_dice_2: 3.302  loss_ce_3: 1.959  loss_mask_3: 0.6154  loss_dice_3: 3.259  loss_ce_4: 1.928  loss_mask_4: 0.6186  loss_dice_4: 3.254  loss_ce_5: 1.91  loss_mask_5: 0.6178  loss_dice_5: 3.252  loss_ce_6: 1.906  loss_mask_6: 0.6131  loss_dice_6: 3.24  loss_ce_7: 1.894  loss_mask_7: 0.6182  loss_dice_7: 3.238  loss_ce_8: 1.866  loss_mask_8: 0.6175  loss_dice_8: 3.237  time: 1.6935  data_time: 0.3476  lr: 5.335e-06  max_mem: 17674M
[01/19 11:05:31] d2.utils.events INFO:  eta: 9:19:55  iter: 20119  total_loss: 59.42  loss_ce: 1.813  loss_mask: 0.6188  loss_dice: 3.226  loss_ce_0: 3.271  loss_mask_0: 0.6386  loss_dice_0: 3.524  loss_ce_1: 2.06  loss_mask_1: 0.6226  loss_dice_1: 3.372  loss_ce_2: 1.967  loss_mask_2: 0.6174  loss_dice_2: 3.295  loss_ce_3: 1.902  loss_mask_3: 0.6151  loss_dice_3: 3.253  loss_ce_4: 1.849  loss_mask_4: 0.6152  loss_dice_4: 3.249  loss_ce_5: 1.824  loss_mask_5: 0.62  loss_dice_5: 3.244  loss_ce_6: 1.812  loss_mask_6: 0.618  loss_dice_6: 3.238  loss_ce_7: 1.811  loss_mask_7: 0.6197  loss_dice_7: 3.228  loss_ce_8: 1.802  loss_mask_8: 0.6184  loss_dice_8: 3.232  time: 1.6935  data_time: 0.3610  lr: 5.3302e-06  max_mem: 17674M
[01/19 11:06:05] d2.utils.events INFO:  eta: 9:19:37  iter: 20139  total_loss: 59.99  loss_ce: 1.868  loss_mask: 0.6255  loss_dice: 3.248  loss_ce_0: 3.269  loss_mask_0: 0.6457  loss_dice_0: 3.537  loss_ce_1: 2.047  loss_mask_1: 0.6328  loss_dice_1: 3.375  loss_ce_2: 1.961  loss_mask_2: 0.6263  loss_dice_2: 3.309  loss_ce_3: 1.934  loss_mask_3: 0.618  loss_dice_3: 3.278  loss_ce_4: 1.901  loss_mask_4: 0.6216  loss_dice_4: 3.269  loss_ce_5: 1.884  loss_mask_5: 0.6236  loss_dice_5: 3.263  loss_ce_6: 1.884  loss_mask_6: 0.6213  loss_dice_6: 3.251  loss_ce_7: 1.851  loss_mask_7: 0.6236  loss_dice_7: 3.251  loss_ce_8: 1.846  loss_mask_8: 0.6271  loss_dice_8: 3.248  time: 1.6935  data_time: 0.3433  lr: 5.3253e-06  max_mem: 17674M
[01/19 11:06:39] d2.utils.events INFO:  eta: 9:19:23  iter: 20159  total_loss: 59.87  loss_ce: 1.814  loss_mask: 0.6135  loss_dice: 3.248  loss_ce_0: 3.24  loss_mask_0: 0.645  loss_dice_0: 3.558  loss_ce_1: 2.038  loss_mask_1: 0.6282  loss_dice_1: 3.373  loss_ce_2: 1.973  loss_mask_2: 0.6172  loss_dice_2: 3.305  loss_ce_3: 1.923  loss_mask_3: 0.6136  loss_dice_3: 3.267  loss_ce_4: 1.896  loss_mask_4: 0.6132  loss_dice_4: 3.259  loss_ce_5: 1.872  loss_mask_5: 0.6136  loss_dice_5: 3.26  loss_ce_6: 1.85  loss_mask_6: 0.6123  loss_dice_6: 3.247  loss_ce_7: 1.84  loss_mask_7: 0.6134  loss_dice_7: 3.255  loss_ce_8: 1.818  loss_mask_8: 0.6129  loss_dice_8: 3.254  time: 1.6936  data_time: 0.3559  lr: 5.3205e-06  max_mem: 17674M
[01/19 11:07:13] d2.utils.events INFO:  eta: 9:18:37  iter: 20179  total_loss: 60.21  loss_ce: 1.891  loss_mask: 0.6321  loss_dice: 3.258  loss_ce_0: 3.278  loss_mask_0: 0.6531  loss_dice_0: 3.539  loss_ce_1: 2.135  loss_mask_1: 0.6352  loss_dice_1: 3.408  loss_ce_2: 1.993  loss_mask_2: 0.6323  loss_dice_2: 3.329  loss_ce_3: 1.966  loss_mask_3: 0.6289  loss_dice_3: 3.288  loss_ce_4: 1.917  loss_mask_4: 0.6291  loss_dice_4: 3.282  loss_ce_5: 1.884  loss_mask_5: 0.6296  loss_dice_5: 3.28  loss_ce_6: 1.914  loss_mask_6: 0.6278  loss_dice_6: 3.263  loss_ce_7: 1.882  loss_mask_7: 0.6312  loss_dice_7: 3.261  loss_ce_8: 1.896  loss_mask_8: 0.6312  loss_dice_8: 3.26  time: 1.6935  data_time: 0.3273  lr: 5.3157e-06  max_mem: 17674M
[01/19 11:07:47] d2.utils.events INFO:  eta: 9:18:00  iter: 20199  total_loss: 59.94  loss_ce: 1.88  loss_mask: 0.6172  loss_dice: 3.21  loss_ce_0: 3.246  loss_mask_0: 0.6396  loss_dice_0: 3.534  loss_ce_1: 2.184  loss_mask_1: 0.6243  loss_dice_1: 3.364  loss_ce_2: 2.054  loss_mask_2: 0.6136  loss_dice_2: 3.292  loss_ce_3: 1.983  loss_mask_3: 0.6123  loss_dice_3: 3.241  loss_ce_4: 1.926  loss_mask_4: 0.615  loss_dice_4: 3.235  loss_ce_5: 1.907  loss_mask_5: 0.614  loss_dice_5: 3.229  loss_ce_6: 1.894  loss_mask_6: 0.6148  loss_dice_6: 3.219  loss_ce_7: 1.88  loss_mask_7: 0.6181  loss_dice_7: 3.221  loss_ce_8: 1.884  loss_mask_8: 0.6163  loss_dice_8: 3.222  time: 1.6935  data_time: 0.3345  lr: 5.3109e-06  max_mem: 17674M
[01/19 11:08:20] d2.utils.events INFO:  eta: 9:16:54  iter: 20219  total_loss: 59.15  loss_ce: 1.816  loss_mask: 0.6308  loss_dice: 3.196  loss_ce_0: 3.319  loss_mask_0: 0.6555  loss_dice_0: 3.476  loss_ce_1: 2.111  loss_mask_1: 0.6367  loss_dice_1: 3.336  loss_ce_2: 1.99  loss_mask_2: 0.6344  loss_dice_2: 3.266  loss_ce_3: 1.926  loss_mask_3: 0.6322  loss_dice_3: 3.209  loss_ce_4: 1.875  loss_mask_4: 0.6325  loss_dice_4: 3.212  loss_ce_5: 1.849  loss_mask_5: 0.6316  loss_dice_5: 3.21  loss_ce_6: 1.844  loss_mask_6: 0.6315  loss_dice_6: 3.203  loss_ce_7: 1.833  loss_mask_7: 0.6312  loss_dice_7: 3.202  loss_ce_8: 1.821  loss_mask_8: 0.6317  loss_dice_8: 3.205  time: 1.6935  data_time: 0.3368  lr: 5.306e-06  max_mem: 17674M
[01/19 11:08:54] d2.utils.events INFO:  eta: 9:16:48  iter: 20239  total_loss: 59.44  loss_ce: 1.808  loss_mask: 0.6169  loss_dice: 3.21  loss_ce_0: 3.282  loss_mask_0: 0.6375  loss_dice_0: 3.492  loss_ce_1: 2.089  loss_mask_1: 0.6218  loss_dice_1: 3.334  loss_ce_2: 1.978  loss_mask_2: 0.6195  loss_dice_2: 3.268  loss_ce_3: 1.932  loss_mask_3: 0.6129  loss_dice_3: 3.229  loss_ce_4: 1.854  loss_mask_4: 0.6176  loss_dice_4: 3.22  loss_ce_5: 1.827  loss_mask_5: 0.6193  loss_dice_5: 3.226  loss_ce_6: 1.837  loss_mask_6: 0.6196  loss_dice_6: 3.215  loss_ce_7: 1.825  loss_mask_7: 0.618  loss_dice_7: 3.209  loss_ce_8: 1.818  loss_mask_8: 0.6187  loss_dice_8: 3.214  time: 1.6935  data_time: 0.3413  lr: 5.3012e-06  max_mem: 17674M
[01/19 11:09:22] detectron2 INFO: Rank of current process: 0. World size: 1
[01/19 11:09:25] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5,6,7     Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/19 11:09:25] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/19 11:09:25] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/19 11:09:25] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m192[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop192x384[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/19 11:09:26] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop192x384/config.yaml
[01/19 11:09:26] d2.utils.env INFO: Using a generated random seed 26433097
[01/19 11:09:29] d2.utils.events INFO:  eta: 9:16:25  iter: 20259  total_loss: 60.45  loss_ce: 1.889  loss_mask: 0.6283  loss_dice: 3.246  loss_ce_0: 3.384  loss_mask_0: 0.6568  loss_dice_0: 3.53  loss_ce_1: 2.229  loss_mask_1: 0.6385  loss_dice_1: 3.374  loss_ce_2: 2.067  loss_mask_2: 0.6321  loss_dice_2: 3.311  loss_ce_3: 1.998  loss_mask_3: 0.6278  loss_dice_3: 3.259  loss_ce_4: 1.964  loss_mask_4: 0.6286  loss_dice_4: 3.252  loss_ce_5: 1.928  loss_mask_5: 0.6272  loss_dice_5: 3.253  loss_ce_6: 1.933  loss_mask_6: 0.6281  loss_dice_6: 3.241  loss_ce_7: 1.913  loss_mask_7: 0.6289  loss_dice_7: 3.246  loss_ce_8: 1.91  loss_mask_8: 0.6291  loss_dice_8: 3.242  time: 1.6936  data_time: 0.3485  lr: 5.2964e-06  max_mem: 17674M
[01/19 11:09:32] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/19 11:09:33] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 11:09:46] d2.data.build INFO: Using training sampler TrainingSampler
[01/19 11:09:46] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/19 11:09:46] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/19 11:09:46] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/19 11:09:46] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/19 11:09:47] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/19 11:09:47] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/19 11:09:47] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/19 11:09:47] d2.engine.train_loop INFO: Starting training from iteration 0
[01/19 11:10:03] d2.utils.events INFO:  eta: 9:15:48  iter: 20279  total_loss: 59.3  loss_ce: 1.846  loss_mask: 0.623  loss_dice: 3.22  loss_ce_0: 3.26  loss_mask_0: 0.6418  loss_dice_0: 3.513  loss_ce_1: 2.075  loss_mask_1: 0.6343  loss_dice_1: 3.348  loss_ce_2: 1.964  loss_mask_2: 0.6282  loss_dice_2: 3.286  loss_ce_3: 1.932  loss_mask_3: 0.6246  loss_dice_3: 3.24  loss_ce_4: 1.897  loss_mask_4: 0.6273  loss_dice_4: 3.234  loss_ce_5: 1.859  loss_mask_5: 0.626  loss_dice_5: 3.234  loss_ce_6: 1.881  loss_mask_6: 0.6214  loss_dice_6: 3.227  loss_ce_7: 1.868  loss_mask_7: 0.6255  loss_dice_7: 3.226  loss_ce_8: 1.838  loss_mask_8: 0.6245  loss_dice_8: 3.224  time: 1.6936  data_time: 0.3366  lr: 5.2915e-06  max_mem: 17674M
[01/19 11:10:37] d2.utils.events INFO:  eta: 9:15:23  iter: 20299  total_loss: 59.31  loss_ce: 1.791  loss_mask: 0.6239  loss_dice: 3.189  loss_ce_0: 3.27  loss_mask_0: 0.6421  loss_dice_0: 3.484  loss_ce_1: 2.087  loss_mask_1: 0.6253  loss_dice_1: 3.336  loss_ce_2: 1.952  loss_mask_2: 0.6241  loss_dice_2: 3.248  loss_ce_3: 1.89  loss_mask_3: 0.6192  loss_dice_3: 3.207  loss_ce_4: 1.836  loss_mask_4: 0.6158  loss_dice_4: 3.206  loss_ce_5: 1.806  loss_mask_5: 0.6179  loss_dice_5: 3.207  loss_ce_6: 1.818  loss_mask_6: 0.6171  loss_dice_6: 3.192  loss_ce_7: 1.789  loss_mask_7: 0.6184  loss_dice_7: 3.188  loss_ce_8: 1.788  loss_mask_8: 0.6184  loss_dice_8: 3.195  time: 1.6936  data_time: 0.3491  lr: 5.2867e-06  max_mem: 17674M
[01/19 11:11:12] d2.utils.events INFO:  eta: 9:15:03  iter: 20319  total_loss: 58.83  loss_ce: 1.75  loss_mask: 0.6196  loss_dice: 3.253  loss_ce_0: 3.289  loss_mask_0: 0.6347  loss_dice_0: 3.526  loss_ce_1: 2.035  loss_mask_1: 0.624  loss_dice_1: 3.376  loss_ce_2: 1.896  loss_mask_2: 0.6214  loss_dice_2: 3.31  loss_ce_3: 1.854  loss_mask_3: 0.6175  loss_dice_3: 3.264  loss_ce_4: 1.802  loss_mask_4: 0.6165  loss_dice_4: 3.26  loss_ce_5: 1.787  loss_mask_5: 0.622  loss_dice_5: 3.262  loss_ce_6: 1.764  loss_mask_6: 0.6172  loss_dice_6: 3.246  loss_ce_7: 1.768  loss_mask_7: 0.6186  loss_dice_7: 3.251  loss_ce_8: 1.758  loss_mask_8: 0.6187  loss_dice_8: 3.25  time: 1.6936  data_time: 0.3456  lr: 5.2819e-06  max_mem: 17674M
[01/19 11:11:46] d2.utils.events INFO:  eta: 9:14:23  iter: 20339  total_loss: 60.56  loss_ce: 1.97  loss_mask: 0.6279  loss_dice: 3.217  loss_ce_0: 3.279  loss_mask_0: 0.6537  loss_dice_0: 3.506  loss_ce_1: 2.199  loss_mask_1: 0.6301  loss_dice_1: 3.354  loss_ce_2: 2.112  loss_mask_2: 0.6234  loss_dice_2: 3.29  loss_ce_3: 2.05  loss_mask_3: 0.6203  loss_dice_3: 3.247  loss_ce_4: 2.016  loss_mask_4: 0.6224  loss_dice_4: 3.241  loss_ce_5: 2  loss_mask_5: 0.6255  loss_dice_5: 3.235  loss_ce_6: 1.989  loss_mask_6: 0.6284  loss_dice_6: 3.221  loss_ce_7: 1.984  loss_mask_7: 0.6273  loss_dice_7: 3.217  loss_ce_8: 1.965  loss_mask_8: 0.6301  loss_dice_8: 3.22  time: 1.6936  data_time: 0.3349  lr: 5.277e-06  max_mem: 17674M
[01/19 11:12:20] d2.utils.events INFO:  eta: 9:13:35  iter: 20359  total_loss: 59.38  loss_ce: 1.877  loss_mask: 0.6175  loss_dice: 3.203  loss_ce_0: 3.282  loss_mask_0: 0.6381  loss_dice_0: 3.489  loss_ce_1: 2.184  loss_mask_1: 0.6306  loss_dice_1: 3.335  loss_ce_2: 2.019  loss_mask_2: 0.6224  loss_dice_2: 3.277  loss_ce_3: 1.982  loss_mask_3: 0.6175  loss_dice_3: 3.22  loss_ce_4: 1.923  loss_mask_4: 0.6206  loss_dice_4: 3.221  loss_ce_5: 1.891  loss_mask_5: 0.6182  loss_dice_5: 3.221  loss_ce_6: 1.894  loss_mask_6: 0.6166  loss_dice_6: 3.209  loss_ce_7: 1.866  loss_mask_7: 0.6172  loss_dice_7: 3.201  loss_ce_8: 1.869  loss_mask_8: 0.6163  loss_dice_8: 3.205  time: 1.6936  data_time: 0.3442  lr: 5.2722e-06  max_mem: 17674M
[01/19 11:12:54] d2.utils.events INFO:  eta: 9:12:52  iter: 20379  total_loss: 58.85  loss_ce: 1.773  loss_mask: 0.6136  loss_dice: 3.239  loss_ce_0: 3.199  loss_mask_0: 0.6301  loss_dice_0: 3.515  loss_ce_1: 2.088  loss_mask_1: 0.6188  loss_dice_1: 3.378  loss_ce_2: 1.936  loss_mask_2: 0.6237  loss_dice_2: 3.316  loss_ce_3: 1.887  loss_mask_3: 0.6168  loss_dice_3: 3.269  loss_ce_4: 1.843  loss_mask_4: 0.6179  loss_dice_4: 3.26  loss_ce_5: 1.823  loss_mask_5: 0.6166  loss_dice_5: 3.258  loss_ce_6: 1.801  loss_mask_6: 0.616  loss_dice_6: 3.248  loss_ce_7: 1.808  loss_mask_7: 0.6146  loss_dice_7: 3.246  loss_ce_8: 1.782  loss_mask_8: 0.617  loss_dice_8: 3.242  time: 1.6936  data_time: 0.3422  lr: 5.2674e-06  max_mem: 17674M
[01/19 11:13:28] d2.utils.events INFO:  eta: 9:12:23  iter: 20399  total_loss: 60.07  loss_ce: 1.858  loss_mask: 0.6273  loss_dice: 3.235  loss_ce_0: 3.288  loss_mask_0: 0.6484  loss_dice_0: 3.519  loss_ce_1: 2.157  loss_mask_1: 0.6389  loss_dice_1: 3.383  loss_ce_2: 2.015  loss_mask_2: 0.6293  loss_dice_2: 3.309  loss_ce_3: 1.959  loss_mask_3: 0.628  loss_dice_3: 3.267  loss_ce_4: 1.914  loss_mask_4: 0.6307  loss_dice_4: 3.259  loss_ce_5: 1.886  loss_mask_5: 0.6281  loss_dice_5: 3.263  loss_ce_6: 1.873  loss_mask_6: 0.6283  loss_dice_6: 3.239  loss_ce_7: 1.869  loss_mask_7: 0.6298  loss_dice_7: 3.244  loss_ce_8: 1.862  loss_mask_8: 0.6292  loss_dice_8: 3.244  time: 1.6936  data_time: 0.3447  lr: 5.2626e-06  max_mem: 17674M
[01/19 11:14:02] d2.utils.events INFO:  eta: 9:11:44  iter: 20419  total_loss: 59.33  loss_ce: 1.729  loss_mask: 0.6175  loss_dice: 3.21  loss_ce_0: 3.183  loss_mask_0: 0.6437  loss_dice_0: 3.506  loss_ce_1: 2.037  loss_mask_1: 0.6199  loss_dice_1: 3.341  loss_ce_2: 1.904  loss_mask_2: 0.6211  loss_dice_2: 3.277  loss_ce_3: 1.833  loss_mask_3: 0.6222  loss_dice_3: 3.23  loss_ce_4: 1.794  loss_mask_4: 0.6231  loss_dice_4: 3.221  loss_ce_5: 1.765  loss_mask_5: 0.6194  loss_dice_5: 3.225  loss_ce_6: 1.755  loss_mask_6: 0.6193  loss_dice_6: 3.212  loss_ce_7: 1.753  loss_mask_7: 0.6188  loss_dice_7: 3.211  loss_ce_8: 1.747  loss_mask_8: 0.6194  loss_dice_8: 3.208  time: 1.6937  data_time: 0.3430  lr: 5.2577e-06  max_mem: 17674M
[01/19 11:14:37] d2.utils.events INFO:  eta: 9:11:18  iter: 20439  total_loss: 59.74  loss_ce: 1.879  loss_mask: 0.6129  loss_dice: 3.26  loss_ce_0: 3.334  loss_mask_0: 0.6354  loss_dice_0: 3.53  loss_ce_1: 2.109  loss_mask_1: 0.6209  loss_dice_1: 3.399  loss_ce_2: 2.042  loss_mask_2: 0.6158  loss_dice_2: 3.328  loss_ce_3: 1.975  loss_mask_3: 0.6123  loss_dice_3: 3.284  loss_ce_4: 1.93  loss_mask_4: 0.6139  loss_dice_4: 3.281  loss_ce_5: 1.907  loss_mask_5: 0.6141  loss_dice_5: 3.281  loss_ce_6: 1.903  loss_mask_6: 0.6155  loss_dice_6: 3.262  loss_ce_7: 1.888  loss_mask_7: 0.613  loss_dice_7: 3.262  loss_ce_8: 1.891  loss_mask_8: 0.6155  loss_dice_8: 3.264  time: 1.6937  data_time: 0.3568  lr: 5.2529e-06  max_mem: 17674M
[01/19 11:15:11] d2.utils.events INFO:  eta: 9:10:58  iter: 20459  total_loss: 59.97  loss_ce: 1.854  loss_mask: 0.607  loss_dice: 3.244  loss_ce_0: 3.276  loss_mask_0: 0.6265  loss_dice_0: 3.528  loss_ce_1: 2.132  loss_mask_1: 0.6168  loss_dice_1: 3.376  loss_ce_2: 2.003  loss_mask_2: 0.6112  loss_dice_2: 3.308  loss_ce_3: 1.935  loss_mask_3: 0.6086  loss_dice_3: 3.269  loss_ce_4: 1.884  loss_mask_4: 0.6085  loss_dice_4: 3.265  loss_ce_5: 1.864  loss_mask_5: 0.6091  loss_dice_5: 3.262  loss_ce_6: 1.878  loss_mask_6: 0.6082  loss_dice_6: 3.251  loss_ce_7: 1.872  loss_mask_7: 0.6089  loss_dice_7: 3.252  loss_ce_8: 1.86  loss_mask_8: 0.6082  loss_dice_8: 3.248  time: 1.6937  data_time: 0.3416  lr: 5.2481e-06  max_mem: 17674M
[01/19 11:15:45] d2.utils.events INFO:  eta: 9:10:19  iter: 20479  total_loss: 59.96  loss_ce: 1.894  loss_mask: 0.6374  loss_dice: 3.201  loss_ce_0: 3.255  loss_mask_0: 0.6589  loss_dice_0: 3.491  loss_ce_1: 2.172  loss_mask_1: 0.6448  loss_dice_1: 3.337  loss_ce_2: 2.041  loss_mask_2: 0.6383  loss_dice_2: 3.267  loss_ce_3: 1.981  loss_mask_3: 0.6356  loss_dice_3: 3.22  loss_ce_4: 1.926  loss_mask_4: 0.6371  loss_dice_4: 3.226  loss_ce_5: 1.915  loss_mask_5: 0.6375  loss_dice_5: 3.221  loss_ce_6: 1.91  loss_mask_6: 0.6358  loss_dice_6: 3.211  loss_ce_7: 1.893  loss_mask_7: 0.6355  loss_dice_7: 3.206  loss_ce_8: 1.887  loss_mask_8: 0.6359  loss_dice_8: 3.209  time: 1.6937  data_time: 0.3312  lr: 5.2432e-06  max_mem: 17674M
[01/19 11:16:19] d2.utils.events INFO:  eta: 9:09:39  iter: 20499  total_loss: 58.89  loss_ce: 1.795  loss_mask: 0.6229  loss_dice: 3.224  loss_ce_0: 3.262  loss_mask_0: 0.6342  loss_dice_0: 3.489  loss_ce_1: 2.101  loss_mask_1: 0.626  loss_dice_1: 3.339  loss_ce_2: 1.963  loss_mask_2: 0.6212  loss_dice_2: 3.278  loss_ce_3: 1.928  loss_mask_3: 0.6182  loss_dice_3: 3.241  loss_ce_4: 1.85  loss_mask_4: 0.62  loss_dice_4: 3.236  loss_ce_5: 1.825  loss_mask_5: 0.6252  loss_dice_5: 3.231  loss_ce_6: 1.817  loss_mask_6: 0.624  loss_dice_6: 3.223  loss_ce_7: 1.806  loss_mask_7: 0.6236  loss_dice_7: 3.223  loss_ce_8: 1.802  loss_mask_8: 0.6226  loss_dice_8: 3.219  time: 1.6937  data_time: 0.3611  lr: 5.2384e-06  max_mem: 17674M
[01/19 11:16:53] d2.utils.events INFO:  eta: 9:09:40  iter: 20519  total_loss: 59.51  loss_ce: 1.839  loss_mask: 0.6238  loss_dice: 3.171  loss_ce_0: 3.264  loss_mask_0: 0.6456  loss_dice_0: 3.471  loss_ce_1: 2.137  loss_mask_1: 0.6293  loss_dice_1: 3.3  loss_ce_2: 1.991  loss_mask_2: 0.6253  loss_dice_2: 3.234  loss_ce_3: 1.959  loss_mask_3: 0.6225  loss_dice_3: 3.188  loss_ce_4: 1.92  loss_mask_4: 0.6227  loss_dice_4: 3.191  loss_ce_5: 1.873  loss_mask_5: 0.6236  loss_dice_5: 3.185  loss_ce_6: 1.854  loss_mask_6: 0.6242  loss_dice_6: 3.172  loss_ce_7: 1.843  loss_mask_7: 0.6236  loss_dice_7: 3.173  loss_ce_8: 1.829  loss_mask_8: 0.6267  loss_dice_8: 3.176  time: 1.6937  data_time: 0.3517  lr: 5.2335e-06  max_mem: 17674M
[01/19 11:17:27] d2.utils.events INFO:  eta: 9:09:07  iter: 20539  total_loss: 58.97  loss_ce: 1.836  loss_mask: 0.6191  loss_dice: 3.2  loss_ce_0: 3.268  loss_mask_0: 0.6325  loss_dice_0: 3.494  loss_ce_1: 2.05  loss_mask_1: 0.6202  loss_dice_1: 3.35  loss_ce_2: 1.988  loss_mask_2: 0.6223  loss_dice_2: 3.276  loss_ce_3: 1.921  loss_mask_3: 0.6166  loss_dice_3: 3.232  loss_ce_4: 1.843  loss_mask_4: 0.6192  loss_dice_4: 3.227  loss_ce_5: 1.854  loss_mask_5: 0.6201  loss_dice_5: 3.217  loss_ce_6: 1.848  loss_mask_6: 0.6195  loss_dice_6: 3.203  loss_ce_7: 1.844  loss_mask_7: 0.6198  loss_dice_7: 3.199  loss_ce_8: 1.819  loss_mask_8: 0.6222  loss_dice_8: 3.204  time: 1.6937  data_time: 0.3500  lr: 5.2287e-06  max_mem: 17674M
[01/19 11:18:02] d2.utils.events INFO:  eta: 9:09:02  iter: 20559  total_loss: 59.26  loss_ce: 1.823  loss_mask: 0.6319  loss_dice: 3.257  loss_ce_0: 3.269  loss_mask_0: 0.6527  loss_dice_0: 3.519  loss_ce_1: 2.126  loss_mask_1: 0.642  loss_dice_1: 3.386  loss_ce_2: 2.006  loss_mask_2: 0.6326  loss_dice_2: 3.325  loss_ce_3: 1.924  loss_mask_3: 0.6278  loss_dice_3: 3.285  loss_ce_4: 1.881  loss_mask_4: 0.6291  loss_dice_4: 3.275  loss_ce_5: 1.858  loss_mask_5: 0.6316  loss_dice_5: 3.276  loss_ce_6: 1.844  loss_mask_6: 0.6293  loss_dice_6: 3.263  loss_ce_7: 1.84  loss_mask_7: 0.6285  loss_dice_7: 3.26  loss_ce_8: 1.824  loss_mask_8: 0.631  loss_dice_8: 3.264  time: 1.6938  data_time: 0.3609  lr: 5.2239e-06  max_mem: 17674M
[01/19 11:18:36] d2.utils.events INFO:  eta: 9:08:35  iter: 20579  total_loss: 59.15  loss_ce: 1.793  loss_mask: 0.6165  loss_dice: 3.232  loss_ce_0: 3.224  loss_mask_0: 0.6301  loss_dice_0: 3.503  loss_ce_1: 2.067  loss_mask_1: 0.624  loss_dice_1: 3.365  loss_ce_2: 1.973  loss_mask_2: 0.6182  loss_dice_2: 3.297  loss_ce_3: 1.898  loss_mask_3: 0.6169  loss_dice_3: 3.243  loss_ce_4: 1.852  loss_mask_4: 0.6168  loss_dice_4: 3.244  loss_ce_5: 1.825  loss_mask_5: 0.6174  loss_dice_5: 3.239  loss_ce_6: 1.816  loss_mask_6: 0.616  loss_dice_6: 3.23  loss_ce_7: 1.816  loss_mask_7: 0.6155  loss_dice_7: 3.231  loss_ce_8: 1.802  loss_mask_8: 0.6185  loss_dice_8: 3.229  time: 1.6938  data_time: 0.3413  lr: 5.219e-06  max_mem: 17674M
[01/19 11:19:10] d2.utils.events INFO:  eta: 9:08:14  iter: 20599  total_loss: 59.02  loss_ce: 1.771  loss_mask: 0.6317  loss_dice: 3.259  loss_ce_0: 3.219  loss_mask_0: 0.649  loss_dice_0: 3.529  loss_ce_1: 2.072  loss_mask_1: 0.6329  loss_dice_1: 3.393  loss_ce_2: 1.926  loss_mask_2: 0.6282  loss_dice_2: 3.318  loss_ce_3: 1.856  loss_mask_3: 0.6299  loss_dice_3: 3.275  loss_ce_4: 1.821  loss_mask_4: 0.6324  loss_dice_4: 3.273  loss_ce_5: 1.788  loss_mask_5: 0.6318  loss_dice_5: 3.269  loss_ce_6: 1.794  loss_mask_6: 0.6313  loss_dice_6: 3.259  loss_ce_7: 1.788  loss_mask_7: 0.6319  loss_dice_7: 3.254  loss_ce_8: 1.776  loss_mask_8: 0.6313  loss_dice_8: 3.257  time: 1.6938  data_time: 0.3484  lr: 5.2142e-06  max_mem: 17674M
[01/19 11:19:44] d2.utils.events INFO:  eta: 9:07:28  iter: 20619  total_loss: 58.47  loss_ce: 1.767  loss_mask: 0.6223  loss_dice: 3.159  loss_ce_0: 3.166  loss_mask_0: 0.643  loss_dice_0: 3.462  loss_ce_1: 2.083  loss_mask_1: 0.6302  loss_dice_1: 3.287  loss_ce_2: 1.959  loss_mask_2: 0.625  loss_dice_2: 3.218  loss_ce_3: 1.891  loss_mask_3: 0.6211  loss_dice_3: 3.181  loss_ce_4: 1.834  loss_mask_4: 0.6221  loss_dice_4: 3.177  loss_ce_5: 1.795  loss_mask_5: 0.622  loss_dice_5: 3.176  loss_ce_6: 1.789  loss_mask_6: 0.6209  loss_dice_6: 3.161  loss_ce_7: 1.78  loss_mask_7: 0.6208  loss_dice_7: 3.166  loss_ce_8: 1.764  loss_mask_8: 0.6219  loss_dice_8: 3.163  time: 1.6938  data_time: 0.3523  lr: 5.2094e-06  max_mem: 17674M
[01/19 11:20:18] d2.utils.events INFO:  eta: 9:07:24  iter: 20639  total_loss: 59.51  loss_ce: 1.833  loss_mask: 0.6141  loss_dice: 3.207  loss_ce_0: 3.351  loss_mask_0: 0.6485  loss_dice_0: 3.496  loss_ce_1: 2.093  loss_mask_1: 0.6239  loss_dice_1: 3.34  loss_ce_2: 1.973  loss_mask_2: 0.6187  loss_dice_2: 3.272  loss_ce_3: 1.93  loss_mask_3: 0.6093  loss_dice_3: 3.231  loss_ce_4: 1.897  loss_mask_4: 0.6173  loss_dice_4: 3.225  loss_ce_5: 1.869  loss_mask_5: 0.6172  loss_dice_5: 3.224  loss_ce_6: 1.846  loss_mask_6: 0.6164  loss_dice_6: 3.212  loss_ce_7: 1.847  loss_mask_7: 0.6164  loss_dice_7: 3.209  loss_ce_8: 1.828  loss_mask_8: 0.6144  loss_dice_8: 3.209  time: 1.6938  data_time: 0.3498  lr: 5.2045e-06  max_mem: 17674M
[01/19 11:20:52] d2.utils.events INFO:  eta: 9:07:04  iter: 20659  total_loss: 59.92  loss_ce: 1.798  loss_mask: 0.6195  loss_dice: 3.247  loss_ce_0: 3.223  loss_mask_0: 0.6313  loss_dice_0: 3.553  loss_ce_1: 2.06  loss_mask_1: 0.6145  loss_dice_1: 3.389  loss_ce_2: 1.94  loss_mask_2: 0.6158  loss_dice_2: 3.326  loss_ce_3: 1.897  loss_mask_3: 0.6155  loss_dice_3: 3.269  loss_ce_4: 1.852  loss_mask_4: 0.6211  loss_dice_4: 3.266  loss_ce_5: 1.825  loss_mask_5: 0.6209  loss_dice_5: 3.262  loss_ce_6: 1.825  loss_mask_6: 0.6196  loss_dice_6: 3.251  loss_ce_7: 1.805  loss_mask_7: 0.6179  loss_dice_7: 3.241  loss_ce_8: 1.817  loss_mask_8: 0.6205  loss_dice_8: 3.246  time: 1.6938  data_time: 0.3515  lr: 5.1997e-06  max_mem: 17674M
[01/19 11:21:26] d2.utils.events INFO:  eta: 9:06:41  iter: 20679  total_loss: 59.22  loss_ce: 1.799  loss_mask: 0.6267  loss_dice: 3.228  loss_ce_0: 3.27  loss_mask_0: 0.6438  loss_dice_0: 3.51  loss_ce_1: 2.138  loss_mask_1: 0.6294  loss_dice_1: 3.36  loss_ce_2: 1.984  loss_mask_2: 0.6252  loss_dice_2: 3.293  loss_ce_3: 1.934  loss_mask_3: 0.6217  loss_dice_3: 3.263  loss_ce_4: 1.895  loss_mask_4: 0.6224  loss_dice_4: 3.257  loss_ce_5: 1.852  loss_mask_5: 0.6263  loss_dice_5: 3.246  loss_ce_6: 1.856  loss_mask_6: 0.6243  loss_dice_6: 3.243  loss_ce_7: 1.833  loss_mask_7: 0.6257  loss_dice_7: 3.233  loss_ce_8: 1.831  loss_mask_8: 0.6255  loss_dice_8: 3.236  time: 1.6938  data_time: 0.3451  lr: 5.1948e-06  max_mem: 17674M
[01/19 11:22:00] d2.utils.events INFO:  eta: 9:05:56  iter: 20699  total_loss: 59.27  loss_ce: 1.82  loss_mask: 0.6239  loss_dice: 3.201  loss_ce_0: 3.268  loss_mask_0: 0.6466  loss_dice_0: 3.503  loss_ce_1: 2.108  loss_mask_1: 0.6293  loss_dice_1: 3.35  loss_ce_2: 1.981  loss_mask_2: 0.6275  loss_dice_2: 3.268  loss_ce_3: 1.932  loss_mask_3: 0.6261  loss_dice_3: 3.221  loss_ce_4: 1.886  loss_mask_4: 0.626  loss_dice_4: 3.217  loss_ce_5: 1.84  loss_mask_5: 0.6257  loss_dice_5: 3.226  loss_ce_6: 1.843  loss_mask_6: 0.6229  loss_dice_6: 3.202  loss_ce_7: 1.833  loss_mask_7: 0.6243  loss_dice_7: 3.205  loss_ce_8: 1.815  loss_mask_8: 0.6258  loss_dice_8: 3.203  time: 1.6938  data_time: 0.3607  lr: 5.19e-06  max_mem: 17674M
[01/19 11:22:34] d2.utils.events INFO:  eta: 9:05:33  iter: 20719  total_loss: 59.1  loss_ce: 1.828  loss_mask: 0.6237  loss_dice: 3.23  loss_ce_0: 3.178  loss_mask_0: 0.6403  loss_dice_0: 3.518  loss_ce_1: 2.067  loss_mask_1: 0.6297  loss_dice_1: 3.371  loss_ce_2: 1.925  loss_mask_2: 0.6258  loss_dice_2: 3.299  loss_ce_3: 1.901  loss_mask_3: 0.6217  loss_dice_3: 3.252  loss_ce_4: 1.856  loss_mask_4: 0.6215  loss_dice_4: 3.245  loss_ce_5: 1.83  loss_mask_5: 0.6237  loss_dice_5: 3.244  loss_ce_6: 1.832  loss_mask_6: 0.6231  loss_dice_6: 3.233  loss_ce_7: 1.816  loss_mask_7: 0.6229  loss_dice_7: 3.236  loss_ce_8: 1.804  loss_mask_8: 0.6252  loss_dice_8: 3.23  time: 1.6938  data_time: 0.3464  lr: 5.1852e-06  max_mem: 17674M
[01/19 11:23:08] d2.utils.events INFO:  eta: 9:05:05  iter: 20739  total_loss: 59.91  loss_ce: 1.862  loss_mask: 0.6224  loss_dice: 3.248  loss_ce_0: 3.269  loss_mask_0: 0.6454  loss_dice_0: 3.529  loss_ce_1: 2.132  loss_mask_1: 0.6278  loss_dice_1: 3.379  loss_ce_2: 1.97  loss_mask_2: 0.6239  loss_dice_2: 3.309  loss_ce_3: 1.941  loss_mask_3: 0.62  loss_dice_3: 3.264  loss_ce_4: 1.888  loss_mask_4: 0.6237  loss_dice_4: 3.26  loss_ce_5: 1.876  loss_mask_5: 0.622  loss_dice_5: 3.26  loss_ce_6: 1.872  loss_mask_6: 0.6236  loss_dice_6: 3.243  loss_ce_7: 1.868  loss_mask_7: 0.6227  loss_dice_7: 3.241  loss_ce_8: 1.847  loss_mask_8: 0.6252  loss_dice_8: 3.24  time: 1.6938  data_time: 0.3488  lr: 5.1803e-06  max_mem: 17674M
[01/19 11:23:43] d2.utils.events INFO:  eta: 9:04:29  iter: 20759  total_loss: 58.7  loss_ce: 1.759  loss_mask: 0.6116  loss_dice: 3.198  loss_ce_0: 3.259  loss_mask_0: 0.633  loss_dice_0: 3.492  loss_ce_1: 2.1  loss_mask_1: 0.6151  loss_dice_1: 3.326  loss_ce_2: 1.968  loss_mask_2: 0.6099  loss_dice_2: 3.267  loss_ce_3: 1.892  loss_mask_3: 0.6082  loss_dice_3: 3.215  loss_ce_4: 1.837  loss_mask_4: 0.6105  loss_dice_4: 3.217  loss_ce_5: 1.806  loss_mask_5: 0.6091  loss_dice_5: 3.217  loss_ce_6: 1.818  loss_mask_6: 0.6144  loss_dice_6: 3.203  loss_ce_7: 1.79  loss_mask_7: 0.6127  loss_dice_7: 3.202  loss_ce_8: 1.753  loss_mask_8: 0.6135  loss_dice_8: 3.2  time: 1.6938  data_time: 0.3561  lr: 5.1755e-06  max_mem: 17674M
[01/19 11:24:17] d2.utils.events INFO:  eta: 9:03:40  iter: 20779  total_loss: 59.11  loss_ce: 1.816  loss_mask: 0.626  loss_dice: 3.231  loss_ce_0: 3.226  loss_mask_0: 0.6509  loss_dice_0: 3.514  loss_ce_1: 2.132  loss_mask_1: 0.632  loss_dice_1: 3.363  loss_ce_2: 1.978  loss_mask_2: 0.6262  loss_dice_2: 3.294  loss_ce_3: 1.939  loss_mask_3: 0.624  loss_dice_3: 3.252  loss_ce_4: 1.878  loss_mask_4: 0.6216  loss_dice_4: 3.251  loss_ce_5: 1.867  loss_mask_5: 0.6231  loss_dice_5: 3.252  loss_ce_6: 1.843  loss_mask_6: 0.6277  loss_dice_6: 3.233  loss_ce_7: 1.833  loss_mask_7: 0.6258  loss_dice_7: 3.234  loss_ce_8: 1.821  loss_mask_8: 0.6227  loss_dice_8: 3.24  time: 1.6938  data_time: 0.3473  lr: 5.1706e-06  max_mem: 17674M
[01/19 11:24:51] d2.utils.events INFO:  eta: 9:03:18  iter: 20799  total_loss: 58.44  loss_ce: 1.753  loss_mask: 0.6155  loss_dice: 3.185  loss_ce_0: 3.271  loss_mask_0: 0.6383  loss_dice_0: 3.485  loss_ce_1: 2.064  loss_mask_1: 0.6222  loss_dice_1: 3.322  loss_ce_2: 1.959  loss_mask_2: 0.6154  loss_dice_2: 3.263  loss_ce_3: 1.871  loss_mask_3: 0.6141  loss_dice_3: 3.212  loss_ce_4: 1.815  loss_mask_4: 0.6141  loss_dice_4: 3.208  loss_ce_5: 1.81  loss_mask_5: 0.6179  loss_dice_5: 3.209  loss_ce_6: 1.781  loss_mask_6: 0.6136  loss_dice_6: 3.19  loss_ce_7: 1.77  loss_mask_7: 0.6159  loss_dice_7: 3.194  loss_ce_8: 1.756  loss_mask_8: 0.6169  loss_dice_8: 3.192  time: 1.6939  data_time: 0.3663  lr: 5.1658e-06  max_mem: 17674M
[01/19 11:25:25] d2.utils.events INFO:  eta: 9:02:29  iter: 20819  total_loss: 57.95  loss_ce: 1.772  loss_mask: 0.6396  loss_dice: 3.123  loss_ce_0: 3.207  loss_mask_0: 0.6585  loss_dice_0: 3.437  loss_ce_1: 2.093  loss_mask_1: 0.649  loss_dice_1: 3.248  loss_ce_2: 1.95  loss_mask_2: 0.6389  loss_dice_2: 3.191  loss_ce_3: 1.885  loss_mask_3: 0.6339  loss_dice_3: 3.142  loss_ce_4: 1.842  loss_mask_4: 0.6359  loss_dice_4: 3.137  loss_ce_5: 1.789  loss_mask_5: 0.6373  loss_dice_5: 3.141  loss_ce_6: 1.782  loss_mask_6: 0.6372  loss_dice_6: 3.129  loss_ce_7: 1.774  loss_mask_7: 0.6381  loss_dice_7: 3.129  loss_ce_8: 1.752  loss_mask_8: 0.6396  loss_dice_8: 3.131  time: 1.6939  data_time: 0.3285  lr: 5.161e-06  max_mem: 17674M
[01/19 11:25:59] d2.utils.events INFO:  eta: 9:01:58  iter: 20839  total_loss: 58.4  loss_ce: 1.78  loss_mask: 0.6163  loss_dice: 3.187  loss_ce_0: 3.213  loss_mask_0: 0.6456  loss_dice_0: 3.491  loss_ce_1: 2.113  loss_mask_1: 0.6225  loss_dice_1: 3.328  loss_ce_2: 1.951  loss_mask_2: 0.6232  loss_dice_2: 3.246  loss_ce_3: 1.892  loss_mask_3: 0.6196  loss_dice_3: 3.206  loss_ce_4: 1.83  loss_mask_4: 0.624  loss_dice_4: 3.2  loss_ce_5: 1.816  loss_mask_5: 0.6207  loss_dice_5: 3.2  loss_ce_6: 1.802  loss_mask_6: 0.6202  loss_dice_6: 3.185  loss_ce_7: 1.789  loss_mask_7: 0.6198  loss_dice_7: 3.189  loss_ce_8: 1.773  loss_mask_8: 0.6201  loss_dice_8: 3.183  time: 1.6939  data_time: 0.3418  lr: 5.1561e-06  max_mem: 17674M
[01/19 11:26:33] d2.utils.events INFO:  eta: 9:01:39  iter: 20859  total_loss: 60.27  loss_ce: 1.882  loss_mask: 0.6252  loss_dice: 3.207  loss_ce_0: 3.264  loss_mask_0: 0.6483  loss_dice_0: 3.512  loss_ce_1: 2.223  loss_mask_1: 0.63  loss_dice_1: 3.354  loss_ce_2: 2.053  loss_mask_2: 0.6268  loss_dice_2: 3.275  loss_ce_3: 1.974  loss_mask_3: 0.625  loss_dice_3: 3.226  loss_ce_4: 1.921  loss_mask_4: 0.6246  loss_dice_4: 3.225  loss_ce_5: 1.901  loss_mask_5: 0.6258  loss_dice_5: 3.218  loss_ce_6: 1.901  loss_mask_6: 0.6267  loss_dice_6: 3.207  loss_ce_7: 1.885  loss_mask_7: 0.6252  loss_dice_7: 3.212  loss_ce_8: 1.884  loss_mask_8: 0.6252  loss_dice_8: 3.213  time: 1.6939  data_time: 0.3469  lr: 5.1513e-06  max_mem: 17674M
[01/19 11:27:06] d2.utils.events INFO:  eta: 9:01:05  iter: 20879  total_loss: 59.27  loss_ce: 1.849  loss_mask: 0.622  loss_dice: 3.199  loss_ce_0: 3.196  loss_mask_0: 0.6448  loss_dice_0: 3.497  loss_ce_1: 2.134  loss_mask_1: 0.6313  loss_dice_1: 3.333  loss_ce_2: 1.992  loss_mask_2: 0.6302  loss_dice_2: 3.263  loss_ce_3: 1.921  loss_mask_3: 0.623  loss_dice_3: 3.226  loss_ce_4: 1.892  loss_mask_4: 0.6253  loss_dice_4: 3.226  loss_ce_5: 1.866  loss_mask_5: 0.6254  loss_dice_5: 3.217  loss_ce_6: 1.848  loss_mask_6: 0.623  loss_dice_6: 3.202  loss_ce_7: 1.833  loss_mask_7: 0.6234  loss_dice_7: 3.203  loss_ce_8: 1.826  loss_mask_8: 0.6257  loss_dice_8: 3.204  time: 1.6939  data_time: 0.3373  lr: 5.1464e-06  max_mem: 17674M
[01/19 11:27:41] d2.utils.events INFO:  eta: 9:00:31  iter: 20899  total_loss: 59.78  loss_ce: 1.752  loss_mask: 0.619  loss_dice: 3.236  loss_ce_0: 3.296  loss_mask_0: 0.6361  loss_dice_0: 3.518  loss_ce_1: 2.051  loss_mask_1: 0.6237  loss_dice_1: 3.377  loss_ce_2: 1.922  loss_mask_2: 0.624  loss_dice_2: 3.311  loss_ce_3: 1.838  loss_mask_3: 0.6213  loss_dice_3: 3.256  loss_ce_4: 1.795  loss_mask_4: 0.6209  loss_dice_4: 3.251  loss_ce_5: 1.779  loss_mask_5: 0.6212  loss_dice_5: 3.261  loss_ce_6: 1.773  loss_mask_6: 0.6175  loss_dice_6: 3.242  loss_ce_7: 1.747  loss_mask_7: 0.6193  loss_dice_7: 3.241  loss_ce_8: 1.737  loss_mask_8: 0.6198  loss_dice_8: 3.242  time: 1.6939  data_time: 0.3578  lr: 5.1416e-06  max_mem: 17674M
[01/19 11:28:14] d2.utils.events INFO:  eta: 8:59:59  iter: 20919  total_loss: 59.92  loss_ce: 1.845  loss_mask: 0.6314  loss_dice: 3.259  loss_ce_0: 3.27  loss_mask_0: 0.6593  loss_dice_0: 3.542  loss_ce_1: 2.154  loss_mask_1: 0.6414  loss_dice_1: 3.391  loss_ce_2: 2.005  loss_mask_2: 0.6304  loss_dice_2: 3.322  loss_ce_3: 1.948  loss_mask_3: 0.6298  loss_dice_3: 3.278  loss_ce_4: 1.884  loss_mask_4: 0.6277  loss_dice_4: 3.275  loss_ce_5: 1.856  loss_mask_5: 0.6289  loss_dice_5: 3.284  loss_ce_6: 1.865  loss_mask_6: 0.6289  loss_dice_6: 3.264  loss_ce_7: 1.857  loss_mask_7: 0.6321  loss_dice_7: 3.26  loss_ce_8: 1.843  loss_mask_8: 0.6318  loss_dice_8: 3.264  time: 1.6939  data_time: 0.3342  lr: 5.1367e-06  max_mem: 17674M
[01/19 11:28:48] d2.utils.events INFO:  eta: 8:59:29  iter: 20939  total_loss: 59.28  loss_ce: 1.84  loss_mask: 0.6219  loss_dice: 3.235  loss_ce_0: 3.268  loss_mask_0: 0.6381  loss_dice_0: 3.499  loss_ce_1: 2.095  loss_mask_1: 0.6277  loss_dice_1: 3.359  loss_ce_2: 1.971  loss_mask_2: 0.6259  loss_dice_2: 3.291  loss_ce_3: 1.924  loss_mask_3: 0.6229  loss_dice_3: 3.259  loss_ce_4: 1.866  loss_mask_4: 0.6251  loss_dice_4: 3.255  loss_ce_5: 1.846  loss_mask_5: 0.6255  loss_dice_5: 3.253  loss_ce_6: 1.851  loss_mask_6: 0.6261  loss_dice_6: 3.239  loss_ce_7: 1.827  loss_mask_7: 0.6258  loss_dice_7: 3.234  loss_ce_8: 1.828  loss_mask_8: 0.6248  loss_dice_8: 3.23  time: 1.6939  data_time: 0.3363  lr: 5.1319e-06  max_mem: 17674M
[01/19 11:29:22] d2.utils.events INFO:  eta: 8:59:18  iter: 20959  total_loss: 58.96  loss_ce: 1.775  loss_mask: 0.6251  loss_dice: 3.211  loss_ce_0: 3.212  loss_mask_0: 0.648  loss_dice_0: 3.504  loss_ce_1: 2.05  loss_mask_1: 0.6282  loss_dice_1: 3.358  loss_ce_2: 1.892  loss_mask_2: 0.6243  loss_dice_2: 3.286  loss_ce_3: 1.86  loss_mask_3: 0.6241  loss_dice_3: 3.235  loss_ce_4: 1.793  loss_mask_4: 0.6288  loss_dice_4: 3.227  loss_ce_5: 1.792  loss_mask_5: 0.6264  loss_dice_5: 3.229  loss_ce_6: 1.794  loss_mask_6: 0.6259  loss_dice_6: 3.215  loss_ce_7: 1.778  loss_mask_7: 0.6287  loss_dice_7: 3.21  loss_ce_8: 1.768  loss_mask_8: 0.627  loss_dice_8: 3.211  time: 1.6939  data_time: 0.3388  lr: 5.127e-06  max_mem: 17674M
[01/19 11:29:56] d2.utils.events INFO:  eta: 8:58:54  iter: 20979  total_loss: 58.96  loss_ce: 1.798  loss_mask: 0.6177  loss_dice: 3.202  loss_ce_0: 3.245  loss_mask_0: 0.6338  loss_dice_0: 3.493  loss_ce_1: 2.065  loss_mask_1: 0.6234  loss_dice_1: 3.36  loss_ce_2: 1.964  loss_mask_2: 0.6221  loss_dice_2: 3.285  loss_ce_3: 1.912  loss_mask_3: 0.6195  loss_dice_3: 3.235  loss_ce_4: 1.864  loss_mask_4: 0.616  loss_dice_4: 3.228  loss_ce_5: 1.828  loss_mask_5: 0.6155  loss_dice_5: 3.227  loss_ce_6: 1.821  loss_mask_6: 0.6177  loss_dice_6: 3.214  loss_ce_7: 1.796  loss_mask_7: 0.6178  loss_dice_7: 3.207  loss_ce_8: 1.811  loss_mask_8: 0.6193  loss_dice_8: 3.209  time: 1.6939  data_time: 0.3528  lr: 5.1222e-06  max_mem: 17674M
[01/19 11:30:30] d2.utils.events INFO:  eta: 8:58:10  iter: 20999  total_loss: 58.33  loss_ce: 1.748  loss_mask: 0.6076  loss_dice: 3.238  loss_ce_0: 3.109  loss_mask_0: 0.6421  loss_dice_0: 3.517  loss_ce_1: 2.039  loss_mask_1: 0.6255  loss_dice_1: 3.365  loss_ce_2: 1.896  loss_mask_2: 0.6194  loss_dice_2: 3.312  loss_ce_3: 1.843  loss_mask_3: 0.6131  loss_dice_3: 3.267  loss_ce_4: 1.799  loss_mask_4: 0.6122  loss_dice_4: 3.265  loss_ce_5: 1.774  loss_mask_5: 0.6117  loss_dice_5: 3.26  loss_ce_6: 1.768  loss_mask_6: 0.61  loss_dice_6: 3.246  loss_ce_7: 1.734  loss_mask_7: 0.6099  loss_dice_7: 3.242  loss_ce_8: 1.729  loss_mask_8: 0.6109  loss_dice_8: 3.244  time: 1.6939  data_time: 0.3365  lr: 5.1173e-06  max_mem: 17674M
[01/19 11:31:04] d2.utils.events INFO:  eta: 8:57:36  iter: 21019  total_loss: 58.6  loss_ce: 1.753  loss_mask: 0.6128  loss_dice: 3.237  loss_ce_0: 3.161  loss_mask_0: 0.6455  loss_dice_0: 3.521  loss_ce_1: 2.031  loss_mask_1: 0.6265  loss_dice_1: 3.375  loss_ce_2: 1.897  loss_mask_2: 0.6128  loss_dice_2: 3.312  loss_ce_3: 1.832  loss_mask_3: 0.6112  loss_dice_3: 3.269  loss_ce_4: 1.805  loss_mask_4: 0.6108  loss_dice_4: 3.26  loss_ce_5: 1.772  loss_mask_5: 0.6122  loss_dice_5: 3.251  loss_ce_6: 1.775  loss_mask_6: 0.6127  loss_dice_6: 3.241  loss_ce_7: 1.76  loss_mask_7: 0.6137  loss_dice_7: 3.239  loss_ce_8: 1.743  loss_mask_8: 0.6143  loss_dice_8: 3.239  time: 1.6939  data_time: 0.3443  lr: 5.1125e-06  max_mem: 17674M
[01/19 11:31:38] d2.utils.events INFO:  eta: 8:57:02  iter: 21039  total_loss: 58.84  loss_ce: 1.81  loss_mask: 0.6142  loss_dice: 3.232  loss_ce_0: 3.237  loss_mask_0: 0.6421  loss_dice_0: 3.5  loss_ce_1: 2.055  loss_mask_1: 0.6302  loss_dice_1: 3.364  loss_ce_2: 1.956  loss_mask_2: 0.6218  loss_dice_2: 3.301  loss_ce_3: 1.9  loss_mask_3: 0.6186  loss_dice_3: 3.255  loss_ce_4: 1.855  loss_mask_4: 0.6196  loss_dice_4: 3.251  loss_ce_5: 1.843  loss_mask_5: 0.6189  loss_dice_5: 3.25  loss_ce_6: 1.829  loss_mask_6: 0.6184  loss_dice_6: 3.243  loss_ce_7: 1.81  loss_mask_7: 0.618  loss_dice_7: 3.235  loss_ce_8: 1.804  loss_mask_8: 0.615  loss_dice_8: 3.242  time: 1.6939  data_time: 0.3402  lr: 5.1076e-06  max_mem: 17674M
[01/19 11:32:12] d2.utils.events INFO:  eta: 8:56:28  iter: 21059  total_loss: 59.17  loss_ce: 1.83  loss_mask: 0.6226  loss_dice: 3.238  loss_ce_0: 3.221  loss_mask_0: 0.641  loss_dice_0: 3.528  loss_ce_1: 2.089  loss_mask_1: 0.6251  loss_dice_1: 3.376  loss_ce_2: 1.966  loss_mask_2: 0.6185  loss_dice_2: 3.308  loss_ce_3: 1.886  loss_mask_3: 0.6167  loss_dice_3: 3.263  loss_ce_4: 1.861  loss_mask_4: 0.6182  loss_dice_4: 3.263  loss_ce_5: 1.848  loss_mask_5: 0.6212  loss_dice_5: 3.26  loss_ce_6: 1.839  loss_mask_6: 0.6219  loss_dice_6: 3.243  loss_ce_7: 1.824  loss_mask_7: 0.6237  loss_dice_7: 3.241  loss_ce_8: 1.821  loss_mask_8: 0.6242  loss_dice_8: 3.24  time: 1.6939  data_time: 0.3408  lr: 5.1028e-06  max_mem: 17674M
[01/19 11:32:47] d2.utils.events INFO:  eta: 8:55:54  iter: 21079  total_loss: 59.43  loss_ce: 1.879  loss_mask: 0.6301  loss_dice: 3.189  loss_ce_0: 3.266  loss_mask_0: 0.6535  loss_dice_0: 3.49  loss_ce_1: 2.126  loss_mask_1: 0.6389  loss_dice_1: 3.321  loss_ce_2: 2.012  loss_mask_2: 0.6385  loss_dice_2: 3.269  loss_ce_3: 1.975  loss_mask_3: 0.6318  loss_dice_3: 3.227  loss_ce_4: 1.923  loss_mask_4: 0.6328  loss_dice_4: 3.215  loss_ce_5: 1.91  loss_mask_5: 0.6356  loss_dice_5: 3.211  loss_ce_6: 1.893  loss_mask_6: 0.6314  loss_dice_6: 3.195  loss_ce_7: 1.874  loss_mask_7: 0.6304  loss_dice_7: 3.197  loss_ce_8: 1.874  loss_mask_8: 0.6307  loss_dice_8: 3.189  time: 1.6939  data_time: 0.3505  lr: 5.098e-06  max_mem: 17674M
[01/19 11:33:21] d2.utils.events INFO:  eta: 8:55:22  iter: 21099  total_loss: 58.72  loss_ce: 1.76  loss_mask: 0.6097  loss_dice: 3.212  loss_ce_0: 3.222  loss_mask_0: 0.6363  loss_dice_0: 3.514  loss_ce_1: 2.032  loss_mask_1: 0.6204  loss_dice_1: 3.352  loss_ce_2: 1.901  loss_mask_2: 0.6151  loss_dice_2: 3.275  loss_ce_3: 1.844  loss_mask_3: 0.6121  loss_dice_3: 3.225  loss_ce_4: 1.815  loss_mask_4: 0.6171  loss_dice_4: 3.22  loss_ce_5: 1.79  loss_mask_5: 0.6142  loss_dice_5: 3.225  loss_ce_6: 1.776  loss_mask_6: 0.6072  loss_dice_6: 3.213  loss_ce_7: 1.772  loss_mask_7: 0.6099  loss_dice_7: 3.208  loss_ce_8: 1.755  loss_mask_8: 0.6102  loss_dice_8: 3.21  time: 1.6939  data_time: 0.3528  lr: 5.0931e-06  max_mem: 17674M
[01/19 11:33:56] d2.utils.events INFO:  eta: 8:54:52  iter: 21119  total_loss: 58.3  loss_ce: 1.753  loss_mask: 0.616  loss_dice: 3.212  loss_ce_0: 3.113  loss_mask_0: 0.6375  loss_dice_0: 3.507  loss_ce_1: 2.032  loss_mask_1: 0.625  loss_dice_1: 3.336  loss_ce_2: 1.921  loss_mask_2: 0.6178  loss_dice_2: 3.276  loss_ce_3: 1.842  loss_mask_3: 0.6125  loss_dice_3: 3.23  loss_ce_4: 1.798  loss_mask_4: 0.6161  loss_dice_4: 3.235  loss_ce_5: 1.766  loss_mask_5: 0.6187  loss_dice_5: 3.23  loss_ce_6: 1.778  loss_mask_6: 0.6205  loss_dice_6: 3.223  loss_ce_7: 1.742  loss_mask_7: 0.6195  loss_dice_7: 3.218  loss_ce_8: 1.74  loss_mask_8: 0.6195  loss_dice_8: 3.213  time: 1.6940  data_time: 0.3523  lr: 5.0883e-06  max_mem: 17674M
[01/19 11:34:29] d2.utils.events INFO:  eta: 8:54:16  iter: 21139  total_loss: 59.43  loss_ce: 1.824  loss_mask: 0.6247  loss_dice: 3.218  loss_ce_0: 3.259  loss_mask_0: 0.645  loss_dice_0: 3.513  loss_ce_1: 2.103  loss_mask_1: 0.6281  loss_dice_1: 3.339  loss_ce_2: 1.985  loss_mask_2: 0.6246  loss_dice_2: 3.271  loss_ce_3: 1.94  loss_mask_3: 0.6246  loss_dice_3: 3.237  loss_ce_4: 1.869  loss_mask_4: 0.6239  loss_dice_4: 3.231  loss_ce_5: 1.853  loss_mask_5: 0.6229  loss_dice_5: 3.223  loss_ce_6: 1.859  loss_mask_6: 0.6242  loss_dice_6: 3.217  loss_ce_7: 1.84  loss_mask_7: 0.6242  loss_dice_7: 3.222  loss_ce_8: 1.826  loss_mask_8: 0.6242  loss_dice_8: 3.226  time: 1.6939  data_time: 0.3516  lr: 5.0834e-06  max_mem: 17674M
[01/19 11:35:03] d2.utils.events INFO:  eta: 8:53:35  iter: 21159  total_loss: 59.12  loss_ce: 1.774  loss_mask: 0.6089  loss_dice: 3.229  loss_ce_0: 3.258  loss_mask_0: 0.6305  loss_dice_0: 3.529  loss_ce_1: 2.071  loss_mask_1: 0.617  loss_dice_1: 3.357  loss_ce_2: 1.882  loss_mask_2: 0.6103  loss_dice_2: 3.307  loss_ce_3: 1.834  loss_mask_3: 0.6083  loss_dice_3: 3.249  loss_ce_4: 1.79  loss_mask_4: 0.6105  loss_dice_4: 3.247  loss_ce_5: 1.781  loss_mask_5: 0.6097  loss_dice_5: 3.249  loss_ce_6: 1.81  loss_mask_6: 0.611  loss_dice_6: 3.234  loss_ce_7: 1.793  loss_mask_7: 0.6101  loss_dice_7: 3.239  loss_ce_8: 1.799  loss_mask_8: 0.6101  loss_dice_8: 3.233  time: 1.6939  data_time: 0.3258  lr: 5.0785e-06  max_mem: 17674M
[01/19 11:35:38] d2.utils.events INFO:  eta: 8:53:22  iter: 21179  total_loss: 58.43  loss_ce: 1.771  loss_mask: 0.6304  loss_dice: 3.19  loss_ce_0: 3.172  loss_mask_0: 0.6449  loss_dice_0: 3.472  loss_ce_1: 2.078  loss_mask_1: 0.6365  loss_dice_1: 3.326  loss_ce_2: 1.94  loss_mask_2: 0.6299  loss_dice_2: 3.253  loss_ce_3: 1.873  loss_mask_3: 0.6308  loss_dice_3: 3.217  loss_ce_4: 1.818  loss_mask_4: 0.6319  loss_dice_4: 3.206  loss_ce_5: 1.786  loss_mask_5: 0.6332  loss_dice_5: 3.203  loss_ce_6: 1.794  loss_mask_6: 0.6307  loss_dice_6: 3.197  loss_ce_7: 1.782  loss_mask_7: 0.6296  loss_dice_7: 3.195  loss_ce_8: 1.764  loss_mask_8: 0.6308  loss_dice_8: 3.194  time: 1.6940  data_time: 0.3650  lr: 5.0737e-06  max_mem: 17674M
[01/19 11:36:11] d2.utils.events INFO:  eta: 8:52:36  iter: 21199  total_loss: 59.08  loss_ce: 1.835  loss_mask: 0.63  loss_dice: 3.186  loss_ce_0: 3.216  loss_mask_0: 0.6512  loss_dice_0: 3.479  loss_ce_1: 2.105  loss_mask_1: 0.6318  loss_dice_1: 3.316  loss_ce_2: 1.983  loss_mask_2: 0.6328  loss_dice_2: 3.246  loss_ce_3: 1.924  loss_mask_3: 0.6267  loss_dice_3: 3.206  loss_ce_4: 1.885  loss_mask_4: 0.6254  loss_dice_4: 3.201  loss_ce_5: 1.868  loss_mask_5: 0.6256  loss_dice_5: 3.201  loss_ce_6: 1.86  loss_mask_6: 0.6263  loss_dice_6: 3.19  loss_ce_7: 1.849  loss_mask_7: 0.6297  loss_dice_7: 3.183  loss_ce_8: 1.832  loss_mask_8: 0.6294  loss_dice_8: 3.189  time: 1.6940  data_time: 0.3305  lr: 5.0688e-06  max_mem: 17674M
[01/19 11:36:45] d2.utils.events INFO:  eta: 8:51:58  iter: 21219  total_loss: 59.02  loss_ce: 1.792  loss_mask: 0.6491  loss_dice: 3.185  loss_ce_0: 3.27  loss_mask_0: 0.6735  loss_dice_0: 3.453  loss_ce_1: 2.14  loss_mask_1: 0.65  loss_dice_1: 3.328  loss_ce_2: 1.972  loss_mask_2: 0.6466  loss_dice_2: 3.256  loss_ce_3: 1.925  loss_mask_3: 0.6447  loss_dice_3: 3.217  loss_ce_4: 1.859  loss_mask_4: 0.6473  loss_dice_4: 3.213  loss_ce_5: 1.828  loss_mask_5: 0.6467  loss_dice_5: 3.207  loss_ce_6: 1.801  loss_mask_6: 0.6445  loss_dice_6: 3.194  loss_ce_7: 1.807  loss_mask_7: 0.6482  loss_dice_7: 3.189  loss_ce_8: 1.786  loss_mask_8: 0.6471  loss_dice_8: 3.189  time: 1.6939  data_time: 0.3229  lr: 5.064e-06  max_mem: 17674M
[01/19 11:37:19] d2.utils.events INFO:  eta: 8:51:26  iter: 21239  total_loss: 58.92  loss_ce: 1.8  loss_mask: 0.6315  loss_dice: 3.206  loss_ce_0: 3.235  loss_mask_0: 0.6555  loss_dice_0: 3.498  loss_ce_1: 2.116  loss_mask_1: 0.6395  loss_dice_1: 3.345  loss_ce_2: 1.972  loss_mask_2: 0.6349  loss_dice_2: 3.273  loss_ce_3: 1.904  loss_mask_3: 0.6281  loss_dice_3: 3.23  loss_ce_4: 1.853  loss_mask_4: 0.6279  loss_dice_4: 3.23  loss_ce_5: 1.818  loss_mask_5: 0.6311  loss_dice_5: 3.232  loss_ce_6: 1.83  loss_mask_6: 0.629  loss_dice_6: 3.203  loss_ce_7: 1.806  loss_mask_7: 0.6295  loss_dice_7: 3.211  loss_ce_8: 1.815  loss_mask_8: 0.6327  loss_dice_8: 3.207  time: 1.6939  data_time: 0.3531  lr: 5.0591e-06  max_mem: 17674M
[01/19 11:37:53] d2.utils.events INFO:  eta: 8:50:35  iter: 21259  total_loss: 58.95  loss_ce: 1.742  loss_mask: 0.6302  loss_dice: 3.243  loss_ce_0: 3.21  loss_mask_0: 0.6564  loss_dice_0: 3.509  loss_ce_1: 2.052  loss_mask_1: 0.6342  loss_dice_1: 3.359  loss_ce_2: 1.906  loss_mask_2: 0.6276  loss_dice_2: 3.296  loss_ce_3: 1.837  loss_mask_3: 0.6262  loss_dice_3: 3.26  loss_ce_4: 1.798  loss_mask_4: 0.6277  loss_dice_4: 3.261  loss_ce_5: 1.749  loss_mask_5: 0.6305  loss_dice_5: 3.254  loss_ce_6: 1.75  loss_mask_6: 0.6297  loss_dice_6: 3.239  loss_ce_7: 1.747  loss_mask_7: 0.6286  loss_dice_7: 3.245  loss_ce_8: 1.736  loss_mask_8: 0.629  loss_dice_8: 3.244  time: 1.6939  data_time: 0.3387  lr: 5.0543e-06  max_mem: 17674M
[01/19 11:38:27] d2.utils.events INFO:  eta: 8:50:27  iter: 21279  total_loss: 59.61  loss_ce: 1.847  loss_mask: 0.6061  loss_dice: 3.238  loss_ce_0: 3.305  loss_mask_0: 0.6286  loss_dice_0: 3.516  loss_ce_1: 2.072  loss_mask_1: 0.6165  loss_dice_1: 3.369  loss_ce_2: 1.968  loss_mask_2: 0.6097  loss_dice_2: 3.314  loss_ce_3: 1.915  loss_mask_3: 0.605  loss_dice_3: 3.261  loss_ce_4: 1.862  loss_mask_4: 0.6058  loss_dice_4: 3.255  loss_ce_5: 1.845  loss_mask_5: 0.6064  loss_dice_5: 3.247  loss_ce_6: 1.823  loss_mask_6: 0.6068  loss_dice_6: 3.235  loss_ce_7: 1.82  loss_mask_7: 0.6091  loss_dice_7: 3.243  loss_ce_8: 1.816  loss_mask_8: 0.6084  loss_dice_8: 3.244  time: 1.6940  data_time: 0.3607  lr: 5.0494e-06  max_mem: 17674M
[01/19 11:39:01] d2.utils.events INFO:  eta: 8:49:46  iter: 21299  total_loss: 59.43  loss_ce: 1.822  loss_mask: 0.6404  loss_dice: 3.2  loss_ce_0: 3.223  loss_mask_0: 0.6585  loss_dice_0: 3.48  loss_ce_1: 2.098  loss_mask_1: 0.649  loss_dice_1: 3.333  loss_ce_2: 1.986  loss_mask_2: 0.645  loss_dice_2: 3.269  loss_ce_3: 1.947  loss_mask_3: 0.6418  loss_dice_3: 3.222  loss_ce_4: 1.893  loss_mask_4: 0.6408  loss_dice_4: 3.214  loss_ce_5: 1.857  loss_mask_5: 0.6418  loss_dice_5: 3.208  loss_ce_6: 1.862  loss_mask_6: 0.6374  loss_dice_6: 3.193  loss_ce_7: 1.833  loss_mask_7: 0.6402  loss_dice_7: 3.2  loss_ce_8: 1.81  loss_mask_8: 0.6396  loss_dice_8: 3.204  time: 1.6940  data_time: 0.3516  lr: 5.0446e-06  max_mem: 17674M
[01/19 11:39:35] d2.utils.events INFO:  eta: 8:49:07  iter: 21319  total_loss: 59.29  loss_ce: 1.82  loss_mask: 0.6177  loss_dice: 3.232  loss_ce_0: 3.18  loss_mask_0: 0.6489  loss_dice_0: 3.512  loss_ce_1: 2.079  loss_mask_1: 0.6253  loss_dice_1: 3.365  loss_ce_2: 1.99  loss_mask_2: 0.6165  loss_dice_2: 3.301  loss_ce_3: 1.934  loss_mask_3: 0.6144  loss_dice_3: 3.262  loss_ce_4: 1.874  loss_mask_4: 0.6145  loss_dice_4: 3.259  loss_ce_5: 1.846  loss_mask_5: 0.6163  loss_dice_5: 3.259  loss_ce_6: 1.843  loss_mask_6: 0.6167  loss_dice_6: 3.242  loss_ce_7: 1.823  loss_mask_7: 0.617  loss_dice_7: 3.24  loss_ce_8: 1.809  loss_mask_8: 0.6186  loss_dice_8: 3.24  time: 1.6940  data_time: 0.3350  lr: 5.0397e-06  max_mem: 17674M
[01/19 11:40:09] d2.utils.events INFO:  eta: 8:48:33  iter: 21339  total_loss: 58.93  loss_ce: 1.793  loss_mask: 0.6151  loss_dice: 3.251  loss_ce_0: 3.199  loss_mask_0: 0.6349  loss_dice_0: 3.534  loss_ce_1: 2.1  loss_mask_1: 0.624  loss_dice_1: 3.385  loss_ce_2: 1.946  loss_mask_2: 0.6189  loss_dice_2: 3.323  loss_ce_3: 1.882  loss_mask_3: 0.6168  loss_dice_3: 3.29  loss_ce_4: 1.82  loss_mask_4: 0.6169  loss_dice_4: 3.279  loss_ce_5: 1.793  loss_mask_5: 0.6191  loss_dice_5: 3.273  loss_ce_6: 1.822  loss_mask_6: 0.6173  loss_dice_6: 3.264  loss_ce_7: 1.786  loss_mask_7: 0.6136  loss_dice_7: 3.259  loss_ce_8: 1.799  loss_mask_8: 0.6159  loss_dice_8: 3.264  time: 1.6940  data_time: 0.3670  lr: 5.0349e-06  max_mem: 17674M
[01/19 11:40:44] d2.utils.events INFO:  eta: 8:48:08  iter: 21359  total_loss: 58.96  loss_ce: 1.758  loss_mask: 0.6162  loss_dice: 3.203  loss_ce_0: 3.153  loss_mask_0: 0.6384  loss_dice_0: 3.487  loss_ce_1: 2.088  loss_mask_1: 0.6247  loss_dice_1: 3.316  loss_ce_2: 1.931  loss_mask_2: 0.6181  loss_dice_2: 3.262  loss_ce_3: 1.861  loss_mask_3: 0.6139  loss_dice_3: 3.224  loss_ce_4: 1.8  loss_mask_4: 0.6164  loss_dice_4: 3.214  loss_ce_5: 1.795  loss_mask_5: 0.6167  loss_dice_5: 3.214  loss_ce_6: 1.804  loss_mask_6: 0.6157  loss_dice_6: 3.203  loss_ce_7: 1.788  loss_mask_7: 0.6168  loss_dice_7: 3.204  loss_ce_8: 1.766  loss_mask_8: 0.6174  loss_dice_8: 3.201  time: 1.6940  data_time: 0.3671  lr: 5.03e-06  max_mem: 17674M
[01/19 11:41:18] d2.utils.events INFO:  eta: 8:47:37  iter: 21379  total_loss: 58.98  loss_ce: 1.828  loss_mask: 0.6154  loss_dice: 3.211  loss_ce_0: 3.203  loss_mask_0: 0.6302  loss_dice_0: 3.505  loss_ce_1: 2.121  loss_mask_1: 0.6183  loss_dice_1: 3.357  loss_ce_2: 1.991  loss_mask_2: 0.6177  loss_dice_2: 3.281  loss_ce_3: 1.928  loss_mask_3: 0.6166  loss_dice_3: 3.233  loss_ce_4: 1.899  loss_mask_4: 0.6176  loss_dice_4: 3.227  loss_ce_5: 1.869  loss_mask_5: 0.6179  loss_dice_5: 3.23  loss_ce_6: 1.872  loss_mask_6: 0.617  loss_dice_6: 3.215  loss_ce_7: 1.85  loss_mask_7: 0.6163  loss_dice_7: 3.218  loss_ce_8: 1.843  loss_mask_8: 0.6169  loss_dice_8: 3.222  time: 1.6940  data_time: 0.3513  lr: 5.0251e-06  max_mem: 17674M
[01/19 11:41:51] d2.utils.events INFO:  eta: 8:46:50  iter: 21399  total_loss: 58.96  loss_ce: 1.836  loss_mask: 0.64  loss_dice: 3.162  loss_ce_0: 3.238  loss_mask_0: 0.6617  loss_dice_0: 3.466  loss_ce_1: 2.138  loss_mask_1: 0.6443  loss_dice_1: 3.293  loss_ce_2: 2  loss_mask_2: 0.6366  loss_dice_2: 3.231  loss_ce_3: 1.938  loss_mask_3: 0.6334  loss_dice_3: 3.185  loss_ce_4: 1.88  loss_mask_4: 0.6349  loss_dice_4: 3.182  loss_ce_5: 1.865  loss_mask_5: 0.6355  loss_dice_5: 3.179  loss_ce_6: 1.846  loss_mask_6: 0.6397  loss_dice_6: 3.172  loss_ce_7: 1.837  loss_mask_7: 0.6374  loss_dice_7: 3.173  loss_ce_8: 1.825  loss_mask_8: 0.6399  loss_dice_8: 3.168  time: 1.6940  data_time: 0.3508  lr: 5.0203e-06  max_mem: 17674M
[01/19 11:42:25] d2.utils.events INFO:  eta: 8:46:03  iter: 21419  total_loss: 57.6  loss_ce: 1.73  loss_mask: 0.6193  loss_dice: 3.216  loss_ce_0: 3.169  loss_mask_0: 0.64  loss_dice_0: 3.498  loss_ce_1: 2.072  loss_mask_1: 0.6264  loss_dice_1: 3.344  loss_ce_2: 1.898  loss_mask_2: 0.62  loss_dice_2: 3.282  loss_ce_3: 1.835  loss_mask_3: 0.6171  loss_dice_3: 3.236  loss_ce_4: 1.78  loss_mask_4: 0.6189  loss_dice_4: 3.233  loss_ce_5: 1.77  loss_mask_5: 0.6206  loss_dice_5: 3.23  loss_ce_6: 1.744  loss_mask_6: 0.6195  loss_dice_6: 3.221  loss_ce_7: 1.738  loss_mask_7: 0.6203  loss_dice_7: 3.218  loss_ce_8: 1.729  loss_mask_8: 0.6195  loss_dice_8: 3.218  time: 1.6940  data_time: 0.3450  lr: 5.0154e-06  max_mem: 17674M
[01/19 11:42:59] d2.utils.events INFO:  eta: 8:45:16  iter: 21439  total_loss: 58.39  loss_ce: 1.78  loss_mask: 0.6165  loss_dice: 3.181  loss_ce_0: 3.162  loss_mask_0: 0.6373  loss_dice_0: 3.499  loss_ce_1: 2.058  loss_mask_1: 0.6275  loss_dice_1: 3.321  loss_ce_2: 1.929  loss_mask_2: 0.623  loss_dice_2: 3.249  loss_ce_3: 1.877  loss_mask_3: 0.6168  loss_dice_3: 3.205  loss_ce_4: 1.825  loss_mask_4: 0.6161  loss_dice_4: 3.202  loss_ce_5: 1.788  loss_mask_5: 0.6169  loss_dice_5: 3.207  loss_ce_6: 1.786  loss_mask_6: 0.6161  loss_dice_6: 3.194  loss_ce_7: 1.772  loss_mask_7: 0.617  loss_dice_7: 3.19  loss_ce_8: 1.775  loss_mask_8: 0.6166  loss_dice_8: 3.188  time: 1.6940  data_time: 0.3348  lr: 5.0106e-06  max_mem: 17674M
[01/19 11:43:33] d2.utils.events INFO:  eta: 8:44:40  iter: 21459  total_loss: 58.34  loss_ce: 1.76  loss_mask: 0.6211  loss_dice: 3.17  loss_ce_0: 3.176  loss_mask_0: 0.6447  loss_dice_0: 3.482  loss_ce_1: 2.057  loss_mask_1: 0.6239  loss_dice_1: 3.312  loss_ce_2: 1.928  loss_mask_2: 0.6162  loss_dice_2: 3.248  loss_ce_3: 1.856  loss_mask_3: 0.6164  loss_dice_3: 3.203  loss_ce_4: 1.811  loss_mask_4: 0.6176  loss_dice_4: 3.193  loss_ce_5: 1.791  loss_mask_5: 0.6184  loss_dice_5: 3.189  loss_ce_6: 1.794  loss_mask_6: 0.619  loss_dice_6: 3.178  loss_ce_7: 1.773  loss_mask_7: 0.6196  loss_dice_7: 3.177  loss_ce_8: 1.768  loss_mask_8: 0.6205  loss_dice_8: 3.174  time: 1.6940  data_time: 0.3376  lr: 5.0057e-06  max_mem: 17674M
[01/19 11:44:08] d2.utils.events INFO:  eta: 8:44:10  iter: 21479  total_loss: 58.83  loss_ce: 1.763  loss_mask: 0.6281  loss_dice: 3.228  loss_ce_0: 3.172  loss_mask_0: 0.6431  loss_dice_0: 3.503  loss_ce_1: 2.063  loss_mask_1: 0.6273  loss_dice_1: 3.365  loss_ce_2: 1.901  loss_mask_2: 0.6226  loss_dice_2: 3.301  loss_ce_3: 1.85  loss_mask_3: 0.6243  loss_dice_3: 3.255  loss_ce_4: 1.812  loss_mask_4: 0.6268  loss_dice_4: 3.253  loss_ce_5: 1.79  loss_mask_5: 0.6275  loss_dice_5: 3.255  loss_ce_6: 1.77  loss_mask_6: 0.6284  loss_dice_6: 3.244  loss_ce_7: 1.764  loss_mask_7: 0.6273  loss_dice_7: 3.237  loss_ce_8: 1.766  loss_mask_8: 0.6289  loss_dice_8: 3.234  time: 1.6940  data_time: 0.3613  lr: 5.0009e-06  max_mem: 17674M
[01/19 11:44:42] d2.utils.events INFO:  eta: 8:43:53  iter: 21499  total_loss: 58.07  loss_ce: 1.725  loss_mask: 0.6006  loss_dice: 3.197  loss_ce_0: 3.142  loss_mask_0: 0.6197  loss_dice_0: 3.514  loss_ce_1: 2.01  loss_mask_1: 0.6094  loss_dice_1: 3.341  loss_ce_2: 1.869  loss_mask_2: 0.6087  loss_dice_2: 3.272  loss_ce_3: 1.804  loss_mask_3: 0.6034  loss_dice_3: 3.233  loss_ce_4: 1.767  loss_mask_4: 0.5997  loss_dice_4: 3.225  loss_ce_5: 1.749  loss_mask_5: 0.6031  loss_dice_5: 3.225  loss_ce_6: 1.735  loss_mask_6: 0.5996  loss_dice_6: 3.209  loss_ce_7: 1.729  loss_mask_7: 0.6006  loss_dice_7: 3.205  loss_ce_8: 1.736  loss_mask_8: 0.6004  loss_dice_8: 3.208  time: 1.6941  data_time: 0.3485  lr: 4.996e-06  max_mem: 17674M
[01/19 11:45:16] d2.utils.events INFO:  eta: 8:43:23  iter: 21519  total_loss: 59.61  loss_ce: 1.818  loss_mask: 0.6268  loss_dice: 3.273  loss_ce_0: 3.251  loss_mask_0: 0.6533  loss_dice_0: 3.538  loss_ce_1: 2.102  loss_mask_1: 0.634  loss_dice_1: 3.411  loss_ce_2: 1.964  loss_mask_2: 0.6297  loss_dice_2: 3.337  loss_ce_3: 1.907  loss_mask_3: 0.628  loss_dice_3: 3.296  loss_ce_4: 1.863  loss_mask_4: 0.6323  loss_dice_4: 3.285  loss_ce_5: 1.826  loss_mask_5: 0.6332  loss_dice_5: 3.286  loss_ce_6: 1.815  loss_mask_6: 0.6268  loss_dice_6: 3.276  loss_ce_7: 1.805  loss_mask_7: 0.6283  loss_dice_7: 3.271  loss_ce_8: 1.793  loss_mask_8: 0.627  loss_dice_8: 3.276  time: 1.6941  data_time: 0.3518  lr: 4.9911e-06  max_mem: 17674M
[01/19 11:45:50] d2.utils.events INFO:  eta: 8:42:49  iter: 21539  total_loss: 58.34  loss_ce: 1.741  loss_mask: 0.6211  loss_dice: 3.188  loss_ce_0: 3.142  loss_mask_0: 0.6457  loss_dice_0: 3.485  loss_ce_1: 2.028  loss_mask_1: 0.6325  loss_dice_1: 3.333  loss_ce_2: 1.91  loss_mask_2: 0.6243  loss_dice_2: 3.267  loss_ce_3: 1.863  loss_mask_3: 0.619  loss_dice_3: 3.218  loss_ce_4: 1.794  loss_mask_4: 0.6187  loss_dice_4: 3.2  loss_ce_5: 1.76  loss_mask_5: 0.6179  loss_dice_5: 3.21  loss_ce_6: 1.768  loss_mask_6: 0.6196  loss_dice_6: 3.193  loss_ce_7: 1.774  loss_mask_7: 0.6206  loss_dice_7: 3.196  loss_ce_8: 1.723  loss_mask_8: 0.6205  loss_dice_8: 3.196  time: 1.6941  data_time: 0.3415  lr: 4.9863e-06  max_mem: 17674M
[01/19 11:46:25] d2.utils.events INFO:  eta: 8:41:59  iter: 21559  total_loss: 57.48  loss_ce: 1.71  loss_mask: 0.613  loss_dice: 3.192  loss_ce_0: 3.109  loss_mask_0: 0.6358  loss_dice_0: 3.489  loss_ce_1: 1.942  loss_mask_1: 0.6222  loss_dice_1: 3.336  loss_ce_2: 1.865  loss_mask_2: 0.6197  loss_dice_2: 3.258  loss_ce_3: 1.781  loss_mask_3: 0.6142  loss_dice_3: 3.217  loss_ce_4: 1.743  loss_mask_4: 0.6135  loss_dice_4: 3.212  loss_ce_5: 1.714  loss_mask_5: 0.6142  loss_dice_5: 3.211  loss_ce_6: 1.724  loss_mask_6: 0.6109  loss_dice_6: 3.194  loss_ce_7: 1.696  loss_mask_7: 0.6107  loss_dice_7: 3.193  loss_ce_8: 1.7  loss_mask_8: 0.6133  loss_dice_8: 3.195  time: 1.6941  data_time: 0.3714  lr: 4.9814e-06  max_mem: 17674M
[01/19 11:46:59] d2.utils.events INFO:  eta: 8:41:31  iter: 21579  total_loss: 58.19  loss_ce: 1.691  loss_mask: 0.6162  loss_dice: 3.209  loss_ce_0: 3.172  loss_mask_0: 0.6388  loss_dice_0: 3.498  loss_ce_1: 2.011  loss_mask_1: 0.6214  loss_dice_1: 3.329  loss_ce_2: 1.873  loss_mask_2: 0.6239  loss_dice_2: 3.272  loss_ce_3: 1.817  loss_mask_3: 0.6143  loss_dice_3: 3.227  loss_ce_4: 1.761  loss_mask_4: 0.615  loss_dice_4: 3.224  loss_ce_5: 1.726  loss_mask_5: 0.6197  loss_dice_5: 3.226  loss_ce_6: 1.705  loss_mask_6: 0.6183  loss_dice_6: 3.206  loss_ce_7: 1.684  loss_mask_7: 0.6173  loss_dice_7: 3.21  loss_ce_8: 1.675  loss_mask_8: 0.6166  loss_dice_8: 3.206  time: 1.6941  data_time: 0.3393  lr: 4.9765e-06  max_mem: 17674M
[01/19 11:47:33] d2.utils.events INFO:  eta: 8:40:57  iter: 21599  total_loss: 58.58  loss_ce: 1.742  loss_mask: 0.62  loss_dice: 3.184  loss_ce_0: 3.199  loss_mask_0: 0.6387  loss_dice_0: 3.478  loss_ce_1: 2.005  loss_mask_1: 0.626  loss_dice_1: 3.335  loss_ce_2: 1.882  loss_mask_2: 0.6224  loss_dice_2: 3.266  loss_ce_3: 1.839  loss_mask_3: 0.6176  loss_dice_3: 3.211  loss_ce_4: 1.792  loss_mask_4: 0.6184  loss_dice_4: 3.201  loss_ce_5: 1.763  loss_mask_5: 0.6228  loss_dice_5: 3.197  loss_ce_6: 1.753  loss_mask_6: 0.6201  loss_dice_6: 3.187  loss_ce_7: 1.757  loss_mask_7: 0.6194  loss_dice_7: 3.187  loss_ce_8: 1.752  loss_mask_8: 0.6214  loss_dice_8: 3.186  time: 1.6941  data_time: 0.3591  lr: 4.9717e-06  max_mem: 17674M
[01/19 11:48:07] d2.utils.events INFO:  eta: 8:40:37  iter: 21619  total_loss: 59.39  loss_ce: 1.78  loss_mask: 0.6227  loss_dice: 3.233  loss_ce_0: 3.257  loss_mask_0: 0.6444  loss_dice_0: 3.522  loss_ce_1: 2.053  loss_mask_1: 0.6339  loss_dice_1: 3.386  loss_ce_2: 1.938  loss_mask_2: 0.6293  loss_dice_2: 3.309  loss_ce_3: 1.877  loss_mask_3: 0.6237  loss_dice_3: 3.254  loss_ce_4: 1.839  loss_mask_4: 0.6235  loss_dice_4: 3.257  loss_ce_5: 1.813  loss_mask_5: 0.6229  loss_dice_5: 3.258  loss_ce_6: 1.793  loss_mask_6: 0.6239  loss_dice_6: 3.248  loss_ce_7: 1.774  loss_mask_7: 0.6263  loss_dice_7: 3.241  loss_ce_8: 1.762  loss_mask_8: 0.625  loss_dice_8: 3.242  time: 1.6941  data_time: 0.3474  lr: 4.9668e-06  max_mem: 17674M
[01/19 11:48:41] d2.utils.events INFO:  eta: 8:39:43  iter: 21639  total_loss: 59.24  loss_ce: 1.836  loss_mask: 0.6295  loss_dice: 3.188  loss_ce_0: 3.224  loss_mask_0: 0.6604  loss_dice_0: 3.479  loss_ce_1: 2.167  loss_mask_1: 0.6308  loss_dice_1: 3.325  loss_ce_2: 2.047  loss_mask_2: 0.6298  loss_dice_2: 3.258  loss_ce_3: 1.958  loss_mask_3: 0.6324  loss_dice_3: 3.21  loss_ce_4: 1.906  loss_mask_4: 0.6284  loss_dice_4: 3.207  loss_ce_5: 1.879  loss_mask_5: 0.6305  loss_dice_5: 3.209  loss_ce_6: 1.869  loss_mask_6: 0.6297  loss_dice_6: 3.188  loss_ce_7: 1.851  loss_mask_7: 0.631  loss_dice_7: 3.195  loss_ce_8: 1.853  loss_mask_8: 0.6307  loss_dice_8: 3.19  time: 1.6941  data_time: 0.3304  lr: 4.962e-06  max_mem: 17674M
[01/19 11:49:15] d2.utils.events INFO:  eta: 8:39:01  iter: 21659  total_loss: 59.14  loss_ce: 1.849  loss_mask: 0.618  loss_dice: 3.206  loss_ce_0: 3.213  loss_mask_0: 0.6289  loss_dice_0: 3.499  loss_ce_1: 2.073  loss_mask_1: 0.6194  loss_dice_1: 3.352  loss_ce_2: 1.976  loss_mask_2: 0.6168  loss_dice_2: 3.284  loss_ce_3: 1.943  loss_mask_3: 0.6153  loss_dice_3: 3.239  loss_ce_4: 1.883  loss_mask_4: 0.6161  loss_dice_4: 3.236  loss_ce_5: 1.864  loss_mask_5: 0.6161  loss_dice_5: 3.225  loss_ce_6: 1.863  loss_mask_6: 0.6149  loss_dice_6: 3.216  loss_ce_7: 1.85  loss_mask_7: 0.6183  loss_dice_7: 3.213  loss_ce_8: 1.851  loss_mask_8: 0.6183  loss_dice_8: 3.215  time: 1.6941  data_time: 0.3334  lr: 4.9571e-06  max_mem: 17674M
[01/19 11:49:49] d2.utils.events INFO:  eta: 8:38:35  iter: 21679  total_loss: 58.87  loss_ce: 1.795  loss_mask: 0.6215  loss_dice: 3.174  loss_ce_0: 3.178  loss_mask_0: 0.6475  loss_dice_0: 3.464  loss_ce_1: 2.071  loss_mask_1: 0.6243  loss_dice_1: 3.313  loss_ce_2: 1.981  loss_mask_2: 0.6245  loss_dice_2: 3.236  loss_ce_3: 1.89  loss_mask_3: 0.6155  loss_dice_3: 3.195  loss_ce_4: 1.856  loss_mask_4: 0.6172  loss_dice_4: 3.193  loss_ce_5: 1.801  loss_mask_5: 0.6207  loss_dice_5: 3.194  loss_ce_6: 1.807  loss_mask_6: 0.6168  loss_dice_6: 3.185  loss_ce_7: 1.774  loss_mask_7: 0.6196  loss_dice_7: 3.185  loss_ce_8: 1.775  loss_mask_8: 0.6207  loss_dice_8: 3.185  time: 1.6941  data_time: 0.3523  lr: 4.9522e-06  max_mem: 17674M
[01/19 11:50:23] d2.utils.events INFO:  eta: 8:38:02  iter: 21699  total_loss: 58.6  loss_ce: 1.806  loss_mask: 0.6316  loss_dice: 3.166  loss_ce_0: 3.151  loss_mask_0: 0.6564  loss_dice_0: 3.467  loss_ce_1: 2.097  loss_mask_1: 0.6421  loss_dice_1: 3.295  loss_ce_2: 1.963  loss_mask_2: 0.6263  loss_dice_2: 3.237  loss_ce_3: 1.921  loss_mask_3: 0.6309  loss_dice_3: 3.19  loss_ce_4: 1.864  loss_mask_4: 0.633  loss_dice_4: 3.181  loss_ce_5: 1.845  loss_mask_5: 0.634  loss_dice_5: 3.177  loss_ce_6: 1.832  loss_mask_6: 0.6312  loss_dice_6: 3.164  loss_ce_7: 1.801  loss_mask_7: 0.6319  loss_dice_7: 3.162  loss_ce_8: 1.81  loss_mask_8: 0.6318  loss_dice_8: 3.161  time: 1.6941  data_time: 0.3493  lr: 4.9474e-06  max_mem: 17674M
[01/19 11:50:58] d2.utils.events INFO:  eta: 8:37:43  iter: 21719  total_loss: 58.33  loss_ce: 1.762  loss_mask: 0.6066  loss_dice: 3.221  loss_ce_0: 3.159  loss_mask_0: 0.6254  loss_dice_0: 3.499  loss_ce_1: 2.047  loss_mask_1: 0.6145  loss_dice_1: 3.34  loss_ce_2: 1.915  loss_mask_2: 0.6088  loss_dice_2: 3.283  loss_ce_3: 1.825  loss_mask_3: 0.6117  loss_dice_3: 3.243  loss_ce_4: 1.803  loss_mask_4: 0.6103  loss_dice_4: 3.235  loss_ce_5: 1.784  loss_mask_5: 0.6114  loss_dice_5: 3.238  loss_ce_6: 1.782  loss_mask_6: 0.6044  loss_dice_6: 3.22  loss_ce_7: 1.76  loss_mask_7: 0.6061  loss_dice_7: 3.222  loss_ce_8: 1.765  loss_mask_8: 0.6067  loss_dice_8: 3.221  time: 1.6942  data_time: 0.3571  lr: 4.9425e-06  max_mem: 17674M
[01/19 11:51:32] d2.utils.events INFO:  eta: 8:36:55  iter: 21739  total_loss: 58.63  loss_ce: 1.728  loss_mask: 0.614  loss_dice: 3.242  loss_ce_0: 3.169  loss_mask_0: 0.6326  loss_dice_0: 3.528  loss_ce_1: 1.996  loss_mask_1: 0.6162  loss_dice_1: 3.373  loss_ce_2: 1.9  loss_mask_2: 0.6165  loss_dice_2: 3.303  loss_ce_3: 1.827  loss_mask_3: 0.6118  loss_dice_3: 3.26  loss_ce_4: 1.772  loss_mask_4: 0.6133  loss_dice_4: 3.267  loss_ce_5: 1.735  loss_mask_5: 0.6144  loss_dice_5: 3.261  loss_ce_6: 1.735  loss_mask_6: 0.6125  loss_dice_6: 3.248  loss_ce_7: 1.718  loss_mask_7: 0.6138  loss_dice_7: 3.255  loss_ce_8: 1.709  loss_mask_8: 0.6174  loss_dice_8: 3.246  time: 1.6942  data_time: 0.3500  lr: 4.9376e-06  max_mem: 17674M
[01/19 11:52:06] d2.utils.events INFO:  eta: 8:36:21  iter: 21759  total_loss: 57.33  loss_ce: 1.679  loss_mask: 0.5934  loss_dice: 3.232  loss_ce_0: 3.122  loss_mask_0: 0.6294  loss_dice_0: 3.514  loss_ce_1: 1.951  loss_mask_1: 0.6049  loss_dice_1: 3.367  loss_ce_2: 1.824  loss_mask_2: 0.5999  loss_dice_2: 3.3  loss_ce_3: 1.77  loss_mask_3: 0.597  loss_dice_3: 3.258  loss_ce_4: 1.711  loss_mask_4: 0.5963  loss_dice_4: 3.255  loss_ce_5: 1.682  loss_mask_5: 0.5952  loss_dice_5: 3.252  loss_ce_6: 1.681  loss_mask_6: 0.5962  loss_dice_6: 3.233  loss_ce_7: 1.672  loss_mask_7: 0.5992  loss_dice_7: 3.236  loss_ce_8: 1.659  loss_mask_8: 0.5988  loss_dice_8: 3.234  time: 1.6942  data_time: 0.3541  lr: 4.9328e-06  max_mem: 17674M
[01/19 11:52:40] d2.utils.events INFO:  eta: 8:35:52  iter: 21779  total_loss: 58.08  loss_ce: 1.775  loss_mask: 0.6244  loss_dice: 3.209  loss_ce_0: 3.135  loss_mask_0: 0.645  loss_dice_0: 3.509  loss_ce_1: 2.07  loss_mask_1: 0.6264  loss_dice_1: 3.341  loss_ce_2: 1.935  loss_mask_2: 0.6246  loss_dice_2: 3.278  loss_ce_3: 1.891  loss_mask_3: 0.622  loss_dice_3: 3.237  loss_ce_4: 1.833  loss_mask_4: 0.6223  loss_dice_4: 3.233  loss_ce_5: 1.819  loss_mask_5: 0.6253  loss_dice_5: 3.225  loss_ce_6: 1.807  loss_mask_6: 0.6241  loss_dice_6: 3.214  loss_ce_7: 1.792  loss_mask_7: 0.625  loss_dice_7: 3.213  loss_ce_8: 1.779  loss_mask_8: 0.6268  loss_dice_8: 3.208  time: 1.6942  data_time: 0.3575  lr: 4.9279e-06  max_mem: 17674M
[01/19 11:53:14] d2.utils.events INFO:  eta: 8:35:12  iter: 21799  total_loss: 59.19  loss_ce: 1.839  loss_mask: 0.6228  loss_dice: 3.251  loss_ce_0: 3.202  loss_mask_0: 0.6403  loss_dice_0: 3.523  loss_ce_1: 2.101  loss_mask_1: 0.6273  loss_dice_1: 3.389  loss_ce_2: 1.971  loss_mask_2: 0.6227  loss_dice_2: 3.318  loss_ce_3: 1.964  loss_mask_3: 0.6223  loss_dice_3: 3.271  loss_ce_4: 1.88  loss_mask_4: 0.6215  loss_dice_4: 3.273  loss_ce_5: 1.87  loss_mask_5: 0.6232  loss_dice_5: 3.26  loss_ce_6: 1.877  loss_mask_6: 0.6218  loss_dice_6: 3.256  loss_ce_7: 1.832  loss_mask_7: 0.6189  loss_dice_7: 3.249  loss_ce_8: 1.842  loss_mask_8: 0.62  loss_dice_8: 3.248  time: 1.6942  data_time: 0.3548  lr: 4.923e-06  max_mem: 17674M
[01/19 11:53:48] d2.utils.events INFO:  eta: 8:34:49  iter: 21819  total_loss: 59.03  loss_ce: 1.827  loss_mask: 0.62  loss_dice: 3.198  loss_ce_0: 3.16  loss_mask_0: 0.6518  loss_dice_0: 3.496  loss_ce_1: 2.036  loss_mask_1: 0.6341  loss_dice_1: 3.345  loss_ce_2: 1.925  loss_mask_2: 0.6275  loss_dice_2: 3.275  loss_ce_3: 1.898  loss_mask_3: 0.6229  loss_dice_3: 3.237  loss_ce_4: 1.838  loss_mask_4: 0.621  loss_dice_4: 3.225  loss_ce_5: 1.822  loss_mask_5: 0.6234  loss_dice_5: 3.225  loss_ce_6: 1.814  loss_mask_6: 0.6213  loss_dice_6: 3.21  loss_ce_7: 1.821  loss_mask_7: 0.6243  loss_dice_7: 3.204  loss_ce_8: 1.83  loss_mask_8: 0.6228  loss_dice_8: 3.205  time: 1.6942  data_time: 0.3334  lr: 4.9182e-06  max_mem: 17674M
[01/19 11:54:23] d2.utils.events INFO:  eta: 8:34:21  iter: 21839  total_loss: 58.82  loss_ce: 1.777  loss_mask: 0.6133  loss_dice: 3.197  loss_ce_0: 3.178  loss_mask_0: 0.6351  loss_dice_0: 3.486  loss_ce_1: 2.036  loss_mask_1: 0.6266  loss_dice_1: 3.342  loss_ce_2: 1.933  loss_mask_2: 0.621  loss_dice_2: 3.275  loss_ce_3: 1.87  loss_mask_3: 0.6137  loss_dice_3: 3.226  loss_ce_4: 1.821  loss_mask_4: 0.6125  loss_dice_4: 3.223  loss_ce_5: 1.802  loss_mask_5: 0.6111  loss_dice_5: 3.219  loss_ce_6: 1.793  loss_mask_6: 0.6162  loss_dice_6: 3.207  loss_ce_7: 1.777  loss_mask_7: 0.617  loss_dice_7: 3.21  loss_ce_8: 1.795  loss_mask_8: 0.6133  loss_dice_8: 3.202  time: 1.6942  data_time: 0.3624  lr: 4.9133e-06  max_mem: 17674M
[01/19 11:54:57] d2.utils.events INFO:  eta: 8:33:31  iter: 21859  total_loss: 58.32  loss_ce: 1.747  loss_mask: 0.6332  loss_dice: 3.224  loss_ce_0: 3.178  loss_mask_0: 0.6485  loss_dice_0: 3.511  loss_ce_1: 1.997  loss_mask_1: 0.6328  loss_dice_1: 3.37  loss_ce_2: 1.9  loss_mask_2: 0.6314  loss_dice_2: 3.291  loss_ce_3: 1.859  loss_mask_3: 0.631  loss_dice_3: 3.247  loss_ce_4: 1.81  loss_mask_4: 0.6307  loss_dice_4: 3.248  loss_ce_5: 1.768  loss_mask_5: 0.6303  loss_dice_5: 3.243  loss_ce_6: 1.769  loss_mask_6: 0.6304  loss_dice_6: 3.233  loss_ce_7: 1.781  loss_mask_7: 0.6315  loss_dice_7: 3.231  loss_ce_8: 1.754  loss_mask_8: 0.6327  loss_dice_8: 3.23  time: 1.6942  data_time: 0.3427  lr: 4.9084e-06  max_mem: 17674M
[01/19 11:55:31] d2.utils.events INFO:  eta: 8:33:02  iter: 21879  total_loss: 58.24  loss_ce: 1.728  loss_mask: 0.6246  loss_dice: 3.178  loss_ce_0: 3.134  loss_mask_0: 0.6501  loss_dice_0: 3.474  loss_ce_1: 2.043  loss_mask_1: 0.6311  loss_dice_1: 3.314  loss_ce_2: 1.898  loss_mask_2: 0.6263  loss_dice_2: 3.243  loss_ce_3: 1.837  loss_mask_3: 0.6251  loss_dice_3: 3.192  loss_ce_4: 1.78  loss_mask_4: 0.6252  loss_dice_4: 3.195  loss_ce_5: 1.771  loss_mask_5: 0.6277  loss_dice_5: 3.191  loss_ce_6: 1.751  loss_mask_6: 0.6217  loss_dice_6: 3.183  loss_ce_7: 1.744  loss_mask_7: 0.6227  loss_dice_7: 3.183  loss_ce_8: 1.712  loss_mask_8: 0.6244  loss_dice_8: 3.181  time: 1.6942  data_time: 0.3431  lr: 4.9035e-06  max_mem: 17674M
[01/19 11:56:05] d2.utils.events INFO:  eta: 8:32:36  iter: 21899  total_loss: 58.24  loss_ce: 1.733  loss_mask: 0.6219  loss_dice: 3.219  loss_ce_0: 3.156  loss_mask_0: 0.6408  loss_dice_0: 3.498  loss_ce_1: 2.007  loss_mask_1: 0.6287  loss_dice_1: 3.344  loss_ce_2: 1.894  loss_mask_2: 0.6153  loss_dice_2: 3.284  loss_ce_3: 1.825  loss_mask_3: 0.6104  loss_dice_3: 3.232  loss_ce_4: 1.767  loss_mask_4: 0.6108  loss_dice_4: 3.23  loss_ce_5: 1.746  loss_mask_5: 0.6143  loss_dice_5: 3.236  loss_ce_6: 1.749  loss_mask_6: 0.6189  loss_dice_6: 3.219  loss_ce_7: 1.732  loss_mask_7: 0.6188  loss_dice_7: 3.22  loss_ce_8: 1.719  loss_mask_8: 0.6214  loss_dice_8: 3.214  time: 1.6943  data_time: 0.3613  lr: 4.8987e-06  max_mem: 17674M
[01/19 11:56:39] d2.utils.events INFO:  eta: 8:31:59  iter: 21919  total_loss: 57.82  loss_ce: 1.677  loss_mask: 0.6322  loss_dice: 3.199  loss_ce_0: 3.167  loss_mask_0: 0.6567  loss_dice_0: 3.484  loss_ce_1: 2.002  loss_mask_1: 0.6406  loss_dice_1: 3.323  loss_ce_2: 1.849  loss_mask_2: 0.6309  loss_dice_2: 3.251  loss_ce_3: 1.768  loss_mask_3: 0.6304  loss_dice_3: 3.212  loss_ce_4: 1.721  loss_mask_4: 0.6307  loss_dice_4: 3.211  loss_ce_5: 1.704  loss_mask_5: 0.6275  loss_dice_5: 3.212  loss_ce_6: 1.689  loss_mask_6: 0.6298  loss_dice_6: 3.201  loss_ce_7: 1.689  loss_mask_7: 0.6294  loss_dice_7: 3.203  loss_ce_8: 1.684  loss_mask_8: 0.6324  loss_dice_8: 3.195  time: 1.6943  data_time: 0.3458  lr: 4.8938e-06  max_mem: 17674M
[01/19 11:57:13] d2.utils.events INFO:  eta: 8:31:28  iter: 21939  total_loss: 58.9  loss_ce: 1.791  loss_mask: 0.6186  loss_dice: 3.217  loss_ce_0: 3.076  loss_mask_0: 0.6345  loss_dice_0: 3.525  loss_ce_1: 2.068  loss_mask_1: 0.6116  loss_dice_1: 3.358  loss_ce_2: 1.931  loss_mask_2: 0.6173  loss_dice_2: 3.279  loss_ce_3: 1.867  loss_mask_3: 0.6165  loss_dice_3: 3.242  loss_ce_4: 1.833  loss_mask_4: 0.6164  loss_dice_4: 3.235  loss_ce_5: 1.809  loss_mask_5: 0.6179  loss_dice_5: 3.237  loss_ce_6: 1.806  loss_mask_6: 0.6198  loss_dice_6: 3.223  loss_ce_7: 1.793  loss_mask_7: 0.6189  loss_dice_7: 3.226  loss_ce_8: 1.792  loss_mask_8: 0.6189  loss_dice_8: 3.218  time: 1.6943  data_time: 0.3304  lr: 4.8889e-06  max_mem: 17674M
[01/19 11:57:47] d2.utils.events INFO:  eta: 8:30:40  iter: 21959  total_loss: 58.15  loss_ce: 1.761  loss_mask: 0.6379  loss_dice: 3.169  loss_ce_0: 3.108  loss_mask_0: 0.6611  loss_dice_0: 3.493  loss_ce_1: 2.032  loss_mask_1: 0.6376  loss_dice_1: 3.296  loss_ce_2: 1.897  loss_mask_2: 0.633  loss_dice_2: 3.237  loss_ce_3: 1.841  loss_mask_3: 0.6328  loss_dice_3: 3.188  loss_ce_4: 1.818  loss_mask_4: 0.6371  loss_dice_4: 3.185  loss_ce_5: 1.772  loss_mask_5: 0.6382  loss_dice_5: 3.187  loss_ce_6: 1.776  loss_mask_6: 0.6367  loss_dice_6: 3.18  loss_ce_7: 1.773  loss_mask_7: 0.6361  loss_dice_7: 3.174  loss_ce_8: 1.772  loss_mask_8: 0.6383  loss_dice_8: 3.17  time: 1.6943  data_time: 0.3344  lr: 4.8841e-06  max_mem: 17674M
[01/19 11:58:21] d2.utils.events INFO:  eta: 8:30:04  iter: 21979  total_loss: 58.3  loss_ce: 1.757  loss_mask: 0.6258  loss_dice: 3.142  loss_ce_0: 3.159  loss_mask_0: 0.6477  loss_dice_0: 3.457  loss_ce_1: 2.048  loss_mask_1: 0.6272  loss_dice_1: 3.281  loss_ce_2: 1.908  loss_mask_2: 0.6247  loss_dice_2: 3.209  loss_ce_3: 1.847  loss_mask_3: 0.6211  loss_dice_3: 3.161  loss_ce_4: 1.817  loss_mask_4: 0.6194  loss_dice_4: 3.161  loss_ce_5: 1.775  loss_mask_5: 0.6245  loss_dice_5: 3.161  loss_ce_6: 1.795  loss_mask_6: 0.6261  loss_dice_6: 3.149  loss_ce_7: 1.77  loss_mask_7: 0.6234  loss_dice_7: 3.143  loss_ce_8: 1.747  loss_mask_8: 0.6267  loss_dice_8: 3.148  time: 1.6943  data_time: 0.3539  lr: 4.8792e-06  max_mem: 17674M
[01/19 11:58:55] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 11:58:56] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 11:58:56] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 12:04:38] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.9236315552433734, 'error_1pix': 0.3399999597830084, 'error_3pix': 0.14596885677501964, 'mIoU': 8.649844032431234, 'fwIoU': 24.417329911165154, 'IoU-0': nan, 'IoU-1': 95.5042407953642, 'IoU-2': 12.296881404082551, 'IoU-3': 41.001600590033576, 'IoU-4': 27.36071412079249, 'IoU-5': 19.11088517423507, 'IoU-6': 21.299848387999937, 'IoU-7': 12.254146309283236, 'IoU-8': 5.825651992112838, 'IoU-9': 10.63695419714143, 'IoU-10': 23.111281800385342, 'IoU-11': 32.238462062689536, 'IoU-12': 31.314027104628718, 'IoU-13': 28.447552600990168, 'IoU-14': 29.410096376374845, 'IoU-15': 26.857136779249117, 'IoU-16': 24.168721129518982, 'IoU-17': 23.935105625338736, 'IoU-18': 22.40737127948264, 'IoU-19': 20.91178771081144, 'IoU-20': 22.11828269787724, 'IoU-21': 23.0033407992528, 'IoU-22': 22.639235051288008, 'IoU-23': 21.13845996744348, 'IoU-24': 19.298099981553218, 'IoU-25': 21.178063869104562, 'IoU-26': 18.94538928415964, 'IoU-27': 20.86935270045348, 'IoU-28': 19.02054510637984, 'IoU-29': 21.618812033145378, 'IoU-30': 21.073108105328124, 'IoU-31': 18.858903560103744, 'IoU-32': 14.746178923809769, 'IoU-33': 18.791216975049345, 'IoU-34': 19.43419130578339, 'IoU-35': 15.674732208731726, 'IoU-36': 18.036314773594572, 'IoU-37': 17.104301863482863, 'IoU-38': 16.134355323134116, 'IoU-39': 17.385596688306794, 'IoU-40': 15.789685672913004, 'IoU-41': 14.432609338109328, 'IoU-42': 15.563600396640394, 'IoU-43': 14.123505697553796, 'IoU-44': 11.428164637390138, 'IoU-45': 14.234887637122897, 'IoU-46': 14.646286594848492, 'IoU-47': 11.798266095781557, 'IoU-48': 13.437339946681776, 'IoU-49': 13.258942286182165, 'IoU-50': 14.376993335966546, 'IoU-51': 14.515995236975963, 'IoU-52': 12.711028795342575, 'IoU-53': 14.64579639215606, 'IoU-54': 14.822579710179218, 'IoU-55': 14.700806985443492, 'IoU-56': 11.072939116727024, 'IoU-57': 12.19365177979571, 'IoU-58': 13.06240064959359, 'IoU-59': 8.900416368429322, 'IoU-60': 12.42727695685466, 'IoU-61': 10.910607494566694, 'IoU-62': 10.927924806731127, 'IoU-63': 11.14079038252969, 'IoU-64': 8.948565461386208, 'IoU-65': 11.125527810616095, 'IoU-66': 7.550866447929215, 'IoU-67': 9.047482529646457, 'IoU-68': 6.347212066954181, 'IoU-69': 8.277048892360284, 'IoU-70': 7.3781675727020195, 'IoU-71': 6.806806745766933, 'IoU-72': 5.957348538600913, 'IoU-73': 6.698997339817544, 'IoU-74': 7.008523553664918, 'IoU-75': 6.854626181119556, 'IoU-76': 6.6460728793101636, 'IoU-77': 5.282057532825714, 'IoU-78': 5.441916552777554, 'IoU-79': 7.396142624359395, 'IoU-80': 5.593836436849258, 'IoU-81': 5.476392966804176, 'IoU-82': 6.01948238331651, 'IoU-83': 4.016767003712212, 'IoU-84': 5.286377204666288, 'IoU-85': 7.029819496048489, 'IoU-86': 4.499288362959623, 'IoU-87': 6.780635310320051, 'IoU-88': 5.207055720829307, 'IoU-89': 6.631263920190703, 'IoU-90': 5.860211678776961, 'IoU-91': 5.709142068509352, 'IoU-92': 4.670821240039461, 'IoU-93': 4.999201562136676, 'IoU-94': 5.222300408595137, 'IoU-95': 5.491576254741113, 'IoU-96': 7.561051139876486, 'IoU-97': 6.161585484858323, 'IoU-98': 5.638052156464481, 'IoU-99': 3.722301901177226, 'IoU-100': 6.334334444505946, 'IoU-101': 5.203044275055344, 'IoU-102': 5.512518394739003, 'IoU-103': 4.557153737668954, 'IoU-104': 5.2635562009502905, 'IoU-105': 5.306998700576438, 'IoU-106': 3.6027799119801474, 'IoU-107': 5.550046720224447, 'IoU-108': 4.163104999336078, 'IoU-109': 3.763076461077562, 'IoU-110': 5.174646938214381, 'IoU-111': 4.741354315620158, 'IoU-112': 3.535930439951774, 'IoU-113': 4.221702278142922, 'IoU-114': 5.254538750189792, 'IoU-115': 5.394797886755325, 'IoU-116': 4.106222497858894, 'IoU-117': 5.296618405780199, 'IoU-118': 3.4638484456094916, 'IoU-119': 5.376836836923863, 'IoU-120': 4.446697278708728, 'IoU-121': 3.970351283427645, 'IoU-122': 3.5848152314684114, 'IoU-123': 3.704570831682455, 'IoU-124': 3.7817841972093285, 'IoU-125': 2.14800967802339, 'IoU-126': 3.301802035303701, 'IoU-127': 4.328719886082056, 'IoU-128': 3.8144004022493987, 'IoU-129': 3.572419413291038, 'IoU-130': 2.0957876775153528, 'IoU-131': 2.1345552543698765, 'IoU-132': 2.346770876182641, 'IoU-133': 2.9408681009695576, 'IoU-134': 2.7068476046118675, 'IoU-135': 3.5639998959985437, 'IoU-136': 2.2096722207430037, 'IoU-137': 1.3321204131051396, 'IoU-138': 1.052125731735451, 'IoU-139': 2.541982236708159, 'IoU-140': 3.2165791940085606, 'IoU-141': 2.3002481579632668, 'IoU-142': 1.6937604691806596, 'IoU-143': 2.1367078059099085, 'IoU-144': 1.5686121070477324, 'IoU-145': 2.545158571336867, 'IoU-146': 1.9492903469083749, 'IoU-147': 2.0740874167102707, 'IoU-148': 1.7435578143046366, 'IoU-149': 2.1304698873960937, 'IoU-150': 1.5479358312703042, 'IoU-151': 0.7144542815285884, 'IoU-152': 0.3285083666974643, 'IoU-153': 0.5602960549691427, 'IoU-154': 1.7643682538463983, 'IoU-155': 0.6588291449576646, 'IoU-156': 2.3883886641704133, 'IoU-157': 1.2754541802437174, 'IoU-158': 0.6796455680121956, 'IoU-159': 1.2069564620539066, 'IoU-160': 1.9047565751875204, 'IoU-161': 0.5370293819364801, 'IoU-162': 1.9256436347295947, 'IoU-163': 0.8224851338312377, 'IoU-164': 1.2660268093094462, 'IoU-165': 1.1378687271650918, 'IoU-166': 0.6262975855709599, 'IoU-167': 1.065343320679375, 'IoU-168': 1.2897325933400605, 'IoU-169': 0.1892655229435667, 'IoU-170': 0.9285525833467584, 'IoU-171': 0.11565157269976384, 'IoU-172': 1.0987355298759078, 'IoU-173': 0.39677932160483476, 'IoU-174': 0.6108559965519627, 'IoU-175': 0.6624669842905353, 'IoU-176': 0.274096637518269, 'IoU-177': 0.33806008641756086, 'IoU-178': 0.9267610117113414, 'IoU-179': 0.5573478074022618, 'IoU-180': 0.795534493515458, 'IoU-181': 0.7496072040480566, 'IoU-182': 1.788286082888704, 'IoU-183': 0.8012507991310881, 'IoU-184': 0.39080187258420895, 'IoU-185': 0.34489316434030515, 'IoU-186': 0.7344086380091671, 'IoU-187': 2.032050286145077, 'IoU-188': 0.7405377376532682, 'IoU-189': 2.5713321931852713, 'IoU-190': 2.62181212444872, 'IoU-191': 1.8335290288821102, 'IoU-192': 2.179565913069219, 'mACC': 14.645593350025385, 'pACC': 34.85543560884979, 'ACC-0': nan, 'ACC-1': 98.35067377924875, 'ACC-2': 13.080647165323583, 'ACC-3': 61.14809671150384, 'ACC-4': 38.93155361742813, 'ACC-5': 27.706610820288397, 'ACC-6': 34.768736731184795, 'ACC-7': 16.594287714538872, 'ACC-8': 6.636874324730975, 'ACC-9': 12.277635799918087, 'ACC-10': 37.294449965150974, 'ACC-11': 50.00368354080068, 'ACC-12': 51.1915418546265, 'ACC-13': 48.840531416864344, 'ACC-14': 48.407405432960225, 'ACC-15': 42.90149673542087, 'ACC-16': 35.708118195112974, 'ACC-17': 40.08182087385506, 'ACC-18': 35.131748665186926, 'ACC-19': 31.55387856918207, 'ACC-20': 37.17348177230107, 'ACC-21': 42.31917406291181, 'ACC-22': 37.14099169997257, 'ACC-23': 35.02956929304476, 'ACC-24': 29.879583153434, 'ACC-25': 37.79387680175977, 'ACC-26': 29.731186515155777, 'ACC-27': 33.74034291140586, 'ACC-28': 32.61814916654421, 'ACC-29': 38.88993523508352, 'ACC-30': 38.47953133556793, 'ACC-31': 28.25459854504041, 'ACC-32': 21.827292107757582, 'ACC-33': 34.834436579109614, 'ACC-34': 35.18750109428145, 'ACC-35': 24.028291876971362, 'ACC-36': 29.943092373448543, 'ACC-37': 30.106260262510435, 'ACC-38': 26.90285294246959, 'ACC-39': 32.264475471894805, 'ACC-40': 27.142442836407426, 'ACC-41': 25.948800093076336, 'ACC-42': 28.073303834166936, 'ACC-43': 23.535066871076012, 'ACC-44': 16.923502558045755, 'ACC-45': 24.825658772410563, 'ACC-46': 30.630233271124958, 'ACC-47': 19.41946424989204, 'ACC-48': 24.603029664364946, 'ACC-49': 21.915494487368367, 'ACC-50': 26.064178333680733, 'ACC-51': 25.681503902926984, 'ACC-52': 21.545251867290176, 'ACC-53': 27.378836520417497, 'ACC-54': 28.07379528600698, 'ACC-55': 29.257154367369264, 'ACC-56': 18.407164700298303, 'ACC-57': 21.777947297417946, 'ACC-58': 23.818735216873677, 'ACC-59': 15.183317447414533, 'ACC-60': 25.335444434866705, 'ACC-61': 19.302332297854612, 'ACC-62': 20.032861369918326, 'ACC-63': 22.530664028202644, 'ACC-64': 14.879609939379671, 'ACC-65': 24.219632452258708, 'ACC-66': 12.977615573964515, 'ACC-67': 20.615086347268566, 'ACC-68': 11.083353352503554, 'ACC-69': 15.516830298021226, 'ACC-70': 14.870985178291315, 'ACC-71': 13.538544148073745, 'ACC-72': 11.143677607940509, 'ACC-73': 14.250062650023049, 'ACC-74': 11.728750963885988, 'ACC-75': 13.557028804058799, 'ACC-76': 13.111587128303084, 'ACC-77': 9.915128552711929, 'ACC-78': 9.010036663336862, 'ACC-79': 15.507923529312832, 'ACC-80': 9.87857105496918, 'ACC-81': 10.671599537737238, 'ACC-82': 12.32860837414314, 'ACC-83': 6.754119802396841, 'ACC-84': 9.238650322960847, 'ACC-85': 14.046106672628875, 'ACC-86': 6.3206226539158665, 'ACC-87': 12.330513492853502, 'ACC-88': 8.210789088495039, 'ACC-89': 13.145637837657073, 'ACC-90': 10.50700736377639, 'ACC-91': 10.561367689590766, 'ACC-92': 7.75725325027775, 'ACC-93': 8.41236722166805, 'ACC-94': 8.657274279833889, 'ACC-95': 8.819274150137407, 'ACC-96': 15.081045065262872, 'ACC-97': 11.08061886420575, 'ACC-98': 9.532298803491262, 'ACC-99': 5.571938442171325, 'ACC-100': 12.041224606636517, 'ACC-101': 9.459722028780664, 'ACC-102': 10.14404168554599, 'ACC-103': 7.382426560876547, 'ACC-104': 10.263176016330144, 'ACC-105': 10.284478480806406, 'ACC-106': 5.241879126910267, 'ACC-107': 9.554972825259236, 'ACC-108': 6.6544385170683285, 'ACC-109': 5.81896374540563, 'ACC-110': 9.049735198660471, 'ACC-111': 8.430461681272352, 'ACC-112': 5.2871496837920136, 'ACC-113': 6.516061802438183, 'ACC-114': 10.240900409147677, 'ACC-115': 10.354103709049358, 'ACC-116': 6.830822948288845, 'ACC-117': 10.730418933286828, 'ACC-118': 5.525933819457303, 'ACC-119': 10.079874348980951, 'ACC-120': 9.039908355207906, 'ACC-121': 7.774114325451133, 'ACC-122': 5.924500174549709, 'ACC-123': 6.597255802111437, 'ACC-124': 7.683017589357205, 'ACC-125': 3.3252371478947924, 'ACC-126': 6.997559176313081, 'ACC-127': 9.9888794400471, 'ACC-128': 8.845505073235344, 'ACC-129': 6.965289644123625, 'ACC-130': 3.713403827748728, 'ACC-131': 3.068292757489302, 'ACC-132': 3.670617566929055, 'ACC-133': 5.668415358549878, 'ACC-134': 4.806066350710901, 'ACC-135': 7.814548771449746, 'ACC-136': 5.165334979500559, 'ACC-137': 1.9603622911319272, 'ACC-138': 2.0475067898570956, 'ACC-139': 4.728990213592424, 'ACC-140': 11.202411183278752, 'ACC-141': 4.043834860192649, 'ACC-142': 3.2999988646893046, 'ACC-143': 4.442185985031266, 'ACC-144': 2.9669675090252707, 'ACC-145': 6.525458977168541, 'ACC-146': 3.5241598318521397, 'ACC-147': 3.934509644070519, 'ACC-148': 3.0291307170469874, 'ACC-149': 4.784553616430493, 'ACC-150': 2.8551952295632, 'ACC-151': 1.1647871697558199, 'ACC-152': 0.37763841122125563, 'ACC-153': 0.7042543835541143, 'ACC-154': 3.4541669455315285, 'ACC-155': 0.9050615905320426, 'ACC-156': 6.163909842476423, 'ACC-157': 1.9445158989728242, 'ACC-158': 0.9966819607904018, 'ACC-159': 3.1909313357169387, 'ACC-160': 3.8498733203637516, 'ACC-161': 0.8409697902419981, 'ACC-162': 6.630001100859563, 'ACC-163': 1.3199993273888777, 'ACC-164': 3.5243960058219366, 'ACC-165': 2.0452502485492032, 'ACC-166': 0.942995525933636, 'ACC-167': 2.1800798030806003, 'ACC-168': 1.8696814121949505, 'ACC-169': 0.20424886776991472, 'ACC-170': 1.4115450686429007, 'ACC-171': 0.11829341542847381, 'ACC-172': 1.6072156165499871, 'ACC-173': 0.5207843373357968, 'ACC-174': 0.8559483001261927, 'ACC-175': 0.8249534553939051, 'ACC-176': 0.30310395867192946, 'ACC-177': 0.3689083523877542, 'ACC-178': 1.079752989602307, 'ACC-179': 0.7683396195024762, 'ACC-180': 1.2684564326594194, 'ACC-181': 1.1990117982571455, 'ACC-182': 3.556595883806496, 'ACC-183': 1.1124164510501446, 'ACC-184': 0.4742734371499256, 'ACC-185': 0.4020989519097968, 'ACC-186': 0.935759761858111, 'ACC-187': 3.855325626064582, 'ACC-188': 0.9472983334005891, 'ACC-189': 6.712346702745166, 'ACC-190': 9.711581793600722, 'ACC-191': 5.999608482871126, 'ACC-192': 10.33474733353897})])
[01/19 12:04:38] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 12:04:38] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 12:04:38] d2.evaluation.testing INFO: copypaste: 2.9236,0.3400,0.1460,8.6498,24.4173,14.6456,34.8554
[01/19 12:04:39] d2.utils.events INFO:  eta: 8:29:49  iter: 21999  total_loss: 58.59  loss_ce: 1.797  loss_mask: 0.6204  loss_dice: 3.168  loss_ce_0: 3.139  loss_mask_0: 0.6381  loss_dice_0: 3.465  loss_ce_1: 2.09  loss_mask_1: 0.626  loss_dice_1: 3.297  loss_ce_2: 1.942  loss_mask_2: 0.6189  loss_dice_2: 3.235  loss_ce_3: 1.862  loss_mask_3: 0.6146  loss_dice_3: 3.189  loss_ce_4: 1.833  loss_mask_4: 0.6134  loss_dice_4: 3.188  loss_ce_5: 1.821  loss_mask_5: 0.617  loss_dice_5: 3.189  loss_ce_6: 1.8  loss_mask_6: 0.6191  loss_dice_6: 3.175  loss_ce_7: 1.796  loss_mask_7: 0.6188  loss_dice_7: 3.166  loss_ce_8: 1.813  loss_mask_8: 0.6183  loss_dice_8: 3.171  time: 1.6943  data_time: 0.3645  lr: 4.8743e-06  max_mem: 17674M
[01/19 12:05:13] d2.utils.events INFO:  eta: 8:29:15  iter: 22019  total_loss: 57.91  loss_ce: 1.772  loss_mask: 0.6206  loss_dice: 3.127  loss_ce_0: 3.178  loss_mask_0: 0.6316  loss_dice_0: 3.45  loss_ce_1: 2.053  loss_mask_1: 0.6201  loss_dice_1: 3.285  loss_ce_2: 1.922  loss_mask_2: 0.6232  loss_dice_2: 3.208  loss_ce_3: 1.877  loss_mask_3: 0.6199  loss_dice_3: 3.15  loss_ce_4: 1.839  loss_mask_4: 0.6225  loss_dice_4: 3.148  loss_ce_5: 1.826  loss_mask_5: 0.6203  loss_dice_5: 3.144  loss_ce_6: 1.801  loss_mask_6: 0.6186  loss_dice_6: 3.13  loss_ce_7: 1.788  loss_mask_7: 0.6221  loss_dice_7: 3.132  loss_ce_8: 1.777  loss_mask_8: 0.6242  loss_dice_8: 3.127  time: 1.6943  data_time: 0.3466  lr: 4.8694e-06  max_mem: 17674M
[01/19 12:05:47] d2.utils.events INFO:  eta: 8:28:59  iter: 22039  total_loss: 58.23  loss_ce: 1.791  loss_mask: 0.6244  loss_dice: 3.174  loss_ce_0: 3.141  loss_mask_0: 0.6488  loss_dice_0: 3.472  loss_ce_1: 2.044  loss_mask_1: 0.6334  loss_dice_1: 3.303  loss_ce_2: 1.954  loss_mask_2: 0.6306  loss_dice_2: 3.252  loss_ce_3: 1.864  loss_mask_3: 0.6243  loss_dice_3: 3.204  loss_ce_4: 1.832  loss_mask_4: 0.6235  loss_dice_4: 3.194  loss_ce_5: 1.825  loss_mask_5: 0.6251  loss_dice_5: 3.194  loss_ce_6: 1.792  loss_mask_6: 0.6231  loss_dice_6: 3.187  loss_ce_7: 1.776  loss_mask_7: 0.6227  loss_dice_7: 3.179  loss_ce_8: 1.804  loss_mask_8: 0.6248  loss_dice_8: 3.176  time: 1.6943  data_time: 0.3453  lr: 4.8646e-06  max_mem: 17674M
[01/19 12:06:21] d2.utils.events INFO:  eta: 8:28:26  iter: 22059  total_loss: 58.47  loss_ce: 1.751  loss_mask: 0.6186  loss_dice: 3.197  loss_ce_0: 3.222  loss_mask_0: 0.6347  loss_dice_0: 3.471  loss_ce_1: 2.039  loss_mask_1: 0.6164  loss_dice_1: 3.324  loss_ce_2: 1.92  loss_mask_2: 0.6168  loss_dice_2: 3.26  loss_ce_3: 1.854  loss_mask_3: 0.6159  loss_dice_3: 3.22  loss_ce_4: 1.798  loss_mask_4: 0.6175  loss_dice_4: 3.218  loss_ce_5: 1.77  loss_mask_5: 0.62  loss_dice_5: 3.211  loss_ce_6: 1.777  loss_mask_6: 0.6189  loss_dice_6: 3.204  loss_ce_7: 1.749  loss_mask_7: 0.6197  loss_dice_7: 3.202  loss_ce_8: 1.754  loss_mask_8: 0.62  loss_dice_8: 3.196  time: 1.6943  data_time: 0.3467  lr: 4.8597e-06  max_mem: 17674M
[01/19 12:06:55] d2.utils.events INFO:  eta: 8:27:41  iter: 22079  total_loss: 58.69  loss_ce: 1.79  loss_mask: 0.627  loss_dice: 3.198  loss_ce_0: 3.133  loss_mask_0: 0.6508  loss_dice_0: 3.504  loss_ce_1: 2.089  loss_mask_1: 0.6355  loss_dice_1: 3.33  loss_ce_2: 1.925  loss_mask_2: 0.6288  loss_dice_2: 3.266  loss_ce_3: 1.875  loss_mask_3: 0.6291  loss_dice_3: 3.225  loss_ce_4: 1.818  loss_mask_4: 0.629  loss_dice_4: 3.217  loss_ce_5: 1.811  loss_mask_5: 0.631  loss_dice_5: 3.214  loss_ce_6: 1.776  loss_mask_6: 0.6276  loss_dice_6: 3.201  loss_ce_7: 1.78  loss_mask_7: 0.6281  loss_dice_7: 3.196  loss_ce_8: 1.78  loss_mask_8: 0.6268  loss_dice_8: 3.201  time: 1.6943  data_time: 0.3410  lr: 4.8548e-06  max_mem: 17674M
[01/19 12:07:29] d2.utils.events INFO:  eta: 8:26:43  iter: 22099  total_loss: 58.46  loss_ce: 1.767  loss_mask: 0.6159  loss_dice: 3.208  loss_ce_0: 3.187  loss_mask_0: 0.6302  loss_dice_0: 3.493  loss_ce_1: 2.054  loss_mask_1: 0.6166  loss_dice_1: 3.343  loss_ce_2: 1.913  loss_mask_2: 0.6127  loss_dice_2: 3.274  loss_ce_3: 1.857  loss_mask_3: 0.6166  loss_dice_3: 3.228  loss_ce_4: 1.805  loss_mask_4: 0.6142  loss_dice_4: 3.228  loss_ce_5: 1.786  loss_mask_5: 0.6154  loss_dice_5: 3.221  loss_ce_6: 1.777  loss_mask_6: 0.6135  loss_dice_6: 3.212  loss_ce_7: 1.777  loss_mask_7: 0.6139  loss_dice_7: 3.207  loss_ce_8: 1.772  loss_mask_8: 0.6136  loss_dice_8: 3.212  time: 1.6943  data_time: 0.3543  lr: 4.8499e-06  max_mem: 17674M
[01/19 12:08:03] d2.utils.events INFO:  eta: 8:26:00  iter: 22119  total_loss: 58.95  loss_ce: 1.855  loss_mask: 0.6388  loss_dice: 3.157  loss_ce_0: 3.137  loss_mask_0: 0.6596  loss_dice_0: 3.45  loss_ce_1: 2.103  loss_mask_1: 0.6456  loss_dice_1: 3.292  loss_ce_2: 1.963  loss_mask_2: 0.6443  loss_dice_2: 3.222  loss_ce_3: 1.912  loss_mask_3: 0.6357  loss_dice_3: 3.185  loss_ce_4: 1.86  loss_mask_4: 0.6343  loss_dice_4: 3.182  loss_ce_5: 1.844  loss_mask_5: 0.633  loss_dice_5: 3.185  loss_ce_6: 1.854  loss_mask_6: 0.6357  loss_dice_6: 3.161  loss_ce_7: 1.849  loss_mask_7: 0.6358  loss_dice_7: 3.159  loss_ce_8: 1.842  loss_mask_8: 0.6389  loss_dice_8: 3.16  time: 1.6943  data_time: 0.3493  lr: 4.8451e-06  max_mem: 17674M
[01/19 12:08:36] d2.utils.events INFO:  eta: 8:25:26  iter: 22139  total_loss: 58.92  loss_ce: 1.788  loss_mask: 0.634  loss_dice: 3.176  loss_ce_0: 3.071  loss_mask_0: 0.6666  loss_dice_0: 3.484  loss_ce_1: 2.114  loss_mask_1: 0.643  loss_dice_1: 3.31  loss_ce_2: 1.961  loss_mask_2: 0.6384  loss_dice_2: 3.239  loss_ce_3: 1.879  loss_mask_3: 0.634  loss_dice_3: 3.193  loss_ce_4: 1.832  loss_mask_4: 0.6322  loss_dice_4: 3.192  loss_ce_5: 1.81  loss_mask_5: 0.6369  loss_dice_5: 3.189  loss_ce_6: 1.812  loss_mask_6: 0.6356  loss_dice_6: 3.179  loss_ce_7: 1.797  loss_mask_7: 0.636  loss_dice_7: 3.182  loss_ce_8: 1.791  loss_mask_8: 0.6346  loss_dice_8: 3.18  time: 1.6943  data_time: 0.3583  lr: 4.8402e-06  max_mem: 17674M
[01/19 12:09:10] d2.utils.events INFO:  eta: 8:24:51  iter: 22159  total_loss: 58.52  loss_ce: 1.773  loss_mask: 0.6275  loss_dice: 3.185  loss_ce_0: 3.166  loss_mask_0: 0.6518  loss_dice_0: 3.497  loss_ce_1: 2.033  loss_mask_1: 0.6349  loss_dice_1: 3.329  loss_ce_2: 1.913  loss_mask_2: 0.6268  loss_dice_2: 3.266  loss_ce_3: 1.866  loss_mask_3: 0.6285  loss_dice_3: 3.213  loss_ce_4: 1.818  loss_mask_4: 0.628  loss_dice_4: 3.205  loss_ce_5: 1.802  loss_mask_5: 0.6263  loss_dice_5: 3.203  loss_ce_6: 1.782  loss_mask_6: 0.6255  loss_dice_6: 3.192  loss_ce_7: 1.771  loss_mask_7: 0.6284  loss_dice_7: 3.19  loss_ce_8: 1.778  loss_mask_8: 0.6277  loss_dice_8: 3.191  time: 1.6943  data_time: 0.3421  lr: 4.8353e-06  max_mem: 17674M
[01/19 12:09:44] d2.utils.events INFO:  eta: 8:23:57  iter: 22179  total_loss: 58.89  loss_ce: 1.774  loss_mask: 0.6348  loss_dice: 3.201  loss_ce_0: 3.118  loss_mask_0: 0.6595  loss_dice_0: 3.496  loss_ce_1: 2.042  loss_mask_1: 0.6432  loss_dice_1: 3.324  loss_ce_2: 1.916  loss_mask_2: 0.6371  loss_dice_2: 3.268  loss_ce_3: 1.84  loss_mask_3: 0.634  loss_dice_3: 3.226  loss_ce_4: 1.788  loss_mask_4: 0.6353  loss_dice_4: 3.232  loss_ce_5: 1.781  loss_mask_5: 0.6339  loss_dice_5: 3.221  loss_ce_6: 1.776  loss_mask_6: 0.6355  loss_dice_6: 3.213  loss_ce_7: 1.767  loss_mask_7: 0.6365  loss_dice_7: 3.204  loss_ce_8: 1.76  loss_mask_8: 0.6375  loss_dice_8: 3.205  time: 1.6943  data_time: 0.3379  lr: 4.8304e-06  max_mem: 17674M
[01/19 12:10:17] d2.utils.events INFO:  eta: 8:23:23  iter: 22199  total_loss: 58.38  loss_ce: 1.762  loss_mask: 0.6261  loss_dice: 3.145  loss_ce_0: 3.17  loss_mask_0: 0.6446  loss_dice_0: 3.446  loss_ce_1: 2.026  loss_mask_1: 0.6308  loss_dice_1: 3.271  loss_ce_2: 1.893  loss_mask_2: 0.6288  loss_dice_2: 3.201  loss_ce_3: 1.852  loss_mask_3: 0.6219  loss_dice_3: 3.171  loss_ce_4: 1.799  loss_mask_4: 0.626  loss_dice_4: 3.161  loss_ce_5: 1.786  loss_mask_5: 0.6314  loss_dice_5: 3.154  loss_ce_6: 1.77  loss_mask_6: 0.6294  loss_dice_6: 3.153  loss_ce_7: 1.76  loss_mask_7: 0.6266  loss_dice_7: 3.149  loss_ce_8: 1.762  loss_mask_8: 0.6289  loss_dice_8: 3.147  time: 1.6943  data_time: 0.3177  lr: 4.8255e-06  max_mem: 17674M
[01/19 12:10:51] d2.utils.events INFO:  eta: 8:23:02  iter: 22219  total_loss: 58.57  loss_ce: 1.782  loss_mask: 0.6304  loss_dice: 3.229  loss_ce_0: 3.144  loss_mask_0: 0.6488  loss_dice_0: 3.507  loss_ce_1: 2.08  loss_mask_1: 0.6293  loss_dice_1: 3.367  loss_ce_2: 1.945  loss_mask_2: 0.6256  loss_dice_2: 3.287  loss_ce_3: 1.881  loss_mask_3: 0.6254  loss_dice_3: 3.247  loss_ce_4: 1.84  loss_mask_4: 0.6257  loss_dice_4: 3.255  loss_ce_5: 1.815  loss_mask_5: 0.6296  loss_dice_5: 3.249  loss_ce_6: 1.815  loss_mask_6: 0.6306  loss_dice_6: 3.243  loss_ce_7: 1.797  loss_mask_7: 0.6304  loss_dice_7: 3.237  loss_ce_8: 1.805  loss_mask_8: 0.6316  loss_dice_8: 3.238  time: 1.6943  data_time: 0.3321  lr: 4.8207e-06  max_mem: 17674M
[01/19 12:11:25] d2.utils.events INFO:  eta: 8:22:12  iter: 22239  total_loss: 58.67  loss_ce: 1.771  loss_mask: 0.6257  loss_dice: 3.224  loss_ce_0: 3.138  loss_mask_0: 0.6503  loss_dice_0: 3.514  loss_ce_1: 2.006  loss_mask_1: 0.6311  loss_dice_1: 3.356  loss_ce_2: 1.895  loss_mask_2: 0.6231  loss_dice_2: 3.308  loss_ce_3: 1.863  loss_mask_3: 0.6229  loss_dice_3: 3.256  loss_ce_4: 1.825  loss_mask_4: 0.6247  loss_dice_4: 3.25  loss_ce_5: 1.8  loss_mask_5: 0.6261  loss_dice_5: 3.248  loss_ce_6: 1.779  loss_mask_6: 0.6248  loss_dice_6: 3.234  loss_ce_7: 1.756  loss_mask_7: 0.626  loss_dice_7: 3.234  loss_ce_8: 1.754  loss_mask_8: 0.6242  loss_dice_8: 3.226  time: 1.6943  data_time: 0.3549  lr: 4.8158e-06  max_mem: 17674M
[01/19 12:11:59] d2.utils.events INFO:  eta: 8:21:38  iter: 22259  total_loss: 58.75  loss_ce: 1.805  loss_mask: 0.6157  loss_dice: 3.186  loss_ce_0: 3.107  loss_mask_0: 0.6301  loss_dice_0: 3.482  loss_ce_1: 2.09  loss_mask_1: 0.6165  loss_dice_1: 3.321  loss_ce_2: 1.96  loss_mask_2: 0.6134  loss_dice_2: 3.251  loss_ce_3: 1.905  loss_mask_3: 0.6117  loss_dice_3: 3.2  loss_ce_4: 1.848  loss_mask_4: 0.6113  loss_dice_4: 3.194  loss_ce_5: 1.812  loss_mask_5: 0.612  loss_dice_5: 3.194  loss_ce_6: 1.803  loss_mask_6: 0.6108  loss_dice_6: 3.187  loss_ce_7: 1.79  loss_mask_7: 0.614  loss_dice_7: 3.186  loss_ce_8: 1.791  loss_mask_8: 0.6152  loss_dice_8: 3.183  time: 1.6943  data_time: 0.3520  lr: 4.8109e-06  max_mem: 17674M
[01/19 12:12:33] d2.utils.events INFO:  eta: 8:20:48  iter: 22279  total_loss: 58.71  loss_ce: 1.812  loss_mask: 0.6296  loss_dice: 3.207  loss_ce_0: 3.123  loss_mask_0: 0.6436  loss_dice_0: 3.504  loss_ce_1: 2.066  loss_mask_1: 0.6327  loss_dice_1: 3.338  loss_ce_2: 1.961  loss_mask_2: 0.632  loss_dice_2: 3.272  loss_ce_3: 1.872  loss_mask_3: 0.6282  loss_dice_3: 3.23  loss_ce_4: 1.836  loss_mask_4: 0.6308  loss_dice_4: 3.224  loss_ce_5: 1.811  loss_mask_5: 0.6307  loss_dice_5: 3.222  loss_ce_6: 1.819  loss_mask_6: 0.6288  loss_dice_6: 3.211  loss_ce_7: 1.804  loss_mask_7: 0.6297  loss_dice_7: 3.208  loss_ce_8: 1.799  loss_mask_8: 0.6273  loss_dice_8: 3.21  time: 1.6943  data_time: 0.3436  lr: 4.806e-06  max_mem: 17674M
[01/19 12:13:07] d2.utils.events INFO:  eta: 8:20:12  iter: 22299  total_loss: 58.62  loss_ce: 1.786  loss_mask: 0.6323  loss_dice: 3.192  loss_ce_0: 3.116  loss_mask_0: 0.6543  loss_dice_0: 3.499  loss_ce_1: 2.081  loss_mask_1: 0.6341  loss_dice_1: 3.33  loss_ce_2: 1.938  loss_mask_2: 0.6282  loss_dice_2: 3.271  loss_ce_3: 1.908  loss_mask_3: 0.6285  loss_dice_3: 3.219  loss_ce_4: 1.839  loss_mask_4: 0.6303  loss_dice_4: 3.206  loss_ce_5: 1.792  loss_mask_5: 0.6284  loss_dice_5: 3.212  loss_ce_6: 1.79  loss_mask_6: 0.6318  loss_dice_6: 3.198  loss_ce_7: 1.783  loss_mask_7: 0.628  loss_dice_7: 3.199  loss_ce_8: 1.768  loss_mask_8: 0.6295  loss_dice_8: 3.199  time: 1.6943  data_time: 0.3417  lr: 4.8011e-06  max_mem: 17674M
[01/19 12:13:41] d2.utils.events INFO:  eta: 8:19:41  iter: 22319  total_loss: 58.22  loss_ce: 1.728  loss_mask: 0.6292  loss_dice: 3.204  loss_ce_0: 3.17  loss_mask_0: 0.6454  loss_dice_0: 3.493  loss_ce_1: 1.995  loss_mask_1: 0.6313  loss_dice_1: 3.336  loss_ce_2: 1.888  loss_mask_2: 0.6285  loss_dice_2: 3.262  loss_ce_3: 1.829  loss_mask_3: 0.6263  loss_dice_3: 3.227  loss_ce_4: 1.764  loss_mask_4: 0.6296  loss_dice_4: 3.218  loss_ce_5: 1.758  loss_mask_5: 0.6279  loss_dice_5: 3.221  loss_ce_6: 1.764  loss_mask_6: 0.6289  loss_dice_6: 3.206  loss_ce_7: 1.729  loss_mask_7: 0.6301  loss_dice_7: 3.208  loss_ce_8: 1.736  loss_mask_8: 0.6289  loss_dice_8: 3.204  time: 1.6943  data_time: 0.3528  lr: 4.7963e-06  max_mem: 17674M
[01/19 12:14:15] d2.utils.events INFO:  eta: 8:19:06  iter: 22339  total_loss: 57.73  loss_ce: 1.748  loss_mask: 0.6191  loss_dice: 3.181  loss_ce_0: 3.116  loss_mask_0: 0.6388  loss_dice_0: 3.495  loss_ce_1: 2.036  loss_mask_1: 0.6252  loss_dice_1: 3.326  loss_ce_2: 1.914  loss_mask_2: 0.6199  loss_dice_2: 3.263  loss_ce_3: 1.847  loss_mask_3: 0.6127  loss_dice_3: 3.212  loss_ce_4: 1.793  loss_mask_4: 0.6133  loss_dice_4: 3.197  loss_ce_5: 1.771  loss_mask_5: 0.6172  loss_dice_5: 3.201  loss_ce_6: 1.758  loss_mask_6: 0.616  loss_dice_6: 3.186  loss_ce_7: 1.749  loss_mask_7: 0.6155  loss_dice_7: 3.193  loss_ce_8: 1.754  loss_mask_8: 0.6187  loss_dice_8: 3.181  time: 1.6943  data_time: 0.3400  lr: 4.7914e-06  max_mem: 17674M
[01/19 12:14:49] d2.utils.events INFO:  eta: 8:18:14  iter: 22359  total_loss: 58.74  loss_ce: 1.796  loss_mask: 0.6434  loss_dice: 3.209  loss_ce_0: 3.17  loss_mask_0: 0.6623  loss_dice_0: 3.503  loss_ce_1: 2.127  loss_mask_1: 0.652  loss_dice_1: 3.335  loss_ce_2: 1.968  loss_mask_2: 0.6484  loss_dice_2: 3.268  loss_ce_3: 1.895  loss_mask_3: 0.6414  loss_dice_3: 3.231  loss_ce_4: 1.834  loss_mask_4: 0.6411  loss_dice_4: 3.222  loss_ce_5: 1.814  loss_mask_5: 0.6408  loss_dice_5: 3.223  loss_ce_6: 1.809  loss_mask_6: 0.6397  loss_dice_6: 3.215  loss_ce_7: 1.785  loss_mask_7: 0.6426  loss_dice_7: 3.209  loss_ce_8: 1.786  loss_mask_8: 0.6454  loss_dice_8: 3.212  time: 1.6943  data_time: 0.3473  lr: 4.7865e-06  max_mem: 17674M
[01/19 12:15:23] d2.utils.events INFO:  eta: 8:17:39  iter: 22379  total_loss: 58.47  loss_ce: 1.793  loss_mask: 0.6081  loss_dice: 3.218  loss_ce_0: 3.151  loss_mask_0: 0.635  loss_dice_0: 3.509  loss_ce_1: 2.079  loss_mask_1: 0.6193  loss_dice_1: 3.358  loss_ce_2: 1.956  loss_mask_2: 0.6122  loss_dice_2: 3.288  loss_ce_3: 1.902  loss_mask_3: 0.6099  loss_dice_3: 3.233  loss_ce_4: 1.832  loss_mask_4: 0.609  loss_dice_4: 3.238  loss_ce_5: 1.804  loss_mask_5: 0.6074  loss_dice_5: 3.236  loss_ce_6: 1.804  loss_mask_6: 0.6088  loss_dice_6: 3.22  loss_ce_7: 1.798  loss_mask_7: 0.6082  loss_dice_7: 3.218  loss_ce_8: 1.773  loss_mask_8: 0.6068  loss_dice_8: 3.221  time: 1.6943  data_time: 0.3471  lr: 4.7816e-06  max_mem: 17674M
[01/19 12:15:57] d2.utils.events INFO:  eta: 8:17:10  iter: 22399  total_loss: 57.7  loss_ce: 1.691  loss_mask: 0.6046  loss_dice: 3.186  loss_ce_0: 3.137  loss_mask_0: 0.621  loss_dice_0: 3.482  loss_ce_1: 1.965  loss_mask_1: 0.6085  loss_dice_1: 3.319  loss_ce_2: 1.852  loss_mask_2: 0.6028  loss_dice_2: 3.25  loss_ce_3: 1.793  loss_mask_3: 0.6055  loss_dice_3: 3.201  loss_ce_4: 1.78  loss_mask_4: 0.6061  loss_dice_4: 3.196  loss_ce_5: 1.726  loss_mask_5: 0.6037  loss_dice_5: 3.201  loss_ce_6: 1.73  loss_mask_6: 0.6056  loss_dice_6: 3.184  loss_ce_7: 1.721  loss_mask_7: 0.6076  loss_dice_7: 3.183  loss_ce_8: 1.707  loss_mask_8: 0.6082  loss_dice_8: 3.18  time: 1.6943  data_time: 0.3359  lr: 4.7767e-06  max_mem: 17674M
[01/19 12:16:31] d2.utils.events INFO:  eta: 8:16:52  iter: 22419  total_loss: 57.49  loss_ce: 1.689  loss_mask: 0.6247  loss_dice: 3.15  loss_ce_0: 3.061  loss_mask_0: 0.6542  loss_dice_0: 3.479  loss_ce_1: 1.963  loss_mask_1: 0.634  loss_dice_1: 3.292  loss_ce_2: 1.832  loss_mask_2: 0.6316  loss_dice_2: 3.221  loss_ce_3: 1.768  loss_mask_3: 0.6244  loss_dice_3: 3.175  loss_ce_4: 1.743  loss_mask_4: 0.627  loss_dice_4: 3.168  loss_ce_5: 1.72  loss_mask_5: 0.6242  loss_dice_5: 3.166  loss_ce_6: 1.72  loss_mask_6: 0.6234  loss_dice_6: 3.162  loss_ce_7: 1.703  loss_mask_7: 0.624  loss_dice_7: 3.155  loss_ce_8: 1.687  loss_mask_8: 0.6213  loss_dice_8: 3.15  time: 1.6943  data_time: 0.3378  lr: 4.7718e-06  max_mem: 17674M
[01/19 12:17:05] d2.utils.events INFO:  eta: 8:16:02  iter: 22439  total_loss: 58.27  loss_ce: 1.718  loss_mask: 0.6362  loss_dice: 3.172  loss_ce_0: 3.129  loss_mask_0: 0.6594  loss_dice_0: 3.484  loss_ce_1: 2.002  loss_mask_1: 0.6452  loss_dice_1: 3.31  loss_ce_2: 1.88  loss_mask_2: 0.6475  loss_dice_2: 3.242  loss_ce_3: 1.806  loss_mask_3: 0.6387  loss_dice_3: 3.198  loss_ce_4: 1.765  loss_mask_4: 0.6369  loss_dice_4: 3.188  loss_ce_5: 1.748  loss_mask_5: 0.6347  loss_dice_5: 3.188  loss_ce_6: 1.735  loss_mask_6: 0.6364  loss_dice_6: 3.176  loss_ce_7: 1.728  loss_mask_7: 0.639  loss_dice_7: 3.174  loss_ce_8: 1.713  loss_mask_8: 0.6383  loss_dice_8: 3.173  time: 1.6943  data_time: 0.3218  lr: 4.7669e-06  max_mem: 17674M
[01/19 12:17:39] d2.utils.events INFO:  eta: 8:15:44  iter: 22459  total_loss: 57.23  loss_ce: 1.648  loss_mask: 0.6  loss_dice: 3.198  loss_ce_0: 3.09  loss_mask_0: 0.6223  loss_dice_0: 3.498  loss_ce_1: 1.957  loss_mask_1: 0.6001  loss_dice_1: 3.327  loss_ce_2: 1.805  loss_mask_2: 0.6017  loss_dice_2: 3.265  loss_ce_3: 1.744  loss_mask_3: 0.5977  loss_dice_3: 3.226  loss_ce_4: 1.714  loss_mask_4: 0.5959  loss_dice_4: 3.219  loss_ce_5: 1.664  loss_mask_5: 0.5981  loss_dice_5: 3.219  loss_ce_6: 1.655  loss_mask_6: 0.5939  loss_dice_6: 3.204  loss_ce_7: 1.629  loss_mask_7: 0.5937  loss_dice_7: 3.202  loss_ce_8: 1.63  loss_mask_8: 0.5993  loss_dice_8: 3.198  time: 1.6943  data_time: 0.3591  lr: 4.7621e-06  max_mem: 17674M
[01/19 12:18:13] d2.utils.events INFO:  eta: 8:14:54  iter: 22479  total_loss: 57.7  loss_ce: 1.695  loss_mask: 0.6288  loss_dice: 3.205  loss_ce_0: 3.03  loss_mask_0: 0.6406  loss_dice_0: 3.486  loss_ce_1: 1.94  loss_mask_1: 0.6277  loss_dice_1: 3.336  loss_ce_2: 1.856  loss_mask_2: 0.6247  loss_dice_2: 3.271  loss_ce_3: 1.786  loss_mask_3: 0.6262  loss_dice_3: 3.23  loss_ce_4: 1.738  loss_mask_4: 0.6276  loss_dice_4: 3.222  loss_ce_5: 1.705  loss_mask_5: 0.6275  loss_dice_5: 3.225  loss_ce_6: 1.723  loss_mask_6: 0.6278  loss_dice_6: 3.213  loss_ce_7: 1.704  loss_mask_7: 0.6295  loss_dice_7: 3.214  loss_ce_8: 1.682  loss_mask_8: 0.6297  loss_dice_8: 3.21  time: 1.6943  data_time: 0.3502  lr: 4.7572e-06  max_mem: 17674M
[01/19 12:18:47] d2.utils.events INFO:  eta: 8:14:07  iter: 22499  total_loss: 57.77  loss_ce: 1.65  loss_mask: 0.6152  loss_dice: 3.207  loss_ce_0: 3.061  loss_mask_0: 0.6331  loss_dice_0: 3.493  loss_ce_1: 1.996  loss_mask_1: 0.619  loss_dice_1: 3.329  loss_ce_2: 1.803  loss_mask_2: 0.6182  loss_dice_2: 3.271  loss_ce_3: 1.737  loss_mask_3: 0.6146  loss_dice_3: 3.231  loss_ce_4: 1.691  loss_mask_4: 0.6128  loss_dice_4: 3.227  loss_ce_5: 1.678  loss_mask_5: 0.6147  loss_dice_5: 3.223  loss_ce_6: 1.659  loss_mask_6: 0.6156  loss_dice_6: 3.208  loss_ce_7: 1.642  loss_mask_7: 0.6146  loss_dice_7: 3.214  loss_ce_8: 1.64  loss_mask_8: 0.6154  loss_dice_8: 3.208  time: 1.6943  data_time: 0.3365  lr: 4.7523e-06  max_mem: 17674M
[01/19 12:19:21] d2.utils.events INFO:  eta: 8:13:31  iter: 22519  total_loss: 58.54  loss_ce: 1.791  loss_mask: 0.6306  loss_dice: 3.183  loss_ce_0: 3.123  loss_mask_0: 0.659  loss_dice_0: 3.485  loss_ce_1: 2.105  loss_mask_1: 0.6362  loss_dice_1: 3.309  loss_ce_2: 1.979  loss_mask_2: 0.6277  loss_dice_2: 3.239  loss_ce_3: 1.941  loss_mask_3: 0.6278  loss_dice_3: 3.208  loss_ce_4: 1.871  loss_mask_4: 0.6266  loss_dice_4: 3.212  loss_ce_5: 1.839  loss_mask_5: 0.6291  loss_dice_5: 3.2  loss_ce_6: 1.814  loss_mask_6: 0.6281  loss_dice_6: 3.196  loss_ce_7: 1.798  loss_mask_7: 0.6293  loss_dice_7: 3.196  loss_ce_8: 1.8  loss_mask_8: 0.629  loss_dice_8: 3.189  time: 1.6943  data_time: 0.3448  lr: 4.7474e-06  max_mem: 17674M
[01/19 12:19:55] d2.utils.events INFO:  eta: 8:12:59  iter: 22539  total_loss: 57.65  loss_ce: 1.656  loss_mask: 0.6256  loss_dice: 3.252  loss_ce_0: 3.137  loss_mask_0: 0.6412  loss_dice_0: 3.515  loss_ce_1: 2.004  loss_mask_1: 0.6266  loss_dice_1: 3.381  loss_ce_2: 1.833  loss_mask_2: 0.6201  loss_dice_2: 3.316  loss_ce_3: 1.763  loss_mask_3: 0.6235  loss_dice_3: 3.271  loss_ce_4: 1.714  loss_mask_4: 0.6248  loss_dice_4: 3.267  loss_ce_5: 1.674  loss_mask_5: 0.6278  loss_dice_5: 3.266  loss_ce_6: 1.687  loss_mask_6: 0.6234  loss_dice_6: 3.257  loss_ce_7: 1.664  loss_mask_7: 0.6249  loss_dice_7: 3.249  loss_ce_8: 1.659  loss_mask_8: 0.6259  loss_dice_8: 3.255  time: 1.6943  data_time: 0.3355  lr: 4.7425e-06  max_mem: 17674M
[01/19 12:20:29] d2.utils.events INFO:  eta: 8:12:33  iter: 22559  total_loss: 58.01  loss_ce: 1.784  loss_mask: 0.6158  loss_dice: 3.181  loss_ce_0: 3.112  loss_mask_0: 0.6424  loss_dice_0: 3.45  loss_ce_1: 2.107  loss_mask_1: 0.6225  loss_dice_1: 3.292  loss_ce_2: 1.945  loss_mask_2: 0.6209  loss_dice_2: 3.234  loss_ce_3: 1.861  loss_mask_3: 0.6158  loss_dice_3: 3.195  loss_ce_4: 1.821  loss_mask_4: 0.6138  loss_dice_4: 3.199  loss_ce_5: 1.799  loss_mask_5: 0.6133  loss_dice_5: 3.192  loss_ce_6: 1.8  loss_mask_6: 0.6154  loss_dice_6: 3.186  loss_ce_7: 1.768  loss_mask_7: 0.6162  loss_dice_7: 3.188  loss_ce_8: 1.768  loss_mask_8: 0.6161  loss_dice_8: 3.185  time: 1.6943  data_time: 0.3482  lr: 4.7376e-06  max_mem: 17674M
[01/19 12:21:03] d2.utils.events INFO:  eta: 8:11:50  iter: 22579  total_loss: 58.57  loss_ce: 1.781  loss_mask: 0.6296  loss_dice: 3.206  loss_ce_0: 3.046  loss_mask_0: 0.6448  loss_dice_0: 3.517  loss_ce_1: 2.091  loss_mask_1: 0.6286  loss_dice_1: 3.352  loss_ce_2: 1.934  loss_mask_2: 0.6247  loss_dice_2: 3.28  loss_ce_3: 1.887  loss_mask_3: 0.6242  loss_dice_3: 3.232  loss_ce_4: 1.847  loss_mask_4: 0.6249  loss_dice_4: 3.225  loss_ce_5: 1.831  loss_mask_5: 0.6302  loss_dice_5: 3.222  loss_ce_6: 1.79  loss_mask_6: 0.6291  loss_dice_6: 3.213  loss_ce_7: 1.785  loss_mask_7: 0.6305  loss_dice_7: 3.21  loss_ce_8: 1.787  loss_mask_8: 0.6286  loss_dice_8: 3.213  time: 1.6943  data_time: 0.3451  lr: 4.7327e-06  max_mem: 17674M
[01/19 12:21:36] d2.utils.events INFO:  eta: 8:11:16  iter: 22599  total_loss: 58.22  loss_ce: 1.755  loss_mask: 0.6336  loss_dice: 3.173  loss_ce_0: 3.137  loss_mask_0: 0.6553  loss_dice_0: 3.47  loss_ce_1: 2.039  loss_mask_1: 0.6373  loss_dice_1: 3.318  loss_ce_2: 1.923  loss_mask_2: 0.6373  loss_dice_2: 3.242  loss_ce_3: 1.887  loss_mask_3: 0.6346  loss_dice_3: 3.196  loss_ce_4: 1.809  loss_mask_4: 0.6323  loss_dice_4: 3.197  loss_ce_5: 1.773  loss_mask_5: 0.6335  loss_dice_5: 3.193  loss_ce_6: 1.795  loss_mask_6: 0.633  loss_dice_6: 3.188  loss_ce_7: 1.772  loss_mask_7: 0.6338  loss_dice_7: 3.183  loss_ce_8: 1.75  loss_mask_8: 0.633  loss_dice_8: 3.178  time: 1.6943  data_time: 0.3527  lr: 4.7278e-06  max_mem: 17674M
[01/19 12:22:10] d2.utils.events INFO:  eta: 8:10:35  iter: 22619  total_loss: 58.53  loss_ce: 1.749  loss_mask: 0.6222  loss_dice: 3.185  loss_ce_0: 3.088  loss_mask_0: 0.6399  loss_dice_0: 3.49  loss_ce_1: 2.062  loss_mask_1: 0.6234  loss_dice_1: 3.316  loss_ce_2: 1.925  loss_mask_2: 0.6221  loss_dice_2: 3.253  loss_ce_3: 1.869  loss_mask_3: 0.622  loss_dice_3: 3.213  loss_ce_4: 1.821  loss_mask_4: 0.6231  loss_dice_4: 3.207  loss_ce_5: 1.795  loss_mask_5: 0.6228  loss_dice_5: 3.205  loss_ce_6: 1.779  loss_mask_6: 0.6199  loss_dice_6: 3.184  loss_ce_7: 1.76  loss_mask_7: 0.6225  loss_dice_7: 3.189  loss_ce_8: 1.764  loss_mask_8: 0.6218  loss_dice_8: 3.182  time: 1.6943  data_time: 0.3594  lr: 4.7229e-06  max_mem: 17674M
[01/19 12:22:44] d2.utils.events INFO:  eta: 8:09:59  iter: 22639  total_loss: 58.01  loss_ce: 1.764  loss_mask: 0.6289  loss_dice: 3.184  loss_ce_0: 3.135  loss_mask_0: 0.655  loss_dice_0: 3.45  loss_ce_1: 2.028  loss_mask_1: 0.6273  loss_dice_1: 3.306  loss_ce_2: 1.902  loss_mask_2: 0.6294  loss_dice_2: 3.24  loss_ce_3: 1.883  loss_mask_3: 0.6259  loss_dice_3: 3.2  loss_ce_4: 1.82  loss_mask_4: 0.6228  loss_dice_4: 3.201  loss_ce_5: 1.783  loss_mask_5: 0.623  loss_dice_5: 3.198  loss_ce_6: 1.784  loss_mask_6: 0.626  loss_dice_6: 3.185  loss_ce_7: 1.774  loss_mask_7: 0.626  loss_dice_7: 3.189  loss_ce_8: 1.757  loss_mask_8: 0.628  loss_dice_8: 3.185  time: 1.6943  data_time: 0.3439  lr: 4.7181e-06  max_mem: 17674M
[01/19 12:23:18] d2.utils.events INFO:  eta: 8:09:20  iter: 22659  total_loss: 57.84  loss_ce: 1.727  loss_mask: 0.6251  loss_dice: 3.165  loss_ce_0: 3.108  loss_mask_0: 0.6411  loss_dice_0: 3.481  loss_ce_1: 2.038  loss_mask_1: 0.6274  loss_dice_1: 3.316  loss_ce_2: 1.893  loss_mask_2: 0.6236  loss_dice_2: 3.242  loss_ce_3: 1.848  loss_mask_3: 0.6207  loss_dice_3: 3.201  loss_ce_4: 1.779  loss_mask_4: 0.622  loss_dice_4: 3.187  loss_ce_5: 1.757  loss_mask_5: 0.6207  loss_dice_5: 3.186  loss_ce_6: 1.751  loss_mask_6: 0.6226  loss_dice_6: 3.175  loss_ce_7: 1.742  loss_mask_7: 0.622  loss_dice_7: 3.175  loss_ce_8: 1.739  loss_mask_8: 0.6246  loss_dice_8: 3.17  time: 1.6943  data_time: 0.3409  lr: 4.7132e-06  max_mem: 17674M
[01/19 12:23:52] d2.utils.events INFO:  eta: 8:08:26  iter: 22679  total_loss: 57.82  loss_ce: 1.712  loss_mask: 0.6174  loss_dice: 3.16  loss_ce_0: 3.197  loss_mask_0: 0.6347  loss_dice_0: 3.467  loss_ce_1: 2.017  loss_mask_1: 0.6238  loss_dice_1: 3.305  loss_ce_2: 1.862  loss_mask_2: 0.6185  loss_dice_2: 3.239  loss_ce_3: 1.811  loss_mask_3: 0.6159  loss_dice_3: 3.178  loss_ce_4: 1.765  loss_mask_4: 0.6187  loss_dice_4: 3.183  loss_ce_5: 1.739  loss_mask_5: 0.6188  loss_dice_5: 3.184  loss_ce_6: 1.727  loss_mask_6: 0.6184  loss_dice_6: 3.165  loss_ce_7: 1.702  loss_mask_7: 0.617  loss_dice_7: 3.163  loss_ce_8: 1.707  loss_mask_8: 0.6168  loss_dice_8: 3.166  time: 1.6943  data_time: 0.3316  lr: 4.7083e-06  max_mem: 17674M
[01/19 12:24:25] d2.utils.events INFO:  eta: 8:07:51  iter: 22699  total_loss: 59.6  loss_ce: 1.814  loss_mask: 0.6223  loss_dice: 3.22  loss_ce_0: 3.074  loss_mask_0: 0.6428  loss_dice_0: 3.513  loss_ce_1: 2.095  loss_mask_1: 0.6247  loss_dice_1: 3.356  loss_ce_2: 1.954  loss_mask_2: 0.6256  loss_dice_2: 3.285  loss_ce_3: 1.919  loss_mask_3: 0.6249  loss_dice_3: 3.242  loss_ce_4: 1.881  loss_mask_4: 0.6242  loss_dice_4: 3.244  loss_ce_5: 1.856  loss_mask_5: 0.6252  loss_dice_5: 3.241  loss_ce_6: 1.837  loss_mask_6: 0.6211  loss_dice_6: 3.226  loss_ce_7: 1.803  loss_mask_7: 0.6229  loss_dice_7: 3.221  loss_ce_8: 1.788  loss_mask_8: 0.6222  loss_dice_8: 3.222  time: 1.6943  data_time: 0.3382  lr: 4.7034e-06  max_mem: 17674M
[01/19 12:24:59] d2.utils.events INFO:  eta: 8:07:00  iter: 22719  total_loss: 57.97  loss_ce: 1.719  loss_mask: 0.6541  loss_dice: 3.173  loss_ce_0: 3.094  loss_mask_0: 0.6833  loss_dice_0: 3.484  loss_ce_1: 1.982  loss_mask_1: 0.6566  loss_dice_1: 3.325  loss_ce_2: 1.869  loss_mask_2: 0.6536  loss_dice_2: 3.239  loss_ce_3: 1.841  loss_mask_3: 0.6503  loss_dice_3: 3.203  loss_ce_4: 1.78  loss_mask_4: 0.6535  loss_dice_4: 3.189  loss_ce_5: 1.756  loss_mask_5: 0.6555  loss_dice_5: 3.191  loss_ce_6: 1.768  loss_mask_6: 0.6548  loss_dice_6: 3.176  loss_ce_7: 1.745  loss_mask_7: 0.653  loss_dice_7: 3.178  loss_ce_8: 1.724  loss_mask_8: 0.6527  loss_dice_8: 3.175  time: 1.6942  data_time: 0.3255  lr: 4.6985e-06  max_mem: 17674M
[01/19 12:25:33] d2.utils.events INFO:  eta: 8:06:19  iter: 22739  total_loss: 59.13  loss_ce: 1.777  loss_mask: 0.6291  loss_dice: 3.198  loss_ce_0: 3.161  loss_mask_0: 0.6539  loss_dice_0: 3.499  loss_ce_1: 2.051  loss_mask_1: 0.6388  loss_dice_1: 3.327  loss_ce_2: 1.914  loss_mask_2: 0.6325  loss_dice_2: 3.268  loss_ce_3: 1.85  loss_mask_3: 0.6226  loss_dice_3: 3.224  loss_ce_4: 1.82  loss_mask_4: 0.6272  loss_dice_4: 3.222  loss_ce_5: 1.812  loss_mask_5: 0.6294  loss_dice_5: 3.217  loss_ce_6: 1.79  loss_mask_6: 0.6285  loss_dice_6: 3.208  loss_ce_7: 1.767  loss_mask_7: 0.6299  loss_dice_7: 3.21  loss_ce_8: 1.779  loss_mask_8: 0.6309  loss_dice_8: 3.206  time: 1.6942  data_time: 0.3413  lr: 4.6936e-06  max_mem: 17674M
[01/19 12:26:07] d2.utils.events INFO:  eta: 8:05:49  iter: 22759  total_loss: 58.4  loss_ce: 1.747  loss_mask: 0.6135  loss_dice: 3.214  loss_ce_0: 3.106  loss_mask_0: 0.6351  loss_dice_0: 3.485  loss_ce_1: 2.04  loss_mask_1: 0.6189  loss_dice_1: 3.343  loss_ce_2: 1.89  loss_mask_2: 0.6172  loss_dice_2: 3.282  loss_ce_3: 1.838  loss_mask_3: 0.6171  loss_dice_3: 3.236  loss_ce_4: 1.799  loss_mask_4: 0.6169  loss_dice_4: 3.236  loss_ce_5: 1.773  loss_mask_5: 0.6159  loss_dice_5: 3.23  loss_ce_6: 1.766  loss_mask_6: 0.6165  loss_dice_6: 3.215  loss_ce_7: 1.748  loss_mask_7: 0.6152  loss_dice_7: 3.22  loss_ce_8: 1.727  loss_mask_8: 0.6159  loss_dice_8: 3.223  time: 1.6942  data_time: 0.3548  lr: 4.6887e-06  max_mem: 17674M
[01/19 12:26:40] d2.utils.events INFO:  eta: 8:05:11  iter: 22779  total_loss: 57.81  loss_ce: 1.74  loss_mask: 0.6274  loss_dice: 3.168  loss_ce_0: 3.101  loss_mask_0: 0.6382  loss_dice_0: 3.47  loss_ce_1: 2.005  loss_mask_1: 0.6282  loss_dice_1: 3.309  loss_ce_2: 1.898  loss_mask_2: 0.6272  loss_dice_2: 3.234  loss_ce_3: 1.837  loss_mask_3: 0.6225  loss_dice_3: 3.196  loss_ce_4: 1.788  loss_mask_4: 0.6255  loss_dice_4: 3.189  loss_ce_5: 1.76  loss_mask_5: 0.6285  loss_dice_5: 3.188  loss_ce_6: 1.729  loss_mask_6: 0.6264  loss_dice_6: 3.181  loss_ce_7: 1.734  loss_mask_7: 0.6265  loss_dice_7: 3.178  loss_ce_8: 1.738  loss_mask_8: 0.6299  loss_dice_8: 3.176  time: 1.6942  data_time: 0.3423  lr: 4.6838e-06  max_mem: 17674M
[01/19 12:27:14] d2.utils.events INFO:  eta: 8:04:38  iter: 22799  total_loss: 58.24  loss_ce: 1.793  loss_mask: 0.6229  loss_dice: 3.203  loss_ce_0: 3.068  loss_mask_0: 0.6428  loss_dice_0: 3.507  loss_ce_1: 2.012  loss_mask_1: 0.626  loss_dice_1: 3.335  loss_ce_2: 1.935  loss_mask_2: 0.6203  loss_dice_2: 3.275  loss_ce_3: 1.879  loss_mask_3: 0.62  loss_dice_3: 3.23  loss_ce_4: 1.833  loss_mask_4: 0.6212  loss_dice_4: 3.225  loss_ce_5: 1.825  loss_mask_5: 0.6222  loss_dice_5: 3.221  loss_ce_6: 1.8  loss_mask_6: 0.6207  loss_dice_6: 3.213  loss_ce_7: 1.785  loss_mask_7: 0.6234  loss_dice_7: 3.219  loss_ce_8: 1.785  loss_mask_8: 0.6267  loss_dice_8: 3.209  time: 1.6942  data_time: 0.3452  lr: 4.6789e-06  max_mem: 17674M
[01/19 12:27:48] d2.utils.events INFO:  eta: 8:03:56  iter: 22819  total_loss: 58.28  loss_ce: 1.751  loss_mask: 0.612  loss_dice: 3.205  loss_ce_0: 3.05  loss_mask_0: 0.6478  loss_dice_0: 3.491  loss_ce_1: 2.042  loss_mask_1: 0.6212  loss_dice_1: 3.33  loss_ce_2: 1.91  loss_mask_2: 0.6154  loss_dice_2: 3.262  loss_ce_3: 1.841  loss_mask_3: 0.6138  loss_dice_3: 3.225  loss_ce_4: 1.806  loss_mask_4: 0.6143  loss_dice_4: 3.224  loss_ce_5: 1.788  loss_mask_5: 0.6168  loss_dice_5: 3.23  loss_ce_6: 1.759  loss_mask_6: 0.6114  loss_dice_6: 3.212  loss_ce_7: 1.751  loss_mask_7: 0.614  loss_dice_7: 3.208  loss_ce_8: 1.755  loss_mask_8: 0.6142  loss_dice_8: 3.208  time: 1.6942  data_time: 0.3362  lr: 4.674e-06  max_mem: 17674M
[01/19 12:28:22] d2.utils.events INFO:  eta: 8:03:08  iter: 22839  total_loss: 57.6  loss_ce: 1.714  loss_mask: 0.6137  loss_dice: 3.188  loss_ce_0: 3.097  loss_mask_0: 0.6319  loss_dice_0: 3.479  loss_ce_1: 1.963  loss_mask_1: 0.6257  loss_dice_1: 3.316  loss_ce_2: 1.863  loss_mask_2: 0.6159  loss_dice_2: 3.247  loss_ce_3: 1.797  loss_mask_3: 0.6101  loss_dice_3: 3.212  loss_ce_4: 1.742  loss_mask_4: 0.612  loss_dice_4: 3.206  loss_ce_5: 1.709  loss_mask_5: 0.6137  loss_dice_5: 3.2  loss_ce_6: 1.719  loss_mask_6: 0.6124  loss_dice_6: 3.19  loss_ce_7: 1.704  loss_mask_7: 0.6164  loss_dice_7: 3.183  loss_ce_8: 1.707  loss_mask_8: 0.615  loss_dice_8: 3.18  time: 1.6942  data_time: 0.3336  lr: 4.6691e-06  max_mem: 17674M
[01/19 12:28:56] d2.utils.events INFO:  eta: 8:02:39  iter: 22859  total_loss: 57.81  loss_ce: 1.74  loss_mask: 0.6227  loss_dice: 3.158  loss_ce_0: 3.078  loss_mask_0: 0.6401  loss_dice_0: 3.456  loss_ce_1: 1.97  loss_mask_1: 0.6246  loss_dice_1: 3.316  loss_ce_2: 1.873  loss_mask_2: 0.6213  loss_dice_2: 3.232  loss_ce_3: 1.838  loss_mask_3: 0.62  loss_dice_3: 3.195  loss_ce_4: 1.778  loss_mask_4: 0.6222  loss_dice_4: 3.189  loss_ce_5: 1.756  loss_mask_5: 0.625  loss_dice_5: 3.184  loss_ce_6: 1.752  loss_mask_6: 0.6228  loss_dice_6: 3.169  loss_ce_7: 1.743  loss_mask_7: 0.6204  loss_dice_7: 3.172  loss_ce_8: 1.719  loss_mask_8: 0.6207  loss_dice_8: 3.166  time: 1.6942  data_time: 0.3479  lr: 4.6642e-06  max_mem: 17674M
[01/19 12:29:30] d2.utils.events INFO:  eta: 8:02:11  iter: 22879  total_loss: 56.98  loss_ce: 1.676  loss_mask: 0.6158  loss_dice: 3.205  loss_ce_0: 3.068  loss_mask_0: 0.6293  loss_dice_0: 3.502  loss_ce_1: 1.909  loss_mask_1: 0.6156  loss_dice_1: 3.333  loss_ce_2: 1.82  loss_mask_2: 0.6143  loss_dice_2: 3.269  loss_ce_3: 1.757  loss_mask_3: 0.6094  loss_dice_3: 3.234  loss_ce_4: 1.713  loss_mask_4: 0.6099  loss_dice_4: 3.232  loss_ce_5: 1.693  loss_mask_5: 0.612  loss_dice_5: 3.227  loss_ce_6: 1.699  loss_mask_6: 0.6111  loss_dice_6: 3.212  loss_ce_7: 1.677  loss_mask_7: 0.6151  loss_dice_7: 3.209  loss_ce_8: 1.68  loss_mask_8: 0.6124  loss_dice_8: 3.206  time: 1.6942  data_time: 0.3374  lr: 4.6593e-06  max_mem: 17674M
[01/19 12:30:05] d2.utils.events INFO:  eta: 8:01:31  iter: 22899  total_loss: 58.4  loss_ce: 1.823  loss_mask: 0.6242  loss_dice: 3.138  loss_ce_0: 3.127  loss_mask_0: 0.6512  loss_dice_0: 3.449  loss_ce_1: 2.071  loss_mask_1: 0.6294  loss_dice_1: 3.277  loss_ce_2: 1.964  loss_mask_2: 0.6277  loss_dice_2: 3.213  loss_ce_3: 1.928  loss_mask_3: 0.6169  loss_dice_3: 3.163  loss_ce_4: 1.863  loss_mask_4: 0.6181  loss_dice_4: 3.167  loss_ce_5: 1.842  loss_mask_5: 0.62  loss_dice_5: 3.162  loss_ce_6: 1.832  loss_mask_6: 0.6201  loss_dice_6: 3.148  loss_ce_7: 1.812  loss_mask_7: 0.6248  loss_dice_7: 3.147  loss_ce_8: 1.815  loss_mask_8: 0.6247  loss_dice_8: 3.148  time: 1.6942  data_time: 0.3517  lr: 4.6544e-06  max_mem: 17674M
[01/19 12:30:39] d2.utils.events INFO:  eta: 8:00:52  iter: 22919  total_loss: 58.81  loss_ce: 1.789  loss_mask: 0.6235  loss_dice: 3.218  loss_ce_0: 3.117  loss_mask_0: 0.645  loss_dice_0: 3.512  loss_ce_1: 2.039  loss_mask_1: 0.6258  loss_dice_1: 3.364  loss_ce_2: 1.921  loss_mask_2: 0.6228  loss_dice_2: 3.285  loss_ce_3: 1.883  loss_mask_3: 0.6241  loss_dice_3: 3.248  loss_ce_4: 1.822  loss_mask_4: 0.6248  loss_dice_4: 3.239  loss_ce_5: 1.809  loss_mask_5: 0.626  loss_dice_5: 3.237  loss_ce_6: 1.807  loss_mask_6: 0.6246  loss_dice_6: 3.229  loss_ce_7: 1.799  loss_mask_7: 0.6229  loss_dice_7: 3.223  loss_ce_8: 1.799  loss_mask_8: 0.6237  loss_dice_8: 3.224  time: 1.6943  data_time: 0.3483  lr: 4.6495e-06  max_mem: 17674M
[01/19 12:31:12] d2.utils.events INFO:  eta: 8:00:20  iter: 22939  total_loss: 58.18  loss_ce: 1.735  loss_mask: 0.626  loss_dice: 3.184  loss_ce_0: 3.168  loss_mask_0: 0.6509  loss_dice_0: 3.49  loss_ce_1: 2.037  loss_mask_1: 0.6225  loss_dice_1: 3.33  loss_ce_2: 1.921  loss_mask_2: 0.6253  loss_dice_2: 3.26  loss_ce_3: 1.846  loss_mask_3: 0.6228  loss_dice_3: 3.212  loss_ce_4: 1.802  loss_mask_4: 0.6224  loss_dice_4: 3.206  loss_ce_5: 1.767  loss_mask_5: 0.6258  loss_dice_5: 3.205  loss_ce_6: 1.764  loss_mask_6: 0.6273  loss_dice_6: 3.189  loss_ce_7: 1.735  loss_mask_7: 0.6272  loss_dice_7: 3.194  loss_ce_8: 1.739  loss_mask_8: 0.6256  loss_dice_8: 3.184  time: 1.6942  data_time: 0.3399  lr: 4.6446e-06  max_mem: 17674M
[01/19 12:31:46] d2.utils.events INFO:  eta: 7:59:42  iter: 22959  total_loss: 57.93  loss_ce: 1.7  loss_mask: 0.6201  loss_dice: 3.186  loss_ce_0: 3.055  loss_mask_0: 0.6457  loss_dice_0: 3.51  loss_ce_1: 1.96  loss_mask_1: 0.6315  loss_dice_1: 3.321  loss_ce_2: 1.835  loss_mask_2: 0.6253  loss_dice_2: 3.257  loss_ce_3: 1.778  loss_mask_3: 0.6201  loss_dice_3: 3.213  loss_ce_4: 1.739  loss_mask_4: 0.6224  loss_dice_4: 3.204  loss_ce_5: 1.703  loss_mask_5: 0.6221  loss_dice_5: 3.21  loss_ce_6: 1.702  loss_mask_6: 0.6201  loss_dice_6: 3.19  loss_ce_7: 1.717  loss_mask_7: 0.6183  loss_dice_7: 3.193  loss_ce_8: 1.706  loss_mask_8: 0.6203  loss_dice_8: 3.185  time: 1.6942  data_time: 0.3433  lr: 4.6397e-06  max_mem: 17674M
[01/19 12:32:21] d2.utils.events INFO:  eta: 7:59:06  iter: 22979  total_loss: 57.79  loss_ce: 1.703  loss_mask: 0.6216  loss_dice: 3.192  loss_ce_0: 3.068  loss_mask_0: 0.6413  loss_dice_0: 3.485  loss_ce_1: 2.006  loss_mask_1: 0.6232  loss_dice_1: 3.318  loss_ce_2: 1.86  loss_mask_2: 0.6253  loss_dice_2: 3.257  loss_ce_3: 1.81  loss_mask_3: 0.619  loss_dice_3: 3.21  loss_ce_4: 1.745  loss_mask_4: 0.6215  loss_dice_4: 3.207  loss_ce_5: 1.731  loss_mask_5: 0.6222  loss_dice_5: 3.203  loss_ce_6: 1.712  loss_mask_6: 0.6222  loss_dice_6: 3.192  loss_ce_7: 1.718  loss_mask_7: 0.6267  loss_dice_7: 3.195  loss_ce_8: 1.696  loss_mask_8: 0.6263  loss_dice_8: 3.192  time: 1.6943  data_time: 0.3480  lr: 4.6348e-06  max_mem: 17674M
[01/19 12:32:54] d2.utils.events INFO:  eta: 7:58:22  iter: 22999  total_loss: 57.93  loss_ce: 1.736  loss_mask: 0.6162  loss_dice: 3.208  loss_ce_0: 3.05  loss_mask_0: 0.6375  loss_dice_0: 3.51  loss_ce_1: 2.063  loss_mask_1: 0.6231  loss_dice_1: 3.333  loss_ce_2: 1.924  loss_mask_2: 0.6195  loss_dice_2: 3.269  loss_ce_3: 1.855  loss_mask_3: 0.6177  loss_dice_3: 3.226  loss_ce_4: 1.8  loss_mask_4: 0.6184  loss_dice_4: 3.223  loss_ce_5: 1.781  loss_mask_5: 0.6182  loss_dice_5: 3.22  loss_ce_6: 1.745  loss_mask_6: 0.6183  loss_dice_6: 3.207  loss_ce_7: 1.744  loss_mask_7: 0.6165  loss_dice_7: 3.212  loss_ce_8: 1.734  loss_mask_8: 0.6173  loss_dice_8: 3.207  time: 1.6943  data_time: 0.3324  lr: 4.6299e-06  max_mem: 17674M
[01/19 12:33:29] d2.utils.events INFO:  eta: 7:57:45  iter: 23019  total_loss: 57.7  loss_ce: 1.719  loss_mask: 0.6176  loss_dice: 3.166  loss_ce_0: 3.023  loss_mask_0: 0.6342  loss_dice_0: 3.479  loss_ce_1: 2.026  loss_mask_1: 0.6188  loss_dice_1: 3.301  loss_ce_2: 1.887  loss_mask_2: 0.618  loss_dice_2: 3.23  loss_ce_3: 1.818  loss_mask_3: 0.6134  loss_dice_3: 3.188  loss_ce_4: 1.769  loss_mask_4: 0.6189  loss_dice_4: 3.18  loss_ce_5: 1.753  loss_mask_5: 0.6148  loss_dice_5: 3.184  loss_ce_6: 1.742  loss_mask_6: 0.6174  loss_dice_6: 3.17  loss_ce_7: 1.726  loss_mask_7: 0.6182  loss_dice_7: 3.167  loss_ce_8: 1.711  loss_mask_8: 0.618  loss_dice_8: 3.17  time: 1.6943  data_time: 0.3572  lr: 4.625e-06  max_mem: 17674M
[01/19 12:34:02] d2.utils.events INFO:  eta: 7:57:05  iter: 23039  total_loss: 57.84  loss_ce: 1.745  loss_mask: 0.6149  loss_dice: 3.149  loss_ce_0: 3.11  loss_mask_0: 0.6295  loss_dice_0: 3.474  loss_ce_1: 2.05  loss_mask_1: 0.6198  loss_dice_1: 3.289  loss_ce_2: 1.892  loss_mask_2: 0.6147  loss_dice_2: 3.228  loss_ce_3: 1.835  loss_mask_3: 0.611  loss_dice_3: 3.177  loss_ce_4: 1.797  loss_mask_4: 0.6141  loss_dice_4: 3.169  loss_ce_5: 1.772  loss_mask_5: 0.614  loss_dice_5: 3.169  loss_ce_6: 1.774  loss_mask_6: 0.6151  loss_dice_6: 3.153  loss_ce_7: 1.743  loss_mask_7: 0.6156  loss_dice_7: 3.152  loss_ce_8: 1.735  loss_mask_8: 0.6151  loss_dice_8: 3.155  time: 1.6943  data_time: 0.3248  lr: 4.6201e-06  max_mem: 17674M
[01/19 12:34:36] d2.utils.events INFO:  eta: 7:56:28  iter: 23059  total_loss: 57.53  loss_ce: 1.674  loss_mask: 0.608  loss_dice: 3.207  loss_ce_0: 3.007  loss_mask_0: 0.6195  loss_dice_0: 3.507  loss_ce_1: 1.907  loss_mask_1: 0.6084  loss_dice_1: 3.348  loss_ce_2: 1.818  loss_mask_2: 0.6084  loss_dice_2: 3.275  loss_ce_3: 1.767  loss_mask_3: 0.6037  loss_dice_3: 3.23  loss_ce_4: 1.722  loss_mask_4: 0.6036  loss_dice_4: 3.224  loss_ce_5: 1.701  loss_mask_5: 0.6081  loss_dice_5: 3.224  loss_ce_6: 1.693  loss_mask_6: 0.6068  loss_dice_6: 3.21  loss_ce_7: 1.679  loss_mask_7: 0.6073  loss_dice_7: 3.207  loss_ce_8: 1.685  loss_mask_8: 0.6078  loss_dice_8: 3.211  time: 1.6943  data_time: 0.3353  lr: 4.6152e-06  max_mem: 17674M
[01/19 12:35:10] d2.utils.events INFO:  eta: 7:55:54  iter: 23079  total_loss: 57.43  loss_ce: 1.741  loss_mask: 0.6226  loss_dice: 3.186  loss_ce_0: 2.996  loss_mask_0: 0.6383  loss_dice_0: 3.485  loss_ce_1: 2.011  loss_mask_1: 0.6216  loss_dice_1: 3.314  loss_ce_2: 1.918  loss_mask_2: 0.6184  loss_dice_2: 3.256  loss_ce_3: 1.867  loss_mask_3: 0.6191  loss_dice_3: 3.208  loss_ce_4: 1.809  loss_mask_4: 0.6219  loss_dice_4: 3.209  loss_ce_5: 1.783  loss_mask_5: 0.6258  loss_dice_5: 3.2  loss_ce_6: 1.798  loss_mask_6: 0.6243  loss_dice_6: 3.187  loss_ce_7: 1.773  loss_mask_7: 0.6236  loss_dice_7: 3.196  loss_ce_8: 1.755  loss_mask_8: 0.6263  loss_dice_8: 3.19  time: 1.6943  data_time: 0.3560  lr: 4.6103e-06  max_mem: 17674M
[01/19 12:35:45] d2.utils.events INFO:  eta: 7:55:34  iter: 23099  total_loss: 58.22  loss_ce: 1.734  loss_mask: 0.6197  loss_dice: 3.177  loss_ce_0: 3.072  loss_mask_0: 0.6377  loss_dice_0: 3.513  loss_ce_1: 1.969  loss_mask_1: 0.6277  loss_dice_1: 3.329  loss_ce_2: 1.873  loss_mask_2: 0.6186  loss_dice_2: 3.249  loss_ce_3: 1.821  loss_mask_3: 0.6187  loss_dice_3: 3.21  loss_ce_4: 1.779  loss_mask_4: 0.6164  loss_dice_4: 3.2  loss_ce_5: 1.761  loss_mask_5: 0.6165  loss_dice_5: 3.2  loss_ce_6: 1.75  loss_mask_6: 0.6171  loss_dice_6: 3.187  loss_ce_7: 1.739  loss_mask_7: 0.6187  loss_dice_7: 3.186  loss_ce_8: 1.734  loss_mask_8: 0.6182  loss_dice_8: 3.188  time: 1.6943  data_time: 0.3609  lr: 4.6054e-06  max_mem: 17674M
[01/19 12:36:19] d2.utils.events INFO:  eta: 7:54:54  iter: 23119  total_loss: 57.51  loss_ce: 1.736  loss_mask: 0.6151  loss_dice: 3.16  loss_ce_0: 3.037  loss_mask_0: 0.6412  loss_dice_0: 3.469  loss_ce_1: 2.004  loss_mask_1: 0.6207  loss_dice_1: 3.298  loss_ce_2: 1.885  loss_mask_2: 0.6172  loss_dice_2: 3.242  loss_ce_3: 1.83  loss_mask_3: 0.6163  loss_dice_3: 3.197  loss_ce_4: 1.787  loss_mask_4: 0.616  loss_dice_4: 3.19  loss_ce_5: 1.778  loss_mask_5: 0.6159  loss_dice_5: 3.181  loss_ce_6: 1.77  loss_mask_6: 0.611  loss_dice_6: 3.172  loss_ce_7: 1.742  loss_mask_7: 0.6135  loss_dice_7: 3.169  loss_ce_8: 1.752  loss_mask_8: 0.6133  loss_dice_8: 3.171  time: 1.6943  data_time: 0.3316  lr: 4.6005e-06  max_mem: 17674M
[01/19 12:36:53] d2.utils.events INFO:  eta: 7:54:30  iter: 23139  total_loss: 57.58  loss_ce: 1.757  loss_mask: 0.6206  loss_dice: 3.129  loss_ce_0: 3.112  loss_mask_0: 0.646  loss_dice_0: 3.454  loss_ce_1: 2.042  loss_mask_1: 0.6288  loss_dice_1: 3.284  loss_ce_2: 1.928  loss_mask_2: 0.6228  loss_dice_2: 3.214  loss_ce_3: 1.83  loss_mask_3: 0.6207  loss_dice_3: 3.164  loss_ce_4: 1.817  loss_mask_4: 0.6248  loss_dice_4: 3.159  loss_ce_5: 1.77  loss_mask_5: 0.6234  loss_dice_5: 3.149  loss_ce_6: 1.769  loss_mask_6: 0.6209  loss_dice_6: 3.134  loss_ce_7: 1.755  loss_mask_7: 0.6241  loss_dice_7: 3.137  loss_ce_8: 1.745  loss_mask_8: 0.6232  loss_dice_8: 3.128  time: 1.6943  data_time: 0.3370  lr: 4.5956e-06  max_mem: 17674M
[01/19 12:37:27] d2.utils.events INFO:  eta: 7:54:01  iter: 23159  total_loss: 57.63  loss_ce: 1.718  loss_mask: 0.6062  loss_dice: 3.178  loss_ce_0: 3.036  loss_mask_0: 0.6262  loss_dice_0: 3.486  loss_ce_1: 2.029  loss_mask_1: 0.6187  loss_dice_1: 3.305  loss_ce_2: 1.881  loss_mask_2: 0.6142  loss_dice_2: 3.241  loss_ce_3: 1.809  loss_mask_3: 0.6069  loss_dice_3: 3.203  loss_ce_4: 1.756  loss_mask_4: 0.6092  loss_dice_4: 3.199  loss_ce_5: 1.747  loss_mask_5: 0.6093  loss_dice_5: 3.195  loss_ce_6: 1.721  loss_mask_6: 0.6053  loss_dice_6: 3.181  loss_ce_7: 1.699  loss_mask_7: 0.6067  loss_dice_7: 3.179  loss_ce_8: 1.723  loss_mask_8: 0.6095  loss_dice_8: 3.18  time: 1.6943  data_time: 0.3408  lr: 4.5907e-06  max_mem: 17674M
[01/19 12:38:00] d2.utils.events INFO:  eta: 7:53:31  iter: 23179  total_loss: 58.17  loss_ce: 1.761  loss_mask: 0.6302  loss_dice: 3.149  loss_ce_0: 3.092  loss_mask_0: 0.6572  loss_dice_0: 3.456  loss_ce_1: 2.028  loss_mask_1: 0.6344  loss_dice_1: 3.281  loss_ce_2: 1.928  loss_mask_2: 0.6335  loss_dice_2: 3.217  loss_ce_3: 1.869  loss_mask_3: 0.6296  loss_dice_3: 3.177  loss_ce_4: 1.823  loss_mask_4: 0.6317  loss_dice_4: 3.168  loss_ce_5: 1.774  loss_mask_5: 0.6315  loss_dice_5: 3.168  loss_ce_6: 1.787  loss_mask_6: 0.6327  loss_dice_6: 3.15  loss_ce_7: 1.778  loss_mask_7: 0.632  loss_dice_7: 3.148  loss_ce_8: 1.755  loss_mask_8: 0.6302  loss_dice_8: 3.154  time: 1.6943  data_time: 0.3378  lr: 4.5858e-06  max_mem: 17674M
[01/19 12:38:34] d2.utils.events INFO:  eta: 7:53:08  iter: 23199  total_loss: 58.01  loss_ce: 1.775  loss_mask: 0.6249  loss_dice: 3.137  loss_ce_0: 3.081  loss_mask_0: 0.6424  loss_dice_0: 3.462  loss_ce_1: 2.044  loss_mask_1: 0.6265  loss_dice_1: 3.291  loss_ce_2: 1.933  loss_mask_2: 0.6203  loss_dice_2: 3.211  loss_ce_3: 1.889  loss_mask_3: 0.6203  loss_dice_3: 3.162  loss_ce_4: 1.82  loss_mask_4: 0.6233  loss_dice_4: 3.156  loss_ce_5: 1.809  loss_mask_5: 0.6242  loss_dice_5: 3.155  loss_ce_6: 1.785  loss_mask_6: 0.6224  loss_dice_6: 3.14  loss_ce_7: 1.778  loss_mask_7: 0.6253  loss_dice_7: 3.137  loss_ce_8: 1.764  loss_mask_8: 0.6234  loss_dice_8: 3.142  time: 1.6943  data_time: 0.3378  lr: 4.5809e-06  max_mem: 17674M
[01/19 12:39:08] d2.utils.events INFO:  eta: 7:52:34  iter: 23219  total_loss: 59.32  loss_ce: 1.765  loss_mask: 0.6225  loss_dice: 3.208  loss_ce_0: 3.101  loss_mask_0: 0.636  loss_dice_0: 3.491  loss_ce_1: 2.102  loss_mask_1: 0.6249  loss_dice_1: 3.339  loss_ce_2: 1.94  loss_mask_2: 0.6243  loss_dice_2: 3.272  loss_ce_3: 1.867  loss_mask_3: 0.6232  loss_dice_3: 3.226  loss_ce_4: 1.813  loss_mask_4: 0.6196  loss_dice_4: 3.23  loss_ce_5: 1.807  loss_mask_5: 0.6238  loss_dice_5: 3.23  loss_ce_6: 1.798  loss_mask_6: 0.622  loss_dice_6: 3.204  loss_ce_7: 1.774  loss_mask_7: 0.621  loss_dice_7: 3.207  loss_ce_8: 1.79  loss_mask_8: 0.6226  loss_dice_8: 3.207  time: 1.6943  data_time: 0.3371  lr: 4.576e-06  max_mem: 17674M
[01/19 12:39:41] d2.utils.events INFO:  eta: 7:51:54  iter: 23239  total_loss: 58.07  loss_ce: 1.718  loss_mask: 0.6338  loss_dice: 3.186  loss_ce_0: 3.096  loss_mask_0: 0.6569  loss_dice_0: 3.455  loss_ce_1: 1.991  loss_mask_1: 0.6389  loss_dice_1: 3.306  loss_ce_2: 1.852  loss_mask_2: 0.6332  loss_dice_2: 3.239  loss_ce_3: 1.801  loss_mask_3: 0.6305  loss_dice_3: 3.206  loss_ce_4: 1.731  loss_mask_4: 0.6304  loss_dice_4: 3.2  loss_ce_5: 1.712  loss_mask_5: 0.6336  loss_dice_5: 3.195  loss_ce_6: 1.733  loss_mask_6: 0.6332  loss_dice_6: 3.183  loss_ce_7: 1.715  loss_mask_7: 0.6327  loss_dice_7: 3.186  loss_ce_8: 1.718  loss_mask_8: 0.6335  loss_dice_8: 3.175  time: 1.6943  data_time: 0.3361  lr: 4.571e-06  max_mem: 17674M
[01/19 12:40:15] d2.utils.events INFO:  eta: 7:51:20  iter: 23259  total_loss: 58.71  loss_ce: 1.751  loss_mask: 0.617  loss_dice: 3.21  loss_ce_0: 3.04  loss_mask_0: 0.6434  loss_dice_0: 3.518  loss_ce_1: 2.028  loss_mask_1: 0.6153  loss_dice_1: 3.364  loss_ce_2: 1.911  loss_mask_2: 0.6201  loss_dice_2: 3.291  loss_ce_3: 1.865  loss_mask_3: 0.6143  loss_dice_3: 3.233  loss_ce_4: 1.8  loss_mask_4: 0.6151  loss_dice_4: 3.229  loss_ce_5: 1.781  loss_mask_5: 0.6162  loss_dice_5: 3.232  loss_ce_6: 1.779  loss_mask_6: 0.617  loss_dice_6: 3.212  loss_ce_7: 1.768  loss_mask_7: 0.6161  loss_dice_7: 3.208  loss_ce_8: 1.756  loss_mask_8: 0.616  loss_dice_8: 3.213  time: 1.6943  data_time: 0.3553  lr: 4.5661e-06  max_mem: 17674M
[01/19 12:40:49] d2.utils.events INFO:  eta: 7:50:40  iter: 23279  total_loss: 57.66  loss_ce: 1.699  loss_mask: 0.6109  loss_dice: 3.187  loss_ce_0: 3.055  loss_mask_0: 0.6333  loss_dice_0: 3.478  loss_ce_1: 2.01  loss_mask_1: 0.6194  loss_dice_1: 3.323  loss_ce_2: 1.848  loss_mask_2: 0.6151  loss_dice_2: 3.25  loss_ce_3: 1.788  loss_mask_3: 0.6082  loss_dice_3: 3.216  loss_ce_4: 1.743  loss_mask_4: 0.6094  loss_dice_4: 3.207  loss_ce_5: 1.734  loss_mask_5: 0.6102  loss_dice_5: 3.206  loss_ce_6: 1.724  loss_mask_6: 0.6073  loss_dice_6: 3.189  loss_ce_7: 1.69  loss_mask_7: 0.6072  loss_dice_7: 3.191  loss_ce_8: 1.708  loss_mask_8: 0.6084  loss_dice_8: 3.186  time: 1.6943  data_time: 0.3454  lr: 4.5612e-06  max_mem: 17674M
[01/19 12:41:24] d2.utils.events INFO:  eta: 7:50:19  iter: 23299  total_loss: 58.86  loss_ce: 1.776  loss_mask: 0.6125  loss_dice: 3.213  loss_ce_0: 3.1  loss_mask_0: 0.6289  loss_dice_0: 3.513  loss_ce_1: 2.06  loss_mask_1: 0.6168  loss_dice_1: 3.339  loss_ce_2: 1.949  loss_mask_2: 0.6107  loss_dice_2: 3.272  loss_ce_3: 1.875  loss_mask_3: 0.6129  loss_dice_3: 3.231  loss_ce_4: 1.812  loss_mask_4: 0.6109  loss_dice_4: 3.226  loss_ce_5: 1.792  loss_mask_5: 0.6125  loss_dice_5: 3.224  loss_ce_6: 1.796  loss_mask_6: 0.6145  loss_dice_6: 3.216  loss_ce_7: 1.786  loss_mask_7: 0.6116  loss_dice_7: 3.216  loss_ce_8: 1.776  loss_mask_8: 0.6131  loss_dice_8: 3.214  time: 1.6943  data_time: 0.3465  lr: 4.5563e-06  max_mem: 17674M
[01/19 12:41:58] d2.utils.events INFO:  eta: 7:49:41  iter: 23319  total_loss: 57.43  loss_ce: 1.717  loss_mask: 0.6045  loss_dice: 3.178  loss_ce_0: 3.03  loss_mask_0: 0.6266  loss_dice_0: 3.48  loss_ce_1: 1.956  loss_mask_1: 0.6047  loss_dice_1: 3.308  loss_ce_2: 1.816  loss_mask_2: 0.6049  loss_dice_2: 3.261  loss_ce_3: 1.77  loss_mask_3: 0.6052  loss_dice_3: 3.21  loss_ce_4: 1.724  loss_mask_4: 0.6061  loss_dice_4: 3.204  loss_ce_5: 1.703  loss_mask_5: 0.6048  loss_dice_5: 3.203  loss_ce_6: 1.706  loss_mask_6: 0.604  loss_dice_6: 3.19  loss_ce_7: 1.698  loss_mask_7: 0.6042  loss_dice_7: 3.187  loss_ce_8: 1.694  loss_mask_8: 0.6045  loss_dice_8: 3.177  time: 1.6943  data_time: 0.3321  lr: 4.5514e-06  max_mem: 17674M
[01/19 12:42:32] d2.utils.events INFO:  eta: 7:49:10  iter: 23339  total_loss: 58.34  loss_ce: 1.735  loss_mask: 0.6159  loss_dice: 3.179  loss_ce_0: 3.043  loss_mask_0: 0.6373  loss_dice_0: 3.476  loss_ce_1: 2.027  loss_mask_1: 0.618  loss_dice_1: 3.314  loss_ce_2: 1.879  loss_mask_2: 0.614  loss_dice_2: 3.238  loss_ce_3: 1.807  loss_mask_3: 0.6152  loss_dice_3: 3.202  loss_ce_4: 1.762  loss_mask_4: 0.6187  loss_dice_4: 3.192  loss_ce_5: 1.75  loss_mask_5: 0.617  loss_dice_5: 3.192  loss_ce_6: 1.773  loss_mask_6: 0.6164  loss_dice_6: 3.184  loss_ce_7: 1.753  loss_mask_7: 0.616  loss_dice_7: 3.187  loss_ce_8: 1.751  loss_mask_8: 0.6148  loss_dice_8: 3.178  time: 1.6943  data_time: 0.3489  lr: 4.5465e-06  max_mem: 17674M
[01/19 12:43:05] d2.utils.events INFO:  eta: 7:48:40  iter: 23359  total_loss: 57.44  loss_ce: 1.685  loss_mask: 0.6182  loss_dice: 3.228  loss_ce_0: 3.025  loss_mask_0: 0.6429  loss_dice_0: 3.515  loss_ce_1: 1.973  loss_mask_1: 0.6236  loss_dice_1: 3.368  loss_ce_2: 1.838  loss_mask_2: 0.6195  loss_dice_2: 3.293  loss_ce_3: 1.782  loss_mask_3: 0.6146  loss_dice_3: 3.249  loss_ce_4: 1.736  loss_mask_4: 0.615  loss_dice_4: 3.247  loss_ce_5: 1.687  loss_mask_5: 0.6173  loss_dice_5: 3.245  loss_ce_6: 1.705  loss_mask_6: 0.6141  loss_dice_6: 3.233  loss_ce_7: 1.684  loss_mask_7: 0.6168  loss_dice_7: 3.233  loss_ce_8: 1.681  loss_mask_8: 0.6191  loss_dice_8: 3.228  time: 1.6943  data_time: 0.3300  lr: 4.5416e-06  max_mem: 17674M
[01/19 12:43:39] d2.utils.events INFO:  eta: 7:48:06  iter: 23379  total_loss: 58.07  loss_ce: 1.754  loss_mask: 0.6247  loss_dice: 3.149  loss_ce_0: 3.09  loss_mask_0: 0.6502  loss_dice_0: 3.468  loss_ce_1: 2.102  loss_mask_1: 0.6248  loss_dice_1: 3.287  loss_ce_2: 1.97  loss_mask_2: 0.6247  loss_dice_2: 3.215  loss_ce_3: 1.887  loss_mask_3: 0.6267  loss_dice_3: 3.181  loss_ce_4: 1.84  loss_mask_4: 0.6281  loss_dice_4: 3.172  loss_ce_5: 1.811  loss_mask_5: 0.6258  loss_dice_5: 3.164  loss_ce_6: 1.776  loss_mask_6: 0.6239  loss_dice_6: 3.159  loss_ce_7: 1.768  loss_mask_7: 0.6245  loss_dice_7: 3.166  loss_ce_8: 1.741  loss_mask_8: 0.6237  loss_dice_8: 3.155  time: 1.6943  data_time: 0.3409  lr: 4.5367e-06  max_mem: 17674M
[01/19 12:44:13] d2.utils.events INFO:  eta: 7:47:27  iter: 23399  total_loss: 56.9  loss_ce: 1.648  loss_mask: 0.6189  loss_dice: 3.176  loss_ce_0: 3.004  loss_mask_0: 0.6322  loss_dice_0: 3.487  loss_ce_1: 1.919  loss_mask_1: 0.6168  loss_dice_1: 3.321  loss_ce_2: 1.792  loss_mask_2: 0.6218  loss_dice_2: 3.251  loss_ce_3: 1.725  loss_mask_3: 0.6165  loss_dice_3: 3.199  loss_ce_4: 1.66  loss_mask_4: 0.6201  loss_dice_4: 3.203  loss_ce_5: 1.641  loss_mask_5: 0.6194  loss_dice_5: 3.201  loss_ce_6: 1.645  loss_mask_6: 0.6194  loss_dice_6: 3.185  loss_ce_7: 1.645  loss_mask_7: 0.6176  loss_dice_7: 3.178  loss_ce_8: 1.657  loss_mask_8: 0.6189  loss_dice_8: 3.19  time: 1.6943  data_time: 0.3493  lr: 4.5318e-06  max_mem: 17674M
[01/19 12:44:47] d2.utils.events INFO:  eta: 7:46:52  iter: 23419  total_loss: 57.98  loss_ce: 1.74  loss_mask: 0.6296  loss_dice: 3.16  loss_ce_0: 3.002  loss_mask_0: 0.6596  loss_dice_0: 3.464  loss_ce_1: 2.038  loss_mask_1: 0.6383  loss_dice_1: 3.291  loss_ce_2: 1.881  loss_mask_2: 0.6325  loss_dice_2: 3.227  loss_ce_3: 1.846  loss_mask_3: 0.6289  loss_dice_3: 3.186  loss_ce_4: 1.799  loss_mask_4: 0.6283  loss_dice_4: 3.186  loss_ce_5: 1.754  loss_mask_5: 0.6289  loss_dice_5: 3.178  loss_ce_6: 1.752  loss_mask_6: 0.6278  loss_dice_6: 3.167  loss_ce_7: 1.745  loss_mask_7: 0.6288  loss_dice_7: 3.16  loss_ce_8: 1.735  loss_mask_8: 0.6278  loss_dice_8: 3.159  time: 1.6943  data_time: 0.3384  lr: 4.5268e-06  max_mem: 17674M
[01/19 12:45:21] d2.utils.events INFO:  eta: 7:46:18  iter: 23439  total_loss: 57.34  loss_ce: 1.676  loss_mask: 0.6115  loss_dice: 3.242  loss_ce_0: 2.981  loss_mask_0: 0.6349  loss_dice_0: 3.514  loss_ce_1: 1.927  loss_mask_1: 0.6224  loss_dice_1: 3.368  loss_ce_2: 1.791  loss_mask_2: 0.6143  loss_dice_2: 3.311  loss_ce_3: 1.741  loss_mask_3: 0.6116  loss_dice_3: 3.265  loss_ce_4: 1.714  loss_mask_4: 0.6122  loss_dice_4: 3.263  loss_ce_5: 1.684  loss_mask_5: 0.6115  loss_dice_5: 3.254  loss_ce_6: 1.68  loss_mask_6: 0.6137  loss_dice_6: 3.245  loss_ce_7: 1.672  loss_mask_7: 0.6122  loss_dice_7: 3.241  loss_ce_8: 1.676  loss_mask_8: 0.6133  loss_dice_8: 3.243  time: 1.6943  data_time: 0.3361  lr: 4.5219e-06  max_mem: 17674M
[01/19 12:45:54] d2.utils.events INFO:  eta: 7:45:39  iter: 23459  total_loss: 57.58  loss_ce: 1.724  loss_mask: 0.6254  loss_dice: 3.195  loss_ce_0: 3.013  loss_mask_0: 0.6496  loss_dice_0: 3.491  loss_ce_1: 1.98  loss_mask_1: 0.6323  loss_dice_1: 3.337  loss_ce_2: 1.861  loss_mask_2: 0.6267  loss_dice_2: 3.27  loss_ce_3: 1.802  loss_mask_3: 0.6259  loss_dice_3: 3.229  loss_ce_4: 1.753  loss_mask_4: 0.6287  loss_dice_4: 3.218  loss_ce_5: 1.723  loss_mask_5: 0.6244  loss_dice_5: 3.226  loss_ce_6: 1.734  loss_mask_6: 0.6248  loss_dice_6: 3.212  loss_ce_7: 1.713  loss_mask_7: 0.6232  loss_dice_7: 3.202  loss_ce_8: 1.701  loss_mask_8: 0.6251  loss_dice_8: 3.203  time: 1.6942  data_time: 0.3474  lr: 4.517e-06  max_mem: 17674M
[01/19 12:46:28] d2.utils.events INFO:  eta: 7:45:03  iter: 23479  total_loss: 57.74  loss_ce: 1.695  loss_mask: 0.6211  loss_dice: 3.208  loss_ce_0: 3.065  loss_mask_0: 0.652  loss_dice_0: 3.517  loss_ce_1: 1.998  loss_mask_1: 0.6232  loss_dice_1: 3.343  loss_ce_2: 1.886  loss_mask_2: 0.6221  loss_dice_2: 3.277  loss_ce_3: 1.818  loss_mask_3: 0.6184  loss_dice_3: 3.233  loss_ce_4: 1.769  loss_mask_4: 0.6185  loss_dice_4: 3.228  loss_ce_5: 1.721  loss_mask_5: 0.6194  loss_dice_5: 3.224  loss_ce_6: 1.721  loss_mask_6: 0.6176  loss_dice_6: 3.211  loss_ce_7: 1.701  loss_mask_7: 0.621  loss_dice_7: 3.207  loss_ce_8: 1.684  loss_mask_8: 0.6194  loss_dice_8: 3.207  time: 1.6942  data_time: 0.3337  lr: 4.5121e-06  max_mem: 17674M
[01/19 12:47:02] d2.utils.events INFO:  eta: 7:44:35  iter: 23499  total_loss: 57.15  loss_ce: 1.712  loss_mask: 0.6244  loss_dice: 3.159  loss_ce_0: 3  loss_mask_0: 0.6419  loss_dice_0: 3.467  loss_ce_1: 2  loss_mask_1: 0.6228  loss_dice_1: 3.297  loss_ce_2: 1.867  loss_mask_2: 0.6201  loss_dice_2: 3.228  loss_ce_3: 1.792  loss_mask_3: 0.622  loss_dice_3: 3.185  loss_ce_4: 1.744  loss_mask_4: 0.6231  loss_dice_4: 3.171  loss_ce_5: 1.734  loss_mask_5: 0.6238  loss_dice_5: 3.172  loss_ce_6: 1.707  loss_mask_6: 0.6239  loss_dice_6: 3.163  loss_ce_7: 1.717  loss_mask_7: 0.6255  loss_dice_7: 3.159  loss_ce_8: 1.71  loss_mask_8: 0.6253  loss_dice_8: 3.164  time: 1.6942  data_time: 0.3453  lr: 4.5072e-06  max_mem: 17674M
[01/19 12:47:36] d2.utils.events INFO:  eta: 7:44:01  iter: 23519  total_loss: 58.37  loss_ce: 1.746  loss_mask: 0.6165  loss_dice: 3.209  loss_ce_0: 3.055  loss_mask_0: 0.6384  loss_dice_0: 3.495  loss_ce_1: 2.083  loss_mask_1: 0.6225  loss_dice_1: 3.335  loss_ce_2: 1.926  loss_mask_2: 0.6221  loss_dice_2: 3.272  loss_ce_3: 1.846  loss_mask_3: 0.6172  loss_dice_3: 3.237  loss_ce_4: 1.787  loss_mask_4: 0.6152  loss_dice_4: 3.228  loss_ce_5: 1.767  loss_mask_5: 0.6151  loss_dice_5: 3.229  loss_ce_6: 1.765  loss_mask_6: 0.6154  loss_dice_6: 3.214  loss_ce_7: 1.759  loss_mask_7: 0.6148  loss_dice_7: 3.215  loss_ce_8: 1.761  loss_mask_8: 0.617  loss_dice_8: 3.205  time: 1.6942  data_time: 0.3429  lr: 4.5023e-06  max_mem: 17674M
[01/19 12:48:10] d2.utils.events INFO:  eta: 7:43:21  iter: 23539  total_loss: 57.47  loss_ce: 1.688  loss_mask: 0.627  loss_dice: 3.171  loss_ce_0: 2.979  loss_mask_0: 0.6556  loss_dice_0: 3.481  loss_ce_1: 1.94  loss_mask_1: 0.635  loss_dice_1: 3.304  loss_ce_2: 1.853  loss_mask_2: 0.6336  loss_dice_2: 3.233  loss_ce_3: 1.793  loss_mask_3: 0.6319  loss_dice_3: 3.187  loss_ce_4: 1.736  loss_mask_4: 0.6297  loss_dice_4: 3.19  loss_ce_5: 1.699  loss_mask_5: 0.6323  loss_dice_5: 3.19  loss_ce_6: 1.694  loss_mask_6: 0.6306  loss_dice_6: 3.177  loss_ce_7: 1.674  loss_mask_7: 0.6321  loss_dice_7: 3.176  loss_ce_8: 1.686  loss_mask_8: 0.6279  loss_dice_8: 3.176  time: 1.6942  data_time: 0.3359  lr: 4.4973e-06  max_mem: 17674M
[01/19 12:48:44] d2.utils.events INFO:  eta: 7:42:48  iter: 23559  total_loss: 56.74  loss_ce: 1.634  loss_mask: 0.6035  loss_dice: 3.166  loss_ce_0: 2.98  loss_mask_0: 0.6252  loss_dice_0: 3.466  loss_ce_1: 1.923  loss_mask_1: 0.608  loss_dice_1: 3.306  loss_ce_2: 1.789  loss_mask_2: 0.5992  loss_dice_2: 3.239  loss_ce_3: 1.754  loss_mask_3: 0.6016  loss_dice_3: 3.195  loss_ce_4: 1.703  loss_mask_4: 0.6033  loss_dice_4: 3.193  loss_ce_5: 1.677  loss_mask_5: 0.6026  loss_dice_5: 3.187  loss_ce_6: 1.666  loss_mask_6: 0.6064  loss_dice_6: 3.175  loss_ce_7: 1.648  loss_mask_7: 0.6011  loss_dice_7: 3.173  loss_ce_8: 1.639  loss_mask_8: 0.6039  loss_dice_8: 3.181  time: 1.6942  data_time: 0.3340  lr: 4.4924e-06  max_mem: 17674M
[01/19 12:49:18] d2.utils.events INFO:  eta: 7:42:17  iter: 23579  total_loss: 57.68  loss_ce: 1.712  loss_mask: 0.6066  loss_dice: 3.169  loss_ce_0: 3.018  loss_mask_0: 0.6285  loss_dice_0: 3.476  loss_ce_1: 2.036  loss_mask_1: 0.6218  loss_dice_1: 3.301  loss_ce_2: 1.877  loss_mask_2: 0.6127  loss_dice_2: 3.239  loss_ce_3: 1.794  loss_mask_3: 0.6086  loss_dice_3: 3.196  loss_ce_4: 1.758  loss_mask_4: 0.6064  loss_dice_4: 3.193  loss_ce_5: 1.718  loss_mask_5: 0.6091  loss_dice_5: 3.186  loss_ce_6: 1.725  loss_mask_6: 0.6079  loss_dice_6: 3.17  loss_ce_7: 1.696  loss_mask_7: 0.6056  loss_dice_7: 3.171  loss_ce_8: 1.697  loss_mask_8: 0.6088  loss_dice_8: 3.17  time: 1.6942  data_time: 0.3633  lr: 4.4875e-06  max_mem: 17674M
[01/19 12:49:52] d2.utils.events INFO:  eta: 7:41:38  iter: 23599  total_loss: 57.71  loss_ce: 1.718  loss_mask: 0.6311  loss_dice: 3.178  loss_ce_0: 2.985  loss_mask_0: 0.6466  loss_dice_0: 3.48  loss_ce_1: 1.982  loss_mask_1: 0.6258  loss_dice_1: 3.301  loss_ce_2: 1.88  loss_mask_2: 0.6279  loss_dice_2: 3.241  loss_ce_3: 1.806  loss_mask_3: 0.6243  loss_dice_3: 3.198  loss_ce_4: 1.777  loss_mask_4: 0.6274  loss_dice_4: 3.195  loss_ce_5: 1.715  loss_mask_5: 0.6287  loss_dice_5: 3.195  loss_ce_6: 1.721  loss_mask_6: 0.6281  loss_dice_6: 3.177  loss_ce_7: 1.72  loss_mask_7: 0.6285  loss_dice_7: 3.18  loss_ce_8: 1.687  loss_mask_8: 0.628  loss_dice_8: 3.179  time: 1.6942  data_time: 0.3367  lr: 4.4826e-06  max_mem: 17674M
[01/19 12:50:25] d2.utils.events INFO:  eta: 7:40:58  iter: 23619  total_loss: 57.53  loss_ce: 1.679  loss_mask: 0.6243  loss_dice: 3.143  loss_ce_0: 2.986  loss_mask_0: 0.6398  loss_dice_0: 3.467  loss_ce_1: 1.97  loss_mask_1: 0.6197  loss_dice_1: 3.29  loss_ce_2: 1.832  loss_mask_2: 0.6201  loss_dice_2: 3.231  loss_ce_3: 1.774  loss_mask_3: 0.6211  loss_dice_3: 3.172  loss_ce_4: 1.737  loss_mask_4: 0.6228  loss_dice_4: 3.17  loss_ce_5: 1.686  loss_mask_5: 0.6215  loss_dice_5: 3.163  loss_ce_6: 1.702  loss_mask_6: 0.6248  loss_dice_6: 3.151  loss_ce_7: 1.693  loss_mask_7: 0.6265  loss_dice_7: 3.149  loss_ce_8: 1.681  loss_mask_8: 0.626  loss_dice_8: 3.152  time: 1.6942  data_time: 0.3457  lr: 4.4777e-06  max_mem: 17674M
[01/19 12:50:59] d2.utils.events INFO:  eta: 7:40:22  iter: 23639  total_loss: 57.01  loss_ce: 1.662  loss_mask: 0.6171  loss_dice: 3.18  loss_ce_0: 2.963  loss_mask_0: 0.6381  loss_dice_0: 3.477  loss_ce_1: 1.923  loss_mask_1: 0.6213  loss_dice_1: 3.299  loss_ce_2: 1.789  loss_mask_2: 0.6171  loss_dice_2: 3.233  loss_ce_3: 1.747  loss_mask_3: 0.6146  loss_dice_3: 3.197  loss_ce_4: 1.71  loss_mask_4: 0.618  loss_dice_4: 3.188  loss_ce_5: 1.683  loss_mask_5: 0.6178  loss_dice_5: 3.191  loss_ce_6: 1.665  loss_mask_6: 0.6165  loss_dice_6: 3.177  loss_ce_7: 1.665  loss_mask_7: 0.6162  loss_dice_7: 3.179  loss_ce_8: 1.658  loss_mask_8: 0.6144  loss_dice_8: 3.179  time: 1.6942  data_time: 0.3293  lr: 4.4728e-06  max_mem: 17674M
[01/19 12:51:33] d2.utils.events INFO:  eta: 7:39:57  iter: 23659  total_loss: 57.99  loss_ce: 1.754  loss_mask: 0.6216  loss_dice: 3.17  loss_ce_0: 3.069  loss_mask_0: 0.6428  loss_dice_0: 3.478  loss_ce_1: 1.963  loss_mask_1: 0.6256  loss_dice_1: 3.309  loss_ce_2: 1.829  loss_mask_2: 0.6198  loss_dice_2: 3.24  loss_ce_3: 1.812  loss_mask_3: 0.6197  loss_dice_3: 3.199  loss_ce_4: 1.78  loss_mask_4: 0.6192  loss_dice_4: 3.192  loss_ce_5: 1.773  loss_mask_5: 0.6191  loss_dice_5: 3.193  loss_ce_6: 1.763  loss_mask_6: 0.6219  loss_dice_6: 3.173  loss_ce_7: 1.752  loss_mask_7: 0.62  loss_dice_7: 3.17  loss_ce_8: 1.751  loss_mask_8: 0.621  loss_dice_8: 3.168  time: 1.6942  data_time: 0.3231  lr: 4.4678e-06  max_mem: 17674M
[01/19 12:52:07] d2.utils.events INFO:  eta: 7:39:49  iter: 23679  total_loss: 56.99  loss_ce: 1.718  loss_mask: 0.6032  loss_dice: 3.167  loss_ce_0: 2.982  loss_mask_0: 0.6126  loss_dice_0: 3.488  loss_ce_1: 1.981  loss_mask_1: 0.5982  loss_dice_1: 3.293  loss_ce_2: 1.868  loss_mask_2: 0.5986  loss_dice_2: 3.23  loss_ce_3: 1.799  loss_mask_3: 0.5985  loss_dice_3: 3.187  loss_ce_4: 1.773  loss_mask_4: 0.5998  loss_dice_4: 3.182  loss_ce_5: 1.758  loss_mask_5: 0.6015  loss_dice_5: 3.185  loss_ce_6: 1.734  loss_mask_6: 0.6008  loss_dice_6: 3.169  loss_ce_7: 1.727  loss_mask_7: 0.6023  loss_dice_7: 3.168  loss_ce_8: 1.713  loss_mask_8: 0.6011  loss_dice_8: 3.165  time: 1.6942  data_time: 0.3536  lr: 4.4629e-06  max_mem: 17674M
[01/19 12:52:41] d2.utils.events INFO:  eta: 7:39:22  iter: 23699  total_loss: 57.49  loss_ce: 1.692  loss_mask: 0.6171  loss_dice: 3.149  loss_ce_0: 3.005  loss_mask_0: 0.6446  loss_dice_0: 3.468  loss_ce_1: 2.016  loss_mask_1: 0.6273  loss_dice_1: 3.286  loss_ce_2: 1.861  loss_mask_2: 0.6191  loss_dice_2: 3.22  loss_ce_3: 1.785  loss_mask_3: 0.6201  loss_dice_3: 3.172  loss_ce_4: 1.737  loss_mask_4: 0.6175  loss_dice_4: 3.166  loss_ce_5: 1.706  loss_mask_5: 0.6159  loss_dice_5: 3.169  loss_ce_6: 1.723  loss_mask_6: 0.6156  loss_dice_6: 3.156  loss_ce_7: 1.692  loss_mask_7: 0.6147  loss_dice_7: 3.159  loss_ce_8: 1.685  loss_mask_8: 0.6155  loss_dice_8: 3.154  time: 1.6942  data_time: 0.3442  lr: 4.458e-06  max_mem: 17674M
[01/19 12:53:15] d2.utils.events INFO:  eta: 7:38:50  iter: 23719  total_loss: 57.03  loss_ce: 1.68  loss_mask: 0.6256  loss_dice: 3.163  loss_ce_0: 2.983  loss_mask_0: 0.651  loss_dice_0: 3.465  loss_ce_1: 1.951  loss_mask_1: 0.6241  loss_dice_1: 3.297  loss_ce_2: 1.814  loss_mask_2: 0.6259  loss_dice_2: 3.225  loss_ce_3: 1.755  loss_mask_3: 0.6257  loss_dice_3: 3.188  loss_ce_4: 1.703  loss_mask_4: 0.6281  loss_dice_4: 3.19  loss_ce_5: 1.686  loss_mask_5: 0.6273  loss_dice_5: 3.183  loss_ce_6: 1.668  loss_mask_6: 0.6298  loss_dice_6: 3.164  loss_ce_7: 1.677  loss_mask_7: 0.6302  loss_dice_7: 3.164  loss_ce_8: 1.652  loss_mask_8: 0.6281  loss_dice_8: 3.168  time: 1.6942  data_time: 0.3382  lr: 4.4531e-06  max_mem: 17674M
[01/19 12:53:49] d2.utils.events INFO:  eta: 7:38:26  iter: 23739  total_loss: 58.01  loss_ce: 1.724  loss_mask: 0.6065  loss_dice: 3.202  loss_ce_0: 3.049  loss_mask_0: 0.6255  loss_dice_0: 3.522  loss_ce_1: 1.972  loss_mask_1: 0.6102  loss_dice_1: 3.354  loss_ce_2: 1.855  loss_mask_2: 0.6074  loss_dice_2: 3.276  loss_ce_3: 1.812  loss_mask_3: 0.6047  loss_dice_3: 3.236  loss_ce_4: 1.771  loss_mask_4: 0.605  loss_dice_4: 3.225  loss_ce_5: 1.753  loss_mask_5: 0.6058  loss_dice_5: 3.221  loss_ce_6: 1.743  loss_mask_6: 0.6052  loss_dice_6: 3.216  loss_ce_7: 1.738  loss_mask_7: 0.6067  loss_dice_7: 3.204  loss_ce_8: 1.716  loss_mask_8: 0.6075  loss_dice_8: 3.215  time: 1.6942  data_time: 0.3367  lr: 4.4481e-06  max_mem: 17674M
[01/19 12:54:23] d2.utils.events INFO:  eta: 7:37:58  iter: 23759  total_loss: 58.6  loss_ce: 1.757  loss_mask: 0.6143  loss_dice: 3.218  loss_ce_0: 3.029  loss_mask_0: 0.6345  loss_dice_0: 3.501  loss_ce_1: 2.018  loss_mask_1: 0.6234  loss_dice_1: 3.335  loss_ce_2: 1.915  loss_mask_2: 0.6166  loss_dice_2: 3.279  loss_ce_3: 1.838  loss_mask_3: 0.6145  loss_dice_3: 3.232  loss_ce_4: 1.794  loss_mask_4: 0.6143  loss_dice_4: 3.232  loss_ce_5: 1.779  loss_mask_5: 0.6159  loss_dice_5: 3.23  loss_ce_6: 1.766  loss_mask_6: 0.6176  loss_dice_6: 3.219  loss_ce_7: 1.759  loss_mask_7: 0.6146  loss_dice_7: 3.216  loss_ce_8: 1.756  loss_mask_8: 0.6154  loss_dice_8: 3.219  time: 1.6943  data_time: 0.3492  lr: 4.4432e-06  max_mem: 17674M
[01/19 12:54:58] d2.utils.events INFO:  eta: 7:37:30  iter: 23779  total_loss: 57.34  loss_ce: 1.673  loss_mask: 0.6119  loss_dice: 3.178  loss_ce_0: 2.953  loss_mask_0: 0.6391  loss_dice_0: 3.483  loss_ce_1: 1.928  loss_mask_1: 0.6179  loss_dice_1: 3.314  loss_ce_2: 1.82  loss_mask_2: 0.6153  loss_dice_2: 3.248  loss_ce_3: 1.771  loss_mask_3: 0.6107  loss_dice_3: 3.213  loss_ce_4: 1.719  loss_mask_4: 0.6117  loss_dice_4: 3.202  loss_ce_5: 1.686  loss_mask_5: 0.6106  loss_dice_5: 3.202  loss_ce_6: 1.693  loss_mask_6: 0.6082  loss_dice_6: 3.185  loss_ce_7: 1.666  loss_mask_7: 0.6092  loss_dice_7: 3.186  loss_ce_8: 1.655  loss_mask_8: 0.6121  loss_dice_8: 3.182  time: 1.6943  data_time: 0.3597  lr: 4.4383e-06  max_mem: 17674M
[01/19 12:55:32] d2.utils.events INFO:  eta: 7:36:54  iter: 23799  total_loss: 57.19  loss_ce: 1.674  loss_mask: 0.6297  loss_dice: 3.178  loss_ce_0: 3.048  loss_mask_0: 0.6553  loss_dice_0: 3.496  loss_ce_1: 1.992  loss_mask_1: 0.6309  loss_dice_1: 3.315  loss_ce_2: 1.845  loss_mask_2: 0.6229  loss_dice_2: 3.244  loss_ce_3: 1.803  loss_mask_3: 0.6248  loss_dice_3: 3.2  loss_ce_4: 1.749  loss_mask_4: 0.6294  loss_dice_4: 3.201  loss_ce_5: 1.706  loss_mask_5: 0.6306  loss_dice_5: 3.193  loss_ce_6: 1.7  loss_mask_6: 0.6288  loss_dice_6: 3.18  loss_ce_7: 1.681  loss_mask_7: 0.6302  loss_dice_7: 3.179  loss_ce_8: 1.68  loss_mask_8: 0.6294  loss_dice_8: 3.171  time: 1.6943  data_time: 0.3558  lr: 4.4334e-06  max_mem: 17674M
[01/19 12:56:05] d2.utils.events INFO:  eta: 7:36:23  iter: 23819  total_loss: 58.18  loss_ce: 1.78  loss_mask: 0.6311  loss_dice: 3.157  loss_ce_0: 3.036  loss_mask_0: 0.644  loss_dice_0: 3.454  loss_ce_1: 2.063  loss_mask_1: 0.6367  loss_dice_1: 3.288  loss_ce_2: 1.914  loss_mask_2: 0.6317  loss_dice_2: 3.223  loss_ce_3: 1.889  loss_mask_3: 0.6315  loss_dice_3: 3.18  loss_ce_4: 1.846  loss_mask_4: 0.6293  loss_dice_4: 3.17  loss_ce_5: 1.81  loss_mask_5: 0.6314  loss_dice_5: 3.17  loss_ce_6: 1.796  loss_mask_6: 0.6273  loss_dice_6: 3.162  loss_ce_7: 1.781  loss_mask_7: 0.6293  loss_dice_7: 3.157  loss_ce_8: 1.789  loss_mask_8: 0.6298  loss_dice_8: 3.161  time: 1.6943  data_time: 0.3409  lr: 4.4284e-06  max_mem: 17674M
[01/19 12:56:40] d2.utils.events INFO:  eta: 7:35:47  iter: 23839  total_loss: 57.84  loss_ce: 1.712  loss_mask: 0.6268  loss_dice: 3.184  loss_ce_0: 3.012  loss_mask_0: 0.6504  loss_dice_0: 3.49  loss_ce_1: 2.009  loss_mask_1: 0.6329  loss_dice_1: 3.301  loss_ce_2: 1.869  loss_mask_2: 0.6306  loss_dice_2: 3.249  loss_ce_3: 1.822  loss_mask_3: 0.6251  loss_dice_3: 3.21  loss_ce_4: 1.768  loss_mask_4: 0.627  loss_dice_4: 3.213  loss_ce_5: 1.74  loss_mask_5: 0.6247  loss_dice_5: 3.208  loss_ce_6: 1.729  loss_mask_6: 0.6263  loss_dice_6: 3.19  loss_ce_7: 1.71  loss_mask_7: 0.6259  loss_dice_7: 3.189  loss_ce_8: 1.717  loss_mask_8: 0.6292  loss_dice_8: 3.187  time: 1.6943  data_time: 0.3440  lr: 4.4235e-06  max_mem: 17674M
[01/19 12:57:13] d2.utils.events INFO:  eta: 7:35:15  iter: 23859  total_loss: 56.86  loss_ce: 1.683  loss_mask: 0.6201  loss_dice: 3.169  loss_ce_0: 2.937  loss_mask_0: 0.6404  loss_dice_0: 3.468  loss_ce_1: 1.969  loss_mask_1: 0.6216  loss_dice_1: 3.307  loss_ce_2: 1.833  loss_mask_2: 0.6255  loss_dice_2: 3.237  loss_ce_3: 1.799  loss_mask_3: 0.616  loss_dice_3: 3.19  loss_ce_4: 1.743  loss_mask_4: 0.6177  loss_dice_4: 3.189  loss_ce_5: 1.72  loss_mask_5: 0.6182  loss_dice_5: 3.19  loss_ce_6: 1.702  loss_mask_6: 0.6192  loss_dice_6: 3.169  loss_ce_7: 1.7  loss_mask_7: 0.6194  loss_dice_7: 3.171  loss_ce_8: 1.695  loss_mask_8: 0.619  loss_dice_8: 3.174  time: 1.6943  data_time: 0.3442  lr: 4.4186e-06  max_mem: 17674M
[01/19 12:57:48] d2.utils.events INFO:  eta: 7:34:43  iter: 23879  total_loss: 57.5  loss_ce: 1.716  loss_mask: 0.6302  loss_dice: 3.17  loss_ce_0: 3.056  loss_mask_0: 0.6514  loss_dice_0: 3.46  loss_ce_1: 2.004  loss_mask_1: 0.6333  loss_dice_1: 3.297  loss_ce_2: 1.868  loss_mask_2: 0.6269  loss_dice_2: 3.236  loss_ce_3: 1.811  loss_mask_3: 0.626  loss_dice_3: 3.195  loss_ce_4: 1.758  loss_mask_4: 0.6273  loss_dice_4: 3.19  loss_ce_5: 1.748  loss_mask_5: 0.6289  loss_dice_5: 3.187  loss_ce_6: 1.737  loss_mask_6: 0.6265  loss_dice_6: 3.17  loss_ce_7: 1.71  loss_mask_7: 0.6269  loss_dice_7: 3.174  loss_ce_8: 1.714  loss_mask_8: 0.6257  loss_dice_8: 3.174  time: 1.6943  data_time: 0.3553  lr: 4.4137e-06  max_mem: 17674M
[01/19 12:58:22] d2.utils.events INFO:  eta: 7:34:08  iter: 23899  total_loss: 57.92  loss_ce: 1.676  loss_mask: 0.6212  loss_dice: 3.188  loss_ce_0: 3.023  loss_mask_0: 0.6411  loss_dice_0: 3.501  loss_ce_1: 1.965  loss_mask_1: 0.6293  loss_dice_1: 3.317  loss_ce_2: 1.834  loss_mask_2: 0.6198  loss_dice_2: 3.259  loss_ce_3: 1.778  loss_mask_3: 0.6189  loss_dice_3: 3.206  loss_ce_4: 1.723  loss_mask_4: 0.6197  loss_dice_4: 3.202  loss_ce_5: 1.7  loss_mask_5: 0.6215  loss_dice_5: 3.201  loss_ce_6: 1.71  loss_mask_6: 0.621  loss_dice_6: 3.195  loss_ce_7: 1.682  loss_mask_7: 0.6217  loss_dice_7: 3.196  loss_ce_8: 1.664  loss_mask_8: 0.6204  loss_dice_8: 3.197  time: 1.6943  data_time: 0.3462  lr: 4.4087e-06  max_mem: 17674M
[01/19 12:58:56] d2.utils.events INFO:  eta: 7:33:33  iter: 23919  total_loss: 56.73  loss_ce: 1.681  loss_mask: 0.62  loss_dice: 3.122  loss_ce_0: 3.012  loss_mask_0: 0.6436  loss_dice_0: 3.44  loss_ce_1: 1.939  loss_mask_1: 0.6227  loss_dice_1: 3.253  loss_ce_2: 1.833  loss_mask_2: 0.6229  loss_dice_2: 3.191  loss_ce_3: 1.777  loss_mask_3: 0.6161  loss_dice_3: 3.144  loss_ce_4: 1.725  loss_mask_4: 0.6224  loss_dice_4: 3.147  loss_ce_5: 1.684  loss_mask_5: 0.6202  loss_dice_5: 3.14  loss_ce_6: 1.677  loss_mask_6: 0.6184  loss_dice_6: 3.126  loss_ce_7: 1.66  loss_mask_7: 0.6184  loss_dice_7: 3.132  loss_ce_8: 1.686  loss_mask_8: 0.6178  loss_dice_8: 3.124  time: 1.6943  data_time: 0.3282  lr: 4.4038e-06  max_mem: 17674M
[01/19 12:59:29] d2.utils.events INFO:  eta: 7:32:57  iter: 23939  total_loss: 57.89  loss_ce: 1.759  loss_mask: 0.6383  loss_dice: 3.152  loss_ce_0: 3.046  loss_mask_0: 0.6623  loss_dice_0: 3.478  loss_ce_1: 2.046  loss_mask_1: 0.6491  loss_dice_1: 3.294  loss_ce_2: 1.936  loss_mask_2: 0.6417  loss_dice_2: 3.223  loss_ce_3: 1.856  loss_mask_3: 0.6313  loss_dice_3: 3.178  loss_ce_4: 1.81  loss_mask_4: 0.6391  loss_dice_4: 3.177  loss_ce_5: 1.775  loss_mask_5: 0.6388  loss_dice_5: 3.174  loss_ce_6: 1.782  loss_mask_6: 0.6387  loss_dice_6: 3.161  loss_ce_7: 1.752  loss_mask_7: 0.6381  loss_dice_7: 3.153  loss_ce_8: 1.744  loss_mask_8: 0.6408  loss_dice_8: 3.152  time: 1.6943  data_time: 0.3337  lr: 4.3989e-06  max_mem: 17674M
[01/19 13:00:04] d2.utils.events INFO:  eta: 7:32:26  iter: 23959  total_loss: 58.28  loss_ce: 1.715  loss_mask: 0.6074  loss_dice: 3.184  loss_ce_0: 3.008  loss_mask_0: 0.6298  loss_dice_0: 3.495  loss_ce_1: 1.974  loss_mask_1: 0.6143  loss_dice_1: 3.32  loss_ce_2: 1.878  loss_mask_2: 0.614  loss_dice_2: 3.251  loss_ce_3: 1.807  loss_mask_3: 0.6112  loss_dice_3: 3.211  loss_ce_4: 1.765  loss_mask_4: 0.6114  loss_dice_4: 3.205  loss_ce_5: 1.733  loss_mask_5: 0.6128  loss_dice_5: 3.201  loss_ce_6: 1.732  loss_mask_6: 0.6113  loss_dice_6: 3.187  loss_ce_7: 1.724  loss_mask_7: 0.6084  loss_dice_7: 3.19  loss_ce_8: 1.694  loss_mask_8: 0.6096  loss_dice_8: 3.188  time: 1.6943  data_time: 0.3676  lr: 4.3939e-06  max_mem: 17674M
[01/19 13:00:38] d2.utils.events INFO:  eta: 7:31:53  iter: 23979  total_loss: 56.76  loss_ce: 1.657  loss_mask: 0.6136  loss_dice: 3.146  loss_ce_0: 2.976  loss_mask_0: 0.6297  loss_dice_0: 3.444  loss_ce_1: 1.976  loss_mask_1: 0.6211  loss_dice_1: 3.293  loss_ce_2: 1.809  loss_mask_2: 0.6195  loss_dice_2: 3.235  loss_ce_3: 1.765  loss_mask_3: 0.6145  loss_dice_3: 3.183  loss_ce_4: 1.71  loss_mask_4: 0.6173  loss_dice_4: 3.176  loss_ce_5: 1.696  loss_mask_5: 0.6172  loss_dice_5: 3.17  loss_ce_6: 1.688  loss_mask_6: 0.6143  loss_dice_6: 3.156  loss_ce_7: 1.644  loss_mask_7: 0.6167  loss_dice_7: 3.15  loss_ce_8: 1.654  loss_mask_8: 0.6174  loss_dice_8: 3.154  time: 1.6943  data_time: 0.3417  lr: 4.389e-06  max_mem: 17674M
[01/19 13:01:12] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 13:01:13] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 13:01:13] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 13:06:49] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.8829366939304415, 'error_1pix': 0.32969797851561555, 'error_3pix': 0.1464376734898039, 'mIoU': 8.838143885023666, 'fwIoU': 25.368281234682517, 'IoU-0': nan, 'IoU-1': 95.53671078253164, 'IoU-2': 11.415184412152081, 'IoU-3': 38.72881547933872, 'IoU-4': 30.34485832312745, 'IoU-5': 16.192980681703247, 'IoU-6': 20.89801755693679, 'IoU-7': 14.121231839625592, 'IoU-8': 6.839428458031111, 'IoU-9': 8.593106161414177, 'IoU-10': 24.597610570096766, 'IoU-11': 33.032737593171326, 'IoU-12': 32.8919430194181, 'IoU-13': 30.718610665772772, 'IoU-14': 29.86126042737933, 'IoU-15': 29.878355335468687, 'IoU-16': 25.89701264317069, 'IoU-17': 23.91452155546223, 'IoU-18': 25.07939946003767, 'IoU-19': 24.097359012730475, 'IoU-20': 23.99279344344366, 'IoU-21': 23.831053942361134, 'IoU-22': 25.11031025898664, 'IoU-23': 23.13098884355514, 'IoU-24': 21.948428738653273, 'IoU-25': 21.61978305081955, 'IoU-26': 23.127711302645455, 'IoU-27': 24.111779991668236, 'IoU-28': 19.07379790309644, 'IoU-29': 24.621426521448388, 'IoU-30': 23.238077040196544, 'IoU-31': 20.68127855995206, 'IoU-32': 16.940708146057002, 'IoU-33': 21.724804703322096, 'IoU-34': 19.510965636843657, 'IoU-35': 17.006321295844188, 'IoU-36': 20.086336922976493, 'IoU-37': 18.593635486408655, 'IoU-38': 18.547756189086005, 'IoU-39': 16.564176707129498, 'IoU-40': 17.341508120441677, 'IoU-41': 15.56214817151567, 'IoU-42': 16.506723055587592, 'IoU-43': 14.307281989634646, 'IoU-44': 15.228720554829748, 'IoU-45': 15.466121805173353, 'IoU-46': 14.802819424032384, 'IoU-47': 13.134970556446964, 'IoU-48': 13.028708606251746, 'IoU-49': 14.309422219041082, 'IoU-50': 12.833254433269634, 'IoU-51': 14.397384620627138, 'IoU-52': 12.262664634291566, 'IoU-53': 14.490418252326046, 'IoU-54': 14.429340738208603, 'IoU-55': 15.134638248752836, 'IoU-56': 12.418535222354635, 'IoU-57': 12.160973051420115, 'IoU-58': 13.40941577617507, 'IoU-59': 10.468132940855503, 'IoU-60': 13.040335080376527, 'IoU-61': 10.990740765086205, 'IoU-62': 10.891911140295157, 'IoU-63': 10.435235604461312, 'IoU-64': 10.97353790922152, 'IoU-65': 11.235797589536583, 'IoU-66': 8.808549850658043, 'IoU-67': 9.682815075157365, 'IoU-68': 8.712617339860872, 'IoU-69': 7.864700772280117, 'IoU-70': 7.901908354943392, 'IoU-71': 7.804394885342241, 'IoU-72': 5.892725933014885, 'IoU-73': 7.95905594565948, 'IoU-74': 6.7348622267806855, 'IoU-75': 7.344842350183479, 'IoU-76': 6.419879440274283, 'IoU-77': 5.850726049722198, 'IoU-78': 5.5840121449749915, 'IoU-79': 6.276493434142741, 'IoU-80': 5.454525530076271, 'IoU-81': 6.351748368240122, 'IoU-82': 4.566348986416169, 'IoU-83': 4.201794267290159, 'IoU-84': 5.013953725838315, 'IoU-85': 5.195679250150116, 'IoU-86': 4.362244132421096, 'IoU-87': 5.905404204250857, 'IoU-88': 4.601330751043989, 'IoU-89': 4.453884873760812, 'IoU-90': 4.199849458915858, 'IoU-91': 4.78916508143237, 'IoU-92': 4.21907535579821, 'IoU-93': 3.776084291199356, 'IoU-94': 4.820559239181588, 'IoU-95': 4.123326766742333, 'IoU-96': 5.961753702036113, 'IoU-97': 3.591896682057933, 'IoU-98': 4.1866214938704776, 'IoU-99': 4.574605786687025, 'IoU-100': 4.223667410266994, 'IoU-101': 4.727086147339008, 'IoU-102': 3.9820723549213644, 'IoU-103': 5.110527839434132, 'IoU-104': 3.92499944927905, 'IoU-105': 4.696023821530763, 'IoU-106': 5.213165222750309, 'IoU-107': 4.479008657491663, 'IoU-108': 4.3840835953685495, 'IoU-109': 5.053788537166864, 'IoU-110': 5.027625104506165, 'IoU-111': 4.840526540518675, 'IoU-112': 4.411987031818718, 'IoU-113': 4.310449085543709, 'IoU-114': 4.893219868740036, 'IoU-115': 4.700084656139559, 'IoU-116': 3.6912096597014123, 'IoU-117': 4.067355483197048, 'IoU-118': 3.6778599974591555, 'IoU-119': 4.030696920048853, 'IoU-120': 4.555198580764678, 'IoU-121': 3.7115049763156063, 'IoU-122': 3.1393304114991727, 'IoU-123': 2.628632759079242, 'IoU-124': 4.034550527841439, 'IoU-125': 2.1923580417783226, 'IoU-126': 3.4642074988785985, 'IoU-127': 3.6775898331395482, 'IoU-128': 3.0112872525150123, 'IoU-129': 2.9668559749736145, 'IoU-130': 2.2870124690663736, 'IoU-131': 1.9152447266847075, 'IoU-132': 2.8637903080252802, 'IoU-133': 1.6575133454080258, 'IoU-134': 1.5556921514974935, 'IoU-135': 3.1900460519879235, 'IoU-136': 1.4782058862785479, 'IoU-137': 1.456839107306209, 'IoU-138': 0.9369593873747649, 'IoU-139': 1.9778990500486358, 'IoU-140': 2.7638386929933803, 'IoU-141': 1.437899217742326, 'IoU-142': 1.2145045363497113, 'IoU-143': 1.7336720565238928, 'IoU-144': 0.9039659095389868, 'IoU-145': 3.0704159787028216, 'IoU-146': 1.6387440036604208, 'IoU-147': 2.3202236334077067, 'IoU-148': 1.1852959646550116, 'IoU-149': 1.1429970180065139, 'IoU-150': 2.0230196573475245, 'IoU-151': 0.9404160395791799, 'IoU-152': 0.7453506236771705, 'IoU-153': 1.0510580612926081, 'IoU-154': 1.7847152782286866, 'IoU-155': 0.9215260222347007, 'IoU-156': 1.9383768822540604, 'IoU-157': 0.7066173623392533, 'IoU-158': 0.5783454822559397, 'IoU-159': 0.8519391998626119, 'IoU-160': 1.8556569233446956, 'IoU-161': 0.29687445633812937, 'IoU-162': 1.473502249717222, 'IoU-163': 0.583301665123399, 'IoU-164': 1.4076819055821774, 'IoU-165': 1.245965150106049, 'IoU-166': 0.32406342824496065, 'IoU-167': 1.104846645234287, 'IoU-168': 1.1098965255953195, 'IoU-169': 0.48015101784382686, 'IoU-170': 1.1422166195835501, 'IoU-171': 0.1331577195293164, 'IoU-172': 0.5758579076028096, 'IoU-173': 0.8520802522532579, 'IoU-174': 0.4644331378898084, 'IoU-175': 0.19253764617660768, 'IoU-176': 0.028279024481044107, 'IoU-177': 0.5276827374208678, 'IoU-178': 0.9298206774407793, 'IoU-179': 0.38364357710799324, 'IoU-180': 0.6148309456325275, 'IoU-181': 1.7860384199223491, 'IoU-182': 0.699175445326097, 'IoU-183': 0.7399837586795259, 'IoU-184': 0.7211169557991387, 'IoU-185': 0.1482663745555218, 'IoU-186': 0.33608084051081, 'IoU-187': 1.5925227128568733, 'IoU-188': 0.9758321395797594, 'IoU-189': 2.234536809225694, 'IoU-190': 2.543306803039579, 'IoU-191': 2.3676307479548573, 'IoU-192': 3.404122437827052, 'mACC': 14.8624804044311, 'pACC': 36.17710828596113, 'ACC-0': nan, 'ACC-1': 98.64129364082193, 'ACC-2': 12.058875300270984, 'ACC-3': 57.27658630482656, 'ACC-4': 43.82402911482198, 'ACC-5': 21.47660433398617, 'ACC-6': 36.84397511714499, 'ACC-7': 20.573671563640605, 'ACC-8': 8.094178445357203, 'ACC-9': 9.640955598509263, 'ACC-10': 40.73963475227267, 'ACC-11': 52.35768661084188, 'ACC-12': 54.84788929980373, 'ACC-13': 55.074353144021615, 'ACC-14': 46.17340932052778, 'ACC-15': 48.003922511404724, 'ACC-16': 38.40258049077851, 'ACC-17': 37.08250453757377, 'ACC-18': 38.56851567831725, 'ACC-19': 37.73108678114222, 'ACC-20': 39.60762387622625, 'ACC-21': 37.707752447785694, 'ACC-22': 40.617633603475674, 'ACC-23': 37.91878249638301, 'ACC-24': 35.6000249070996, 'ACC-25': 35.575945534973094, 'ACC-26': 39.90359844698044, 'ACC-27': 39.34660972434741, 'ACC-28': 29.24898212722118, 'ACC-29': 45.30008232113005, 'ACC-30': 40.82971567530365, 'ACC-31': 30.282382332618617, 'ACC-32': 24.155177527854605, 'ACC-33': 41.588898439468984, 'ACC-34': 33.726528814849424, 'ACC-35': 25.815887214645432, 'ACC-36': 33.50814669755347, 'ACC-37': 33.45152697398094, 'ACC-38': 31.94218826644398, 'ACC-39': 28.260987981745682, 'ACC-40': 29.24003194045288, 'ACC-41': 28.10273097164101, 'ACC-42': 29.758004387720842, 'ACC-43': 23.162810702998318, 'ACC-44': 23.994527979037734, 'ACC-45': 25.168118370287218, 'ACC-46': 28.607113977131732, 'ACC-47': 21.47035101455263, 'ACC-48': 20.724146693614163, 'ACC-49': 24.54395415276078, 'ACC-50': 20.8963448478724, 'ACC-51': 26.085577611876065, 'ACC-52': 20.44994219919016, 'ACC-53': 26.811068366336055, 'ACC-54': 25.943458478752255, 'ACC-55': 29.122627750875218, 'ACC-56': 20.704796552045515, 'ACC-57': 21.752238594387027, 'ACC-58': 24.682241574258708, 'ACC-59': 18.334678213726836, 'ACC-60': 27.003944027707654, 'ACC-61': 19.19024818101201, 'ACC-62': 20.70328519063485, 'ACC-63': 18.9031633530923, 'ACC-64': 19.15120887392856, 'ACC-65': 24.72717812617619, 'ACC-66': 14.761393048575428, 'ACC-67': 20.63744262013402, 'ACC-68': 16.97962553670164, 'ACC-69': 14.28899933577226, 'ACC-70': 14.851064893320043, 'ACC-71': 15.528447709832975, 'ACC-72': 10.160936329287708, 'ACC-73': 18.197909102440633, 'ACC-74': 11.135359929379113, 'ACC-75': 14.836607373935149, 'ACC-76': 12.487921293219106, 'ACC-77': 12.46929539494784, 'ACC-78': 9.761527477093457, 'ACC-79': 11.869772924949986, 'ACC-80': 9.632121528245822, 'ACC-81': 16.54431994078782, 'ACC-82': 8.454150089030374, 'ACC-83': 6.85662307476651, 'ACC-84': 9.668036102475973, 'ACC-85': 9.778220160137167, 'ACC-86': 7.101916473920408, 'ACC-87': 11.924506870486029, 'ACC-88': 8.02891140089432, 'ACC-89': 8.685834697801702, 'ACC-90': 6.872380315185469, 'ACC-91': 8.738662437768768, 'ACC-92': 7.9734668069886245, 'ACC-93': 6.238340485018145, 'ACC-94': 9.150248387669658, 'ACC-95': 6.230116882667179, 'ACC-96': 12.735232025877666, 'ACC-97': 6.069617857328129, 'ACC-98': 6.665458309044323, 'ACC-99': 8.025026091343229, 'ACC-100': 7.482258806127737, 'ACC-101': 8.249401190912202, 'ACC-102': 6.462890801993656, 'ACC-103': 8.633276660054785, 'ACC-104': 6.441504144020069, 'ACC-105': 8.65916444454433, 'ACC-106': 9.626784793224767, 'ACC-107': 7.517329608500972, 'ACC-108': 7.373424971679683, 'ACC-109': 8.993016132210132, 'ACC-110': 9.046122013062268, 'ACC-111': 8.640372361112808, 'ACC-112': 8.364313508023482, 'ACC-113': 7.007894358126092, 'ACC-114': 9.024098787280014, 'ACC-115': 10.214882804865216, 'ACC-116': 6.279643950315285, 'ACC-117': 7.530496404883926, 'ACC-118': 6.162664688245398, 'ACC-119': 6.184332481105812, 'ACC-120': 9.792033439104355, 'ACC-121': 7.216708370673143, 'ACC-122': 4.917678583222471, 'ACC-123': 4.120836285622369, 'ACC-124': 8.62340385520012, 'ACC-125': 4.453844672887641, 'ACC-126': 7.473314875363164, 'ACC-127': 6.979319496490949, 'ACC-128': 6.332793017608439, 'ACC-129': 5.8883292052569125, 'ACC-130': 4.689430739107891, 'ACC-131': 2.9171011349008085, 'ACC-132': 6.3274053074095296, 'ACC-133': 2.434083841950914, 'ACC-134': 2.214011202068074, 'ACC-135': 7.876902685137678, 'ACC-136': 2.8863008991800223, 'ACC-137': 2.111329649974012, 'ACC-138': 1.3897790440896516, 'ACC-139': 3.2557411213581764, 'ACC-140': 7.9534593257764366, 'ACC-141': 2.1990645286709003, 'ACC-142': 1.8003407678717553, 'ACC-143': 2.8870839185409034, 'ACC-144': 1.469043321299639, 'ACC-145': 11.327534157740558, 'ACC-146': 2.5889287427748964, 'ACC-147': 6.376609472944327, 'ACC-148': 1.9752844681484072, 'ACC-149': 1.9225835108902116, 'ACC-150': 4.2293745420357745, 'ACC-151': 1.5137224057134147, 'ACC-152': 0.8771874367792839, 'ACC-153': 1.4694296341083566, 'ACC-154': 4.034205857453676, 'ACC-155': 1.5352644929411852, 'ACC-156': 5.31443308964688, 'ACC-157': 0.8494242126051232, 'ACC-158': 0.8531495968532964, 'ACC-159': 1.6316167026286763, 'ACC-160': 3.4066359770166947, 'ACC-161': 0.37140843132243867, 'ACC-162': 4.732506002659915, 'ACC-163': 0.8329677284240875, 'ACC-164': 3.2547033698102794, 'ACC-165': 2.2596537145797533, 'ACC-166': 0.4589905230376644, 'ACC-167': 1.796351015430796, 'ACC-168': 2.199345945565792, 'ACC-169': 0.5739673938792019, 'ACC-170': 1.7414498062098045, 'ACC-171': 0.13519247477539864, 'ACC-172': 0.6893358521317183, 'ACC-173': 1.4362961095453297, 'ACC-174': 0.665447611378595, 'ACC-175': 0.22833202989947843, 'ACC-176': 0.02865973995820757, 'ACC-177': 0.6025441573516847, 'ACC-178': 1.2087825060699888, 'ACC-179': 0.4278923310089048, 'ACC-180': 0.8085272105387923, 'ACC-181': 3.589218842155379, 'ACC-182': 1.0450402640201475, 'ACC-183': 0.9546769754514998, 'ACC-184': 1.041703516604287, 'ACC-185': 0.16005432146667958, 'ACC-186': 0.38549336304598775, 'ACC-187': 2.3839379552785127, 'ACC-188': 1.2524716516686172, 'ACC-189': 4.740180888835262, 'ACC-190': 6.476047245249799, 'ACC-191': 5.755562805872757, 'ACC-192': 20.97738637296213})])
[01/19 13:06:49] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 13:06:49] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 13:06:49] d2.evaluation.testing INFO: copypaste: 2.8829,0.3297,0.1464,8.8381,25.3683,14.8625,36.1771
[01/19 13:06:49] d2.utils.events INFO:  eta: 7:31:23  iter: 23999  total_loss: 57.49  loss_ce: 1.675  loss_mask: 0.6134  loss_dice: 3.236  loss_ce_0: 3.057  loss_mask_0: 0.6354  loss_dice_0: 3.529  loss_ce_1: 1.968  loss_mask_1: 0.6214  loss_dice_1: 3.373  loss_ce_2: 1.854  loss_mask_2: 0.6196  loss_dice_2: 3.297  loss_ce_3: 1.797  loss_mask_3: 0.6177  loss_dice_3: 3.259  loss_ce_4: 1.736  loss_mask_4: 0.6159  loss_dice_4: 3.26  loss_ce_5: 1.718  loss_mask_5: 0.6153  loss_dice_5: 3.257  loss_ce_6: 1.704  loss_mask_6: 0.6134  loss_dice_6: 3.238  loss_ce_7: 1.67  loss_mask_7: 0.6124  loss_dice_7: 3.242  loss_ce_8: 1.673  loss_mask_8: 0.6168  loss_dice_8: 3.237  time: 1.6943  data_time: 0.3514  lr: 4.3841e-06  max_mem: 17674M
[01/19 13:07:23] d2.utils.events INFO:  eta: 7:30:54  iter: 24019  total_loss: 56.87  loss_ce: 1.682  loss_mask: 0.6269  loss_dice: 3.123  loss_ce_0: 2.986  loss_mask_0: 0.6541  loss_dice_0: 3.441  loss_ce_1: 1.995  loss_mask_1: 0.6291  loss_dice_1: 3.264  loss_ce_2: 1.846  loss_mask_2: 0.627  loss_dice_2: 3.199  loss_ce_3: 1.793  loss_mask_3: 0.6255  loss_dice_3: 3.152  loss_ce_4: 1.718  loss_mask_4: 0.6235  loss_dice_4: 3.153  loss_ce_5: 1.695  loss_mask_5: 0.6263  loss_dice_5: 3.144  loss_ce_6: 1.715  loss_mask_6: 0.6241  loss_dice_6: 3.125  loss_ce_7: 1.689  loss_mask_7: 0.628  loss_dice_7: 3.129  loss_ce_8: 1.695  loss_mask_8: 0.6268  loss_dice_8: 3.13  time: 1.6943  data_time: 0.3461  lr: 4.3791e-06  max_mem: 17674M
[01/19 13:07:57] d2.utils.events INFO:  eta: 7:30:20  iter: 24039  total_loss: 56.62  loss_ce: 1.703  loss_mask: 0.6175  loss_dice: 3.123  loss_ce_0: 2.931  loss_mask_0: 0.6416  loss_dice_0: 3.443  loss_ce_1: 1.937  loss_mask_1: 0.6327  loss_dice_1: 3.251  loss_ce_2: 1.84  loss_mask_2: 0.6308  loss_dice_2: 3.184  loss_ce_3: 1.756  loss_mask_3: 0.6174  loss_dice_3: 3.148  loss_ce_4: 1.739  loss_mask_4: 0.619  loss_dice_4: 3.141  loss_ce_5: 1.719  loss_mask_5: 0.6196  loss_dice_5: 3.145  loss_ce_6: 1.717  loss_mask_6: 0.6189  loss_dice_6: 3.134  loss_ce_7: 1.698  loss_mask_7: 0.618  loss_dice_7: 3.13  loss_ce_8: 1.697  loss_mask_8: 0.6167  loss_dice_8: 3.133  time: 1.6943  data_time: 0.3242  lr: 4.3742e-06  max_mem: 17674M
[01/19 13:08:31] d2.utils.events INFO:  eta: 7:29:40  iter: 24059  total_loss: 57.64  loss_ce: 1.709  loss_mask: 0.6379  loss_dice: 3.167  loss_ce_0: 3.027  loss_mask_0: 0.6519  loss_dice_0: 3.461  loss_ce_1: 2.006  loss_mask_1: 0.6343  loss_dice_1: 3.304  loss_ce_2: 1.879  loss_mask_2: 0.6378  loss_dice_2: 3.231  loss_ce_3: 1.811  loss_mask_3: 0.63  loss_dice_3: 3.195  loss_ce_4: 1.761  loss_mask_4: 0.6299  loss_dice_4: 3.189  loss_ce_5: 1.729  loss_mask_5: 0.6311  loss_dice_5: 3.182  loss_ce_6: 1.728  loss_mask_6: 0.6324  loss_dice_6: 3.18  loss_ce_7: 1.686  loss_mask_7: 0.6348  loss_dice_7: 3.173  loss_ce_8: 1.703  loss_mask_8: 0.6344  loss_dice_8: 3.172  time: 1.6943  data_time: 0.3395  lr: 4.3693e-06  max_mem: 17674M
[01/19 13:09:05] d2.utils.events INFO:  eta: 7:29:17  iter: 24079  total_loss: 58.04  loss_ce: 1.721  loss_mask: 0.6293  loss_dice: 3.218  loss_ce_0: 3.028  loss_mask_0: 0.653  loss_dice_0: 3.517  loss_ce_1: 1.998  loss_mask_1: 0.6391  loss_dice_1: 3.365  loss_ce_2: 1.864  loss_mask_2: 0.6298  loss_dice_2: 3.306  loss_ce_3: 1.808  loss_mask_3: 0.6251  loss_dice_3: 3.262  loss_ce_4: 1.764  loss_mask_4: 0.6298  loss_dice_4: 3.258  loss_ce_5: 1.739  loss_mask_5: 0.6298  loss_dice_5: 3.25  loss_ce_6: 1.731  loss_mask_6: 0.63  loss_dice_6: 3.241  loss_ce_7: 1.709  loss_mask_7: 0.6313  loss_dice_7: 3.234  loss_ce_8: 1.704  loss_mask_8: 0.63  loss_dice_8: 3.231  time: 1.6943  data_time: 0.3449  lr: 4.3643e-06  max_mem: 17674M
[01/19 13:09:39] d2.utils.events INFO:  eta: 7:28:34  iter: 24099  total_loss: 57.5  loss_ce: 1.698  loss_mask: 0.612  loss_dice: 3.136  loss_ce_0: 2.971  loss_mask_0: 0.6361  loss_dice_0: 3.465  loss_ce_1: 1.963  loss_mask_1: 0.6198  loss_dice_1: 3.265  loss_ce_2: 1.845  loss_mask_2: 0.6142  loss_dice_2: 3.209  loss_ce_3: 1.78  loss_mask_3: 0.6104  loss_dice_3: 3.16  loss_ce_4: 1.731  loss_mask_4: 0.613  loss_dice_4: 3.152  loss_ce_5: 1.714  loss_mask_5: 0.6121  loss_dice_5: 3.155  loss_ce_6: 1.707  loss_mask_6: 0.6141  loss_dice_6: 3.144  loss_ce_7: 1.688  loss_mask_7: 0.614  loss_dice_7: 3.138  loss_ce_8: 1.69  loss_mask_8: 0.6159  loss_dice_8: 3.144  time: 1.6943  data_time: 0.3565  lr: 4.3594e-06  max_mem: 17674M
[01/19 13:10:13] d2.utils.events INFO:  eta: 7:28:02  iter: 24119  total_loss: 56.9  loss_ce: 1.652  loss_mask: 0.6161  loss_dice: 3.2  loss_ce_0: 2.967  loss_mask_0: 0.6307  loss_dice_0: 3.498  loss_ce_1: 1.931  loss_mask_1: 0.6155  loss_dice_1: 3.324  loss_ce_2: 1.812  loss_mask_2: 0.611  loss_dice_2: 3.265  loss_ce_3: 1.732  loss_mask_3: 0.6113  loss_dice_3: 3.222  loss_ce_4: 1.693  loss_mask_4: 0.6126  loss_dice_4: 3.224  loss_ce_5: 1.68  loss_mask_5: 0.6139  loss_dice_5: 3.225  loss_ce_6: 1.659  loss_mask_6: 0.613  loss_dice_6: 3.203  loss_ce_7: 1.645  loss_mask_7: 0.6146  loss_dice_7: 3.195  loss_ce_8: 1.651  loss_mask_8: 0.6142  loss_dice_8: 3.197  time: 1.6943  data_time: 0.3312  lr: 4.3545e-06  max_mem: 17674M
[01/19 13:10:47] d2.utils.events INFO:  eta: 7:27:36  iter: 24139  total_loss: 57.4  loss_ce: 1.68  loss_mask: 0.6108  loss_dice: 3.168  loss_ce_0: 2.982  loss_mask_0: 0.631  loss_dice_0: 3.46  loss_ce_1: 2.004  loss_mask_1: 0.6144  loss_dice_1: 3.291  loss_ce_2: 1.882  loss_mask_2: 0.6174  loss_dice_2: 3.23  loss_ce_3: 1.81  loss_mask_3: 0.6098  loss_dice_3: 3.191  loss_ce_4: 1.753  loss_mask_4: 0.6147  loss_dice_4: 3.191  loss_ce_5: 1.718  loss_mask_5: 0.6114  loss_dice_5: 3.192  loss_ce_6: 1.724  loss_mask_6: 0.6107  loss_dice_6: 3.176  loss_ce_7: 1.702  loss_mask_7: 0.61  loss_dice_7: 3.178  loss_ce_8: 1.695  loss_mask_8: 0.6113  loss_dice_8: 3.171  time: 1.6943  data_time: 0.3476  lr: 4.3495e-06  max_mem: 17674M
[01/19 13:11:21] d2.utils.events INFO:  eta: 7:27:02  iter: 24159  total_loss: 57.59  loss_ce: 1.647  loss_mask: 0.6251  loss_dice: 3.209  loss_ce_0: 2.929  loss_mask_0: 0.6484  loss_dice_0: 3.504  loss_ce_1: 2  loss_mask_1: 0.6285  loss_dice_1: 3.328  loss_ce_2: 1.807  loss_mask_2: 0.6257  loss_dice_2: 3.265  loss_ce_3: 1.77  loss_mask_3: 0.6234  loss_dice_3: 3.226  loss_ce_4: 1.722  loss_mask_4: 0.6253  loss_dice_4: 3.222  loss_ce_5: 1.698  loss_mask_5: 0.6266  loss_dice_5: 3.221  loss_ce_6: 1.667  loss_mask_6: 0.6265  loss_dice_6: 3.204  loss_ce_7: 1.647  loss_mask_7: 0.6275  loss_dice_7: 3.207  loss_ce_8: 1.648  loss_mask_8: 0.6258  loss_dice_8: 3.213  time: 1.6944  data_time: 0.3473  lr: 4.3446e-06  max_mem: 17674M
[01/19 13:11:55] d2.utils.events INFO:  eta: 7:26:38  iter: 24179  total_loss: 57.29  loss_ce: 1.696  loss_mask: 0.6221  loss_dice: 3.189  loss_ce_0: 2.996  loss_mask_0: 0.6445  loss_dice_0: 3.481  loss_ce_1: 1.963  loss_mask_1: 0.6228  loss_dice_1: 3.316  loss_ce_2: 1.826  loss_mask_2: 0.6193  loss_dice_2: 3.256  loss_ce_3: 1.773  loss_mask_3: 0.6183  loss_dice_3: 3.213  loss_ce_4: 1.721  loss_mask_4: 0.6187  loss_dice_4: 3.209  loss_ce_5: 1.702  loss_mask_5: 0.6186  loss_dice_5: 3.207  loss_ce_6: 1.697  loss_mask_6: 0.6189  loss_dice_6: 3.196  loss_ce_7: 1.688  loss_mask_7: 0.6208  loss_dice_7: 3.194  loss_ce_8: 1.69  loss_mask_8: 0.6201  loss_dice_8: 3.191  time: 1.6944  data_time: 0.3461  lr: 4.3397e-06  max_mem: 17674M
[01/19 13:12:29] d2.utils.events INFO:  eta: 7:26:01  iter: 24199  total_loss: 57.22  loss_ce: 1.698  loss_mask: 0.6267  loss_dice: 3.172  loss_ce_0: 2.965  loss_mask_0: 0.6495  loss_dice_0: 3.477  loss_ce_1: 1.947  loss_mask_1: 0.6289  loss_dice_1: 3.302  loss_ce_2: 1.826  loss_mask_2: 0.627  loss_dice_2: 3.236  loss_ce_3: 1.784  loss_mask_3: 0.6213  loss_dice_3: 3.201  loss_ce_4: 1.752  loss_mask_4: 0.6213  loss_dice_4: 3.19  loss_ce_5: 1.72  loss_mask_5: 0.6214  loss_dice_5: 3.19  loss_ce_6: 1.728  loss_mask_6: 0.627  loss_dice_6: 3.179  loss_ce_7: 1.716  loss_mask_7: 0.6242  loss_dice_7: 3.182  loss_ce_8: 1.698  loss_mask_8: 0.6254  loss_dice_8: 3.175  time: 1.6943  data_time: 0.3495  lr: 4.3347e-06  max_mem: 17674M
[01/19 13:13:03] d2.utils.events INFO:  eta: 7:25:29  iter: 24219  total_loss: 57.05  loss_ce: 1.693  loss_mask: 0.6179  loss_dice: 3.126  loss_ce_0: 3.039  loss_mask_0: 0.6435  loss_dice_0: 3.455  loss_ce_1: 1.949  loss_mask_1: 0.6241  loss_dice_1: 3.283  loss_ce_2: 1.802  loss_mask_2: 0.623  loss_dice_2: 3.21  loss_ce_3: 1.753  loss_mask_3: 0.62  loss_dice_3: 3.159  loss_ce_4: 1.732  loss_mask_4: 0.6163  loss_dice_4: 3.159  loss_ce_5: 1.714  loss_mask_5: 0.6173  loss_dice_5: 3.148  loss_ce_6: 1.701  loss_mask_6: 0.6173  loss_dice_6: 3.137  loss_ce_7: 1.712  loss_mask_7: 0.6185  loss_dice_7: 3.14  loss_ce_8: 1.71  loss_mask_8: 0.6181  loss_dice_8: 3.131  time: 1.6943  data_time: 0.3499  lr: 4.3298e-06  max_mem: 17674M
[01/19 13:13:37] d2.utils.events INFO:  eta: 7:25:05  iter: 24239  total_loss: 56.81  loss_ce: 1.647  loss_mask: 0.6054  loss_dice: 3.145  loss_ce_0: 2.912  loss_mask_0: 0.624  loss_dice_0: 3.459  loss_ce_1: 1.923  loss_mask_1: 0.6148  loss_dice_1: 3.275  loss_ce_2: 1.794  loss_mask_2: 0.6092  loss_dice_2: 3.218  loss_ce_3: 1.728  loss_mask_3: 0.6055  loss_dice_3: 3.163  loss_ce_4: 1.668  loss_mask_4: 0.6087  loss_dice_4: 3.163  loss_ce_5: 1.65  loss_mask_5: 0.6091  loss_dice_5: 3.169  loss_ce_6: 1.652  loss_mask_6: 0.6039  loss_dice_6: 3.151  loss_ce_7: 1.632  loss_mask_7: 0.6065  loss_dice_7: 3.146  loss_ce_8: 1.635  loss_mask_8: 0.6072  loss_dice_8: 3.149  time: 1.6944  data_time: 0.3509  lr: 4.3249e-06  max_mem: 17674M
[01/19 13:14:11] d2.utils.events INFO:  eta: 7:24:16  iter: 24259  total_loss: 58.57  loss_ce: 1.71  loss_mask: 0.6373  loss_dice: 3.17  loss_ce_0: 3.096  loss_mask_0: 0.6649  loss_dice_0: 3.479  loss_ce_1: 2.04  loss_mask_1: 0.6439  loss_dice_1: 3.307  loss_ce_2: 1.89  loss_mask_2: 0.6383  loss_dice_2: 3.246  loss_ce_3: 1.793  loss_mask_3: 0.6368  loss_dice_3: 3.197  loss_ce_4: 1.749  loss_mask_4: 0.6397  loss_dice_4: 3.197  loss_ce_5: 1.741  loss_mask_5: 0.639  loss_dice_5: 3.185  loss_ce_6: 1.726  loss_mask_6: 0.6396  loss_dice_6: 3.175  loss_ce_7: 1.699  loss_mask_7: 0.6388  loss_dice_7: 3.178  loss_ce_8: 1.701  loss_mask_8: 0.6358  loss_dice_8: 3.175  time: 1.6943  data_time: 0.3420  lr: 4.3199e-06  max_mem: 17674M
[01/19 13:14:45] d2.utils.events INFO:  eta: 7:23:47  iter: 24279  total_loss: 57.41  loss_ce: 1.671  loss_mask: 0.6164  loss_dice: 3.189  loss_ce_0: 2.965  loss_mask_0: 0.6312  loss_dice_0: 3.495  loss_ce_1: 1.956  loss_mask_1: 0.6167  loss_dice_1: 3.315  loss_ce_2: 1.828  loss_mask_2: 0.6167  loss_dice_2: 3.255  loss_ce_3: 1.759  loss_mask_3: 0.61  loss_dice_3: 3.206  loss_ce_4: 1.737  loss_mask_4: 0.6134  loss_dice_4: 3.207  loss_ce_5: 1.687  loss_mask_5: 0.6178  loss_dice_5: 3.205  loss_ce_6: 1.692  loss_mask_6: 0.6161  loss_dice_6: 3.189  loss_ce_7: 1.679  loss_mask_7: 0.6189  loss_dice_7: 3.183  loss_ce_8: 1.684  loss_mask_8: 0.6181  loss_dice_8: 3.187  time: 1.6943  data_time: 0.3520  lr: 4.315e-06  max_mem: 17674M
[01/19 13:15:19] d2.utils.events INFO:  eta: 7:23:10  iter: 24299  total_loss: 56.26  loss_ce: 1.601  loss_mask: 0.6183  loss_dice: 3.16  loss_ce_0: 2.918  loss_mask_0: 0.6421  loss_dice_0: 3.461  loss_ce_1: 1.913  loss_mask_1: 0.6264  loss_dice_1: 3.287  loss_ce_2: 1.786  loss_mask_2: 0.6199  loss_dice_2: 3.226  loss_ce_3: 1.721  loss_mask_3: 0.6204  loss_dice_3: 3.187  loss_ce_4: 1.663  loss_mask_4: 0.6196  loss_dice_4: 3.171  loss_ce_5: 1.639  loss_mask_5: 0.6215  loss_dice_5: 3.175  loss_ce_6: 1.634  loss_mask_6: 0.6218  loss_dice_6: 3.163  loss_ce_7: 1.611  loss_mask_7: 0.6198  loss_dice_7: 3.164  loss_ce_8: 1.604  loss_mask_8: 0.6193  loss_dice_8: 3.163  time: 1.6943  data_time: 0.3567  lr: 4.31e-06  max_mem: 17674M
[01/19 13:15:52] d2.utils.events INFO:  eta: 7:22:32  iter: 24319  total_loss: 56.49  loss_ce: 1.646  loss_mask: 0.6036  loss_dice: 3.177  loss_ce_0: 2.912  loss_mask_0: 0.6245  loss_dice_0: 3.482  loss_ce_1: 1.907  loss_mask_1: 0.6112  loss_dice_1: 3.312  loss_ce_2: 1.801  loss_mask_2: 0.6026  loss_dice_2: 3.239  loss_ce_3: 1.732  loss_mask_3: 0.5989  loss_dice_3: 3.197  loss_ce_4: 1.673  loss_mask_4: 0.6051  loss_dice_4: 3.192  loss_ce_5: 1.653  loss_mask_5: 0.6043  loss_dice_5: 3.197  loss_ce_6: 1.66  loss_mask_6: 0.6045  loss_dice_6: 3.178  loss_ce_7: 1.649  loss_mask_7: 0.6034  loss_dice_7: 3.178  loss_ce_8: 1.636  loss_mask_8: 0.6047  loss_dice_8: 3.179  time: 1.6943  data_time: 0.3385  lr: 4.3051e-06  max_mem: 17674M
[01/19 13:16:26] d2.utils.events INFO:  eta: 7:21:55  iter: 24339  total_loss: 57.32  loss_ce: 1.723  loss_mask: 0.6191  loss_dice: 3.185  loss_ce_0: 2.934  loss_mask_0: 0.6419  loss_dice_0: 3.469  loss_ce_1: 2.023  loss_mask_1: 0.6289  loss_dice_1: 3.305  loss_ce_2: 1.869  loss_mask_2: 0.6212  loss_dice_2: 3.246  loss_ce_3: 1.824  loss_mask_3: 0.6184  loss_dice_3: 3.208  loss_ce_4: 1.757  loss_mask_4: 0.6199  loss_dice_4: 3.212  loss_ce_5: 1.729  loss_mask_5: 0.6172  loss_dice_5: 3.202  loss_ce_6: 1.734  loss_mask_6: 0.6171  loss_dice_6: 3.197  loss_ce_7: 1.706  loss_mask_7: 0.619  loss_dice_7: 3.193  loss_ce_8: 1.71  loss_mask_8: 0.6201  loss_dice_8: 3.193  time: 1.6943  data_time: 0.3268  lr: 4.3001e-06  max_mem: 17674M
[01/19 13:17:00] d2.utils.events INFO:  eta: 7:21:11  iter: 24359  total_loss: 56.86  loss_ce: 1.684  loss_mask: 0.6305  loss_dice: 3.151  loss_ce_0: 2.946  loss_mask_0: 0.6536  loss_dice_0: 3.444  loss_ce_1: 2.019  loss_mask_1: 0.6344  loss_dice_1: 3.279  loss_ce_2: 1.866  loss_mask_2: 0.6307  loss_dice_2: 3.216  loss_ce_3: 1.788  loss_mask_3: 0.6298  loss_dice_3: 3.177  loss_ce_4: 1.754  loss_mask_4: 0.6295  loss_dice_4: 3.17  loss_ce_5: 1.726  loss_mask_5: 0.626  loss_dice_5: 3.168  loss_ce_6: 1.717  loss_mask_6: 0.6278  loss_dice_6: 3.159  loss_ce_7: 1.697  loss_mask_7: 0.6293  loss_dice_7: 3.152  loss_ce_8: 1.679  loss_mask_8: 0.6311  loss_dice_8: 3.157  time: 1.6943  data_time: 0.3260  lr: 4.2952e-06  max_mem: 17674M
[01/19 13:17:34] d2.utils.events INFO:  eta: 7:20:42  iter: 24379  total_loss: 57.04  loss_ce: 1.635  loss_mask: 0.6132  loss_dice: 3.215  loss_ce_0: 3.006  loss_mask_0: 0.6258  loss_dice_0: 3.499  loss_ce_1: 1.895  loss_mask_1: 0.6177  loss_dice_1: 3.355  loss_ce_2: 1.798  loss_mask_2: 0.6142  loss_dice_2: 3.283  loss_ce_3: 1.732  loss_mask_3: 0.6119  loss_dice_3: 3.244  loss_ce_4: 1.686  loss_mask_4: 0.6097  loss_dice_4: 3.236  loss_ce_5: 1.665  loss_mask_5: 0.6107  loss_dice_5: 3.236  loss_ce_6: 1.67  loss_mask_6: 0.6132  loss_dice_6: 3.213  loss_ce_7: 1.642  loss_mask_7: 0.6133  loss_dice_7: 3.222  loss_ce_8: 1.635  loss_mask_8: 0.612  loss_dice_8: 3.222  time: 1.6943  data_time: 0.3504  lr: 4.2903e-06  max_mem: 17674M
[01/19 13:18:08] d2.utils.events INFO:  eta: 7:20:16  iter: 24399  total_loss: 57.1  loss_ce: 1.671  loss_mask: 0.6172  loss_dice: 3.182  loss_ce_0: 2.96  loss_mask_0: 0.641  loss_dice_0: 3.481  loss_ce_1: 1.954  loss_mask_1: 0.6276  loss_dice_1: 3.322  loss_ce_2: 1.823  loss_mask_2: 0.6219  loss_dice_2: 3.255  loss_ce_3: 1.766  loss_mask_3: 0.6219  loss_dice_3: 3.21  loss_ce_4: 1.729  loss_mask_4: 0.62  loss_dice_4: 3.213  loss_ce_5: 1.691  loss_mask_5: 0.6182  loss_dice_5: 3.202  loss_ce_6: 1.688  loss_mask_6: 0.6156  loss_dice_6: 3.18  loss_ce_7: 1.672  loss_mask_7: 0.6161  loss_dice_7: 3.182  loss_ce_8: 1.671  loss_mask_8: 0.6183  loss_dice_8: 3.186  time: 1.6943  data_time: 0.3516  lr: 4.2853e-06  max_mem: 17674M
[01/19 13:18:41] d2.utils.events INFO:  eta: 7:19:32  iter: 24419  total_loss: 57.26  loss_ce: 1.698  loss_mask: 0.6384  loss_dice: 3.162  loss_ce_0: 3.05  loss_mask_0: 0.6551  loss_dice_0: 3.468  loss_ce_1: 1.971  loss_mask_1: 0.6398  loss_dice_1: 3.298  loss_ce_2: 1.833  loss_mask_2: 0.6349  loss_dice_2: 3.238  loss_ce_3: 1.778  loss_mask_3: 0.6335  loss_dice_3: 3.192  loss_ce_4: 1.735  loss_mask_4: 0.634  loss_dice_4: 3.19  loss_ce_5: 1.689  loss_mask_5: 0.6375  loss_dice_5: 3.182  loss_ce_6: 1.702  loss_mask_6: 0.6389  loss_dice_6: 3.169  loss_ce_7: 1.685  loss_mask_7: 0.6412  loss_dice_7: 3.173  loss_ce_8: 1.683  loss_mask_8: 0.6394  loss_dice_8: 3.166  time: 1.6943  data_time: 0.3325  lr: 4.2804e-06  max_mem: 17674M
[01/19 13:19:15] d2.utils.events INFO:  eta: 7:19:03  iter: 24439  total_loss: 57.65  loss_ce: 1.74  loss_mask: 0.6317  loss_dice: 3.194  loss_ce_0: 2.951  loss_mask_0: 0.6509  loss_dice_0: 3.481  loss_ce_1: 1.979  loss_mask_1: 0.637  loss_dice_1: 3.318  loss_ce_2: 1.853  loss_mask_2: 0.6302  loss_dice_2: 3.273  loss_ce_3: 1.811  loss_mask_3: 0.6248  loss_dice_3: 3.223  loss_ce_4: 1.744  loss_mask_4: 0.6263  loss_dice_4: 3.217  loss_ce_5: 1.744  loss_mask_5: 0.6299  loss_dice_5: 3.205  loss_ce_6: 1.75  loss_mask_6: 0.6264  loss_dice_6: 3.198  loss_ce_7: 1.723  loss_mask_7: 0.6288  loss_dice_7: 3.197  loss_ce_8: 1.714  loss_mask_8: 0.6308  loss_dice_8: 3.193  time: 1.6943  data_time: 0.3465  lr: 4.2754e-06  max_mem: 17674M
[01/19 13:19:49] d2.utils.events INFO:  eta: 7:18:31  iter: 24459  total_loss: 58.19  loss_ce: 1.733  loss_mask: 0.6267  loss_dice: 3.203  loss_ce_0: 2.97  loss_mask_0: 0.6463  loss_dice_0: 3.504  loss_ce_1: 1.984  loss_mask_1: 0.6319  loss_dice_1: 3.338  loss_ce_2: 1.879  loss_mask_2: 0.6296  loss_dice_2: 3.262  loss_ce_3: 1.832  loss_mask_3: 0.6273  loss_dice_3: 3.219  loss_ce_4: 1.781  loss_mask_4: 0.6281  loss_dice_4: 3.213  loss_ce_5: 1.738  loss_mask_5: 0.6259  loss_dice_5: 3.21  loss_ce_6: 1.738  loss_mask_6: 0.6276  loss_dice_6: 3.205  loss_ce_7: 1.725  loss_mask_7: 0.627  loss_dice_7: 3.203  loss_ce_8: 1.745  loss_mask_8: 0.6271  loss_dice_8: 3.206  time: 1.6943  data_time: 0.3503  lr: 4.2705e-06  max_mem: 17674M
[01/19 13:20:23] d2.utils.events INFO:  eta: 7:17:55  iter: 24479  total_loss: 57.15  loss_ce: 1.619  loss_mask: 0.6137  loss_dice: 3.21  loss_ce_0: 2.905  loss_mask_0: 0.6326  loss_dice_0: 3.503  loss_ce_1: 1.874  loss_mask_1: 0.6332  loss_dice_1: 3.341  loss_ce_2: 1.733  loss_mask_2: 0.6256  loss_dice_2: 3.28  loss_ce_3: 1.705  loss_mask_3: 0.6152  loss_dice_3: 3.232  loss_ce_4: 1.652  loss_mask_4: 0.6146  loss_dice_4: 3.231  loss_ce_5: 1.632  loss_mask_5: 0.6151  loss_dice_5: 3.237  loss_ce_6: 1.629  loss_mask_6: 0.6155  loss_dice_6: 3.218  loss_ce_7: 1.613  loss_mask_7: 0.6163  loss_dice_7: 3.211  loss_ce_8: 1.612  loss_mask_8: 0.6167  loss_dice_8: 3.214  time: 1.6943  data_time: 0.3335  lr: 4.2655e-06  max_mem: 17674M
[01/19 13:20:57] d2.utils.events INFO:  eta: 7:17:10  iter: 24499  total_loss: 56.5  loss_ce: 1.627  loss_mask: 0.6292  loss_dice: 3.184  loss_ce_0: 2.964  loss_mask_0: 0.6512  loss_dice_0: 3.485  loss_ce_1: 1.928  loss_mask_1: 0.6308  loss_dice_1: 3.319  loss_ce_2: 1.794  loss_mask_2: 0.6288  loss_dice_2: 3.26  loss_ce_3: 1.729  loss_mask_3: 0.6261  loss_dice_3: 3.201  loss_ce_4: 1.685  loss_mask_4: 0.6306  loss_dice_4: 3.198  loss_ce_5: 1.644  loss_mask_5: 0.6324  loss_dice_5: 3.2  loss_ce_6: 1.654  loss_mask_6: 0.6277  loss_dice_6: 3.179  loss_ce_7: 1.63  loss_mask_7: 0.627  loss_dice_7: 3.188  loss_ce_8: 1.628  loss_mask_8: 0.6313  loss_dice_8: 3.182  time: 1.6943  data_time: 0.3306  lr: 4.2606e-06  max_mem: 17674M
[01/19 13:21:30] d2.utils.events INFO:  eta: 7:16:37  iter: 24519  total_loss: 57.06  loss_ce: 1.682  loss_mask: 0.6105  loss_dice: 3.167  loss_ce_0: 2.95  loss_mask_0: 0.6435  loss_dice_0: 3.475  loss_ce_1: 1.984  loss_mask_1: 0.6175  loss_dice_1: 3.298  loss_ce_2: 1.864  loss_mask_2: 0.6205  loss_dice_2: 3.236  loss_ce_3: 1.797  loss_mask_3: 0.6141  loss_dice_3: 3.188  loss_ce_4: 1.754  loss_mask_4: 0.6113  loss_dice_4: 3.191  loss_ce_5: 1.725  loss_mask_5: 0.6134  loss_dice_5: 3.184  loss_ce_6: 1.708  loss_mask_6: 0.6124  loss_dice_6: 3.169  loss_ce_7: 1.688  loss_mask_7: 0.6112  loss_dice_7: 3.168  loss_ce_8: 1.653  loss_mask_8: 0.6107  loss_dice_8: 3.177  time: 1.6943  data_time: 0.3410  lr: 4.2556e-06  max_mem: 17674M
[01/19 13:22:05] d2.utils.events INFO:  eta: 7:16:16  iter: 24539  total_loss: 58.16  loss_ce: 1.712  loss_mask: 0.6025  loss_dice: 3.186  loss_ce_0: 2.99  loss_mask_0: 0.6298  loss_dice_0: 3.487  loss_ce_1: 1.993  loss_mask_1: 0.6073  loss_dice_1: 3.326  loss_ce_2: 1.862  loss_mask_2: 0.6046  loss_dice_2: 3.267  loss_ce_3: 1.795  loss_mask_3: 0.6017  loss_dice_3: 3.216  loss_ce_4: 1.747  loss_mask_4: 0.6039  loss_dice_4: 3.207  loss_ce_5: 1.721  loss_mask_5: 0.6044  loss_dice_5: 3.208  loss_ce_6: 1.716  loss_mask_6: 0.6019  loss_dice_6: 3.195  loss_ce_7: 1.712  loss_mask_7: 0.6019  loss_dice_7: 3.191  loss_ce_8: 1.725  loss_mask_8: 0.6013  loss_dice_8: 3.188  time: 1.6943  data_time: 0.3556  lr: 4.2507e-06  max_mem: 17674M
[01/19 13:22:39] d2.utils.events INFO:  eta: 7:15:42  iter: 24559  total_loss: 57.69  loss_ce: 1.693  loss_mask: 0.6099  loss_dice: 3.151  loss_ce_0: 2.926  loss_mask_0: 0.6263  loss_dice_0: 3.476  loss_ce_1: 1.906  loss_mask_1: 0.6094  loss_dice_1: 3.301  loss_ce_2: 1.796  loss_mask_2: 0.6117  loss_dice_2: 3.226  loss_ce_3: 1.745  loss_mask_3: 0.6081  loss_dice_3: 3.172  loss_ce_4: 1.723  loss_mask_4: 0.6105  loss_dice_4: 3.169  loss_ce_5: 1.708  loss_mask_5: 0.6094  loss_dice_5: 3.166  loss_ce_6: 1.691  loss_mask_6: 0.6082  loss_dice_6: 3.16  loss_ce_7: 1.671  loss_mask_7: 0.6094  loss_dice_7: 3.165  loss_ce_8: 1.684  loss_mask_8: 0.6093  loss_dice_8: 3.157  time: 1.6943  data_time: 0.3576  lr: 4.2457e-06  max_mem: 17674M
[01/19 13:23:12] d2.utils.events INFO:  eta: 7:15:04  iter: 24579  total_loss: 57.64  loss_ce: 1.762  loss_mask: 0.6227  loss_dice: 3.139  loss_ce_0: 3.024  loss_mask_0: 0.6453  loss_dice_0: 3.452  loss_ce_1: 2.049  loss_mask_1: 0.6314  loss_dice_1: 3.276  loss_ce_2: 1.937  loss_mask_2: 0.6268  loss_dice_2: 3.215  loss_ce_3: 1.875  loss_mask_3: 0.6203  loss_dice_3: 3.164  loss_ce_4: 1.808  loss_mask_4: 0.6227  loss_dice_4: 3.164  loss_ce_5: 1.801  loss_mask_5: 0.6214  loss_dice_5: 3.158  loss_ce_6: 1.777  loss_mask_6: 0.6219  loss_dice_6: 3.148  loss_ce_7: 1.774  loss_mask_7: 0.6218  loss_dice_7: 3.144  loss_ce_8: 1.761  loss_mask_8: 0.6227  loss_dice_8: 3.148  time: 1.6943  data_time: 0.3431  lr: 4.2408e-06  max_mem: 17674M
[01/19 13:23:46] d2.utils.events INFO:  eta: 7:14:37  iter: 24599  total_loss: 57.71  loss_ce: 1.736  loss_mask: 0.6277  loss_dice: 3.177  loss_ce_0: 2.977  loss_mask_0: 0.6509  loss_dice_0: 3.481  loss_ce_1: 2  loss_mask_1: 0.6299  loss_dice_1: 3.327  loss_ce_2: 1.861  loss_mask_2: 0.6323  loss_dice_2: 3.248  loss_ce_3: 1.831  loss_mask_3: 0.6278  loss_dice_3: 3.199  loss_ce_4: 1.772  loss_mask_4: 0.6294  loss_dice_4: 3.196  loss_ce_5: 1.745  loss_mask_5: 0.6297  loss_dice_5: 3.197  loss_ce_6: 1.751  loss_mask_6: 0.6272  loss_dice_6: 3.188  loss_ce_7: 1.737  loss_mask_7: 0.6284  loss_dice_7: 3.182  loss_ce_8: 1.725  loss_mask_8: 0.6274  loss_dice_8: 3.177  time: 1.6943  data_time: 0.3514  lr: 4.2358e-06  max_mem: 17674M
[01/19 13:24:19] d2.utils.events INFO:  eta: 7:13:56  iter: 24619  total_loss: 57.36  loss_ce: 1.721  loss_mask: 0.6164  loss_dice: 3.168  loss_ce_0: 2.925  loss_mask_0: 0.6461  loss_dice_0: 3.473  loss_ce_1: 1.982  loss_mask_1: 0.6264  loss_dice_1: 3.31  loss_ce_2: 1.855  loss_mask_2: 0.624  loss_dice_2: 3.234  loss_ce_3: 1.795  loss_mask_3: 0.6155  loss_dice_3: 3.194  loss_ce_4: 1.758  loss_mask_4: 0.6177  loss_dice_4: 3.192  loss_ce_5: 1.733  loss_mask_5: 0.616  loss_dice_5: 3.19  loss_ce_6: 1.732  loss_mask_6: 0.6145  loss_dice_6: 3.173  loss_ce_7: 1.713  loss_mask_7: 0.6158  loss_dice_7: 3.172  loss_ce_8: 1.715  loss_mask_8: 0.6161  loss_dice_8: 3.17  time: 1.6943  data_time: 0.3347  lr: 4.2309e-06  max_mem: 17674M
[01/19 13:24:53] d2.utils.events INFO:  eta: 7:13:20  iter: 24639  total_loss: 57.48  loss_ce: 1.72  loss_mask: 0.6218  loss_dice: 3.158  loss_ce_0: 2.973  loss_mask_0: 0.6537  loss_dice_0: 3.468  loss_ce_1: 1.955  loss_mask_1: 0.6342  loss_dice_1: 3.301  loss_ce_2: 1.866  loss_mask_2: 0.6273  loss_dice_2: 3.23  loss_ce_3: 1.828  loss_mask_3: 0.6259  loss_dice_3: 3.184  loss_ce_4: 1.786  loss_mask_4: 0.6267  loss_dice_4: 3.177  loss_ce_5: 1.734  loss_mask_5: 0.6292  loss_dice_5: 3.172  loss_ce_6: 1.745  loss_mask_6: 0.6255  loss_dice_6: 3.163  loss_ce_7: 1.707  loss_mask_7: 0.6251  loss_dice_7: 3.163  loss_ce_8: 1.709  loss_mask_8: 0.6223  loss_dice_8: 3.163  time: 1.6943  data_time: 0.3459  lr: 4.2259e-06  max_mem: 17674M
[01/19 13:25:27] d2.utils.events INFO:  eta: 7:12:45  iter: 24659  total_loss: 57.37  loss_ce: 1.688  loss_mask: 0.6295  loss_dice: 3.144  loss_ce_0: 2.917  loss_mask_0: 0.6366  loss_dice_0: 3.456  loss_ce_1: 1.979  loss_mask_1: 0.6219  loss_dice_1: 3.288  loss_ce_2: 1.864  loss_mask_2: 0.6181  loss_dice_2: 3.22  loss_ce_3: 1.812  loss_mask_3: 0.6205  loss_dice_3: 3.166  loss_ce_4: 1.754  loss_mask_4: 0.6232  loss_dice_4: 3.167  loss_ce_5: 1.717  loss_mask_5: 0.6213  loss_dice_5: 3.167  loss_ce_6: 1.704  loss_mask_6: 0.6233  loss_dice_6: 3.146  loss_ce_7: 1.704  loss_mask_7: 0.6231  loss_dice_7: 3.144  loss_ce_8: 1.693  loss_mask_8: 0.6256  loss_dice_8: 3.149  time: 1.6943  data_time: 0.3404  lr: 4.221e-06  max_mem: 17674M
[01/19 13:26:01] d2.utils.events INFO:  eta: 7:11:54  iter: 24679  total_loss: 57.44  loss_ce: 1.748  loss_mask: 0.6183  loss_dice: 3.138  loss_ce_0: 2.946  loss_mask_0: 0.6407  loss_dice_0: 3.44  loss_ce_1: 2.043  loss_mask_1: 0.6199  loss_dice_1: 3.273  loss_ce_2: 1.909  loss_mask_2: 0.6176  loss_dice_2: 3.206  loss_ce_3: 1.837  loss_mask_3: 0.6133  loss_dice_3: 3.161  loss_ce_4: 1.797  loss_mask_4: 0.6145  loss_dice_4: 3.157  loss_ce_5: 1.76  loss_mask_5: 0.6189  loss_dice_5: 3.154  loss_ce_6: 1.741  loss_mask_6: 0.6188  loss_dice_6: 3.142  loss_ce_7: 1.752  loss_mask_7: 0.6203  loss_dice_7: 3.138  loss_ce_8: 1.718  loss_mask_8: 0.6192  loss_dice_8: 3.137  time: 1.6942  data_time: 0.3297  lr: 4.216e-06  max_mem: 17674M
[01/19 13:26:35] d2.utils.events INFO:  eta: 7:11:14  iter: 24699  total_loss: 57.41  loss_ce: 1.704  loss_mask: 0.6275  loss_dice: 3.139  loss_ce_0: 2.98  loss_mask_0: 0.6413  loss_dice_0: 3.458  loss_ce_1: 1.977  loss_mask_1: 0.6245  loss_dice_1: 3.277  loss_ce_2: 1.867  loss_mask_2: 0.6249  loss_dice_2: 3.208  loss_ce_3: 1.802  loss_mask_3: 0.6234  loss_dice_3: 3.17  loss_ce_4: 1.75  loss_mask_4: 0.6244  loss_dice_4: 3.162  loss_ce_5: 1.727  loss_mask_5: 0.6261  loss_dice_5: 3.163  loss_ce_6: 1.73  loss_mask_6: 0.6248  loss_dice_6: 3.147  loss_ce_7: 1.696  loss_mask_7: 0.6251  loss_dice_7: 3.145  loss_ce_8: 1.713  loss_mask_8: 0.6262  loss_dice_8: 3.142  time: 1.6943  data_time: 0.3501  lr: 4.2111e-06  max_mem: 17674M
[01/19 13:27:08] d2.utils.events INFO:  eta: 7:10:27  iter: 24719  total_loss: 56.81  loss_ce: 1.716  loss_mask: 0.6212  loss_dice: 3.093  loss_ce_0: 2.921  loss_mask_0: 0.6539  loss_dice_0: 3.422  loss_ce_1: 1.98  loss_mask_1: 0.6289  loss_dice_1: 3.227  loss_ce_2: 1.862  loss_mask_2: 0.6272  loss_dice_2: 3.156  loss_ce_3: 1.812  loss_mask_3: 0.6212  loss_dice_3: 3.117  loss_ce_4: 1.757  loss_mask_4: 0.6206  loss_dice_4: 3.11  loss_ce_5: 1.744  loss_mask_5: 0.6219  loss_dice_5: 3.106  loss_ce_6: 1.729  loss_mask_6: 0.6209  loss_dice_6: 3.091  loss_ce_7: 1.714  loss_mask_7: 0.6211  loss_dice_7: 3.09  loss_ce_8: 1.706  loss_mask_8: 0.6225  loss_dice_8: 3.093  time: 1.6942  data_time: 0.3317  lr: 4.2061e-06  max_mem: 17674M
[01/19 13:27:42] d2.utils.events INFO:  eta: 7:09:48  iter: 24739  total_loss: 56.64  loss_ce: 1.644  loss_mask: 0.6128  loss_dice: 3.128  loss_ce_0: 2.843  loss_mask_0: 0.6256  loss_dice_0: 3.45  loss_ce_1: 1.916  loss_mask_1: 0.6065  loss_dice_1: 3.258  loss_ce_2: 1.811  loss_mask_2: 0.6073  loss_dice_2: 3.197  loss_ce_3: 1.724  loss_mask_3: 0.6078  loss_dice_3: 3.15  loss_ce_4: 1.69  loss_mask_4: 0.6104  loss_dice_4: 3.143  loss_ce_5: 1.656  loss_mask_5: 0.6092  loss_dice_5: 3.141  loss_ce_6: 1.65  loss_mask_6: 0.6108  loss_dice_6: 3.136  loss_ce_7: 1.645  loss_mask_7: 0.6117  loss_dice_7: 3.125  loss_ce_8: 1.638  loss_mask_8: 0.6122  loss_dice_8: 3.124  time: 1.6942  data_time: 0.3218  lr: 4.2012e-06  max_mem: 17674M
[01/19 13:28:15] d2.utils.events INFO:  eta: 7:09:00  iter: 24759  total_loss: 57.73  loss_ce: 1.73  loss_mask: 0.6165  loss_dice: 3.176  loss_ce_0: 2.984  loss_mask_0: 0.6438  loss_dice_0: 3.488  loss_ce_1: 2.009  loss_mask_1: 0.6216  loss_dice_1: 3.331  loss_ce_2: 1.899  loss_mask_2: 0.6222  loss_dice_2: 3.258  loss_ce_3: 1.838  loss_mask_3: 0.617  loss_dice_3: 3.204  loss_ce_4: 1.769  loss_mask_4: 0.6187  loss_dice_4: 3.199  loss_ce_5: 1.738  loss_mask_5: 0.6171  loss_dice_5: 3.199  loss_ce_6: 1.737  loss_mask_6: 0.619  loss_dice_6: 3.176  loss_ce_7: 1.726  loss_mask_7: 0.6186  loss_dice_7: 3.182  loss_ce_8: 1.712  loss_mask_8: 0.617  loss_dice_8: 3.176  time: 1.6942  data_time: 0.3464  lr: 4.1962e-06  max_mem: 17674M
[01/19 13:28:50] d2.utils.events INFO:  eta: 7:08:24  iter: 24779  total_loss: 56.73  loss_ce: 1.638  loss_mask: 0.6154  loss_dice: 3.157  loss_ce_0: 2.935  loss_mask_0: 0.6381  loss_dice_0: 3.445  loss_ce_1: 1.932  loss_mask_1: 0.6197  loss_dice_1: 3.285  loss_ce_2: 1.808  loss_mask_2: 0.6181  loss_dice_2: 3.22  loss_ce_3: 1.769  loss_mask_3: 0.6131  loss_dice_3: 3.174  loss_ce_4: 1.692  loss_mask_4: 0.6172  loss_dice_4: 3.177  loss_ce_5: 1.669  loss_mask_5: 0.618  loss_dice_5: 3.178  loss_ce_6: 1.664  loss_mask_6: 0.6198  loss_dice_6: 3.157  loss_ce_7: 1.648  loss_mask_7: 0.6179  loss_dice_7: 3.156  loss_ce_8: 1.648  loss_mask_8: 0.6164  loss_dice_8: 3.153  time: 1.6942  data_time: 0.3352  lr: 4.1913e-06  max_mem: 17674M
[01/19 13:29:24] d2.utils.events INFO:  eta: 7:07:52  iter: 24799  total_loss: 57.23  loss_ce: 1.684  loss_mask: 0.6223  loss_dice: 3.17  loss_ce_0: 2.995  loss_mask_0: 0.6406  loss_dice_0: 3.46  loss_ce_1: 1.996  loss_mask_1: 0.6272  loss_dice_1: 3.307  loss_ce_2: 1.852  loss_mask_2: 0.6273  loss_dice_2: 3.229  loss_ce_3: 1.791  loss_mask_3: 0.623  loss_dice_3: 3.197  loss_ce_4: 1.745  loss_mask_4: 0.6249  loss_dice_4: 3.195  loss_ce_5: 1.726  loss_mask_5: 0.6281  loss_dice_5: 3.186  loss_ce_6: 1.708  loss_mask_6: 0.6202  loss_dice_6: 3.172  loss_ce_7: 1.692  loss_mask_7: 0.6232  loss_dice_7: 3.179  loss_ce_8: 1.673  loss_mask_8: 0.6222  loss_dice_8: 3.175  time: 1.6942  data_time: 0.3501  lr: 4.1863e-06  max_mem: 17674M
[01/19 13:29:58] d2.utils.events INFO:  eta: 7:07:19  iter: 24819  total_loss: 57.32  loss_ce: 1.64  loss_mask: 0.6176  loss_dice: 3.188  loss_ce_0: 2.916  loss_mask_0: 0.6465  loss_dice_0: 3.5  loss_ce_1: 1.935  loss_mask_1: 0.6226  loss_dice_1: 3.336  loss_ce_2: 1.805  loss_mask_2: 0.6259  loss_dice_2: 3.253  loss_ce_3: 1.75  loss_mask_3: 0.62  loss_dice_3: 3.212  loss_ce_4: 1.69  loss_mask_4: 0.6196  loss_dice_4: 3.205  loss_ce_5: 1.67  loss_mask_5: 0.621  loss_dice_5: 3.205  loss_ce_6: 1.674  loss_mask_6: 0.6208  loss_dice_6: 3.182  loss_ce_7: 1.644  loss_mask_7: 0.6211  loss_dice_7: 3.189  loss_ce_8: 1.642  loss_mask_8: 0.6191  loss_dice_8: 3.186  time: 1.6942  data_time: 0.3615  lr: 4.1813e-06  max_mem: 17674M
[01/19 13:30:32] d2.utils.events INFO:  eta: 7:06:44  iter: 24839  total_loss: 56.1  loss_ce: 1.56  loss_mask: 0.6066  loss_dice: 3.18  loss_ce_0: 2.831  loss_mask_0: 0.6337  loss_dice_0: 3.482  loss_ce_1: 1.836  loss_mask_1: 0.6118  loss_dice_1: 3.32  loss_ce_2: 1.704  loss_mask_2: 0.6054  loss_dice_2: 3.259  loss_ce_3: 1.661  loss_mask_3: 0.6054  loss_dice_3: 3.214  loss_ce_4: 1.593  loss_mask_4: 0.6027  loss_dice_4: 3.208  loss_ce_5: 1.573  loss_mask_5: 0.6065  loss_dice_5: 3.205  loss_ce_6: 1.572  loss_mask_6: 0.6065  loss_dice_6: 3.202  loss_ce_7: 1.563  loss_mask_7: 0.6075  loss_dice_7: 3.192  loss_ce_8: 1.562  loss_mask_8: 0.6071  loss_dice_8: 3.195  time: 1.6942  data_time: 0.3404  lr: 4.1764e-06  max_mem: 17674M
[01/19 13:31:06] d2.utils.events INFO:  eta: 7:06:15  iter: 24859  total_loss: 56.44  loss_ce: 1.612  loss_mask: 0.6132  loss_dice: 3.142  loss_ce_0: 2.845  loss_mask_0: 0.6323  loss_dice_0: 3.449  loss_ce_1: 1.906  loss_mask_1: 0.6156  loss_dice_1: 3.274  loss_ce_2: 1.793  loss_mask_2: 0.6176  loss_dice_2: 3.208  loss_ce_3: 1.731  loss_mask_3: 0.6147  loss_dice_3: 3.16  loss_ce_4: 1.669  loss_mask_4: 0.6123  loss_dice_4: 3.159  loss_ce_5: 1.646  loss_mask_5: 0.6134  loss_dice_5: 3.157  loss_ce_6: 1.628  loss_mask_6: 0.6142  loss_dice_6: 3.146  loss_ce_7: 1.635  loss_mask_7: 0.6139  loss_dice_7: 3.14  loss_ce_8: 1.616  loss_mask_8: 0.6148  loss_dice_8: 3.142  time: 1.6942  data_time: 0.3631  lr: 4.1714e-06  max_mem: 17674M
[01/19 13:31:40] d2.utils.events INFO:  eta: 7:05:45  iter: 24879  total_loss: 56.62  loss_ce: 1.677  loss_mask: 0.6041  loss_dice: 3.181  loss_ce_0: 2.937  loss_mask_0: 0.6297  loss_dice_0: 3.472  loss_ce_1: 1.994  loss_mask_1: 0.6156  loss_dice_1: 3.305  loss_ce_2: 1.851  loss_mask_2: 0.6068  loss_dice_2: 3.253  loss_ce_3: 1.774  loss_mask_3: 0.6017  loss_dice_3: 3.211  loss_ce_4: 1.732  loss_mask_4: 0.6007  loss_dice_4: 3.201  loss_ce_5: 1.695  loss_mask_5: 0.6012  loss_dice_5: 3.2  loss_ce_6: 1.681  loss_mask_6: 0.6034  loss_dice_6: 3.184  loss_ce_7: 1.676  loss_mask_7: 0.6047  loss_dice_7: 3.185  loss_ce_8: 1.659  loss_mask_8: 0.6032  loss_dice_8: 3.179  time: 1.6943  data_time: 0.3497  lr: 4.1665e-06  max_mem: 17674M
[01/19 13:32:14] d2.utils.events INFO:  eta: 7:05:16  iter: 24899  total_loss: 57.32  loss_ce: 1.701  loss_mask: 0.6158  loss_dice: 3.17  loss_ce_0: 2.894  loss_mask_0: 0.6321  loss_dice_0: 3.499  loss_ce_1: 1.948  loss_mask_1: 0.6168  loss_dice_1: 3.311  loss_ce_2: 1.842  loss_mask_2: 0.6121  loss_dice_2: 3.25  loss_ce_3: 1.79  loss_mask_3: 0.6107  loss_dice_3: 3.199  loss_ce_4: 1.743  loss_mask_4: 0.6146  loss_dice_4: 3.19  loss_ce_5: 1.716  loss_mask_5: 0.6114  loss_dice_5: 3.183  loss_ce_6: 1.714  loss_mask_6: 0.6118  loss_dice_6: 3.173  loss_ce_7: 1.699  loss_mask_7: 0.6119  loss_dice_7: 3.171  loss_ce_8: 1.686  loss_mask_8: 0.6126  loss_dice_8: 3.171  time: 1.6943  data_time: 0.3394  lr: 4.1615e-06  max_mem: 17674M
[01/19 13:32:48] d2.utils.events INFO:  eta: 7:04:43  iter: 24919  total_loss: 56.75  loss_ce: 1.7  loss_mask: 0.6169  loss_dice: 3.131  loss_ce_0: 2.934  loss_mask_0: 0.6249  loss_dice_0: 3.448  loss_ce_1: 1.946  loss_mask_1: 0.6186  loss_dice_1: 3.277  loss_ce_2: 1.835  loss_mask_2: 0.6148  loss_dice_2: 3.204  loss_ce_3: 1.772  loss_mask_3: 0.6144  loss_dice_3: 3.161  loss_ce_4: 1.724  loss_mask_4: 0.6179  loss_dice_4: 3.153  loss_ce_5: 1.686  loss_mask_5: 0.6182  loss_dice_5: 3.156  loss_ce_6: 1.711  loss_mask_6: 0.6156  loss_dice_6: 3.145  loss_ce_7: 1.701  loss_mask_7: 0.6153  loss_dice_7: 3.144  loss_ce_8: 1.698  loss_mask_8: 0.6174  loss_dice_8: 3.141  time: 1.6943  data_time: 0.3277  lr: 4.1566e-06  max_mem: 17674M
[01/19 13:33:22] d2.utils.events INFO:  eta: 7:04:11  iter: 24939  total_loss: 57.2  loss_ce: 1.677  loss_mask: 0.6222  loss_dice: 3.146  loss_ce_0: 2.935  loss_mask_0: 0.6392  loss_dice_0: 3.465  loss_ce_1: 1.975  loss_mask_1: 0.6158  loss_dice_1: 3.277  loss_ce_2: 1.86  loss_mask_2: 0.6166  loss_dice_2: 3.219  loss_ce_3: 1.793  loss_mask_3: 0.6177  loss_dice_3: 3.174  loss_ce_4: 1.752  loss_mask_4: 0.6162  loss_dice_4: 3.166  loss_ce_5: 1.735  loss_mask_5: 0.6176  loss_dice_5: 3.172  loss_ce_6: 1.704  loss_mask_6: 0.6195  loss_dice_6: 3.156  loss_ce_7: 1.712  loss_mask_7: 0.619  loss_dice_7: 3.158  loss_ce_8: 1.679  loss_mask_8: 0.6185  loss_dice_8: 3.149  time: 1.6943  data_time: 0.3558  lr: 4.1516e-06  max_mem: 17674M
[01/19 13:33:56] d2.utils.events INFO:  eta: 7:03:34  iter: 24959  total_loss: 57.72  loss_ce: 1.709  loss_mask: 0.6229  loss_dice: 3.14  loss_ce_0: 2.936  loss_mask_0: 0.6421  loss_dice_0: 3.455  loss_ce_1: 1.993  loss_mask_1: 0.6205  loss_dice_1: 3.28  loss_ce_2: 1.884  loss_mask_2: 0.6174  loss_dice_2: 3.211  loss_ce_3: 1.824  loss_mask_3: 0.6164  loss_dice_3: 3.156  loss_ce_4: 1.758  loss_mask_4: 0.6201  loss_dice_4: 3.17  loss_ce_5: 1.727  loss_mask_5: 0.6231  loss_dice_5: 3.164  loss_ce_6: 1.724  loss_mask_6: 0.6244  loss_dice_6: 3.146  loss_ce_7: 1.697  loss_mask_7: 0.6232  loss_dice_7: 3.145  loss_ce_8: 1.707  loss_mask_8: 0.6241  loss_dice_8: 3.14  time: 1.6943  data_time: 0.3575  lr: 4.1466e-06  max_mem: 17674M
[01/19 13:34:30] d2.utils.events INFO:  eta: 7:03:02  iter: 24979  total_loss: 56.89  loss_ce: 1.659  loss_mask: 0.615  loss_dice: 3.157  loss_ce_0: 2.919  loss_mask_0: 0.6224  loss_dice_0: 3.467  loss_ce_1: 1.924  loss_mask_1: 0.6186  loss_dice_1: 3.276  loss_ce_2: 1.818  loss_mask_2: 0.6143  loss_dice_2: 3.22  loss_ce_3: 1.77  loss_mask_3: 0.6113  loss_dice_3: 3.177  loss_ce_4: 1.699  loss_mask_4: 0.613  loss_dice_4: 3.174  loss_ce_5: 1.682  loss_mask_5: 0.6136  loss_dice_5: 3.168  loss_ce_6: 1.666  loss_mask_6: 0.6112  loss_dice_6: 3.16  loss_ce_7: 1.663  loss_mask_7: 0.6119  loss_dice_7: 3.162  loss_ce_8: 1.66  loss_mask_8: 0.6149  loss_dice_8: 3.16  time: 1.6943  data_time: 0.3361  lr: 4.1417e-06  max_mem: 17674M
[01/19 13:35:04] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/sceneflow_crop192x384/model_0024999.pth
[01/19 13:35:05] d2.utils.events INFO:  eta: 7:02:27  iter: 24999  total_loss: 57.37  loss_ce: 1.675  loss_mask: 0.6164  loss_dice: 3.119  loss_ce_0: 2.896  loss_mask_0: 0.6464  loss_dice_0: 3.454  loss_ce_1: 1.961  loss_mask_1: 0.6221  loss_dice_1: 3.262  loss_ce_2: 1.849  loss_mask_2: 0.6187  loss_dice_2: 3.204  loss_ce_3: 1.82  loss_mask_3: 0.6115  loss_dice_3: 3.156  loss_ce_4: 1.753  loss_mask_4: 0.6152  loss_dice_4: 3.155  loss_ce_5: 1.73  loss_mask_5: 0.616  loss_dice_5: 3.154  loss_ce_6: 1.739  loss_mask_6: 0.6171  loss_dice_6: 3.132  loss_ce_7: 1.726  loss_mask_7: 0.6187  loss_dice_7: 3.134  loss_ce_8: 1.694  loss_mask_8: 0.6175  loss_dice_8: 3.13  time: 1.6943  data_time: 0.3548  lr: 4.1367e-06  max_mem: 17674M
[01/19 13:35:39] d2.utils.events INFO:  eta: 7:01:52  iter: 25019  total_loss: 56.83  loss_ce: 1.647  loss_mask: 0.6102  loss_dice: 3.163  loss_ce_0: 2.926  loss_mask_0: 0.6325  loss_dice_0: 3.486  loss_ce_1: 1.936  loss_mask_1: 0.6134  loss_dice_1: 3.316  loss_ce_2: 1.832  loss_mask_2: 0.6128  loss_dice_2: 3.24  loss_ce_3: 1.768  loss_mask_3: 0.6115  loss_dice_3: 3.198  loss_ce_4: 1.701  loss_mask_4: 0.6117  loss_dice_4: 3.184  loss_ce_5: 1.685  loss_mask_5: 0.613  loss_dice_5: 3.186  loss_ce_6: 1.68  loss_mask_6: 0.6122  loss_dice_6: 3.169  loss_ce_7: 1.682  loss_mask_7: 0.6107  loss_dice_7: 3.173  loss_ce_8: 1.646  loss_mask_8: 0.6097  loss_dice_8: 3.167  time: 1.6943  data_time: 0.3346  lr: 4.1317e-06  max_mem: 17674M
[01/19 13:36:13] d2.utils.events INFO:  eta: 7:01:19  iter: 25039  total_loss: 57.01  loss_ce: 1.66  loss_mask: 0.6109  loss_dice: 3.177  loss_ce_0: 2.893  loss_mask_0: 0.6217  loss_dice_0: 3.485  loss_ce_1: 1.912  loss_mask_1: 0.6084  loss_dice_1: 3.307  loss_ce_2: 1.796  loss_mask_2: 0.6073  loss_dice_2: 3.244  loss_ce_3: 1.729  loss_mask_3: 0.6082  loss_dice_3: 3.206  loss_ce_4: 1.68  loss_mask_4: 0.6094  loss_dice_4: 3.2  loss_ce_5: 1.65  loss_mask_5: 0.6107  loss_dice_5: 3.197  loss_ce_6: 1.662  loss_mask_6: 0.6086  loss_dice_6: 3.182  loss_ce_7: 1.641  loss_mask_7: 0.6099  loss_dice_7: 3.183  loss_ce_8: 1.627  loss_mask_8: 0.6118  loss_dice_8: 3.175  time: 1.6943  data_time: 0.3604  lr: 4.1268e-06  max_mem: 17674M
[01/19 13:36:47] d2.utils.events INFO:  eta: 7:00:51  iter: 25059  total_loss: 56.99  loss_ce: 1.717  loss_mask: 0.616  loss_dice: 3.13  loss_ce_0: 2.918  loss_mask_0: 0.636  loss_dice_0: 3.453  loss_ce_1: 1.963  loss_mask_1: 0.6192  loss_dice_1: 3.261  loss_ce_2: 1.867  loss_mask_2: 0.6139  loss_dice_2: 3.209  loss_ce_3: 1.826  loss_mask_3: 0.615  loss_dice_3: 3.159  loss_ce_4: 1.766  loss_mask_4: 0.6168  loss_dice_4: 3.155  loss_ce_5: 1.736  loss_mask_5: 0.6155  loss_dice_5: 3.149  loss_ce_6: 1.748  loss_mask_6: 0.6173  loss_dice_6: 3.134  loss_ce_7: 1.729  loss_mask_7: 0.6176  loss_dice_7: 3.14  loss_ce_8: 1.696  loss_mask_8: 0.62  loss_dice_8: 3.137  time: 1.6943  data_time: 0.3333  lr: 4.1218e-06  max_mem: 17674M
[01/19 13:37:21] d2.utils.events INFO:  eta: 7:00:18  iter: 25079  total_loss: 57.06  loss_ce: 1.627  loss_mask: 0.6187  loss_dice: 3.19  loss_ce_0: 2.87  loss_mask_0: 0.6368  loss_dice_0: 3.491  loss_ce_1: 1.851  loss_mask_1: 0.6233  loss_dice_1: 3.312  loss_ce_2: 1.746  loss_mask_2: 0.6256  loss_dice_2: 3.251  loss_ce_3: 1.689  loss_mask_3: 0.6197  loss_dice_3: 3.208  loss_ce_4: 1.652  loss_mask_4: 0.6187  loss_dice_4: 3.2  loss_ce_5: 1.651  loss_mask_5: 0.6203  loss_dice_5: 3.207  loss_ce_6: 1.649  loss_mask_6: 0.6181  loss_dice_6: 3.192  loss_ce_7: 1.639  loss_mask_7: 0.6181  loss_dice_7: 3.188  loss_ce_8: 1.63  loss_mask_8: 0.6202  loss_dice_8: 3.194  time: 1.6943  data_time: 0.3440  lr: 4.1168e-06  max_mem: 17674M
[01/19 13:37:55] d2.utils.events INFO:  eta: 6:59:52  iter: 25099  total_loss: 57.38  loss_ce: 1.714  loss_mask: 0.6196  loss_dice: 3.167  loss_ce_0: 2.946  loss_mask_0: 0.6484  loss_dice_0: 3.453  loss_ce_1: 1.996  loss_mask_1: 0.6284  loss_dice_1: 3.29  loss_ce_2: 1.897  loss_mask_2: 0.6224  loss_dice_2: 3.227  loss_ce_3: 1.833  loss_mask_3: 0.6192  loss_dice_3: 3.19  loss_ce_4: 1.773  loss_mask_4: 0.6198  loss_dice_4: 3.182  loss_ce_5: 1.735  loss_mask_5: 0.6212  loss_dice_5: 3.178  loss_ce_6: 1.747  loss_mask_6: 0.6198  loss_dice_6: 3.166  loss_ce_7: 1.743  loss_mask_7: 0.6201  loss_dice_7: 3.172  loss_ce_8: 1.717  loss_mask_8: 0.6207  loss_dice_8: 3.173  time: 1.6943  data_time: 0.3422  lr: 4.1119e-06  max_mem: 17674M
[01/19 13:38:29] d2.utils.events INFO:  eta: 6:59:07  iter: 25119  total_loss: 56.3  loss_ce: 1.59  loss_mask: 0.6178  loss_dice: 3.143  loss_ce_0: 2.922  loss_mask_0: 0.6334  loss_dice_0: 3.464  loss_ce_1: 1.916  loss_mask_1: 0.6124  loss_dice_1: 3.278  loss_ce_2: 1.758  loss_mask_2: 0.61  loss_dice_2: 3.214  loss_ce_3: 1.706  loss_mask_3: 0.6138  loss_dice_3: 3.171  loss_ce_4: 1.635  loss_mask_4: 0.6182  loss_dice_4: 3.171  loss_ce_5: 1.61  loss_mask_5: 0.6168  loss_dice_5: 3.168  loss_ce_6: 1.601  loss_mask_6: 0.6189  loss_dice_6: 3.16  loss_ce_7: 1.578  loss_mask_7: 0.6194  loss_dice_7: 3.155  loss_ce_8: 1.58  loss_mask_8: 0.6176  loss_dice_8: 3.157  time: 1.6943  data_time: 0.3281  lr: 4.1069e-06  max_mem: 17674M
[01/19 13:39:02] d2.utils.events INFO:  eta: 6:58:25  iter: 25139  total_loss: 56.98  loss_ce: 1.698  loss_mask: 0.622  loss_dice: 3.149  loss_ce_0: 2.929  loss_mask_0: 0.6418  loss_dice_0: 3.468  loss_ce_1: 1.947  loss_mask_1: 0.6273  loss_dice_1: 3.295  loss_ce_2: 1.851  loss_mask_2: 0.6191  loss_dice_2: 3.226  loss_ce_3: 1.79  loss_mask_3: 0.6174  loss_dice_3: 3.179  loss_ce_4: 1.746  loss_mask_4: 0.6231  loss_dice_4: 3.17  loss_ce_5: 1.729  loss_mask_5: 0.6224  loss_dice_5: 3.173  loss_ce_6: 1.704  loss_mask_6: 0.6219  loss_dice_6: 3.163  loss_ce_7: 1.694  loss_mask_7: 0.6227  loss_dice_7: 3.162  loss_ce_8: 1.692  loss_mask_8: 0.622  loss_dice_8: 3.161  time: 1.6943  data_time: 0.3343  lr: 4.1019e-06  max_mem: 17674M
[01/19 13:39:36] d2.utils.events INFO:  eta: 6:57:55  iter: 25159  total_loss: 55.86  loss_ce: 1.582  loss_mask: 0.6011  loss_dice: 3.149  loss_ce_0: 2.901  loss_mask_0: 0.6181  loss_dice_0: 3.458  loss_ce_1: 1.854  loss_mask_1: 0.6054  loss_dice_1: 3.27  loss_ce_2: 1.721  loss_mask_2: 0.6013  loss_dice_2: 3.21  loss_ce_3: 1.664  loss_mask_3: 0.599  loss_dice_3: 3.183  loss_ce_4: 1.626  loss_mask_4: 0.6016  loss_dice_4: 3.173  loss_ce_5: 1.599  loss_mask_5: 0.602  loss_dice_5: 3.168  loss_ce_6: 1.596  loss_mask_6: 0.6002  loss_dice_6: 3.154  loss_ce_7: 1.576  loss_mask_7: 0.6001  loss_dice_7: 3.155  loss_ce_8: 1.571  loss_mask_8: 0.601  loss_dice_8: 3.156  time: 1.6943  data_time: 0.3291  lr: 4.097e-06  max_mem: 17674M
[01/19 13:40:10] d2.utils.events INFO:  eta: 6:57:11  iter: 25179  total_loss: 56.46  loss_ce: 1.676  loss_mask: 0.621  loss_dice: 3.1  loss_ce_0: 2.953  loss_mask_0: 0.6572  loss_dice_0: 3.427  loss_ce_1: 1.964  loss_mask_1: 0.6261  loss_dice_1: 3.242  loss_ce_2: 1.84  loss_mask_2: 0.6201  loss_dice_2: 3.174  loss_ce_3: 1.784  loss_mask_3: 0.6227  loss_dice_3: 3.122  loss_ce_4: 1.71  loss_mask_4: 0.6225  loss_dice_4: 3.121  loss_ce_5: 1.687  loss_mask_5: 0.622  loss_dice_5: 3.11  loss_ce_6: 1.699  loss_mask_6: 0.6227  loss_dice_6: 3.108  loss_ce_7: 1.682  loss_mask_7: 0.6236  loss_dice_7: 3.102  loss_ce_8: 1.656  loss_mask_8: 0.6219  loss_dice_8: 3.101  time: 1.6942  data_time: 0.3375  lr: 4.092e-06  max_mem: 17674M
[01/19 13:40:44] d2.utils.events INFO:  eta: 6:56:37  iter: 25199  total_loss: 56.44  loss_ce: 1.594  loss_mask: 0.6216  loss_dice: 3.141  loss_ce_0: 2.928  loss_mask_0: 0.6387  loss_dice_0: 3.456  loss_ce_1: 1.863  loss_mask_1: 0.6338  loss_dice_1: 3.284  loss_ce_2: 1.746  loss_mask_2: 0.6293  loss_dice_2: 3.212  loss_ce_3: 1.687  loss_mask_3: 0.619  loss_dice_3: 3.164  loss_ce_4: 1.634  loss_mask_4: 0.6187  loss_dice_4: 3.164  loss_ce_5: 1.615  loss_mask_5: 0.6187  loss_dice_5: 3.157  loss_ce_6: 1.613  loss_mask_6: 0.6182  loss_dice_6: 3.146  loss_ce_7: 1.601  loss_mask_7: 0.6179  loss_dice_7: 3.142  loss_ce_8: 1.58  loss_mask_8: 0.6202  loss_dice_8: 3.142  time: 1.6942  data_time: 0.3550  lr: 4.087e-06  max_mem: 17674M
[01/19 13:41:18] d2.utils.events INFO:  eta: 6:56:08  iter: 25219  total_loss: 57.23  loss_ce: 1.685  loss_mask: 0.6165  loss_dice: 3.173  loss_ce_0: 2.919  loss_mask_0: 0.6288  loss_dice_0: 3.483  loss_ce_1: 1.933  loss_mask_1: 0.6264  loss_dice_1: 3.306  loss_ce_2: 1.807  loss_mask_2: 0.6243  loss_dice_2: 3.249  loss_ce_3: 1.777  loss_mask_3: 0.621  loss_dice_3: 3.208  loss_ce_4: 1.738  loss_mask_4: 0.6204  loss_dice_4: 3.2  loss_ce_5: 1.701  loss_mask_5: 0.6207  loss_dice_5: 3.2  loss_ce_6: 1.699  loss_mask_6: 0.6186  loss_dice_6: 3.183  loss_ce_7: 1.702  loss_mask_7: 0.6187  loss_dice_7: 3.182  loss_ce_8: 1.672  loss_mask_8: 0.6179  loss_dice_8: 3.179  time: 1.6943  data_time: 0.3409  lr: 4.0821e-06  max_mem: 17674M
[01/19 13:41:52] d2.utils.events INFO:  eta: 6:55:37  iter: 25239  total_loss: 56.48  loss_ce: 1.648  loss_mask: 0.616  loss_dice: 3.1  loss_ce_0: 2.925  loss_mask_0: 0.629  loss_dice_0: 3.42  loss_ce_1: 1.943  loss_mask_1: 0.6204  loss_dice_1: 3.245  loss_ce_2: 1.82  loss_mask_2: 0.623  loss_dice_2: 3.168  loss_ce_3: 1.759  loss_mask_3: 0.6173  loss_dice_3: 3.127  loss_ce_4: 1.689  loss_mask_4: 0.6154  loss_dice_4: 3.116  loss_ce_5: 1.665  loss_mask_5: 0.6154  loss_dice_5: 3.119  loss_ce_6: 1.655  loss_mask_6: 0.6152  loss_dice_6: 3.107  loss_ce_7: 1.641  loss_mask_7: 0.6149  loss_dice_7: 3.108  loss_ce_8: 1.634  loss_mask_8: 0.6151  loss_dice_8: 3.106  time: 1.6943  data_time: 0.3357  lr: 4.0771e-06  max_mem: 17674M
[01/19 13:42:26] d2.utils.events INFO:  eta: 6:55:06  iter: 25259  total_loss: 56.96  loss_ce: 1.637  loss_mask: 0.6212  loss_dice: 3.102  loss_ce_0: 2.924  loss_mask_0: 0.6467  loss_dice_0: 3.42  loss_ce_1: 1.917  loss_mask_1: 0.6325  loss_dice_1: 3.242  loss_ce_2: 1.778  loss_mask_2: 0.6247  loss_dice_2: 3.167  loss_ce_3: 1.74  loss_mask_3: 0.6211  loss_dice_3: 3.132  loss_ce_4: 1.68  loss_mask_4: 0.6214  loss_dice_4: 3.124  loss_ce_5: 1.669  loss_mask_5: 0.6235  loss_dice_5: 3.111  loss_ce_6: 1.671  loss_mask_6: 0.6249  loss_dice_6: 3.11  loss_ce_7: 1.645  loss_mask_7: 0.62  loss_dice_7: 3.106  loss_ce_8: 1.629  loss_mask_8: 0.6236  loss_dice_8: 3.102  time: 1.6942  data_time: 0.3292  lr: 4.0721e-06  max_mem: 17674M
[01/19 13:42:59] d2.utils.events INFO:  eta: 6:54:24  iter: 25279  total_loss: 55.59  loss_ce: 1.591  loss_mask: 0.6253  loss_dice: 3.1  loss_ce_0: 2.841  loss_mask_0: 0.6498  loss_dice_0: 3.423  loss_ce_1: 1.893  loss_mask_1: 0.6334  loss_dice_1: 3.237  loss_ce_2: 1.763  loss_mask_2: 0.6251  loss_dice_2: 3.17  loss_ce_3: 1.693  loss_mask_3: 0.6246  loss_dice_3: 3.128  loss_ce_4: 1.64  loss_mask_4: 0.6234  loss_dice_4: 3.122  loss_ce_5: 1.606  loss_mask_5: 0.6262  loss_dice_5: 3.119  loss_ce_6: 1.598  loss_mask_6: 0.6253  loss_dice_6: 3.106  loss_ce_7: 1.575  loss_mask_7: 0.6247  loss_dice_7: 3.111  loss_ce_8: 1.571  loss_mask_8: 0.626  loss_dice_8: 3.104  time: 1.6942  data_time: 0.3415  lr: 4.0671e-06  max_mem: 17674M
[01/19 13:43:34] d2.utils.events INFO:  eta: 6:53:56  iter: 25299  total_loss: 57.13  loss_ce: 1.569  loss_mask: 0.6012  loss_dice: 3.21  loss_ce_0: 2.862  loss_mask_0: 0.6225  loss_dice_0: 3.512  loss_ce_1: 1.869  loss_mask_1: 0.6079  loss_dice_1: 3.354  loss_ce_2: 1.745  loss_mask_2: 0.6025  loss_dice_2: 3.291  loss_ce_3: 1.68  loss_mask_3: 0.5982  loss_dice_3: 3.244  loss_ce_4: 1.645  loss_mask_4: 0.5977  loss_dice_4: 3.234  loss_ce_5: 1.621  loss_mask_5: 0.601  loss_dice_5: 3.242  loss_ce_6: 1.609  loss_mask_6: 0.5994  loss_dice_6: 3.219  loss_ce_7: 1.603  loss_mask_7: 0.6  loss_dice_7: 3.214  loss_ce_8: 1.59  loss_mask_8: 0.5989  loss_dice_8: 3.214  time: 1.6943  data_time: 0.3616  lr: 4.0622e-06  max_mem: 17674M
[01/19 13:44:08] d2.utils.events INFO:  eta: 6:53:32  iter: 25319  total_loss: 57.23  loss_ce: 1.71  loss_mask: 0.6337  loss_dice: 3.141  loss_ce_0: 2.94  loss_mask_0: 0.6588  loss_dice_0: 3.447  loss_ce_1: 1.998  loss_mask_1: 0.6393  loss_dice_1: 3.277  loss_ce_2: 1.886  loss_mask_2: 0.6362  loss_dice_2: 3.199  loss_ce_3: 1.814  loss_mask_3: 0.6283  loss_dice_3: 3.162  loss_ce_4: 1.771  loss_mask_4: 0.6289  loss_dice_4: 3.158  loss_ce_5: 1.745  loss_mask_5: 0.6292  loss_dice_5: 3.151  loss_ce_6: 1.735  loss_mask_6: 0.6305  loss_dice_6: 3.143  loss_ce_7: 1.714  loss_mask_7: 0.6314  loss_dice_7: 3.137  loss_ce_8: 1.702  loss_mask_8: 0.6313  loss_dice_8: 3.141  time: 1.6943  data_time: 0.3359  lr: 4.0572e-06  max_mem: 17674M
[01/19 13:44:42] d2.utils.events INFO:  eta: 6:53:05  iter: 25339  total_loss: 56.99  loss_ce: 1.646  loss_mask: 0.6102  loss_dice: 3.176  loss_ce_0: 2.905  loss_mask_0: 0.6328  loss_dice_0: 3.483  loss_ce_1: 1.907  loss_mask_1: 0.6264  loss_dice_1: 3.309  loss_ce_2: 1.787  loss_mask_2: 0.6247  loss_dice_2: 3.247  loss_ce_3: 1.74  loss_mask_3: 0.6123  loss_dice_3: 3.199  loss_ce_4: 1.691  loss_mask_4: 0.6124  loss_dice_4: 3.194  loss_ce_5: 1.662  loss_mask_5: 0.6138  loss_dice_5: 3.191  loss_ce_6: 1.662  loss_mask_6: 0.6105  loss_dice_6: 3.177  loss_ce_7: 1.648  loss_mask_7: 0.6117  loss_dice_7: 3.177  loss_ce_8: 1.646  loss_mask_8: 0.6093  loss_dice_8: 3.175  time: 1.6943  data_time: 0.3383  lr: 4.0522e-06  max_mem: 17674M
[01/19 13:45:16] d2.utils.events INFO:  eta: 6:52:36  iter: 25359  total_loss: 57.88  loss_ce: 1.764  loss_mask: 0.6249  loss_dice: 3.193  loss_ce_0: 2.912  loss_mask_0: 0.6505  loss_dice_0: 3.493  loss_ce_1: 2.034  loss_mask_1: 0.6265  loss_dice_1: 3.335  loss_ce_2: 1.878  loss_mask_2: 0.6203  loss_dice_2: 3.26  loss_ce_3: 1.844  loss_mask_3: 0.6193  loss_dice_3: 3.22  loss_ce_4: 1.797  loss_mask_4: 0.6238  loss_dice_4: 3.213  loss_ce_5: 1.792  loss_mask_5: 0.621  loss_dice_5: 3.206  loss_ce_6: 1.778  loss_mask_6: 0.6201  loss_dice_6: 3.197  loss_ce_7: 1.755  loss_mask_7: 0.6219  loss_dice_7: 3.195  loss_ce_8: 1.753  loss_mask_8: 0.6245  loss_dice_8: 3.192  time: 1.6943  data_time: 0.3591  lr: 4.0472e-06  max_mem: 17674M
[01/19 13:45:50] d2.utils.events INFO:  eta: 6:52:03  iter: 25379  total_loss: 57.18  loss_ce: 1.667  loss_mask: 0.6157  loss_dice: 3.137  loss_ce_0: 2.862  loss_mask_0: 0.6458  loss_dice_0: 3.454  loss_ce_1: 1.955  loss_mask_1: 0.6222  loss_dice_1: 3.278  loss_ce_2: 1.829  loss_mask_2: 0.6131  loss_dice_2: 3.208  loss_ce_3: 1.776  loss_mask_3: 0.6113  loss_dice_3: 3.163  loss_ce_4: 1.731  loss_mask_4: 0.6141  loss_dice_4: 3.159  loss_ce_5: 1.686  loss_mask_5: 0.6158  loss_dice_5: 3.151  loss_ce_6: 1.695  loss_mask_6: 0.6149  loss_dice_6: 3.142  loss_ce_7: 1.663  loss_mask_7: 0.6144  loss_dice_7: 3.14  loss_ce_8: 1.678  loss_mask_8: 0.6165  loss_dice_8: 3.143  time: 1.6943  data_time: 0.3282  lr: 4.0423e-06  max_mem: 17674M
[01/19 13:46:23] d2.utils.events INFO:  eta: 6:51:24  iter: 25399  total_loss: 56.9  loss_ce: 1.663  loss_mask: 0.6171  loss_dice: 3.14  loss_ce_0: 2.917  loss_mask_0: 0.6408  loss_dice_0: 3.443  loss_ce_1: 1.954  loss_mask_1: 0.6202  loss_dice_1: 3.277  loss_ce_2: 1.819  loss_mask_2: 0.6145  loss_dice_2: 3.217  loss_ce_3: 1.755  loss_mask_3: 0.6142  loss_dice_3: 3.163  loss_ce_4: 1.717  loss_mask_4: 0.6172  loss_dice_4: 3.161  loss_ce_5: 1.695  loss_mask_5: 0.6173  loss_dice_5: 3.157  loss_ce_6: 1.682  loss_mask_6: 0.615  loss_dice_6: 3.151  loss_ce_7: 1.666  loss_mask_7: 0.6156  loss_dice_7: 3.15  loss_ce_8: 1.675  loss_mask_8: 0.6185  loss_dice_8: 3.144  time: 1.6942  data_time: 0.3392  lr: 4.0373e-06  max_mem: 17674M
[01/19 13:46:57] d2.utils.events INFO:  eta: 6:50:52  iter: 25419  total_loss: 56.87  loss_ce: 1.677  loss_mask: 0.6332  loss_dice: 3.163  loss_ce_0: 2.81  loss_mask_0: 0.6387  loss_dice_0: 3.467  loss_ce_1: 1.951  loss_mask_1: 0.6318  loss_dice_1: 3.294  loss_ce_2: 1.814  loss_mask_2: 0.63  loss_dice_2: 3.232  loss_ce_3: 1.764  loss_mask_3: 0.6254  loss_dice_3: 3.185  loss_ce_4: 1.705  loss_mask_4: 0.6312  loss_dice_4: 3.177  loss_ce_5: 1.676  loss_mask_5: 0.6335  loss_dice_5: 3.178  loss_ce_6: 1.693  loss_mask_6: 0.6338  loss_dice_6: 3.163  loss_ce_7: 1.682  loss_mask_7: 0.6348  loss_dice_7: 3.161  loss_ce_8: 1.662  loss_mask_8: 0.6329  loss_dice_8: 3.165  time: 1.6942  data_time: 0.3414  lr: 4.0323e-06  max_mem: 17674M
[01/19 13:47:31] d2.utils.events INFO:  eta: 6:50:14  iter: 25439  total_loss: 56.4  loss_ce: 1.617  loss_mask: 0.6262  loss_dice: 3.128  loss_ce_0: 2.864  loss_mask_0: 0.6437  loss_dice_0: 3.464  loss_ce_1: 1.927  loss_mask_1: 0.6258  loss_dice_1: 3.264  loss_ce_2: 1.782  loss_mask_2: 0.6206  loss_dice_2: 3.197  loss_ce_3: 1.729  loss_mask_3: 0.6243  loss_dice_3: 3.154  loss_ce_4: 1.691  loss_mask_4: 0.6255  loss_dice_4: 3.148  loss_ce_5: 1.651  loss_mask_5: 0.6271  loss_dice_5: 3.144  loss_ce_6: 1.647  loss_mask_6: 0.6255  loss_dice_6: 3.143  loss_ce_7: 1.643  loss_mask_7: 0.6254  loss_dice_7: 3.136  loss_ce_8: 1.615  loss_mask_8: 0.6275  loss_dice_8: 3.135  time: 1.6942  data_time: 0.3330  lr: 4.0273e-06  max_mem: 17674M
[01/19 13:48:05] d2.utils.events INFO:  eta: 6:49:35  iter: 25459  total_loss: 56.69  loss_ce: 1.721  loss_mask: 0.6118  loss_dice: 3.104  loss_ce_0: 2.91  loss_mask_0: 0.6263  loss_dice_0: 3.417  loss_ce_1: 1.991  loss_mask_1: 0.6171  loss_dice_1: 3.238  loss_ce_2: 1.853  loss_mask_2: 0.615  loss_dice_2: 3.169  loss_ce_3: 1.783  loss_mask_3: 0.6124  loss_dice_3: 3.135  loss_ce_4: 1.719  loss_mask_4: 0.6125  loss_dice_4: 3.131  loss_ce_5: 1.733  loss_mask_5: 0.6139  loss_dice_5: 3.118  loss_ce_6: 1.715  loss_mask_6: 0.6122  loss_dice_6: 3.111  loss_ce_7: 1.726  loss_mask_7: 0.6137  loss_dice_7: 3.104  loss_ce_8: 1.729  loss_mask_8: 0.6135  loss_dice_8: 3.101  time: 1.6942  data_time: 0.3466  lr: 4.0224e-06  max_mem: 17674M
[01/19 13:48:39] d2.utils.events INFO:  eta: 6:49:09  iter: 25479  total_loss: 56.78  loss_ce: 1.655  loss_mask: 0.6142  loss_dice: 3.174  loss_ce_0: 2.852  loss_mask_0: 0.6369  loss_dice_0: 3.489  loss_ce_1: 1.914  loss_mask_1: 0.6156  loss_dice_1: 3.308  loss_ce_2: 1.796  loss_mask_2: 0.6154  loss_dice_2: 3.245  loss_ce_3: 1.768  loss_mask_3: 0.6106  loss_dice_3: 3.201  loss_ce_4: 1.712  loss_mask_4: 0.6122  loss_dice_4: 3.192  loss_ce_5: 1.676  loss_mask_5: 0.6146  loss_dice_5: 3.198  loss_ce_6: 1.683  loss_mask_6: 0.615  loss_dice_6: 3.184  loss_ce_7: 1.661  loss_mask_7: 0.6128  loss_dice_7: 3.183  loss_ce_8: 1.66  loss_mask_8: 0.6149  loss_dice_8: 3.182  time: 1.6943  data_time: 0.3407  lr: 4.0174e-06  max_mem: 17674M
[01/19 13:49:13] d2.utils.events INFO:  eta: 6:48:37  iter: 25499  total_loss: 56.16  loss_ce: 1.594  loss_mask: 0.6204  loss_dice: 3.176  loss_ce_0: 2.828  loss_mask_0: 0.6401  loss_dice_0: 3.476  loss_ce_1: 1.895  loss_mask_1: 0.6207  loss_dice_1: 3.307  loss_ce_2: 1.758  loss_mask_2: 0.6214  loss_dice_2: 3.242  loss_ce_3: 1.689  loss_mask_3: 0.6173  loss_dice_3: 3.205  loss_ce_4: 1.645  loss_mask_4: 0.6179  loss_dice_4: 3.197  loss_ce_5: 1.604  loss_mask_5: 0.6175  loss_dice_5: 3.187  loss_ce_6: 1.61  loss_mask_6: 0.6177  loss_dice_6: 3.174  loss_ce_7: 1.586  loss_mask_7: 0.6202  loss_dice_7: 3.187  loss_ce_8: 1.584  loss_mask_8: 0.6206  loss_dice_8: 3.175  time: 1.6943  data_time: 0.3364  lr: 4.0124e-06  max_mem: 17674M
[01/19 13:49:47] d2.utils.events INFO:  eta: 6:48:05  iter: 25519  total_loss: 56.98  loss_ce: 1.657  loss_mask: 0.6239  loss_dice: 3.161  loss_ce_0: 2.851  loss_mask_0: 0.6468  loss_dice_0: 3.484  loss_ce_1: 1.923  loss_mask_1: 0.6305  loss_dice_1: 3.306  loss_ce_2: 1.825  loss_mask_2: 0.6252  loss_dice_2: 3.233  loss_ce_3: 1.76  loss_mask_3: 0.6232  loss_dice_3: 3.191  loss_ce_4: 1.711  loss_mask_4: 0.6228  loss_dice_4: 3.179  loss_ce_5: 1.686  loss_mask_5: 0.6245  loss_dice_5: 3.178  loss_ce_6: 1.675  loss_mask_6: 0.6225  loss_dice_6: 3.165  loss_ce_7: 1.663  loss_mask_7: 0.6234  loss_dice_7: 3.167  loss_ce_8: 1.671  loss_mask_8: 0.6239  loss_dice_8: 3.165  time: 1.6943  data_time: 0.3559  lr: 4.0074e-06  max_mem: 17674M
[01/19 13:50:21] d2.utils.events INFO:  eta: 6:47:29  iter: 25539  total_loss: 55.96  loss_ce: 1.602  loss_mask: 0.6128  loss_dice: 3.076  loss_ce_0: 2.829  loss_mask_0: 0.6404  loss_dice_0: 3.425  loss_ce_1: 1.893  loss_mask_1: 0.6211  loss_dice_1: 3.229  loss_ce_2: 1.781  loss_mask_2: 0.6189  loss_dice_2: 3.165  loss_ce_3: 1.722  loss_mask_3: 0.6096  loss_dice_3: 3.11  loss_ce_4: 1.672  loss_mask_4: 0.6115  loss_dice_4: 3.099  loss_ce_5: 1.636  loss_mask_5: 0.6123  loss_dice_5: 3.096  loss_ce_6: 1.628  loss_mask_6: 0.6124  loss_dice_6: 3.083  loss_ce_7: 1.615  loss_mask_7: 0.6122  loss_dice_7: 3.089  loss_ce_8: 1.607  loss_mask_8: 0.615  loss_dice_8: 3.081  time: 1.6943  data_time: 0.3463  lr: 4.0024e-06  max_mem: 17674M
[01/19 13:50:55] d2.utils.events INFO:  eta: 6:46:39  iter: 25559  total_loss: 57  loss_ce: 1.706  loss_mask: 0.6217  loss_dice: 3.126  loss_ce_0: 2.933  loss_mask_0: 0.6503  loss_dice_0: 3.441  loss_ce_1: 1.962  loss_mask_1: 0.6335  loss_dice_1: 3.24  loss_ce_2: 1.817  loss_mask_2: 0.6219  loss_dice_2: 3.199  loss_ce_3: 1.773  loss_mask_3: 0.6249  loss_dice_3: 3.146  loss_ce_4: 1.727  loss_mask_4: 0.6285  loss_dice_4: 3.143  loss_ce_5: 1.709  loss_mask_5: 0.6279  loss_dice_5: 3.146  loss_ce_6: 1.712  loss_mask_6: 0.6224  loss_dice_6: 3.13  loss_ce_7: 1.693  loss_mask_7: 0.6241  loss_dice_7: 3.125  loss_ce_8: 1.7  loss_mask_8: 0.6217  loss_dice_8: 3.129  time: 1.6942  data_time: 0.3229  lr: 3.9975e-06  max_mem: 17674M
[01/19 13:51:29] d2.utils.events INFO:  eta: 6:46:17  iter: 25579  total_loss: 56.28  loss_ce: 1.625  loss_mask: 0.6084  loss_dice: 3.124  loss_ce_0: 2.872  loss_mask_0: 0.639  loss_dice_0: 3.447  loss_ce_1: 1.915  loss_mask_1: 0.6174  loss_dice_1: 3.271  loss_ce_2: 1.774  loss_mask_2: 0.6166  loss_dice_2: 3.194  loss_ce_3: 1.703  loss_mask_3: 0.6152  loss_dice_3: 3.149  loss_ce_4: 1.664  loss_mask_4: 0.6149  loss_dice_4: 3.144  loss_ce_5: 1.626  loss_mask_5: 0.6159  loss_dice_5: 3.147  loss_ce_6: 1.644  loss_mask_6: 0.614  loss_dice_6: 3.128  loss_ce_7: 1.631  loss_mask_7: 0.6122  loss_dice_7: 3.123  loss_ce_8: 1.617  loss_mask_8: 0.6115  loss_dice_8: 3.132  time: 1.6943  data_time: 0.3493  lr: 3.9925e-06  max_mem: 17674M
[01/19 13:52:03] d2.utils.events INFO:  eta: 6:45:38  iter: 25599  total_loss: 56.09  loss_ce: 1.63  loss_mask: 0.6082  loss_dice: 3.152  loss_ce_0: 2.791  loss_mask_0: 0.6324  loss_dice_0: 3.47  loss_ce_1: 1.854  loss_mask_1: 0.6161  loss_dice_1: 3.29  loss_ce_2: 1.745  loss_mask_2: 0.6097  loss_dice_2: 3.223  loss_ce_3: 1.701  loss_mask_3: 0.608  loss_dice_3: 3.173  loss_ce_4: 1.644  loss_mask_4: 0.6099  loss_dice_4: 3.169  loss_ce_5: 1.619  loss_mask_5: 0.6077  loss_dice_5: 3.17  loss_ce_6: 1.642  loss_mask_6: 0.6086  loss_dice_6: 3.144  loss_ce_7: 1.611  loss_mask_7: 0.6079  loss_dice_7: 3.152  loss_ce_8: 1.616  loss_mask_8: 0.6088  loss_dice_8: 3.147  time: 1.6943  data_time: 0.3507  lr: 3.9875e-06  max_mem: 17674M
[01/19 13:52:37] d2.utils.events INFO:  eta: 6:45:16  iter: 25619  total_loss: 56.87  loss_ce: 1.616  loss_mask: 0.6153  loss_dice: 3.124  loss_ce_0: 2.823  loss_mask_0: 0.6471  loss_dice_0: 3.445  loss_ce_1: 1.889  loss_mask_1: 0.6231  loss_dice_1: 3.258  loss_ce_2: 1.747  loss_mask_2: 0.6188  loss_dice_2: 3.192  loss_ce_3: 1.715  loss_mask_3: 0.6168  loss_dice_3: 3.147  loss_ce_4: 1.641  loss_mask_4: 0.6159  loss_dice_4: 3.138  loss_ce_5: 1.628  loss_mask_5: 0.617  loss_dice_5: 3.132  loss_ce_6: 1.63  loss_mask_6: 0.6156  loss_dice_6: 3.124  loss_ce_7: 1.614  loss_mask_7: 0.6165  loss_dice_7: 3.125  loss_ce_8: 1.625  loss_mask_8: 0.6152  loss_dice_8: 3.122  time: 1.6943  data_time: 0.3416  lr: 3.9825e-06  max_mem: 17674M
[01/19 13:53:11] d2.utils.events INFO:  eta: 6:44:42  iter: 25639  total_loss: 57.39  loss_ce: 1.7  loss_mask: 0.6108  loss_dice: 3.133  loss_ce_0: 2.903  loss_mask_0: 0.641  loss_dice_0: 3.43  loss_ce_1: 1.993  loss_mask_1: 0.6241  loss_dice_1: 3.259  loss_ce_2: 1.877  loss_mask_2: 0.6193  loss_dice_2: 3.179  loss_ce_3: 1.813  loss_mask_3: 0.6132  loss_dice_3: 3.149  loss_ce_4: 1.758  loss_mask_4: 0.6129  loss_dice_4: 3.144  loss_ce_5: 1.739  loss_mask_5: 0.6115  loss_dice_5: 3.14  loss_ce_6: 1.722  loss_mask_6: 0.612  loss_dice_6: 3.136  loss_ce_7: 1.708  loss_mask_7: 0.611  loss_dice_7: 3.135  loss_ce_8: 1.695  loss_mask_8: 0.611  loss_dice_8: 3.13  time: 1.6943  data_time: 0.3332  lr: 3.9775e-06  max_mem: 17674M
[01/19 13:53:46] d2.utils.events INFO:  eta: 6:44:18  iter: 25659  total_loss: 56.54  loss_ce: 1.672  loss_mask: 0.6089  loss_dice: 3.178  loss_ce_0: 2.875  loss_mask_0: 0.6203  loss_dice_0: 3.51  loss_ce_1: 1.893  loss_mask_1: 0.6097  loss_dice_1: 3.334  loss_ce_2: 1.793  loss_mask_2: 0.6048  loss_dice_2: 3.264  loss_ce_3: 1.742  loss_mask_3: 0.6069  loss_dice_3: 3.218  loss_ce_4: 1.685  loss_mask_4: 0.6064  loss_dice_4: 3.211  loss_ce_5: 1.668  loss_mask_5: 0.6088  loss_dice_5: 3.194  loss_ce_6: 1.653  loss_mask_6: 0.608  loss_dice_6: 3.184  loss_ce_7: 1.646  loss_mask_7: 0.608  loss_dice_7: 3.178  loss_ce_8: 1.657  loss_mask_8: 0.6072  loss_dice_8: 3.181  time: 1.6943  data_time: 0.3380  lr: 3.9725e-06  max_mem: 17674M
[01/19 13:54:20] d2.utils.events INFO:  eta: 6:43:51  iter: 25679  total_loss: 56.57  loss_ce: 1.699  loss_mask: 0.6261  loss_dice: 3.148  loss_ce_0: 2.863  loss_mask_0: 0.6479  loss_dice_0: 3.431  loss_ce_1: 1.904  loss_mask_1: 0.6285  loss_dice_1: 3.284  loss_ce_2: 1.793  loss_mask_2: 0.6259  loss_dice_2: 3.211  loss_ce_3: 1.743  loss_mask_3: 0.6241  loss_dice_3: 3.173  loss_ce_4: 1.719  loss_mask_4: 0.6263  loss_dice_4: 3.169  loss_ce_5: 1.695  loss_mask_5: 0.6259  loss_dice_5: 3.157  loss_ce_6: 1.691  loss_mask_6: 0.6236  loss_dice_6: 3.155  loss_ce_7: 1.7  loss_mask_7: 0.6244  loss_dice_7: 3.147  loss_ce_8: 1.683  loss_mask_8: 0.624  loss_dice_8: 3.152  time: 1.6943  data_time: 0.3557  lr: 3.9675e-06  max_mem: 17674M
[01/19 13:54:53] d2.utils.events INFO:  eta: 6:43:11  iter: 25699  total_loss: 56.22  loss_ce: 1.646  loss_mask: 0.6128  loss_dice: 3.108  loss_ce_0: 2.826  loss_mask_0: 0.6363  loss_dice_0: 3.427  loss_ce_1: 1.911  loss_mask_1: 0.6203  loss_dice_1: 3.252  loss_ce_2: 1.784  loss_mask_2: 0.6185  loss_dice_2: 3.179  loss_ce_3: 1.733  loss_mask_3: 0.6168  loss_dice_3: 3.139  loss_ce_4: 1.682  loss_mask_4: 0.6185  loss_dice_4: 3.134  loss_ce_5: 1.658  loss_mask_5: 0.6189  loss_dice_5: 3.126  loss_ce_6: 1.671  loss_mask_6: 0.6134  loss_dice_6: 3.108  loss_ce_7: 1.637  loss_mask_7: 0.6138  loss_dice_7: 3.11  loss_ce_8: 1.645  loss_mask_8: 0.6163  loss_dice_8: 3.11  time: 1.6943  data_time: 0.3338  lr: 3.9626e-06  max_mem: 17674M
[01/19 13:55:27] d2.utils.events INFO:  eta: 6:42:41  iter: 25719  total_loss: 56.94  loss_ce: 1.7  loss_mask: 0.6096  loss_dice: 3.139  loss_ce_0: 2.928  loss_mask_0: 0.6349  loss_dice_0: 3.452  loss_ce_1: 1.998  loss_mask_1: 0.616  loss_dice_1: 3.277  loss_ce_2: 1.825  loss_mask_2: 0.6111  loss_dice_2: 3.209  loss_ce_3: 1.785  loss_mask_3: 0.6118  loss_dice_3: 3.164  loss_ce_4: 1.742  loss_mask_4: 0.6095  loss_dice_4: 3.155  loss_ce_5: 1.737  loss_mask_5: 0.6092  loss_dice_5: 3.151  loss_ce_6: 1.725  loss_mask_6: 0.6111  loss_dice_6: 3.144  loss_ce_7: 1.717  loss_mask_7: 0.6098  loss_dice_7: 3.145  loss_ce_8: 1.725  loss_mask_8: 0.6111  loss_dice_8: 3.138  time: 1.6943  data_time: 0.3400  lr: 3.9576e-06  max_mem: 17674M
[01/19 13:56:01] d2.utils.events INFO:  eta: 6:42:03  iter: 25739  total_loss: 56.39  loss_ce: 1.58  loss_mask: 0.6098  loss_dice: 3.174  loss_ce_0: 2.781  loss_mask_0: 0.6333  loss_dice_0: 3.479  loss_ce_1: 1.87  loss_mask_1: 0.6142  loss_dice_1: 3.302  loss_ce_2: 1.732  loss_mask_2: 0.6099  loss_dice_2: 3.244  loss_ce_3: 1.679  loss_mask_3: 0.6088  loss_dice_3: 3.205  loss_ce_4: 1.623  loss_mask_4: 0.6106  loss_dice_4: 3.205  loss_ce_5: 1.597  loss_mask_5: 0.6095  loss_dice_5: 3.2  loss_ce_6: 1.597  loss_mask_6: 0.6108  loss_dice_6: 3.188  loss_ce_7: 1.593  loss_mask_7: 0.6101  loss_dice_7: 3.186  loss_ce_8: 1.568  loss_mask_8: 0.61  loss_dice_8: 3.178  time: 1.6943  data_time: 0.3394  lr: 3.9526e-06  max_mem: 17674M
[01/19 13:56:35] d2.utils.events INFO:  eta: 6:41:40  iter: 25759  total_loss: 57.68  loss_ce: 1.718  loss_mask: 0.617  loss_dice: 3.159  loss_ce_0: 2.924  loss_mask_0: 0.6405  loss_dice_0: 3.476  loss_ce_1: 1.989  loss_mask_1: 0.623  loss_dice_1: 3.292  loss_ce_2: 1.884  loss_mask_2: 0.6183  loss_dice_2: 3.231  loss_ce_3: 1.839  loss_mask_3: 0.6164  loss_dice_3: 3.181  loss_ce_4: 1.771  loss_mask_4: 0.6164  loss_dice_4: 3.175  loss_ce_5: 1.746  loss_mask_5: 0.6174  loss_dice_5: 3.171  loss_ce_6: 1.742  loss_mask_6: 0.6194  loss_dice_6: 3.154  loss_ce_7: 1.725  loss_mask_7: 0.6184  loss_dice_7: 3.164  loss_ce_8: 1.719  loss_mask_8: 0.619  loss_dice_8: 3.155  time: 1.6943  data_time: 0.3480  lr: 3.9476e-06  max_mem: 17674M
[01/19 13:57:08] d2.utils.events INFO:  eta: 6:41:04  iter: 25779  total_loss: 57.29  loss_ce: 1.647  loss_mask: 0.6296  loss_dice: 3.202  loss_ce_0: 2.889  loss_mask_0: 0.654  loss_dice_0: 3.502  loss_ce_1: 1.929  loss_mask_1: 0.6322  loss_dice_1: 3.341  loss_ce_2: 1.815  loss_mask_2: 0.6281  loss_dice_2: 3.265  loss_ce_3: 1.755  loss_mask_3: 0.6266  loss_dice_3: 3.225  loss_ce_4: 1.723  loss_mask_4: 0.6289  loss_dice_4: 3.221  loss_ce_5: 1.676  loss_mask_5: 0.6306  loss_dice_5: 3.21  loss_ce_6: 1.663  loss_mask_6: 0.6282  loss_dice_6: 3.204  loss_ce_7: 1.65  loss_mask_7: 0.6278  loss_dice_7: 3.208  loss_ce_8: 1.642  loss_mask_8: 0.6307  loss_dice_8: 3.199  time: 1.6943  data_time: 0.3344  lr: 3.9426e-06  max_mem: 17674M
[01/19 13:57:42] d2.utils.events INFO:  eta: 6:40:25  iter: 25799  total_loss: 56.37  loss_ce: 1.588  loss_mask: 0.608  loss_dice: 3.155  loss_ce_0: 2.864  loss_mask_0: 0.6265  loss_dice_0: 3.469  loss_ce_1: 1.849  loss_mask_1: 0.6099  loss_dice_1: 3.298  loss_ce_2: 1.743  loss_mask_2: 0.6112  loss_dice_2: 3.227  loss_ce_3: 1.672  loss_mask_3: 0.6034  loss_dice_3: 3.185  loss_ce_4: 1.65  loss_mask_4: 0.6029  loss_dice_4: 3.172  loss_ce_5: 1.627  loss_mask_5: 0.608  loss_dice_5: 3.171  loss_ce_6: 1.62  loss_mask_6: 0.6049  loss_dice_6: 3.166  loss_ce_7: 1.597  loss_mask_7: 0.6058  loss_dice_7: 3.16  loss_ce_8: 1.593  loss_mask_8: 0.6043  loss_dice_8: 3.158  time: 1.6943  data_time: 0.3345  lr: 3.9376e-06  max_mem: 17674M
[01/19 13:58:16] d2.utils.events INFO:  eta: 6:39:52  iter: 25819  total_loss: 57.35  loss_ce: 1.68  loss_mask: 0.6355  loss_dice: 3.149  loss_ce_0: 2.917  loss_mask_0: 0.6582  loss_dice_0: 3.469  loss_ce_1: 1.911  loss_mask_1: 0.6369  loss_dice_1: 3.295  loss_ce_2: 1.79  loss_mask_2: 0.6361  loss_dice_2: 3.228  loss_ce_3: 1.736  loss_mask_3: 0.6303  loss_dice_3: 3.175  loss_ce_4: 1.708  loss_mask_4: 0.6355  loss_dice_4: 3.168  loss_ce_5: 1.7  loss_mask_5: 0.6346  loss_dice_5: 3.164  loss_ce_6: 1.709  loss_mask_6: 0.6382  loss_dice_6: 3.155  loss_ce_7: 1.689  loss_mask_7: 0.6362  loss_dice_7: 3.156  loss_ce_8: 1.702  loss_mask_8: 0.6365  loss_dice_8: 3.151  time: 1.6943  data_time: 0.3378  lr: 3.9326e-06  max_mem: 17674M
[01/19 13:58:50] d2.utils.events INFO:  eta: 6:39:19  iter: 25839  total_loss: 56.54  loss_ce: 1.658  loss_mask: 0.6262  loss_dice: 3.148  loss_ce_0: 2.847  loss_mask_0: 0.6443  loss_dice_0: 3.448  loss_ce_1: 1.895  loss_mask_1: 0.6305  loss_dice_1: 3.28  loss_ce_2: 1.811  loss_mask_2: 0.631  loss_dice_2: 3.21  loss_ce_3: 1.733  loss_mask_3: 0.6253  loss_dice_3: 3.168  loss_ce_4: 1.699  loss_mask_4: 0.6267  loss_dice_4: 3.163  loss_ce_5: 1.672  loss_mask_5: 0.6262  loss_dice_5: 3.166  loss_ce_6: 1.667  loss_mask_6: 0.6244  loss_dice_6: 3.148  loss_ce_7: 1.659  loss_mask_7: 0.6248  loss_dice_7: 3.15  loss_ce_8: 1.656  loss_mask_8: 0.6243  loss_dice_8: 3.155  time: 1.6943  data_time: 0.3433  lr: 3.9276e-06  max_mem: 17674M
[01/19 13:59:24] d2.utils.events INFO:  eta: 6:38:38  iter: 25859  total_loss: 57.11  loss_ce: 1.697  loss_mask: 0.6221  loss_dice: 3.177  loss_ce_0: 2.936  loss_mask_0: 0.6444  loss_dice_0: 3.487  loss_ce_1: 1.989  loss_mask_1: 0.6318  loss_dice_1: 3.315  loss_ce_2: 1.879  loss_mask_2: 0.6259  loss_dice_2: 3.247  loss_ce_3: 1.814  loss_mask_3: 0.62  loss_dice_3: 3.194  loss_ce_4: 1.758  loss_mask_4: 0.6229  loss_dice_4: 3.192  loss_ce_5: 1.719  loss_mask_5: 0.6225  loss_dice_5: 3.191  loss_ce_6: 1.712  loss_mask_6: 0.6232  loss_dice_6: 3.18  loss_ce_7: 1.7  loss_mask_7: 0.6239  loss_dice_7: 3.177  loss_ce_8: 1.675  loss_mask_8: 0.6208  loss_dice_8: 3.18  time: 1.6943  data_time: 0.3456  lr: 3.9226e-06  max_mem: 17674M
[01/19 13:59:58] d2.utils.events INFO:  eta: 6:38:00  iter: 25879  total_loss: 56.84  loss_ce: 1.681  loss_mask: 0.6194  loss_dice: 3.115  loss_ce_0: 2.901  loss_mask_0: 0.6448  loss_dice_0: 3.46  loss_ce_1: 1.968  loss_mask_1: 0.6302  loss_dice_1: 3.276  loss_ce_2: 1.818  loss_mask_2: 0.6285  loss_dice_2: 3.202  loss_ce_3: 1.775  loss_mask_3: 0.6241  loss_dice_3: 3.151  loss_ce_4: 1.718  loss_mask_4: 0.6233  loss_dice_4: 3.144  loss_ce_5: 1.713  loss_mask_5: 0.6227  loss_dice_5: 3.137  loss_ce_6: 1.696  loss_mask_6: 0.6218  loss_dice_6: 3.129  loss_ce_7: 1.675  loss_mask_7: 0.6216  loss_dice_7: 3.122  loss_ce_8: 1.671  loss_mask_8: 0.6199  loss_dice_8: 3.119  time: 1.6943  data_time: 0.3566  lr: 3.9176e-06  max_mem: 17674M
[01/19 14:00:32] d2.utils.events INFO:  eta: 6:37:26  iter: 25899  total_loss: 55.99  loss_ce: 1.673  loss_mask: 0.6032  loss_dice: 3.075  loss_ce_0: 2.833  loss_mask_0: 0.6303  loss_dice_0: 3.404  loss_ce_1: 1.899  loss_mask_1: 0.6143  loss_dice_1: 3.217  loss_ce_2: 1.796  loss_mask_2: 0.6097  loss_dice_2: 3.15  loss_ce_3: 1.752  loss_mask_3: 0.6121  loss_dice_3: 3.106  loss_ce_4: 1.703  loss_mask_4: 0.6082  loss_dice_4: 3.108  loss_ce_5: 1.676  loss_mask_5: 0.6066  loss_dice_5: 3.101  loss_ce_6: 1.677  loss_mask_6: 0.6036  loss_dice_6: 3.092  loss_ce_7: 1.669  loss_mask_7: 0.6039  loss_dice_7: 3.081  loss_ce_8: 1.68  loss_mask_8: 0.6052  loss_dice_8: 3.083  time: 1.6943  data_time: 0.3385  lr: 3.9126e-06  max_mem: 17674M
[01/19 14:01:06] d2.utils.events INFO:  eta: 6:36:52  iter: 25919  total_loss: 56.45  loss_ce: 1.665  loss_mask: 0.6182  loss_dice: 3.124  loss_ce_0: 2.895  loss_mask_0: 0.6436  loss_dice_0: 3.43  loss_ce_1: 1.953  loss_mask_1: 0.6284  loss_dice_1: 3.255  loss_ce_2: 1.862  loss_mask_2: 0.6243  loss_dice_2: 3.186  loss_ce_3: 1.774  loss_mask_3: 0.6144  loss_dice_3: 3.147  loss_ce_4: 1.725  loss_mask_4: 0.6144  loss_dice_4: 3.145  loss_ce_5: 1.681  loss_mask_5: 0.6155  loss_dice_5: 3.146  loss_ce_6: 1.669  loss_mask_6: 0.6176  loss_dice_6: 3.132  loss_ce_7: 1.655  loss_mask_7: 0.6181  loss_dice_7: 3.125  loss_ce_8: 1.666  loss_mask_8: 0.6203  loss_dice_8: 3.121  time: 1.6943  data_time: 0.3292  lr: 3.9077e-06  max_mem: 17674M
[01/19 14:01:40] d2.utils.events INFO:  eta: 6:36:17  iter: 25939  total_loss: 56.86  loss_ce: 1.679  loss_mask: 0.6261  loss_dice: 3.198  loss_ce_0: 2.845  loss_mask_0: 0.6561  loss_dice_0: 3.49  loss_ce_1: 1.94  loss_mask_1: 0.6256  loss_dice_1: 3.323  loss_ce_2: 1.835  loss_mask_2: 0.6264  loss_dice_2: 3.263  loss_ce_3: 1.784  loss_mask_3: 0.6258  loss_dice_3: 3.223  loss_ce_4: 1.728  loss_mask_4: 0.6296  loss_dice_4: 3.217  loss_ce_5: 1.705  loss_mask_5: 0.629  loss_dice_5: 3.218  loss_ce_6: 1.693  loss_mask_6: 0.6264  loss_dice_6: 3.212  loss_ce_7: 1.671  loss_mask_7: 0.6262  loss_dice_7: 3.203  loss_ce_8: 1.663  loss_mask_8: 0.6266  loss_dice_8: 3.202  time: 1.6943  data_time: 0.3481  lr: 3.9027e-06  max_mem: 17674M
[01/19 14:02:13] d2.utils.events INFO:  eta: 6:35:28  iter: 25959  total_loss: 57.45  loss_ce: 1.642  loss_mask: 0.6154  loss_dice: 3.176  loss_ce_0: 2.843  loss_mask_0: 0.6303  loss_dice_0: 3.463  loss_ce_1: 1.929  loss_mask_1: 0.6163  loss_dice_1: 3.31  loss_ce_2: 1.799  loss_mask_2: 0.6155  loss_dice_2: 3.24  loss_ce_3: 1.739  loss_mask_3: 0.617  loss_dice_3: 3.194  loss_ce_4: 1.679  loss_mask_4: 0.6183  loss_dice_4: 3.191  loss_ce_5: 1.663  loss_mask_5: 0.617  loss_dice_5: 3.19  loss_ce_6: 1.65  loss_mask_6: 0.6178  loss_dice_6: 3.182  loss_ce_7: 1.647  loss_mask_7: 0.6187  loss_dice_7: 3.182  loss_ce_8: 1.637  loss_mask_8: 0.6177  loss_dice_8: 3.183  time: 1.6942  data_time: 0.3203  lr: 3.8977e-06  max_mem: 17674M
[01/19 14:02:47] d2.utils.events INFO:  eta: 6:34:46  iter: 25979  total_loss: 57.05  loss_ce: 1.651  loss_mask: 0.6098  loss_dice: 3.188  loss_ce_0: 2.824  loss_mask_0: 0.6376  loss_dice_0: 3.481  loss_ce_1: 1.931  loss_mask_1: 0.618  loss_dice_1: 3.321  loss_ce_2: 1.768  loss_mask_2: 0.6148  loss_dice_2: 3.254  loss_ce_3: 1.749  loss_mask_3: 0.6136  loss_dice_3: 3.214  loss_ce_4: 1.696  loss_mask_4: 0.6134  loss_dice_4: 3.201  loss_ce_5: 1.678  loss_mask_5: 0.6139  loss_dice_5: 3.204  loss_ce_6: 1.663  loss_mask_6: 0.6128  loss_dice_6: 3.188  loss_ce_7: 1.655  loss_mask_7: 0.6097  loss_dice_7: 3.187  loss_ce_8: 1.64  loss_mask_8: 0.6117  loss_dice_8: 3.188  time: 1.6942  data_time: 0.3481  lr: 3.8927e-06  max_mem: 17674M
[01/19 14:03:21] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 14:03:22] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 14:03:22] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 14:09:00] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.827390661957147, 'error_1pix': 0.3142866690990773, 'error_3pix': 0.13458649534964678, 'mIoU': 9.412693768552225, 'fwIoU': 25.907931833969638, 'IoU-0': nan, 'IoU-1': 95.44280658845979, 'IoU-2': 12.591016480972272, 'IoU-3': 41.5441339570466, 'IoU-4': 28.515261730054238, 'IoU-5': 22.146300295485645, 'IoU-6': 19.481894788375936, 'IoU-7': 13.58671597252959, 'IoU-8': 7.194609126145286, 'IoU-9': 14.742059430643852, 'IoU-10': 24.748988539396805, 'IoU-11': 32.411189848005826, 'IoU-12': 33.424599685583104, 'IoU-13': 30.973782068753465, 'IoU-14': 31.115794190512432, 'IoU-15': 29.83508005204888, 'IoU-16': 28.66590459360548, 'IoU-17': 24.474587295811137, 'IoU-18': 25.837954896856548, 'IoU-19': 25.544383464356603, 'IoU-20': 23.10452300680515, 'IoU-21': 25.972288779071583, 'IoU-22': 26.263822175656376, 'IoU-23': 25.371993860643844, 'IoU-24': 21.714836209728308, 'IoU-25': 22.947083511229653, 'IoU-26': 21.519650446328072, 'IoU-27': 26.160736273507517, 'IoU-28': 18.908913645065017, 'IoU-29': 24.628562302812036, 'IoU-30': 23.301343056219487, 'IoU-31': 20.56532427239289, 'IoU-32': 18.643625923309486, 'IoU-33': 19.7729550617446, 'IoU-34': 20.31927001197699, 'IoU-35': 17.068910701118924, 'IoU-36': 20.244805354279972, 'IoU-37': 18.65141993009909, 'IoU-38': 17.77386110794936, 'IoU-39': 19.21156412187139, 'IoU-40': 17.633013433388005, 'IoU-41': 15.281384808175424, 'IoU-42': 15.238202991787904, 'IoU-43': 15.313562401738837, 'IoU-44': 14.510626289591643, 'IoU-45': 15.437028287098133, 'IoU-46': 13.857075741999012, 'IoU-47': 14.665312233438474, 'IoU-48': 13.665124384173561, 'IoU-49': 15.386706558301777, 'IoU-50': 13.746063274302864, 'IoU-51': 15.036613277574167, 'IoU-52': 13.650206195487675, 'IoU-53': 14.411374458047327, 'IoU-54': 14.657062201495938, 'IoU-55': 14.809493050550927, 'IoU-56': 12.256353123188365, 'IoU-57': 13.612296391142781, 'IoU-58': 13.833491047031849, 'IoU-59': 12.41823519830703, 'IoU-60': 13.320690887729675, 'IoU-61': 10.842289228224804, 'IoU-62': 11.990899279797041, 'IoU-63': 10.045861046847126, 'IoU-64': 10.665026161718725, 'IoU-65': 10.846149134449105, 'IoU-66': 9.613819566245517, 'IoU-67': 10.373459904896423, 'IoU-68': 8.772902034836868, 'IoU-69': 8.37764396066663, 'IoU-70': 9.5527136644839, 'IoU-71': 8.757747371813274, 'IoU-72': 6.914251327196751, 'IoU-73': 9.063588178637476, 'IoU-74': 8.619228479328056, 'IoU-75': 9.236109516612128, 'IoU-76': 7.901677884929461, 'IoU-77': 8.182932654766024, 'IoU-78': 6.5153043501540635, 'IoU-79': 8.34614325181323, 'IoU-80': 7.058570430463732, 'IoU-81': 7.106805570866865, 'IoU-82': 6.452067014628474, 'IoU-83': 5.416472032116545, 'IoU-84': 6.410807107196859, 'IoU-85': 7.512362250430542, 'IoU-86': 6.3271215032173505, 'IoU-87': 6.837548099836665, 'IoU-88': 7.090926275642106, 'IoU-89': 6.508588407807489, 'IoU-90': 6.748761651758231, 'IoU-91': 5.6075153756296885, 'IoU-92': 5.650746202913832, 'IoU-93': 5.778170829085717, 'IoU-94': 6.791109200884043, 'IoU-95': 5.997875669572837, 'IoU-96': 8.272279837243325, 'IoU-97': 6.500705650784953, 'IoU-98': 6.247250517821213, 'IoU-99': 6.187707106975295, 'IoU-100': 6.66184314111341, 'IoU-101': 5.919892813539324, 'IoU-102': 5.527344195003927, 'IoU-103': 5.169601417850061, 'IoU-104': 5.458378838403615, 'IoU-105': 5.147843226868832, 'IoU-106': 4.777194333927944, 'IoU-107': 4.662477608556115, 'IoU-108': 5.554699518718592, 'IoU-109': 5.1935429517170135, 'IoU-110': 4.241469835222007, 'IoU-111': 4.947233199963998, 'IoU-112': 4.519444543543178, 'IoU-113': 4.124864352494488, 'IoU-114': 5.379545560693988, 'IoU-115': 4.216797171628604, 'IoU-116': 4.690441233338937, 'IoU-117': 4.752226065323038, 'IoU-118': 3.8608689508015908, 'IoU-119': 3.5931370814378525, 'IoU-120': 3.9024861578020493, 'IoU-121': 5.273749319049416, 'IoU-122': 2.7896371660713024, 'IoU-123': 3.052517693409292, 'IoU-124': 4.967315589985874, 'IoU-125': 2.3593089021809104, 'IoU-126': 3.379719559076224, 'IoU-127': 3.82549896768512, 'IoU-128': 3.0393777219329445, 'IoU-129': 2.450198541861227, 'IoU-130': 2.9267233947498843, 'IoU-131': 1.739969497574819, 'IoU-132': 2.0561163105687332, 'IoU-133': 1.9144700799640244, 'IoU-134': 2.244817294654343, 'IoU-135': 3.228412287738247, 'IoU-136': 1.9097592686996672, 'IoU-137': 1.9015710796022691, 'IoU-138': 0.8868338141077088, 'IoU-139': 2.165622784374779, 'IoU-140': 3.025141067206865, 'IoU-141': 2.3863534769394223, 'IoU-142': 0.7775213772966718, 'IoU-143': 2.1562205122505596, 'IoU-144': 1.3917165734632453, 'IoU-145': 2.565181224651368, 'IoU-146': 1.3764763070193407, 'IoU-147': 2.796420303689853, 'IoU-148': 1.0627998920372168, 'IoU-149': 2.4321365415770213, 'IoU-150': 2.315470412581364, 'IoU-151': 1.057023325395261, 'IoU-152': 1.0723635083984928, 'IoU-153': 1.1344204733970356, 'IoU-154': 1.7781428874284504, 'IoU-155': 0.9039096358422837, 'IoU-156': 2.1001577327585763, 'IoU-157': 0.8952205571960813, 'IoU-158': 0.4400122583360859, 'IoU-159': 1.3277016010062581, 'IoU-160': 1.8606675706671394, 'IoU-161': 0.6014565544952285, 'IoU-162': 1.8128200293627272, 'IoU-163': 1.1990951121807558, 'IoU-164': 1.4963301692317983, 'IoU-165': 1.3694114106240698, 'IoU-166': 0.3407633286504316, 'IoU-167': 0.41025236437510476, 'IoU-168': 1.0001091417251669, 'IoU-169': 0.7699289642839446, 'IoU-170': 1.8730639665858302, 'IoU-171': 0.06789367779700846, 'IoU-172': 0.35547980356798137, 'IoU-173': 1.0589024122705375, 'IoU-174': 2.0145996898424663, 'IoU-175': 0.2121624864269524, 'IoU-176': 0.34602563941904035, 'IoU-177': 0.06202650191495905, 'IoU-178': 1.053824142723016, 'IoU-179': 0.7982421357565725, 'IoU-180': 0.8474368868360126, 'IoU-181': 1.7026148317756247, 'IoU-182': 1.103277703683003, 'IoU-183': 0.6327433782872791, 'IoU-184': 0.730477550110991, 'IoU-185': 0.6447455910476704, 'IoU-186': 0.4732966679584752, 'IoU-187': 0.9477848040734662, 'IoU-188': 1.5804583341661835, 'IoU-189': 2.6746778669876, 'IoU-190': 2.2086569243163523, 'IoU-191': 1.876985583264364, 'IoU-192': 3.4200444746157492, 'mACC': 15.71807016582226, 'pACC': 36.971993857437155, 'ACC-0': nan, 'ACC-1': 98.95709377397434, 'ACC-2': 13.373503822168578, 'ACC-3': 58.42690138208808, 'ACC-4': 39.719096678855955, 'ACC-5': 33.04810437422965, 'ACC-6': 31.981229207518663, 'ACC-7': 19.08397781594233, 'ACC-8': 8.664041653758133, 'ACC-9': 18.363034401472202, 'ACC-10': 38.91175029394125, 'ACC-11': 48.6346184277847, 'ACC-12': 62.16824368298796, 'ACC-13': 49.846035206830045, 'ACC-14': 45.15340990715269, 'ACC-15': 45.662599871224906, 'ACC-16': 46.182033621875625, 'ACC-17': 37.64025536988551, 'ACC-18': 40.67738377384863, 'ACC-19': 41.26029891985799, 'ACC-20': 35.26710318617694, 'ACC-21': 43.31289466245573, 'ACC-22': 40.77021015566217, 'ACC-23': 44.324892691147646, 'ACC-24': 32.192395059277054, 'ACC-25': 37.11481031658519, 'ACC-26': 34.01362503259532, 'ACC-27': 46.27822339738357, 'ACC-28': 27.82851223062651, 'ACC-29': 43.68858342868286, 'ACC-30': 41.40516546040398, 'ACC-31': 29.22102247397611, 'ACC-32': 27.260789614568125, 'ACC-33': 34.80455463549613, 'ACC-34': 35.66584607076937, 'ACC-35': 27.034569266439462, 'ACC-36': 35.03073097330039, 'ACC-37': 32.40115882652167, 'ACC-38': 28.82600071092955, 'ACC-39': 36.13132333811612, 'ACC-40': 30.627175739892685, 'ACC-41': 25.46685714899077, 'ACC-42': 25.539082011931807, 'ACC-43': 26.969094342553074, 'ACC-44': 22.92926712376307, 'ACC-45': 27.556443056390517, 'ACC-46': 26.006802455138985, 'ACC-47': 26.336104635754875, 'ACC-48': 23.47483776733595, 'ACC-49': 27.11616446712741, 'ACC-50': 23.424803577569307, 'ACC-51': 25.9679739571581, 'ACC-52': 23.848253537555895, 'ACC-53': 26.04276164441408, 'ACC-54': 26.06312660095255, 'ACC-55': 27.72265504201427, 'ACC-56': 19.708056250879707, 'ACC-57': 24.687501255307765, 'ACC-58': 25.212390770757608, 'ACC-59': 22.314447082914963, 'ACC-60': 27.019889380300448, 'ACC-61': 18.80635924612163, 'ACC-62': 22.18693634802944, 'ACC-63': 17.57786272608818, 'ACC-64': 17.716800006542343, 'ACC-65': 21.14143866595908, 'ACC-66': 16.0206779881367, 'ACC-67': 22.339513596063096, 'ACC-68': 15.28916976734578, 'ACC-69': 14.487642726610916, 'ACC-70': 18.933568973748432, 'ACC-71': 16.132613193509922, 'ACC-72': 11.092383426567135, 'ACC-73': 18.81677420666508, 'ACC-74': 13.74954835290008, 'ACC-75': 20.38208485168809, 'ACC-76': 14.38557562001204, 'ACC-77': 16.55857786945464, 'ACC-78': 10.905551366495162, 'ACC-79': 16.624436283133697, 'ACC-80': 12.615037700574053, 'ACC-81': 16.285798494654394, 'ACC-82': 12.200750271884111, 'ACC-83': 9.236223743831301, 'ACC-84': 11.488459867304266, 'ACC-85': 15.002629297315664, 'ACC-86': 10.687453419242528, 'ACC-87': 11.442376300420186, 'ACC-88': 12.984113761345203, 'ACC-89': 12.17272779339743, 'ACC-90': 12.558386013618714, 'ACC-91': 9.682666644168668, 'ACC-92': 9.595431089731967, 'ACC-93': 8.962286040580084, 'ACC-94': 11.474184468593922, 'ACC-95': 9.573187814989817, 'ACC-96': 15.816431632396977, 'ACC-97': 11.910483939865385, 'ACC-98': 11.35729191170059, 'ACC-99': 11.223712923487762, 'ACC-100': 12.230313985275073, 'ACC-101': 11.361811369549033, 'ACC-102': 9.728001812415044, 'ACC-103': 8.56297818078776, 'ACC-104': 10.596738889845305, 'ACC-105': 9.159247319215098, 'ACC-106': 8.825166767753926, 'ACC-107': 7.572157748391055, 'ACC-108': 9.942745839559565, 'ACC-109': 9.349736279967058, 'ACC-110': 7.0757615767219315, 'ACC-111': 9.474436683787332, 'ACC-112': 7.69285951183119, 'ACC-113': 7.2721030757307, 'ACC-114': 10.325958811179458, 'ACC-115': 8.38009111000857, 'ACC-116': 8.652299749564135, 'ACC-117': 9.121597457902947, 'ACC-118': 6.699172900667046, 'ACC-119': 5.879297647860617, 'ACC-120': 7.770392547535465, 'ACC-121': 11.670005863845239, 'ACC-122': 4.258446790644135, 'ACC-123': 5.514250921212863, 'ACC-124': 10.885242722687805, 'ACC-125': 4.57224186746693, 'ACC-126': 6.522714232370058, 'ACC-127': 7.21066685979684, 'ACC-128': 5.992016011884506, 'ACC-129': 4.260902796821455, 'ACC-130': 7.148587746973376, 'ACC-131': 2.3799887420391794, 'ACC-132': 3.4968315723510703, 'ACC-133': 2.9199071900494666, 'ACC-134': 3.3826798793623434, 'ACC-135': 6.923422267829656, 'ACC-136': 3.4334379658963847, 'ACC-137': 3.0015638630852752, 'ACC-138': 1.2270921643779984, 'ACC-139': 3.861437520547193, 'ACC-140': 9.017918225835574, 'ACC-141': 5.413548008126044, 'ACC-142': 1.0092912080666445, 'ACC-143': 4.445510772761542, 'ACC-144': 2.280234657039711, 'ACC-145': 6.74693083476822, 'ACC-146': 2.155582463274771, 'ACC-147': 7.314135877725089, 'ACC-148': 1.53081932339782, 'ACC-149': 4.789725668284876, 'ACC-150': 4.562392055942773, 'ACC-151': 1.8690523008516617, 'ACC-152': 1.3164660462607054, 'ACC-153': 1.679675333003536, 'ACC-154': 3.7029731103823447, 'ACC-155': 1.4131187709995736, 'ACC-156': 5.284311634250551, 'ACC-157': 1.226704122449924, 'ACC-158': 0.5207811434886127, 'ACC-159': 2.3030335680078937, 'ACC-160': 3.722910917070081, 'ACC-161': 0.8071287951763243, 'ACC-162': 8.91086310365039, 'ACC-163': 1.8522793109404787, 'ACC-164': 3.901426628065158, 'ACC-165': 2.803762066150616, 'ACC-166': 0.48702688636878727, 'ACC-167': 0.5058479989299369, 'ACC-168': 2.4650116041915746, 'ACC-169': 1.1996988908444217, 'ACC-170': 3.9735863253687693, 'ACC-171': 0.0709025750860107, 'ACC-172': 0.41949105456161795, 'ACC-173': 1.9343149465857394, 'ACC-174': 4.48217178241168, 'ACC-175': 0.2272227244910599, 'ACC-176': 0.40069218713721844, 'ACC-177': 0.06551398954359818, 'ACC-178': 1.3636951890147206, 'ACC-179': 0.9353170440735187, 'ACC-180': 1.0993430187273527, 'ACC-181': 3.959439197879582, 'ACC-182': 1.5619928498492024, 'ACC-183': 0.8529703284983438, 'ACC-184': 1.0438260730112237, 'ACC-185': 0.7233623879273312, 'ACC-186': 0.5420041405717011, 'ACC-187': 1.1971635318136242, 'ACC-188': 3.190700536701505, 'ACC-189': 4.53017937415441, 'ACC-190': 5.724870830145572, 'ACC-191': 3.190603588907015, 'ACC-192': 13.030780680927412})])
[01/19 14:09:00] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 14:09:00] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 14:09:00] d2.evaluation.testing INFO: copypaste: 2.8274,0.3143,0.1346,9.4127,25.9079,15.7181,36.9720
[01/19 14:09:00] d2.utils.events INFO:  eta: 6:34:14  iter: 25999  total_loss: 57.03  loss_ce: 1.661  loss_mask: 0.6061  loss_dice: 3.159  loss_ce_0: 2.883  loss_mask_0: 0.6208  loss_dice_0: 3.454  loss_ce_1: 1.964  loss_mask_1: 0.6094  loss_dice_1: 3.279  loss_ce_2: 1.823  loss_mask_2: 0.6095  loss_dice_2: 3.222  loss_ce_3: 1.754  loss_mask_3: 0.6009  loss_dice_3: 3.188  loss_ce_4: 1.696  loss_mask_4: 0.6013  loss_dice_4: 3.181  loss_ce_5: 1.67  loss_mask_5: 0.604  loss_dice_5: 3.176  loss_ce_6: 1.669  loss_mask_6: 0.6049  loss_dice_6: 3.167  loss_ce_7: 1.645  loss_mask_7: 0.6053  loss_dice_7: 3.164  loss_ce_8: 1.651  loss_mask_8: 0.6057  loss_dice_8: 3.161  time: 1.6942  data_time: 0.3378  lr: 3.8877e-06  max_mem: 17674M
[01/19 14:09:34] d2.utils.events INFO:  eta: 6:33:37  iter: 26019  total_loss: 56.82  loss_ce: 1.675  loss_mask: 0.6302  loss_dice: 3.119  loss_ce_0: 2.908  loss_mask_0: 0.6521  loss_dice_0: 3.435  loss_ce_1: 1.983  loss_mask_1: 0.642  loss_dice_1: 3.272  loss_ce_2: 1.858  loss_mask_2: 0.6355  loss_dice_2: 3.206  loss_ce_3: 1.788  loss_mask_3: 0.6337  loss_dice_3: 3.162  loss_ce_4: 1.723  loss_mask_4: 0.6335  loss_dice_4: 3.154  loss_ce_5: 1.713  loss_mask_5: 0.6334  loss_dice_5: 3.154  loss_ce_6: 1.715  loss_mask_6: 0.6302  loss_dice_6: 3.13  loss_ce_7: 1.675  loss_mask_7: 0.6305  loss_dice_7: 3.133  loss_ce_8: 1.674  loss_mask_8: 0.6296  loss_dice_8: 3.124  time: 1.6942  data_time: 0.3486  lr: 3.8827e-06  max_mem: 17674M
[01/19 14:10:09] d2.utils.events INFO:  eta: 6:33:04  iter: 26039  total_loss: 56.71  loss_ce: 1.672  loss_mask: 0.6192  loss_dice: 3.169  loss_ce_0: 2.834  loss_mask_0: 0.6467  loss_dice_0: 3.456  loss_ce_1: 1.941  loss_mask_1: 0.629  loss_dice_1: 3.286  loss_ce_2: 1.79  loss_mask_2: 0.6246  loss_dice_2: 3.234  loss_ce_3: 1.751  loss_mask_3: 0.6212  loss_dice_3: 3.193  loss_ce_4: 1.711  loss_mask_4: 0.6218  loss_dice_4: 3.178  loss_ce_5: 1.689  loss_mask_5: 0.6194  loss_dice_5: 3.18  loss_ce_6: 1.693  loss_mask_6: 0.6191  loss_dice_6: 3.17  loss_ce_7: 1.664  loss_mask_7: 0.6179  loss_dice_7: 3.167  loss_ce_8: 1.66  loss_mask_8: 0.6193  loss_dice_8: 3.168  time: 1.6943  data_time: 0.3658  lr: 3.8777e-06  max_mem: 17674M
[01/19 14:10:42] d2.utils.events INFO:  eta: 6:32:20  iter: 26059  total_loss: 57.02  loss_ce: 1.715  loss_mask: 0.6217  loss_dice: 3.156  loss_ce_0: 2.893  loss_mask_0: 0.6413  loss_dice_0: 3.475  loss_ce_1: 1.957  loss_mask_1: 0.6285  loss_dice_1: 3.314  loss_ce_2: 1.836  loss_mask_2: 0.6281  loss_dice_2: 3.248  loss_ce_3: 1.783  loss_mask_3: 0.6231  loss_dice_3: 3.194  loss_ce_4: 1.735  loss_mask_4: 0.624  loss_dice_4: 3.191  loss_ce_5: 1.714  loss_mask_5: 0.6226  loss_dice_5: 3.189  loss_ce_6: 1.707  loss_mask_6: 0.6212  loss_dice_6: 3.171  loss_ce_7: 1.694  loss_mask_7: 0.6228  loss_dice_7: 3.161  loss_ce_8: 1.694  loss_mask_8: 0.6231  loss_dice_8: 3.16  time: 1.6942  data_time: 0.3312  lr: 3.8727e-06  max_mem: 17674M
[01/19 14:11:16] d2.utils.events INFO:  eta: 6:31:46  iter: 26079  total_loss: 56.23  loss_ce: 1.643  loss_mask: 0.6179  loss_dice: 3.157  loss_ce_0: 2.842  loss_mask_0: 0.6361  loss_dice_0: 3.446  loss_ce_1: 1.923  loss_mask_1: 0.6245  loss_dice_1: 3.291  loss_ce_2: 1.799  loss_mask_2: 0.6198  loss_dice_2: 3.224  loss_ce_3: 1.727  loss_mask_3: 0.6173  loss_dice_3: 3.174  loss_ce_4: 1.686  loss_mask_4: 0.618  loss_dice_4: 3.173  loss_ce_5: 1.679  loss_mask_5: 0.6176  loss_dice_5: 3.172  loss_ce_6: 1.663  loss_mask_6: 0.6173  loss_dice_6: 3.158  loss_ce_7: 1.654  loss_mask_7: 0.6196  loss_dice_7: 3.16  loss_ce_8: 1.635  loss_mask_8: 0.6207  loss_dice_8: 3.159  time: 1.6943  data_time: 0.3470  lr: 3.8677e-06  max_mem: 17674M
[01/19 14:11:51] d2.utils.events INFO:  eta: 6:31:22  iter: 26099  total_loss: 56.03  loss_ce: 1.602  loss_mask: 0.6133  loss_dice: 3.19  loss_ce_0: 2.775  loss_mask_0: 0.6328  loss_dice_0: 3.468  loss_ce_1: 1.849  loss_mask_1: 0.6202  loss_dice_1: 3.311  loss_ce_2: 1.76  loss_mask_2: 0.6206  loss_dice_2: 3.251  loss_ce_3: 1.683  loss_mask_3: 0.617  loss_dice_3: 3.209  loss_ce_4: 1.637  loss_mask_4: 0.615  loss_dice_4: 3.208  loss_ce_5: 1.622  loss_mask_5: 0.6141  loss_dice_5: 3.204  loss_ce_6: 1.59  loss_mask_6: 0.6132  loss_dice_6: 3.197  loss_ce_7: 1.582  loss_mask_7: 0.6126  loss_dice_7: 3.19  loss_ce_8: 1.581  loss_mask_8: 0.6131  loss_dice_8: 3.192  time: 1.6943  data_time: 0.3441  lr: 3.8627e-06  max_mem: 17674M
[01/19 14:12:25] d2.utils.events INFO:  eta: 6:30:55  iter: 26119  total_loss: 56.59  loss_ce: 1.681  loss_mask: 0.6116  loss_dice: 3.131  loss_ce_0: 2.834  loss_mask_0: 0.6336  loss_dice_0: 3.443  loss_ce_1: 1.95  loss_mask_1: 0.6169  loss_dice_1: 3.288  loss_ce_2: 1.861  loss_mask_2: 0.6129  loss_dice_2: 3.226  loss_ce_3: 1.785  loss_mask_3: 0.614  loss_dice_3: 3.158  loss_ce_4: 1.738  loss_mask_4: 0.6144  loss_dice_4: 3.15  loss_ce_5: 1.704  loss_mask_5: 0.6159  loss_dice_5: 3.147  loss_ce_6: 1.716  loss_mask_6: 0.6136  loss_dice_6: 3.133  loss_ce_7: 1.692  loss_mask_7: 0.6142  loss_dice_7: 3.133  loss_ce_8: 1.681  loss_mask_8: 0.6142  loss_dice_8: 3.134  time: 1.6943  data_time: 0.3419  lr: 3.8577e-06  max_mem: 17674M
[01/19 14:12:58] d2.utils.events INFO:  eta: 6:30:15  iter: 26139  total_loss: 57.19  loss_ce: 1.705  loss_mask: 0.6112  loss_dice: 3.136  loss_ce_0: 2.963  loss_mask_0: 0.6384  loss_dice_0: 3.451  loss_ce_1: 1.967  loss_mask_1: 0.6185  loss_dice_1: 3.283  loss_ce_2: 1.834  loss_mask_2: 0.6124  loss_dice_2: 3.211  loss_ce_3: 1.787  loss_mask_3: 0.612  loss_dice_3: 3.164  loss_ce_4: 1.742  loss_mask_4: 0.6121  loss_dice_4: 3.157  loss_ce_5: 1.706  loss_mask_5: 0.6096  loss_dice_5: 3.153  loss_ce_6: 1.715  loss_mask_6: 0.6101  loss_dice_6: 3.138  loss_ce_7: 1.694  loss_mask_7: 0.6097  loss_dice_7: 3.139  loss_ce_8: 1.709  loss_mask_8: 0.6106  loss_dice_8: 3.141  time: 1.6943  data_time: 0.2974  lr: 3.8527e-06  max_mem: 17674M
[01/19 14:13:32] d2.utils.events INFO:  eta: 6:29:37  iter: 26159  total_loss: 55.2  loss_ce: 1.598  loss_mask: 0.6163  loss_dice: 3.111  loss_ce_0: 2.795  loss_mask_0: 0.6385  loss_dice_0: 3.437  loss_ce_1: 1.85  loss_mask_1: 0.6264  loss_dice_1: 3.245  loss_ce_2: 1.731  loss_mask_2: 0.6184  loss_dice_2: 3.185  loss_ce_3: 1.692  loss_mask_3: 0.6148  loss_dice_3: 3.143  loss_ce_4: 1.636  loss_mask_4: 0.6146  loss_dice_4: 3.137  loss_ce_5: 1.607  loss_mask_5: 0.6153  loss_dice_5: 3.135  loss_ce_6: 1.603  loss_mask_6: 0.6169  loss_dice_6: 3.124  loss_ce_7: 1.613  loss_mask_7: 0.6166  loss_dice_7: 3.119  loss_ce_8: 1.601  loss_mask_8: 0.617  loss_dice_8: 3.121  time: 1.6943  data_time: 0.3290  lr: 3.8477e-06  max_mem: 17674M
[01/19 14:14:06] d2.utils.events INFO:  eta: 6:29:06  iter: 26179  total_loss: 56.2  loss_ce: 1.659  loss_mask: 0.6113  loss_dice: 3.144  loss_ce_0: 2.83  loss_mask_0: 0.6386  loss_dice_0: 3.438  loss_ce_1: 1.914  loss_mask_1: 0.6203  loss_dice_1: 3.265  loss_ce_2: 1.779  loss_mask_2: 0.6171  loss_dice_2: 3.204  loss_ce_3: 1.715  loss_mask_3: 0.6141  loss_dice_3: 3.163  loss_ce_4: 1.687  loss_mask_4: 0.6147  loss_dice_4: 3.155  loss_ce_5: 1.653  loss_mask_5: 0.6128  loss_dice_5: 3.155  loss_ce_6: 1.663  loss_mask_6: 0.6078  loss_dice_6: 3.146  loss_ce_7: 1.649  loss_mask_7: 0.6094  loss_dice_7: 3.151  loss_ce_8: 1.634  loss_mask_8: 0.6107  loss_dice_8: 3.147  time: 1.6943  data_time: 0.3182  lr: 3.8427e-06  max_mem: 17674M
[01/19 14:14:40] d2.utils.events INFO:  eta: 6:28:32  iter: 26199  total_loss: 56.73  loss_ce: 1.656  loss_mask: 0.6194  loss_dice: 3.182  loss_ce_0: 2.889  loss_mask_0: 0.6427  loss_dice_0: 3.485  loss_ce_1: 1.909  loss_mask_1: 0.6237  loss_dice_1: 3.313  loss_ce_2: 1.751  loss_mask_2: 0.6202  loss_dice_2: 3.252  loss_ce_3: 1.715  loss_mask_3: 0.621  loss_dice_3: 3.207  loss_ce_4: 1.68  loss_mask_4: 0.6211  loss_dice_4: 3.203  loss_ce_5: 1.655  loss_mask_5: 0.6217  loss_dice_5: 3.199  loss_ce_6: 1.673  loss_mask_6: 0.6225  loss_dice_6: 3.185  loss_ce_7: 1.653  loss_mask_7: 0.6203  loss_dice_7: 3.183  loss_ce_8: 1.636  loss_mask_8: 0.6202  loss_dice_8: 3.184  time: 1.6943  data_time: 0.3240  lr: 3.8377e-06  max_mem: 17674M
[01/19 14:15:14] d2.utils.events INFO:  eta: 6:27:50  iter: 26219  total_loss: 56.76  loss_ce: 1.645  loss_mask: 0.6322  loss_dice: 3.168  loss_ce_0: 2.891  loss_mask_0: 0.6609  loss_dice_0: 3.462  loss_ce_1: 1.943  loss_mask_1: 0.641  loss_dice_1: 3.303  loss_ce_2: 1.828  loss_mask_2: 0.6369  loss_dice_2: 3.226  loss_ce_3: 1.734  loss_mask_3: 0.634  loss_dice_3: 3.182  loss_ce_4: 1.702  loss_mask_4: 0.6305  loss_dice_4: 3.183  loss_ce_5: 1.668  loss_mask_5: 0.6306  loss_dice_5: 3.181  loss_ce_6: 1.661  loss_mask_6: 0.6313  loss_dice_6: 3.169  loss_ce_7: 1.641  loss_mask_7: 0.6299  loss_dice_7: 3.168  loss_ce_8: 1.636  loss_mask_8: 0.6306  loss_dice_8: 3.161  time: 1.6943  data_time: 0.3210  lr: 3.8326e-06  max_mem: 17674M
[01/19 14:15:48] d2.utils.events INFO:  eta: 6:27:08  iter: 26239  total_loss: 56.96  loss_ce: 1.667  loss_mask: 0.6298  loss_dice: 3.147  loss_ce_0: 2.833  loss_mask_0: 0.6509  loss_dice_0: 3.458  loss_ce_1: 1.966  loss_mask_1: 0.6372  loss_dice_1: 3.264  loss_ce_2: 1.824  loss_mask_2: 0.6317  loss_dice_2: 3.208  loss_ce_3: 1.781  loss_mask_3: 0.6279  loss_dice_3: 3.174  loss_ce_4: 1.726  loss_mask_4: 0.6291  loss_dice_4: 3.171  loss_ce_5: 1.691  loss_mask_5: 0.6273  loss_dice_5: 3.164  loss_ce_6: 1.698  loss_mask_6: 0.627  loss_dice_6: 3.151  loss_ce_7: 1.681  loss_mask_7: 0.6285  loss_dice_7: 3.153  loss_ce_8: 1.667  loss_mask_8: 0.6291  loss_dice_8: 3.153  time: 1.6942  data_time: 0.3162  lr: 3.8276e-06  max_mem: 17674M
[01/19 14:16:22] d2.utils.events INFO:  eta: 6:26:42  iter: 26259  total_loss: 56.49  loss_ce: 1.644  loss_mask: 0.6166  loss_dice: 3.145  loss_ce_0: 2.78  loss_mask_0: 0.6336  loss_dice_0: 3.452  loss_ce_1: 1.904  loss_mask_1: 0.6147  loss_dice_1: 3.279  loss_ce_2: 1.796  loss_mask_2: 0.6196  loss_dice_2: 3.215  loss_ce_3: 1.74  loss_mask_3: 0.6161  loss_dice_3: 3.172  loss_ce_4: 1.676  loss_mask_4: 0.6145  loss_dice_4: 3.165  loss_ce_5: 1.651  loss_mask_5: 0.6142  loss_dice_5: 3.163  loss_ce_6: 1.668  loss_mask_6: 0.6143  loss_dice_6: 3.153  loss_ce_7: 1.638  loss_mask_7: 0.6162  loss_dice_7: 3.146  loss_ce_8: 1.631  loss_mask_8: 0.6176  loss_dice_8: 3.147  time: 1.6943  data_time: 0.3226  lr: 3.8226e-06  max_mem: 17674M
[01/19 14:16:55] d2.utils.events INFO:  eta: 6:26:10  iter: 26279  total_loss: 56.4  loss_ce: 1.673  loss_mask: 0.6302  loss_dice: 3.104  loss_ce_0: 2.82  loss_mask_0: 0.6601  loss_dice_0: 3.422  loss_ce_1: 1.972  loss_mask_1: 0.6434  loss_dice_1: 3.249  loss_ce_2: 1.812  loss_mask_2: 0.6332  loss_dice_2: 3.181  loss_ce_3: 1.763  loss_mask_3: 0.6286  loss_dice_3: 3.135  loss_ce_4: 1.73  loss_mask_4: 0.6342  loss_dice_4: 3.135  loss_ce_5: 1.69  loss_mask_5: 0.633  loss_dice_5: 3.124  loss_ce_6: 1.676  loss_mask_6: 0.634  loss_dice_6: 3.101  loss_ce_7: 1.672  loss_mask_7: 0.6306  loss_dice_7: 3.11  loss_ce_8: 1.668  loss_mask_8: 0.6314  loss_dice_8: 3.109  time: 1.6942  data_time: 0.3178  lr: 3.8176e-06  max_mem: 17674M
[01/19 14:17:30] d2.utils.events INFO:  eta: 6:25:36  iter: 26299  total_loss: 56.62  loss_ce: 1.673  loss_mask: 0.6095  loss_dice: 3.176  loss_ce_0: 2.811  loss_mask_0: 0.6355  loss_dice_0: 3.481  loss_ce_1: 1.859  loss_mask_1: 0.6139  loss_dice_1: 3.307  loss_ce_2: 1.765  loss_mask_2: 0.6125  loss_dice_2: 3.24  loss_ce_3: 1.739  loss_mask_3: 0.6096  loss_dice_3: 3.204  loss_ce_4: 1.711  loss_mask_4: 0.612  loss_dice_4: 3.194  loss_ce_5: 1.695  loss_mask_5: 0.6082  loss_dice_5: 3.188  loss_ce_6: 1.687  loss_mask_6: 0.61  loss_dice_6: 3.18  loss_ce_7: 1.663  loss_mask_7: 0.6124  loss_dice_7: 3.178  loss_ce_8: 1.673  loss_mask_8: 0.6097  loss_dice_8: 3.176  time: 1.6943  data_time: 0.3318  lr: 3.8126e-06  max_mem: 17674M
[01/19 14:18:04] d2.utils.events INFO:  eta: 6:25:01  iter: 26319  total_loss: 56.15  loss_ce: 1.633  loss_mask: 0.6222  loss_dice: 3.127  loss_ce_0: 2.811  loss_mask_0: 0.6514  loss_dice_0: 3.461  loss_ce_1: 1.892  loss_mask_1: 0.6299  loss_dice_1: 3.277  loss_ce_2: 1.787  loss_mask_2: 0.6323  loss_dice_2: 3.215  loss_ce_3: 1.7  loss_mask_3: 0.6265  loss_dice_3: 3.16  loss_ce_4: 1.689  loss_mask_4: 0.6214  loss_dice_4: 3.154  loss_ce_5: 1.665  loss_mask_5: 0.6249  loss_dice_5: 3.151  loss_ce_6: 1.646  loss_mask_6: 0.6241  loss_dice_6: 3.137  loss_ce_7: 1.638  loss_mask_7: 0.6236  loss_dice_7: 3.133  loss_ce_8: 1.645  loss_mask_8: 0.6239  loss_dice_8: 3.133  time: 1.6943  data_time: 0.3592  lr: 3.8076e-06  max_mem: 17674M
[01/19 14:18:38] d2.utils.events INFO:  eta: 6:24:02  iter: 26339  total_loss: 56.49  loss_ce: 1.632  loss_mask: 0.6324  loss_dice: 3.117  loss_ce_0: 2.796  loss_mask_0: 0.6544  loss_dice_0: 3.437  loss_ce_1: 1.881  loss_mask_1: 0.6386  loss_dice_1: 3.26  loss_ce_2: 1.774  loss_mask_2: 0.6329  loss_dice_2: 3.183  loss_ce_3: 1.714  loss_mask_3: 0.6273  loss_dice_3: 3.151  loss_ce_4: 1.686  loss_mask_4: 0.628  loss_dice_4: 3.139  loss_ce_5: 1.666  loss_mask_5: 0.6304  loss_dice_5: 3.14  loss_ce_6: 1.65  loss_mask_6: 0.629  loss_dice_6: 3.13  loss_ce_7: 1.64  loss_mask_7: 0.63  loss_dice_7: 3.127  loss_ce_8: 1.632  loss_mask_8: 0.6328  loss_dice_8: 3.121  time: 1.6943  data_time: 0.3162  lr: 3.8026e-06  max_mem: 17674M
[01/19 14:19:12] d2.utils.events INFO:  eta: 6:23:25  iter: 26359  total_loss: 56.4  loss_ce: 1.604  loss_mask: 0.6065  loss_dice: 3.147  loss_ce_0: 2.836  loss_mask_0: 0.6214  loss_dice_0: 3.452  loss_ce_1: 1.859  loss_mask_1: 0.6105  loss_dice_1: 3.297  loss_ce_2: 1.768  loss_mask_2: 0.6059  loss_dice_2: 3.223  loss_ce_3: 1.702  loss_mask_3: 0.6071  loss_dice_3: 3.173  loss_ce_4: 1.651  loss_mask_4: 0.61  loss_dice_4: 3.168  loss_ce_5: 1.63  loss_mask_5: 0.6079  loss_dice_5: 3.161  loss_ce_6: 1.64  loss_mask_6: 0.6063  loss_dice_6: 3.154  loss_ce_7: 1.624  loss_mask_7: 0.6038  loss_dice_7: 3.15  loss_ce_8: 1.621  loss_mask_8: 0.6058  loss_dice_8: 3.147  time: 1.6943  data_time: 0.3388  lr: 3.7976e-06  max_mem: 17674M
[01/19 14:19:46] d2.utils.events INFO:  eta: 6:22:51  iter: 26379  total_loss: 57.4  loss_ce: 1.674  loss_mask: 0.6201  loss_dice: 3.188  loss_ce_0: 2.965  loss_mask_0: 0.6468  loss_dice_0: 3.49  loss_ce_1: 1.897  loss_mask_1: 0.6319  loss_dice_1: 3.339  loss_ce_2: 1.793  loss_mask_2: 0.6265  loss_dice_2: 3.269  loss_ce_3: 1.749  loss_mask_3: 0.6232  loss_dice_3: 3.222  loss_ce_4: 1.713  loss_mask_4: 0.6217  loss_dice_4: 3.226  loss_ce_5: 1.681  loss_mask_5: 0.6238  loss_dice_5: 3.213  loss_ce_6: 1.681  loss_mask_6: 0.6236  loss_dice_6: 3.199  loss_ce_7: 1.651  loss_mask_7: 0.6222  loss_dice_7: 3.195  loss_ce_8: 1.674  loss_mask_8: 0.6203  loss_dice_8: 3.193  time: 1.6943  data_time: 0.3268  lr: 3.7926e-06  max_mem: 17674M
[01/19 14:20:19] d2.utils.events INFO:  eta: 6:22:15  iter: 26399  total_loss: 56.23  loss_ce: 1.641  loss_mask: 0.629  loss_dice: 3.15  loss_ce_0: 2.896  loss_mask_0: 0.6472  loss_dice_0: 3.455  loss_ce_1: 1.885  loss_mask_1: 0.6354  loss_dice_1: 3.285  loss_ce_2: 1.757  loss_mask_2: 0.6279  loss_dice_2: 3.221  loss_ce_3: 1.696  loss_mask_3: 0.6291  loss_dice_3: 3.169  loss_ce_4: 1.683  loss_mask_4: 0.6293  loss_dice_4: 3.165  loss_ce_5: 1.651  loss_mask_5: 0.6314  loss_dice_5: 3.167  loss_ce_6: 1.639  loss_mask_6: 0.6324  loss_dice_6: 3.154  loss_ce_7: 1.65  loss_mask_7: 0.6312  loss_dice_7: 3.151  loss_ce_8: 1.632  loss_mask_8: 0.6295  loss_dice_8: 3.154  time: 1.6942  data_time: 0.3244  lr: 3.7876e-06  max_mem: 17674M
[01/19 14:20:53] d2.utils.events INFO:  eta: 6:21:43  iter: 26419  total_loss: 55.88  loss_ce: 1.552  loss_mask: 0.6048  loss_dice: 3.13  loss_ce_0: 2.773  loss_mask_0: 0.6303  loss_dice_0: 3.441  loss_ce_1: 1.79  loss_mask_1: 0.6146  loss_dice_1: 3.276  loss_ce_2: 1.681  loss_mask_2: 0.6075  loss_dice_2: 3.204  loss_ce_3: 1.636  loss_mask_3: 0.6105  loss_dice_3: 3.158  loss_ce_4: 1.585  loss_mask_4: 0.6101  loss_dice_4: 3.152  loss_ce_5: 1.589  loss_mask_5: 0.6121  loss_dice_5: 3.151  loss_ce_6: 1.576  loss_mask_6: 0.6084  loss_dice_6: 3.134  loss_ce_7: 1.557  loss_mask_7: 0.6097  loss_dice_7: 3.132  loss_ce_8: 1.555  loss_mask_8: 0.609  loss_dice_8: 3.133  time: 1.6942  data_time: 0.3393  lr: 3.7825e-06  max_mem: 17674M
[01/19 14:21:27] d2.utils.events INFO:  eta: 6:21:24  iter: 26439  total_loss: 56.44  loss_ce: 1.632  loss_mask: 0.6272  loss_dice: 3.136  loss_ce_0: 2.838  loss_mask_0: 0.6493  loss_dice_0: 3.451  loss_ce_1: 1.904  loss_mask_1: 0.6332  loss_dice_1: 3.269  loss_ce_2: 1.783  loss_mask_2: 0.6257  loss_dice_2: 3.2  loss_ce_3: 1.73  loss_mask_3: 0.6239  loss_dice_3: 3.168  loss_ce_4: 1.681  loss_mask_4: 0.6255  loss_dice_4: 3.161  loss_ce_5: 1.65  loss_mask_5: 0.6292  loss_dice_5: 3.154  loss_ce_6: 1.657  loss_mask_6: 0.6236  loss_dice_6: 3.139  loss_ce_7: 1.632  loss_mask_7: 0.6252  loss_dice_7: 3.139  loss_ce_8: 1.633  loss_mask_8: 0.6256  loss_dice_8: 3.137  time: 1.6942  data_time: 0.3356  lr: 3.7775e-06  max_mem: 17674M
[01/19 14:22:01] d2.utils.events INFO:  eta: 6:20:57  iter: 26459  total_loss: 55.79  loss_ce: 1.568  loss_mask: 0.6149  loss_dice: 3.124  loss_ce_0: 2.796  loss_mask_0: 0.6271  loss_dice_0: 3.456  loss_ce_1: 1.862  loss_mask_1: 0.6228  loss_dice_1: 3.261  loss_ce_2: 1.716  loss_mask_2: 0.6231  loss_dice_2: 3.197  loss_ce_3: 1.666  loss_mask_3: 0.6165  loss_dice_3: 3.148  loss_ce_4: 1.624  loss_mask_4: 0.6148  loss_dice_4: 3.144  loss_ce_5: 1.602  loss_mask_5: 0.6163  loss_dice_5: 3.14  loss_ce_6: 1.603  loss_mask_6: 0.6119  loss_dice_6: 3.131  loss_ce_7: 1.581  loss_mask_7: 0.6148  loss_dice_7: 3.128  loss_ce_8: 1.596  loss_mask_8: 0.6129  loss_dice_8: 3.127  time: 1.6943  data_time: 0.3357  lr: 3.7725e-06  max_mem: 17674M
[01/19 14:22:35] d2.utils.events INFO:  eta: 6:20:17  iter: 26479  total_loss: 56.86  loss_ce: 1.682  loss_mask: 0.6067  loss_dice: 3.152  loss_ce_0: 2.858  loss_mask_0: 0.6125  loss_dice_0: 3.496  loss_ce_1: 1.89  loss_mask_1: 0.6025  loss_dice_1: 3.31  loss_ce_2: 1.789  loss_mask_2: 0.5988  loss_dice_2: 3.235  loss_ce_3: 1.762  loss_mask_3: 0.6001  loss_dice_3: 3.196  loss_ce_4: 1.711  loss_mask_4: 0.6016  loss_dice_4: 3.183  loss_ce_5: 1.694  loss_mask_5: 0.6027  loss_dice_5: 3.182  loss_ce_6: 1.686  loss_mask_6: 0.6044  loss_dice_6: 3.163  loss_ce_7: 1.676  loss_mask_7: 0.6052  loss_dice_7: 3.158  loss_ce_8: 1.666  loss_mask_8: 0.6062  loss_dice_8: 3.165  time: 1.6943  data_time: 0.3239  lr: 3.7675e-06  max_mem: 17674M
[01/19 14:23:09] d2.utils.events INFO:  eta: 6:19:53  iter: 26499  total_loss: 56.06  loss_ce: 1.629  loss_mask: 0.6169  loss_dice: 3.151  loss_ce_0: 2.825  loss_mask_0: 0.6341  loss_dice_0: 3.471  loss_ce_1: 1.856  loss_mask_1: 0.624  loss_dice_1: 3.285  loss_ce_2: 1.75  loss_mask_2: 0.6236  loss_dice_2: 3.226  loss_ce_3: 1.708  loss_mask_3: 0.6192  loss_dice_3: 3.179  loss_ce_4: 1.665  loss_mask_4: 0.6189  loss_dice_4: 3.172  loss_ce_5: 1.653  loss_mask_5: 0.6195  loss_dice_5: 3.171  loss_ce_6: 1.639  loss_mask_6: 0.6184  loss_dice_6: 3.156  loss_ce_7: 1.627  loss_mask_7: 0.6163  loss_dice_7: 3.149  loss_ce_8: 1.611  loss_mask_8: 0.6177  loss_dice_8: 3.148  time: 1.6943  data_time: 0.3508  lr: 3.7625e-06  max_mem: 17674M
[01/19 14:23:43] d2.utils.events INFO:  eta: 6:19:22  iter: 26519  total_loss: 56.38  loss_ce: 1.612  loss_mask: 0.6024  loss_dice: 3.152  loss_ce_0: 2.8  loss_mask_0: 0.6144  loss_dice_0: 3.468  loss_ce_1: 1.878  loss_mask_1: 0.6047  loss_dice_1: 3.297  loss_ce_2: 1.743  loss_mask_2: 0.6043  loss_dice_2: 3.244  loss_ce_3: 1.708  loss_mask_3: 0.6035  loss_dice_3: 3.185  loss_ce_4: 1.668  loss_mask_4: 0.6048  loss_dice_4: 3.174  loss_ce_5: 1.651  loss_mask_5: 0.6032  loss_dice_5: 3.178  loss_ce_6: 1.642  loss_mask_6: 0.6032  loss_dice_6: 3.16  loss_ce_7: 1.635  loss_mask_7: 0.603  loss_dice_7: 3.155  loss_ce_8: 1.62  loss_mask_8: 0.6022  loss_dice_8: 3.159  time: 1.6943  data_time: 0.3502  lr: 3.7575e-06  max_mem: 17674M
[01/19 14:24:17] d2.utils.events INFO:  eta: 6:18:44  iter: 26539  total_loss: 56.3  loss_ce: 1.648  loss_mask: 0.6106  loss_dice: 3.142  loss_ce_0: 2.805  loss_mask_0: 0.6361  loss_dice_0: 3.461  loss_ce_1: 1.927  loss_mask_1: 0.6149  loss_dice_1: 3.286  loss_ce_2: 1.8  loss_mask_2: 0.6091  loss_dice_2: 3.214  loss_ce_3: 1.736  loss_mask_3: 0.6069  loss_dice_3: 3.168  loss_ce_4: 1.7  loss_mask_4: 0.6094  loss_dice_4: 3.159  loss_ce_5: 1.672  loss_mask_5: 0.6104  loss_dice_5: 3.162  loss_ce_6: 1.672  loss_mask_6: 0.6106  loss_dice_6: 3.152  loss_ce_7: 1.655  loss_mask_7: 0.6108  loss_dice_7: 3.148  loss_ce_8: 1.661  loss_mask_8: 0.6125  loss_dice_8: 3.145  time: 1.6943  data_time: 0.3512  lr: 3.7525e-06  max_mem: 17674M
[01/19 14:24:51] d2.utils.events INFO:  eta: 6:18:19  iter: 26559  total_loss: 55.79  loss_ce: 1.593  loss_mask: 0.6106  loss_dice: 3.135  loss_ce_0: 2.846  loss_mask_0: 0.633  loss_dice_0: 3.437  loss_ce_1: 1.864  loss_mask_1: 0.6181  loss_dice_1: 3.262  loss_ce_2: 1.748  loss_mask_2: 0.6132  loss_dice_2: 3.199  loss_ce_3: 1.667  loss_mask_3: 0.6105  loss_dice_3: 3.154  loss_ce_4: 1.617  loss_mask_4: 0.6111  loss_dice_4: 3.151  loss_ce_5: 1.603  loss_mask_5: 0.6138  loss_dice_5: 3.148  loss_ce_6: 1.588  loss_mask_6: 0.6118  loss_dice_6: 3.136  loss_ce_7: 1.576  loss_mask_7: 0.6115  loss_dice_7: 3.139  loss_ce_8: 1.58  loss_mask_8: 0.6134  loss_dice_8: 3.141  time: 1.6943  data_time: 0.3425  lr: 3.7474e-06  max_mem: 17674M
[01/19 14:25:25] d2.utils.events INFO:  eta: 6:17:26  iter: 26579  total_loss: 56.28  loss_ce: 1.61  loss_mask: 0.6286  loss_dice: 3.113  loss_ce_0: 2.8  loss_mask_0: 0.6409  loss_dice_0: 3.438  loss_ce_1: 1.856  loss_mask_1: 0.6311  loss_dice_1: 3.263  loss_ce_2: 1.739  loss_mask_2: 0.6309  loss_dice_2: 3.19  loss_ce_3: 1.703  loss_mask_3: 0.6286  loss_dice_3: 3.135  loss_ce_4: 1.656  loss_mask_4: 0.6287  loss_dice_4: 3.138  loss_ce_5: 1.615  loss_mask_5: 0.6284  loss_dice_5: 3.134  loss_ce_6: 1.629  loss_mask_6: 0.6269  loss_dice_6: 3.122  loss_ce_7: 1.625  loss_mask_7: 0.629  loss_dice_7: 3.122  loss_ce_8: 1.61  loss_mask_8: 0.6299  loss_dice_8: 3.124  time: 1.6943  data_time: 0.3377  lr: 3.7424e-06  max_mem: 17674M
[01/19 14:25:59] d2.utils.events INFO:  eta: 6:16:56  iter: 26599  total_loss: 56.91  loss_ce: 1.639  loss_mask: 0.6282  loss_dice: 3.152  loss_ce_0: 2.83  loss_mask_0: 0.6484  loss_dice_0: 3.448  loss_ce_1: 1.914  loss_mask_1: 0.6289  loss_dice_1: 3.286  loss_ce_2: 1.798  loss_mask_2: 0.631  loss_dice_2: 3.223  loss_ce_3: 1.755  loss_mask_3: 0.627  loss_dice_3: 3.176  loss_ce_4: 1.696  loss_mask_4: 0.6276  loss_dice_4: 3.176  loss_ce_5: 1.659  loss_mask_5: 0.6263  loss_dice_5: 3.169  loss_ce_6: 1.642  loss_mask_6: 0.6247  loss_dice_6: 3.16  loss_ce_7: 1.632  loss_mask_7: 0.628  loss_dice_7: 3.156  loss_ce_8: 1.626  loss_mask_8: 0.629  loss_dice_8: 3.153  time: 1.6943  data_time: 0.3459  lr: 3.7374e-06  max_mem: 17674M
[01/19 14:26:33] d2.utils.events INFO:  eta: 6:16:18  iter: 26619  total_loss: 56.41  loss_ce: 1.626  loss_mask: 0.6126  loss_dice: 3.129  loss_ce_0: 2.829  loss_mask_0: 0.6349  loss_dice_0: 3.431  loss_ce_1: 1.895  loss_mask_1: 0.6228  loss_dice_1: 3.274  loss_ce_2: 1.794  loss_mask_2: 0.6167  loss_dice_2: 3.214  loss_ce_3: 1.721  loss_mask_3: 0.6105  loss_dice_3: 3.157  loss_ce_4: 1.708  loss_mask_4: 0.6102  loss_dice_4: 3.156  loss_ce_5: 1.641  loss_mask_5: 0.6106  loss_dice_5: 3.146  loss_ce_6: 1.647  loss_mask_6: 0.611  loss_dice_6: 3.136  loss_ce_7: 1.642  loss_mask_7: 0.6114  loss_dice_7: 3.132  loss_ce_8: 1.618  loss_mask_8: 0.6131  loss_dice_8: 3.125  time: 1.6943  data_time: 0.3549  lr: 3.7324e-06  max_mem: 17674M
[01/19 14:27:06] d2.utils.events INFO:  eta: 6:15:47  iter: 26639  total_loss: 56.51  loss_ce: 1.621  loss_mask: 0.6163  loss_dice: 3.179  loss_ce_0: 2.863  loss_mask_0: 0.6318  loss_dice_0: 3.466  loss_ce_1: 1.915  loss_mask_1: 0.6174  loss_dice_1: 3.314  loss_ce_2: 1.787  loss_mask_2: 0.6158  loss_dice_2: 3.244  loss_ce_3: 1.708  loss_mask_3: 0.6152  loss_dice_3: 3.203  loss_ce_4: 1.66  loss_mask_4: 0.6201  loss_dice_4: 3.198  loss_ce_5: 1.646  loss_mask_5: 0.6212  loss_dice_5: 3.194  loss_ce_6: 1.637  loss_mask_6: 0.6186  loss_dice_6: 3.18  loss_ce_7: 1.63  loss_mask_7: 0.6163  loss_dice_7: 3.179  loss_ce_8: 1.63  loss_mask_8: 0.6189  loss_dice_8: 3.178  time: 1.6942  data_time: 0.3323  lr: 3.7274e-06  max_mem: 17674M
[01/19 14:27:41] d2.utils.events INFO:  eta: 6:15:11  iter: 26659  total_loss: 56.03  loss_ce: 1.628  loss_mask: 0.606  loss_dice: 3.137  loss_ce_0: 2.805  loss_mask_0: 0.6375  loss_dice_0: 3.459  loss_ce_1: 1.877  loss_mask_1: 0.6151  loss_dice_1: 3.285  loss_ce_2: 1.772  loss_mask_2: 0.6171  loss_dice_2: 3.208  loss_ce_3: 1.724  loss_mask_3: 0.6064  loss_dice_3: 3.169  loss_ce_4: 1.663  loss_mask_4: 0.6074  loss_dice_4: 3.165  loss_ce_5: 1.64  loss_mask_5: 0.6084  loss_dice_5: 3.16  loss_ce_6: 1.634  loss_mask_6: 0.606  loss_dice_6: 3.142  loss_ce_7: 1.617  loss_mask_7: 0.6073  loss_dice_7: 3.144  loss_ce_8: 1.626  loss_mask_8: 0.6069  loss_dice_8: 3.136  time: 1.6943  data_time: 0.3582  lr: 3.7223e-06  max_mem: 17674M
[01/19 14:28:14] d2.utils.events INFO:  eta: 6:14:24  iter: 26679  total_loss: 56.87  loss_ce: 1.664  loss_mask: 0.6232  loss_dice: 3.169  loss_ce_0: 2.849  loss_mask_0: 0.6482  loss_dice_0: 3.47  loss_ce_1: 1.917  loss_mask_1: 0.6271  loss_dice_1: 3.313  loss_ce_2: 1.819  loss_mask_2: 0.6236  loss_dice_2: 3.239  loss_ce_3: 1.757  loss_mask_3: 0.6215  loss_dice_3: 3.2  loss_ce_4: 1.705  loss_mask_4: 0.6223  loss_dice_4: 3.194  loss_ce_5: 1.683  loss_mask_5: 0.6252  loss_dice_5: 3.195  loss_ce_6: 1.687  loss_mask_6: 0.6249  loss_dice_6: 3.172  loss_ce_7: 1.664  loss_mask_7: 0.625  loss_dice_7: 3.176  loss_ce_8: 1.678  loss_mask_8: 0.6228  loss_dice_8: 3.174  time: 1.6943  data_time: 0.3443  lr: 3.7173e-06  max_mem: 17674M
[01/19 14:28:48] d2.utils.events INFO:  eta: 6:13:50  iter: 26699  total_loss: 56.47  loss_ce: 1.647  loss_mask: 0.6224  loss_dice: 3.13  loss_ce_0: 2.824  loss_mask_0: 0.6479  loss_dice_0: 3.457  loss_ce_1: 1.894  loss_mask_1: 0.6307  loss_dice_1: 3.277  loss_ce_2: 1.786  loss_mask_2: 0.6264  loss_dice_2: 3.2  loss_ce_3: 1.723  loss_mask_3: 0.6233  loss_dice_3: 3.161  loss_ce_4: 1.683  loss_mask_4: 0.6226  loss_dice_4: 3.156  loss_ce_5: 1.666  loss_mask_5: 0.6255  loss_dice_5: 3.15  loss_ce_6: 1.652  loss_mask_6: 0.6225  loss_dice_6: 3.137  loss_ce_7: 1.645  loss_mask_7: 0.6235  loss_dice_7: 3.137  loss_ce_8: 1.634  loss_mask_8: 0.6219  loss_dice_8: 3.138  time: 1.6943  data_time: 0.3511  lr: 3.7123e-06  max_mem: 17674M
[01/19 14:29:22] d2.utils.events INFO:  eta: 6:13:29  iter: 26719  total_loss: 55.36  loss_ce: 1.604  loss_mask: 0.6244  loss_dice: 3.116  loss_ce_0: 2.763  loss_mask_0: 0.652  loss_dice_0: 3.44  loss_ce_1: 1.85  loss_mask_1: 0.6278  loss_dice_1: 3.241  loss_ce_2: 1.731  loss_mask_2: 0.6225  loss_dice_2: 3.179  loss_ce_3: 1.683  loss_mask_3: 0.622  loss_dice_3: 3.142  loss_ce_4: 1.646  loss_mask_4: 0.6223  loss_dice_4: 3.136  loss_ce_5: 1.624  loss_mask_5: 0.6227  loss_dice_5: 3.137  loss_ce_6: 1.626  loss_mask_6: 0.6255  loss_dice_6: 3.124  loss_ce_7: 1.618  loss_mask_7: 0.6256  loss_dice_7: 3.118  loss_ce_8: 1.61  loss_mask_8: 0.6253  loss_dice_8: 3.119  time: 1.6942  data_time: 0.3237  lr: 3.7073e-06  max_mem: 17674M
[01/19 14:29:56] d2.utils.events INFO:  eta: 6:13:10  iter: 26739  total_loss: 57.79  loss_ce: 1.698  loss_mask: 0.611  loss_dice: 3.174  loss_ce_0: 2.846  loss_mask_0: 0.6302  loss_dice_0: 3.492  loss_ce_1: 1.913  loss_mask_1: 0.6157  loss_dice_1: 3.324  loss_ce_2: 1.814  loss_mask_2: 0.6128  loss_dice_2: 3.247  loss_ce_3: 1.756  loss_mask_3: 0.6084  loss_dice_3: 3.198  loss_ce_4: 1.725  loss_mask_4: 0.6122  loss_dice_4: 3.193  loss_ce_5: 1.718  loss_mask_5: 0.6107  loss_dice_5: 3.19  loss_ce_6: 1.708  loss_mask_6: 0.6093  loss_dice_6: 3.178  loss_ce_7: 1.696  loss_mask_7: 0.6124  loss_dice_7: 3.18  loss_ce_8: 1.716  loss_mask_8: 0.6115  loss_dice_8: 3.18  time: 1.6943  data_time: 0.3621  lr: 3.7022e-06  max_mem: 17674M
[01/19 14:30:30] d2.utils.events INFO:  eta: 6:12:25  iter: 26759  total_loss: 56.25  loss_ce: 1.658  loss_mask: 0.6231  loss_dice: 3.144  loss_ce_0: 2.822  loss_mask_0: 0.6399  loss_dice_0: 3.453  loss_ce_1: 1.885  loss_mask_1: 0.6261  loss_dice_1: 3.293  loss_ce_2: 1.805  loss_mask_2: 0.6228  loss_dice_2: 3.22  loss_ce_3: 1.742  loss_mask_3: 0.623  loss_dice_3: 3.171  loss_ce_4: 1.714  loss_mask_4: 0.6214  loss_dice_4: 3.164  loss_ce_5: 1.679  loss_mask_5: 0.6233  loss_dice_5: 3.163  loss_ce_6: 1.673  loss_mask_6: 0.6235  loss_dice_6: 3.151  loss_ce_7: 1.66  loss_mask_7: 0.6238  loss_dice_7: 3.146  loss_ce_8: 1.654  loss_mask_8: 0.6245  loss_dice_8: 3.146  time: 1.6943  data_time: 0.3277  lr: 3.6972e-06  max_mem: 17674M
[01/19 14:31:04] d2.utils.events INFO:  eta: 6:11:59  iter: 26779  total_loss: 55.74  loss_ce: 1.601  loss_mask: 0.6124  loss_dice: 3.131  loss_ce_0: 2.784  loss_mask_0: 0.6361  loss_dice_0: 3.443  loss_ce_1: 1.856  loss_mask_1: 0.6174  loss_dice_1: 3.272  loss_ce_2: 1.721  loss_mask_2: 0.6146  loss_dice_2: 3.199  loss_ce_3: 1.692  loss_mask_3: 0.6129  loss_dice_3: 3.161  loss_ce_4: 1.656  loss_mask_4: 0.6123  loss_dice_4: 3.152  loss_ce_5: 1.637  loss_mask_5: 0.6123  loss_dice_5: 3.151  loss_ce_6: 1.633  loss_mask_6: 0.6136  loss_dice_6: 3.137  loss_ce_7: 1.615  loss_mask_7: 0.6134  loss_dice_7: 3.132  loss_ce_8: 1.589  loss_mask_8: 0.6119  loss_dice_8: 3.137  time: 1.6943  data_time: 0.3407  lr: 3.6922e-06  max_mem: 17674M
[01/19 14:31:38] d2.utils.events INFO:  eta: 6:11:27  iter: 26799  total_loss: 54.98  loss_ce: 1.55  loss_mask: 0.6152  loss_dice: 3.102  loss_ce_0: 2.728  loss_mask_0: 0.6343  loss_dice_0: 3.422  loss_ce_1: 1.82  loss_mask_1: 0.6215  loss_dice_1: 3.232  loss_ce_2: 1.686  loss_mask_2: 0.6218  loss_dice_2: 3.169  loss_ce_3: 1.622  loss_mask_3: 0.6128  loss_dice_3: 3.126  loss_ce_4: 1.569  loss_mask_4: 0.614  loss_dice_4: 3.125  loss_ce_5: 1.559  loss_mask_5: 0.6156  loss_dice_5: 3.12  loss_ce_6: 1.553  loss_mask_6: 0.6149  loss_dice_6: 3.106  loss_ce_7: 1.536  loss_mask_7: 0.6147  loss_dice_7: 3.106  loss_ce_8: 1.532  loss_mask_8: 0.6158  loss_dice_8: 3.104  time: 1.6943  data_time: 0.3560  lr: 3.6872e-06  max_mem: 17674M
[01/19 14:32:12] d2.utils.events INFO:  eta: 6:10:51  iter: 26819  total_loss: 55.51  loss_ce: 1.56  loss_mask: 0.6191  loss_dice: 3.1  loss_ce_0: 2.767  loss_mask_0: 0.6467  loss_dice_0: 3.405  loss_ce_1: 1.853  loss_mask_1: 0.6275  loss_dice_1: 3.233  loss_ce_2: 1.718  loss_mask_2: 0.6247  loss_dice_2: 3.169  loss_ce_3: 1.673  loss_mask_3: 0.6206  loss_dice_3: 3.125  loss_ce_4: 1.627  loss_mask_4: 0.6225  loss_dice_4: 3.118  loss_ce_5: 1.6  loss_mask_5: 0.6211  loss_dice_5: 3.124  loss_ce_6: 1.597  loss_mask_6: 0.6199  loss_dice_6: 3.103  loss_ce_7: 1.569  loss_mask_7: 0.6202  loss_dice_7: 3.1  loss_ce_8: 1.564  loss_mask_8: 0.6205  loss_dice_8: 3.104  time: 1.6943  data_time: 0.3475  lr: 3.6821e-06  max_mem: 17674M
[01/19 14:32:46] d2.utils.events INFO:  eta: 6:10:20  iter: 26839  total_loss: 55.88  loss_ce: 1.591  loss_mask: 0.6223  loss_dice: 3.194  loss_ce_0: 2.829  loss_mask_0: 0.6482  loss_dice_0: 3.502  loss_ce_1: 1.85  loss_mask_1: 0.6345  loss_dice_1: 3.329  loss_ce_2: 1.742  loss_mask_2: 0.6278  loss_dice_2: 3.27  loss_ce_3: 1.698  loss_mask_3: 0.6229  loss_dice_3: 3.225  loss_ce_4: 1.651  loss_mask_4: 0.6256  loss_dice_4: 3.221  loss_ce_5: 1.619  loss_mask_5: 0.6256  loss_dice_5: 3.226  loss_ce_6: 1.625  loss_mask_6: 0.6239  loss_dice_6: 3.208  loss_ce_7: 1.604  loss_mask_7: 0.6212  loss_dice_7: 3.201  loss_ce_8: 1.6  loss_mask_8: 0.6216  loss_dice_8: 3.196  time: 1.6943  data_time: 0.3480  lr: 3.6771e-06  max_mem: 17674M
[01/19 14:33:20] d2.utils.events INFO:  eta: 6:09:51  iter: 26859  total_loss: 55.87  loss_ce: 1.622  loss_mask: 0.6145  loss_dice: 3.104  loss_ce_0: 2.84  loss_mask_0: 0.6324  loss_dice_0: 3.428  loss_ce_1: 1.885  loss_mask_1: 0.6232  loss_dice_1: 3.252  loss_ce_2: 1.746  loss_mask_2: 0.616  loss_dice_2: 3.184  loss_ce_3: 1.712  loss_mask_3: 0.6157  loss_dice_3: 3.139  loss_ce_4: 1.659  loss_mask_4: 0.618  loss_dice_4: 3.131  loss_ce_5: 1.634  loss_mask_5: 0.6155  loss_dice_5: 3.129  loss_ce_6: 1.618  loss_mask_6: 0.6163  loss_dice_6: 3.11  loss_ce_7: 1.603  loss_mask_7: 0.6157  loss_dice_7: 3.121  loss_ce_8: 1.608  loss_mask_8: 0.6159  loss_dice_8: 3.11  time: 1.6943  data_time: 0.3433  lr: 3.6721e-06  max_mem: 17674M
[01/19 14:33:54] d2.utils.events INFO:  eta: 6:09:10  iter: 26879  total_loss: 55.09  loss_ce: 1.598  loss_mask: 0.6277  loss_dice: 3.13  loss_ce_0: 2.803  loss_mask_0: 0.6438  loss_dice_0: 3.444  loss_ce_1: 1.875  loss_mask_1: 0.6246  loss_dice_1: 3.27  loss_ce_2: 1.732  loss_mask_2: 0.6236  loss_dice_2: 3.198  loss_ce_3: 1.672  loss_mask_3: 0.6206  loss_dice_3: 3.151  loss_ce_4: 1.624  loss_mask_4: 0.6239  loss_dice_4: 3.145  loss_ce_5: 1.603  loss_mask_5: 0.6247  loss_dice_5: 3.146  loss_ce_6: 1.6  loss_mask_6: 0.6264  loss_dice_6: 3.139  loss_ce_7: 1.587  loss_mask_7: 0.626  loss_dice_7: 3.141  loss_ce_8: 1.592  loss_mask_8: 0.6267  loss_dice_8: 3.138  time: 1.6943  data_time: 0.3434  lr: 3.667e-06  max_mem: 17674M
[01/19 14:34:28] d2.utils.events INFO:  eta: 6:08:36  iter: 26899  total_loss: 55.87  loss_ce: 1.627  loss_mask: 0.6279  loss_dice: 3.102  loss_ce_0: 2.771  loss_mask_0: 0.6555  loss_dice_0: 3.434  loss_ce_1: 1.924  loss_mask_1: 0.6397  loss_dice_1: 3.234  loss_ce_2: 1.809  loss_mask_2: 0.6344  loss_dice_2: 3.166  loss_ce_3: 1.731  loss_mask_3: 0.6286  loss_dice_3: 3.126  loss_ce_4: 1.69  loss_mask_4: 0.6271  loss_dice_4: 3.123  loss_ce_5: 1.642  loss_mask_5: 0.6277  loss_dice_5: 3.115  loss_ce_6: 1.643  loss_mask_6: 0.6252  loss_dice_6: 3.11  loss_ce_7: 1.623  loss_mask_7: 0.6278  loss_dice_7: 3.108  loss_ce_8: 1.629  loss_mask_8: 0.6265  loss_dice_8: 3.104  time: 1.6943  data_time: 0.3331  lr: 3.662e-06  max_mem: 17674M
[01/19 14:35:02] d2.utils.events INFO:  eta: 6:08:02  iter: 26919  total_loss: 56.52  loss_ce: 1.623  loss_mask: 0.6217  loss_dice: 3.137  loss_ce_0: 2.874  loss_mask_0: 0.6366  loss_dice_0: 3.446  loss_ce_1: 1.898  loss_mask_1: 0.6232  loss_dice_1: 3.278  loss_ce_2: 1.768  loss_mask_2: 0.6206  loss_dice_2: 3.215  loss_ce_3: 1.72  loss_mask_3: 0.6186  loss_dice_3: 3.167  loss_ce_4: 1.667  loss_mask_4: 0.6203  loss_dice_4: 3.165  loss_ce_5: 1.653  loss_mask_5: 0.622  loss_dice_5: 3.153  loss_ce_6: 1.658  loss_mask_6: 0.6217  loss_dice_6: 3.141  loss_ce_7: 1.635  loss_mask_7: 0.6228  loss_dice_7: 3.15  loss_ce_8: 1.632  loss_mask_8: 0.622  loss_dice_8: 3.139  time: 1.6943  data_time: 0.3303  lr: 3.657e-06  max_mem: 17674M
[01/19 14:35:36] d2.utils.events INFO:  eta: 6:07:40  iter: 26939  total_loss: 56.29  loss_ce: 1.616  loss_mask: 0.6114  loss_dice: 3.162  loss_ce_0: 2.802  loss_mask_0: 0.6358  loss_dice_0: 3.476  loss_ce_1: 1.841  loss_mask_1: 0.6172  loss_dice_1: 3.297  loss_ce_2: 1.728  loss_mask_2: 0.6135  loss_dice_2: 3.223  loss_ce_3: 1.677  loss_mask_3: 0.6085  loss_dice_3: 3.191  loss_ce_4: 1.646  loss_mask_4: 0.6106  loss_dice_4: 3.183  loss_ce_5: 1.616  loss_mask_5: 0.6089  loss_dice_5: 3.182  loss_ce_6: 1.622  loss_mask_6: 0.6098  loss_dice_6: 3.166  loss_ce_7: 1.596  loss_mask_7: 0.6099  loss_dice_7: 3.164  loss_ce_8: 1.595  loss_mask_8: 0.6117  loss_dice_8: 3.165  time: 1.6943  data_time: 0.3470  lr: 3.6519e-06  max_mem: 17674M
[01/19 14:36:10] d2.utils.events INFO:  eta: 6:07:22  iter: 26959  total_loss: 55.86  loss_ce: 1.556  loss_mask: 0.6087  loss_dice: 3.166  loss_ce_0: 2.824  loss_mask_0: 0.6275  loss_dice_0: 3.458  loss_ce_1: 1.825  loss_mask_1: 0.619  loss_dice_1: 3.283  loss_ce_2: 1.696  loss_mask_2: 0.6131  loss_dice_2: 3.225  loss_ce_3: 1.662  loss_mask_3: 0.6124  loss_dice_3: 3.193  loss_ce_4: 1.596  loss_mask_4: 0.6149  loss_dice_4: 3.178  loss_ce_5: 1.581  loss_mask_5: 0.6128  loss_dice_5: 3.184  loss_ce_6: 1.569  loss_mask_6: 0.6117  loss_dice_6: 3.167  loss_ce_7: 1.563  loss_mask_7: 0.6119  loss_dice_7: 3.176  loss_ce_8: 1.569  loss_mask_8: 0.6124  loss_dice_8: 3.168  time: 1.6943  data_time: 0.3446  lr: 3.6469e-06  max_mem: 17674M
[01/19 14:36:44] d2.utils.events INFO:  eta: 6:06:42  iter: 26979  total_loss: 56.16  loss_ce: 1.603  loss_mask: 0.6139  loss_dice: 3.146  loss_ce_0: 2.81  loss_mask_0: 0.6343  loss_dice_0: 3.47  loss_ce_1: 1.848  loss_mask_1: 0.6187  loss_dice_1: 3.295  loss_ce_2: 1.77  loss_mask_2: 0.6188  loss_dice_2: 3.217  loss_ce_3: 1.696  loss_mask_3: 0.6134  loss_dice_3: 3.172  loss_ce_4: 1.658  loss_mask_4: 0.6127  loss_dice_4: 3.166  loss_ce_5: 1.626  loss_mask_5: 0.6139  loss_dice_5: 3.164  loss_ce_6: 1.617  loss_mask_6: 0.6122  loss_dice_6: 3.149  loss_ce_7: 1.616  loss_mask_7: 0.6138  loss_dice_7: 3.15  loss_ce_8: 1.6  loss_mask_8: 0.6146  loss_dice_8: 3.145  time: 1.6943  data_time: 0.3632  lr: 3.6419e-06  max_mem: 17674M
[01/19 14:37:18] d2.utils.events INFO:  eta: 6:06:14  iter: 26999  total_loss: 56.82  loss_ce: 1.633  loss_mask: 0.6075  loss_dice: 3.184  loss_ce_0: 2.783  loss_mask_0: 0.6305  loss_dice_0: 3.504  loss_ce_1: 1.886  loss_mask_1: 0.616  loss_dice_1: 3.332  loss_ce_2: 1.778  loss_mask_2: 0.6123  loss_dice_2: 3.253  loss_ce_3: 1.708  loss_mask_3: 0.6099  loss_dice_3: 3.213  loss_ce_4: 1.656  loss_mask_4: 0.6084  loss_dice_4: 3.207  loss_ce_5: 1.649  loss_mask_5: 0.6098  loss_dice_5: 3.205  loss_ce_6: 1.636  loss_mask_6: 0.6098  loss_dice_6: 3.192  loss_ce_7: 1.631  loss_mask_7: 0.6079  loss_dice_7: 3.198  loss_ce_8: 1.632  loss_mask_8: 0.6074  loss_dice_8: 3.193  time: 1.6943  data_time: 0.3479  lr: 3.6368e-06  max_mem: 17674M
[01/19 14:37:52] d2.utils.events INFO:  eta: 6:05:43  iter: 27019  total_loss: 55.76  loss_ce: 1.6  loss_mask: 0.6259  loss_dice: 3.128  loss_ce_0: 2.762  loss_mask_0: 0.6443  loss_dice_0: 3.444  loss_ce_1: 1.85  loss_mask_1: 0.6318  loss_dice_1: 3.275  loss_ce_2: 1.753  loss_mask_2: 0.6292  loss_dice_2: 3.206  loss_ce_3: 1.696  loss_mask_3: 0.6264  loss_dice_3: 3.159  loss_ce_4: 1.644  loss_mask_4: 0.6307  loss_dice_4: 3.148  loss_ce_5: 1.62  loss_mask_5: 0.6282  loss_dice_5: 3.151  loss_ce_6: 1.625  loss_mask_6: 0.6266  loss_dice_6: 3.135  loss_ce_7: 1.605  loss_mask_7: 0.6263  loss_dice_7: 3.135  loss_ce_8: 1.601  loss_mask_8: 0.6267  loss_dice_8: 3.133  time: 1.6943  data_time: 0.3213  lr: 3.6318e-06  max_mem: 17674M
[01/19 14:38:26] d2.utils.events INFO:  eta: 6:05:06  iter: 27039  total_loss: 55.68  loss_ce: 1.643  loss_mask: 0.6186  loss_dice: 3.134  loss_ce_0: 2.777  loss_mask_0: 0.6402  loss_dice_0: 3.456  loss_ce_1: 1.871  loss_mask_1: 0.626  loss_dice_1: 3.267  loss_ce_2: 1.745  loss_mask_2: 0.6235  loss_dice_2: 3.206  loss_ce_3: 1.709  loss_mask_3: 0.6181  loss_dice_3: 3.161  loss_ce_4: 1.678  loss_mask_4: 0.6173  loss_dice_4: 3.153  loss_ce_5: 1.648  loss_mask_5: 0.621  loss_dice_5: 3.156  loss_ce_6: 1.644  loss_mask_6: 0.6225  loss_dice_6: 3.138  loss_ce_7: 1.635  loss_mask_7: 0.6209  loss_dice_7: 3.136  loss_ce_8: 1.641  loss_mask_8: 0.622  loss_dice_8: 3.139  time: 1.6943  data_time: 0.3455  lr: 3.6268e-06  max_mem: 17674M
[01/19 14:39:00] d2.utils.events INFO:  eta: 6:04:41  iter: 27059  total_loss: 55.68  loss_ce: 1.633  loss_mask: 0.6222  loss_dice: 3.11  loss_ce_0: 2.818  loss_mask_0: 0.6295  loss_dice_0: 3.421  loss_ce_1: 1.878  loss_mask_1: 0.6199  loss_dice_1: 3.237  loss_ce_2: 1.771  loss_mask_2: 0.6147  loss_dice_2: 3.172  loss_ce_3: 1.719  loss_mask_3: 0.6161  loss_dice_3: 3.127  loss_ce_4: 1.666  loss_mask_4: 0.6195  loss_dice_4: 3.126  loss_ce_5: 1.633  loss_mask_5: 0.6229  loss_dice_5: 3.134  loss_ce_6: 1.643  loss_mask_6: 0.6205  loss_dice_6: 3.115  loss_ce_7: 1.612  loss_mask_7: 0.6212  loss_dice_7: 3.108  loss_ce_8: 1.62  loss_mask_8: 0.6202  loss_dice_8: 3.108  time: 1.6943  data_time: 0.3381  lr: 3.6217e-06  max_mem: 17674M
[01/19 14:39:34] d2.utils.events INFO:  eta: 6:04:03  iter: 27079  total_loss: 55.24  loss_ce: 1.533  loss_mask: 0.6094  loss_dice: 3.125  loss_ce_0: 2.795  loss_mask_0: 0.6345  loss_dice_0: 3.437  loss_ce_1: 1.791  loss_mask_1: 0.62  loss_dice_1: 3.266  loss_ce_2: 1.653  loss_mask_2: 0.6161  loss_dice_2: 3.203  loss_ce_3: 1.612  loss_mask_3: 0.6107  loss_dice_3: 3.152  loss_ce_4: 1.569  loss_mask_4: 0.6114  loss_dice_4: 3.145  loss_ce_5: 1.541  loss_mask_5: 0.6117  loss_dice_5: 3.148  loss_ce_6: 1.535  loss_mask_6: 0.6105  loss_dice_6: 3.127  loss_ce_7: 1.53  loss_mask_7: 0.6088  loss_dice_7: 3.124  loss_ce_8: 1.516  loss_mask_8: 0.6093  loss_dice_8: 3.128  time: 1.6943  data_time: 0.3398  lr: 3.6167e-06  max_mem: 17674M
[01/19 14:40:08] d2.utils.events INFO:  eta: 6:03:11  iter: 27099  total_loss: 56  loss_ce: 1.681  loss_mask: 0.6231  loss_dice: 3.088  loss_ce_0: 2.804  loss_mask_0: 0.6499  loss_dice_0: 3.419  loss_ce_1: 1.93  loss_mask_1: 0.6297  loss_dice_1: 3.255  loss_ce_2: 1.792  loss_mask_2: 0.6269  loss_dice_2: 3.178  loss_ce_3: 1.748  loss_mask_3: 0.6249  loss_dice_3: 3.128  loss_ce_4: 1.706  loss_mask_4: 0.6235  loss_dice_4: 3.116  loss_ce_5: 1.669  loss_mask_5: 0.6212  loss_dice_5: 3.106  loss_ce_6: 1.669  loss_mask_6: 0.6248  loss_dice_6: 3.108  loss_ce_7: 1.683  loss_mask_7: 0.6239  loss_dice_7: 3.101  loss_ce_8: 1.679  loss_mask_8: 0.6243  loss_dice_8: 3.098  time: 1.6943  data_time: 0.3450  lr: 3.6117e-06  max_mem: 17674M
[01/19 14:40:42] d2.utils.events INFO:  eta: 6:02:35  iter: 27119  total_loss: 55.42  loss_ce: 1.543  loss_mask: 0.6093  loss_dice: 3.147  loss_ce_0: 2.684  loss_mask_0: 0.6264  loss_dice_0: 3.463  loss_ce_1: 1.788  loss_mask_1: 0.6173  loss_dice_1: 3.29  loss_ce_2: 1.667  loss_mask_2: 0.615  loss_dice_2: 3.219  loss_ce_3: 1.63  loss_mask_3: 0.6104  loss_dice_3: 3.173  loss_ce_4: 1.586  loss_mask_4: 0.6111  loss_dice_4: 3.168  loss_ce_5: 1.562  loss_mask_5: 0.6097  loss_dice_5: 3.168  loss_ce_6: 1.54  loss_mask_6: 0.6092  loss_dice_6: 3.157  loss_ce_7: 1.535  loss_mask_7: 0.6108  loss_dice_7: 3.149  loss_ce_8: 1.533  loss_mask_8: 0.6101  loss_dice_8: 3.146  time: 1.6943  data_time: 0.3457  lr: 3.6066e-06  max_mem: 17674M
[01/19 14:41:16] d2.utils.events INFO:  eta: 6:02:15  iter: 27139  total_loss: 55.77  loss_ce: 1.575  loss_mask: 0.6152  loss_dice: 3.135  loss_ce_0: 2.754  loss_mask_0: 0.6411  loss_dice_0: 3.444  loss_ce_1: 1.833  loss_mask_1: 0.6219  loss_dice_1: 3.264  loss_ce_2: 1.713  loss_mask_2: 0.6178  loss_dice_2: 3.202  loss_ce_3: 1.635  loss_mask_3: 0.6164  loss_dice_3: 3.15  loss_ce_4: 1.593  loss_mask_4: 0.6157  loss_dice_4: 3.144  loss_ce_5: 1.595  loss_mask_5: 0.616  loss_dice_5: 3.15  loss_ce_6: 1.572  loss_mask_6: 0.6145  loss_dice_6: 3.131  loss_ce_7: 1.549  loss_mask_7: 0.6152  loss_dice_7: 3.137  loss_ce_8: 1.55  loss_mask_8: 0.6151  loss_dice_8: 3.134  time: 1.6943  data_time: 0.3318  lr: 3.6016e-06  max_mem: 17674M
[01/19 14:41:50] d2.utils.events INFO:  eta: 6:01:44  iter: 27159  total_loss: 55.94  loss_ce: 1.627  loss_mask: 0.6262  loss_dice: 3.094  loss_ce_0: 2.724  loss_mask_0: 0.644  loss_dice_0: 3.404  loss_ce_1: 1.881  loss_mask_1: 0.6259  loss_dice_1: 3.227  loss_ce_2: 1.759  loss_mask_2: 0.6267  loss_dice_2: 3.169  loss_ce_3: 1.73  loss_mask_3: 0.6248  loss_dice_3: 3.124  loss_ce_4: 1.679  loss_mask_4: 0.6262  loss_dice_4: 3.119  loss_ce_5: 1.636  loss_mask_5: 0.6267  loss_dice_5: 3.116  loss_ce_6: 1.641  loss_mask_6: 0.6274  loss_dice_6: 3.1  loss_ce_7: 1.633  loss_mask_7: 0.6261  loss_dice_7: 3.09  loss_ce_8: 1.62  loss_mask_8: 0.6269  loss_dice_8: 3.096  time: 1.6943  data_time: 0.3434  lr: 3.5965e-06  max_mem: 17674M
[01/19 14:42:23] d2.utils.events INFO:  eta: 6:01:12  iter: 27179  total_loss: 55.39  loss_ce: 1.545  loss_mask: 0.6329  loss_dice: 3.076  loss_ce_0: 2.722  loss_mask_0: 0.658  loss_dice_0: 3.408  loss_ce_1: 1.779  loss_mask_1: 0.6393  loss_dice_1: 3.212  loss_ce_2: 1.695  loss_mask_2: 0.6363  loss_dice_2: 3.153  loss_ce_3: 1.631  loss_mask_3: 0.6294  loss_dice_3: 3.103  loss_ce_4: 1.582  loss_mask_4: 0.6289  loss_dice_4: 3.102  loss_ce_5: 1.56  loss_mask_5: 0.6306  loss_dice_5: 3.098  loss_ce_6: 1.567  loss_mask_6: 0.6329  loss_dice_6: 3.082  loss_ce_7: 1.56  loss_mask_7: 0.6321  loss_dice_7: 3.086  loss_ce_8: 1.558  loss_mask_8: 0.6334  loss_dice_8: 3.077  time: 1.6943  data_time: 0.3274  lr: 3.5915e-06  max_mem: 17674M
[01/19 14:42:57] d2.utils.events INFO:  eta: 6:00:35  iter: 27199  total_loss: 56.46  loss_ce: 1.616  loss_mask: 0.6107  loss_dice: 3.181  loss_ce_0: 2.819  loss_mask_0: 0.6367  loss_dice_0: 3.467  loss_ce_1: 1.878  loss_mask_1: 0.6268  loss_dice_1: 3.311  loss_ce_2: 1.753  loss_mask_2: 0.6224  loss_dice_2: 3.252  loss_ce_3: 1.721  loss_mask_3: 0.6159  loss_dice_3: 3.206  loss_ce_4: 1.68  loss_mask_4: 0.6137  loss_dice_4: 3.198  loss_ce_5: 1.655  loss_mask_5: 0.6134  loss_dice_5: 3.193  loss_ce_6: 1.626  loss_mask_6: 0.6125  loss_dice_6: 3.182  loss_ce_7: 1.622  loss_mask_7: 0.6123  loss_dice_7: 3.179  loss_ce_8: 1.616  loss_mask_8: 0.6101  loss_dice_8: 3.175  time: 1.6943  data_time: 0.3474  lr: 3.5865e-06  max_mem: 17674M
[01/19 14:43:31] d2.utils.events INFO:  eta: 6:00:10  iter: 27219  total_loss: 55.48  loss_ce: 1.555  loss_mask: 0.6133  loss_dice: 3.155  loss_ce_0: 2.774  loss_mask_0: 0.6403  loss_dice_0: 3.45  loss_ce_1: 1.82  loss_mask_1: 0.6176  loss_dice_1: 3.295  loss_ce_2: 1.721  loss_mask_2: 0.6153  loss_dice_2: 3.228  loss_ce_3: 1.654  loss_mask_3: 0.6131  loss_dice_3: 3.174  loss_ce_4: 1.62  loss_mask_4: 0.6157  loss_dice_4: 3.177  loss_ce_5: 1.569  loss_mask_5: 0.6145  loss_dice_5: 3.176  loss_ce_6: 1.571  loss_mask_6: 0.6153  loss_dice_6: 3.167  loss_ce_7: 1.575  loss_mask_7: 0.6154  loss_dice_7: 3.154  loss_ce_8: 1.574  loss_mask_8: 0.6143  loss_dice_8: 3.161  time: 1.6943  data_time: 0.3635  lr: 3.5814e-06  max_mem: 17674M
[01/19 14:44:05] d2.utils.events INFO:  eta: 5:59:33  iter: 27239  total_loss: 55.86  loss_ce: 1.576  loss_mask: 0.6156  loss_dice: 3.127  loss_ce_0: 2.832  loss_mask_0: 0.629  loss_dice_0: 3.43  loss_ce_1: 1.835  loss_mask_1: 0.6237  loss_dice_1: 3.265  loss_ce_2: 1.707  loss_mask_2: 0.6258  loss_dice_2: 3.198  loss_ce_3: 1.687  loss_mask_3: 0.6152  loss_dice_3: 3.145  loss_ce_4: 1.623  loss_mask_4: 0.617  loss_dice_4: 3.147  loss_ce_5: 1.607  loss_mask_5: 0.614  loss_dice_5: 3.136  loss_ce_6: 1.605  loss_mask_6: 0.6139  loss_dice_6: 3.133  loss_ce_7: 1.602  loss_mask_7: 0.6152  loss_dice_7: 3.127  loss_ce_8: 1.573  loss_mask_8: 0.6137  loss_dice_8: 3.129  time: 1.6943  data_time: 0.3412  lr: 3.5764e-06  max_mem: 17674M
[01/19 14:44:39] d2.utils.events INFO:  eta: 5:58:58  iter: 27259  total_loss: 55.7  loss_ce: 1.588  loss_mask: 0.6265  loss_dice: 3.125  loss_ce_0: 2.791  loss_mask_0: 0.65  loss_dice_0: 3.442  loss_ce_1: 1.874  loss_mask_1: 0.6353  loss_dice_1: 3.271  loss_ce_2: 1.751  loss_mask_2: 0.6318  loss_dice_2: 3.2  loss_ce_3: 1.686  loss_mask_3: 0.6257  loss_dice_3: 3.152  loss_ce_4: 1.631  loss_mask_4: 0.6265  loss_dice_4: 3.153  loss_ce_5: 1.613  loss_mask_5: 0.6284  loss_dice_5: 3.145  loss_ce_6: 1.6  loss_mask_6: 0.6258  loss_dice_6: 3.128  loss_ce_7: 1.589  loss_mask_7: 0.6276  loss_dice_7: 3.134  loss_ce_8: 1.582  loss_mask_8: 0.6261  loss_dice_8: 3.124  time: 1.6943  data_time: 0.3344  lr: 3.5713e-06  max_mem: 17674M
[01/19 14:45:13] d2.utils.events INFO:  eta: 5:58:29  iter: 27279  total_loss: 55.77  loss_ce: 1.637  loss_mask: 0.6039  loss_dice: 3.115  loss_ce_0: 2.87  loss_mask_0: 0.6209  loss_dice_0: 3.431  loss_ce_1: 1.843  loss_mask_1: 0.6103  loss_dice_1: 3.255  loss_ce_2: 1.749  loss_mask_2: 0.603  loss_dice_2: 3.185  loss_ce_3: 1.719  loss_mask_3: 0.5992  loss_dice_3: 3.139  loss_ce_4: 1.662  loss_mask_4: 0.6036  loss_dice_4: 3.14  loss_ce_5: 1.658  loss_mask_5: 0.6031  loss_dice_5: 3.137  loss_ce_6: 1.663  loss_mask_6: 0.6021  loss_dice_6: 3.119  loss_ce_7: 1.637  loss_mask_7: 0.6034  loss_dice_7: 3.122  loss_ce_8: 1.626  loss_mask_8: 0.6042  loss_dice_8: 3.115  time: 1.6943  data_time: 0.3431  lr: 3.5663e-06  max_mem: 17674M
[01/19 14:45:46] d2.utils.events INFO:  eta: 5:57:44  iter: 27299  total_loss: 54.99  loss_ce: 1.531  loss_mask: 0.6144  loss_dice: 3.098  loss_ce_0: 2.718  loss_mask_0: 0.6307  loss_dice_0: 3.424  loss_ce_1: 1.772  loss_mask_1: 0.6207  loss_dice_1: 3.235  loss_ce_2: 1.666  loss_mask_2: 0.6157  loss_dice_2: 3.167  loss_ce_3: 1.639  loss_mask_3: 0.6139  loss_dice_3: 3.125  loss_ce_4: 1.589  loss_mask_4: 0.615  loss_dice_4: 3.125  loss_ce_5: 1.575  loss_mask_5: 0.6143  loss_dice_5: 3.126  loss_ce_6: 1.552  loss_mask_6: 0.616  loss_dice_6: 3.11  loss_ce_7: 1.532  loss_mask_7: 0.6122  loss_dice_7: 3.105  loss_ce_8: 1.528  loss_mask_8: 0.6127  loss_dice_8: 3.096  time: 1.6943  data_time: 0.3277  lr: 3.5612e-06  max_mem: 17674M
[01/19 14:46:20] d2.utils.events INFO:  eta: 5:57:04  iter: 27319  total_loss: 56.08  loss_ce: 1.551  loss_mask: 0.6212  loss_dice: 3.124  loss_ce_0: 2.79  loss_mask_0: 0.6396  loss_dice_0: 3.447  loss_ce_1: 1.8  loss_mask_1: 0.6277  loss_dice_1: 3.268  loss_ce_2: 1.693  loss_mask_2: 0.6249  loss_dice_2: 3.207  loss_ce_3: 1.649  loss_mask_3: 0.621  loss_dice_3: 3.152  loss_ce_4: 1.618  loss_mask_4: 0.6215  loss_dice_4: 3.152  loss_ce_5: 1.577  loss_mask_5: 0.6227  loss_dice_5: 3.142  loss_ce_6: 1.553  loss_mask_6: 0.6192  loss_dice_6: 3.141  loss_ce_7: 1.568  loss_mask_7: 0.6202  loss_dice_7: 3.129  loss_ce_8: 1.561  loss_mask_8: 0.6213  loss_dice_8: 3.126  time: 1.6943  data_time: 0.3522  lr: 3.5562e-06  max_mem: 17674M
[01/19 14:46:54] d2.utils.events INFO:  eta: 5:56:40  iter: 27339  total_loss: 56.54  loss_ce: 1.634  loss_mask: 0.6372  loss_dice: 3.109  loss_ce_0: 2.82  loss_mask_0: 0.6616  loss_dice_0: 3.434  loss_ce_1: 1.925  loss_mask_1: 0.6436  loss_dice_1: 3.256  loss_ce_2: 1.791  loss_mask_2: 0.6414  loss_dice_2: 3.178  loss_ce_3: 1.751  loss_mask_3: 0.6411  loss_dice_3: 3.135  loss_ce_4: 1.692  loss_mask_4: 0.6386  loss_dice_4: 3.127  loss_ce_5: 1.665  loss_mask_5: 0.638  loss_dice_5: 3.13  loss_ce_6: 1.645  loss_mask_6: 0.6387  loss_dice_6: 3.117  loss_ce_7: 1.638  loss_mask_7: 0.6373  loss_dice_7: 3.119  loss_ce_8: 1.634  loss_mask_8: 0.6375  loss_dice_8: 3.115  time: 1.6943  data_time: 0.3332  lr: 3.5511e-06  max_mem: 17674M
[01/19 14:47:28] d2.utils.events INFO:  eta: 5:55:52  iter: 27359  total_loss: 56  loss_ce: 1.646  loss_mask: 0.6095  loss_dice: 3.144  loss_ce_0: 2.842  loss_mask_0: 0.6274  loss_dice_0: 3.457  loss_ce_1: 1.906  loss_mask_1: 0.6195  loss_dice_1: 3.28  loss_ce_2: 1.791  loss_mask_2: 0.6094  loss_dice_2: 3.213  loss_ce_3: 1.746  loss_mask_3: 0.6051  loss_dice_3: 3.173  loss_ce_4: 1.692  loss_mask_4: 0.6109  loss_dice_4: 3.162  loss_ce_5: 1.66  loss_mask_5: 0.6106  loss_dice_5: 3.161  loss_ce_6: 1.667  loss_mask_6: 0.6071  loss_dice_6: 3.154  loss_ce_7: 1.654  loss_mask_7: 0.6074  loss_dice_7: 3.157  loss_ce_8: 1.652  loss_mask_8: 0.6091  loss_dice_8: 3.145  time: 1.6943  data_time: 0.3419  lr: 3.5461e-06  max_mem: 17674M
[01/19 14:48:02] d2.utils.events INFO:  eta: 5:55:18  iter: 27379  total_loss: 56.21  loss_ce: 1.566  loss_mask: 0.6122  loss_dice: 3.174  loss_ce_0: 2.807  loss_mask_0: 0.628  loss_dice_0: 3.476  loss_ce_1: 1.865  loss_mask_1: 0.6155  loss_dice_1: 3.314  loss_ce_2: 1.72  loss_mask_2: 0.6134  loss_dice_2: 3.243  loss_ce_3: 1.68  loss_mask_3: 0.614  loss_dice_3: 3.204  loss_ce_4: 1.635  loss_mask_4: 0.6143  loss_dice_4: 3.183  loss_ce_5: 1.606  loss_mask_5: 0.6133  loss_dice_5: 3.187  loss_ce_6: 1.605  loss_mask_6: 0.6104  loss_dice_6: 3.182  loss_ce_7: 1.592  loss_mask_7: 0.6108  loss_dice_7: 3.179  loss_ce_8: 1.585  loss_mask_8: 0.6115  loss_dice_8: 3.175  time: 1.6943  data_time: 0.3427  lr: 3.541e-06  max_mem: 17674M
[01/19 14:48:36] d2.utils.events INFO:  eta: 5:54:44  iter: 27399  total_loss: 55.41  loss_ce: 1.539  loss_mask: 0.6115  loss_dice: 3.114  loss_ce_0: 2.696  loss_mask_0: 0.6282  loss_dice_0: 3.424  loss_ce_1: 1.802  loss_mask_1: 0.6178  loss_dice_1: 3.263  loss_ce_2: 1.685  loss_mask_2: 0.6146  loss_dice_2: 3.186  loss_ce_3: 1.622  loss_mask_3: 0.6133  loss_dice_3: 3.146  loss_ce_4: 1.578  loss_mask_4: 0.6102  loss_dice_4: 3.138  loss_ce_5: 1.565  loss_mask_5: 0.6132  loss_dice_5: 3.135  loss_ce_6: 1.559  loss_mask_6: 0.6131  loss_dice_6: 3.12  loss_ce_7: 1.52  loss_mask_7: 0.6116  loss_dice_7: 3.116  loss_ce_8: 1.531  loss_mask_8: 0.6121  loss_dice_8: 3.113  time: 1.6943  data_time: 0.3420  lr: 3.536e-06  max_mem: 17674M
[01/19 14:49:10] d2.utils.events INFO:  eta: 5:54:25  iter: 27419  total_loss: 55.82  loss_ce: 1.561  loss_mask: 0.6031  loss_dice: 3.148  loss_ce_0: 2.852  loss_mask_0: 0.6196  loss_dice_0: 3.459  loss_ce_1: 1.812  loss_mask_1: 0.6141  loss_dice_1: 3.302  loss_ce_2: 1.703  loss_mask_2: 0.6097  loss_dice_2: 3.227  loss_ce_3: 1.655  loss_mask_3: 0.6021  loss_dice_3: 3.178  loss_ce_4: 1.622  loss_mask_4: 0.6035  loss_dice_4: 3.173  loss_ce_5: 1.587  loss_mask_5: 0.6044  loss_dice_5: 3.161  loss_ce_6: 1.582  loss_mask_6: 0.6031  loss_dice_6: 3.157  loss_ce_7: 1.569  loss_mask_7: 0.6033  loss_dice_7: 3.154  loss_ce_8: 1.546  loss_mask_8: 0.6016  loss_dice_8: 3.146  time: 1.6943  data_time: 0.3476  lr: 3.5309e-06  max_mem: 17674M
[01/19 14:49:44] d2.utils.events INFO:  eta: 5:53:54  iter: 27439  total_loss: 55.44  loss_ce: 1.576  loss_mask: 0.6028  loss_dice: 3.115  loss_ce_0: 2.796  loss_mask_0: 0.6163  loss_dice_0: 3.424  loss_ce_1: 1.847  loss_mask_1: 0.6105  loss_dice_1: 3.251  loss_ce_2: 1.728  loss_mask_2: 0.61  loss_dice_2: 3.177  loss_ce_3: 1.673  loss_mask_3: 0.6014  loss_dice_3: 3.146  loss_ce_4: 1.629  loss_mask_4: 0.6017  loss_dice_4: 3.135  loss_ce_5: 1.606  loss_mask_5: 0.6013  loss_dice_5: 3.133  loss_ce_6: 1.59  loss_mask_6: 0.6014  loss_dice_6: 3.121  loss_ce_7: 1.581  loss_mask_7: 0.6003  loss_dice_7: 3.117  loss_ce_8: 1.568  loss_mask_8: 0.6021  loss_dice_8: 3.119  time: 1.6943  data_time: 0.3404  lr: 3.5259e-06  max_mem: 17674M
[01/19 14:50:19] d2.utils.events INFO:  eta: 5:53:19  iter: 27459  total_loss: 56.63  loss_ce: 1.605  loss_mask: 0.6241  loss_dice: 3.175  loss_ce_0: 2.8  loss_mask_0: 0.6445  loss_dice_0: 3.5  loss_ce_1: 1.887  loss_mask_1: 0.6303  loss_dice_1: 3.333  loss_ce_2: 1.769  loss_mask_2: 0.629  loss_dice_2: 3.259  loss_ce_3: 1.708  loss_mask_3: 0.622  loss_dice_3: 3.216  loss_ce_4: 1.662  loss_mask_4: 0.6255  loss_dice_4: 3.209  loss_ce_5: 1.648  loss_mask_5: 0.6268  loss_dice_5: 3.206  loss_ce_6: 1.616  loss_mask_6: 0.6255  loss_dice_6: 3.184  loss_ce_7: 1.595  loss_mask_7: 0.6233  loss_dice_7: 3.189  loss_ce_8: 1.619  loss_mask_8: 0.6246  loss_dice_8: 3.19  time: 1.6943  data_time: 0.3663  lr: 3.5208e-06  max_mem: 17674M
[01/19 14:50:53] d2.utils.events INFO:  eta: 5:52:51  iter: 27479  total_loss: 55.89  loss_ce: 1.582  loss_mask: 0.6159  loss_dice: 3.118  loss_ce_0: 2.734  loss_mask_0: 0.631  loss_dice_0: 3.445  loss_ce_1: 1.86  loss_mask_1: 0.6243  loss_dice_1: 3.26  loss_ce_2: 1.734  loss_mask_2: 0.6193  loss_dice_2: 3.195  loss_ce_3: 1.691  loss_mask_3: 0.6157  loss_dice_3: 3.15  loss_ce_4: 1.637  loss_mask_4: 0.6163  loss_dice_4: 3.144  loss_ce_5: 1.616  loss_mask_5: 0.6164  loss_dice_5: 3.146  loss_ce_6: 1.61  loss_mask_6: 0.6147  loss_dice_6: 3.122  loss_ce_7: 1.599  loss_mask_7: 0.616  loss_dice_7: 3.123  loss_ce_8: 1.586  loss_mask_8: 0.6168  loss_dice_8: 3.12  time: 1.6943  data_time: 0.3238  lr: 3.5158e-06  max_mem: 17674M
[01/19 14:51:27] d2.utils.events INFO:  eta: 5:52:20  iter: 27499  total_loss: 55.61  loss_ce: 1.611  loss_mask: 0.6158  loss_dice: 3.116  loss_ce_0: 2.81  loss_mask_0: 0.6404  loss_dice_0: 3.43  loss_ce_1: 1.85  loss_mask_1: 0.631  loss_dice_1: 3.257  loss_ce_2: 1.725  loss_mask_2: 0.626  loss_dice_2: 3.193  loss_ce_3: 1.684  loss_mask_3: 0.6224  loss_dice_3: 3.139  loss_ce_4: 1.645  loss_mask_4: 0.6199  loss_dice_4: 3.141  loss_ce_5: 1.61  loss_mask_5: 0.6172  loss_dice_5: 3.141  loss_ce_6: 1.618  loss_mask_6: 0.6135  loss_dice_6: 3.125  loss_ce_7: 1.611  loss_mask_7: 0.6145  loss_dice_7: 3.128  loss_ce_8: 1.609  loss_mask_8: 0.6143  loss_dice_8: 3.127  time: 1.6943  data_time: 0.3476  lr: 3.5107e-06  max_mem: 17674M
[01/19 14:52:00] d2.utils.events INFO:  eta: 5:51:38  iter: 27519  total_loss: 56.57  loss_ce: 1.627  loss_mask: 0.5996  loss_dice: 3.129  loss_ce_0: 2.829  loss_mask_0: 0.6186  loss_dice_0: 3.444  loss_ce_1: 1.881  loss_mask_1: 0.6038  loss_dice_1: 3.271  loss_ce_2: 1.771  loss_mask_2: 0.6024  loss_dice_2: 3.198  loss_ce_3: 1.71  loss_mask_3: 0.6007  loss_dice_3: 3.155  loss_ce_4: 1.658  loss_mask_4: 0.6023  loss_dice_4: 3.147  loss_ce_5: 1.631  loss_mask_5: 0.6029  loss_dice_5: 3.157  loss_ce_6: 1.634  loss_mask_6: 0.6017  loss_dice_6: 3.135  loss_ce_7: 1.629  loss_mask_7: 0.6028  loss_dice_7: 3.138  loss_ce_8: 1.617  loss_mask_8: 0.5996  loss_dice_8: 3.129  time: 1.6943  data_time: 0.3470  lr: 3.5057e-06  max_mem: 17674M
[01/19 14:52:34] d2.utils.events INFO:  eta: 5:51:06  iter: 27539  total_loss: 55.88  loss_ce: 1.619  loss_mask: 0.6216  loss_dice: 3.112  loss_ce_0: 2.79  loss_mask_0: 0.6483  loss_dice_0: 3.435  loss_ce_1: 1.862  loss_mask_1: 0.6321  loss_dice_1: 3.267  loss_ce_2: 1.756  loss_mask_2: 0.6281  loss_dice_2: 3.188  loss_ce_3: 1.703  loss_mask_3: 0.6224  loss_dice_3: 3.143  loss_ce_4: 1.663  loss_mask_4: 0.6227  loss_dice_4: 3.137  loss_ce_5: 1.655  loss_mask_5: 0.6251  loss_dice_5: 3.136  loss_ce_6: 1.64  loss_mask_6: 0.6226  loss_dice_6: 3.125  loss_ce_7: 1.628  loss_mask_7: 0.625  loss_dice_7: 3.121  loss_ce_8: 1.628  loss_mask_8: 0.6237  loss_dice_8: 3.111  time: 1.6943  data_time: 0.3570  lr: 3.5006e-06  max_mem: 17674M
[01/19 14:53:08] d2.utils.events INFO:  eta: 5:50:30  iter: 27559  total_loss: 56.37  loss_ce: 1.615  loss_mask: 0.6127  loss_dice: 3.161  loss_ce_0: 2.719  loss_mask_0: 0.6319  loss_dice_0: 3.463  loss_ce_1: 1.856  loss_mask_1: 0.6186  loss_dice_1: 3.309  loss_ce_2: 1.732  loss_mask_2: 0.6131  loss_dice_2: 3.233  loss_ce_3: 1.667  loss_mask_3: 0.6151  loss_dice_3: 3.197  loss_ce_4: 1.623  loss_mask_4: 0.6174  loss_dice_4: 3.179  loss_ce_5: 1.605  loss_mask_5: 0.6164  loss_dice_5: 3.185  loss_ce_6: 1.625  loss_mask_6: 0.6161  loss_dice_6: 3.172  loss_ce_7: 1.614  loss_mask_7: 0.6151  loss_dice_7: 3.174  loss_ce_8: 1.589  loss_mask_8: 0.613  loss_dice_8: 3.168  time: 1.6943  data_time: 0.3300  lr: 3.4956e-06  max_mem: 17674M
[01/19 14:53:42] d2.utils.events INFO:  eta: 5:50:05  iter: 27579  total_loss: 56.56  loss_ce: 1.671  loss_mask: 0.6284  loss_dice: 3.138  loss_ce_0: 2.781  loss_mask_0: 0.6544  loss_dice_0: 3.457  loss_ce_1: 1.889  loss_mask_1: 0.6358  loss_dice_1: 3.284  loss_ce_2: 1.798  loss_mask_2: 0.6279  loss_dice_2: 3.211  loss_ce_3: 1.746  loss_mask_3: 0.6254  loss_dice_3: 3.163  loss_ce_4: 1.723  loss_mask_4: 0.6257  loss_dice_4: 3.16  loss_ce_5: 1.682  loss_mask_5: 0.6262  loss_dice_5: 3.158  loss_ce_6: 1.697  loss_mask_6: 0.6258  loss_dice_6: 3.143  loss_ce_7: 1.653  loss_mask_7: 0.6273  loss_dice_7: 3.147  loss_ce_8: 1.654  loss_mask_8: 0.6266  loss_dice_8: 3.148  time: 1.6943  data_time: 0.3543  lr: 3.4905e-06  max_mem: 17674M
[01/19 14:54:16] d2.utils.events INFO:  eta: 5:49:31  iter: 27599  total_loss: 55.28  loss_ce: 1.504  loss_mask: 0.6128  loss_dice: 3.16  loss_ce_0: 2.71  loss_mask_0: 0.6303  loss_dice_0: 3.461  loss_ce_1: 1.777  loss_mask_1: 0.6218  loss_dice_1: 3.286  loss_ce_2: 1.659  loss_mask_2: 0.6175  loss_dice_2: 3.226  loss_ce_3: 1.61  loss_mask_3: 0.6138  loss_dice_3: 3.179  loss_ce_4: 1.556  loss_mask_4: 0.6159  loss_dice_4: 3.176  loss_ce_5: 1.536  loss_mask_5: 0.6145  loss_dice_5: 3.172  loss_ce_6: 1.517  loss_mask_6: 0.6119  loss_dice_6: 3.167  loss_ce_7: 1.508  loss_mask_7: 0.6132  loss_dice_7: 3.167  loss_ce_8: 1.507  loss_mask_8: 0.6127  loss_dice_8: 3.162  time: 1.6943  data_time: 0.3451  lr: 3.4854e-06  max_mem: 17674M
[01/19 14:54:50] d2.utils.events INFO:  eta: 5:48:57  iter: 27619  total_loss: 54.95  loss_ce: 1.509  loss_mask: 0.6071  loss_dice: 3.139  loss_ce_0: 2.754  loss_mask_0: 0.6233  loss_dice_0: 3.452  loss_ce_1: 1.735  loss_mask_1: 0.6107  loss_dice_1: 3.284  loss_ce_2: 1.652  loss_mask_2: 0.6069  loss_dice_2: 3.219  loss_ce_3: 1.602  loss_mask_3: 0.6059  loss_dice_3: 3.168  loss_ce_4: 1.564  loss_mask_4: 0.606  loss_dice_4: 3.155  loss_ce_5: 1.528  loss_mask_5: 0.6072  loss_dice_5: 3.15  loss_ce_6: 1.547  loss_mask_6: 0.6044  loss_dice_6: 3.142  loss_ce_7: 1.522  loss_mask_7: 0.6092  loss_dice_7: 3.138  loss_ce_8: 1.534  loss_mask_8: 0.6104  loss_dice_8: 3.137  time: 1.6943  data_time: 0.3417  lr: 3.4804e-06  max_mem: 17674M
[01/19 14:55:24] d2.utils.events INFO:  eta: 5:48:26  iter: 27639  total_loss: 55.78  loss_ce: 1.571  loss_mask: 0.625  loss_dice: 3.153  loss_ce_0: 2.736  loss_mask_0: 0.643  loss_dice_0: 3.444  loss_ce_1: 1.849  loss_mask_1: 0.6326  loss_dice_1: 3.293  loss_ce_2: 1.738  loss_mask_2: 0.6224  loss_dice_2: 3.217  loss_ce_3: 1.67  loss_mask_3: 0.6199  loss_dice_3: 3.179  loss_ce_4: 1.607  loss_mask_4: 0.6198  loss_dice_4: 3.171  loss_ce_5: 1.603  loss_mask_5: 0.6235  loss_dice_5: 3.175  loss_ce_6: 1.605  loss_mask_6: 0.6181  loss_dice_6: 3.16  loss_ce_7: 1.574  loss_mask_7: 0.6184  loss_dice_7: 3.157  loss_ce_8: 1.576  loss_mask_8: 0.6206  loss_dice_8: 3.156  time: 1.6943  data_time: 0.3445  lr: 3.4753e-06  max_mem: 17674M
[01/19 14:55:58] d2.utils.events INFO:  eta: 5:47:43  iter: 27659  total_loss: 55.97  loss_ce: 1.603  loss_mask: 0.6269  loss_dice: 3.127  loss_ce_0: 2.819  loss_mask_0: 0.6543  loss_dice_0: 3.423  loss_ce_1: 1.849  loss_mask_1: 0.6327  loss_dice_1: 3.26  loss_ce_2: 1.741  loss_mask_2: 0.6313  loss_dice_2: 3.199  loss_ce_3: 1.684  loss_mask_3: 0.6255  loss_dice_3: 3.15  loss_ce_4: 1.654  loss_mask_4: 0.626  loss_dice_4: 3.144  loss_ce_5: 1.621  loss_mask_5: 0.6255  loss_dice_5: 3.14  loss_ce_6: 1.618  loss_mask_6: 0.6261  loss_dice_6: 3.134  loss_ce_7: 1.606  loss_mask_7: 0.6249  loss_dice_7: 3.128  loss_ce_8: 1.588  loss_mask_8: 0.6265  loss_dice_8: 3.132  time: 1.6943  data_time: 0.3300  lr: 3.4703e-06  max_mem: 17674M
[01/19 14:56:32] d2.utils.events INFO:  eta: 5:47:11  iter: 27679  total_loss: 55.78  loss_ce: 1.628  loss_mask: 0.6199  loss_dice: 3.125  loss_ce_0: 2.771  loss_mask_0: 0.6303  loss_dice_0: 3.421  loss_ce_1: 1.875  loss_mask_1: 0.6203  loss_dice_1: 3.249  loss_ce_2: 1.765  loss_mask_2: 0.6261  loss_dice_2: 3.189  loss_ce_3: 1.705  loss_mask_3: 0.6174  loss_dice_3: 3.157  loss_ce_4: 1.653  loss_mask_4: 0.6187  loss_dice_4: 3.143  loss_ce_5: 1.633  loss_mask_5: 0.6172  loss_dice_5: 3.147  loss_ce_6: 1.641  loss_mask_6: 0.6179  loss_dice_6: 3.135  loss_ce_7: 1.599  loss_mask_7: 0.6185  loss_dice_7: 3.135  loss_ce_8: 1.596  loss_mask_8: 0.6185  loss_dice_8: 3.132  time: 1.6943  data_time: 0.3545  lr: 3.4652e-06  max_mem: 17674M
[01/19 14:57:06] d2.utils.events INFO:  eta: 5:46:42  iter: 27699  total_loss: 55.79  loss_ce: 1.604  loss_mask: 0.6143  loss_dice: 3.088  loss_ce_0: 2.807  loss_mask_0: 0.6257  loss_dice_0: 3.415  loss_ce_1: 1.897  loss_mask_1: 0.6167  loss_dice_1: 3.233  loss_ce_2: 1.771  loss_mask_2: 0.6135  loss_dice_2: 3.166  loss_ce_3: 1.742  loss_mask_3: 0.6133  loss_dice_3: 3.12  loss_ce_4: 1.682  loss_mask_4: 0.616  loss_dice_4: 3.107  loss_ce_5: 1.643  loss_mask_5: 0.6149  loss_dice_5: 3.114  loss_ce_6: 1.637  loss_mask_6: 0.6137  loss_dice_6: 3.095  loss_ce_7: 1.624  loss_mask_7: 0.6157  loss_dice_7: 3.096  loss_ce_8: 1.615  loss_mask_8: 0.6161  loss_dice_8: 3.094  time: 1.6943  data_time: 0.3412  lr: 3.4601e-06  max_mem: 17674M
[01/19 14:57:40] d2.utils.events INFO:  eta: 5:46:08  iter: 27719  total_loss: 54.71  loss_ce: 1.509  loss_mask: 0.612  loss_dice: 3.156  loss_ce_0: 2.787  loss_mask_0: 0.6372  loss_dice_0: 3.439  loss_ce_1: 1.749  loss_mask_1: 0.6202  loss_dice_1: 3.282  loss_ce_2: 1.64  loss_mask_2: 0.6145  loss_dice_2: 3.22  loss_ce_3: 1.587  loss_mask_3: 0.6155  loss_dice_3: 3.184  loss_ce_4: 1.557  loss_mask_4: 0.6149  loss_dice_4: 3.174  loss_ce_5: 1.535  loss_mask_5: 0.6136  loss_dice_5: 3.178  loss_ce_6: 1.531  loss_mask_6: 0.6137  loss_dice_6: 3.165  loss_ce_7: 1.518  loss_mask_7: 0.6099  loss_dice_7: 3.166  loss_ce_8: 1.495  loss_mask_8: 0.61  loss_dice_8: 3.163  time: 1.6943  data_time: 0.3445  lr: 3.4551e-06  max_mem: 17674M
[01/19 14:58:15] d2.utils.events INFO:  eta: 5:45:37  iter: 27739  total_loss: 55.51  loss_ce: 1.578  loss_mask: 0.5971  loss_dice: 3.171  loss_ce_0: 2.726  loss_mask_0: 0.6139  loss_dice_0: 3.481  loss_ce_1: 1.831  loss_mask_1: 0.6071  loss_dice_1: 3.315  loss_ce_2: 1.7  loss_mask_2: 0.5998  loss_dice_2: 3.242  loss_ce_3: 1.659  loss_mask_3: 0.5988  loss_dice_3: 3.191  loss_ce_4: 1.615  loss_mask_4: 0.5973  loss_dice_4: 3.194  loss_ce_5: 1.609  loss_mask_5: 0.5966  loss_dice_5: 3.186  loss_ce_6: 1.599  loss_mask_6: 0.5966  loss_dice_6: 3.17  loss_ce_7: 1.584  loss_mask_7: 0.5963  loss_dice_7: 3.177  loss_ce_8: 1.563  loss_mask_8: 0.597  loss_dice_8: 3.171  time: 1.6944  data_time: 0.3540  lr: 3.45e-06  max_mem: 17674M
[01/19 14:58:49] d2.utils.events INFO:  eta: 5:45:11  iter: 27759  total_loss: 55.34  loss_ce: 1.579  loss_mask: 0.6134  loss_dice: 3.117  loss_ce_0: 2.719  loss_mask_0: 0.634  loss_dice_0: 3.441  loss_ce_1: 1.826  loss_mask_1: 0.6196  loss_dice_1: 3.256  loss_ce_2: 1.712  loss_mask_2: 0.619  loss_dice_2: 3.186  loss_ce_3: 1.686  loss_mask_3: 0.6153  loss_dice_3: 3.143  loss_ce_4: 1.663  loss_mask_4: 0.6142  loss_dice_4: 3.135  loss_ce_5: 1.635  loss_mask_5: 0.6186  loss_dice_5: 3.132  loss_ce_6: 1.624  loss_mask_6: 0.6146  loss_dice_6: 3.126  loss_ce_7: 1.608  loss_mask_7: 0.6134  loss_dice_7: 3.123  loss_ce_8: 1.602  loss_mask_8: 0.6159  loss_dice_8: 3.12  time: 1.6944  data_time: 0.3383  lr: 3.4449e-06  max_mem: 17674M
[01/19 14:59:23] d2.utils.events INFO:  eta: 5:44:32  iter: 27779  total_loss: 56.17  loss_ce: 1.609  loss_mask: 0.6191  loss_dice: 3.113  loss_ce_0: 2.793  loss_mask_0: 0.647  loss_dice_0: 3.454  loss_ce_1: 1.842  loss_mask_1: 0.6347  loss_dice_1: 3.27  loss_ce_2: 1.729  loss_mask_2: 0.6261  loss_dice_2: 3.201  loss_ce_3: 1.665  loss_mask_3: 0.6237  loss_dice_3: 3.149  loss_ce_4: 1.646  loss_mask_4: 0.6217  loss_dice_4: 3.144  loss_ce_5: 1.602  loss_mask_5: 0.6239  loss_dice_5: 3.135  loss_ce_6: 1.604  loss_mask_6: 0.6238  loss_dice_6: 3.122  loss_ce_7: 1.605  loss_mask_7: 0.6225  loss_dice_7: 3.119  loss_ce_8: 1.601  loss_mask_8: 0.6227  loss_dice_8: 3.119  time: 1.6944  data_time: 0.3481  lr: 3.4399e-06  max_mem: 17674M
[01/19 14:59:56] d2.utils.events INFO:  eta: 5:43:51  iter: 27799  total_loss: 54.82  loss_ce: 1.533  loss_mask: 0.6288  loss_dice: 3.105  loss_ce_0: 2.708  loss_mask_0: 0.6424  loss_dice_0: 3.414  loss_ce_1: 1.807  loss_mask_1: 0.6341  loss_dice_1: 3.236  loss_ce_2: 1.675  loss_mask_2: 0.6292  loss_dice_2: 3.166  loss_ce_3: 1.601  loss_mask_3: 0.6285  loss_dice_3: 3.125  loss_ce_4: 1.561  loss_mask_4: 0.6285  loss_dice_4: 3.126  loss_ce_5: 1.547  loss_mask_5: 0.6286  loss_dice_5: 3.117  loss_ce_6: 1.537  loss_mask_6: 0.6303  loss_dice_6: 3.107  loss_ce_7: 1.539  loss_mask_7: 0.6288  loss_dice_7: 3.103  loss_ce_8: 1.526  loss_mask_8: 0.6286  loss_dice_8: 3.105  time: 1.6943  data_time: 0.3451  lr: 3.4348e-06  max_mem: 17674M
[01/19 15:00:31] d2.utils.events INFO:  eta: 5:43:27  iter: 27819  total_loss: 55.48  loss_ce: 1.574  loss_mask: 0.6107  loss_dice: 3.109  loss_ce_0: 2.755  loss_mask_0: 0.6303  loss_dice_0: 3.424  loss_ce_1: 1.869  loss_mask_1: 0.6222  loss_dice_1: 3.242  loss_ce_2: 1.724  loss_mask_2: 0.6154  loss_dice_2: 3.183  loss_ce_3: 1.68  loss_mask_3: 0.6105  loss_dice_3: 3.129  loss_ce_4: 1.635  loss_mask_4: 0.612  loss_dice_4: 3.131  loss_ce_5: 1.614  loss_mask_5: 0.6109  loss_dice_5: 3.131  loss_ce_6: 1.602  loss_mask_6: 0.6137  loss_dice_6: 3.113  loss_ce_7: 1.576  loss_mask_7: 0.6114  loss_dice_7: 3.113  loss_ce_8: 1.584  loss_mask_8: 0.6092  loss_dice_8: 3.108  time: 1.6944  data_time: 0.3627  lr: 3.4297e-06  max_mem: 17674M
[01/19 15:01:05] d2.utils.events INFO:  eta: 5:42:46  iter: 27839  total_loss: 55.73  loss_ce: 1.627  loss_mask: 0.6157  loss_dice: 3.135  loss_ce_0: 2.757  loss_mask_0: 0.6334  loss_dice_0: 3.451  loss_ce_1: 1.856  loss_mask_1: 0.6158  loss_dice_1: 3.284  loss_ce_2: 1.762  loss_mask_2: 0.6146  loss_dice_2: 3.212  loss_ce_3: 1.726  loss_mask_3: 0.61  loss_dice_3: 3.164  loss_ce_4: 1.676  loss_mask_4: 0.6144  loss_dice_4: 3.161  loss_ce_5: 1.65  loss_mask_5: 0.6159  loss_dice_5: 3.149  loss_ce_6: 1.653  loss_mask_6: 0.6174  loss_dice_6: 3.14  loss_ce_7: 1.625  loss_mask_7: 0.6166  loss_dice_7: 3.135  loss_ce_8: 1.623  loss_mask_8: 0.6162  loss_dice_8: 3.133  time: 1.6944  data_time: 0.3500  lr: 3.4247e-06  max_mem: 17674M
[01/19 15:01:38] d2.utils.events INFO:  eta: 5:42:09  iter: 27859  total_loss: 56.01  loss_ce: 1.612  loss_mask: 0.6238  loss_dice: 3.141  loss_ce_0: 2.722  loss_mask_0: 0.6488  loss_dice_0: 3.475  loss_ce_1: 1.888  loss_mask_1: 0.632  loss_dice_1: 3.298  loss_ce_2: 1.756  loss_mask_2: 0.628  loss_dice_2: 3.211  loss_ce_3: 1.704  loss_mask_3: 0.6232  loss_dice_3: 3.166  loss_ce_4: 1.66  loss_mask_4: 0.6212  loss_dice_4: 3.16  loss_ce_5: 1.631  loss_mask_5: 0.6211  loss_dice_5: 3.156  loss_ce_6: 1.622  loss_mask_6: 0.6232  loss_dice_6: 3.145  loss_ce_7: 1.617  loss_mask_7: 0.622  loss_dice_7: 3.146  loss_ce_8: 1.591  loss_mask_8: 0.6242  loss_dice_8: 3.138  time: 1.6944  data_time: 0.3612  lr: 3.4196e-06  max_mem: 17674M
[01/19 15:02:12] d2.utils.events INFO:  eta: 5:41:33  iter: 27879  total_loss: 55.15  loss_ce: 1.56  loss_mask: 0.6151  loss_dice: 3.085  loss_ce_0: 2.75  loss_mask_0: 0.6357  loss_dice_0: 3.416  loss_ce_1: 1.805  loss_mask_1: 0.6244  loss_dice_1: 3.232  loss_ce_2: 1.724  loss_mask_2: 0.6174  loss_dice_2: 3.158  loss_ce_3: 1.642  loss_mask_3: 0.6166  loss_dice_3: 3.113  loss_ce_4: 1.612  loss_mask_4: 0.6161  loss_dice_4: 3.113  loss_ce_5: 1.563  loss_mask_5: 0.6146  loss_dice_5: 3.105  loss_ce_6: 1.577  loss_mask_6: 0.6158  loss_dice_6: 3.101  loss_ce_7: 1.556  loss_mask_7: 0.6189  loss_dice_7: 3.095  loss_ce_8: 1.548  loss_mask_8: 0.616  loss_dice_8: 3.088  time: 1.6943  data_time: 0.3345  lr: 3.4145e-06  max_mem: 17674M
[01/19 15:02:46] d2.utils.events INFO:  eta: 5:40:59  iter: 27899  total_loss: 55.68  loss_ce: 1.555  loss_mask: 0.622  loss_dice: 3.127  loss_ce_0: 2.783  loss_mask_0: 0.6478  loss_dice_0: 3.437  loss_ce_1: 1.843  loss_mask_1: 0.6276  loss_dice_1: 3.27  loss_ce_2: 1.716  loss_mask_2: 0.6271  loss_dice_2: 3.196  loss_ce_3: 1.668  loss_mask_3: 0.6225  loss_dice_3: 3.153  loss_ce_4: 1.624  loss_mask_4: 0.6234  loss_dice_4: 3.153  loss_ce_5: 1.601  loss_mask_5: 0.6234  loss_dice_5: 3.141  loss_ce_6: 1.58  loss_mask_6: 0.6229  loss_dice_6: 3.129  loss_ce_7: 1.571  loss_mask_7: 0.6241  loss_dice_7: 3.13  loss_ce_8: 1.564  loss_mask_8: 0.623  loss_dice_8: 3.128  time: 1.6943  data_time: 0.3476  lr: 3.4095e-06  max_mem: 17674M
[01/19 15:03:20] d2.utils.events INFO:  eta: 5:40:34  iter: 27919  total_loss: 54.61  loss_ce: 1.555  loss_mask: 0.607  loss_dice: 3.112  loss_ce_0: 2.705  loss_mask_0: 0.625  loss_dice_0: 3.417  loss_ce_1: 1.721  loss_mask_1: 0.6194  loss_dice_1: 3.239  loss_ce_2: 1.653  loss_mask_2: 0.6175  loss_dice_2: 3.172  loss_ce_3: 1.603  loss_mask_3: 0.6064  loss_dice_3: 3.134  loss_ce_4: 1.564  loss_mask_4: 0.6049  loss_dice_4: 3.126  loss_ce_5: 1.54  loss_mask_5: 0.6063  loss_dice_5: 3.12  loss_ce_6: 1.538  loss_mask_6: 0.6039  loss_dice_6: 3.116  loss_ce_7: 1.521  loss_mask_7: 0.6071  loss_dice_7: 3.115  loss_ce_8: 1.521  loss_mask_8: 0.6061  loss_dice_8: 3.108  time: 1.6944  data_time: 0.3525  lr: 3.4044e-06  max_mem: 17674M
[01/19 15:03:54] d2.utils.events INFO:  eta: 5:39:47  iter: 27939  total_loss: 56.25  loss_ce: 1.654  loss_mask: 0.6225  loss_dice: 3.14  loss_ce_0: 2.841  loss_mask_0: 0.6444  loss_dice_0: 3.431  loss_ce_1: 1.864  loss_mask_1: 0.6299  loss_dice_1: 3.287  loss_ce_2: 1.786  loss_mask_2: 0.6245  loss_dice_2: 3.22  loss_ce_3: 1.722  loss_mask_3: 0.6243  loss_dice_3: 3.182  loss_ce_4: 1.664  loss_mask_4: 0.6253  loss_dice_4: 3.171  loss_ce_5: 1.648  loss_mask_5: 0.6236  loss_dice_5: 3.162  loss_ce_6: 1.658  loss_mask_6: 0.6218  loss_dice_6: 3.149  loss_ce_7: 1.641  loss_mask_7: 0.6228  loss_dice_7: 3.145  loss_ce_8: 1.628  loss_mask_8: 0.623  loss_dice_8: 3.147  time: 1.6943  data_time: 0.3404  lr: 3.3993e-06  max_mem: 17674M
[01/19 17:19:04] detectron2 INFO: Rank of current process: 0. World size: 1
[01/19 17:19:07] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/19 17:19:07] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/19 17:19:07] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/19 17:19:08] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop192x384[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0e-05[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/19 17:19:08] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop192x384/config.yaml
[01/19 17:19:08] d2.utils.env INFO: Using a generated random seed 8503256
[01/19 17:19:13] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/19 17:19:14] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/19 17:19:27] d2.data.build INFO: Using training sampler TrainingSampler
[01/19 17:19:27] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/19 17:19:27] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/19 17:19:27] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/19 17:19:27] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/19 17:19:27] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/19 17:19:28] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/19 17:19:28] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/19 17:19:28] d2.engine.train_loop INFO: Starting training from iteration 0
[01/19 17:20:29] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 395, in run_step
    loss_dict = self.model(data)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/maskformer_model_stereo.py", line 249, in forward
    outputs = self.sem_seg_head(features)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/modeling/meta_arch/mask_former_head.py", line 116, in forward
    return self.layers(features, mask)
  File "/home/nstarli/Mask2Former/mask2former/modeling/meta_arch/mask_former_head.py", line 119, in layers
    mask_features, transformer_encoder_features, multi_scale_features = self.pixel_decoder.forward_features(features)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/cuda/amp/autocast_mode.py", line 141, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py", line 324, in forward_features
    y, spatial_shapes, level_start_index = self.transformer(srcs, pos)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py", line 87, in forward
    memory = self.encoder(src_flatten, spatial_shapes, level_start_index, valid_ratios, lvl_pos_embed_flatten, mask_flatten)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py", line 159, in forward
    output = layer(output, pos, reference_points, spatial_shapes, level_start_index, padding_mask)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/nstarli/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py", line 129, in forward
    src = self.forward_ffn(src)
  File "/home/nstarli/Mask2Former/mask2former/modeling/pixel_decoder/msdeformattn.py", line 117, in forward_ffn
    src2 = self.linear2(self.dropout2(self.activation(self.linear1(src))))
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/nn/functional.py", line 1298, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 672.00 MiB (GPU 0; 31.75 GiB total capacity; 29.53 GiB already allocated; 661.75 MiB free; 29.81 GiB reserved in total by PyTorch)
[01/19 17:20:44] d2.engine.hooks INFO: Total training time: 0:01:16 (0:00:00 on hooks)
[01/19 17:20:44] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 30234M
[01/19 17:25:22] detectron2 INFO: Rank of current process: 0. World size: 1
[01/19 17:25:25] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/19 17:25:25] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/19 17:25:25] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/19 17:25:25] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_crop192x384[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0e-05[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/19 17:25:25] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_crop192x384/config.yaml
[01/19 17:25:26] d2.utils.env INFO: Using a generated random seed 26134224
[01/19 17:25:31] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/19 17:25:31] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/19 17:25:45] d2.data.build INFO: Using training sampler TrainingSampler
[01/19 17:25:45] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/19 17:25:45] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/19 17:25:45] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/19 17:25:46] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/19 17:25:46] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/19 17:25:46] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/19 17:25:46] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/19 17:25:46] d2.engine.train_loop INFO: Starting training from iteration 0
