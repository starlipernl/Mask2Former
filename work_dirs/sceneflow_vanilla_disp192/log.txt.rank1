[01/17 17:03:56] detectron2 INFO: Rank of current process: 1. World size: 4
[01/17 17:03:59] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/17 17:03:59] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/17 17:03:59] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/17 17:04:00] detectron2.utils.env INFO: Using a generated random seed 171727
[01/17 17:04:02] detectron2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/17 17:04:02] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 17:04:05] detectron2.data.build INFO: Using training sampler TrainingSampler
[01/17 17:04:07] detectron2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/17 17:04:07] detectron2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/17 17:04:07] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/17 17:04:07] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/17 17:04:07] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/17 17:04:07] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/17 17:04:07] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/17 17:04:07] detectron2.engine.train_loop INFO: Starting training from iteration 0
[01/17 17:05:31] detectron2.engine.hooks INFO: Overall training speed: 34 iterations in 0:01:06 (1.9549 s / it)
[01/17 17:05:31] detectron2.engine.hooks INFO: Total training time: 0:01:06 (0:00:00 on hooks)
[01/17 17:06:34] detectron2 INFO: Rank of current process: 1. World size: 4
[01/17 17:06:38] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/17 17:06:38] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/17 17:06:38] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/17 17:06:38] detectron2.utils.env INFO: Using a generated random seed 38527177
[01/17 17:06:39] detectron2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/17 17:06:39] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 17:06:43] detectron2.data.build INFO: Using training sampler TrainingSampler
[01/17 17:06:43] detectron2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/17 17:06:43] detectron2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/17 17:06:43] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/17 17:06:43] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/17 17:06:44] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/17 17:06:44] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/17 17:06:44] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/17 17:06:44] detectron2.engine.train_loop INFO: Starting training from iteration 0
[01/17 17:07:40] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 17:07:41] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 17:07:41] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 17:07:41] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 17:07:54] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0165 s/iter. Inference: 0.1928 s/iter. Eval: 0.0290 s/iter. Total: 0.2383 s/iter. ETA=0:04:17
[01/17 17:07:59] detectron2.evaluation.evaluator INFO: Inference done 34/1093. Dataloading: 0.0171 s/iter. Inference: 0.1915 s/iter. Eval: 0.0220 s/iter. Total: 0.2307 s/iter. ETA=0:04:04
[01/17 17:08:04] detectron2.evaluation.evaluator INFO: Inference done 56/1093. Dataloading: 0.0182 s/iter. Inference: 0.1917 s/iter. Eval: 0.0220 s/iter. Total: 0.2320 s/iter. ETA=0:04:00
[01/17 17:08:10] detectron2.evaluation.evaluator INFO: Inference done 79/1093. Dataloading: 0.0176 s/iter. Inference: 0.1903 s/iter. Eval: 0.0214 s/iter. Total: 0.2294 s/iter. ETA=0:03:52
[01/17 17:08:15] detectron2.evaluation.evaluator INFO: Inference done 102/1093. Dataloading: 0.0170 s/iter. Inference: 0.1884 s/iter. Eval: 0.0218 s/iter. Total: 0.2274 s/iter. ETA=0:03:45
[01/17 17:08:20] detectron2.evaluation.evaluator INFO: Inference done 125/1093. Dataloading: 0.0162 s/iter. Inference: 0.1880 s/iter. Eval: 0.0219 s/iter. Total: 0.2261 s/iter. ETA=0:03:38
[01/17 17:08:25] detectron2.evaluation.evaluator INFO: Inference done 147/1093. Dataloading: 0.0155 s/iter. Inference: 0.1895 s/iter. Eval: 0.0214 s/iter. Total: 0.2264 s/iter. ETA=0:03:34
[01/17 17:08:30] detectron2.evaluation.evaluator INFO: Inference done 170/1093. Dataloading: 0.0154 s/iter. Inference: 0.1891 s/iter. Eval: 0.0216 s/iter. Total: 0.2262 s/iter. ETA=0:03:28
[01/17 17:08:35] detectron2.evaluation.evaluator INFO: Inference done 193/1093. Dataloading: 0.0153 s/iter. Inference: 0.1880 s/iter. Eval: 0.0218 s/iter. Total: 0.2252 s/iter. ETA=0:03:22
[01/17 17:08:40] detectron2.evaluation.evaluator INFO: Inference done 215/1093. Dataloading: 0.0153 s/iter. Inference: 0.1888 s/iter. Eval: 0.0218 s/iter. Total: 0.2260 s/iter. ETA=0:03:18
[01/17 17:08:45] detectron2.evaluation.evaluator INFO: Inference done 237/1093. Dataloading: 0.0152 s/iter. Inference: 0.1897 s/iter. Eval: 0.0218 s/iter. Total: 0.2268 s/iter. ETA=0:03:14
[01/17 17:08:50] detectron2.evaluation.evaluator INFO: Inference done 260/1093. Dataloading: 0.0152 s/iter. Inference: 0.1896 s/iter. Eval: 0.0217 s/iter. Total: 0.2266 s/iter. ETA=0:03:08
[01/17 17:08:56] detectron2.evaluation.evaluator INFO: Inference done 283/1093. Dataloading: 0.0152 s/iter. Inference: 0.1893 s/iter. Eval: 0.0217 s/iter. Total: 0.2262 s/iter. ETA=0:03:03
[01/17 17:09:01] detectron2.evaluation.evaluator INFO: Inference done 305/1093. Dataloading: 0.0152 s/iter. Inference: 0.1896 s/iter. Eval: 0.0219 s/iter. Total: 0.2268 s/iter. ETA=0:02:58
[01/17 17:09:06] detectron2.evaluation.evaluator INFO: Inference done 332/1093. Dataloading: 0.0148 s/iter. Inference: 0.1872 s/iter. Eval: 0.0217 s/iter. Total: 0.2238 s/iter. ETA=0:02:50
[01/17 17:09:11] detectron2.evaluation.evaluator INFO: Inference done 355/1093. Dataloading: 0.0148 s/iter. Inference: 0.1870 s/iter. Eval: 0.0217 s/iter. Total: 0.2236 s/iter. ETA=0:02:45
[01/17 17:09:16] detectron2.evaluation.evaluator INFO: Inference done 377/1093. Dataloading: 0.0148 s/iter. Inference: 0.1878 s/iter. Eval: 0.0216 s/iter. Total: 0.2242 s/iter. ETA=0:02:40
[01/17 17:09:21] detectron2.evaluation.evaluator INFO: Inference done 399/1093. Dataloading: 0.0148 s/iter. Inference: 0.1879 s/iter. Eval: 0.0217 s/iter. Total: 0.2245 s/iter. ETA=0:02:35
[01/17 17:09:26] detectron2.evaluation.evaluator INFO: Inference done 419/1093. Dataloading: 0.0148 s/iter. Inference: 0.1894 s/iter. Eval: 0.0216 s/iter. Total: 0.2260 s/iter. ETA=0:02:32
[01/17 17:09:31] detectron2.evaluation.evaluator INFO: Inference done 442/1093. Dataloading: 0.0149 s/iter. Inference: 0.1890 s/iter. Eval: 0.0217 s/iter. Total: 0.2258 s/iter. ETA=0:02:26
[01/17 17:09:36] detectron2.evaluation.evaluator INFO: Inference done 466/1093. Dataloading: 0.0148 s/iter. Inference: 0.1884 s/iter. Eval: 0.0217 s/iter. Total: 0.2249 s/iter. ETA=0:02:21
[01/17 17:09:41] detectron2.evaluation.evaluator INFO: Inference done 488/1093. Dataloading: 0.0148 s/iter. Inference: 0.1885 s/iter. Eval: 0.0218 s/iter. Total: 0.2252 s/iter. ETA=0:02:16
[01/17 17:09:47] detectron2.evaluation.evaluator INFO: Inference done 511/1093. Dataloading: 0.0148 s/iter. Inference: 0.1885 s/iter. Eval: 0.0217 s/iter. Total: 0.2251 s/iter. ETA=0:02:11
[01/17 17:09:52] detectron2.evaluation.evaluator INFO: Inference done 533/1093. Dataloading: 0.0148 s/iter. Inference: 0.1889 s/iter. Eval: 0.0218 s/iter. Total: 0.2257 s/iter. ETA=0:02:06
[01/17 17:09:57] detectron2.evaluation.evaluator INFO: Inference done 556/1093. Dataloading: 0.0148 s/iter. Inference: 0.1890 s/iter. Eval: 0.0217 s/iter. Total: 0.2256 s/iter. ETA=0:02:01
[01/17 17:10:02] detectron2.evaluation.evaluator INFO: Inference done 580/1093. Dataloading: 0.0147 s/iter. Inference: 0.1885 s/iter. Eval: 0.0217 s/iter. Total: 0.2250 s/iter. ETA=0:01:55
[01/17 17:10:07] detectron2.evaluation.evaluator INFO: Inference done 603/1093. Dataloading: 0.0147 s/iter. Inference: 0.1884 s/iter. Eval: 0.0217 s/iter. Total: 0.2249 s/iter. ETA=0:01:50
[01/17 17:10:12] detectron2.evaluation.evaluator INFO: Inference done 624/1093. Dataloading: 0.0147 s/iter. Inference: 0.1891 s/iter. Eval: 0.0217 s/iter. Total: 0.2255 s/iter. ETA=0:01:45
[01/17 17:10:17] detectron2.evaluation.evaluator INFO: Inference done 647/1093. Dataloading: 0.0147 s/iter. Inference: 0.1888 s/iter. Eval: 0.0217 s/iter. Total: 0.2253 s/iter. ETA=0:01:40
[01/17 17:10:22] detectron2.evaluation.evaluator INFO: Inference done 670/1093. Dataloading: 0.0146 s/iter. Inference: 0.1887 s/iter. Eval: 0.0217 s/iter. Total: 0.2251 s/iter. ETA=0:01:35
[01/17 17:10:27] detectron2.evaluation.evaluator INFO: Inference done 691/1093. Dataloading: 0.0147 s/iter. Inference: 0.1891 s/iter. Eval: 0.0217 s/iter. Total: 0.2256 s/iter. ETA=0:01:30
[01/17 17:10:32] detectron2.evaluation.evaluator INFO: Inference done 713/1093. Dataloading: 0.0147 s/iter. Inference: 0.1893 s/iter. Eval: 0.0217 s/iter. Total: 0.2258 s/iter. ETA=0:01:25
[01/17 17:10:37] detectron2.evaluation.evaluator INFO: Inference done 738/1093. Dataloading: 0.0146 s/iter. Inference: 0.1886 s/iter. Eval: 0.0216 s/iter. Total: 0.2249 s/iter. ETA=0:01:19
[01/17 17:10:43] detectron2.evaluation.evaluator INFO: Inference done 761/1093. Dataloading: 0.0145 s/iter. Inference: 0.1887 s/iter. Eval: 0.0216 s/iter. Total: 0.2249 s/iter. ETA=0:01:14
[01/17 17:10:48] detectron2.evaluation.evaluator INFO: Inference done 784/1093. Dataloading: 0.0145 s/iter. Inference: 0.1885 s/iter. Eval: 0.0216 s/iter. Total: 0.2247 s/iter. ETA=0:01:09
[01/17 17:10:53] detectron2.evaluation.evaluator INFO: Inference done 807/1093. Dataloading: 0.0145 s/iter. Inference: 0.1885 s/iter. Eval: 0.0217 s/iter. Total: 0.2247 s/iter. ETA=0:01:04
[01/17 17:10:58] detectron2.evaluation.evaluator INFO: Inference done 828/1093. Dataloading: 0.0144 s/iter. Inference: 0.1890 s/iter. Eval: 0.0218 s/iter. Total: 0.2252 s/iter. ETA=0:00:59
[01/17 17:11:03] detectron2.evaluation.evaluator INFO: Inference done 849/1093. Dataloading: 0.0144 s/iter. Inference: 0.1893 s/iter. Eval: 0.0218 s/iter. Total: 0.2256 s/iter. ETA=0:00:55
[01/17 17:11:08] detectron2.evaluation.evaluator INFO: Inference done 872/1093. Dataloading: 0.0145 s/iter. Inference: 0.1892 s/iter. Eval: 0.0219 s/iter. Total: 0.2256 s/iter. ETA=0:00:49
[01/17 17:11:13] detectron2.evaluation.evaluator INFO: Inference done 893/1093. Dataloading: 0.0145 s/iter. Inference: 0.1895 s/iter. Eval: 0.0219 s/iter. Total: 0.2260 s/iter. ETA=0:00:45
[01/17 17:11:18] detectron2.evaluation.evaluator INFO: Inference done 915/1093. Dataloading: 0.0145 s/iter. Inference: 0.1897 s/iter. Eval: 0.0219 s/iter. Total: 0.2262 s/iter. ETA=0:00:40
[01/17 17:11:24] detectron2.evaluation.evaluator INFO: Inference done 936/1093. Dataloading: 0.0146 s/iter. Inference: 0.1900 s/iter. Eval: 0.0220 s/iter. Total: 0.2266 s/iter. ETA=0:00:35
[01/17 17:11:29] detectron2.evaluation.evaluator INFO: Inference done 960/1093. Dataloading: 0.0146 s/iter. Inference: 0.1896 s/iter. Eval: 0.0219 s/iter. Total: 0.2262 s/iter. ETA=0:00:30
[01/17 17:11:34] detectron2.evaluation.evaluator INFO: Inference done 985/1093. Dataloading: 0.0145 s/iter. Inference: 0.1891 s/iter. Eval: 0.0219 s/iter. Total: 0.2256 s/iter. ETA=0:00:24
[01/17 17:11:39] detectron2.evaluation.evaluator INFO: Inference done 1007/1093. Dataloading: 0.0145 s/iter. Inference: 0.1893 s/iter. Eval: 0.0219 s/iter. Total: 0.2258 s/iter. ETA=0:00:19
[01/17 17:11:44] detectron2.evaluation.evaluator INFO: Inference done 1029/1093. Dataloading: 0.0145 s/iter. Inference: 0.1896 s/iter. Eval: 0.0219 s/iter. Total: 0.2261 s/iter. ETA=0:00:14
[01/17 17:11:49] detectron2.evaluation.evaluator INFO: Inference done 1052/1093. Dataloading: 0.0144 s/iter. Inference: 0.1897 s/iter. Eval: 0.0219 s/iter. Total: 0.2261 s/iter. ETA=0:00:09
[01/17 17:11:54] detectron2.evaluation.evaluator INFO: Inference done 1073/1093. Dataloading: 0.0144 s/iter. Inference: 0.1899 s/iter. Eval: 0.0220 s/iter. Total: 0.2264 s/iter. ETA=0:00:04
[01/17 17:11:59] detectron2.evaluation.evaluator INFO: Total inference time: 0:04:06.602634 (0.226657 s / iter per device, on 4 devices)
[01/17 17:11:59] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:26 (0.189849 s / iter per device, on 4 devices)
[01/17 17:12:39] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 17:12:39] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 17:12:39] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 17:12:40] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 17:12:53] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0114 s/iter. Inference: 0.2012 s/iter. Eval: 0.0277 s/iter. Total: 0.2403 s/iter. ETA=0:04:19
[01/17 17:12:58] detectron2.evaluation.evaluator INFO: Inference done 32/1093. Dataloading: 0.0173 s/iter. Inference: 0.2001 s/iter. Eval: 0.0242 s/iter. Total: 0.2417 s/iter. ETA=0:04:16
[01/17 17:13:03] detectron2.evaluation.evaluator INFO: Inference done 56/1093. Dataloading: 0.0159 s/iter. Inference: 0.1906 s/iter. Eval: 0.0244 s/iter. Total: 0.2310 s/iter. ETA=0:03:59
[01/17 17:13:08] detectron2.evaluation.evaluator INFO: Inference done 79/1093. Dataloading: 0.0162 s/iter. Inference: 0.1883 s/iter. Eval: 0.0238 s/iter. Total: 0.2283 s/iter. ETA=0:03:51
[01/17 17:13:13] detectron2.evaluation.evaluator INFO: Inference done 101/1093. Dataloading: 0.0150 s/iter. Inference: 0.1904 s/iter. Eval: 0.0233 s/iter. Total: 0.2288 s/iter. ETA=0:03:46
[01/17 17:13:18] detectron2.evaluation.evaluator INFO: Inference done 119/1093. Dataloading: 0.0149 s/iter. Inference: 0.1982 s/iter. Eval: 0.0235 s/iter. Total: 0.2366 s/iter. ETA=0:03:50
[01/17 17:13:23] detectron2.evaluation.evaluator INFO: Inference done 138/1093. Dataloading: 0.0149 s/iter. Inference: 0.2034 s/iter. Eval: 0.0231 s/iter. Total: 0.2415 s/iter. ETA=0:03:50
[01/17 17:13:29] detectron2.evaluation.evaluator INFO: Inference done 159/1093. Dataloading: 0.0144 s/iter. Inference: 0.2035 s/iter. Eval: 0.0231 s/iter. Total: 0.2411 s/iter. ETA=0:03:45
[01/17 17:13:34] detectron2.evaluation.evaluator INFO: Inference done 181/1093. Dataloading: 0.0142 s/iter. Inference: 0.2030 s/iter. Eval: 0.0229 s/iter. Total: 0.2402 s/iter. ETA=0:03:39
[01/17 17:13:39] detectron2.evaluation.evaluator INFO: Inference done 203/1093. Dataloading: 0.0147 s/iter. Inference: 0.2013 s/iter. Eval: 0.0230 s/iter. Total: 0.2391 s/iter. ETA=0:03:32
[01/17 17:13:44] detectron2.evaluation.evaluator INFO: Inference done 222/1093. Dataloading: 0.0145 s/iter. Inference: 0.2045 s/iter. Eval: 0.0231 s/iter. Total: 0.2421 s/iter. ETA=0:03:30
[01/17 17:13:49] detectron2.evaluation.evaluator INFO: Inference done 243/1093. Dataloading: 0.0144 s/iter. Inference: 0.2050 s/iter. Eval: 0.0231 s/iter. Total: 0.2426 s/iter. ETA=0:03:26
[01/17 17:13:54] detectron2.evaluation.evaluator INFO: Inference done 263/1093. Dataloading: 0.0144 s/iter. Inference: 0.2058 s/iter. Eval: 0.0230 s/iter. Total: 0.2433 s/iter. ETA=0:03:21
[01/17 17:13:59] detectron2.evaluation.evaluator INFO: Inference done 276/1093. Dataloading: 0.0146 s/iter. Inference: 0.2125 s/iter. Eval: 0.0234 s/iter. Total: 0.2506 s/iter. ETA=0:03:24
[01/17 17:14:04] detectron2.evaluation.evaluator INFO: Inference done 290/1093. Dataloading: 0.0150 s/iter. Inference: 0.2170 s/iter. Eval: 0.0244 s/iter. Total: 0.2564 s/iter. ETA=0:03:25
[01/17 17:14:09] detectron2.evaluation.evaluator INFO: Inference done 301/1093. Dataloading: 0.0152 s/iter. Inference: 0.2238 s/iter. Eval: 0.0247 s/iter. Total: 0.2639 s/iter. ETA=0:03:28
[01/17 17:14:15] detectron2.evaluation.evaluator INFO: Inference done 314/1093. Dataloading: 0.0152 s/iter. Inference: 0.2285 s/iter. Eval: 0.0255 s/iter. Total: 0.2693 s/iter. ETA=0:03:29
[01/17 17:14:20] detectron2.evaluation.evaluator INFO: Inference done 328/1093. Dataloading: 0.0157 s/iter. Inference: 0.2324 s/iter. Eval: 0.0257 s/iter. Total: 0.2738 s/iter. ETA=0:03:29
[01/17 17:14:25] detectron2.evaluation.evaluator INFO: Inference done 346/1093. Dataloading: 0.0158 s/iter. Inference: 0.2326 s/iter. Eval: 0.0260 s/iter. Total: 0.2745 s/iter. ETA=0:03:25
[01/17 17:14:30] detectron2.evaluation.evaluator INFO: Inference done 365/1093. Dataloading: 0.0156 s/iter. Inference: 0.2330 s/iter. Eval: 0.0259 s/iter. Total: 0.2746 s/iter. ETA=0:03:19
[01/17 17:14:35] detectron2.evaluation.evaluator INFO: Inference done 383/1093. Dataloading: 0.0158 s/iter. Inference: 0.2331 s/iter. Eval: 0.0261 s/iter. Total: 0.2751 s/iter. ETA=0:03:15
[01/17 17:14:41] detectron2.evaluation.evaluator INFO: Inference done 405/1093. Dataloading: 0.0159 s/iter. Inference: 0.2309 s/iter. Eval: 0.0259 s/iter. Total: 0.2728 s/iter. ETA=0:03:07
[01/17 17:14:46] detectron2.evaluation.evaluator INFO: Inference done 428/1093. Dataloading: 0.0159 s/iter. Inference: 0.2282 s/iter. Eval: 0.0257 s/iter. Total: 0.2699 s/iter. ETA=0:02:59
[01/17 17:14:51] detectron2.evaluation.evaluator INFO: Inference done 447/1093. Dataloading: 0.0159 s/iter. Inference: 0.2280 s/iter. Eval: 0.0257 s/iter. Total: 0.2697 s/iter. ETA=0:02:54
[01/17 17:14:56] detectron2.evaluation.evaluator INFO: Inference done 468/1093. Dataloading: 0.0159 s/iter. Inference: 0.2271 s/iter. Eval: 0.0257 s/iter. Total: 0.2687 s/iter. ETA=0:02:47
[01/17 17:15:01] detectron2.evaluation.evaluator INFO: Inference done 489/1093. Dataloading: 0.0158 s/iter. Inference: 0.2260 s/iter. Eval: 0.0256 s/iter. Total: 0.2676 s/iter. ETA=0:02:41
[01/17 17:15:06] detectron2.evaluation.evaluator INFO: Inference done 508/1093. Dataloading: 0.0157 s/iter. Inference: 0.2260 s/iter. Eval: 0.0256 s/iter. Total: 0.2674 s/iter. ETA=0:02:36
[01/17 17:15:11] detectron2.evaluation.evaluator INFO: Inference done 528/1093. Dataloading: 0.0158 s/iter. Inference: 0.2255 s/iter. Eval: 0.0255 s/iter. Total: 0.2669 s/iter. ETA=0:02:30
[01/17 17:15:16] detectron2.evaluation.evaluator INFO: Inference done 549/1093. Dataloading: 0.0157 s/iter. Inference: 0.2246 s/iter. Eval: 0.0255 s/iter. Total: 0.2659 s/iter. ETA=0:02:24
[01/17 17:15:21] detectron2.evaluation.evaluator INFO: Inference done 570/1093. Dataloading: 0.0157 s/iter. Inference: 0.2240 s/iter. Eval: 0.0253 s/iter. Total: 0.2652 s/iter. ETA=0:02:18
[01/17 17:15:26] detectron2.evaluation.evaluator INFO: Inference done 590/1093. Dataloading: 0.0159 s/iter. Inference: 0.2236 s/iter. Eval: 0.0255 s/iter. Total: 0.2651 s/iter. ETA=0:02:13
[01/17 17:15:32] detectron2.evaluation.evaluator INFO: Inference done 609/1093. Dataloading: 0.0159 s/iter. Inference: 0.2236 s/iter. Eval: 0.0255 s/iter. Total: 0.2651 s/iter. ETA=0:02:08
[01/17 17:15:37] detectron2.evaluation.evaluator INFO: Inference done 630/1093. Dataloading: 0.0158 s/iter. Inference: 0.2229 s/iter. Eval: 0.0256 s/iter. Total: 0.2644 s/iter. ETA=0:02:02
[01/17 17:15:42] detectron2.evaluation.evaluator INFO: Inference done 650/1093. Dataloading: 0.0158 s/iter. Inference: 0.2224 s/iter. Eval: 0.0256 s/iter. Total: 0.2640 s/iter. ETA=0:01:56
[01/17 17:15:47] detectron2.evaluation.evaluator INFO: Inference done 670/1093. Dataloading: 0.0159 s/iter. Inference: 0.2221 s/iter. Eval: 0.0257 s/iter. Total: 0.2638 s/iter. ETA=0:01:51
[01/17 17:15:52] detectron2.evaluation.evaluator INFO: Inference done 691/1093. Dataloading: 0.0160 s/iter. Inference: 0.2214 s/iter. Eval: 0.0256 s/iter. Total: 0.2631 s/iter. ETA=0:01:45
[01/17 17:15:57] detectron2.evaluation.evaluator INFO: Inference done 711/1093. Dataloading: 0.0160 s/iter. Inference: 0.2211 s/iter. Eval: 0.0257 s/iter. Total: 0.2630 s/iter. ETA=0:01:40
[01/17 17:16:02] detectron2.evaluation.evaluator INFO: Inference done 731/1093. Dataloading: 0.0161 s/iter. Inference: 0.2209 s/iter. Eval: 0.0259 s/iter. Total: 0.2629 s/iter. ETA=0:01:35
[01/17 17:16:08] detectron2.evaluation.evaluator INFO: Inference done 750/1093. Dataloading: 0.0160 s/iter. Inference: 0.2211 s/iter. Eval: 0.0261 s/iter. Total: 0.2633 s/iter. ETA=0:01:30
[01/17 17:16:13] detectron2.evaluation.evaluator INFO: Inference done 771/1093. Dataloading: 0.0160 s/iter. Inference: 0.2206 s/iter. Eval: 0.0261 s/iter. Total: 0.2627 s/iter. ETA=0:01:24
[01/17 17:16:18] detectron2.evaluation.evaluator INFO: Inference done 792/1093. Dataloading: 0.0159 s/iter. Inference: 0.2200 s/iter. Eval: 0.0261 s/iter. Total: 0.2621 s/iter. ETA=0:01:18
[01/17 17:16:23] detectron2.evaluation.evaluator INFO: Inference done 812/1093. Dataloading: 0.0158 s/iter. Inference: 0.2202 s/iter. Eval: 0.0260 s/iter. Total: 0.2622 s/iter. ETA=0:01:13
[01/17 17:16:28] detectron2.evaluation.evaluator INFO: Inference done 832/1093. Dataloading: 0.0159 s/iter. Inference: 0.2201 s/iter. Eval: 0.0260 s/iter. Total: 0.2621 s/iter. ETA=0:01:08
[01/17 17:16:33] detectron2.evaluation.evaluator INFO: Inference done 853/1093. Dataloading: 0.0158 s/iter. Inference: 0.2199 s/iter. Eval: 0.0260 s/iter. Total: 0.2618 s/iter. ETA=0:01:02
[01/17 17:16:39] detectron2.evaluation.evaluator INFO: Inference done 872/1093. Dataloading: 0.0158 s/iter. Inference: 0.2202 s/iter. Eval: 0.0260 s/iter. Total: 0.2621 s/iter. ETA=0:00:57
[01/17 17:16:44] detectron2.evaluation.evaluator INFO: Inference done 892/1093. Dataloading: 0.0157 s/iter. Inference: 0.2203 s/iter. Eval: 0.0259 s/iter. Total: 0.2621 s/iter. ETA=0:00:52
[01/17 17:16:49] detectron2.evaluation.evaluator INFO: Inference done 912/1093. Dataloading: 0.0157 s/iter. Inference: 0.2201 s/iter. Eval: 0.0259 s/iter. Total: 0.2618 s/iter. ETA=0:00:47
[01/17 17:16:54] detectron2.evaluation.evaluator INFO: Inference done 930/1093. Dataloading: 0.0157 s/iter. Inference: 0.2204 s/iter. Eval: 0.0259 s/iter. Total: 0.2622 s/iter. ETA=0:00:42
[01/17 17:16:59] detectron2.evaluation.evaluator INFO: Inference done 950/1093. Dataloading: 0.0158 s/iter. Inference: 0.2201 s/iter. Eval: 0.0260 s/iter. Total: 0.2620 s/iter. ETA=0:00:37
[01/17 17:17:04] detectron2.evaluation.evaluator INFO: Inference done 970/1093. Dataloading: 0.0158 s/iter. Inference: 0.2199 s/iter. Eval: 0.0261 s/iter. Total: 0.2619 s/iter. ETA=0:00:32
[01/17 17:17:09] detectron2.evaluation.evaluator INFO: Inference done 990/1093. Dataloading: 0.0158 s/iter. Inference: 0.2198 s/iter. Eval: 0.0261 s/iter. Total: 0.2617 s/iter. ETA=0:00:26
[01/17 17:17:14] detectron2.evaluation.evaluator INFO: Inference done 1007/1093. Dataloading: 0.0158 s/iter. Inference: 0.2203 s/iter. Eval: 0.0262 s/iter. Total: 0.2623 s/iter. ETA=0:00:22
[01/17 17:17:19] detectron2.evaluation.evaluator INFO: Inference done 1026/1093. Dataloading: 0.0157 s/iter. Inference: 0.2203 s/iter. Eval: 0.0262 s/iter. Total: 0.2623 s/iter. ETA=0:00:17
[01/17 17:17:24] detectron2.evaluation.evaluator INFO: Inference done 1046/1093. Dataloading: 0.0157 s/iter. Inference: 0.2201 s/iter. Eval: 0.0263 s/iter. Total: 0.2622 s/iter. ETA=0:00:12
[01/17 17:17:30] detectron2.evaluation.evaluator INFO: Inference done 1060/1093. Dataloading: 0.0158 s/iter. Inference: 0.2215 s/iter. Eval: 0.0263 s/iter. Total: 0.2637 s/iter. ETA=0:00:08
[01/17 17:17:35] detectron2.evaluation.evaluator INFO: Inference done 1072/1093. Dataloading: 0.0159 s/iter. Inference: 0.2232 s/iter. Eval: 0.0263 s/iter. Total: 0.2655 s/iter. ETA=0:00:05
[01/17 17:17:40] detectron2.evaluation.evaluator INFO: Inference done 1083/1093. Dataloading: 0.0160 s/iter. Inference: 0.2249 s/iter. Eval: 0.0264 s/iter. Total: 0.2674 s/iter. ETA=0:00:02
[01/17 17:17:44] detectron2.evaluation.evaluator INFO: Total inference time: 0:04:52.692512 (0.269019 s / iter per device, on 4 devices)
[01/17 17:17:44] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:04:05 (0.226040 s / iter per device, on 4 devices)
[01/17 17:18:24] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 17:18:25] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 17:18:25] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 17:18:26] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 17:18:38] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0123 s/iter. Inference: 0.2026 s/iter. Eval: 0.0253 s/iter. Total: 0.2402 s/iter. ETA=0:04:19
[01/17 17:18:43] detectron2.evaluation.evaluator INFO: Inference done 31/1093. Dataloading: 0.0222 s/iter. Inference: 0.2088 s/iter. Eval: 0.0212 s/iter. Total: 0.2524 s/iter. ETA=0:04:28
[01/17 17:18:48] detectron2.evaluation.evaluator INFO: Inference done 49/1093. Dataloading: 0.0225 s/iter. Inference: 0.2215 s/iter. Eval: 0.0207 s/iter. Total: 0.2651 s/iter. ETA=0:04:36
[01/17 17:18:53] detectron2.evaluation.evaluator INFO: Inference done 68/1093. Dataloading: 0.0204 s/iter. Inference: 0.2240 s/iter. Eval: 0.0202 s/iter. Total: 0.2649 s/iter. ETA=0:04:31
[01/17 17:18:58] detectron2.evaluation.evaluator INFO: Inference done 85/1093. Dataloading: 0.0198 s/iter. Inference: 0.2318 s/iter. Eval: 0.0200 s/iter. Total: 0.2719 s/iter. ETA=0:04:34
[01/17 17:19:03] detectron2.evaluation.evaluator INFO: Inference done 104/1093. Dataloading: 0.0188 s/iter. Inference: 0.2338 s/iter. Eval: 0.0201 s/iter. Total: 0.2729 s/iter. ETA=0:04:29
[01/17 17:19:08] detectron2.evaluation.evaluator INFO: Inference done 124/1093. Dataloading: 0.0178 s/iter. Inference: 0.2324 s/iter. Eval: 0.0200 s/iter. Total: 0.2705 s/iter. ETA=0:04:22
[01/17 17:19:13] detectron2.evaluation.evaluator INFO: Inference done 144/1093. Dataloading: 0.0175 s/iter. Inference: 0.2293 s/iter. Eval: 0.0207 s/iter. Total: 0.2677 s/iter. ETA=0:04:14
[01/17 17:19:18] detectron2.evaluation.evaluator INFO: Inference done 163/1093. Dataloading: 0.0181 s/iter. Inference: 0.2283 s/iter. Eval: 0.0212 s/iter. Total: 0.2678 s/iter. ETA=0:04:09
[01/17 17:19:24] detectron2.evaluation.evaluator INFO: Inference done 184/1093. Dataloading: 0.0175 s/iter. Inference: 0.2265 s/iter. Eval: 0.0210 s/iter. Total: 0.2651 s/iter. ETA=0:04:01
[01/17 17:19:29] detectron2.evaluation.evaluator INFO: Inference done 203/1093. Dataloading: 0.0178 s/iter. Inference: 0.2264 s/iter. Eval: 0.0213 s/iter. Total: 0.2656 s/iter. ETA=0:03:56
[01/17 17:19:34] detectron2.evaluation.evaluator INFO: Inference done 223/1093. Dataloading: 0.0178 s/iter. Inference: 0.2257 s/iter. Eval: 0.0212 s/iter. Total: 0.2650 s/iter. ETA=0:03:50
[01/17 17:19:39] detectron2.evaluation.evaluator INFO: Inference done 242/1093. Dataloading: 0.0177 s/iter. Inference: 0.2269 s/iter. Eval: 0.0212 s/iter. Total: 0.2660 s/iter. ETA=0:03:46
[01/17 17:19:44] detectron2.evaluation.evaluator INFO: Inference done 262/1093. Dataloading: 0.0175 s/iter. Inference: 0.2265 s/iter. Eval: 0.0211 s/iter. Total: 0.2652 s/iter. ETA=0:03:40
[01/17 17:19:49] detectron2.evaluation.evaluator INFO: Inference done 281/1093. Dataloading: 0.0175 s/iter. Inference: 0.2267 s/iter. Eval: 0.0211 s/iter. Total: 0.2654 s/iter. ETA=0:03:35
[01/17 17:19:55] detectron2.evaluation.evaluator INFO: Inference done 302/1093. Dataloading: 0.0174 s/iter. Inference: 0.2257 s/iter. Eval: 0.0209 s/iter. Total: 0.2641 s/iter. ETA=0:03:28
[01/17 17:20:00] detectron2.evaluation.evaluator INFO: Inference done 323/1093. Dataloading: 0.0172 s/iter. Inference: 0.2250 s/iter. Eval: 0.0208 s/iter. Total: 0.2632 s/iter. ETA=0:03:22
[01/17 17:20:05] detectron2.evaluation.evaluator INFO: Inference done 342/1093. Dataloading: 0.0172 s/iter. Inference: 0.2253 s/iter. Eval: 0.0206 s/iter. Total: 0.2632 s/iter. ETA=0:03:17
[01/17 17:20:10] detectron2.evaluation.evaluator INFO: Inference done 360/1093. Dataloading: 0.0174 s/iter. Inference: 0.2258 s/iter. Eval: 0.0209 s/iter. Total: 0.2642 s/iter. ETA=0:03:13
[01/17 17:20:15] detectron2.evaluation.evaluator INFO: Inference done 379/1093. Dataloading: 0.0176 s/iter. Inference: 0.2257 s/iter. Eval: 0.0213 s/iter. Total: 0.2648 s/iter. ETA=0:03:09
[01/17 17:20:20] detectron2.evaluation.evaluator INFO: Inference done 397/1093. Dataloading: 0.0175 s/iter. Inference: 0.2263 s/iter. Eval: 0.0214 s/iter. Total: 0.2654 s/iter. ETA=0:03:04
[01/17 17:20:25] detectron2.evaluation.evaluator INFO: Inference done 417/1093. Dataloading: 0.0175 s/iter. Inference: 0.2260 s/iter. Eval: 0.0213 s/iter. Total: 0.2650 s/iter. ETA=0:02:59
[01/17 17:20:30] detectron2.evaluation.evaluator INFO: Inference done 435/1093. Dataloading: 0.0176 s/iter. Inference: 0.2269 s/iter. Eval: 0.0214 s/iter. Total: 0.2659 s/iter. ETA=0:02:54
[01/17 17:20:36] detectron2.evaluation.evaluator INFO: Inference done 453/1093. Dataloading: 0.0174 s/iter. Inference: 0.2276 s/iter. Eval: 0.0214 s/iter. Total: 0.2665 s/iter. ETA=0:02:50
[01/17 17:20:41] detectron2.evaluation.evaluator INFO: Inference done 473/1093. Dataloading: 0.0172 s/iter. Inference: 0.2272 s/iter. Eval: 0.0214 s/iter. Total: 0.2659 s/iter. ETA=0:02:44
[01/17 17:20:46] detectron2.evaluation.evaluator INFO: Inference done 490/1093. Dataloading: 0.0172 s/iter. Inference: 0.2286 s/iter. Eval: 0.0215 s/iter. Total: 0.2674 s/iter. ETA=0:02:41
[01/17 17:20:51] detectron2.evaluation.evaluator INFO: Inference done 509/1093. Dataloading: 0.0171 s/iter. Inference: 0.2290 s/iter. Eval: 0.0215 s/iter. Total: 0.2677 s/iter. ETA=0:02:36
[01/17 17:20:56] detectron2.evaluation.evaluator INFO: Inference done 527/1093. Dataloading: 0.0173 s/iter. Inference: 0.2292 s/iter. Eval: 0.0215 s/iter. Total: 0.2682 s/iter. ETA=0:02:31
[01/17 17:21:01] detectron2.evaluation.evaluator INFO: Inference done 546/1093. Dataloading: 0.0173 s/iter. Inference: 0.2293 s/iter. Eval: 0.0214 s/iter. Total: 0.2682 s/iter. ETA=0:02:26
[01/17 17:21:06] detectron2.evaluation.evaluator INFO: Inference done 566/1093. Dataloading: 0.0171 s/iter. Inference: 0.2294 s/iter. Eval: 0.0213 s/iter. Total: 0.2679 s/iter. ETA=0:02:21
[01/17 17:21:11] detectron2.evaluation.evaluator INFO: Inference done 586/1093. Dataloading: 0.0170 s/iter. Inference: 0.2290 s/iter. Eval: 0.0212 s/iter. Total: 0.2674 s/iter. ETA=0:02:15
[01/17 17:21:17] detectron2.evaluation.evaluator INFO: Inference done 604/1093. Dataloading: 0.0170 s/iter. Inference: 0.2295 s/iter. Eval: 0.0212 s/iter. Total: 0.2679 s/iter. ETA=0:02:10
[01/17 17:21:22] detectron2.evaluation.evaluator INFO: Inference done 623/1093. Dataloading: 0.0169 s/iter. Inference: 0.2297 s/iter. Eval: 0.0212 s/iter. Total: 0.2679 s/iter. ETA=0:02:05
[01/17 17:21:27] detectron2.evaluation.evaluator INFO: Inference done 642/1093. Dataloading: 0.0168 s/iter. Inference: 0.2295 s/iter. Eval: 0.0214 s/iter. Total: 0.2678 s/iter. ETA=0:02:00
[01/17 17:21:32] detectron2.evaluation.evaluator INFO: Inference done 659/1093. Dataloading: 0.0169 s/iter. Inference: 0.2304 s/iter. Eval: 0.0212 s/iter. Total: 0.2686 s/iter. ETA=0:01:56
[01/17 17:21:37] detectron2.evaluation.evaluator INFO: Inference done 677/1093. Dataloading: 0.0168 s/iter. Inference: 0.2309 s/iter. Eval: 0.0212 s/iter. Total: 0.2690 s/iter. ETA=0:01:51
[01/17 17:21:42] detectron2.evaluation.evaluator INFO: Inference done 696/1093. Dataloading: 0.0167 s/iter. Inference: 0.2311 s/iter. Eval: 0.0211 s/iter. Total: 0.2691 s/iter. ETA=0:01:46
[01/17 17:21:47] detectron2.evaluation.evaluator INFO: Inference done 714/1093. Dataloading: 0.0166 s/iter. Inference: 0.2318 s/iter. Eval: 0.0210 s/iter. Total: 0.2696 s/iter. ETA=0:01:42
[01/17 17:21:52] detectron2.evaluation.evaluator INFO: Inference done 733/1093. Dataloading: 0.0166 s/iter. Inference: 0.2318 s/iter. Eval: 0.0211 s/iter. Total: 0.2695 s/iter. ETA=0:01:37
[01/17 17:21:57] detectron2.evaluation.evaluator INFO: Inference done 751/1093. Dataloading: 0.0165 s/iter. Inference: 0.2320 s/iter. Eval: 0.0211 s/iter. Total: 0.2698 s/iter. ETA=0:01:32
[01/17 17:22:03] detectron2.evaluation.evaluator INFO: Inference done 769/1093. Dataloading: 0.0167 s/iter. Inference: 0.2321 s/iter. Eval: 0.0212 s/iter. Total: 0.2702 s/iter. ETA=0:01:27
[01/17 17:22:08] detectron2.evaluation.evaluator INFO: Inference done 788/1093. Dataloading: 0.0167 s/iter. Inference: 0.2322 s/iter. Eval: 0.0212 s/iter. Total: 0.2702 s/iter. ETA=0:01:22
[01/17 17:22:13] detectron2.evaluation.evaluator INFO: Inference done 807/1093. Dataloading: 0.0168 s/iter. Inference: 0.2320 s/iter. Eval: 0.0213 s/iter. Total: 0.2703 s/iter. ETA=0:01:17
[01/17 17:22:18] detectron2.evaluation.evaluator INFO: Inference done 827/1093. Dataloading: 0.0167 s/iter. Inference: 0.2320 s/iter. Eval: 0.0213 s/iter. Total: 0.2701 s/iter. ETA=0:01:11
[01/17 17:22:23] detectron2.evaluation.evaluator INFO: Inference done 846/1093. Dataloading: 0.0167 s/iter. Inference: 0.2319 s/iter. Eval: 0.0213 s/iter. Total: 0.2699 s/iter. ETA=0:01:06
[01/17 17:22:28] detectron2.evaluation.evaluator INFO: Inference done 865/1093. Dataloading: 0.0166 s/iter. Inference: 0.2320 s/iter. Eval: 0.0213 s/iter. Total: 0.2700 s/iter. ETA=0:01:01
[01/17 17:22:33] detectron2.evaluation.evaluator INFO: Inference done 883/1093. Dataloading: 0.0165 s/iter. Inference: 0.2324 s/iter. Eval: 0.0212 s/iter. Total: 0.2703 s/iter. ETA=0:00:56
[01/17 17:22:39] detectron2.evaluation.evaluator INFO: Inference done 902/1093. Dataloading: 0.0165 s/iter. Inference: 0.2325 s/iter. Eval: 0.0212 s/iter. Total: 0.2704 s/iter. ETA=0:00:51
[01/17 17:22:44] detectron2.evaluation.evaluator INFO: Inference done 921/1093. Dataloading: 0.0165 s/iter. Inference: 0.2326 s/iter. Eval: 0.0213 s/iter. Total: 0.2705 s/iter. ETA=0:00:46
[01/17 17:22:49] detectron2.evaluation.evaluator INFO: Inference done 940/1093. Dataloading: 0.0165 s/iter. Inference: 0.2325 s/iter. Eval: 0.0212 s/iter. Total: 0.2704 s/iter. ETA=0:00:41
[01/17 17:22:54] detectron2.evaluation.evaluator INFO: Inference done 958/1093. Dataloading: 0.0164 s/iter. Inference: 0.2329 s/iter. Eval: 0.0213 s/iter. Total: 0.2707 s/iter. ETA=0:00:36
[01/17 17:22:59] detectron2.evaluation.evaluator INFO: Inference done 977/1093. Dataloading: 0.0164 s/iter. Inference: 0.2329 s/iter. Eval: 0.0213 s/iter. Total: 0.2707 s/iter. ETA=0:00:31
[01/17 17:23:04] detectron2.evaluation.evaluator INFO: Inference done 995/1093. Dataloading: 0.0164 s/iter. Inference: 0.2331 s/iter. Eval: 0.0212 s/iter. Total: 0.2709 s/iter. ETA=0:00:26
[01/17 17:23:10] detectron2.evaluation.evaluator INFO: Inference done 1016/1093. Dataloading: 0.0164 s/iter. Inference: 0.2327 s/iter. Eval: 0.0212 s/iter. Total: 0.2705 s/iter. ETA=0:00:20
[01/17 17:23:15] detectron2.evaluation.evaluator INFO: Inference done 1036/1093. Dataloading: 0.0163 s/iter. Inference: 0.2327 s/iter. Eval: 0.0212 s/iter. Total: 0.2703 s/iter. ETA=0:00:15
[01/17 17:23:20] detectron2.evaluation.evaluator INFO: Inference done 1056/1093. Dataloading: 0.0163 s/iter. Inference: 0.2326 s/iter. Eval: 0.0212 s/iter. Total: 0.2702 s/iter. ETA=0:00:09
[01/17 17:23:25] detectron2.evaluation.evaluator INFO: Inference done 1075/1093. Dataloading: 0.0163 s/iter. Inference: 0.2326 s/iter. Eval: 0.0212 s/iter. Total: 0.2702 s/iter. ETA=0:00:04
[01/17 17:23:30] detectron2.evaluation.evaluator INFO: Total inference time: 0:04:53.706825 (0.269951 s / iter per device, on 4 devices)
[01/17 17:23:30] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:04:12 (0.231996 s / iter per device, on 4 devices)
[01/17 17:24:07] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 17:24:07] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 17:24:07] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 17:24:08] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 17:24:21] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0117 s/iter. Inference: 0.2209 s/iter. Eval: 0.0215 s/iter. Total: 0.2542 s/iter. ETA=0:04:35
[01/17 17:24:26] detectron2.evaluation.evaluator INFO: Inference done 29/1093. Dataloading: 0.0176 s/iter. Inference: 0.2334 s/iter. Eval: 0.0244 s/iter. Total: 0.2756 s/iter. ETA=0:04:53
[01/17 17:24:31] detectron2.evaluation.evaluator INFO: Inference done 48/1093. Dataloading: 0.0182 s/iter. Inference: 0.2306 s/iter. Eval: 0.0245 s/iter. Total: 0.2734 s/iter. ETA=0:04:45
[01/17 17:24:36] detectron2.evaluation.evaluator INFO: Inference done 66/1093. Dataloading: 0.0182 s/iter. Inference: 0.2386 s/iter. Eval: 0.0225 s/iter. Total: 0.2794 s/iter. ETA=0:04:46
[01/17 17:24:41] detectron2.evaluation.evaluator INFO: Inference done 84/1093. Dataloading: 0.0176 s/iter. Inference: 0.2394 s/iter. Eval: 0.0221 s/iter. Total: 0.2792 s/iter. ETA=0:04:41
[01/17 17:24:47] detectron2.evaluation.evaluator INFO: Inference done 102/1093. Dataloading: 0.0172 s/iter. Inference: 0.2412 s/iter. Eval: 0.0222 s/iter. Total: 0.2807 s/iter. ETA=0:04:38
[01/17 17:24:52] detectron2.evaluation.evaluator INFO: Inference done 121/1093. Dataloading: 0.0172 s/iter. Inference: 0.2388 s/iter. Eval: 0.0221 s/iter. Total: 0.2782 s/iter. ETA=0:04:30
[01/17 17:24:57] detectron2.evaluation.evaluator INFO: Inference done 140/1093. Dataloading: 0.0166 s/iter. Inference: 0.2390 s/iter. Eval: 0.0218 s/iter. Total: 0.2775 s/iter. ETA=0:04:24
[01/17 17:25:02] detectron2.evaluation.evaluator INFO: Inference done 159/1093. Dataloading: 0.0163 s/iter. Inference: 0.2390 s/iter. Eval: 0.0214 s/iter. Total: 0.2768 s/iter. ETA=0:04:18
[01/17 17:25:07] detectron2.evaluation.evaluator INFO: Inference done 180/1093. Dataloading: 0.0159 s/iter. Inference: 0.2361 s/iter. Eval: 0.0213 s/iter. Total: 0.2735 s/iter. ETA=0:04:09
[01/17 17:25:12] detectron2.evaluation.evaluator INFO: Inference done 198/1093. Dataloading: 0.0157 s/iter. Inference: 0.2369 s/iter. Eval: 0.0215 s/iter. Total: 0.2743 s/iter. ETA=0:04:05
[01/17 17:25:17] detectron2.evaluation.evaluator INFO: Inference done 217/1093. Dataloading: 0.0158 s/iter. Inference: 0.2366 s/iter. Eval: 0.0214 s/iter. Total: 0.2738 s/iter. ETA=0:03:59
[01/17 17:25:23] detectron2.evaluation.evaluator INFO: Inference done 236/1093. Dataloading: 0.0158 s/iter. Inference: 0.2366 s/iter. Eval: 0.0213 s/iter. Total: 0.2738 s/iter. ETA=0:03:54
[01/17 17:25:28] detectron2.evaluation.evaluator INFO: Inference done 255/1093. Dataloading: 0.0161 s/iter. Inference: 0.2362 s/iter. Eval: 0.0212 s/iter. Total: 0.2737 s/iter. ETA=0:03:49
[01/17 17:25:33] detectron2.evaluation.evaluator INFO: Inference done 274/1093. Dataloading: 0.0163 s/iter. Inference: 0.2348 s/iter. Eval: 0.0219 s/iter. Total: 0.2731 s/iter. ETA=0:03:43
[01/17 17:25:38] detectron2.evaluation.evaluator INFO: Inference done 291/1093. Dataloading: 0.0163 s/iter. Inference: 0.2364 s/iter. Eval: 0.0219 s/iter. Total: 0.2747 s/iter. ETA=0:03:40
[01/17 17:25:43] detectron2.evaluation.evaluator INFO: Inference done 309/1093. Dataloading: 0.0159 s/iter. Inference: 0.2375 s/iter. Eval: 0.0216 s/iter. Total: 0.2751 s/iter. ETA=0:03:35
[01/17 17:25:44] detectron2.engine.hooks INFO: Overall training speed: 77 iterations in 0:02:20 (1.8222 s / it)
[01/17 17:25:44] detectron2.engine.hooks INFO: Total training time: 0:18:43 (0:16:23 on hooks)
[01/17 17:26:22] detectron2 INFO: Rank of current process: 1. World size: 4
[01/17 17:26:26] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/17 17:26:26] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/17 17:26:26] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/17 17:26:26] detectron2.utils.env INFO: Using a generated random seed 26334600
[01/17 17:26:28] detectron2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/17 17:26:28] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 17:26:31] detectron2.data.build INFO: Using training sampler TrainingSampler
[01/17 17:26:32] detectron2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/17 17:26:32] detectron2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/17 17:26:32] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/17 17:26:33] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/17 17:26:33] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/17 17:26:33] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/17 17:26:33] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/17 17:26:33] detectron2.engine.train_loop INFO: Starting training from iteration 0
[01/17 17:27:43] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 17:27:44] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 17:27:44] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 17:27:45] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 17:27:59] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0139 s/iter. Inference: 0.1917 s/iter. Eval: 0.0289 s/iter. Total: 0.2345 s/iter. ETA=0:04:13
[01/17 17:28:04] detectron2.evaluation.evaluator INFO: Inference done 29/1093. Dataloading: 0.0171 s/iter. Inference: 0.2286 s/iter. Eval: 0.0291 s/iter. Total: 0.2749 s/iter. ETA=0:04:52
[01/17 17:28:09] detectron2.evaluation.evaluator INFO: Inference done 48/1093. Dataloading: 0.0192 s/iter. Inference: 0.2221 s/iter. Eval: 0.0326 s/iter. Total: 0.2741 s/iter. ETA=0:04:46
[01/17 17:28:14] detectron2.evaluation.evaluator INFO: Inference done 66/1093. Dataloading: 0.0179 s/iter. Inference: 0.2294 s/iter. Eval: 0.0310 s/iter. Total: 0.2784 s/iter. ETA=0:04:45
[01/17 17:28:20] detectron2.evaluation.evaluator INFO: Inference done 84/1093. Dataloading: 0.0180 s/iter. Inference: 0.2329 s/iter. Eval: 0.0312 s/iter. Total: 0.2822 s/iter. ETA=0:04:44
[01/17 17:28:25] detectron2.evaluation.evaluator INFO: Inference done 101/1093. Dataloading: 0.0170 s/iter. Inference: 0.2372 s/iter. Eval: 0.0304 s/iter. Total: 0.2848 s/iter. ETA=0:04:42
[01/17 17:28:30] detectron2.evaluation.evaluator INFO: Inference done 121/1093. Dataloading: 0.0168 s/iter. Inference: 0.2329 s/iter. Eval: 0.0299 s/iter. Total: 0.2797 s/iter. ETA=0:04:31
[01/17 17:28:35] detectron2.evaluation.evaluator INFO: Inference done 142/1093. Dataloading: 0.0162 s/iter. Inference: 0.2292 s/iter. Eval: 0.0294 s/iter. Total: 0.2749 s/iter. ETA=0:04:21
[01/17 17:28:40] detectron2.evaluation.evaluator INFO: Inference done 162/1093. Dataloading: 0.0159 s/iter. Inference: 0.2270 s/iter. Eval: 0.0292 s/iter. Total: 0.2721 s/iter. ETA=0:04:13
[01/17 17:28:45] detectron2.evaluation.evaluator INFO: Inference done 183/1093. Dataloading: 0.0155 s/iter. Inference: 0.2240 s/iter. Eval: 0.0288 s/iter. Total: 0.2684 s/iter. ETA=0:04:04
[01/17 17:28:50] detectron2.evaluation.evaluator INFO: Inference done 204/1093. Dataloading: 0.0155 s/iter. Inference: 0.2212 s/iter. Eval: 0.0289 s/iter. Total: 0.2657 s/iter. ETA=0:03:56
[01/17 17:28:55] detectron2.evaluation.evaluator INFO: Inference done 226/1093. Dataloading: 0.0153 s/iter. Inference: 0.2182 s/iter. Eval: 0.0290 s/iter. Total: 0.2627 s/iter. ETA=0:03:47
[01/17 17:29:01] detectron2.evaluation.evaluator INFO: Inference done 250/1093. Dataloading: 0.0151 s/iter. Inference: 0.2141 s/iter. Eval: 0.0286 s/iter. Total: 0.2579 s/iter. ETA=0:03:37
[01/17 17:29:06] detectron2.evaluation.evaluator INFO: Inference done 273/1093. Dataloading: 0.0149 s/iter. Inference: 0.2120 s/iter. Eval: 0.0282 s/iter. Total: 0.2553 s/iter. ETA=0:03:29
[01/17 17:29:11] detectron2.evaluation.evaluator INFO: Inference done 298/1093. Dataloading: 0.0147 s/iter. Inference: 0.2087 s/iter. Eval: 0.0278 s/iter. Total: 0.2513 s/iter. ETA=0:03:19
[01/17 17:29:16] detectron2.evaluation.evaluator INFO: Inference done 320/1093. Dataloading: 0.0145 s/iter. Inference: 0.2078 s/iter. Eval: 0.0278 s/iter. Total: 0.2502 s/iter. ETA=0:03:13
[01/17 17:29:21] detectron2.evaluation.evaluator INFO: Inference done 341/1093. Dataloading: 0.0145 s/iter. Inference: 0.2072 s/iter. Eval: 0.0278 s/iter. Total: 0.2495 s/iter. ETA=0:03:07
[01/17 17:29:26] detectron2.evaluation.evaluator INFO: Inference done 363/1093. Dataloading: 0.0143 s/iter. Inference: 0.2065 s/iter. Eval: 0.0277 s/iter. Total: 0.2486 s/iter. ETA=0:03:01
[01/17 17:29:31] detectron2.evaluation.evaluator INFO: Inference done 384/1093. Dataloading: 0.0142 s/iter. Inference: 0.2062 s/iter. Eval: 0.0277 s/iter. Total: 0.2482 s/iter. ETA=0:02:55
[01/17 17:29:37] detectron2.evaluation.evaluator INFO: Inference done 405/1093. Dataloading: 0.0141 s/iter. Inference: 0.2060 s/iter. Eval: 0.0275 s/iter. Total: 0.2477 s/iter. ETA=0:02:50
[01/17 17:29:42] detectron2.evaluation.evaluator INFO: Inference done 428/1093. Dataloading: 0.0140 s/iter. Inference: 0.2046 s/iter. Eval: 0.0273 s/iter. Total: 0.2461 s/iter. ETA=0:02:43
[01/17 17:29:47] detectron2.evaluation.evaluator INFO: Inference done 449/1093. Dataloading: 0.0140 s/iter. Inference: 0.2044 s/iter. Eval: 0.0274 s/iter. Total: 0.2459 s/iter. ETA=0:02:38
[01/17 17:29:52] detectron2.evaluation.evaluator INFO: Inference done 469/1093. Dataloading: 0.0138 s/iter. Inference: 0.2048 s/iter. Eval: 0.0273 s/iter. Total: 0.2461 s/iter. ETA=0:02:33
[01/17 17:29:57] detectron2.evaluation.evaluator INFO: Inference done 492/1093. Dataloading: 0.0139 s/iter. Inference: 0.2038 s/iter. Eval: 0.0274 s/iter. Total: 0.2451 s/iter. ETA=0:02:27
[01/17 17:30:02] detectron2.evaluation.evaluator INFO: Inference done 515/1093. Dataloading: 0.0139 s/iter. Inference: 0.2032 s/iter. Eval: 0.0272 s/iter. Total: 0.2444 s/iter. ETA=0:02:21
[01/17 17:30:07] detectron2.evaluation.evaluator INFO: Inference done 537/1093. Dataloading: 0.0139 s/iter. Inference: 0.2027 s/iter. Eval: 0.0273 s/iter. Total: 0.2440 s/iter. ETA=0:02:15
[01/17 17:30:12] detectron2.evaluation.evaluator INFO: Inference done 558/1093. Dataloading: 0.0139 s/iter. Inference: 0.2025 s/iter. Eval: 0.0274 s/iter. Total: 0.2438 s/iter. ETA=0:02:10
[01/17 17:30:17] detectron2.evaluation.evaluator INFO: Inference done 580/1093. Dataloading: 0.0139 s/iter. Inference: 0.2021 s/iter. Eval: 0.0274 s/iter. Total: 0.2434 s/iter. ETA=0:02:04
[01/17 17:30:23] detectron2.evaluation.evaluator INFO: Inference done 599/1093. Dataloading: 0.0139 s/iter. Inference: 0.2031 s/iter. Eval: 0.0274 s/iter. Total: 0.2444 s/iter. ETA=0:02:00
[01/17 17:30:28] detectron2.evaluation.evaluator INFO: Inference done 621/1093. Dataloading: 0.0139 s/iter. Inference: 0.2029 s/iter. Eval: 0.0274 s/iter. Total: 0.2443 s/iter. ETA=0:01:55
[01/17 17:30:33] detectron2.evaluation.evaluator INFO: Inference done 641/1093. Dataloading: 0.0139 s/iter. Inference: 0.2035 s/iter. Eval: 0.0274 s/iter. Total: 0.2449 s/iter. ETA=0:01:50
[01/17 17:30:38] detectron2.evaluation.evaluator INFO: Inference done 664/1093. Dataloading: 0.0139 s/iter. Inference: 0.2026 s/iter. Eval: 0.0275 s/iter. Total: 0.2441 s/iter. ETA=0:01:44
[01/17 17:30:43] detectron2.evaluation.evaluator INFO: Inference done 684/1093. Dataloading: 0.0139 s/iter. Inference: 0.2029 s/iter. Eval: 0.0274 s/iter. Total: 0.2443 s/iter. ETA=0:01:39
[01/17 17:30:49] detectron2.evaluation.evaluator INFO: Inference done 706/1093. Dataloading: 0.0140 s/iter. Inference: 0.2027 s/iter. Eval: 0.0274 s/iter. Total: 0.2441 s/iter. ETA=0:01:34
[01/17 17:30:54] detectron2.evaluation.evaluator INFO: Inference done 730/1093. Dataloading: 0.0139 s/iter. Inference: 0.2019 s/iter. Eval: 0.0273 s/iter. Total: 0.2432 s/iter. ETA=0:01:28
[01/17 17:30:59] detectron2.evaluation.evaluator INFO: Inference done 753/1093. Dataloading: 0.0138 s/iter. Inference: 0.2014 s/iter. Eval: 0.0272 s/iter. Total: 0.2426 s/iter. ETA=0:01:22
[01/17 17:31:04] detectron2.evaluation.evaluator INFO: Inference done 776/1093. Dataloading: 0.0138 s/iter. Inference: 0.2011 s/iter. Eval: 0.0272 s/iter. Total: 0.2422 s/iter. ETA=0:01:16
[01/17 17:31:09] detectron2.evaluation.evaluator INFO: Inference done 796/1093. Dataloading: 0.0138 s/iter. Inference: 0.2014 s/iter. Eval: 0.0272 s/iter. Total: 0.2425 s/iter. ETA=0:01:12
[01/17 17:31:14] detectron2.evaluation.evaluator INFO: Inference done 819/1093. Dataloading: 0.0138 s/iter. Inference: 0.2009 s/iter. Eval: 0.0272 s/iter. Total: 0.2420 s/iter. ETA=0:01:06
[01/17 17:31:19] detectron2.evaluation.evaluator INFO: Inference done 839/1093. Dataloading: 0.0138 s/iter. Inference: 0.2011 s/iter. Eval: 0.0272 s/iter. Total: 0.2422 s/iter. ETA=0:01:01
[01/17 17:31:24] detectron2.evaluation.evaluator INFO: Inference done 860/1093. Dataloading: 0.0137 s/iter. Inference: 0.2011 s/iter. Eval: 0.0272 s/iter. Total: 0.2422 s/iter. ETA=0:00:56
[01/17 17:31:30] detectron2.evaluation.evaluator INFO: Inference done 881/1093. Dataloading: 0.0137 s/iter. Inference: 0.2012 s/iter. Eval: 0.0272 s/iter. Total: 0.2422 s/iter. ETA=0:00:51
[01/17 17:31:35] detectron2.evaluation.evaluator INFO: Inference done 902/1093. Dataloading: 0.0137 s/iter. Inference: 0.2012 s/iter. Eval: 0.0272 s/iter. Total: 0.2421 s/iter. ETA=0:00:46
[01/17 17:31:40] detectron2.evaluation.evaluator INFO: Inference done 925/1093. Dataloading: 0.0137 s/iter. Inference: 0.2009 s/iter. Eval: 0.0271 s/iter. Total: 0.2418 s/iter. ETA=0:00:40
[01/17 17:31:45] detectron2.evaluation.evaluator INFO: Inference done 946/1093. Dataloading: 0.0137 s/iter. Inference: 0.2010 s/iter. Eval: 0.0271 s/iter. Total: 0.2419 s/iter. ETA=0:00:35
[01/17 17:31:50] detectron2.evaluation.evaluator INFO: Inference done 968/1093. Dataloading: 0.0137 s/iter. Inference: 0.2008 s/iter. Eval: 0.0272 s/iter. Total: 0.2417 s/iter. ETA=0:00:30
[01/17 17:31:55] detectron2.evaluation.evaluator INFO: Inference done 991/1093. Dataloading: 0.0136 s/iter. Inference: 0.2006 s/iter. Eval: 0.0271 s/iter. Total: 0.2414 s/iter. ETA=0:00:24
[01/17 17:32:01] detectron2.evaluation.evaluator INFO: Inference done 1010/1093. Dataloading: 0.0136 s/iter. Inference: 0.2010 s/iter. Eval: 0.0271 s/iter. Total: 0.2419 s/iter. ETA=0:00:20
[01/17 17:32:06] detectron2.evaluation.evaluator INFO: Inference done 1032/1093. Dataloading: 0.0136 s/iter. Inference: 0.2009 s/iter. Eval: 0.0271 s/iter. Total: 0.2417 s/iter. ETA=0:00:14
[01/17 17:32:11] detectron2.evaluation.evaluator INFO: Inference done 1053/1093. Dataloading: 0.0136 s/iter. Inference: 0.2009 s/iter. Eval: 0.0272 s/iter. Total: 0.2418 s/iter. ETA=0:00:09
[01/17 17:32:16] detectron2.evaluation.evaluator INFO: Inference done 1077/1093. Dataloading: 0.0135 s/iter. Inference: 0.2003 s/iter. Eval: 0.0271 s/iter. Total: 0.2411 s/iter. ETA=0:00:03
[01/17 17:32:20] detectron2.evaluation.evaluator INFO: Total inference time: 0:04:22.065374 (0.240869 s / iter per device, on 4 devices)
[01/17 17:32:20] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:37 (0.199849 s / iter per device, on 4 devices)
[01/17 17:32:57] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 17:32:58] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 17:32:58] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 17:32:59] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 17:33:12] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0101 s/iter. Inference: 0.2143 s/iter. Eval: 0.0317 s/iter. Total: 0.2561 s/iter. ETA=0:04:37
[01/17 17:33:17] detectron2.evaluation.evaluator INFO: Inference done 31/1093. Dataloading: 0.0168 s/iter. Inference: 0.2079 s/iter. Eval: 0.0294 s/iter. Total: 0.2543 s/iter. ETA=0:04:30
[01/17 17:33:22] detectron2.evaluation.evaluator INFO: Inference done 52/1093. Dataloading: 0.0165 s/iter. Inference: 0.2032 s/iter. Eval: 0.0306 s/iter. Total: 0.2504 s/iter. ETA=0:04:20
[01/17 17:33:27] detectron2.evaluation.evaluator INFO: Inference done 73/1093. Dataloading: 0.0155 s/iter. Inference: 0.2014 s/iter. Eval: 0.0299 s/iter. Total: 0.2469 s/iter. ETA=0:04:11
[01/17 17:33:32] detectron2.evaluation.evaluator INFO: Inference done 94/1093. Dataloading: 0.0151 s/iter. Inference: 0.2014 s/iter. Eval: 0.0297 s/iter. Total: 0.2463 s/iter. ETA=0:04:06
[01/17 17:33:37] detectron2.evaluation.evaluator INFO: Inference done 115/1093. Dataloading: 0.0143 s/iter. Inference: 0.2022 s/iter. Eval: 0.0298 s/iter. Total: 0.2463 s/iter. ETA=0:04:00
[01/17 17:33:42] detectron2.evaluation.evaluator INFO: Inference done 136/1093. Dataloading: 0.0140 s/iter. Inference: 0.2028 s/iter. Eval: 0.0295 s/iter. Total: 0.2463 s/iter. ETA=0:03:55
[01/17 17:33:47] detectron2.evaluation.evaluator INFO: Inference done 156/1093. Dataloading: 0.0137 s/iter. Inference: 0.2034 s/iter. Eval: 0.0297 s/iter. Total: 0.2469 s/iter. ETA=0:03:51
[01/17 17:33:52] detectron2.evaluation.evaluator INFO: Inference done 178/1093. Dataloading: 0.0139 s/iter. Inference: 0.2010 s/iter. Eval: 0.0297 s/iter. Total: 0.2447 s/iter. ETA=0:03:43
[01/17 17:33:58] detectron2.evaluation.evaluator INFO: Inference done 199/1093. Dataloading: 0.0137 s/iter. Inference: 0.2006 s/iter. Eval: 0.0299 s/iter. Total: 0.2444 s/iter. ETA=0:03:38
[01/17 17:34:03] detectron2.evaluation.evaluator INFO: Inference done 221/1093. Dataloading: 0.0135 s/iter. Inference: 0.1995 s/iter. Eval: 0.0298 s/iter. Total: 0.2429 s/iter. ETA=0:03:31
[01/17 17:34:08] detectron2.evaluation.evaluator INFO: Inference done 241/1093. Dataloading: 0.0134 s/iter. Inference: 0.2003 s/iter. Eval: 0.0298 s/iter. Total: 0.2436 s/iter. ETA=0:03:27
[01/17 17:34:13] detectron2.evaluation.evaluator INFO: Inference done 264/1093. Dataloading: 0.0134 s/iter. Inference: 0.1990 s/iter. Eval: 0.0294 s/iter. Total: 0.2419 s/iter. ETA=0:03:20
[01/17 17:34:18] detectron2.evaluation.evaluator INFO: Inference done 287/1093. Dataloading: 0.0132 s/iter. Inference: 0.1974 s/iter. Eval: 0.0295 s/iter. Total: 0.2403 s/iter. ETA=0:03:13
[01/17 17:34:23] detectron2.evaluation.evaluator INFO: Inference done 306/1093. Dataloading: 0.0133 s/iter. Inference: 0.1988 s/iter. Eval: 0.0296 s/iter. Total: 0.2418 s/iter. ETA=0:03:10
[01/17 17:34:28] detectron2.evaluation.evaluator INFO: Inference done 329/1093. Dataloading: 0.0130 s/iter. Inference: 0.1976 s/iter. Eval: 0.0294 s/iter. Total: 0.2401 s/iter. ETA=0:03:03
[01/17 17:34:33] detectron2.evaluation.evaluator INFO: Inference done 352/1093. Dataloading: 0.0132 s/iter. Inference: 0.1964 s/iter. Eval: 0.0294 s/iter. Total: 0.2391 s/iter. ETA=0:02:57
[01/17 17:34:38] detectron2.evaluation.evaluator INFO: Inference done 372/1093. Dataloading: 0.0132 s/iter. Inference: 0.1974 s/iter. Eval: 0.0294 s/iter. Total: 0.2401 s/iter. ETA=0:02:53
[01/17 17:34:43] detectron2.evaluation.evaluator INFO: Inference done 393/1093. Dataloading: 0.0132 s/iter. Inference: 0.1976 s/iter. Eval: 0.0293 s/iter. Total: 0.2402 s/iter. ETA=0:02:48
[01/17 17:34:49] detectron2.evaluation.evaluator INFO: Inference done 412/1093. Dataloading: 0.0135 s/iter. Inference: 0.1987 s/iter. Eval: 0.0294 s/iter. Total: 0.2417 s/iter. ETA=0:02:44
[01/17 17:34:54] detectron2.evaluation.evaluator INFO: Inference done 434/1093. Dataloading: 0.0134 s/iter. Inference: 0.1981 s/iter. Eval: 0.0295 s/iter. Total: 0.2411 s/iter. ETA=0:02:38
[01/17 17:34:59] detectron2.evaluation.evaluator INFO: Inference done 456/1093. Dataloading: 0.0133 s/iter. Inference: 0.1982 s/iter. Eval: 0.0295 s/iter. Total: 0.2410 s/iter. ETA=0:02:33
[01/17 17:35:04] detectron2.evaluation.evaluator INFO: Inference done 479/1093. Dataloading: 0.0132 s/iter. Inference: 0.1971 s/iter. Eval: 0.0295 s/iter. Total: 0.2399 s/iter. ETA=0:02:27
[01/17 17:35:09] detectron2.evaluation.evaluator INFO: Inference done 500/1093. Dataloading: 0.0132 s/iter. Inference: 0.1972 s/iter. Eval: 0.0296 s/iter. Total: 0.2401 s/iter. ETA=0:02:22
[01/17 17:35:14] detectron2.evaluation.evaluator INFO: Inference done 521/1093. Dataloading: 0.0132 s/iter. Inference: 0.1971 s/iter. Eval: 0.0296 s/iter. Total: 0.2400 s/iter. ETA=0:02:17
[01/17 17:35:19] detectron2.evaluation.evaluator INFO: Inference done 544/1093. Dataloading: 0.0133 s/iter. Inference: 0.1961 s/iter. Eval: 0.0297 s/iter. Total: 0.2392 s/iter. ETA=0:02:11
[01/17 17:35:24] detectron2.evaluation.evaluator INFO: Inference done 565/1093. Dataloading: 0.0132 s/iter. Inference: 0.1966 s/iter. Eval: 0.0297 s/iter. Total: 0.2396 s/iter. ETA=0:02:06
[01/17 17:35:30] detectron2.evaluation.evaluator INFO: Inference done 586/1093. Dataloading: 0.0133 s/iter. Inference: 0.1968 s/iter. Eval: 0.0297 s/iter. Total: 0.2399 s/iter. ETA=0:02:01
[01/17 17:35:35] detectron2.evaluation.evaluator INFO: Inference done 607/1093. Dataloading: 0.0132 s/iter. Inference: 0.1968 s/iter. Eval: 0.0297 s/iter. Total: 0.2399 s/iter. ETA=0:01:56
[01/17 17:35:40] detectron2.evaluation.evaluator INFO: Inference done 629/1093. Dataloading: 0.0132 s/iter. Inference: 0.1964 s/iter. Eval: 0.0297 s/iter. Total: 0.2394 s/iter. ETA=0:01:51
[01/17 17:35:45] detectron2.evaluation.evaluator INFO: Inference done 650/1093. Dataloading: 0.0132 s/iter. Inference: 0.1965 s/iter. Eval: 0.0297 s/iter. Total: 0.2396 s/iter. ETA=0:01:46
[01/17 17:35:50] detectron2.evaluation.evaluator INFO: Inference done 672/1093. Dataloading: 0.0132 s/iter. Inference: 0.1966 s/iter. Eval: 0.0297 s/iter. Total: 0.2396 s/iter. ETA=0:01:40
[01/17 17:35:55] detectron2.evaluation.evaluator INFO: Inference done 693/1093. Dataloading: 0.0134 s/iter. Inference: 0.1965 s/iter. Eval: 0.0297 s/iter. Total: 0.2397 s/iter. ETA=0:01:35
[01/17 17:36:00] detectron2.evaluation.evaluator INFO: Inference done 713/1093. Dataloading: 0.0133 s/iter. Inference: 0.1971 s/iter. Eval: 0.0297 s/iter. Total: 0.2402 s/iter. ETA=0:01:31
[01/17 17:36:05] detectron2.evaluation.evaluator INFO: Inference done 736/1093. Dataloading: 0.0133 s/iter. Inference: 0.1965 s/iter. Eval: 0.0296 s/iter. Total: 0.2395 s/iter. ETA=0:01:25
[01/17 17:36:10] detectron2.evaluation.evaluator INFO: Inference done 757/1093. Dataloading: 0.0133 s/iter. Inference: 0.1964 s/iter. Eval: 0.0296 s/iter. Total: 0.2395 s/iter. ETA=0:01:20
[01/17 17:36:15] detectron2.evaluation.evaluator INFO: Inference done 779/1093. Dataloading: 0.0133 s/iter. Inference: 0.1963 s/iter. Eval: 0.0296 s/iter. Total: 0.2392 s/iter. ETA=0:01:15
[01/17 17:36:21] detectron2.evaluation.evaluator INFO: Inference done 803/1093. Dataloading: 0.0132 s/iter. Inference: 0.1958 s/iter. Eval: 0.0295 s/iter. Total: 0.2386 s/iter. ETA=0:01:09
[01/17 17:36:26] detectron2.evaluation.evaluator INFO: Inference done 823/1093. Dataloading: 0.0133 s/iter. Inference: 0.1960 s/iter. Eval: 0.0296 s/iter. Total: 0.2389 s/iter. ETA=0:01:04
[01/17 17:36:31] detectron2.evaluation.evaluator INFO: Inference done 845/1093. Dataloading: 0.0132 s/iter. Inference: 0.1958 s/iter. Eval: 0.0295 s/iter. Total: 0.2386 s/iter. ETA=0:00:59
[01/17 17:36:36] detectron2.evaluation.evaluator INFO: Inference done 865/1093. Dataloading: 0.0133 s/iter. Inference: 0.1960 s/iter. Eval: 0.0296 s/iter. Total: 0.2390 s/iter. ETA=0:00:54
[01/17 17:36:41] detectron2.evaluation.evaluator INFO: Inference done 886/1093. Dataloading: 0.0133 s/iter. Inference: 0.1961 s/iter. Eval: 0.0296 s/iter. Total: 0.2391 s/iter. ETA=0:00:49
[01/17 17:36:46] detectron2.evaluation.evaluator INFO: Inference done 906/1093. Dataloading: 0.0133 s/iter. Inference: 0.1963 s/iter. Eval: 0.0297 s/iter. Total: 0.2394 s/iter. ETA=0:00:44
[01/17 17:36:51] detectron2.evaluation.evaluator INFO: Inference done 928/1093. Dataloading: 0.0134 s/iter. Inference: 0.1961 s/iter. Eval: 0.0297 s/iter. Total: 0.2393 s/iter. ETA=0:00:39
[01/17 17:36:56] detectron2.evaluation.evaluator INFO: Inference done 950/1093. Dataloading: 0.0133 s/iter. Inference: 0.1961 s/iter. Eval: 0.0296 s/iter. Total: 0.2391 s/iter. ETA=0:00:34
[01/17 17:37:01] detectron2.evaluation.evaluator INFO: Inference done 972/1093. Dataloading: 0.0133 s/iter. Inference: 0.1961 s/iter. Eval: 0.0296 s/iter. Total: 0.2391 s/iter. ETA=0:00:28
[01/17 17:37:07] detectron2.evaluation.evaluator INFO: Inference done 994/1093. Dataloading: 0.0133 s/iter. Inference: 0.1961 s/iter. Eval: 0.0296 s/iter. Total: 0.2391 s/iter. ETA=0:00:23
[01/17 17:37:12] detectron2.evaluation.evaluator INFO: Inference done 1017/1093. Dataloading: 0.0133 s/iter. Inference: 0.1958 s/iter. Eval: 0.0296 s/iter. Total: 0.2388 s/iter. ETA=0:00:18
[01/17 17:37:17] detectron2.evaluation.evaluator INFO: Inference done 1039/1093. Dataloading: 0.0132 s/iter. Inference: 0.1959 s/iter. Eval: 0.0296 s/iter. Total: 0.2388 s/iter. ETA=0:00:12
[01/17 17:37:22] detectron2.evaluation.evaluator INFO: Inference done 1060/1093. Dataloading: 0.0132 s/iter. Inference: 0.1960 s/iter. Eval: 0.0296 s/iter. Total: 0.2389 s/iter. ETA=0:00:07
[01/17 17:37:27] detectron2.evaluation.evaluator INFO: Inference done 1080/1093. Dataloading: 0.0132 s/iter. Inference: 0.1963 s/iter. Eval: 0.0296 s/iter. Total: 0.2391 s/iter. ETA=0:00:03
[01/17 17:37:30] detectron2.evaluation.evaluator INFO: Total inference time: 0:04:20.270867 (0.239220 s / iter per device, on 4 devices)
[01/17 17:37:30] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:33 (0.195989 s / iter per device, on 4 devices)
[01/17 17:37:51] detectron2.engine.hooks INFO: Overall training speed: 45 iterations in 0:01:34 (2.1032 s / it)
[01/17 17:37:51] detectron2.engine.hooks INFO: Total training time: 0:10:56 (0:09:21 on hooks)
[01/17 17:39:50] detectron2 INFO: Rank of current process: 1. World size: 4
[01/17 17:39:56] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5,6,7     Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/17 17:39:56] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/17 17:39:56] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/17 17:39:56] detectron2.utils.env INFO: Using a generated random seed 56854897
[01/17 17:39:58] detectron2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/17 17:39:58] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 17:40:09] detectron2.data.build INFO: Using training sampler TrainingSampler
[01/17 17:40:09] detectron2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/17 17:40:10] detectron2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/17 17:40:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/17 17:40:10] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/17 17:40:10] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/17 17:40:11] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/17 17:40:11] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/17 17:40:11] detectron2.engine.train_loop INFO: Starting training from iteration 0
[01/17 17:41:27] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 17:41:29] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 17:41:29] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 17:41:31] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 17:54:52] detectron2 INFO: Rank of current process: 1. World size: 4
[01/17 17:54:56] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5,6,7     Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/17 17:54:56] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/17 17:54:56] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/17 17:54:56] detectron2.utils.env INFO: Using a generated random seed 56797528
[01/17 17:54:58] detectron2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/17 17:54:58] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 17:55:09] detectron2.data.build INFO: Using training sampler TrainingSampler
[01/17 17:55:11] detectron2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/17 17:55:11] detectron2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/17 17:55:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/17 17:55:12] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/17 17:55:12] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/17 17:55:12] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/17 17:55:12] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/17 17:55:12] detectron2.engine.train_loop INFO: Starting training from iteration 0
[01/17 17:56:28] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 17:56:31] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 17:56:31] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 17:56:33] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 18:11:08] detectron2 INFO: Rank of current process: 1. World size: 4
[01/17 18:11:12] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/17 18:11:12] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/17 18:11:12] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/17 18:11:12] detectron2.utils.env INFO: Using a generated random seed 12307287
[01/17 18:11:14] detectron2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/17 18:11:14] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 18:11:17] detectron2.data.build INFO: Using training sampler TrainingSampler
[01/17 18:11:18] detectron2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/17 18:11:18] detectron2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/17 18:11:18] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/17 18:11:18] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/17 18:11:18] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/17 18:11:18] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/17 18:11:18] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/17 18:11:18] detectron2.engine.train_loop INFO: Starting training from iteration 0
[01/17 18:12:27] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 18:12:28] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 18:12:28] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 18:12:29] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 18:12:40] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0158 s/iter. Inference: 0.1695 s/iter. Eval: 0.0228 s/iter. Total: 0.2082 s/iter. ETA=0:03:45
[01/17 18:12:45] detectron2.evaluation.evaluator INFO: Inference done 33/1093. Dataloading: 0.0150 s/iter. Inference: 0.1906 s/iter. Eval: 0.0248 s/iter. Total: 0.2305 s/iter. ETA=0:04:04
[01/17 18:12:51] detectron2.evaluation.evaluator INFO: Inference done 55/1093. Dataloading: 0.0142 s/iter. Inference: 0.1920 s/iter. Eval: 0.0236 s/iter. Total: 0.2299 s/iter. ETA=0:03:58
[01/17 18:12:56] detectron2.evaluation.evaluator INFO: Inference done 78/1093. Dataloading: 0.0139 s/iter. Inference: 0.1888 s/iter. Eval: 0.0249 s/iter. Total: 0.2277 s/iter. ETA=0:03:51
[01/17 18:13:01] detectron2.evaluation.evaluator INFO: Inference done 102/1093. Dataloading: 0.0128 s/iter. Inference: 0.1870 s/iter. Eval: 0.0242 s/iter. Total: 0.2241 s/iter. ETA=0:03:42
[01/17 18:13:06] detectron2.evaluation.evaluator INFO: Inference done 124/1093. Dataloading: 0.0130 s/iter. Inference: 0.1880 s/iter. Eval: 0.0243 s/iter. Total: 0.2254 s/iter. ETA=0:03:38
[01/17 18:13:11] detectron2.evaluation.evaluator INFO: Inference done 146/1093. Dataloading: 0.0126 s/iter. Inference: 0.1899 s/iter. Eval: 0.0241 s/iter. Total: 0.2267 s/iter. ETA=0:03:34
[01/17 18:13:16] detectron2.evaluation.evaluator INFO: Inference done 168/1093. Dataloading: 0.0124 s/iter. Inference: 0.1911 s/iter. Eval: 0.0241 s/iter. Total: 0.2277 s/iter. ETA=0:03:30
[01/17 18:13:21] detectron2.evaluation.evaluator INFO: Inference done 190/1093. Dataloading: 0.0123 s/iter. Inference: 0.1911 s/iter. Eval: 0.0242 s/iter. Total: 0.2277 s/iter. ETA=0:03:25
[01/17 18:13:26] detectron2.evaluation.evaluator INFO: Inference done 212/1093. Dataloading: 0.0126 s/iter. Inference: 0.1917 s/iter. Eval: 0.0240 s/iter. Total: 0.2283 s/iter. ETA=0:03:21
[01/17 18:13:31] detectron2.evaluation.evaluator INFO: Inference done 235/1093. Dataloading: 0.0122 s/iter. Inference: 0.1914 s/iter. Eval: 0.0240 s/iter. Total: 0.2278 s/iter. ETA=0:03:15
[01/17 18:13:36] detectron2.evaluation.evaluator INFO: Inference done 259/1093. Dataloading: 0.0123 s/iter. Inference: 0.1896 s/iter. Eval: 0.0241 s/iter. Total: 0.2261 s/iter. ETA=0:03:08
[01/17 18:13:42] detectron2.evaluation.evaluator INFO: Inference done 280/1093. Dataloading: 0.0123 s/iter. Inference: 0.1906 s/iter. Eval: 0.0243 s/iter. Total: 0.2273 s/iter. ETA=0:03:04
[01/17 18:13:47] detectron2.evaluation.evaluator INFO: Inference done 301/1093. Dataloading: 0.0126 s/iter. Inference: 0.1917 s/iter. Eval: 0.0243 s/iter. Total: 0.2286 s/iter. ETA=0:03:01
[01/17 18:13:52] detectron2.evaluation.evaluator INFO: Inference done 325/1093. Dataloading: 0.0125 s/iter. Inference: 0.1909 s/iter. Eval: 0.0242 s/iter. Total: 0.2276 s/iter. ETA=0:02:54
[01/17 18:13:57] detectron2.evaluation.evaluator INFO: Inference done 348/1093. Dataloading: 0.0125 s/iter. Inference: 0.1904 s/iter. Eval: 0.0243 s/iter. Total: 0.2273 s/iter. ETA=0:02:49
[01/17 18:14:02] detectron2.evaluation.evaluator INFO: Inference done 372/1093. Dataloading: 0.0125 s/iter. Inference: 0.1894 s/iter. Eval: 0.0242 s/iter. Total: 0.2263 s/iter. ETA=0:02:43
[01/17 18:14:07] detectron2.evaluation.evaluator INFO: Inference done 394/1093. Dataloading: 0.0126 s/iter. Inference: 0.1895 s/iter. Eval: 0.0245 s/iter. Total: 0.2267 s/iter. ETA=0:02:38
[01/17 18:14:12] detectron2.evaluation.evaluator INFO: Inference done 416/1093. Dataloading: 0.0128 s/iter. Inference: 0.1895 s/iter. Eval: 0.0244 s/iter. Total: 0.2268 s/iter. ETA=0:02:33
[01/17 18:14:17] detectron2.evaluation.evaluator INFO: Inference done 439/1093. Dataloading: 0.0127 s/iter. Inference: 0.1897 s/iter. Eval: 0.0244 s/iter. Total: 0.2269 s/iter. ETA=0:02:28
[01/17 18:14:23] detectron2.evaluation.evaluator INFO: Inference done 461/1093. Dataloading: 0.0126 s/iter. Inference: 0.1902 s/iter. Eval: 0.0243 s/iter. Total: 0.2272 s/iter. ETA=0:02:23
[01/17 18:14:28] detectron2.evaluation.evaluator INFO: Inference done 483/1093. Dataloading: 0.0125 s/iter. Inference: 0.1906 s/iter. Eval: 0.0242 s/iter. Total: 0.2274 s/iter. ETA=0:02:18
[01/17 18:14:33] detectron2.evaluation.evaluator INFO: Inference done 507/1093. Dataloading: 0.0125 s/iter. Inference: 0.1901 s/iter. Eval: 0.0242 s/iter. Total: 0.2269 s/iter. ETA=0:02:12
[01/17 18:14:38] detectron2.evaluation.evaluator INFO: Inference done 528/1093. Dataloading: 0.0126 s/iter. Inference: 0.1907 s/iter. Eval: 0.0241 s/iter. Total: 0.2276 s/iter. ETA=0:02:08
[01/17 18:14:43] detectron2.evaluation.evaluator INFO: Inference done 549/1093. Dataloading: 0.0125 s/iter. Inference: 0.1914 s/iter. Eval: 0.0241 s/iter. Total: 0.2281 s/iter. ETA=0:02:04
[01/17 18:14:48] detectron2.evaluation.evaluator INFO: Inference done 572/1093. Dataloading: 0.0124 s/iter. Inference: 0.1915 s/iter. Eval: 0.0241 s/iter. Total: 0.2281 s/iter. ETA=0:01:58
[01/17 18:14:53] detectron2.evaluation.evaluator INFO: Inference done 592/1093. Dataloading: 0.0125 s/iter. Inference: 0.1922 s/iter. Eval: 0.0241 s/iter. Total: 0.2289 s/iter. ETA=0:01:54
[01/17 18:14:59] detectron2.evaluation.evaluator INFO: Inference done 614/1093. Dataloading: 0.0124 s/iter. Inference: 0.1925 s/iter. Eval: 0.0241 s/iter. Total: 0.2291 s/iter. ETA=0:01:49
[01/17 18:15:04] detectron2.evaluation.evaluator INFO: Inference done 634/1093. Dataloading: 0.0127 s/iter. Inference: 0.1930 s/iter. Eval: 0.0242 s/iter. Total: 0.2300 s/iter. ETA=0:01:45
[01/17 18:15:09] detectron2.evaluation.evaluator INFO: Inference done 656/1093. Dataloading: 0.0128 s/iter. Inference: 0.1931 s/iter. Eval: 0.0241 s/iter. Total: 0.2301 s/iter. ETA=0:01:40
[01/17 18:15:14] detectron2.evaluation.evaluator INFO: Inference done 676/1093. Dataloading: 0.0128 s/iter. Inference: 0.1938 s/iter. Eval: 0.0241 s/iter. Total: 0.2308 s/iter. ETA=0:01:36
[01/17 18:15:19] detectron2.evaluation.evaluator INFO: Inference done 697/1093. Dataloading: 0.0128 s/iter. Inference: 0.1943 s/iter. Eval: 0.0241 s/iter. Total: 0.2313 s/iter. ETA=0:01:31
[01/17 18:15:24] detectron2.evaluation.evaluator INFO: Inference done 719/1093. Dataloading: 0.0128 s/iter. Inference: 0.1944 s/iter. Eval: 0.0242 s/iter. Total: 0.2314 s/iter. ETA=0:01:26
[01/17 18:15:29] detectron2.evaluation.evaluator INFO: Inference done 741/1093. Dataloading: 0.0128 s/iter. Inference: 0.1943 s/iter. Eval: 0.0242 s/iter. Total: 0.2314 s/iter. ETA=0:01:21
[01/17 18:15:35] detectron2.evaluation.evaluator INFO: Inference done 764/1093. Dataloading: 0.0128 s/iter. Inference: 0.1941 s/iter. Eval: 0.0242 s/iter. Total: 0.2312 s/iter. ETA=0:01:16
[01/17 18:15:40] detectron2.evaluation.evaluator INFO: Inference done 787/1093. Dataloading: 0.0127 s/iter. Inference: 0.1940 s/iter. Eval: 0.0242 s/iter. Total: 0.2310 s/iter. ETA=0:01:10
[01/17 18:15:45] detectron2.evaluation.evaluator INFO: Inference done 810/1093. Dataloading: 0.0127 s/iter. Inference: 0.1938 s/iter. Eval: 0.0242 s/iter. Total: 0.2308 s/iter. ETA=0:01:05
[01/17 18:15:50] detectron2.evaluation.evaluator INFO: Inference done 834/1093. Dataloading: 0.0126 s/iter. Inference: 0.1933 s/iter. Eval: 0.0242 s/iter. Total: 0.2303 s/iter. ETA=0:00:59
[01/17 18:15:55] detectron2.evaluation.evaluator INFO: Inference done 855/1093. Dataloading: 0.0126 s/iter. Inference: 0.1938 s/iter. Eval: 0.0242 s/iter. Total: 0.2307 s/iter. ETA=0:00:54
[01/17 18:16:00] detectron2.evaluation.evaluator INFO: Inference done 878/1093. Dataloading: 0.0126 s/iter. Inference: 0.1935 s/iter. Eval: 0.0242 s/iter. Total: 0.2304 s/iter. ETA=0:00:49
[01/17 18:16:05] detectron2.evaluation.evaluator INFO: Inference done 902/1093. Dataloading: 0.0126 s/iter. Inference: 0.1931 s/iter. Eval: 0.0242 s/iter. Total: 0.2300 s/iter. ETA=0:00:43
[01/17 18:16:10] detectron2.evaluation.evaluator INFO: Inference done 923/1093. Dataloading: 0.0126 s/iter. Inference: 0.1934 s/iter. Eval: 0.0241 s/iter. Total: 0.2303 s/iter. ETA=0:00:39
[01/17 18:16:16] detectron2.evaluation.evaluator INFO: Inference done 945/1093. Dataloading: 0.0126 s/iter. Inference: 0.1935 s/iter. Eval: 0.0241 s/iter. Total: 0.2303 s/iter. ETA=0:00:34
[01/17 18:16:21] detectron2.evaluation.evaluator INFO: Inference done 966/1093. Dataloading: 0.0126 s/iter. Inference: 0.1937 s/iter. Eval: 0.0241 s/iter. Total: 0.2306 s/iter. ETA=0:00:29
[01/17 18:16:26] detectron2.evaluation.evaluator INFO: Inference done 987/1093. Dataloading: 0.0126 s/iter. Inference: 0.1941 s/iter. Eval: 0.0241 s/iter. Total: 0.2309 s/iter. ETA=0:00:24
[01/17 18:16:31] detectron2.evaluation.evaluator INFO: Inference done 1008/1093. Dataloading: 0.0126 s/iter. Inference: 0.1945 s/iter. Eval: 0.0241 s/iter. Total: 0.2313 s/iter. ETA=0:00:19
[01/17 18:16:36] detectron2.evaluation.evaluator INFO: Inference done 1030/1093. Dataloading: 0.0125 s/iter. Inference: 0.1945 s/iter. Eval: 0.0241 s/iter. Total: 0.2312 s/iter. ETA=0:00:14
[01/17 18:16:41] detectron2.evaluation.evaluator INFO: Inference done 1052/1093. Dataloading: 0.0125 s/iter. Inference: 0.1945 s/iter. Eval: 0.0241 s/iter. Total: 0.2312 s/iter. ETA=0:00:09
[01/17 18:16:46] detectron2.evaluation.evaluator INFO: Inference done 1074/1093. Dataloading: 0.0125 s/iter. Inference: 0.1947 s/iter. Eval: 0.0241 s/iter. Total: 0.2313 s/iter. ETA=0:00:04
[01/17 18:16:51] detectron2.evaluation.evaluator INFO: Total inference time: 0:04:12.013376 (0.231630 s / iter per device, on 4 devices)
[01/17 18:16:51] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:31 (0.194701 s / iter per device, on 4 devices)
[01/17 18:17:52] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 18:17:52] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 18:17:52] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 18:17:53] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 18:18:05] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0227 s/iter. Inference: 0.1732 s/iter. Eval: 0.0216 s/iter. Total: 0.2175 s/iter. ETA=0:03:55
[01/17 18:18:11] detectron2.evaluation.evaluator INFO: Inference done 32/1093. Dataloading: 0.0146 s/iter. Inference: 0.2042 s/iter. Eval: 0.0220 s/iter. Total: 0.2408 s/iter. ETA=0:04:15
[01/17 18:18:16] detectron2.evaluation.evaluator INFO: Inference done 55/1093. Dataloading: 0.0129 s/iter. Inference: 0.1951 s/iter. Eval: 0.0237 s/iter. Total: 0.2318 s/iter. ETA=0:04:00
[01/17 18:18:21] detectron2.evaluation.evaluator INFO: Inference done 75/1093. Dataloading: 0.0136 s/iter. Inference: 0.2010 s/iter. Eval: 0.0233 s/iter. Total: 0.2380 s/iter. ETA=0:04:02
[01/17 18:18:26] detectron2.evaluation.evaluator INFO: Inference done 98/1093. Dataloading: 0.0134 s/iter. Inference: 0.1978 s/iter. Eval: 0.0229 s/iter. Total: 0.2342 s/iter. ETA=0:03:53
[01/17 18:18:31] detectron2.evaluation.evaluator INFO: Inference done 121/1093. Dataloading: 0.0128 s/iter. Inference: 0.1963 s/iter. Eval: 0.0229 s/iter. Total: 0.2320 s/iter. ETA=0:03:45
[01/17 18:18:36] detectron2.evaluation.evaluator INFO: Inference done 142/1093. Dataloading: 0.0127 s/iter. Inference: 0.1977 s/iter. Eval: 0.0235 s/iter. Total: 0.2340 s/iter. ETA=0:03:42
[01/17 18:18:41] detectron2.evaluation.evaluator INFO: Inference done 163/1093. Dataloading: 0.0122 s/iter. Inference: 0.2003 s/iter. Eval: 0.0231 s/iter. Total: 0.2358 s/iter. ETA=0:03:39
[01/17 18:18:46] detectron2.evaluation.evaluator INFO: Inference done 186/1093. Dataloading: 0.0119 s/iter. Inference: 0.1987 s/iter. Eval: 0.0230 s/iter. Total: 0.2337 s/iter. ETA=0:03:31
[01/17 18:18:52] detectron2.evaluation.evaluator INFO: Inference done 208/1093. Dataloading: 0.0123 s/iter. Inference: 0.1981 s/iter. Eval: 0.0229 s/iter. Total: 0.2334 s/iter. ETA=0:03:26
[01/17 18:18:57] detectron2.evaluation.evaluator INFO: Inference done 231/1093. Dataloading: 0.0119 s/iter. Inference: 0.1973 s/iter. Eval: 0.0229 s/iter. Total: 0.2322 s/iter. ETA=0:03:20
[01/17 18:19:02] detectron2.evaluation.evaluator INFO: Inference done 253/1093. Dataloading: 0.0117 s/iter. Inference: 0.1976 s/iter. Eval: 0.0227 s/iter. Total: 0.2321 s/iter. ETA=0:03:14
[01/17 18:19:07] detectron2.evaluation.evaluator INFO: Inference done 275/1093. Dataloading: 0.0119 s/iter. Inference: 0.1971 s/iter. Eval: 0.0228 s/iter. Total: 0.2319 s/iter. ETA=0:03:09
[01/17 18:19:12] detectron2.evaluation.evaluator INFO: Inference done 297/1093. Dataloading: 0.0117 s/iter. Inference: 0.1970 s/iter. Eval: 0.0227 s/iter. Total: 0.2316 s/iter. ETA=0:03:04
[01/17 18:19:17] detectron2.evaluation.evaluator INFO: Inference done 319/1093. Dataloading: 0.0118 s/iter. Inference: 0.1972 s/iter. Eval: 0.0228 s/iter. Total: 0.2318 s/iter. ETA=0:02:59
[01/17 18:19:22] detectron2.evaluation.evaluator INFO: Inference done 341/1093. Dataloading: 0.0118 s/iter. Inference: 0.1973 s/iter. Eval: 0.0228 s/iter. Total: 0.2319 s/iter. ETA=0:02:54
[01/17 18:19:27] detectron2.evaluation.evaluator INFO: Inference done 363/1093. Dataloading: 0.0119 s/iter. Inference: 0.1970 s/iter. Eval: 0.0230 s/iter. Total: 0.2320 s/iter. ETA=0:02:49
[01/17 18:19:32] detectron2.evaluation.evaluator INFO: Inference done 385/1093. Dataloading: 0.0120 s/iter. Inference: 0.1972 s/iter. Eval: 0.0229 s/iter. Total: 0.2322 s/iter. ETA=0:02:44
[01/17 18:19:38] detectron2.evaluation.evaluator INFO: Inference done 406/1093. Dataloading: 0.0121 s/iter. Inference: 0.1977 s/iter. Eval: 0.0230 s/iter. Total: 0.2329 s/iter. ETA=0:02:40
[01/17 18:19:43] detectron2.evaluation.evaluator INFO: Inference done 429/1093. Dataloading: 0.0121 s/iter. Inference: 0.1972 s/iter. Eval: 0.0229 s/iter. Total: 0.2323 s/iter. ETA=0:02:34
[01/17 18:19:48] detectron2.evaluation.evaluator INFO: Inference done 453/1093. Dataloading: 0.0120 s/iter. Inference: 0.1964 s/iter. Eval: 0.0231 s/iter. Total: 0.2315 s/iter. ETA=0:02:28
[01/17 18:19:53] detectron2.evaluation.evaluator INFO: Inference done 476/1093. Dataloading: 0.0119 s/iter. Inference: 0.1962 s/iter. Eval: 0.0230 s/iter. Total: 0.2311 s/iter. ETA=0:02:22
[01/17 18:19:58] detectron2.evaluation.evaluator INFO: Inference done 497/1093. Dataloading: 0.0119 s/iter. Inference: 0.1966 s/iter. Eval: 0.0230 s/iter. Total: 0.2316 s/iter. ETA=0:02:18
[01/17 18:20:03] detectron2.evaluation.evaluator INFO: Inference done 519/1093. Dataloading: 0.0119 s/iter. Inference: 0.1963 s/iter. Eval: 0.0232 s/iter. Total: 0.2315 s/iter. ETA=0:02:12
[01/17 18:20:08] detectron2.evaluation.evaluator INFO: Inference done 540/1093. Dataloading: 0.0119 s/iter. Inference: 0.1969 s/iter. Eval: 0.0231 s/iter. Total: 0.2321 s/iter. ETA=0:02:08
[01/17 18:20:13] detectron2.evaluation.evaluator INFO: Inference done 560/1093. Dataloading: 0.0119 s/iter. Inference: 0.1976 s/iter. Eval: 0.0231 s/iter. Total: 0.2327 s/iter. ETA=0:02:04
[01/17 18:20:18] detectron2.evaluation.evaluator INFO: Inference done 582/1093. Dataloading: 0.0119 s/iter. Inference: 0.1973 s/iter. Eval: 0.0233 s/iter. Total: 0.2327 s/iter. ETA=0:01:58
[01/17 18:20:23] detectron2.evaluation.evaluator INFO: Inference done 605/1093. Dataloading: 0.0119 s/iter. Inference: 0.1968 s/iter. Eval: 0.0234 s/iter. Total: 0.2322 s/iter. ETA=0:01:53
[01/17 18:20:29] detectron2.evaluation.evaluator INFO: Inference done 628/1093. Dataloading: 0.0118 s/iter. Inference: 0.1966 s/iter. Eval: 0.0233 s/iter. Total: 0.2319 s/iter. ETA=0:01:47
[01/17 18:20:34] detectron2.evaluation.evaluator INFO: Inference done 651/1093. Dataloading: 0.0119 s/iter. Inference: 0.1965 s/iter. Eval: 0.0233 s/iter. Total: 0.2318 s/iter. ETA=0:01:42
[01/17 18:20:39] detectron2.evaluation.evaluator INFO: Inference done 672/1093. Dataloading: 0.0119 s/iter. Inference: 0.1967 s/iter. Eval: 0.0233 s/iter. Total: 0.2321 s/iter. ETA=0:01:37
[01/17 18:20:44] detectron2.evaluation.evaluator INFO: Inference done 692/1093. Dataloading: 0.0120 s/iter. Inference: 0.1972 s/iter. Eval: 0.0234 s/iter. Total: 0.2327 s/iter. ETA=0:01:33
[01/17 18:20:49] detectron2.evaluation.evaluator INFO: Inference done 711/1093. Dataloading: 0.0120 s/iter. Inference: 0.1984 s/iter. Eval: 0.0234 s/iter. Total: 0.2340 s/iter. ETA=0:01:29
[01/17 18:20:54] detectron2.evaluation.evaluator INFO: Inference done 730/1093. Dataloading: 0.0120 s/iter. Inference: 0.1995 s/iter. Eval: 0.0234 s/iter. Total: 0.2349 s/iter. ETA=0:01:25
[01/17 18:21:00] detectron2.evaluation.evaluator INFO: Inference done 750/1093. Dataloading: 0.0121 s/iter. Inference: 0.1999 s/iter. Eval: 0.0235 s/iter. Total: 0.2356 s/iter. ETA=0:01:20
[01/17 18:21:05] detectron2.evaluation.evaluator INFO: Inference done 770/1093. Dataloading: 0.0121 s/iter. Inference: 0.2003 s/iter. Eval: 0.0235 s/iter. Total: 0.2361 s/iter. ETA=0:01:16
[01/17 18:21:10] detectron2.evaluation.evaluator INFO: Inference done 792/1093. Dataloading: 0.0122 s/iter. Inference: 0.2002 s/iter. Eval: 0.0235 s/iter. Total: 0.2361 s/iter. ETA=0:01:11
[01/17 18:21:15] detectron2.evaluation.evaluator INFO: Inference done 812/1093. Dataloading: 0.0122 s/iter. Inference: 0.2005 s/iter. Eval: 0.0237 s/iter. Total: 0.2365 s/iter. ETA=0:01:06
[01/17 18:21:20] detectron2.evaluation.evaluator INFO: Inference done 834/1093. Dataloading: 0.0122 s/iter. Inference: 0.2002 s/iter. Eval: 0.0238 s/iter. Total: 0.2362 s/iter. ETA=0:01:01
[01/17 18:21:25] detectron2.evaluation.evaluator INFO: Inference done 857/1093. Dataloading: 0.0121 s/iter. Inference: 0.1999 s/iter. Eval: 0.0238 s/iter. Total: 0.2359 s/iter. ETA=0:00:55
[01/17 18:21:30] detectron2.evaluation.evaluator INFO: Inference done 877/1093. Dataloading: 0.0122 s/iter. Inference: 0.2004 s/iter. Eval: 0.0238 s/iter. Total: 0.2365 s/iter. ETA=0:00:51
[01/17 18:21:35] detectron2.evaluation.evaluator INFO: Inference done 897/1093. Dataloading: 0.0123 s/iter. Inference: 0.2007 s/iter. Eval: 0.0238 s/iter. Total: 0.2369 s/iter. ETA=0:00:46
[01/17 18:21:41] detectron2.evaluation.evaluator INFO: Inference done 916/1093. Dataloading: 0.0123 s/iter. Inference: 0.2015 s/iter. Eval: 0.0237 s/iter. Total: 0.2376 s/iter. ETA=0:00:42
[01/17 18:21:46] detectron2.evaluation.evaluator INFO: Inference done 936/1093. Dataloading: 0.0122 s/iter. Inference: 0.2019 s/iter. Eval: 0.0237 s/iter. Total: 0.2379 s/iter. ETA=0:00:37
[01/17 18:21:51] detectron2.evaluation.evaluator INFO: Inference done 957/1093. Dataloading: 0.0123 s/iter. Inference: 0.2020 s/iter. Eval: 0.0237 s/iter. Total: 0.2381 s/iter. ETA=0:00:32
[01/17 18:21:56] detectron2.evaluation.evaluator INFO: Inference done 979/1093. Dataloading: 0.0122 s/iter. Inference: 0.2018 s/iter. Eval: 0.0238 s/iter. Total: 0.2379 s/iter. ETA=0:00:27
[01/17 18:22:01] detectron2.evaluation.evaluator INFO: Inference done 1001/1093. Dataloading: 0.0122 s/iter. Inference: 0.2019 s/iter. Eval: 0.0237 s/iter. Total: 0.2379 s/iter. ETA=0:00:21
[01/17 18:22:06] detectron2.evaluation.evaluator INFO: Inference done 1021/1093. Dataloading: 0.0121 s/iter. Inference: 0.2021 s/iter. Eval: 0.0238 s/iter. Total: 0.2381 s/iter. ETA=0:00:17
[01/17 18:22:11] detectron2.evaluation.evaluator INFO: Inference done 1042/1093. Dataloading: 0.0121 s/iter. Inference: 0.2022 s/iter. Eval: 0.0237 s/iter. Total: 0.2382 s/iter. ETA=0:00:12
[01/17 18:22:16] detectron2.evaluation.evaluator INFO: Inference done 1064/1093. Dataloading: 0.0121 s/iter. Inference: 0.2020 s/iter. Eval: 0.0238 s/iter. Total: 0.2380 s/iter. ETA=0:00:06
[01/17 18:22:18] detectron2.engine.hooks INFO: Overall training speed: 37 iterations in 0:01:19 (2.1614 s / it)
[01/17 18:22:18] detectron2.engine.hooks INFO: Total training time: 0:10:38 (0:09:18 on hooks)
[01/17 18:22:58] detectron2 INFO: Rank of current process: 1. World size: 4
[01/17 18:23:02] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/17 18:23:02] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/17 18:23:02] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/17 18:23:02] detectron2.utils.env INFO: Using a generated random seed 2815533
[01/17 18:23:04] detectron2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/17 18:23:04] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 18:23:07] detectron2.data.build INFO: Using training sampler TrainingSampler
[01/17 18:23:08] detectron2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/17 18:23:08] detectron2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/17 18:23:08] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/17 18:23:08] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/17 18:23:08] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/17 18:23:08] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/17 18:23:08] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/17 18:23:08] detectron2.engine.train_loop INFO: Starting training from iteration 0
[01/17 18:24:21] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 18:24:22] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 18:24:22] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 18:24:22] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 18:24:35] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0152 s/iter. Inference: 0.2156 s/iter. Eval: 0.0374 s/iter. Total: 0.2682 s/iter. ETA=0:04:50
[01/17 18:24:40] detectron2.evaluation.evaluator INFO: Inference done 30/1093. Dataloading: 0.0170 s/iter. Inference: 0.2222 s/iter. Eval: 0.0310 s/iter. Total: 0.2704 s/iter. ETA=0:04:47
[01/17 18:24:45] detectron2.evaluation.evaluator INFO: Inference done 51/1093. Dataloading: 0.0170 s/iter. Inference: 0.2110 s/iter. Eval: 0.0299 s/iter. Total: 0.2580 s/iter. ETA=0:04:28
[01/17 18:24:50] detectron2.evaluation.evaluator INFO: Inference done 72/1093. Dataloading: 0.0169 s/iter. Inference: 0.2048 s/iter. Eval: 0.0302 s/iter. Total: 0.2519 s/iter. ETA=0:04:17
[01/17 18:24:56] detectron2.evaluation.evaluator INFO: Inference done 93/1093. Dataloading: 0.0167 s/iter. Inference: 0.2026 s/iter. Eval: 0.0297 s/iter. Total: 0.2491 s/iter. ETA=0:04:09
[01/17 18:25:01] detectron2.evaluation.evaluator INFO: Inference done 115/1093. Dataloading: 0.0160 s/iter. Inference: 0.1997 s/iter. Eval: 0.0292 s/iter. Total: 0.2450 s/iter. ETA=0:03:59
[01/17 18:25:06] detectron2.evaluation.evaluator INFO: Inference done 137/1093. Dataloading: 0.0151 s/iter. Inference: 0.1979 s/iter. Eval: 0.0290 s/iter. Total: 0.2421 s/iter. ETA=0:03:51
[01/17 18:25:11] detectron2.evaluation.evaluator INFO: Inference done 158/1093. Dataloading: 0.0148 s/iter. Inference: 0.1980 s/iter. Eval: 0.0292 s/iter. Total: 0.2420 s/iter. ETA=0:03:46
[01/17 18:25:16] detectron2.evaluation.evaluator INFO: Inference done 177/1093. Dataloading: 0.0146 s/iter. Inference: 0.2000 s/iter. Eval: 0.0297 s/iter. Total: 0.2444 s/iter. ETA=0:03:43
[01/17 18:25:21] detectron2.evaluation.evaluator INFO: Inference done 196/1093. Dataloading: 0.0147 s/iter. Inference: 0.2022 s/iter. Eval: 0.0301 s/iter. Total: 0.2471 s/iter. ETA=0:03:41
[01/17 18:25:26] detectron2.evaluation.evaluator INFO: Inference done 215/1093. Dataloading: 0.0148 s/iter. Inference: 0.2030 s/iter. Eval: 0.0307 s/iter. Total: 0.2486 s/iter. ETA=0:03:38
[01/17 18:25:31] detectron2.evaluation.evaluator INFO: Inference done 235/1093. Dataloading: 0.0147 s/iter. Inference: 0.2035 s/iter. Eval: 0.0308 s/iter. Total: 0.2491 s/iter. ETA=0:03:33
[01/17 18:25:36] detectron2.evaluation.evaluator INFO: Inference done 256/1093. Dataloading: 0.0146 s/iter. Inference: 0.2031 s/iter. Eval: 0.0307 s/iter. Total: 0.2485 s/iter. ETA=0:03:28
[01/17 18:25:41] detectron2.evaluation.evaluator INFO: Inference done 277/1093. Dataloading: 0.0147 s/iter. Inference: 0.2029 s/iter. Eval: 0.0306 s/iter. Total: 0.2483 s/iter. ETA=0:03:22
[01/17 18:25:46] detectron2.evaluation.evaluator INFO: Inference done 298/1093. Dataloading: 0.0150 s/iter. Inference: 0.2024 s/iter. Eval: 0.0304 s/iter. Total: 0.2478 s/iter. ETA=0:03:17
[01/17 18:25:51] detectron2.evaluation.evaluator INFO: Inference done 320/1093. Dataloading: 0.0147 s/iter. Inference: 0.2020 s/iter. Eval: 0.0302 s/iter. Total: 0.2469 s/iter. ETA=0:03:10
[01/17 18:25:56] detectron2.evaluation.evaluator INFO: Inference done 339/1093. Dataloading: 0.0147 s/iter. Inference: 0.2027 s/iter. Eval: 0.0303 s/iter. Total: 0.2479 s/iter. ETA=0:03:06
[01/17 18:26:01] detectron2.evaluation.evaluator INFO: Inference done 359/1093. Dataloading: 0.0148 s/iter. Inference: 0.2031 s/iter. Eval: 0.0302 s/iter. Total: 0.2482 s/iter. ETA=0:03:02
[01/17 18:26:07] detectron2.evaluation.evaluator INFO: Inference done 384/1093. Dataloading: 0.0146 s/iter. Inference: 0.2006 s/iter. Eval: 0.0302 s/iter. Total: 0.2455 s/iter. ETA=0:02:54
[01/17 18:26:12] detectron2.evaluation.evaluator INFO: Inference done 404/1093. Dataloading: 0.0147 s/iter. Inference: 0.2010 s/iter. Eval: 0.0301 s/iter. Total: 0.2459 s/iter. ETA=0:02:49
[01/17 18:26:17] detectron2.evaluation.evaluator INFO: Inference done 425/1093. Dataloading: 0.0148 s/iter. Inference: 0.2004 s/iter. Eval: 0.0302 s/iter. Total: 0.2455 s/iter. ETA=0:02:43
[01/17 18:26:22] detectron2.evaluation.evaluator INFO: Inference done 447/1093. Dataloading: 0.0146 s/iter. Inference: 0.2000 s/iter. Eval: 0.0301 s/iter. Total: 0.2448 s/iter. ETA=0:02:38
[01/17 18:26:27] detectron2.evaluation.evaluator INFO: Inference done 468/1093. Dataloading: 0.0145 s/iter. Inference: 0.1999 s/iter. Eval: 0.0301 s/iter. Total: 0.2446 s/iter. ETA=0:02:32
[01/17 18:26:32] detectron2.evaluation.evaluator INFO: Inference done 490/1093. Dataloading: 0.0145 s/iter. Inference: 0.1996 s/iter. Eval: 0.0300 s/iter. Total: 0.2442 s/iter. ETA=0:02:27
[01/17 18:26:37] detectron2.evaluation.evaluator INFO: Inference done 512/1093. Dataloading: 0.0144 s/iter. Inference: 0.1993 s/iter. Eval: 0.0298 s/iter. Total: 0.2435 s/iter. ETA=0:02:21
[01/17 18:26:42] detectron2.evaluation.evaluator INFO: Inference done 534/1093. Dataloading: 0.0143 s/iter. Inference: 0.1992 s/iter. Eval: 0.0296 s/iter. Total: 0.2431 s/iter. ETA=0:02:15
[01/17 18:26:47] detectron2.evaluation.evaluator INFO: Inference done 556/1093. Dataloading: 0.0143 s/iter. Inference: 0.1989 s/iter. Eval: 0.0295 s/iter. Total: 0.2428 s/iter. ETA=0:02:10
[01/17 18:26:52] detectron2.evaluation.evaluator INFO: Inference done 578/1093. Dataloading: 0.0142 s/iter. Inference: 0.1985 s/iter. Eval: 0.0295 s/iter. Total: 0.2423 s/iter. ETA=0:02:04
[01/17 18:26:58] detectron2.evaluation.evaluator INFO: Inference done 599/1093. Dataloading: 0.0142 s/iter. Inference: 0.1987 s/iter. Eval: 0.0295 s/iter. Total: 0.2425 s/iter. ETA=0:01:59
[01/17 18:27:03] detectron2.evaluation.evaluator INFO: Inference done 621/1093. Dataloading: 0.0142 s/iter. Inference: 0.1986 s/iter. Eval: 0.0294 s/iter. Total: 0.2423 s/iter. ETA=0:01:54
[01/17 18:27:08] detectron2.evaluation.evaluator INFO: Inference done 643/1093. Dataloading: 0.0143 s/iter. Inference: 0.1983 s/iter. Eval: 0.0294 s/iter. Total: 0.2420 s/iter. ETA=0:01:48
[01/17 18:27:13] detectron2.evaluation.evaluator INFO: Inference done 667/1093. Dataloading: 0.0142 s/iter. Inference: 0.1971 s/iter. Eval: 0.0294 s/iter. Total: 0.2408 s/iter. ETA=0:01:42
[01/17 18:27:18] detectron2.evaluation.evaluator INFO: Inference done 689/1093. Dataloading: 0.0142 s/iter. Inference: 0.1970 s/iter. Eval: 0.0295 s/iter. Total: 0.2408 s/iter. ETA=0:01:37
[01/17 18:27:23] detectron2.evaluation.evaluator INFO: Inference done 711/1093. Dataloading: 0.0141 s/iter. Inference: 0.1968 s/iter. Eval: 0.0294 s/iter. Total: 0.2405 s/iter. ETA=0:01:31
[01/17 18:27:29] detectron2.evaluation.evaluator INFO: Inference done 734/1093. Dataloading: 0.0140 s/iter. Inference: 0.1965 s/iter. Eval: 0.0294 s/iter. Total: 0.2399 s/iter. ETA=0:01:26
[01/17 18:27:34] detectron2.evaluation.evaluator INFO: Inference done 756/1093. Dataloading: 0.0139 s/iter. Inference: 0.1963 s/iter. Eval: 0.0293 s/iter. Total: 0.2397 s/iter. ETA=0:01:20
[01/17 18:27:39] detectron2.evaluation.evaluator INFO: Inference done 779/1093. Dataloading: 0.0138 s/iter. Inference: 0.1959 s/iter. Eval: 0.0292 s/iter. Total: 0.2391 s/iter. ETA=0:01:15
[01/17 18:27:44] detectron2.evaluation.evaluator INFO: Inference done 800/1093. Dataloading: 0.0139 s/iter. Inference: 0.1959 s/iter. Eval: 0.0292 s/iter. Total: 0.2391 s/iter. ETA=0:01:10
[01/17 18:27:49] detectron2.evaluation.evaluator INFO: Inference done 822/1093. Dataloading: 0.0139 s/iter. Inference: 0.1958 s/iter. Eval: 0.0292 s/iter. Total: 0.2390 s/iter. ETA=0:01:04
[01/17 18:27:54] detectron2.evaluation.evaluator INFO: Inference done 845/1093. Dataloading: 0.0138 s/iter. Inference: 0.1955 s/iter. Eval: 0.0291 s/iter. Total: 0.2386 s/iter. ETA=0:00:59
[01/17 18:27:59] detectron2.evaluation.evaluator INFO: Inference done 865/1093. Dataloading: 0.0138 s/iter. Inference: 0.1958 s/iter. Eval: 0.0293 s/iter. Total: 0.2390 s/iter. ETA=0:00:54
[01/17 18:28:04] detectron2.evaluation.evaluator INFO: Inference done 887/1093. Dataloading: 0.0138 s/iter. Inference: 0.1958 s/iter. Eval: 0.0292 s/iter. Total: 0.2389 s/iter. ETA=0:00:49
[01/17 18:28:09] detectron2.evaluation.evaluator INFO: Inference done 909/1093. Dataloading: 0.0138 s/iter. Inference: 0.1956 s/iter. Eval: 0.0291 s/iter. Total: 0.2386 s/iter. ETA=0:00:43
[01/17 18:28:14] detectron2.evaluation.evaluator INFO: Inference done 930/1093. Dataloading: 0.0138 s/iter. Inference: 0.1957 s/iter. Eval: 0.0291 s/iter. Total: 0.2387 s/iter. ETA=0:00:38
[01/17 18:28:20] detectron2.evaluation.evaluator INFO: Inference done 952/1093. Dataloading: 0.0138 s/iter. Inference: 0.1957 s/iter. Eval: 0.0290 s/iter. Total: 0.2386 s/iter. ETA=0:00:33
[01/17 18:28:25] detectron2.evaluation.evaluator INFO: Inference done 975/1093. Dataloading: 0.0138 s/iter. Inference: 0.1953 s/iter. Eval: 0.0290 s/iter. Total: 0.2382 s/iter. ETA=0:00:28
[01/17 18:28:30] detectron2.evaluation.evaluator INFO: Inference done 997/1093. Dataloading: 0.0138 s/iter. Inference: 0.1952 s/iter. Eval: 0.0290 s/iter. Total: 0.2380 s/iter. ETA=0:00:22
[01/17 18:28:35] detectron2.evaluation.evaluator INFO: Inference done 1020/1093. Dataloading: 0.0137 s/iter. Inference: 0.1951 s/iter. Eval: 0.0289 s/iter. Total: 0.2378 s/iter. ETA=0:00:17
[01/17 18:28:40] detectron2.evaluation.evaluator INFO: Inference done 1043/1093. Dataloading: 0.0136 s/iter. Inference: 0.1947 s/iter. Eval: 0.0289 s/iter. Total: 0.2373 s/iter. ETA=0:00:11
[01/17 18:28:45] detectron2.evaluation.evaluator INFO: Inference done 1067/1093. Dataloading: 0.0136 s/iter. Inference: 0.1943 s/iter. Eval: 0.0288 s/iter. Total: 0.2368 s/iter. ETA=0:00:06
[01/17 18:28:50] detectron2.evaluation.evaluator INFO: Inference done 1091/1093. Dataloading: 0.0136 s/iter. Inference: 0.1938 s/iter. Eval: 0.0287 s/iter. Total: 0.2362 s/iter. ETA=0:00:00
[01/17 18:28:51] detectron2.evaluation.evaluator INFO: Total inference time: 0:04:17.325606 (0.236513 s / iter per device, on 4 devices)
[01/17 18:28:51] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:30 (0.193727 s / iter per device, on 4 devices)
[01/17 18:29:25] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 18:29:26] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 18:29:26] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 18:29:26] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 18:29:39] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0115 s/iter. Inference: 0.2173 s/iter. Eval: 0.0279 s/iter. Total: 0.2567 s/iter. ETA=0:04:37
[01/17 18:29:45] detectron2.evaluation.evaluator INFO: Inference done 31/1093. Dataloading: 0.0175 s/iter. Inference: 0.2132 s/iter. Eval: 0.0256 s/iter. Total: 0.2564 s/iter. ETA=0:04:32
[01/17 18:29:50] detectron2.evaluation.evaluator INFO: Inference done 52/1093. Dataloading: 0.0167 s/iter. Inference: 0.2082 s/iter. Eval: 0.0247 s/iter. Total: 0.2497 s/iter. ETA=0:04:19
[01/17 18:29:55] detectron2.evaluation.evaluator INFO: Inference done 74/1093. Dataloading: 0.0159 s/iter. Inference: 0.2030 s/iter. Eval: 0.0248 s/iter. Total: 0.2438 s/iter. ETA=0:04:08
[01/17 18:30:00] detectron2.evaluation.evaluator INFO: Inference done 95/1093. Dataloading: 0.0153 s/iter. Inference: 0.2027 s/iter. Eval: 0.0244 s/iter. Total: 0.2425 s/iter. ETA=0:04:02
[01/17 18:30:05] detectron2.evaluation.evaluator INFO: Inference done 118/1093. Dataloading: 0.0146 s/iter. Inference: 0.2004 s/iter. Eval: 0.0245 s/iter. Total: 0.2396 s/iter. ETA=0:03:53
[01/17 18:30:10] detectron2.evaluation.evaluator INFO: Inference done 141/1093. Dataloading: 0.0142 s/iter. Inference: 0.1971 s/iter. Eval: 0.0247 s/iter. Total: 0.2361 s/iter. ETA=0:03:44
[01/17 18:30:15] detectron2.evaluation.evaluator INFO: Inference done 163/1093. Dataloading: 0.0138 s/iter. Inference: 0.1970 s/iter. Eval: 0.0245 s/iter. Total: 0.2354 s/iter. ETA=0:03:38
[01/17 18:30:16] detectron2.engine.hooks INFO: Overall training speed: 37 iterations in 0:01:23 (2.2539 s / it)
[01/17 18:30:16] detectron2.engine.hooks INFO: Total training time: 0:06:45 (0:05:21 on hooks)
[01/17 18:30:59] detectron2 INFO: Rank of current process: 1. World size: 4
[01/17 18:31:02] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/17 18:31:02] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/17 18:31:02] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/17 18:31:03] detectron2.utils.env INFO: Using a generated random seed 3114045
[01/17 18:31:04] detectron2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/17 18:31:04] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 18:31:07] detectron2.data.build INFO: Using training sampler TrainingSampler
[01/17 18:31:08] detectron2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/17 18:31:08] detectron2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/17 18:31:08] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/17 18:31:09] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/17 18:31:09] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/17 18:31:09] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/17 18:31:09] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/17 18:31:09] detectron2.engine.train_loop INFO: Starting training from iteration 0
[01/17 19:23:25] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 19:23:26] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 19:23:26] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 19:23:26] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 19:23:39] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0080 s/iter. Inference: 0.1907 s/iter. Eval: 0.1481 s/iter. Total: 0.3467 s/iter. ETA=0:06:15
[01/17 19:23:44] detectron2.evaluation.evaluator INFO: Inference done 27/1093. Dataloading: 0.0108 s/iter. Inference: 0.1615 s/iter. Eval: 0.1594 s/iter. Total: 0.3317 s/iter. ETA=0:05:53
[01/17 19:23:49] detectron2.evaluation.evaluator INFO: Inference done 43/1093. Dataloading: 0.0105 s/iter. Inference: 0.1546 s/iter. Eval: 0.1601 s/iter. Total: 0.3253 s/iter. ETA=0:05:41
[01/17 19:23:54] detectron2.evaluation.evaluator INFO: Inference done 59/1093. Dataloading: 0.0103 s/iter. Inference: 0.1573 s/iter. Eval: 0.1584 s/iter. Total: 0.3262 s/iter. ETA=0:05:37
[01/17 19:23:59] detectron2.evaluation.evaluator INFO: Inference done 75/1093. Dataloading: 0.0100 s/iter. Inference: 0.1553 s/iter. Eval: 0.1606 s/iter. Total: 0.3260 s/iter. ETA=0:05:31
[01/17 19:24:04] detectron2.evaluation.evaluator INFO: Inference done 92/1093. Dataloading: 0.0096 s/iter. Inference: 0.1542 s/iter. Eval: 0.1568 s/iter. Total: 0.3207 s/iter. ETA=0:05:21
[01/17 19:24:10] detectron2.evaluation.evaluator INFO: Inference done 109/1093. Dataloading: 0.0095 s/iter. Inference: 0.1555 s/iter. Eval: 0.1539 s/iter. Total: 0.3190 s/iter. ETA=0:05:13
[01/17 19:24:15] detectron2.evaluation.evaluator INFO: Inference done 126/1093. Dataloading: 0.0093 s/iter. Inference: 0.1544 s/iter. Eval: 0.1527 s/iter. Total: 0.3165 s/iter. ETA=0:05:06
[01/17 19:24:20] detectron2.evaluation.evaluator INFO: Inference done 143/1093. Dataloading: 0.0091 s/iter. Inference: 0.1544 s/iter. Eval: 0.1515 s/iter. Total: 0.3151 s/iter. ETA=0:04:59
[01/17 19:24:25] detectron2.evaluation.evaluator INFO: Inference done 158/1093. Dataloading: 0.0091 s/iter. Inference: 0.1559 s/iter. Eval: 0.1527 s/iter. Total: 0.3177 s/iter. ETA=0:04:57
[01/17 19:24:30] detectron2.evaluation.evaluator INFO: Inference done 174/1093. Dataloading: 0.0091 s/iter. Inference: 0.1560 s/iter. Eval: 0.1526 s/iter. Total: 0.3178 s/iter. ETA=0:04:52
[01/17 19:24:36] detectron2.evaluation.evaluator INFO: Inference done 191/1093. Dataloading: 0.0092 s/iter. Inference: 0.1559 s/iter. Eval: 0.1521 s/iter. Total: 0.3172 s/iter. ETA=0:04:46
[01/17 19:24:41] detectron2.evaluation.evaluator INFO: Inference done 207/1093. Dataloading: 0.0093 s/iter. Inference: 0.1560 s/iter. Eval: 0.1525 s/iter. Total: 0.3178 s/iter. ETA=0:04:41
[01/17 19:24:46] detectron2.evaluation.evaluator INFO: Inference done 225/1093. Dataloading: 0.0092 s/iter. Inference: 0.1563 s/iter. Eval: 0.1502 s/iter. Total: 0.3158 s/iter. ETA=0:04:34
[01/17 19:24:51] detectron2.evaluation.evaluator INFO: Inference done 241/1093. Dataloading: 0.0091 s/iter. Inference: 0.1566 s/iter. Eval: 0.1508 s/iter. Total: 0.3165 s/iter. ETA=0:04:29
[01/17 19:24:56] detectron2.evaluation.evaluator INFO: Inference done 257/1093. Dataloading: 0.0093 s/iter. Inference: 0.1557 s/iter. Eval: 0.1514 s/iter. Total: 0.3165 s/iter. ETA=0:04:24
[01/17 19:25:01] detectron2.evaluation.evaluator INFO: Inference done 274/1093. Dataloading: 0.0094 s/iter. Inference: 0.1546 s/iter. Eval: 0.1510 s/iter. Total: 0.3151 s/iter. ETA=0:04:18
[01/17 19:25:06] detectron2.evaluation.evaluator INFO: Inference done 290/1093. Dataloading: 0.0094 s/iter. Inference: 0.1540 s/iter. Eval: 0.1517 s/iter. Total: 0.3152 s/iter. ETA=0:04:13
[01/17 19:25:11] detectron2.evaluation.evaluator INFO: Inference done 307/1093. Dataloading: 0.0093 s/iter. Inference: 0.1536 s/iter. Eval: 0.1514 s/iter. Total: 0.3144 s/iter. ETA=0:04:07
[01/17 19:25:17] detectron2.evaluation.evaluator INFO: Inference done 325/1093. Dataloading: 0.0093 s/iter. Inference: 0.1534 s/iter. Eval: 0.1498 s/iter. Total: 0.3127 s/iter. ETA=0:04:00
[01/17 19:25:22] detectron2.evaluation.evaluator INFO: Inference done 342/1093. Dataloading: 0.0093 s/iter. Inference: 0.1531 s/iter. Eval: 0.1494 s/iter. Total: 0.3117 s/iter. ETA=0:03:54
[01/17 19:25:27] detectron2.evaluation.evaluator INFO: Inference done 359/1093. Dataloading: 0.0092 s/iter. Inference: 0.1526 s/iter. Eval: 0.1497 s/iter. Total: 0.3116 s/iter. ETA=0:03:48
[01/17 19:25:32] detectron2.evaluation.evaluator INFO: Inference done 375/1093. Dataloading: 0.0092 s/iter. Inference: 0.1530 s/iter. Eval: 0.1500 s/iter. Total: 0.3123 s/iter. ETA=0:03:44
[01/17 19:25:37] detectron2.evaluation.evaluator INFO: Inference done 390/1093. Dataloading: 0.0092 s/iter. Inference: 0.1529 s/iter. Eval: 0.1513 s/iter. Total: 0.3135 s/iter. ETA=0:03:40
[01/17 19:25:42] detectron2.evaluation.evaluator INFO: Inference done 405/1093. Dataloading: 0.0092 s/iter. Inference: 0.1532 s/iter. Eval: 0.1520 s/iter. Total: 0.3145 s/iter. ETA=0:03:36
[01/17 19:25:47] detectron2.evaluation.evaluator INFO: Inference done 421/1093. Dataloading: 0.0092 s/iter. Inference: 0.1531 s/iter. Eval: 0.1524 s/iter. Total: 0.3148 s/iter. ETA=0:03:31
[01/17 19:25:53] detectron2.evaluation.evaluator INFO: Inference done 437/1093. Dataloading: 0.0091 s/iter. Inference: 0.1536 s/iter. Eval: 0.1523 s/iter. Total: 0.3151 s/iter. ETA=0:03:26
[01/17 19:25:58] detectron2.evaluation.evaluator INFO: Inference done 454/1093. Dataloading: 0.0091 s/iter. Inference: 0.1537 s/iter. Eval: 0.1516 s/iter. Total: 0.3144 s/iter. ETA=0:03:20
[01/17 19:26:03] detectron2.evaluation.evaluator INFO: Inference done 471/1093. Dataloading: 0.0091 s/iter. Inference: 0.1532 s/iter. Eval: 0.1514 s/iter. Total: 0.3138 s/iter. ETA=0:03:15
[01/17 19:26:08] detectron2.evaluation.evaluator INFO: Inference done 487/1093. Dataloading: 0.0091 s/iter. Inference: 0.1533 s/iter. Eval: 0.1517 s/iter. Total: 0.3141 s/iter. ETA=0:03:10
[01/17 19:26:13] detectron2.evaluation.evaluator INFO: Inference done 502/1093. Dataloading: 0.0091 s/iter. Inference: 0.1534 s/iter. Eval: 0.1523 s/iter. Total: 0.3149 s/iter. ETA=0:03:06
[01/17 19:26:18] detectron2.evaluation.evaluator INFO: Inference done 518/1093. Dataloading: 0.0091 s/iter. Inference: 0.1534 s/iter. Eval: 0.1527 s/iter. Total: 0.3152 s/iter. ETA=0:03:01
[01/17 19:26:23] detectron2.evaluation.evaluator INFO: Inference done 534/1093. Dataloading: 0.0091 s/iter. Inference: 0.1531 s/iter. Eval: 0.1530 s/iter. Total: 0.3152 s/iter. ETA=0:02:56
[01/17 19:26:28] detectron2.evaluation.evaluator INFO: Inference done 550/1093. Dataloading: 0.0091 s/iter. Inference: 0.1532 s/iter. Eval: 0.1532 s/iter. Total: 0.3155 s/iter. ETA=0:02:51
[01/17 19:26:34] detectron2.evaluation.evaluator INFO: Inference done 565/1093. Dataloading: 0.0091 s/iter. Inference: 0.1537 s/iter. Eval: 0.1537 s/iter. Total: 0.3165 s/iter. ETA=0:02:47
[01/17 19:26:39] detectron2.evaluation.evaluator INFO: Inference done 579/1093. Dataloading: 0.0091 s/iter. Inference: 0.1540 s/iter. Eval: 0.1545 s/iter. Total: 0.3176 s/iter. ETA=0:02:43
[01/17 19:26:44] detectron2.evaluation.evaluator INFO: Inference done 595/1093. Dataloading: 0.0091 s/iter. Inference: 0.1541 s/iter. Eval: 0.1545 s/iter. Total: 0.3178 s/iter. ETA=0:02:38
[01/17 19:26:49] detectron2.evaluation.evaluator INFO: Inference done 610/1093. Dataloading: 0.0092 s/iter. Inference: 0.1543 s/iter. Eval: 0.1547 s/iter. Total: 0.3183 s/iter. ETA=0:02:33
[01/17 19:26:54] detectron2.evaluation.evaluator INFO: Inference done 626/1093. Dataloading: 0.0092 s/iter. Inference: 0.1545 s/iter. Eval: 0.1548 s/iter. Total: 0.3186 s/iter. ETA=0:02:28
[01/17 19:26:59] detectron2.evaluation.evaluator INFO: Inference done 640/1093. Dataloading: 0.0092 s/iter. Inference: 0.1548 s/iter. Eval: 0.1555 s/iter. Total: 0.3196 s/iter. ETA=0:02:24
[01/17 19:27:05] detectron2.evaluation.evaluator INFO: Inference done 656/1093. Dataloading: 0.0092 s/iter. Inference: 0.1544 s/iter. Eval: 0.1561 s/iter. Total: 0.3197 s/iter. ETA=0:02:19
[01/17 19:27:10] detectron2.evaluation.evaluator INFO: Inference done 671/1093. Dataloading: 0.0092 s/iter. Inference: 0.1548 s/iter. Eval: 0.1564 s/iter. Total: 0.3205 s/iter. ETA=0:02:15
[01/17 19:27:15] detectron2.evaluation.evaluator INFO: Inference done 686/1093. Dataloading: 0.0092 s/iter. Inference: 0.1548 s/iter. Eval: 0.1567 s/iter. Total: 0.3208 s/iter. ETA=0:02:10
[01/17 19:27:20] detectron2.evaluation.evaluator INFO: Inference done 700/1093. Dataloading: 0.0093 s/iter. Inference: 0.1553 s/iter. Eval: 0.1571 s/iter. Total: 0.3217 s/iter. ETA=0:02:06
[01/17 19:27:25] detectron2.evaluation.evaluator INFO: Inference done 716/1093. Dataloading: 0.0093 s/iter. Inference: 0.1553 s/iter. Eval: 0.1572 s/iter. Total: 0.3218 s/iter. ETA=0:02:01
[01/17 19:27:31] detectron2.evaluation.evaluator INFO: Inference done 732/1093. Dataloading: 0.0093 s/iter. Inference: 0.1554 s/iter. Eval: 0.1573 s/iter. Total: 0.3220 s/iter. ETA=0:01:56
[01/17 19:27:36] detectron2.evaluation.evaluator INFO: Inference done 748/1093. Dataloading: 0.0093 s/iter. Inference: 0.1555 s/iter. Eval: 0.1572 s/iter. Total: 0.3220 s/iter. ETA=0:01:51
[01/17 19:27:41] detectron2.evaluation.evaluator INFO: Inference done 764/1093. Dataloading: 0.0093 s/iter. Inference: 0.1554 s/iter. Eval: 0.1574 s/iter. Total: 0.3222 s/iter. ETA=0:01:46
[01/17 19:27:46] detectron2.evaluation.evaluator INFO: Inference done 780/1093. Dataloading: 0.0093 s/iter. Inference: 0.1554 s/iter. Eval: 0.1576 s/iter. Total: 0.3224 s/iter. ETA=0:01:40
[01/17 19:27:52] detectron2.evaluation.evaluator INFO: Inference done 796/1093. Dataloading: 0.0093 s/iter. Inference: 0.1554 s/iter. Eval: 0.1577 s/iter. Total: 0.3224 s/iter. ETA=0:01:35
[01/17 19:27:57] detectron2.evaluation.evaluator INFO: Inference done 811/1093. Dataloading: 0.0093 s/iter. Inference: 0.1556 s/iter. Eval: 0.1580 s/iter. Total: 0.3230 s/iter. ETA=0:01:31
[01/17 19:28:02] detectron2.evaluation.evaluator INFO: Inference done 827/1093. Dataloading: 0.0093 s/iter. Inference: 0.1558 s/iter. Eval: 0.1579 s/iter. Total: 0.3230 s/iter. ETA=0:01:25
[01/17 19:28:07] detectron2.evaluation.evaluator INFO: Inference done 844/1093. Dataloading: 0.0093 s/iter. Inference: 0.1558 s/iter. Eval: 0.1575 s/iter. Total: 0.3227 s/iter. ETA=0:01:20
[01/17 19:28:13] detectron2.evaluation.evaluator INFO: Inference done 860/1093. Dataloading: 0.0093 s/iter. Inference: 0.1559 s/iter. Eval: 0.1576 s/iter. Total: 0.3228 s/iter. ETA=0:01:15
[01/17 19:28:18] detectron2.evaluation.evaluator INFO: Inference done 875/1093. Dataloading: 0.0092 s/iter. Inference: 0.1560 s/iter. Eval: 0.1578 s/iter. Total: 0.3231 s/iter. ETA=0:01:10
[01/17 19:28:23] detectron2.evaluation.evaluator INFO: Inference done 890/1093. Dataloading: 0.0093 s/iter. Inference: 0.1561 s/iter. Eval: 0.1580 s/iter. Total: 0.3234 s/iter. ETA=0:01:05
[01/17 19:28:28] detectron2.evaluation.evaluator INFO: Inference done 906/1093. Dataloading: 0.0093 s/iter. Inference: 0.1558 s/iter. Eval: 0.1581 s/iter. Total: 0.3233 s/iter. ETA=0:01:00
[01/17 19:28:33] detectron2.evaluation.evaluator INFO: Inference done 921/1093. Dataloading: 0.0092 s/iter. Inference: 0.1562 s/iter. Eval: 0.1581 s/iter. Total: 0.3236 s/iter. ETA=0:00:55
[01/17 19:28:38] detectron2.evaluation.evaluator INFO: Inference done 936/1093. Dataloading: 0.0092 s/iter. Inference: 0.1560 s/iter. Eval: 0.1585 s/iter. Total: 0.3239 s/iter. ETA=0:00:50
[01/17 19:28:43] detectron2.evaluation.evaluator INFO: Inference done 952/1093. Dataloading: 0.0092 s/iter. Inference: 0.1561 s/iter. Eval: 0.1586 s/iter. Total: 0.3240 s/iter. ETA=0:00:45
[01/17 19:28:48] detectron2.evaluation.evaluator INFO: Inference done 967/1093. Dataloading: 0.0092 s/iter. Inference: 0.1562 s/iter. Eval: 0.1587 s/iter. Total: 0.3242 s/iter. ETA=0:00:40
[01/17 19:28:54] detectron2.evaluation.evaluator INFO: Inference done 984/1093. Dataloading: 0.0092 s/iter. Inference: 0.1561 s/iter. Eval: 0.1585 s/iter. Total: 0.3238 s/iter. ETA=0:00:35
[01/17 19:28:59] detectron2.evaluation.evaluator INFO: Inference done 1001/1093. Dataloading: 0.0092 s/iter. Inference: 0.1559 s/iter. Eval: 0.1584 s/iter. Total: 0.3236 s/iter. ETA=0:00:29
[01/17 19:29:04] detectron2.evaluation.evaluator INFO: Inference done 1017/1093. Dataloading: 0.0092 s/iter. Inference: 0.1561 s/iter. Eval: 0.1583 s/iter. Total: 0.3237 s/iter. ETA=0:00:24
[01/17 19:29:09] detectron2.evaluation.evaluator INFO: Inference done 1034/1093. Dataloading: 0.0091 s/iter. Inference: 0.1561 s/iter. Eval: 0.1579 s/iter. Total: 0.3232 s/iter. ETA=0:00:19
[01/17 19:29:14] detectron2.evaluation.evaluator INFO: Inference done 1050/1093. Dataloading: 0.0091 s/iter. Inference: 0.1561 s/iter. Eval: 0.1579 s/iter. Total: 0.3232 s/iter. ETA=0:00:13
[01/17 19:29:19] detectron2.evaluation.evaluator INFO: Inference done 1066/1093. Dataloading: 0.0091 s/iter. Inference: 0.1559 s/iter. Eval: 0.1581 s/iter. Total: 0.3232 s/iter. ETA=0:00:08
[01/17 19:29:25] detectron2.evaluation.evaluator INFO: Inference done 1083/1093. Dataloading: 0.0091 s/iter. Inference: 0.1558 s/iter. Eval: 0.1579 s/iter. Total: 0.3228 s/iter. ETA=0:00:03
[01/17 19:29:28] detectron2.evaluation.evaluator INFO: Total inference time: 0:05:51.985173 (0.323516 s / iter per device, on 4 devices)
[01/17 19:29:28] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:49 (0.155753 s / iter per device, on 4 devices)
[01/17 20:19:42] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 20:19:42] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 20:19:42] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 20:19:43] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 20:19:56] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0065 s/iter. Inference: 0.1499 s/iter. Eval: 0.1816 s/iter. Total: 0.3379 s/iter. ETA=0:06:05
[01/17 20:20:01] detectron2.evaluation.evaluator INFO: Inference done 26/1093. Dataloading: 0.0094 s/iter. Inference: 0.1527 s/iter. Eval: 0.1757 s/iter. Total: 0.3378 s/iter. ETA=0:06:00
[01/17 20:20:06] detectron2.evaluation.evaluator INFO: Inference done 39/1093. Dataloading: 0.0104 s/iter. Inference: 0.1594 s/iter. Eval: 0.1858 s/iter. Total: 0.3558 s/iter. ETA=0:06:14
[01/17 20:20:11] detectron2.evaluation.evaluator INFO: Inference done 54/1093. Dataloading: 0.0105 s/iter. Inference: 0.1580 s/iter. Eval: 0.1847 s/iter. Total: 0.3533 s/iter. ETA=0:06:07
[01/17 20:20:16] detectron2.evaluation.evaluator INFO: Inference done 64/1093. Dataloading: 0.0107 s/iter. Inference: 0.1751 s/iter. Eval: 0.1928 s/iter. Total: 0.3786 s/iter. ETA=0:06:29
[01/17 20:20:21] detectron2.evaluation.evaluator INFO: Inference done 74/1093. Dataloading: 0.0117 s/iter. Inference: 0.1874 s/iter. Eval: 0.2015 s/iter. Total: 0.4007 s/iter. ETA=0:06:48
[01/17 20:20:27] detectron2.evaluation.evaluator INFO: Inference done 85/1093. Dataloading: 0.0121 s/iter. Inference: 0.1997 s/iter. Eval: 0.2003 s/iter. Total: 0.4122 s/iter. ETA=0:06:55
[01/17 20:20:32] detectron2.evaluation.evaluator INFO: Inference done 102/1093. Dataloading: 0.0113 s/iter. Inference: 0.1900 s/iter. Eval: 0.1912 s/iter. Total: 0.3926 s/iter. ETA=0:06:29
[01/17 20:20:37] detectron2.evaluation.evaluator INFO: Inference done 119/1093. Dataloading: 0.0108 s/iter. Inference: 0.1833 s/iter. Eval: 0.1846 s/iter. Total: 0.3788 s/iter. ETA=0:06:08
[01/17 20:20:42] detectron2.evaluation.evaluator INFO: Inference done 135/1093. Dataloading: 0.0106 s/iter. Inference: 0.1805 s/iter. Eval: 0.1816 s/iter. Total: 0.3729 s/iter. ETA=0:05:57
[01/17 20:20:47] detectron2.evaluation.evaluator INFO: Inference done 152/1093. Dataloading: 0.0103 s/iter. Inference: 0.1779 s/iter. Eval: 0.1766 s/iter. Total: 0.3648 s/iter. ETA=0:05:43
[01/17 20:20:53] detectron2.evaluation.evaluator INFO: Inference done 166/1093. Dataloading: 0.0103 s/iter. Inference: 0.1772 s/iter. Eval: 0.1779 s/iter. Total: 0.3655 s/iter. ETA=0:05:38
[01/17 20:20:58] detectron2.evaluation.evaluator INFO: Inference done 182/1093. Dataloading: 0.0105 s/iter. Inference: 0.1754 s/iter. Eval: 0.1762 s/iter. Total: 0.3623 s/iter. ETA=0:05:30
[01/17 20:21:03] detectron2.evaluation.evaluator INFO: Inference done 198/1093. Dataloading: 0.0104 s/iter. Inference: 0.1733 s/iter. Eval: 0.1754 s/iter. Total: 0.3592 s/iter. ETA=0:05:21
[01/17 20:21:08] detectron2.evaluation.evaluator INFO: Inference done 215/1093. Dataloading: 0.0105 s/iter. Inference: 0.1711 s/iter. Eval: 0.1732 s/iter. Total: 0.3549 s/iter. ETA=0:05:11
[01/17 20:21:13] detectron2.evaluation.evaluator INFO: Inference done 232/1093. Dataloading: 0.0104 s/iter. Inference: 0.1696 s/iter. Eval: 0.1706 s/iter. Total: 0.3507 s/iter. ETA=0:05:01
[01/17 20:21:19] detectron2.evaluation.evaluator INFO: Inference done 248/1093. Dataloading: 0.0104 s/iter. Inference: 0.1687 s/iter. Eval: 0.1696 s/iter. Total: 0.3488 s/iter. ETA=0:04:54
[01/17 20:21:24] detectron2.evaluation.evaluator INFO: Inference done 263/1093. Dataloading: 0.0105 s/iter. Inference: 0.1683 s/iter. Eval: 0.1703 s/iter. Total: 0.3492 s/iter. ETA=0:04:49
[01/17 20:21:29] detectron2.evaluation.evaluator INFO: Inference done 281/1093. Dataloading: 0.0104 s/iter. Inference: 0.1665 s/iter. Eval: 0.1683 s/iter. Total: 0.3452 s/iter. ETA=0:04:40
[01/17 20:21:34] detectron2.evaluation.evaluator INFO: Inference done 296/1093. Dataloading: 0.0104 s/iter. Inference: 0.1655 s/iter. Eval: 0.1692 s/iter. Total: 0.3452 s/iter. ETA=0:04:35
[01/17 20:21:39] detectron2.evaluation.evaluator INFO: Inference done 313/1093. Dataloading: 0.0103 s/iter. Inference: 0.1649 s/iter. Eval: 0.1673 s/iter. Total: 0.3426 s/iter. ETA=0:04:27
[01/17 20:21:44] detectron2.evaluation.evaluator INFO: Inference done 330/1093. Dataloading: 0.0103 s/iter. Inference: 0.1646 s/iter. Eval: 0.1653 s/iter. Total: 0.3403 s/iter. ETA=0:04:19
[01/17 20:21:50] detectron2.evaluation.evaluator INFO: Inference done 346/1093. Dataloading: 0.0102 s/iter. Inference: 0.1638 s/iter. Eval: 0.1653 s/iter. Total: 0.3394 s/iter. ETA=0:04:13
[01/17 20:21:55] detectron2.evaluation.evaluator INFO: Inference done 362/1093. Dataloading: 0.0102 s/iter. Inference: 0.1631 s/iter. Eval: 0.1654 s/iter. Total: 0.3388 s/iter. ETA=0:04:07
[01/17 20:22:00] detectron2.evaluation.evaluator INFO: Inference done 377/1093. Dataloading: 0.0102 s/iter. Inference: 0.1627 s/iter. Eval: 0.1658 s/iter. Total: 0.3387 s/iter. ETA=0:04:02
[01/17 20:22:05] detectron2.evaluation.evaluator INFO: Inference done 392/1093. Dataloading: 0.0101 s/iter. Inference: 0.1621 s/iter. Eval: 0.1668 s/iter. Total: 0.3391 s/iter. ETA=0:03:57
[01/17 20:22:10] detectron2.evaluation.evaluator INFO: Inference done 407/1093. Dataloading: 0.0102 s/iter. Inference: 0.1616 s/iter. Eval: 0.1673 s/iter. Total: 0.3391 s/iter. ETA=0:03:52
[01/17 20:22:15] detectron2.evaluation.evaluator INFO: Inference done 421/1093. Dataloading: 0.0102 s/iter. Inference: 0.1613 s/iter. Eval: 0.1687 s/iter. Total: 0.3402 s/iter. ETA=0:03:48
[01/17 20:22:20] detectron2.evaluation.evaluator INFO: Inference done 437/1093. Dataloading: 0.0102 s/iter. Inference: 0.1609 s/iter. Eval: 0.1684 s/iter. Total: 0.3395 s/iter. ETA=0:03:42
[01/17 20:22:26] detectron2.evaluation.evaluator INFO: Inference done 454/1093. Dataloading: 0.0101 s/iter. Inference: 0.1608 s/iter. Eval: 0.1671 s/iter. Total: 0.3381 s/iter. ETA=0:03:36
[01/17 20:22:31] detectron2.evaluation.evaluator INFO: Inference done 469/1093. Dataloading: 0.0101 s/iter. Inference: 0.1609 s/iter. Eval: 0.1674 s/iter. Total: 0.3386 s/iter. ETA=0:03:31
[01/17 20:22:36] detectron2.evaluation.evaluator INFO: Inference done 484/1093. Dataloading: 0.0101 s/iter. Inference: 0.1610 s/iter. Eval: 0.1674 s/iter. Total: 0.3385 s/iter. ETA=0:03:26
[01/17 20:22:41] detectron2.evaluation.evaluator INFO: Inference done 499/1093. Dataloading: 0.0101 s/iter. Inference: 0.1607 s/iter. Eval: 0.1681 s/iter. Total: 0.3390 s/iter. ETA=0:03:21
[01/17 20:22:46] detectron2.evaluation.evaluator INFO: Inference done 514/1093. Dataloading: 0.0101 s/iter. Inference: 0.1606 s/iter. Eval: 0.1684 s/iter. Total: 0.3391 s/iter. ETA=0:03:16
[01/17 20:22:52] detectron2.evaluation.evaluator INFO: Inference done 529/1093. Dataloading: 0.0101 s/iter. Inference: 0.1604 s/iter. Eval: 0.1690 s/iter. Total: 0.3395 s/iter. ETA=0:03:11
[01/17 20:22:57] detectron2.evaluation.evaluator INFO: Inference done 546/1093. Dataloading: 0.0100 s/iter. Inference: 0.1597 s/iter. Eval: 0.1686 s/iter. Total: 0.3384 s/iter. ETA=0:03:05
[01/17 20:23:02] detectron2.evaluation.evaluator INFO: Inference done 561/1093. Dataloading: 0.0100 s/iter. Inference: 0.1599 s/iter. Eval: 0.1687 s/iter. Total: 0.3387 s/iter. ETA=0:03:00
[01/17 20:23:07] detectron2.evaluation.evaluator INFO: Inference done 576/1093. Dataloading: 0.0100 s/iter. Inference: 0.1595 s/iter. Eval: 0.1692 s/iter. Total: 0.3387 s/iter. ETA=0:02:55
[01/17 20:23:13] detectron2.evaluation.evaluator INFO: Inference done 592/1093. Dataloading: 0.0100 s/iter. Inference: 0.1590 s/iter. Eval: 0.1695 s/iter. Total: 0.3386 s/iter. ETA=0:02:49
[01/17 20:23:18] detectron2.evaluation.evaluator INFO: Inference done 607/1093. Dataloading: 0.0100 s/iter. Inference: 0.1589 s/iter. Eval: 0.1697 s/iter. Total: 0.3386 s/iter. ETA=0:02:44
[01/17 20:23:23] detectron2.evaluation.evaluator INFO: Inference done 623/1093. Dataloading: 0.0100 s/iter. Inference: 0.1587 s/iter. Eval: 0.1697 s/iter. Total: 0.3385 s/iter. ETA=0:02:39
[01/17 20:23:28] detectron2.evaluation.evaluator INFO: Inference done 638/1093. Dataloading: 0.0100 s/iter. Inference: 0.1584 s/iter. Eval: 0.1701 s/iter. Total: 0.3386 s/iter. ETA=0:02:34
[01/17 20:23:33] detectron2.evaluation.evaluator INFO: Inference done 653/1093. Dataloading: 0.0102 s/iter. Inference: 0.1582 s/iter. Eval: 0.1703 s/iter. Total: 0.3388 s/iter. ETA=0:02:29
[01/17 20:23:38] detectron2.evaluation.evaluator INFO: Inference done 669/1093. Dataloading: 0.0102 s/iter. Inference: 0.1577 s/iter. Eval: 0.1703 s/iter. Total: 0.3383 s/iter. ETA=0:02:23
[01/17 20:23:44] detectron2.evaluation.evaluator INFO: Inference done 683/1093. Dataloading: 0.0102 s/iter. Inference: 0.1581 s/iter. Eval: 0.1707 s/iter. Total: 0.3391 s/iter. ETA=0:02:19
[01/17 20:23:49] detectron2.evaluation.evaluator INFO: Inference done 696/1093. Dataloading: 0.0102 s/iter. Inference: 0.1582 s/iter. Eval: 0.1714 s/iter. Total: 0.3400 s/iter. ETA=0:02:14
[01/17 20:23:54] detectron2.evaluation.evaluator INFO: Inference done 710/1093. Dataloading: 0.0102 s/iter. Inference: 0.1584 s/iter. Eval: 0.1717 s/iter. Total: 0.3403 s/iter. ETA=0:02:10
[01/17 20:23:59] detectron2.evaluation.evaluator INFO: Inference done 725/1093. Dataloading: 0.0102 s/iter. Inference: 0.1582 s/iter. Eval: 0.1718 s/iter. Total: 0.3403 s/iter. ETA=0:02:05
[01/17 20:24:04] detectron2.evaluation.evaluator INFO: Inference done 742/1093. Dataloading: 0.0102 s/iter. Inference: 0.1579 s/iter. Eval: 0.1714 s/iter. Total: 0.3396 s/iter. ETA=0:01:59
[01/17 20:24:09] detectron2.evaluation.evaluator INFO: Inference done 759/1093. Dataloading: 0.0102 s/iter. Inference: 0.1573 s/iter. Eval: 0.1712 s/iter. Total: 0.3388 s/iter. ETA=0:01:53
[01/17 20:24:14] detectron2.evaluation.evaluator INFO: Inference done 775/1093. Dataloading: 0.0101 s/iter. Inference: 0.1572 s/iter. Eval: 0.1711 s/iter. Total: 0.3385 s/iter. ETA=0:01:47
[01/17 20:24:20] detectron2.evaluation.evaluator INFO: Inference done 792/1093. Dataloading: 0.0101 s/iter. Inference: 0.1568 s/iter. Eval: 0.1710 s/iter. Total: 0.3380 s/iter. ETA=0:01:41
[01/17 20:24:25] detectron2.evaluation.evaluator INFO: Inference done 807/1093. Dataloading: 0.0101 s/iter. Inference: 0.1567 s/iter. Eval: 0.1715 s/iter. Total: 0.3383 s/iter. ETA=0:01:36
[01/17 20:24:30] detectron2.evaluation.evaluator INFO: Inference done 823/1093. Dataloading: 0.0100 s/iter. Inference: 0.1563 s/iter. Eval: 0.1714 s/iter. Total: 0.3378 s/iter. ETA=0:01:31
[01/17 20:24:36] detectron2.evaluation.evaluator INFO: Inference done 841/1093. Dataloading: 0.0100 s/iter. Inference: 0.1560 s/iter. Eval: 0.1709 s/iter. Total: 0.3370 s/iter. ETA=0:01:24
[01/17 20:24:41] detectron2.evaluation.evaluator INFO: Inference done 857/1093. Dataloading: 0.0100 s/iter. Inference: 0.1560 s/iter. Eval: 0.1708 s/iter. Total: 0.3369 s/iter. ETA=0:01:19
[01/17 20:24:46] detectron2.evaluation.evaluator INFO: Inference done 872/1093. Dataloading: 0.0100 s/iter. Inference: 0.1558 s/iter. Eval: 0.1710 s/iter. Total: 0.3369 s/iter. ETA=0:01:14
[01/17 20:24:51] detectron2.evaluation.evaluator INFO: Inference done 887/1093. Dataloading: 0.0100 s/iter. Inference: 0.1558 s/iter. Eval: 0.1711 s/iter. Total: 0.3369 s/iter. ETA=0:01:09
[01/17 20:24:56] detectron2.evaluation.evaluator INFO: Inference done 903/1093. Dataloading: 0.0100 s/iter. Inference: 0.1555 s/iter. Eval: 0.1712 s/iter. Total: 0.3367 s/iter. ETA=0:01:03
[01/17 20:25:01] detectron2.evaluation.evaluator INFO: Inference done 919/1093. Dataloading: 0.0100 s/iter. Inference: 0.1555 s/iter. Eval: 0.1709 s/iter. Total: 0.3365 s/iter. ETA=0:00:58
[01/17 20:25:07] detectron2.evaluation.evaluator INFO: Inference done 935/1093. Dataloading: 0.0099 s/iter. Inference: 0.1553 s/iter. Eval: 0.1710 s/iter. Total: 0.3364 s/iter. ETA=0:00:53
[01/17 20:25:12] detectron2.evaluation.evaluator INFO: Inference done 951/1093. Dataloading: 0.0099 s/iter. Inference: 0.1549 s/iter. Eval: 0.1712 s/iter. Total: 0.3361 s/iter. ETA=0:00:47
[01/17 20:25:17] detectron2.evaluation.evaluator INFO: Inference done 967/1093. Dataloading: 0.0099 s/iter. Inference: 0.1548 s/iter. Eval: 0.1712 s/iter. Total: 0.3360 s/iter. ETA=0:00:42
[01/17 20:25:22] detectron2.evaluation.evaluator INFO: Inference done 984/1093. Dataloading: 0.0099 s/iter. Inference: 0.1549 s/iter. Eval: 0.1707 s/iter. Total: 0.3356 s/iter. ETA=0:00:36
[01/17 20:25:28] detectron2.evaluation.evaluator INFO: Inference done 1002/1093. Dataloading: 0.0098 s/iter. Inference: 0.1545 s/iter. Eval: 0.1703 s/iter. Total: 0.3348 s/iter. ETA=0:00:30
[01/17 20:25:33] detectron2.evaluation.evaluator INFO: Inference done 1019/1093. Dataloading: 0.0098 s/iter. Inference: 0.1543 s/iter. Eval: 0.1700 s/iter. Total: 0.3343 s/iter. ETA=0:00:24
[01/17 20:25:38] detectron2.evaluation.evaluator INFO: Inference done 1037/1093. Dataloading: 0.0098 s/iter. Inference: 0.1542 s/iter. Eval: 0.1695 s/iter. Total: 0.3336 s/iter. ETA=0:00:18
[01/17 20:25:43] detectron2.evaluation.evaluator INFO: Inference done 1053/1093. Dataloading: 0.0098 s/iter. Inference: 0.1542 s/iter. Eval: 0.1695 s/iter. Total: 0.3335 s/iter. ETA=0:00:13
[01/17 20:25:49] detectron2.evaluation.evaluator INFO: Inference done 1069/1093. Dataloading: 0.0098 s/iter. Inference: 0.1542 s/iter. Eval: 0.1693 s/iter. Total: 0.3334 s/iter. ETA=0:00:08
[01/17 20:25:54] detectron2.evaluation.evaluator INFO: Inference done 1087/1093. Dataloading: 0.0097 s/iter. Inference: 0.1539 s/iter. Eval: 0.1690 s/iter. Total: 0.3327 s/iter. ETA=0:00:01
[01/17 20:25:56] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:02.118835 (0.332830 s / iter per device, on 4 devices)
[01/17 20:25:56] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:47 (0.153834 s / iter per device, on 4 devices)
[01/17 21:15:47] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 21:15:47] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 21:15:47] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 21:15:48] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 21:16:01] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0094 s/iter. Inference: 0.1351 s/iter. Eval: 0.1958 s/iter. Total: 0.3403 s/iter. ETA=0:06:08
[01/17 21:16:06] detectron2.evaluation.evaluator INFO: Inference done 25/1093. Dataloading: 0.0120 s/iter. Inference: 0.1587 s/iter. Eval: 0.1907 s/iter. Total: 0.3615 s/iter. ETA=0:06:26
[01/17 21:16:11] detectron2.evaluation.evaluator INFO: Inference done 40/1093. Dataloading: 0.0115 s/iter. Inference: 0.1524 s/iter. Eval: 0.1870 s/iter. Total: 0.3511 s/iter. ETA=0:06:09
[01/17 21:16:16] detectron2.evaluation.evaluator INFO: Inference done 57/1093. Dataloading: 0.0107 s/iter. Inference: 0.1474 s/iter. Eval: 0.1771 s/iter. Total: 0.3353 s/iter. ETA=0:05:47
[01/17 21:16:22] detectron2.evaluation.evaluator INFO: Inference done 72/1093. Dataloading: 0.0105 s/iter. Inference: 0.1483 s/iter. Eval: 0.1804 s/iter. Total: 0.3393 s/iter. ETA=0:05:46
[01/17 21:16:27] detectron2.evaluation.evaluator INFO: Inference done 89/1093. Dataloading: 0.0103 s/iter. Inference: 0.1481 s/iter. Eval: 0.1747 s/iter. Total: 0.3331 s/iter. ETA=0:05:34
[01/17 21:16:32] detectron2.evaluation.evaluator INFO: Inference done 106/1093. Dataloading: 0.0098 s/iter. Inference: 0.1472 s/iter. Eval: 0.1697 s/iter. Total: 0.3269 s/iter. ETA=0:05:22
[01/17 21:16:37] detectron2.evaluation.evaluator INFO: Inference done 122/1093. Dataloading: 0.0097 s/iter. Inference: 0.1495 s/iter. Eval: 0.1659 s/iter. Total: 0.3251 s/iter. ETA=0:05:15
[01/17 21:16:42] detectron2.evaluation.evaluator INFO: Inference done 138/1093. Dataloading: 0.0102 s/iter. Inference: 0.1507 s/iter. Eval: 0.1637 s/iter. Total: 0.3247 s/iter. ETA=0:05:10
[01/17 21:16:47] detectron2.evaluation.evaluator INFO: Inference done 155/1093. Dataloading: 0.0100 s/iter. Inference: 0.1507 s/iter. Eval: 0.1613 s/iter. Total: 0.3221 s/iter. ETA=0:05:02
[01/17 21:16:53] detectron2.evaluation.evaluator INFO: Inference done 171/1093. Dataloading: 0.0098 s/iter. Inference: 0.1518 s/iter. Eval: 0.1615 s/iter. Total: 0.3232 s/iter. ETA=0:04:58
[01/17 21:16:58] detectron2.evaluation.evaluator INFO: Inference done 186/1093. Dataloading: 0.0098 s/iter. Inference: 0.1518 s/iter. Eval: 0.1624 s/iter. Total: 0.3241 s/iter. ETA=0:04:53
[01/17 21:17:03] detectron2.evaluation.evaluator INFO: Inference done 201/1093. Dataloading: 0.0098 s/iter. Inference: 0.1530 s/iter. Eval: 0.1634 s/iter. Total: 0.3263 s/iter. ETA=0:04:51
[01/17 21:17:08] detectron2.evaluation.evaluator INFO: Inference done 218/1093. Dataloading: 0.0097 s/iter. Inference: 0.1526 s/iter. Eval: 0.1618 s/iter. Total: 0.3242 s/iter. ETA=0:04:43
[01/17 21:17:13] detectron2.evaluation.evaluator INFO: Inference done 233/1093. Dataloading: 0.0098 s/iter. Inference: 0.1534 s/iter. Eval: 0.1628 s/iter. Total: 0.3260 s/iter. ETA=0:04:40
[01/17 21:17:18] detectron2.evaluation.evaluator INFO: Inference done 249/1093. Dataloading: 0.0098 s/iter. Inference: 0.1529 s/iter. Eval: 0.1630 s/iter. Total: 0.3257 s/iter. ETA=0:04:34
[01/17 21:17:23] detectron2.evaluation.evaluator INFO: Inference done 264/1093. Dataloading: 0.0098 s/iter. Inference: 0.1525 s/iter. Eval: 0.1641 s/iter. Total: 0.3265 s/iter. ETA=0:04:30
[01/17 21:17:28] detectron2.evaluation.evaluator INFO: Inference done 279/1093. Dataloading: 0.0097 s/iter. Inference: 0.1529 s/iter. Eval: 0.1643 s/iter. Total: 0.3270 s/iter. ETA=0:04:26
[01/17 21:17:34] detectron2.evaluation.evaluator INFO: Inference done 294/1093. Dataloading: 0.0097 s/iter. Inference: 0.1535 s/iter. Eval: 0.1653 s/iter. Total: 0.3286 s/iter. ETA=0:04:22
[01/17 21:17:39] detectron2.evaluation.evaluator INFO: Inference done 312/1093. Dataloading: 0.0096 s/iter. Inference: 0.1529 s/iter. Eval: 0.1634 s/iter. Total: 0.3260 s/iter. ETA=0:04:14
[01/17 21:17:44] detectron2.evaluation.evaluator INFO: Inference done 330/1093. Dataloading: 0.0096 s/iter. Inference: 0.1523 s/iter. Eval: 0.1622 s/iter. Total: 0.3242 s/iter. ETA=0:04:07
[01/17 21:17:49] detectron2.evaluation.evaluator INFO: Inference done 347/1093. Dataloading: 0.0096 s/iter. Inference: 0.1521 s/iter. Eval: 0.1616 s/iter. Total: 0.3234 s/iter. ETA=0:04:01
[01/17 21:17:54] detectron2.evaluation.evaluator INFO: Inference done 361/1093. Dataloading: 0.0096 s/iter. Inference: 0.1523 s/iter. Eval: 0.1628 s/iter. Total: 0.3247 s/iter. ETA=0:03:57
[01/17 21:18:00] detectron2.evaluation.evaluator INFO: Inference done 377/1093. Dataloading: 0.0096 s/iter. Inference: 0.1524 s/iter. Eval: 0.1623 s/iter. Total: 0.3244 s/iter. ETA=0:03:52
[01/17 21:18:05] detectron2.evaluation.evaluator INFO: Inference done 391/1093. Dataloading: 0.0096 s/iter. Inference: 0.1523 s/iter. Eval: 0.1640 s/iter. Total: 0.3261 s/iter. ETA=0:03:48
[01/17 21:18:10] detectron2.evaluation.evaluator INFO: Inference done 405/1093. Dataloading: 0.0096 s/iter. Inference: 0.1522 s/iter. Eval: 0.1653 s/iter. Total: 0.3272 s/iter. ETA=0:03:45
[01/17 21:18:15] detectron2.evaluation.evaluator INFO: Inference done 420/1093. Dataloading: 0.0097 s/iter. Inference: 0.1522 s/iter. Eval: 0.1661 s/iter. Total: 0.3281 s/iter. ETA=0:03:40
[01/17 21:18:20] detectron2.evaluation.evaluator INFO: Inference done 436/1093. Dataloading: 0.0097 s/iter. Inference: 0.1523 s/iter. Eval: 0.1658 s/iter. Total: 0.3278 s/iter. ETA=0:03:35
[01/17 21:18:25] detectron2.evaluation.evaluator INFO: Inference done 453/1093. Dataloading: 0.0096 s/iter. Inference: 0.1523 s/iter. Eval: 0.1651 s/iter. Total: 0.3271 s/iter. ETA=0:03:29
[01/17 21:18:31] detectron2.evaluation.evaluator INFO: Inference done 470/1093. Dataloading: 0.0096 s/iter. Inference: 0.1523 s/iter. Eval: 0.1650 s/iter. Total: 0.3269 s/iter. ETA=0:03:23
[01/17 21:18:36] detectron2.evaluation.evaluator INFO: Inference done 487/1093. Dataloading: 0.0096 s/iter. Inference: 0.1523 s/iter. Eval: 0.1643 s/iter. Total: 0.3263 s/iter. ETA=0:03:17
[01/17 21:18:42] detectron2.evaluation.evaluator INFO: Inference done 502/1093. Dataloading: 0.0096 s/iter. Inference: 0.1523 s/iter. Eval: 0.1653 s/iter. Total: 0.3273 s/iter. ETA=0:03:13
[01/17 21:18:47] detectron2.evaluation.evaluator INFO: Inference done 518/1093. Dataloading: 0.0095 s/iter. Inference: 0.1521 s/iter. Eval: 0.1653 s/iter. Total: 0.3270 s/iter. ETA=0:03:08
[01/17 21:18:52] detectron2.evaluation.evaluator INFO: Inference done 532/1093. Dataloading: 0.0096 s/iter. Inference: 0.1522 s/iter. Eval: 0.1660 s/iter. Total: 0.3279 s/iter. ETA=0:03:03
[01/17 21:18:57] detectron2.evaluation.evaluator INFO: Inference done 549/1093. Dataloading: 0.0096 s/iter. Inference: 0.1520 s/iter. Eval: 0.1655 s/iter. Total: 0.3272 s/iter. ETA=0:02:57
[01/17 21:19:02] detectron2.evaluation.evaluator INFO: Inference done 564/1093. Dataloading: 0.0096 s/iter. Inference: 0.1520 s/iter. Eval: 0.1658 s/iter. Total: 0.3275 s/iter. ETA=0:02:53
[01/17 21:19:07] detectron2.evaluation.evaluator INFO: Inference done 578/1093. Dataloading: 0.0096 s/iter. Inference: 0.1522 s/iter. Eval: 0.1667 s/iter. Total: 0.3286 s/iter. ETA=0:02:49
[01/17 21:19:12] detectron2.evaluation.evaluator INFO: Inference done 593/1093. Dataloading: 0.0096 s/iter. Inference: 0.1524 s/iter. Eval: 0.1668 s/iter. Total: 0.3288 s/iter. ETA=0:02:44
[01/17 21:19:17] detectron2.evaluation.evaluator INFO: Inference done 608/1093. Dataloading: 0.0096 s/iter. Inference: 0.1529 s/iter. Eval: 0.1666 s/iter. Total: 0.3292 s/iter. ETA=0:02:39
[01/17 21:19:23] detectron2.evaluation.evaluator INFO: Inference done 624/1093. Dataloading: 0.0096 s/iter. Inference: 0.1532 s/iter. Eval: 0.1660 s/iter. Total: 0.3289 s/iter. ETA=0:02:34
[01/17 21:19:28] detectron2.evaluation.evaluator INFO: Inference done 639/1093. Dataloading: 0.0097 s/iter. Inference: 0.1532 s/iter. Eval: 0.1664 s/iter. Total: 0.3294 s/iter. ETA=0:02:29
[01/17 21:19:33] detectron2.evaluation.evaluator INFO: Inference done 654/1093. Dataloading: 0.0097 s/iter. Inference: 0.1531 s/iter. Eval: 0.1670 s/iter. Total: 0.3298 s/iter. ETA=0:02:24
[01/17 21:19:38] detectron2.evaluation.evaluator INFO: Inference done 669/1093. Dataloading: 0.0097 s/iter. Inference: 0.1529 s/iter. Eval: 0.1672 s/iter. Total: 0.3299 s/iter. ETA=0:02:19
[01/17 21:19:43] detectron2.evaluation.evaluator INFO: Inference done 685/1093. Dataloading: 0.0096 s/iter. Inference: 0.1529 s/iter. Eval: 0.1673 s/iter. Total: 0.3299 s/iter. ETA=0:02:14
[01/17 21:19:48] detectron2.evaluation.evaluator INFO: Inference done 699/1093. Dataloading: 0.0097 s/iter. Inference: 0.1530 s/iter. Eval: 0.1677 s/iter. Total: 0.3305 s/iter. ETA=0:02:10
[01/17 21:19:53] detectron2.evaluation.evaluator INFO: Inference done 715/1093. Dataloading: 0.0096 s/iter. Inference: 0.1531 s/iter. Eval: 0.1676 s/iter. Total: 0.3303 s/iter. ETA=0:02:04
[01/17 21:19:59] detectron2.evaluation.evaluator INFO: Inference done 731/1093. Dataloading: 0.0096 s/iter. Inference: 0.1529 s/iter. Eval: 0.1675 s/iter. Total: 0.3301 s/iter. ETA=0:01:59
[01/17 21:20:04] detectron2.evaluation.evaluator INFO: Inference done 748/1093. Dataloading: 0.0096 s/iter. Inference: 0.1526 s/iter. Eval: 0.1674 s/iter. Total: 0.3297 s/iter. ETA=0:01:53
[01/17 21:20:09] detectron2.evaluation.evaluator INFO: Inference done 763/1093. Dataloading: 0.0096 s/iter. Inference: 0.1526 s/iter. Eval: 0.1676 s/iter. Total: 0.3299 s/iter. ETA=0:01:48
[01/17 21:20:14] detectron2.evaluation.evaluator INFO: Inference done 779/1093. Dataloading: 0.0096 s/iter. Inference: 0.1522 s/iter. Eval: 0.1678 s/iter. Total: 0.3297 s/iter. ETA=0:01:43
[01/17 21:20:19] detectron2.evaluation.evaluator INFO: Inference done 796/1093. Dataloading: 0.0096 s/iter. Inference: 0.1520 s/iter. Eval: 0.1678 s/iter. Total: 0.3294 s/iter. ETA=0:01:37
[01/17 21:20:25] detectron2.evaluation.evaluator INFO: Inference done 811/1093. Dataloading: 0.0096 s/iter. Inference: 0.1522 s/iter. Eval: 0.1679 s/iter. Total: 0.3298 s/iter. ETA=0:01:32
[01/17 21:20:30] detectron2.evaluation.evaluator INFO: Inference done 827/1093. Dataloading: 0.0096 s/iter. Inference: 0.1521 s/iter. Eval: 0.1678 s/iter. Total: 0.3295 s/iter. ETA=0:01:27
[01/17 21:20:35] detectron2.evaluation.evaluator INFO: Inference done 843/1093. Dataloading: 0.0096 s/iter. Inference: 0.1523 s/iter. Eval: 0.1674 s/iter. Total: 0.3294 s/iter. ETA=0:01:22
[01/17 21:20:40] detectron2.evaluation.evaluator INFO: Inference done 859/1093. Dataloading: 0.0095 s/iter. Inference: 0.1523 s/iter. Eval: 0.1673 s/iter. Total: 0.3292 s/iter. ETA=0:01:17
[01/17 21:20:45] detectron2.evaluation.evaluator INFO: Inference done 874/1093. Dataloading: 0.0095 s/iter. Inference: 0.1524 s/iter. Eval: 0.1674 s/iter. Total: 0.3294 s/iter. ETA=0:01:12
[01/17 21:20:50] detectron2.evaluation.evaluator INFO: Inference done 888/1093. Dataloading: 0.0096 s/iter. Inference: 0.1528 s/iter. Eval: 0.1675 s/iter. Total: 0.3299 s/iter. ETA=0:01:07
[01/17 21:20:55] detectron2.evaluation.evaluator INFO: Inference done 903/1093. Dataloading: 0.0095 s/iter. Inference: 0.1530 s/iter. Eval: 0.1676 s/iter. Total: 0.3302 s/iter. ETA=0:01:02
[01/17 21:21:00] detectron2.evaluation.evaluator INFO: Inference done 919/1093. Dataloading: 0.0095 s/iter. Inference: 0.1528 s/iter. Eval: 0.1675 s/iter. Total: 0.3300 s/iter. ETA=0:00:57
[01/17 21:21:06] detectron2.evaluation.evaluator INFO: Inference done 933/1093. Dataloading: 0.0095 s/iter. Inference: 0.1529 s/iter. Eval: 0.1679 s/iter. Total: 0.3305 s/iter. ETA=0:00:52
[01/17 21:21:11] detectron2.evaluation.evaluator INFO: Inference done 946/1093. Dataloading: 0.0096 s/iter. Inference: 0.1532 s/iter. Eval: 0.1684 s/iter. Total: 0.3313 s/iter. ETA=0:00:48
[01/17 21:21:16] detectron2.evaluation.evaluator INFO: Inference done 962/1093. Dataloading: 0.0096 s/iter. Inference: 0.1533 s/iter. Eval: 0.1682 s/iter. Total: 0.3312 s/iter. ETA=0:00:43
[01/17 21:21:21] detectron2.evaluation.evaluator INFO: Inference done 978/1093. Dataloading: 0.0096 s/iter. Inference: 0.1534 s/iter. Eval: 0.1678 s/iter. Total: 0.3309 s/iter. ETA=0:00:38
[01/17 21:21:26] detectron2.evaluation.evaluator INFO: Inference done 995/1093. Dataloading: 0.0095 s/iter. Inference: 0.1533 s/iter. Eval: 0.1675 s/iter. Total: 0.3304 s/iter. ETA=0:00:32
[01/17 21:21:31] detectron2.evaluation.evaluator INFO: Inference done 1010/1093. Dataloading: 0.0095 s/iter. Inference: 0.1534 s/iter. Eval: 0.1675 s/iter. Total: 0.3305 s/iter. ETA=0:00:27
[01/17 21:21:36] detectron2.evaluation.evaluator INFO: Inference done 1027/1093. Dataloading: 0.0095 s/iter. Inference: 0.1533 s/iter. Eval: 0.1673 s/iter. Total: 0.3302 s/iter. ETA=0:00:21
[01/17 21:21:41] detectron2.evaluation.evaluator INFO: Inference done 1044/1093. Dataloading: 0.0095 s/iter. Inference: 0.1532 s/iter. Eval: 0.1669 s/iter. Total: 0.3297 s/iter. ETA=0:00:16
[01/17 21:21:47] detectron2.evaluation.evaluator INFO: Inference done 1060/1093. Dataloading: 0.0095 s/iter. Inference: 0.1532 s/iter. Eval: 0.1669 s/iter. Total: 0.3296 s/iter. ETA=0:00:10
[01/17 21:21:52] detectron2.evaluation.evaluator INFO: Inference done 1077/1093. Dataloading: 0.0095 s/iter. Inference: 0.1530 s/iter. Eval: 0.1665 s/iter. Total: 0.3291 s/iter. ETA=0:00:05
[01/17 21:21:57] detectron2.evaluation.evaluator INFO: Total inference time: 0:05:58.038419 (0.329079 s / iter per device, on 4 devices)
[01/17 21:21:57] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:46 (0.152889 s / iter per device, on 4 devices)
[01/17 22:11:54] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 22:11:54] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 22:11:54] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 22:11:55] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 22:12:08] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0062 s/iter. Inference: 0.1454 s/iter. Eval: 0.1739 s/iter. Total: 0.3255 s/iter. ETA=0:05:52
[01/17 22:12:13] detectron2.evaluation.evaluator INFO: Inference done 25/1093. Dataloading: 0.0110 s/iter. Inference: 0.1608 s/iter. Eval: 0.1876 s/iter. Total: 0.3595 s/iter. ETA=0:06:23
[01/17 22:12:18] detectron2.evaluation.evaluator INFO: Inference done 38/1093. Dataloading: 0.0127 s/iter. Inference: 0.1587 s/iter. Eval: 0.1988 s/iter. Total: 0.3703 s/iter. ETA=0:06:30
[01/17 22:12:24] detectron2.evaluation.evaluator INFO: Inference done 54/1093. Dataloading: 0.0118 s/iter. Inference: 0.1531 s/iter. Eval: 0.1900 s/iter. Total: 0.3550 s/iter. ETA=0:06:08
[01/17 22:12:29] detectron2.evaluation.evaluator INFO: Inference done 70/1093. Dataloading: 0.0111 s/iter. Inference: 0.1514 s/iter. Eval: 0.1847 s/iter. Total: 0.3473 s/iter. ETA=0:05:55
[01/17 22:12:34] detectron2.evaluation.evaluator INFO: Inference done 85/1093. Dataloading: 0.0109 s/iter. Inference: 0.1517 s/iter. Eval: 0.1822 s/iter. Total: 0.3449 s/iter. ETA=0:05:47
[01/17 22:12:39] detectron2.evaluation.evaluator INFO: Inference done 103/1093. Dataloading: 0.0102 s/iter. Inference: 0.1503 s/iter. Eval: 0.1748 s/iter. Total: 0.3354 s/iter. ETA=0:05:32
[01/17 22:12:44] detectron2.evaluation.evaluator INFO: Inference done 120/1093. Dataloading: 0.0099 s/iter. Inference: 0.1507 s/iter. Eval: 0.1713 s/iter. Total: 0.3319 s/iter. ETA=0:05:22
[01/17 22:12:50] detectron2.evaluation.evaluator INFO: Inference done 137/1093. Dataloading: 0.0097 s/iter. Inference: 0.1497 s/iter. Eval: 0.1695 s/iter. Total: 0.3290 s/iter. ETA=0:05:14
[01/17 22:12:55] detectron2.evaluation.evaluator INFO: Inference done 154/1093. Dataloading: 0.0096 s/iter. Inference: 0.1497 s/iter. Eval: 0.1663 s/iter. Total: 0.3257 s/iter. ETA=0:05:05
[01/17 22:13:00] detectron2.evaluation.evaluator INFO: Inference done 169/1093. Dataloading: 0.0095 s/iter. Inference: 0.1506 s/iter. Eval: 0.1671 s/iter. Total: 0.3273 s/iter. ETA=0:05:02
[01/17 22:13:05] detectron2.evaluation.evaluator INFO: Inference done 184/1093. Dataloading: 0.0096 s/iter. Inference: 0.1520 s/iter. Eval: 0.1668 s/iter. Total: 0.3284 s/iter. ETA=0:04:58
[01/17 22:13:10] detectron2.evaluation.evaluator INFO: Inference done 198/1093. Dataloading: 0.0095 s/iter. Inference: 0.1527 s/iter. Eval: 0.1682 s/iter. Total: 0.3305 s/iter. ETA=0:04:55
[01/17 22:13:15] detectron2.evaluation.evaluator INFO: Inference done 214/1093. Dataloading: 0.0096 s/iter. Inference: 0.1535 s/iter. Eval: 0.1668 s/iter. Total: 0.3300 s/iter. ETA=0:04:50
[01/17 22:13:20] detectron2.evaluation.evaluator INFO: Inference done 230/1093. Dataloading: 0.0096 s/iter. Inference: 0.1548 s/iter. Eval: 0.1653 s/iter. Total: 0.3298 s/iter. ETA=0:04:44
[01/17 22:13:25] detectron2.evaluation.evaluator INFO: Inference done 245/1093. Dataloading: 0.0096 s/iter. Inference: 0.1557 s/iter. Eval: 0.1650 s/iter. Total: 0.3304 s/iter. ETA=0:04:40
[01/17 22:13:30] detectron2.evaluation.evaluator INFO: Inference done 260/1093. Dataloading: 0.0096 s/iter. Inference: 0.1552 s/iter. Eval: 0.1657 s/iter. Total: 0.3306 s/iter. ETA=0:04:35
[01/17 22:13:35] detectron2.evaluation.evaluator INFO: Inference done 277/1093. Dataloading: 0.0095 s/iter. Inference: 0.1547 s/iter. Eval: 0.1642 s/iter. Total: 0.3285 s/iter. ETA=0:04:28
[01/17 22:13:41] detectron2.evaluation.evaluator INFO: Inference done 292/1093. Dataloading: 0.0096 s/iter. Inference: 0.1550 s/iter. Eval: 0.1653 s/iter. Total: 0.3299 s/iter. ETA=0:04:24
[01/17 22:13:46] detectron2.evaluation.evaluator INFO: Inference done 308/1093. Dataloading: 0.0096 s/iter. Inference: 0.1551 s/iter. Eval: 0.1650 s/iter. Total: 0.3297 s/iter. ETA=0:04:18
[01/17 22:13:51] detectron2.evaluation.evaluator INFO: Inference done 325/1093. Dataloading: 0.0096 s/iter. Inference: 0.1554 s/iter. Eval: 0.1636 s/iter. Total: 0.3287 s/iter. ETA=0:04:12
[01/17 22:13:56] detectron2.evaluation.evaluator INFO: Inference done 341/1093. Dataloading: 0.0097 s/iter. Inference: 0.1553 s/iter. Eval: 0.1631 s/iter. Total: 0.3282 s/iter. ETA=0:04:06
[01/17 22:14:01] detectron2.evaluation.evaluator INFO: Inference done 356/1093. Dataloading: 0.0097 s/iter. Inference: 0.1549 s/iter. Eval: 0.1639 s/iter. Total: 0.3286 s/iter. ETA=0:04:02
[01/17 22:14:07] detectron2.evaluation.evaluator INFO: Inference done 372/1093. Dataloading: 0.0097 s/iter. Inference: 0.1549 s/iter. Eval: 0.1646 s/iter. Total: 0.3293 s/iter. ETA=0:03:57
[01/17 22:14:12] detectron2.evaluation.evaluator INFO: Inference done 385/1093. Dataloading: 0.0098 s/iter. Inference: 0.1554 s/iter. Eval: 0.1662 s/iter. Total: 0.3314 s/iter. ETA=0:03:54
[01/17 22:14:17] detectron2.evaluation.evaluator INFO: Inference done 399/1093. Dataloading: 0.0098 s/iter. Inference: 0.1558 s/iter. Eval: 0.1671 s/iter. Total: 0.3328 s/iter. ETA=0:03:50
[01/17 22:14:22] detectron2.evaluation.evaluator INFO: Inference done 413/1093. Dataloading: 0.0099 s/iter. Inference: 0.1560 s/iter. Eval: 0.1681 s/iter. Total: 0.3340 s/iter. ETA=0:03:47
[01/17 22:14:28] detectron2.evaluation.evaluator INFO: Inference done 428/1093. Dataloading: 0.0099 s/iter. Inference: 0.1559 s/iter. Eval: 0.1688 s/iter. Total: 0.3346 s/iter. ETA=0:03:42
[01/17 22:14:33] detectron2.evaluation.evaluator INFO: Inference done 444/1093. Dataloading: 0.0098 s/iter. Inference: 0.1557 s/iter. Eval: 0.1686 s/iter. Total: 0.3342 s/iter. ETA=0:03:36
[01/17 22:14:38] detectron2.evaluation.evaluator INFO: Inference done 461/1093. Dataloading: 0.0097 s/iter. Inference: 0.1557 s/iter. Eval: 0.1674 s/iter. Total: 0.3330 s/iter. ETA=0:03:30
[01/17 22:14:43] detectron2.evaluation.evaluator INFO: Inference done 477/1093. Dataloading: 0.0097 s/iter. Inference: 0.1556 s/iter. Eval: 0.1675 s/iter. Total: 0.3329 s/iter. ETA=0:03:25
[01/17 22:14:48] detectron2.evaluation.evaluator INFO: Inference done 493/1093. Dataloading: 0.0096 s/iter. Inference: 0.1553 s/iter. Eval: 0.1675 s/iter. Total: 0.3325 s/iter. ETA=0:03:19
[01/17 22:14:54] detectron2.evaluation.evaluator INFO: Inference done 508/1093. Dataloading: 0.0097 s/iter. Inference: 0.1552 s/iter. Eval: 0.1679 s/iter. Total: 0.3329 s/iter. ETA=0:03:14
[01/17 22:14:59] detectron2.evaluation.evaluator INFO: Inference done 521/1093. Dataloading: 0.0097 s/iter. Inference: 0.1557 s/iter. Eval: 0.1693 s/iter. Total: 0.3347 s/iter. ETA=0:03:11
[01/17 22:15:04] detectron2.evaluation.evaluator INFO: Inference done 538/1093. Dataloading: 0.0097 s/iter. Inference: 0.1552 s/iter. Eval: 0.1690 s/iter. Total: 0.3340 s/iter. ETA=0:03:05
[01/17 22:15:09] detectron2.evaluation.evaluator INFO: Inference done 554/1093. Dataloading: 0.0096 s/iter. Inference: 0.1554 s/iter. Eval: 0.1686 s/iter. Total: 0.3337 s/iter. ETA=0:02:59
[01/17 22:15:15] detectron2.evaluation.evaluator INFO: Inference done 569/1093. Dataloading: 0.0096 s/iter. Inference: 0.1555 s/iter. Eval: 0.1688 s/iter. Total: 0.3340 s/iter. ETA=0:02:55
[01/17 22:15:20] detectron2.evaluation.evaluator INFO: Inference done 584/1093. Dataloading: 0.0096 s/iter. Inference: 0.1556 s/iter. Eval: 0.1691 s/iter. Total: 0.3344 s/iter. ETA=0:02:50
[01/17 22:15:25] detectron2.evaluation.evaluator INFO: Inference done 599/1093. Dataloading: 0.0096 s/iter. Inference: 0.1558 s/iter. Eval: 0.1690 s/iter. Total: 0.3345 s/iter. ETA=0:02:45
[01/17 22:15:30] detectron2.evaluation.evaluator INFO: Inference done 615/1093. Dataloading: 0.0096 s/iter. Inference: 0.1560 s/iter. Eval: 0.1685 s/iter. Total: 0.3342 s/iter. ETA=0:02:39
[01/17 22:15:35] detectron2.evaluation.evaluator INFO: Inference done 630/1093. Dataloading: 0.0096 s/iter. Inference: 0.1561 s/iter. Eval: 0.1684 s/iter. Total: 0.3342 s/iter. ETA=0:02:34
[01/17 22:15:40] detectron2.evaluation.evaluator INFO: Inference done 644/1093. Dataloading: 0.0096 s/iter. Inference: 0.1560 s/iter. Eval: 0.1691 s/iter. Total: 0.3348 s/iter. ETA=0:02:30
[01/17 22:15:45] detectron2.evaluation.evaluator INFO: Inference done 660/1093. Dataloading: 0.0096 s/iter. Inference: 0.1558 s/iter. Eval: 0.1692 s/iter. Total: 0.3348 s/iter. ETA=0:02:24
[01/17 22:15:50] detectron2.evaluation.evaluator INFO: Inference done 674/1093. Dataloading: 0.0096 s/iter. Inference: 0.1561 s/iter. Eval: 0.1695 s/iter. Total: 0.3353 s/iter. ETA=0:02:20
[01/17 22:15:56] detectron2.evaluation.evaluator INFO: Inference done 689/1093. Dataloading: 0.0097 s/iter. Inference: 0.1561 s/iter. Eval: 0.1699 s/iter. Total: 0.3358 s/iter. ETA=0:02:15
[01/17 22:16:01] detectron2.evaluation.evaluator INFO: Inference done 704/1093. Dataloading: 0.0096 s/iter. Inference: 0.1561 s/iter. Eval: 0.1702 s/iter. Total: 0.3360 s/iter. ETA=0:02:10
[01/17 22:16:06] detectron2.evaluation.evaluator INFO: Inference done 720/1093. Dataloading: 0.0096 s/iter. Inference: 0.1561 s/iter. Eval: 0.1699 s/iter. Total: 0.3357 s/iter. ETA=0:02:05
[01/17 22:16:11] detectron2.evaluation.evaluator INFO: Inference done 736/1093. Dataloading: 0.0096 s/iter. Inference: 0.1561 s/iter. Eval: 0.1697 s/iter. Total: 0.3354 s/iter. ETA=0:01:59
[01/17 22:16:17] detectron2.evaluation.evaluator INFO: Inference done 752/1093. Dataloading: 0.0096 s/iter. Inference: 0.1558 s/iter. Eval: 0.1698 s/iter. Total: 0.3353 s/iter. ETA=0:01:54
[01/17 22:16:22] detectron2.evaluation.evaluator INFO: Inference done 767/1093. Dataloading: 0.0096 s/iter. Inference: 0.1557 s/iter. Eval: 0.1701 s/iter. Total: 0.3354 s/iter. ETA=0:01:49
[01/17 22:16:27] detectron2.evaluation.evaluator INFO: Inference done 782/1093. Dataloading: 0.0096 s/iter. Inference: 0.1558 s/iter. Eval: 0.1703 s/iter. Total: 0.3358 s/iter. ETA=0:01:44
[01/17 22:16:32] detectron2.evaluation.evaluator INFO: Inference done 799/1093. Dataloading: 0.0096 s/iter. Inference: 0.1555 s/iter. Eval: 0.1701 s/iter. Total: 0.3353 s/iter. ETA=0:01:38
[01/17 22:16:37] detectron2.evaluation.evaluator INFO: Inference done 814/1093. Dataloading: 0.0096 s/iter. Inference: 0.1556 s/iter. Eval: 0.1701 s/iter. Total: 0.3354 s/iter. ETA=0:01:33
[01/17 22:16:43] detectron2.evaluation.evaluator INFO: Inference done 830/1093. Dataloading: 0.0095 s/iter. Inference: 0.1555 s/iter. Eval: 0.1701 s/iter. Total: 0.3352 s/iter. ETA=0:01:28
[01/17 22:16:48] detectron2.evaluation.evaluator INFO: Inference done 847/1093. Dataloading: 0.0095 s/iter. Inference: 0.1555 s/iter. Eval: 0.1694 s/iter. Total: 0.3344 s/iter. ETA=0:01:22
[01/17 22:16:53] detectron2.evaluation.evaluator INFO: Inference done 863/1093. Dataloading: 0.0095 s/iter. Inference: 0.1554 s/iter. Eval: 0.1694 s/iter. Total: 0.3344 s/iter. ETA=0:01:16
[01/17 22:16:58] detectron2.evaluation.evaluator INFO: Inference done 878/1093. Dataloading: 0.0095 s/iter. Inference: 0.1552 s/iter. Eval: 0.1696 s/iter. Total: 0.3344 s/iter. ETA=0:01:11
[01/17 22:17:03] detectron2.evaluation.evaluator INFO: Inference done 893/1093. Dataloading: 0.0094 s/iter. Inference: 0.1552 s/iter. Eval: 0.1697 s/iter. Total: 0.3344 s/iter. ETA=0:01:06
[01/17 22:17:08] detectron2.evaluation.evaluator INFO: Inference done 907/1093. Dataloading: 0.0095 s/iter. Inference: 0.1553 s/iter. Eval: 0.1700 s/iter. Total: 0.3348 s/iter. ETA=0:01:02
[01/17 22:17:13] detectron2.evaluation.evaluator INFO: Inference done 922/1093. Dataloading: 0.0095 s/iter. Inference: 0.1552 s/iter. Eval: 0.1701 s/iter. Total: 0.3348 s/iter. ETA=0:00:57
[01/17 22:17:18] detectron2.evaluation.evaluator INFO: Inference done 936/1093. Dataloading: 0.0095 s/iter. Inference: 0.1552 s/iter. Eval: 0.1705 s/iter. Total: 0.3353 s/iter. ETA=0:00:52
[01/17 22:17:24] detectron2.evaluation.evaluator INFO: Inference done 952/1093. Dataloading: 0.0095 s/iter. Inference: 0.1549 s/iter. Eval: 0.1707 s/iter. Total: 0.3352 s/iter. ETA=0:00:47
[01/17 22:17:29] detectron2.evaluation.evaluator INFO: Inference done 969/1093. Dataloading: 0.0095 s/iter. Inference: 0.1548 s/iter. Eval: 0.1703 s/iter. Total: 0.3347 s/iter. ETA=0:00:41
[01/17 22:17:34] detectron2.evaluation.evaluator INFO: Inference done 986/1093. Dataloading: 0.0094 s/iter. Inference: 0.1546 s/iter. Eval: 0.1700 s/iter. Total: 0.3341 s/iter. ETA=0:00:35
[01/17 22:17:39] detectron2.evaluation.evaluator INFO: Inference done 1002/1093. Dataloading: 0.0094 s/iter. Inference: 0.1545 s/iter. Eval: 0.1698 s/iter. Total: 0.3338 s/iter. ETA=0:00:30
[01/17 22:17:44] detectron2.evaluation.evaluator INFO: Inference done 1018/1093. Dataloading: 0.0094 s/iter. Inference: 0.1545 s/iter. Eval: 0.1696 s/iter. Total: 0.3335 s/iter. ETA=0:00:25
[01/17 22:17:49] detectron2.evaluation.evaluator INFO: Inference done 1035/1093. Dataloading: 0.0094 s/iter. Inference: 0.1545 s/iter. Eval: 0.1691 s/iter. Total: 0.3331 s/iter. ETA=0:00:19
[01/17 22:17:55] detectron2.evaluation.evaluator INFO: Inference done 1051/1093. Dataloading: 0.0094 s/iter. Inference: 0.1545 s/iter. Eval: 0.1691 s/iter. Total: 0.3331 s/iter. ETA=0:00:13
[01/17 22:18:00] detectron2.evaluation.evaluator INFO: Inference done 1066/1093. Dataloading: 0.0094 s/iter. Inference: 0.1543 s/iter. Eval: 0.1693 s/iter. Total: 0.3331 s/iter. ETA=0:00:08
[01/17 22:18:05] detectron2.evaluation.evaluator INFO: Inference done 1082/1093. Dataloading: 0.0094 s/iter. Inference: 0.1544 s/iter. Eval: 0.1691 s/iter. Total: 0.3330 s/iter. ETA=0:00:03
[01/17 22:18:09] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:02.424702 (0.333111 s / iter per device, on 4 devices)
[01/17 22:18:09] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:47 (0.154289 s / iter per device, on 4 devices)
[01/17 23:08:23] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/17 23:08:24] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/17 23:08:24] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/17 23:08:24] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/17 23:08:38] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0055 s/iter. Inference: 0.1573 s/iter. Eval: 0.2034 s/iter. Total: 0.3662 s/iter. ETA=0:06:36
[01/17 23:08:43] detectron2.evaluation.evaluator INFO: Inference done 24/1093. Dataloading: 0.0107 s/iter. Inference: 0.1658 s/iter. Eval: 0.2167 s/iter. Total: 0.3933 s/iter. ETA=0:07:00
[01/17 23:08:48] detectron2.evaluation.evaluator INFO: Inference done 38/1093. Dataloading: 0.0112 s/iter. Inference: 0.1583 s/iter. Eval: 0.2143 s/iter. Total: 0.3839 s/iter. ETA=0:06:44
[01/17 23:08:54] detectron2.evaluation.evaluator INFO: Inference done 53/1093. Dataloading: 0.0114 s/iter. Inference: 0.1579 s/iter. Eval: 0.2039 s/iter. Total: 0.3733 s/iter. ETA=0:06:28
[01/17 23:08:59] detectron2.evaluation.evaluator INFO: Inference done 67/1093. Dataloading: 0.0112 s/iter. Inference: 0.1660 s/iter. Eval: 0.1937 s/iter. Total: 0.3711 s/iter. ETA=0:06:20
[01/17 23:09:04] detectron2.evaluation.evaluator INFO: Inference done 81/1093. Dataloading: 0.0114 s/iter. Inference: 0.1646 s/iter. Eval: 0.1929 s/iter. Total: 0.3689 s/iter. ETA=0:06:13
[01/17 23:09:09] detectron2.evaluation.evaluator INFO: Inference done 96/1093. Dataloading: 0.0111 s/iter. Inference: 0.1666 s/iter. Eval: 0.1859 s/iter. Total: 0.3638 s/iter. ETA=0:06:02
[01/17 23:09:14] detectron2.evaluation.evaluator INFO: Inference done 112/1093. Dataloading: 0.0107 s/iter. Inference: 0.1646 s/iter. Eval: 0.1839 s/iter. Total: 0.3593 s/iter. ETA=0:05:52
[01/17 23:09:19] detectron2.evaluation.evaluator INFO: Inference done 127/1093. Dataloading: 0.0105 s/iter. Inference: 0.1628 s/iter. Eval: 0.1833 s/iter. Total: 0.3567 s/iter. ETA=0:05:44
[01/17 23:09:24] detectron2.evaluation.evaluator INFO: Inference done 143/1093. Dataloading: 0.0102 s/iter. Inference: 0.1628 s/iter. Eval: 0.1786 s/iter. Total: 0.3518 s/iter. ETA=0:05:34
[01/17 23:09:29] detectron2.evaluation.evaluator INFO: Inference done 159/1093. Dataloading: 0.0099 s/iter. Inference: 0.1620 s/iter. Eval: 0.1772 s/iter. Total: 0.3492 s/iter. ETA=0:05:26
[01/17 23:09:35] detectron2.evaluation.evaluator INFO: Inference done 175/1093. Dataloading: 0.0098 s/iter. Inference: 0.1611 s/iter. Eval: 0.1762 s/iter. Total: 0.3472 s/iter. ETA=0:05:18
[01/17 23:09:40] detectron2.evaluation.evaluator INFO: Inference done 191/1093. Dataloading: 0.0098 s/iter. Inference: 0.1601 s/iter. Eval: 0.1749 s/iter. Total: 0.3449 s/iter. ETA=0:05:11
[01/17 23:09:45] detectron2.evaluation.evaluator INFO: Inference done 205/1093. Dataloading: 0.0100 s/iter. Inference: 0.1596 s/iter. Eval: 0.1764 s/iter. Total: 0.3461 s/iter. ETA=0:05:07
[01/17 23:09:50] detectron2.evaluation.evaluator INFO: Inference done 223/1093. Dataloading: 0.0098 s/iter. Inference: 0.1596 s/iter. Eval: 0.1724 s/iter. Total: 0.3418 s/iter. ETA=0:04:57
[01/17 23:09:55] detectron2.evaluation.evaluator INFO: Inference done 239/1093. Dataloading: 0.0096 s/iter. Inference: 0.1587 s/iter. Eval: 0.1714 s/iter. Total: 0.3399 s/iter. ETA=0:04:50
[01/17 23:10:01] detectron2.evaluation.evaluator INFO: Inference done 251/1093. Dataloading: 0.0099 s/iter. Inference: 0.1614 s/iter. Eval: 0.1735 s/iter. Total: 0.3449 s/iter. ETA=0:04:50
[01/17 23:10:06] detectron2.evaluation.evaluator INFO: Inference done 263/1093. Dataloading: 0.0099 s/iter. Inference: 0.1632 s/iter. Eval: 0.1753 s/iter. Total: 0.3485 s/iter. ETA=0:04:49
[01/17 23:10:11] detectron2.evaluation.evaluator INFO: Inference done 278/1093. Dataloading: 0.0101 s/iter. Inference: 0.1644 s/iter. Eval: 0.1745 s/iter. Total: 0.3491 s/iter. ETA=0:04:44
[01/17 23:10:16] detectron2.evaluation.evaluator INFO: Inference done 292/1093. Dataloading: 0.0102 s/iter. Inference: 0.1641 s/iter. Eval: 0.1754 s/iter. Total: 0.3497 s/iter. ETA=0:04:40
[01/17 23:10:21] detectron2.evaluation.evaluator INFO: Inference done 307/1093. Dataloading: 0.0101 s/iter. Inference: 0.1650 s/iter. Eval: 0.1745 s/iter. Total: 0.3497 s/iter. ETA=0:04:34
[01/17 23:10:26] detectron2.evaluation.evaluator INFO: Inference done 323/1093. Dataloading: 0.0101 s/iter. Inference: 0.1654 s/iter. Eval: 0.1728 s/iter. Total: 0.3484 s/iter. ETA=0:04:28
[01/17 23:10:32] detectron2.evaluation.evaluator INFO: Inference done 339/1093. Dataloading: 0.0100 s/iter. Inference: 0.1657 s/iter. Eval: 0.1719 s/iter. Total: 0.3478 s/iter. ETA=0:04:22
[01/17 23:10:37] detectron2.evaluation.evaluator INFO: Inference done 353/1093. Dataloading: 0.0101 s/iter. Inference: 0.1655 s/iter. Eval: 0.1733 s/iter. Total: 0.3490 s/iter. ETA=0:04:18
[01/17 23:10:42] detectron2.evaluation.evaluator INFO: Inference done 366/1093. Dataloading: 0.0100 s/iter. Inference: 0.1661 s/iter. Eval: 0.1744 s/iter. Total: 0.3506 s/iter. ETA=0:04:14
[01/17 23:10:47] detectron2.evaluation.evaluator INFO: Inference done 380/1093. Dataloading: 0.0101 s/iter. Inference: 0.1658 s/iter. Eval: 0.1751 s/iter. Total: 0.3511 s/iter. ETA=0:04:10
[01/17 23:10:53] detectron2.evaluation.evaluator INFO: Inference done 393/1093. Dataloading: 0.0101 s/iter. Inference: 0.1671 s/iter. Eval: 0.1759 s/iter. Total: 0.3532 s/iter. ETA=0:04:07
[01/17 23:10:58] detectron2.evaluation.evaluator INFO: Inference done 406/1093. Dataloading: 0.0101 s/iter. Inference: 0.1676 s/iter. Eval: 0.1765 s/iter. Total: 0.3543 s/iter. ETA=0:04:03
[01/17 23:11:03] detectron2.evaluation.evaluator INFO: Inference done 420/1093. Dataloading: 0.0101 s/iter. Inference: 0.1675 s/iter. Eval: 0.1773 s/iter. Total: 0.3550 s/iter. ETA=0:03:58
[01/17 23:11:08] detectron2.evaluation.evaluator INFO: Inference done 435/1093. Dataloading: 0.0101 s/iter. Inference: 0.1675 s/iter. Eval: 0.1771 s/iter. Total: 0.3548 s/iter. ETA=0:03:53
[01/17 23:11:14] detectron2.evaluation.evaluator INFO: Inference done 452/1093. Dataloading: 0.0100 s/iter. Inference: 0.1671 s/iter. Eval: 0.1759 s/iter. Total: 0.3531 s/iter. ETA=0:03:46
[01/17 23:11:19] detectron2.evaluation.evaluator INFO: Inference done 467/1093. Dataloading: 0.0100 s/iter. Inference: 0.1669 s/iter. Eval: 0.1759 s/iter. Total: 0.3529 s/iter. ETA=0:03:40
[01/17 23:11:24] detectron2.evaluation.evaluator INFO: Inference done 483/1093. Dataloading: 0.0100 s/iter. Inference: 0.1661 s/iter. Eval: 0.1756 s/iter. Total: 0.3517 s/iter. ETA=0:03:34
[01/17 23:11:29] detectron2.evaluation.evaluator INFO: Inference done 497/1093. Dataloading: 0.0100 s/iter. Inference: 0.1664 s/iter. Eval: 0.1759 s/iter. Total: 0.3524 s/iter. ETA=0:03:30
[01/17 23:11:34] detectron2.evaluation.evaluator INFO: Inference done 512/1093. Dataloading: 0.0100 s/iter. Inference: 0.1669 s/iter. Eval: 0.1757 s/iter. Total: 0.3527 s/iter. ETA=0:03:24
[01/17 23:11:40] detectron2.evaluation.evaluator INFO: Inference done 526/1093. Dataloading: 0.0100 s/iter. Inference: 0.1667 s/iter. Eval: 0.1765 s/iter. Total: 0.3533 s/iter. ETA=0:03:20
[01/17 23:11:45] detectron2.evaluation.evaluator INFO: Inference done 542/1093. Dataloading: 0.0100 s/iter. Inference: 0.1670 s/iter. Eval: 0.1757 s/iter. Total: 0.3527 s/iter. ETA=0:03:14
[01/17 23:11:51] detectron2.evaluation.evaluator INFO: Inference done 557/1093. Dataloading: 0.0100 s/iter. Inference: 0.1674 s/iter. Eval: 0.1755 s/iter. Total: 0.3529 s/iter. ETA=0:03:09
[01/17 23:11:56] detectron2.evaluation.evaluator INFO: Inference done 571/1093. Dataloading: 0.0100 s/iter. Inference: 0.1676 s/iter. Eval: 0.1757 s/iter. Total: 0.3534 s/iter. ETA=0:03:04
[01/17 23:12:01] detectron2.evaluation.evaluator INFO: Inference done 585/1093. Dataloading: 0.0100 s/iter. Inference: 0.1674 s/iter. Eval: 0.1765 s/iter. Total: 0.3540 s/iter. ETA=0:02:59
[01/17 23:12:06] detectron2.evaluation.evaluator INFO: Inference done 599/1093. Dataloading: 0.0101 s/iter. Inference: 0.1673 s/iter. Eval: 0.1766 s/iter. Total: 0.3542 s/iter. ETA=0:02:54
[01/17 23:12:11] detectron2.evaluation.evaluator INFO: Inference done 612/1093. Dataloading: 0.0102 s/iter. Inference: 0.1677 s/iter. Eval: 0.1769 s/iter. Total: 0.3549 s/iter. ETA=0:02:50
[01/17 23:12:17] detectron2.evaluation.evaluator INFO: Inference done 626/1093. Dataloading: 0.0102 s/iter. Inference: 0.1683 s/iter. Eval: 0.1771 s/iter. Total: 0.3556 s/iter. ETA=0:02:46
[01/17 23:12:22] detectron2.evaluation.evaluator INFO: Inference done 640/1093. Dataloading: 0.0102 s/iter. Inference: 0.1683 s/iter. Eval: 0.1775 s/iter. Total: 0.3560 s/iter. ETA=0:02:41
[01/17 23:12:27] detectron2.evaluation.evaluator INFO: Inference done 653/1093. Dataloading: 0.0102 s/iter. Inference: 0.1688 s/iter. Eval: 0.1778 s/iter. Total: 0.3569 s/iter. ETA=0:02:37
[01/17 23:12:32] detectron2.evaluation.evaluator INFO: Inference done 666/1093. Dataloading: 0.0101 s/iter. Inference: 0.1695 s/iter. Eval: 0.1777 s/iter. Total: 0.3575 s/iter. ETA=0:02:32
[01/17 23:12:37] detectron2.evaluation.evaluator INFO: Inference done 681/1093. Dataloading: 0.0101 s/iter. Inference: 0.1695 s/iter. Eval: 0.1778 s/iter. Total: 0.3575 s/iter. ETA=0:02:27
[01/17 23:12:43] detectron2.evaluation.evaluator INFO: Inference done 694/1093. Dataloading: 0.0101 s/iter. Inference: 0.1697 s/iter. Eval: 0.1785 s/iter. Total: 0.3585 s/iter. ETA=0:02:23
[01/17 23:12:48] detectron2.evaluation.evaluator INFO: Inference done 708/1093. Dataloading: 0.0102 s/iter. Inference: 0.1699 s/iter. Eval: 0.1785 s/iter. Total: 0.3587 s/iter. ETA=0:02:18
[01/17 23:12:53] detectron2.evaluation.evaluator INFO: Inference done 724/1093. Dataloading: 0.0101 s/iter. Inference: 0.1697 s/iter. Eval: 0.1781 s/iter. Total: 0.3580 s/iter. ETA=0:02:12
[01/17 23:12:58] detectron2.evaluation.evaluator INFO: Inference done 738/1093. Dataloading: 0.0101 s/iter. Inference: 0.1699 s/iter. Eval: 0.1780 s/iter. Total: 0.3581 s/iter. ETA=0:02:07
[01/17 23:13:04] detectron2.evaluation.evaluator INFO: Inference done 754/1093. Dataloading: 0.0101 s/iter. Inference: 0.1700 s/iter. Eval: 0.1777 s/iter. Total: 0.3579 s/iter. ETA=0:02:01
[01/17 23:13:09] detectron2.evaluation.evaluator INFO: Inference done 768/1093. Dataloading: 0.0100 s/iter. Inference: 0.1699 s/iter. Eval: 0.1780 s/iter. Total: 0.3580 s/iter. ETA=0:01:56
[01/17 23:13:14] detectron2.evaluation.evaluator INFO: Inference done 782/1093. Dataloading: 0.0100 s/iter. Inference: 0.1701 s/iter. Eval: 0.1780 s/iter. Total: 0.3582 s/iter. ETA=0:01:51
[01/17 23:13:19] detectron2.evaluation.evaluator INFO: Inference done 796/1093. Dataloading: 0.0101 s/iter. Inference: 0.1703 s/iter. Eval: 0.1779 s/iter. Total: 0.3583 s/iter. ETA=0:01:46
[01/17 23:13:24] detectron2.evaluation.evaluator INFO: Inference done 811/1093. Dataloading: 0.0101 s/iter. Inference: 0.1700 s/iter. Eval: 0.1779 s/iter. Total: 0.3581 s/iter. ETA=0:01:40
[01/17 23:13:29] detectron2.evaluation.evaluator INFO: Inference done 826/1093. Dataloading: 0.0101 s/iter. Inference: 0.1699 s/iter. Eval: 0.1778 s/iter. Total: 0.3578 s/iter. ETA=0:01:35
[01/17 23:13:35] detectron2.evaluation.evaluator INFO: Inference done 841/1093. Dataloading: 0.0101 s/iter. Inference: 0.1697 s/iter. Eval: 0.1777 s/iter. Total: 0.3576 s/iter. ETA=0:01:30
[01/17 23:13:40] detectron2.evaluation.evaluator INFO: Inference done 856/1093. Dataloading: 0.0101 s/iter. Inference: 0.1695 s/iter. Eval: 0.1776 s/iter. Total: 0.3573 s/iter. ETA=0:01:24
[01/17 23:13:45] detectron2.evaluation.evaluator INFO: Inference done 870/1093. Dataloading: 0.0101 s/iter. Inference: 0.1693 s/iter. Eval: 0.1780 s/iter. Total: 0.3575 s/iter. ETA=0:01:19
[01/17 23:13:50] detectron2.evaluation.evaluator INFO: Inference done 884/1093. Dataloading: 0.0101 s/iter. Inference: 0.1694 s/iter. Eval: 0.1783 s/iter. Total: 0.3579 s/iter. ETA=0:01:14
[01/17 23:13:55] detectron2.evaluation.evaluator INFO: Inference done 898/1093. Dataloading: 0.0101 s/iter. Inference: 0.1693 s/iter. Eval: 0.1784 s/iter. Total: 0.3579 s/iter. ETA=0:01:09
[01/17 23:14:01] detectron2.evaluation.evaluator INFO: Inference done 911/1093. Dataloading: 0.0102 s/iter. Inference: 0.1692 s/iter. Eval: 0.1792 s/iter. Total: 0.3587 s/iter. ETA=0:01:05
[01/17 23:14:06] detectron2.evaluation.evaluator INFO: Inference done 925/1093. Dataloading: 0.0101 s/iter. Inference: 0.1693 s/iter. Eval: 0.1794 s/iter. Total: 0.3589 s/iter. ETA=0:01:00
[01/17 23:14:11] detectron2.evaluation.evaluator INFO: Inference done 939/1093. Dataloading: 0.0101 s/iter. Inference: 0.1691 s/iter. Eval: 0.1797 s/iter. Total: 0.3590 s/iter. ETA=0:00:55
[01/17 23:14:16] detectron2.evaluation.evaluator INFO: Inference done 954/1093. Dataloading: 0.0101 s/iter. Inference: 0.1690 s/iter. Eval: 0.1797 s/iter. Total: 0.3589 s/iter. ETA=0:00:49
[01/17 23:14:21] detectron2.evaluation.evaluator INFO: Inference done 970/1093. Dataloading: 0.0101 s/iter. Inference: 0.1688 s/iter. Eval: 0.1793 s/iter. Total: 0.3582 s/iter. ETA=0:00:44
[01/17 23:14:26] detectron2.evaluation.evaluator INFO: Inference done 985/1093. Dataloading: 0.0100 s/iter. Inference: 0.1689 s/iter. Eval: 0.1788 s/iter. Total: 0.3579 s/iter. ETA=0:00:38
[01/17 23:14:32] detectron2.evaluation.evaluator INFO: Inference done 1000/1093. Dataloading: 0.0100 s/iter. Inference: 0.1692 s/iter. Eval: 0.1783 s/iter. Total: 0.3577 s/iter. ETA=0:00:33
[01/17 23:14:37] detectron2.evaluation.evaluator INFO: Inference done 1015/1093. Dataloading: 0.0100 s/iter. Inference: 0.1692 s/iter. Eval: 0.1781 s/iter. Total: 0.3574 s/iter. ETA=0:00:27
[01/17 23:14:42] detectron2.evaluation.evaluator INFO: Inference done 1030/1093. Dataloading: 0.0100 s/iter. Inference: 0.1693 s/iter. Eval: 0.1778 s/iter. Total: 0.3572 s/iter. ETA=0:00:22
[01/17 23:14:47] detectron2.evaluation.evaluator INFO: Inference done 1040/1093. Dataloading: 0.0100 s/iter. Inference: 0.1707 s/iter. Eval: 0.1783 s/iter. Total: 0.3591 s/iter. ETA=0:00:19
[01/17 23:14:53] detectron2.evaluation.evaluator INFO: Inference done 1050/1093. Dataloading: 0.0100 s/iter. Inference: 0.1717 s/iter. Eval: 0.1788 s/iter. Total: 0.3607 s/iter. ETA=0:00:15
[01/17 23:14:58] detectron2.evaluation.evaluator INFO: Inference done 1059/1093. Dataloading: 0.0101 s/iter. Inference: 0.1728 s/iter. Eval: 0.1794 s/iter. Total: 0.3624 s/iter. ETA=0:00:12
[01/17 23:15:03] detectron2.evaluation.evaluator INFO: Inference done 1068/1093. Dataloading: 0.0101 s/iter. Inference: 0.1741 s/iter. Eval: 0.1801 s/iter. Total: 0.3645 s/iter. ETA=0:00:09
[01/17 23:15:08] detectron2.evaluation.evaluator INFO: Inference done 1084/1093. Dataloading: 0.0101 s/iter. Inference: 0.1740 s/iter. Eval: 0.1797 s/iter. Total: 0.3639 s/iter. ETA=0:00:03
[01/17 23:15:11] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:35.545163 (0.363553 s / iter per device, on 4 devices)
[01/17 23:15:11] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:08 (0.173672 s / iter per device, on 4 devices)
[01/18 00:06:55] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 00:06:55] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 00:06:55] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 00:06:56] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 00:07:09] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0069 s/iter. Inference: 0.1520 s/iter. Eval: 0.2016 s/iter. Total: 0.3605 s/iter. ETA=0:06:30
[01/18 00:07:14] detectron2.evaluation.evaluator INFO: Inference done 24/1093. Dataloading: 0.0109 s/iter. Inference: 0.1678 s/iter. Eval: 0.2043 s/iter. Total: 0.3832 s/iter. ETA=0:06:49
[01/18 00:07:19] detectron2.evaluation.evaluator INFO: Inference done 36/1093. Dataloading: 0.0116 s/iter. Inference: 0.1690 s/iter. Eval: 0.2212 s/iter. Total: 0.4019 s/iter. ETA=0:07:04
[01/18 00:07:24] detectron2.evaluation.evaluator INFO: Inference done 51/1093. Dataloading: 0.0116 s/iter. Inference: 0.1608 s/iter. Eval: 0.2082 s/iter. Total: 0.3807 s/iter. ETA=0:06:36
[01/18 00:07:29] detectron2.evaluation.evaluator INFO: Inference done 66/1093. Dataloading: 0.0112 s/iter. Inference: 0.1593 s/iter. Eval: 0.2003 s/iter. Total: 0.3710 s/iter. ETA=0:06:21
[01/18 00:07:34] detectron2.evaluation.evaluator INFO: Inference done 80/1093. Dataloading: 0.0112 s/iter. Inference: 0.1600 s/iter. Eval: 0.1995 s/iter. Total: 0.3708 s/iter. ETA=0:06:15
[01/18 00:07:40] detectron2.evaluation.evaluator INFO: Inference done 96/1093. Dataloading: 0.0108 s/iter. Inference: 0.1603 s/iter. Eval: 0.1907 s/iter. Total: 0.3619 s/iter. ETA=0:06:00
[01/18 00:07:45] detectron2.evaluation.evaluator INFO: Inference done 111/1093. Dataloading: 0.0108 s/iter. Inference: 0.1617 s/iter. Eval: 0.1865 s/iter. Total: 0.3591 s/iter. ETA=0:05:52
[01/18 00:07:50] detectron2.evaluation.evaluator INFO: Inference done 126/1093. Dataloading: 0.0107 s/iter. Inference: 0.1622 s/iter. Eval: 0.1840 s/iter. Total: 0.3570 s/iter. ETA=0:05:45
[01/18 00:07:55] detectron2.evaluation.evaluator INFO: Inference done 142/1093. Dataloading: 0.0105 s/iter. Inference: 0.1615 s/iter. Eval: 0.1799 s/iter. Total: 0.3519 s/iter. ETA=0:05:34
[01/18 00:08:00] detectron2.evaluation.evaluator INFO: Inference done 157/1093. Dataloading: 0.0103 s/iter. Inference: 0.1609 s/iter. Eval: 0.1801 s/iter. Total: 0.3514 s/iter. ETA=0:05:28
[01/18 00:08:05] detectron2.evaluation.evaluator INFO: Inference done 171/1093. Dataloading: 0.0103 s/iter. Inference: 0.1624 s/iter. Eval: 0.1796 s/iter. Total: 0.3524 s/iter. ETA=0:05:24
[01/18 00:08:10] detectron2.evaluation.evaluator INFO: Inference done 186/1093. Dataloading: 0.0102 s/iter. Inference: 0.1623 s/iter. Eval: 0.1785 s/iter. Total: 0.3511 s/iter. ETA=0:05:18
[01/18 00:08:15] detectron2.evaluation.evaluator INFO: Inference done 200/1093. Dataloading: 0.0102 s/iter. Inference: 0.1624 s/iter. Eval: 0.1792 s/iter. Total: 0.3519 s/iter. ETA=0:05:14
[01/18 00:08:20] detectron2.evaluation.evaluator INFO: Inference done 216/1093. Dataloading: 0.0102 s/iter. Inference: 0.1622 s/iter. Eval: 0.1772 s/iter. Total: 0.3497 s/iter. ETA=0:05:06
[01/18 00:08:26] detectron2.evaluation.evaluator INFO: Inference done 232/1093. Dataloading: 0.0102 s/iter. Inference: 0.1619 s/iter. Eval: 0.1752 s/iter. Total: 0.3473 s/iter. ETA=0:04:59
[01/18 00:08:31] detectron2.evaluation.evaluator INFO: Inference done 242/1093. Dataloading: 0.0106 s/iter. Inference: 0.1679 s/iter. Eval: 0.1780 s/iter. Total: 0.3566 s/iter. ETA=0:05:03
[01/18 00:08:36] detectron2.evaluation.evaluator INFO: Inference done 249/1093. Dataloading: 0.0110 s/iter. Inference: 0.1745 s/iter. Eval: 0.1823 s/iter. Total: 0.3679 s/iter. ETA=0:05:10
[01/18 00:08:42] detectron2.evaluation.evaluator INFO: Inference done 257/1093. Dataloading: 0.0114 s/iter. Inference: 0.1793 s/iter. Eval: 0.1881 s/iter. Total: 0.3790 s/iter. ETA=0:05:16
[01/18 00:08:48] detectron2.evaluation.evaluator INFO: Inference done 265/1093. Dataloading: 0.0115 s/iter. Inference: 0.1862 s/iter. Eval: 0.1917 s/iter. Total: 0.3894 s/iter. ETA=0:05:22
[01/18 00:08:53] detectron2.evaluation.evaluator INFO: Inference done 273/1093. Dataloading: 0.0118 s/iter. Inference: 0.1920 s/iter. Eval: 0.1934 s/iter. Total: 0.3973 s/iter. ETA=0:05:25
[01/18 00:08:59] detectron2.evaluation.evaluator INFO: Inference done 281/1093. Dataloading: 0.0120 s/iter. Inference: 0.1990 s/iter. Eval: 0.1944 s/iter. Total: 0.4055 s/iter. ETA=0:05:29
[01/18 00:09:04] detectron2.evaluation.evaluator INFO: Inference done 294/1093. Dataloading: 0.0120 s/iter. Inference: 0.1980 s/iter. Eval: 0.1951 s/iter. Total: 0.4052 s/iter. ETA=0:05:23
[01/18 00:09:09] detectron2.evaluation.evaluator INFO: Inference done 312/1093. Dataloading: 0.0117 s/iter. Inference: 0.1950 s/iter. Eval: 0.1916 s/iter. Total: 0.3984 s/iter. ETA=0:05:11
[01/18 00:09:14] detectron2.evaluation.evaluator INFO: Inference done 328/1093. Dataloading: 0.0115 s/iter. Inference: 0.1934 s/iter. Eval: 0.1898 s/iter. Total: 0.3948 s/iter. ETA=0:05:01
[01/18 00:09:19] detectron2.evaluation.evaluator INFO: Inference done 344/1093. Dataloading: 0.0114 s/iter. Inference: 0.1916 s/iter. Eval: 0.1885 s/iter. Total: 0.3917 s/iter. ETA=0:04:53
[01/18 00:09:25] detectron2.evaluation.evaluator INFO: Inference done 356/1093. Dataloading: 0.0114 s/iter. Inference: 0.1918 s/iter. Eval: 0.1894 s/iter. Total: 0.3927 s/iter. ETA=0:04:49
[01/18 00:09:30] detectron2.evaluation.evaluator INFO: Inference done 371/1093. Dataloading: 0.0114 s/iter. Inference: 0.1907 s/iter. Eval: 0.1883 s/iter. Total: 0.3905 s/iter. ETA=0:04:41
[01/18 00:09:35] detectron2.evaluation.evaluator INFO: Inference done 384/1093. Dataloading: 0.0114 s/iter. Inference: 0.1904 s/iter. Eval: 0.1889 s/iter. Total: 0.3908 s/iter. ETA=0:04:37
[01/18 00:09:40] detectron2.evaluation.evaluator INFO: Inference done 394/1093. Dataloading: 0.0115 s/iter. Inference: 0.1925 s/iter. Eval: 0.1902 s/iter. Total: 0.3943 s/iter. ETA=0:04:35
[01/18 00:09:45] detectron2.evaluation.evaluator INFO: Inference done 408/1093. Dataloading: 0.0115 s/iter. Inference: 0.1915 s/iter. Eval: 0.1902 s/iter. Total: 0.3933 s/iter. ETA=0:04:29
[01/18 00:09:50] detectron2.evaluation.evaluator INFO: Inference done 422/1093. Dataloading: 0.0115 s/iter. Inference: 0.1904 s/iter. Eval: 0.1905 s/iter. Total: 0.3925 s/iter. ETA=0:04:23
[01/18 00:09:56] detectron2.evaluation.evaluator INFO: Inference done 437/1093. Dataloading: 0.0115 s/iter. Inference: 0.1899 s/iter. Eval: 0.1897 s/iter. Total: 0.3912 s/iter. ETA=0:04:16
[01/18 00:10:01] detectron2.evaluation.evaluator INFO: Inference done 450/1093. Dataloading: 0.0114 s/iter. Inference: 0.1910 s/iter. Eval: 0.1888 s/iter. Total: 0.3914 s/iter. ETA=0:04:11
[01/18 00:10:06] detectron2.evaluation.evaluator INFO: Inference done 465/1093. Dataloading: 0.0114 s/iter. Inference: 0.1908 s/iter. Eval: 0.1875 s/iter. Total: 0.3898 s/iter. ETA=0:04:04
[01/18 00:10:11] detectron2.evaluation.evaluator INFO: Inference done 481/1093. Dataloading: 0.0113 s/iter. Inference: 0.1894 s/iter. Eval: 0.1869 s/iter. Total: 0.3877 s/iter. ETA=0:03:57
[01/18 00:10:16] detectron2.evaluation.evaluator INFO: Inference done 495/1093. Dataloading: 0.0113 s/iter. Inference: 0.1887 s/iter. Eval: 0.1868 s/iter. Total: 0.3869 s/iter. ETA=0:03:51
[01/18 00:10:21] detectron2.evaluation.evaluator INFO: Inference done 510/1093. Dataloading: 0.0112 s/iter. Inference: 0.1877 s/iter. Eval: 0.1866 s/iter. Total: 0.3856 s/iter. ETA=0:03:44
[01/18 00:10:27] detectron2.evaluation.evaluator INFO: Inference done 524/1093. Dataloading: 0.0112 s/iter. Inference: 0.1873 s/iter. Eval: 0.1866 s/iter. Total: 0.3852 s/iter. ETA=0:03:39
[01/18 00:10:32] detectron2.evaluation.evaluator INFO: Inference done 540/1093. Dataloading: 0.0111 s/iter. Inference: 0.1863 s/iter. Eval: 0.1858 s/iter. Total: 0.3833 s/iter. ETA=0:03:31
[01/18 00:10:37] detectron2.evaluation.evaluator INFO: Inference done 555/1093. Dataloading: 0.0111 s/iter. Inference: 0.1860 s/iter. Eval: 0.1852 s/iter. Total: 0.3824 s/iter. ETA=0:03:25
[01/18 00:10:42] detectron2.evaluation.evaluator INFO: Inference done 566/1093. Dataloading: 0.0111 s/iter. Inference: 0.1873 s/iter. Eval: 0.1860 s/iter. Total: 0.3845 s/iter. ETA=0:03:22
[01/18 00:10:47] detectron2.evaluation.evaluator INFO: Inference done 575/1093. Dataloading: 0.0111 s/iter. Inference: 0.1888 s/iter. Eval: 0.1872 s/iter. Total: 0.3872 s/iter. ETA=0:03:20
[01/18 00:10:52] detectron2.evaluation.evaluator INFO: Inference done 583/1093. Dataloading: 0.0112 s/iter. Inference: 0.1911 s/iter. Eval: 0.1881 s/iter. Total: 0.3905 s/iter. ETA=0:03:19
[01/18 00:10:58] detectron2.evaluation.evaluator INFO: Inference done 592/1093. Dataloading: 0.0113 s/iter. Inference: 0.1928 s/iter. Eval: 0.1890 s/iter. Total: 0.3932 s/iter. ETA=0:03:16
[01/18 00:11:03] detectron2.evaluation.evaluator INFO: Inference done 601/1093. Dataloading: 0.0113 s/iter. Inference: 0.1947 s/iter. Eval: 0.1898 s/iter. Total: 0.3959 s/iter. ETA=0:03:14
[01/18 00:11:08] detectron2.evaluation.evaluator INFO: Inference done 618/1093. Dataloading: 0.0113 s/iter. Inference: 0.1933 s/iter. Eval: 0.1888 s/iter. Total: 0.3935 s/iter. ETA=0:03:06
[01/18 00:11:13] detectron2.evaluation.evaluator INFO: Inference done 632/1093. Dataloading: 0.0112 s/iter. Inference: 0.1933 s/iter. Eval: 0.1884 s/iter. Total: 0.3929 s/iter. ETA=0:03:01
[01/18 00:11:18] detectron2.evaluation.evaluator INFO: Inference done 646/1093. Dataloading: 0.0112 s/iter. Inference: 0.1925 s/iter. Eval: 0.1886 s/iter. Total: 0.3924 s/iter. ETA=0:02:55
[01/18 00:11:23] detectron2.evaluation.evaluator INFO: Inference done 662/1093. Dataloading: 0.0111 s/iter. Inference: 0.1917 s/iter. Eval: 0.1879 s/iter. Total: 0.3908 s/iter. ETA=0:02:48
[01/18 00:11:29] detectron2.evaluation.evaluator INFO: Inference done 677/1093. Dataloading: 0.0111 s/iter. Inference: 0.1910 s/iter. Eval: 0.1877 s/iter. Total: 0.3899 s/iter. ETA=0:02:42
[01/18 00:11:34] detectron2.evaluation.evaluator INFO: Inference done 689/1093. Dataloading: 0.0111 s/iter. Inference: 0.1911 s/iter. Eval: 0.1883 s/iter. Total: 0.3906 s/iter. ETA=0:02:37
[01/18 00:11:39] detectron2.evaluation.evaluator INFO: Inference done 698/1093. Dataloading: 0.0112 s/iter. Inference: 0.1924 s/iter. Eval: 0.1896 s/iter. Total: 0.3933 s/iter. ETA=0:02:35
[01/18 00:11:45] detectron2.evaluation.evaluator INFO: Inference done 708/1093. Dataloading: 0.0113 s/iter. Inference: 0.1939 s/iter. Eval: 0.1902 s/iter. Total: 0.3955 s/iter. ETA=0:02:32
[01/18 00:11:50] detectron2.evaluation.evaluator INFO: Inference done 717/1093. Dataloading: 0.0114 s/iter. Inference: 0.1962 s/iter. Eval: 0.1902 s/iter. Total: 0.3978 s/iter. ETA=0:02:29
[01/18 00:11:55] detectron2.evaluation.evaluator INFO: Inference done 727/1093. Dataloading: 0.0114 s/iter. Inference: 0.1974 s/iter. Eval: 0.1910 s/iter. Total: 0.3999 s/iter. ETA=0:02:26
[01/18 00:12:01] detectron2.evaluation.evaluator INFO: Inference done 737/1093. Dataloading: 0.0114 s/iter. Inference: 0.1984 s/iter. Eval: 0.1916 s/iter. Total: 0.4015 s/iter. ETA=0:02:22
[01/18 00:12:06] detectron2.evaluation.evaluator INFO: Inference done 747/1093. Dataloading: 0.0115 s/iter. Inference: 0.1999 s/iter. Eval: 0.1918 s/iter. Total: 0.4033 s/iter. ETA=0:02:19
[01/18 00:12:11] detectron2.evaluation.evaluator INFO: Inference done 756/1093. Dataloading: 0.0116 s/iter. Inference: 0.2011 s/iter. Eval: 0.1927 s/iter. Total: 0.4054 s/iter. ETA=0:02:16
[01/18 00:12:17] detectron2.evaluation.evaluator INFO: Inference done 765/1093. Dataloading: 0.0116 s/iter. Inference: 0.2028 s/iter. Eval: 0.1932 s/iter. Total: 0.4077 s/iter. ETA=0:02:13
[01/18 00:12:22] detectron2.evaluation.evaluator INFO: Inference done 775/1093. Dataloading: 0.0116 s/iter. Inference: 0.2034 s/iter. Eval: 0.1941 s/iter. Total: 0.4093 s/iter. ETA=0:02:10
[01/18 00:12:27] detectron2.evaluation.evaluator INFO: Inference done 785/1093. Dataloading: 0.0117 s/iter. Inference: 0.2041 s/iter. Eval: 0.1948 s/iter. Total: 0.4106 s/iter. ETA=0:02:06
[01/18 00:12:32] detectron2.evaluation.evaluator INFO: Inference done 794/1093. Dataloading: 0.0118 s/iter. Inference: 0.2057 s/iter. Eval: 0.1952 s/iter. Total: 0.4128 s/iter. ETA=0:02:03
[01/18 00:12:38] detectron2.evaluation.evaluator INFO: Inference done 803/1093. Dataloading: 0.0119 s/iter. Inference: 0.2072 s/iter. Eval: 0.1954 s/iter. Total: 0.4147 s/iter. ETA=0:02:00
[01/18 00:12:43] detectron2.evaluation.evaluator INFO: Inference done 812/1093. Dataloading: 0.0120 s/iter. Inference: 0.2082 s/iter. Eval: 0.1961 s/iter. Total: 0.4164 s/iter. ETA=0:01:57
[01/18 00:12:48] detectron2.evaluation.evaluator INFO: Inference done 821/1093. Dataloading: 0.0121 s/iter. Inference: 0.2097 s/iter. Eval: 0.1963 s/iter. Total: 0.4181 s/iter. ETA=0:01:53
[01/18 00:12:53] detectron2.evaluation.evaluator INFO: Inference done 830/1093. Dataloading: 0.0123 s/iter. Inference: 0.2108 s/iter. Eval: 0.1967 s/iter. Total: 0.4199 s/iter. ETA=0:01:50
[01/18 00:12:59] detectron2.evaluation.evaluator INFO: Inference done 840/1093. Dataloading: 0.0123 s/iter. Inference: 0.2116 s/iter. Eval: 0.1974 s/iter. Total: 0.4214 s/iter. ETA=0:01:46
[01/18 00:13:04] detectron2.evaluation.evaluator INFO: Inference done 851/1093. Dataloading: 0.0124 s/iter. Inference: 0.2126 s/iter. Eval: 0.1974 s/iter. Total: 0.4226 s/iter. ETA=0:01:42
[01/18 00:13:09] detectron2.evaluation.evaluator INFO: Inference done 860/1093. Dataloading: 0.0124 s/iter. Inference: 0.2138 s/iter. Eval: 0.1979 s/iter. Total: 0.4242 s/iter. ETA=0:01:38
[01/18 00:13:14] detectron2.evaluation.evaluator INFO: Inference done 869/1093. Dataloading: 0.0125 s/iter. Inference: 0.2144 s/iter. Eval: 0.1987 s/iter. Total: 0.4257 s/iter. ETA=0:01:35
[01/18 00:13:20] detectron2.evaluation.evaluator INFO: Inference done 878/1093. Dataloading: 0.0126 s/iter. Inference: 0.2156 s/iter. Eval: 0.1994 s/iter. Total: 0.4278 s/iter. ETA=0:01:31
[01/18 00:13:26] detectron2.evaluation.evaluator INFO: Inference done 887/1093. Dataloading: 0.0127 s/iter. Inference: 0.2168 s/iter. Eval: 0.2001 s/iter. Total: 0.4297 s/iter. ETA=0:01:28
[01/18 00:13:31] detectron2.evaluation.evaluator INFO: Inference done 897/1093. Dataloading: 0.0127 s/iter. Inference: 0.2174 s/iter. Eval: 0.2003 s/iter. Total: 0.4306 s/iter. ETA=0:01:24
[01/18 00:13:36] detectron2.evaluation.evaluator INFO: Inference done 906/1093. Dataloading: 0.0128 s/iter. Inference: 0.2180 s/iter. Eval: 0.2012 s/iter. Total: 0.4321 s/iter. ETA=0:01:20
[01/18 00:13:41] detectron2.evaluation.evaluator INFO: Inference done 916/1093. Dataloading: 0.0128 s/iter. Inference: 0.2186 s/iter. Eval: 0.2014 s/iter. Total: 0.4329 s/iter. ETA=0:01:16
[01/18 00:13:46] detectron2.evaluation.evaluator INFO: Inference done 925/1093. Dataloading: 0.0128 s/iter. Inference: 0.2192 s/iter. Eval: 0.2021 s/iter. Total: 0.4342 s/iter. ETA=0:01:12
[01/18 00:13:51] detectron2.evaluation.evaluator INFO: Inference done 934/1093. Dataloading: 0.0128 s/iter. Inference: 0.2199 s/iter. Eval: 0.2029 s/iter. Total: 0.4357 s/iter. ETA=0:01:09
[01/18 00:13:57] detectron2.evaluation.evaluator INFO: Inference done 943/1093. Dataloading: 0.0128 s/iter. Inference: 0.2202 s/iter. Eval: 0.2040 s/iter. Total: 0.4372 s/iter. ETA=0:01:05
[01/18 00:14:02] detectron2.evaluation.evaluator INFO: Inference done 953/1093. Dataloading: 0.0128 s/iter. Inference: 0.2206 s/iter. Eval: 0.2044 s/iter. Total: 0.4379 s/iter. ETA=0:01:01
[01/18 00:14:07] detectron2.evaluation.evaluator INFO: Inference done 964/1093. Dataloading: 0.0129 s/iter. Inference: 0.2210 s/iter. Eval: 0.2045 s/iter. Total: 0.4384 s/iter. ETA=0:00:56
[01/18 00:14:12] detectron2.evaluation.evaluator INFO: Inference done 976/1093. Dataloading: 0.0129 s/iter. Inference: 0.2213 s/iter. Eval: 0.2041 s/iter. Total: 0.4383 s/iter. ETA=0:00:51
[01/18 00:14:17] detectron2.evaluation.evaluator INFO: Inference done 987/1093. Dataloading: 0.0128 s/iter. Inference: 0.2216 s/iter. Eval: 0.2041 s/iter. Total: 0.4387 s/iter. ETA=0:00:46
[01/18 00:14:23] detectron2.evaluation.evaluator INFO: Inference done 999/1093. Dataloading: 0.0129 s/iter. Inference: 0.2220 s/iter. Eval: 0.2039 s/iter. Total: 0.4388 s/iter. ETA=0:00:41
[01/18 00:14:28] detectron2.evaluation.evaluator INFO: Inference done 1010/1093. Dataloading: 0.0129 s/iter. Inference: 0.2225 s/iter. Eval: 0.2040 s/iter. Total: 0.4395 s/iter. ETA=0:00:36
[01/18 00:14:33] detectron2.evaluation.evaluator INFO: Inference done 1020/1093. Dataloading: 0.0129 s/iter. Inference: 0.2230 s/iter. Eval: 0.2041 s/iter. Total: 0.4401 s/iter. ETA=0:00:32
[01/18 00:14:39] detectron2.evaluation.evaluator INFO: Inference done 1031/1093. Dataloading: 0.0129 s/iter. Inference: 0.2237 s/iter. Eval: 0.2038 s/iter. Total: 0.4404 s/iter. ETA=0:00:27
[01/18 00:14:44] detectron2.evaluation.evaluator INFO: Inference done 1041/1093. Dataloading: 0.0129 s/iter. Inference: 0.2243 s/iter. Eval: 0.2038 s/iter. Total: 0.4411 s/iter. ETA=0:00:22
[01/18 00:14:49] detectron2.evaluation.evaluator INFO: Inference done 1051/1093. Dataloading: 0.0129 s/iter. Inference: 0.2246 s/iter. Eval: 0.2041 s/iter. Total: 0.4417 s/iter. ETA=0:00:18
[01/18 00:14:54] detectron2.evaluation.evaluator INFO: Inference done 1060/1093. Dataloading: 0.0130 s/iter. Inference: 0.2253 s/iter. Eval: 0.2043 s/iter. Total: 0.4427 s/iter. ETA=0:00:14
[01/18 00:14:59] detectron2.evaluation.evaluator INFO: Inference done 1070/1093. Dataloading: 0.0131 s/iter. Inference: 0.2257 s/iter. Eval: 0.2043 s/iter. Total: 0.4433 s/iter. ETA=0:00:10
[01/18 00:15:04] detectron2.evaluation.evaluator INFO: Inference done 1081/1093. Dataloading: 0.0131 s/iter. Inference: 0.2261 s/iter. Eval: 0.2043 s/iter. Total: 0.4437 s/iter. ETA=0:00:05
[01/18 00:15:09] detectron2.evaluation.evaluator INFO: Inference done 1093/1093. Dataloading: 0.0131 s/iter. Inference: 0.2263 s/iter. Eval: 0.2042 s/iter. Total: 0.4437 s/iter. ETA=0:00:00
[01/18 00:15:10] detectron2.evaluation.evaluator INFO: Total inference time: 0:08:03.251741 (0.444165 s / iter per device, on 4 devices)
[01/18 00:15:10] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:04:06 (0.226341 s / iter per device, on 4 devices)
[01/18 01:05:57] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 01:05:57] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 01:05:57] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 01:05:58] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 01:06:10] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0054 s/iter. Inference: 0.1286 s/iter. Eval: 0.1635 s/iter. Total: 0.2974 s/iter. ETA=0:05:21
[01/18 01:06:15] detectron2.evaluation.evaluator INFO: Inference done 24/1093. Dataloading: 0.0092 s/iter. Inference: 0.1471 s/iter. Eval: 0.2011 s/iter. Total: 0.3575 s/iter. ETA=0:06:22
[01/18 01:06:20] detectron2.evaluation.evaluator INFO: Inference done 39/1093. Dataloading: 0.0095 s/iter. Inference: 0.1412 s/iter. Eval: 0.2052 s/iter. Total: 0.3560 s/iter. ETA=0:06:15
[01/18 01:06:25] detectron2.evaluation.evaluator INFO: Inference done 54/1093. Dataloading: 0.0093 s/iter. Inference: 0.1482 s/iter. Eval: 0.1949 s/iter. Total: 0.3524 s/iter. ETA=0:06:06
[01/18 01:06:31] detectron2.evaluation.evaluator INFO: Inference done 69/1093. Dataloading: 0.0092 s/iter. Inference: 0.1521 s/iter. Eval: 0.1927 s/iter. Total: 0.3541 s/iter. ETA=0:06:02
[01/18 01:06:36] detectron2.evaluation.evaluator INFO: Inference done 83/1093. Dataloading: 0.0094 s/iter. Inference: 0.1557 s/iter. Eval: 0.1910 s/iter. Total: 0.3562 s/iter. ETA=0:05:59
[01/18 01:06:41] detectron2.evaluation.evaluator INFO: Inference done 100/1093. Dataloading: 0.0089 s/iter. Inference: 0.1558 s/iter. Eval: 0.1829 s/iter. Total: 0.3476 s/iter. ETA=0:05:45
[01/18 01:06:46] detectron2.evaluation.evaluator INFO: Inference done 116/1093. Dataloading: 0.0088 s/iter. Inference: 0.1576 s/iter. Eval: 0.1784 s/iter. Total: 0.3449 s/iter. ETA=0:05:36
[01/18 01:06:51] detectron2.evaluation.evaluator INFO: Inference done 131/1093. Dataloading: 0.0089 s/iter. Inference: 0.1573 s/iter. Eval: 0.1776 s/iter. Total: 0.3438 s/iter. ETA=0:05:30
[01/18 01:06:56] detectron2.evaluation.evaluator INFO: Inference done 148/1093. Dataloading: 0.0086 s/iter. Inference: 0.1560 s/iter. Eval: 0.1737 s/iter. Total: 0.3384 s/iter. ETA=0:05:19
[01/18 01:07:01] detectron2.evaluation.evaluator INFO: Inference done 163/1093. Dataloading: 0.0086 s/iter. Inference: 0.1570 s/iter. Eval: 0.1732 s/iter. Total: 0.3389 s/iter. ETA=0:05:15
[01/18 01:07:07] detectron2.evaluation.evaluator INFO: Inference done 178/1093. Dataloading: 0.0087 s/iter. Inference: 0.1577 s/iter. Eval: 0.1734 s/iter. Total: 0.3400 s/iter. ETA=0:05:11
[01/18 01:07:12] detectron2.evaluation.evaluator INFO: Inference done 194/1093. Dataloading: 0.0086 s/iter. Inference: 0.1572 s/iter. Eval: 0.1730 s/iter. Total: 0.3389 s/iter. ETA=0:05:04
[01/18 01:07:17] detectron2.evaluation.evaluator INFO: Inference done 208/1093. Dataloading: 0.0088 s/iter. Inference: 0.1577 s/iter. Eval: 0.1741 s/iter. Total: 0.3407 s/iter. ETA=0:05:01
[01/18 01:07:22] detectron2.evaluation.evaluator INFO: Inference done 225/1093. Dataloading: 0.0087 s/iter. Inference: 0.1580 s/iter. Eval: 0.1706 s/iter. Total: 0.3374 s/iter. ETA=0:04:52
[01/18 01:07:27] detectron2.evaluation.evaluator INFO: Inference done 240/1093. Dataloading: 0.0086 s/iter. Inference: 0.1576 s/iter. Eval: 0.1709 s/iter. Total: 0.3372 s/iter. ETA=0:04:47
[01/18 01:07:32] detectron2.evaluation.evaluator INFO: Inference done 254/1093. Dataloading: 0.0087 s/iter. Inference: 0.1585 s/iter. Eval: 0.1720 s/iter. Total: 0.3393 s/iter. ETA=0:04:44
[01/18 01:07:38] detectron2.evaluation.evaluator INFO: Inference done 268/1093. Dataloading: 0.0087 s/iter. Inference: 0.1590 s/iter. Eval: 0.1732 s/iter. Total: 0.3410 s/iter. ETA=0:04:41
[01/18 01:07:43] detectron2.evaluation.evaluator INFO: Inference done 284/1093. Dataloading: 0.0087 s/iter. Inference: 0.1583 s/iter. Eval: 0.1724 s/iter. Total: 0.3394 s/iter. ETA=0:04:34
[01/18 01:07:48] detectron2.evaluation.evaluator INFO: Inference done 299/1093. Dataloading: 0.0086 s/iter. Inference: 0.1583 s/iter. Eval: 0.1730 s/iter. Total: 0.3400 s/iter. ETA=0:04:29
[01/18 01:07:53] detectron2.evaluation.evaluator INFO: Inference done 316/1093. Dataloading: 0.0086 s/iter. Inference: 0.1583 s/iter. Eval: 0.1708 s/iter. Total: 0.3378 s/iter. ETA=0:04:22
[01/18 01:07:58] detectron2.evaluation.evaluator INFO: Inference done 332/1093. Dataloading: 0.0087 s/iter. Inference: 0.1583 s/iter. Eval: 0.1700 s/iter. Total: 0.3370 s/iter. ETA=0:04:16
[01/18 01:08:03] detectron2.evaluation.evaluator INFO: Inference done 347/1093. Dataloading: 0.0087 s/iter. Inference: 0.1584 s/iter. Eval: 0.1704 s/iter. Total: 0.3375 s/iter. ETA=0:04:11
[01/18 01:08:08] detectron2.evaluation.evaluator INFO: Inference done 361/1093. Dataloading: 0.0087 s/iter. Inference: 0.1583 s/iter. Eval: 0.1713 s/iter. Total: 0.3384 s/iter. ETA=0:04:07
[01/18 01:08:14] detectron2.evaluation.evaluator INFO: Inference done 378/1093. Dataloading: 0.0087 s/iter. Inference: 0.1579 s/iter. Eval: 0.1708 s/iter. Total: 0.3375 s/iter. ETA=0:04:01
[01/18 01:08:19] detectron2.evaluation.evaluator INFO: Inference done 392/1093. Dataloading: 0.0087 s/iter. Inference: 0.1578 s/iter. Eval: 0.1721 s/iter. Total: 0.3386 s/iter. ETA=0:03:57
[01/18 01:08:24] detectron2.evaluation.evaluator INFO: Inference done 406/1093. Dataloading: 0.0087 s/iter. Inference: 0.1579 s/iter. Eval: 0.1736 s/iter. Total: 0.3403 s/iter. ETA=0:03:53
[01/18 01:08:29] detectron2.evaluation.evaluator INFO: Inference done 421/1093. Dataloading: 0.0087 s/iter. Inference: 0.1575 s/iter. Eval: 0.1741 s/iter. Total: 0.3405 s/iter. ETA=0:03:48
[01/18 01:08:35] detectron2.evaluation.evaluator INFO: Inference done 437/1093. Dataloading: 0.0087 s/iter. Inference: 0.1579 s/iter. Eval: 0.1735 s/iter. Total: 0.3402 s/iter. ETA=0:03:43
[01/18 01:08:40] detectron2.evaluation.evaluator INFO: Inference done 455/1093. Dataloading: 0.0086 s/iter. Inference: 0.1573 s/iter. Eval: 0.1721 s/iter. Total: 0.3381 s/iter. ETA=0:03:35
[01/18 01:08:45] detectron2.evaluation.evaluator INFO: Inference done 471/1093. Dataloading: 0.0086 s/iter. Inference: 0.1574 s/iter. Eval: 0.1717 s/iter. Total: 0.3378 s/iter. ETA=0:03:30
[01/18 01:08:50] detectron2.evaluation.evaluator INFO: Inference done 486/1093. Dataloading: 0.0086 s/iter. Inference: 0.1574 s/iter. Eval: 0.1717 s/iter. Total: 0.3378 s/iter. ETA=0:03:25
[01/18 01:08:55] detectron2.evaluation.evaluator INFO: Inference done 500/1093. Dataloading: 0.0086 s/iter. Inference: 0.1571 s/iter. Eval: 0.1726 s/iter. Total: 0.3384 s/iter. ETA=0:03:20
[01/18 01:09:00] detectron2.evaluation.evaluator INFO: Inference done 514/1093. Dataloading: 0.0087 s/iter. Inference: 0.1576 s/iter. Eval: 0.1729 s/iter. Total: 0.3392 s/iter. ETA=0:03:16
[01/18 01:09:06] detectron2.evaluation.evaluator INFO: Inference done 528/1093. Dataloading: 0.0087 s/iter. Inference: 0.1577 s/iter. Eval: 0.1734 s/iter. Total: 0.3399 s/iter. ETA=0:03:12
[01/18 01:09:11] detectron2.evaluation.evaluator INFO: Inference done 545/1093. Dataloading: 0.0086 s/iter. Inference: 0.1577 s/iter. Eval: 0.1726 s/iter. Total: 0.3389 s/iter. ETA=0:03:05
[01/18 01:09:16] detectron2.evaluation.evaluator INFO: Inference done 560/1093. Dataloading: 0.0086 s/iter. Inference: 0.1578 s/iter. Eval: 0.1729 s/iter. Total: 0.3394 s/iter. ETA=0:03:00
[01/18 01:09:21] detectron2.evaluation.evaluator INFO: Inference done 574/1093. Dataloading: 0.0086 s/iter. Inference: 0.1580 s/iter. Eval: 0.1733 s/iter. Total: 0.3399 s/iter. ETA=0:02:56
[01/18 01:09:26] detectron2.evaluation.evaluator INFO: Inference done 589/1093. Dataloading: 0.0086 s/iter. Inference: 0.1581 s/iter. Eval: 0.1733 s/iter. Total: 0.3401 s/iter. ETA=0:02:51
[01/18 01:09:32] detectron2.evaluation.evaluator INFO: Inference done 605/1093. Dataloading: 0.0086 s/iter. Inference: 0.1580 s/iter. Eval: 0.1731 s/iter. Total: 0.3398 s/iter. ETA=0:02:45
[01/18 01:09:37] detectron2.evaluation.evaluator INFO: Inference done 621/1093. Dataloading: 0.0086 s/iter. Inference: 0.1579 s/iter. Eval: 0.1728 s/iter. Total: 0.3393 s/iter. ETA=0:02:40
[01/18 01:09:42] detectron2.evaluation.evaluator INFO: Inference done 635/1093. Dataloading: 0.0086 s/iter. Inference: 0.1585 s/iter. Eval: 0.1728 s/iter. Total: 0.3400 s/iter. ETA=0:02:35
[01/18 01:09:47] detectron2.evaluation.evaluator INFO: Inference done 648/1093. Dataloading: 0.0086 s/iter. Inference: 0.1588 s/iter. Eval: 0.1734 s/iter. Total: 0.3409 s/iter. ETA=0:02:31
[01/18 01:09:52] detectron2.evaluation.evaluator INFO: Inference done 663/1093. Dataloading: 0.0086 s/iter. Inference: 0.1587 s/iter. Eval: 0.1735 s/iter. Total: 0.3408 s/iter. ETA=0:02:26
[01/18 01:09:57] detectron2.evaluation.evaluator INFO: Inference done 677/1093. Dataloading: 0.0086 s/iter. Inference: 0.1587 s/iter. Eval: 0.1739 s/iter. Total: 0.3412 s/iter. ETA=0:02:21
[01/18 01:10:02] detectron2.evaluation.evaluator INFO: Inference done 691/1093. Dataloading: 0.0086 s/iter. Inference: 0.1587 s/iter. Eval: 0.1745 s/iter. Total: 0.3419 s/iter. ETA=0:02:17
[01/18 01:10:08] detectron2.evaluation.evaluator INFO: Inference done 707/1093. Dataloading: 0.0086 s/iter. Inference: 0.1584 s/iter. Eval: 0.1744 s/iter. Total: 0.3414 s/iter. ETA=0:02:11
[01/18 01:10:13] detectron2.evaluation.evaluator INFO: Inference done 724/1093. Dataloading: 0.0086 s/iter. Inference: 0.1579 s/iter. Eval: 0.1740 s/iter. Total: 0.3405 s/iter. ETA=0:02:05
[01/18 01:10:18] detectron2.evaluation.evaluator INFO: Inference done 741/1093. Dataloading: 0.0086 s/iter. Inference: 0.1575 s/iter. Eval: 0.1734 s/iter. Total: 0.3396 s/iter. ETA=0:01:59
[01/18 01:10:23] detectron2.evaluation.evaluator INFO: Inference done 757/1093. Dataloading: 0.0086 s/iter. Inference: 0.1575 s/iter. Eval: 0.1732 s/iter. Total: 0.3393 s/iter. ETA=0:01:54
[01/18 01:10:28] detectron2.evaluation.evaluator INFO: Inference done 773/1093. Dataloading: 0.0085 s/iter. Inference: 0.1574 s/iter. Eval: 0.1731 s/iter. Total: 0.3391 s/iter. ETA=0:01:48
[01/18 01:10:33] detectron2.evaluation.evaluator INFO: Inference done 788/1093. Dataloading: 0.0086 s/iter. Inference: 0.1575 s/iter. Eval: 0.1730 s/iter. Total: 0.3392 s/iter. ETA=0:01:43
[01/18 01:10:39] detectron2.evaluation.evaluator INFO: Inference done 805/1093. Dataloading: 0.0086 s/iter. Inference: 0.1571 s/iter. Eval: 0.1729 s/iter. Total: 0.3386 s/iter. ETA=0:01:37
[01/18 01:10:44] detectron2.evaluation.evaluator INFO: Inference done 821/1093. Dataloading: 0.0085 s/iter. Inference: 0.1568 s/iter. Eval: 0.1731 s/iter. Total: 0.3385 s/iter. ETA=0:01:32
[01/18 01:10:49] detectron2.evaluation.evaluator INFO: Inference done 838/1093. Dataloading: 0.0085 s/iter. Inference: 0.1565 s/iter. Eval: 0.1728 s/iter. Total: 0.3379 s/iter. ETA=0:01:26
[01/18 01:10:54] detectron2.evaluation.evaluator INFO: Inference done 854/1093. Dataloading: 0.0085 s/iter. Inference: 0.1563 s/iter. Eval: 0.1726 s/iter. Total: 0.3374 s/iter. ETA=0:01:20
[01/18 01:11:00] detectron2.evaluation.evaluator INFO: Inference done 869/1093. Dataloading: 0.0085 s/iter. Inference: 0.1562 s/iter. Eval: 0.1728 s/iter. Total: 0.3376 s/iter. ETA=0:01:15
[01/18 01:11:05] detectron2.evaluation.evaluator INFO: Inference done 884/1093. Dataloading: 0.0085 s/iter. Inference: 0.1562 s/iter. Eval: 0.1729 s/iter. Total: 0.3377 s/iter. ETA=0:01:10
[01/18 01:11:10] detectron2.evaluation.evaluator INFO: Inference done 900/1093. Dataloading: 0.0086 s/iter. Inference: 0.1561 s/iter. Eval: 0.1727 s/iter. Total: 0.3375 s/iter. ETA=0:01:05
[01/18 01:11:15] detectron2.evaluation.evaluator INFO: Inference done 915/1093. Dataloading: 0.0086 s/iter. Inference: 0.1560 s/iter. Eval: 0.1732 s/iter. Total: 0.3378 s/iter. ETA=0:01:00
[01/18 01:11:20] detectron2.evaluation.evaluator INFO: Inference done 928/1093. Dataloading: 0.0086 s/iter. Inference: 0.1560 s/iter. Eval: 0.1739 s/iter. Total: 0.3386 s/iter. ETA=0:00:55
[01/18 01:11:26] detectron2.evaluation.evaluator INFO: Inference done 943/1093. Dataloading: 0.0086 s/iter. Inference: 0.1558 s/iter. Eval: 0.1742 s/iter. Total: 0.3387 s/iter. ETA=0:00:50
[01/18 01:11:31] detectron2.evaluation.evaluator INFO: Inference done 959/1093. Dataloading: 0.0086 s/iter. Inference: 0.1558 s/iter. Eval: 0.1739 s/iter. Total: 0.3384 s/iter. ETA=0:00:45
[01/18 01:11:36] detectron2.evaluation.evaluator INFO: Inference done 976/1093. Dataloading: 0.0085 s/iter. Inference: 0.1558 s/iter. Eval: 0.1732 s/iter. Total: 0.3376 s/iter. ETA=0:00:39
[01/18 01:11:41] detectron2.evaluation.evaluator INFO: Inference done 992/1093. Dataloading: 0.0085 s/iter. Inference: 0.1559 s/iter. Eval: 0.1730 s/iter. Total: 0.3375 s/iter. ETA=0:00:34
[01/18 01:11:46] detectron2.evaluation.evaluator INFO: Inference done 1009/1093. Dataloading: 0.0085 s/iter. Inference: 0.1559 s/iter. Eval: 0.1725 s/iter. Total: 0.3371 s/iter. ETA=0:00:28
[01/18 01:11:51] detectron2.evaluation.evaluator INFO: Inference done 1025/1093. Dataloading: 0.0085 s/iter. Inference: 0.1560 s/iter. Eval: 0.1722 s/iter. Total: 0.3368 s/iter. ETA=0:00:22
[01/18 01:11:57] detectron2.evaluation.evaluator INFO: Inference done 1041/1093. Dataloading: 0.0085 s/iter. Inference: 0.1562 s/iter. Eval: 0.1719 s/iter. Total: 0.3367 s/iter. ETA=0:00:17
[01/18 01:12:02] detectron2.evaluation.evaluator INFO: Inference done 1057/1093. Dataloading: 0.0085 s/iter. Inference: 0.1560 s/iter. Eval: 0.1720 s/iter. Total: 0.3366 s/iter. ETA=0:00:12
[01/18 01:12:07] detectron2.evaluation.evaluator INFO: Inference done 1073/1093. Dataloading: 0.0085 s/iter. Inference: 0.1559 s/iter. Eval: 0.1719 s/iter. Total: 0.3364 s/iter. ETA=0:00:06
[01/18 01:12:12] detectron2.evaluation.evaluator INFO: Inference done 1089/1093. Dataloading: 0.0085 s/iter. Inference: 0.1560 s/iter. Eval: 0.1718 s/iter. Total: 0.3364 s/iter. ETA=0:00:01
[01/18 01:12:14] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:06.283473 (0.336658 s / iter per device, on 4 devices)
[01/18 01:12:14] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:49 (0.155904 s / iter per device, on 4 devices)
[01/18 02:00:58] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 02:00:59] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 02:00:59] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 02:00:59] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 02:01:12] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0062 s/iter. Inference: 0.1305 s/iter. Eval: 0.1990 s/iter. Total: 0.3357 s/iter. ETA=0:06:03
[01/18 02:01:17] detectron2.evaluation.evaluator INFO: Inference done 24/1093. Dataloading: 0.0093 s/iter. Inference: 0.1358 s/iter. Eval: 0.2301 s/iter. Total: 0.3753 s/iter. ETA=0:06:41
[01/18 02:01:23] detectron2.evaluation.evaluator INFO: Inference done 37/1093. Dataloading: 0.0102 s/iter. Inference: 0.1375 s/iter. Eval: 0.2401 s/iter. Total: 0.3879 s/iter. ETA=0:06:49
[01/18 02:01:28] detectron2.evaluation.evaluator INFO: Inference done 52/1093. Dataloading: 0.0103 s/iter. Inference: 0.1363 s/iter. Eval: 0.2246 s/iter. Total: 0.3712 s/iter. ETA=0:06:26
[01/18 02:01:33] detectron2.evaluation.evaluator INFO: Inference done 68/1093. Dataloading: 0.0100 s/iter. Inference: 0.1359 s/iter. Eval: 0.2149 s/iter. Total: 0.3610 s/iter. ETA=0:06:10
[01/18 02:01:38] detectron2.evaluation.evaluator INFO: Inference done 81/1093. Dataloading: 0.0102 s/iter. Inference: 0.1371 s/iter. Eval: 0.2208 s/iter. Total: 0.3682 s/iter. ETA=0:06:12
[01/18 02:01:43] detectron2.evaluation.evaluator INFO: Inference done 98/1093. Dataloading: 0.0097 s/iter. Inference: 0.1361 s/iter. Eval: 0.2094 s/iter. Total: 0.3553 s/iter. ETA=0:05:53
[01/18 02:01:48] detectron2.evaluation.evaluator INFO: Inference done 114/1093. Dataloading: 0.0096 s/iter. Inference: 0.1359 s/iter. Eval: 0.2043 s/iter. Total: 0.3500 s/iter. ETA=0:05:42
[01/18 02:01:54] detectron2.evaluation.evaluator INFO: Inference done 130/1093. Dataloading: 0.0097 s/iter. Inference: 0.1355 s/iter. Eval: 0.2018 s/iter. Total: 0.3471 s/iter. ETA=0:05:34
[01/18 02:01:59] detectron2.evaluation.evaluator INFO: Inference done 146/1093. Dataloading: 0.0095 s/iter. Inference: 0.1359 s/iter. Eval: 0.1987 s/iter. Total: 0.3442 s/iter. ETA=0:05:25
[01/18 02:02:04] detectron2.evaluation.evaluator INFO: Inference done 160/1093. Dataloading: 0.0096 s/iter. Inference: 0.1365 s/iter. Eval: 0.1998 s/iter. Total: 0.3459 s/iter. ETA=0:05:22
[01/18 02:02:09] detectron2.evaluation.evaluator INFO: Inference done 175/1093. Dataloading: 0.0095 s/iter. Inference: 0.1368 s/iter. Eval: 0.1989 s/iter. Total: 0.3453 s/iter. ETA=0:05:17
[01/18 02:02:14] detectron2.evaluation.evaluator INFO: Inference done 191/1093. Dataloading: 0.0095 s/iter. Inference: 0.1365 s/iter. Eval: 0.1982 s/iter. Total: 0.3443 s/iter. ETA=0:05:10
[01/18 02:02:19] detectron2.evaluation.evaluator INFO: Inference done 204/1093. Dataloading: 0.0095 s/iter. Inference: 0.1364 s/iter. Eval: 0.2010 s/iter. Total: 0.3471 s/iter. ETA=0:05:08
[01/18 02:02:24] detectron2.evaluation.evaluator INFO: Inference done 220/1093. Dataloading: 0.0095 s/iter. Inference: 0.1367 s/iter. Eval: 0.1987 s/iter. Total: 0.3450 s/iter. ETA=0:05:01
[01/18 02:02:30] detectron2.evaluation.evaluator INFO: Inference done 237/1093. Dataloading: 0.0094 s/iter. Inference: 0.1362 s/iter. Eval: 0.1963 s/iter. Total: 0.3420 s/iter. ETA=0:04:52
[01/18 02:02:35] detectron2.evaluation.evaluator INFO: Inference done 251/1093. Dataloading: 0.0094 s/iter. Inference: 0.1365 s/iter. Eval: 0.1973 s/iter. Total: 0.3433 s/iter. ETA=0:04:49
[01/18 02:02:40] detectron2.evaluation.evaluator INFO: Inference done 263/1093. Dataloading: 0.0096 s/iter. Inference: 0.1373 s/iter. Eval: 0.2001 s/iter. Total: 0.3472 s/iter. ETA=0:04:48
[01/18 02:02:45] detectron2.evaluation.evaluator INFO: Inference done 281/1093. Dataloading: 0.0095 s/iter. Inference: 0.1363 s/iter. Eval: 0.1969 s/iter. Total: 0.3429 s/iter. ETA=0:04:38
[01/18 02:02:50] detectron2.evaluation.evaluator INFO: Inference done 297/1093. Dataloading: 0.0095 s/iter. Inference: 0.1355 s/iter. Eval: 0.1969 s/iter. Total: 0.3421 s/iter. ETA=0:04:32
[01/18 02:02:55] detectron2.evaluation.evaluator INFO: Inference done 314/1093. Dataloading: 0.0095 s/iter. Inference: 0.1359 s/iter. Eval: 0.1943 s/iter. Total: 0.3398 s/iter. ETA=0:04:24
[01/18 02:03:00] detectron2.evaluation.evaluator INFO: Inference done 330/1093. Dataloading: 0.0095 s/iter. Inference: 0.1362 s/iter. Eval: 0.1932 s/iter. Total: 0.3389 s/iter. ETA=0:04:18
[01/18 02:03:06] detectron2.evaluation.evaluator INFO: Inference done 345/1093. Dataloading: 0.0095 s/iter. Inference: 0.1362 s/iter. Eval: 0.1933 s/iter. Total: 0.3391 s/iter. ETA=0:04:13
[01/18 02:03:11] detectron2.evaluation.evaluator INFO: Inference done 360/1093. Dataloading: 0.0096 s/iter. Inference: 0.1365 s/iter. Eval: 0.1935 s/iter. Total: 0.3396 s/iter. ETA=0:04:08
[01/18 02:03:16] detectron2.evaluation.evaluator INFO: Inference done 375/1093. Dataloading: 0.0096 s/iter. Inference: 0.1366 s/iter. Eval: 0.1934 s/iter. Total: 0.3396 s/iter. ETA=0:04:03
[01/18 02:03:21] detectron2.evaluation.evaluator INFO: Inference done 386/1093. Dataloading: 0.0097 s/iter. Inference: 0.1371 s/iter. Eval: 0.1973 s/iter. Total: 0.3441 s/iter. ETA=0:04:03
[01/18 02:03:27] detectron2.evaluation.evaluator INFO: Inference done 400/1093. Dataloading: 0.0096 s/iter. Inference: 0.1373 s/iter. Eval: 0.1980 s/iter. Total: 0.3450 s/iter. ETA=0:03:59
[01/18 02:03:32] detectron2.evaluation.evaluator INFO: Inference done 414/1093. Dataloading: 0.0097 s/iter. Inference: 0.1370 s/iter. Eval: 0.1993 s/iter. Total: 0.3461 s/iter. ETA=0:03:54
[01/18 02:03:37] detectron2.evaluation.evaluator INFO: Inference done 430/1093. Dataloading: 0.0096 s/iter. Inference: 0.1368 s/iter. Eval: 0.1987 s/iter. Total: 0.3453 s/iter. ETA=0:03:48
[01/18 02:03:42] detectron2.evaluation.evaluator INFO: Inference done 445/1093. Dataloading: 0.0097 s/iter. Inference: 0.1370 s/iter. Eval: 0.1983 s/iter. Total: 0.3451 s/iter. ETA=0:03:43
[01/18 02:03:47] detectron2.evaluation.evaluator INFO: Inference done 462/1093. Dataloading: 0.0096 s/iter. Inference: 0.1367 s/iter. Eval: 0.1970 s/iter. Total: 0.3435 s/iter. ETA=0:03:36
[01/18 02:03:52] detectron2.evaluation.evaluator INFO: Inference done 476/1093. Dataloading: 0.0096 s/iter. Inference: 0.1368 s/iter. Eval: 0.1976 s/iter. Total: 0.3441 s/iter. ETA=0:03:32
[01/18 02:03:57] detectron2.evaluation.evaluator INFO: Inference done 491/1093. Dataloading: 0.0096 s/iter. Inference: 0.1371 s/iter. Eval: 0.1971 s/iter. Total: 0.3439 s/iter. ETA=0:03:27
[01/18 02:04:02] detectron2.evaluation.evaluator INFO: Inference done 505/1093. Dataloading: 0.0096 s/iter. Inference: 0.1369 s/iter. Eval: 0.1977 s/iter. Total: 0.3443 s/iter. ETA=0:03:22
[01/18 02:04:08] detectron2.evaluation.evaluator INFO: Inference done 519/1093. Dataloading: 0.0096 s/iter. Inference: 0.1370 s/iter. Eval: 0.1982 s/iter. Total: 0.3450 s/iter. ETA=0:03:18
[01/18 02:04:13] detectron2.evaluation.evaluator INFO: Inference done 534/1093. Dataloading: 0.0096 s/iter. Inference: 0.1371 s/iter. Eval: 0.1982 s/iter. Total: 0.3450 s/iter. ETA=0:03:12
[01/18 02:04:18] detectron2.evaluation.evaluator INFO: Inference done 549/1093. Dataloading: 0.0096 s/iter. Inference: 0.1373 s/iter. Eval: 0.1977 s/iter. Total: 0.3447 s/iter. ETA=0:03:07
[01/18 02:04:23] detectron2.evaluation.evaluator INFO: Inference done 563/1093. Dataloading: 0.0096 s/iter. Inference: 0.1375 s/iter. Eval: 0.1985 s/iter. Total: 0.3457 s/iter. ETA=0:03:03
[01/18 02:04:28] detectron2.evaluation.evaluator INFO: Inference done 578/1093. Dataloading: 0.0096 s/iter. Inference: 0.1372 s/iter. Eval: 0.1989 s/iter. Total: 0.3459 s/iter. ETA=0:02:58
[01/18 02:04:33] detectron2.evaluation.evaluator INFO: Inference done 592/1093. Dataloading: 0.0097 s/iter. Inference: 0.1373 s/iter. Eval: 0.1991 s/iter. Total: 0.3462 s/iter. ETA=0:02:53
[01/18 02:04:39] detectron2.evaluation.evaluator INFO: Inference done 606/1093. Dataloading: 0.0096 s/iter. Inference: 0.1375 s/iter. Eval: 0.1995 s/iter. Total: 0.3467 s/iter. ETA=0:02:48
[01/18 02:04:44] detectron2.evaluation.evaluator INFO: Inference done 622/1093. Dataloading: 0.0096 s/iter. Inference: 0.1374 s/iter. Eval: 0.1987 s/iter. Total: 0.3458 s/iter. ETA=0:02:42
[01/18 02:04:49] detectron2.evaluation.evaluator INFO: Inference done 635/1093. Dataloading: 0.0097 s/iter. Inference: 0.1375 s/iter. Eval: 0.1994 s/iter. Total: 0.3467 s/iter. ETA=0:02:38
[01/18 02:04:54] detectron2.evaluation.evaluator INFO: Inference done 650/1093. Dataloading: 0.0097 s/iter. Inference: 0.1374 s/iter. Eval: 0.1995 s/iter. Total: 0.3467 s/iter. ETA=0:02:33
[01/18 02:04:59] detectron2.evaluation.evaluator INFO: Inference done 665/1093. Dataloading: 0.0097 s/iter. Inference: 0.1373 s/iter. Eval: 0.1997 s/iter. Total: 0.3468 s/iter. ETA=0:02:28
[01/18 02:05:04] detectron2.evaluation.evaluator INFO: Inference done 679/1093. Dataloading: 0.0097 s/iter. Inference: 0.1375 s/iter. Eval: 0.2000 s/iter. Total: 0.3473 s/iter. ETA=0:02:23
[01/18 02:05:09] detectron2.evaluation.evaluator INFO: Inference done 692/1093. Dataloading: 0.0097 s/iter. Inference: 0.1375 s/iter. Eval: 0.2008 s/iter. Total: 0.3481 s/iter. ETA=0:02:19
[01/18 02:05:15] detectron2.evaluation.evaluator INFO: Inference done 708/1093. Dataloading: 0.0097 s/iter. Inference: 0.1374 s/iter. Eval: 0.2005 s/iter. Total: 0.3477 s/iter. ETA=0:02:13
[01/18 02:05:20] detectron2.evaluation.evaluator INFO: Inference done 722/1093. Dataloading: 0.0097 s/iter. Inference: 0.1376 s/iter. Eval: 0.2005 s/iter. Total: 0.3479 s/iter. ETA=0:02:09
[01/18 02:05:25] detectron2.evaluation.evaluator INFO: Inference done 737/1093. Dataloading: 0.0097 s/iter. Inference: 0.1376 s/iter. Eval: 0.2004 s/iter. Total: 0.3478 s/iter. ETA=0:02:03
[01/18 02:05:30] detectron2.evaluation.evaluator INFO: Inference done 753/1093. Dataloading: 0.0097 s/iter. Inference: 0.1376 s/iter. Eval: 0.1999 s/iter. Total: 0.3473 s/iter. ETA=0:01:58
[01/18 02:05:35] detectron2.evaluation.evaluator INFO: Inference done 768/1093. Dataloading: 0.0097 s/iter. Inference: 0.1375 s/iter. Eval: 0.2000 s/iter. Total: 0.3473 s/iter. ETA=0:01:52
[01/18 02:05:40] detectron2.evaluation.evaluator INFO: Inference done 783/1093. Dataloading: 0.0096 s/iter. Inference: 0.1375 s/iter. Eval: 0.1999 s/iter. Total: 0.3470 s/iter. ETA=0:01:47
[01/18 02:05:45] detectron2.evaluation.evaluator INFO: Inference done 799/1093. Dataloading: 0.0096 s/iter. Inference: 0.1373 s/iter. Eval: 0.1994 s/iter. Total: 0.3465 s/iter. ETA=0:01:41
[01/18 02:05:50] detectron2.evaluation.evaluator INFO: Inference done 813/1093. Dataloading: 0.0096 s/iter. Inference: 0.1374 s/iter. Eval: 0.1995 s/iter. Total: 0.3467 s/iter. ETA=0:01:37
[01/18 02:05:56] detectron2.evaluation.evaluator INFO: Inference done 829/1093. Dataloading: 0.0096 s/iter. Inference: 0.1373 s/iter. Eval: 0.1992 s/iter. Total: 0.3463 s/iter. ETA=0:01:31
[01/18 02:06:01] detectron2.evaluation.evaluator INFO: Inference done 845/1093. Dataloading: 0.0096 s/iter. Inference: 0.1373 s/iter. Eval: 0.1987 s/iter. Total: 0.3457 s/iter. ETA=0:01:25
[01/18 02:06:06] detectron2.evaluation.evaluator INFO: Inference done 860/1093. Dataloading: 0.0096 s/iter. Inference: 0.1373 s/iter. Eval: 0.1984 s/iter. Total: 0.3455 s/iter. ETA=0:01:20
[01/18 02:06:11] detectron2.evaluation.evaluator INFO: Inference done 875/1093. Dataloading: 0.0097 s/iter. Inference: 0.1372 s/iter. Eval: 0.1986 s/iter. Total: 0.3456 s/iter. ETA=0:01:15
[01/18 02:06:16] detectron2.evaluation.evaluator INFO: Inference done 889/1093. Dataloading: 0.0097 s/iter. Inference: 0.1373 s/iter. Eval: 0.1989 s/iter. Total: 0.3460 s/iter. ETA=0:01:10
[01/18 02:06:21] detectron2.evaluation.evaluator INFO: Inference done 904/1093. Dataloading: 0.0097 s/iter. Inference: 0.1372 s/iter. Eval: 0.1988 s/iter. Total: 0.3458 s/iter. ETA=0:01:05
[01/18 02:06:26] detectron2.evaluation.evaluator INFO: Inference done 919/1093. Dataloading: 0.0097 s/iter. Inference: 0.1372 s/iter. Eval: 0.1987 s/iter. Total: 0.3456 s/iter. ETA=0:01:00
[01/18 02:06:31] detectron2.evaluation.evaluator INFO: Inference done 932/1093. Dataloading: 0.0097 s/iter. Inference: 0.1372 s/iter. Eval: 0.1993 s/iter. Total: 0.3463 s/iter. ETA=0:00:55
[01/18 02:06:36] detectron2.evaluation.evaluator INFO: Inference done 947/1093. Dataloading: 0.0097 s/iter. Inference: 0.1372 s/iter. Eval: 0.1993 s/iter. Total: 0.3463 s/iter. ETA=0:00:50
[01/18 02:06:41] detectron2.evaluation.evaluator INFO: Inference done 962/1093. Dataloading: 0.0097 s/iter. Inference: 0.1371 s/iter. Eval: 0.1992 s/iter. Total: 0.3461 s/iter. ETA=0:00:45
[01/18 02:06:47] detectron2.evaluation.evaluator INFO: Inference done 979/1093. Dataloading: 0.0097 s/iter. Inference: 0.1370 s/iter. Eval: 0.1985 s/iter. Total: 0.3453 s/iter. ETA=0:00:39
[01/18 02:06:52] detectron2.evaluation.evaluator INFO: Inference done 995/1093. Dataloading: 0.0097 s/iter. Inference: 0.1370 s/iter. Eval: 0.1982 s/iter. Total: 0.3449 s/iter. ETA=0:00:33
[01/18 02:06:57] detectron2.evaluation.evaluator INFO: Inference done 1012/1093. Dataloading: 0.0096 s/iter. Inference: 0.1368 s/iter. Eval: 0.1976 s/iter. Total: 0.3441 s/iter. ETA=0:00:27
[01/18 02:07:02] detectron2.evaluation.evaluator INFO: Inference done 1027/1093. Dataloading: 0.0097 s/iter. Inference: 0.1370 s/iter. Eval: 0.1974 s/iter. Total: 0.3442 s/iter. ETA=0:00:22
[01/18 02:07:07] detectron2.evaluation.evaluator INFO: Inference done 1043/1093. Dataloading: 0.0096 s/iter. Inference: 0.1372 s/iter. Eval: 0.1969 s/iter. Total: 0.3438 s/iter. ETA=0:00:17
[01/18 02:07:12] detectron2.evaluation.evaluator INFO: Inference done 1058/1093. Dataloading: 0.0096 s/iter. Inference: 0.1372 s/iter. Eval: 0.1969 s/iter. Total: 0.3438 s/iter. ETA=0:00:12
[01/18 02:07:17] detectron2.evaluation.evaluator INFO: Inference done 1073/1093. Dataloading: 0.0096 s/iter. Inference: 0.1372 s/iter. Eval: 0.1969 s/iter. Total: 0.3437 s/iter. ETA=0:00:06
[01/18 02:07:23] detectron2.evaluation.evaluator INFO: Inference done 1089/1093. Dataloading: 0.0096 s/iter. Inference: 0.1372 s/iter. Eval: 0.1965 s/iter. Total: 0.3434 s/iter. ETA=0:00:01
[01/18 02:07:24] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:14.208163 (0.343941 s / iter per device, on 4 devices)
[01/18 02:07:24] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:29 (0.137246 s / iter per device, on 4 devices)
[01/18 02:58:33] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 02:58:34] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 02:58:34] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 02:58:35] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 02:58:47] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0075 s/iter. Inference: 0.1592 s/iter. Eval: 0.1970 s/iter. Total: 0.3636 s/iter. ETA=0:06:33
[01/18 02:58:53] detectron2.evaluation.evaluator INFO: Inference done 24/1093. Dataloading: 0.0104 s/iter. Inference: 0.1391 s/iter. Eval: 0.2313 s/iter. Total: 0.3809 s/iter. ETA=0:06:47
[01/18 02:58:58] detectron2.evaluation.evaluator INFO: Inference done 36/1093. Dataloading: 0.0111 s/iter. Inference: 0.1407 s/iter. Eval: 0.2485 s/iter. Total: 0.4005 s/iter. ETA=0:07:03
[01/18 02:59:03] detectron2.evaluation.evaluator INFO: Inference done 50/1093. Dataloading: 0.0113 s/iter. Inference: 0.1438 s/iter. Eval: 0.2389 s/iter. Total: 0.3940 s/iter. ETA=0:06:50
[01/18 02:59:08] detectron2.evaluation.evaluator INFO: Inference done 63/1093. Dataloading: 0.0112 s/iter. Inference: 0.1468 s/iter. Eval: 0.2342 s/iter. Total: 0.3923 s/iter. ETA=0:06:44
[01/18 02:59:13] detectron2.evaluation.evaluator INFO: Inference done 75/1093. Dataloading: 0.0113 s/iter. Inference: 0.1474 s/iter. Eval: 0.2389 s/iter. Total: 0.3977 s/iter. ETA=0:06:44
[01/18 02:59:18] detectron2.evaluation.evaluator INFO: Inference done 91/1093. Dataloading: 0.0111 s/iter. Inference: 0.1467 s/iter. Eval: 0.2266 s/iter. Total: 0.3844 s/iter. ETA=0:06:25
[01/18 02:59:24] detectron2.evaluation.evaluator INFO: Inference done 109/1093. Dataloading: 0.0103 s/iter. Inference: 0.1445 s/iter. Eval: 0.2136 s/iter. Total: 0.3685 s/iter. ETA=0:06:02
[01/18 02:59:29] detectron2.evaluation.evaluator INFO: Inference done 123/1093. Dataloading: 0.0104 s/iter. Inference: 0.1443 s/iter. Eval: 0.2138 s/iter. Total: 0.3686 s/iter. ETA=0:05:57
[01/18 02:59:34] detectron2.evaluation.evaluator INFO: Inference done 137/1093. Dataloading: 0.0105 s/iter. Inference: 0.1461 s/iter. Eval: 0.2134 s/iter. Total: 0.3701 s/iter. ETA=0:05:53
[01/18 02:59:39] detectron2.evaluation.evaluator INFO: Inference done 150/1093. Dataloading: 0.0106 s/iter. Inference: 0.1489 s/iter. Eval: 0.2141 s/iter. Total: 0.3737 s/iter. ETA=0:05:52
[01/18 02:59:45] detectron2.evaluation.evaluator INFO: Inference done 161/1093. Dataloading: 0.0107 s/iter. Inference: 0.1509 s/iter. Eval: 0.2185 s/iter. Total: 0.3802 s/iter. ETA=0:05:54
[01/18 02:59:50] detectron2.evaluation.evaluator INFO: Inference done 173/1093. Dataloading: 0.0108 s/iter. Inference: 0.1516 s/iter. Eval: 0.2205 s/iter. Total: 0.3830 s/iter. ETA=0:05:52
[01/18 02:59:55] detectron2.evaluation.evaluator INFO: Inference done 186/1093. Dataloading: 0.0108 s/iter. Inference: 0.1526 s/iter. Eval: 0.2210 s/iter. Total: 0.3845 s/iter. ETA=0:05:48
[01/18 03:00:00] detectron2.evaluation.evaluator INFO: Inference done 198/1093. Dataloading: 0.0109 s/iter. Inference: 0.1527 s/iter. Eval: 0.2238 s/iter. Total: 0.3874 s/iter. ETA=0:05:46
[01/18 03:00:05] detectron2.evaluation.evaluator INFO: Inference done 211/1093. Dataloading: 0.0112 s/iter. Inference: 0.1531 s/iter. Eval: 0.2242 s/iter. Total: 0.3885 s/iter. ETA=0:05:42
[01/18 03:00:10] detectron2.evaluation.evaluator INFO: Inference done 225/1093. Dataloading: 0.0111 s/iter. Inference: 0.1534 s/iter. Eval: 0.2221 s/iter. Total: 0.3867 s/iter. ETA=0:05:35
[01/18 03:00:15] detectron2.evaluation.evaluator INFO: Inference done 238/1093. Dataloading: 0.0111 s/iter. Inference: 0.1534 s/iter. Eval: 0.2222 s/iter. Total: 0.3867 s/iter. ETA=0:05:30
[01/18 03:00:21] detectron2.evaluation.evaluator INFO: Inference done 251/1093. Dataloading: 0.0112 s/iter. Inference: 0.1537 s/iter. Eval: 0.2240 s/iter. Total: 0.3889 s/iter. ETA=0:05:27
[01/18 03:00:26] detectron2.evaluation.evaluator INFO: Inference done 263/1093. Dataloading: 0.0113 s/iter. Inference: 0.1535 s/iter. Eval: 0.2256 s/iter. Total: 0.3905 s/iter. ETA=0:05:24
[01/18 03:00:31] detectron2.evaluation.evaluator INFO: Inference done 276/1093. Dataloading: 0.0112 s/iter. Inference: 0.1538 s/iter. Eval: 0.2255 s/iter. Total: 0.3906 s/iter. ETA=0:05:19
[01/18 03:00:36] detectron2.evaluation.evaluator INFO: Inference done 288/1093. Dataloading: 0.0113 s/iter. Inference: 0.1543 s/iter. Eval: 0.2263 s/iter. Total: 0.3920 s/iter. ETA=0:05:15
[01/18 03:00:41] detectron2.evaluation.evaluator INFO: Inference done 300/1093. Dataloading: 0.0114 s/iter. Inference: 0.1544 s/iter. Eval: 0.2274 s/iter. Total: 0.3932 s/iter. ETA=0:05:11
[01/18 03:00:46] detectron2.evaluation.evaluator INFO: Inference done 314/1093. Dataloading: 0.0113 s/iter. Inference: 0.1546 s/iter. Eval: 0.2257 s/iter. Total: 0.3917 s/iter. ETA=0:05:05
[01/18 03:00:52] detectron2.evaluation.evaluator INFO: Inference done 327/1093. Dataloading: 0.0112 s/iter. Inference: 0.1551 s/iter. Eval: 0.2261 s/iter. Total: 0.3925 s/iter. ETA=0:05:00
[01/18 03:00:57] detectron2.evaluation.evaluator INFO: Inference done 340/1093. Dataloading: 0.0112 s/iter. Inference: 0.1549 s/iter. Eval: 0.2264 s/iter. Total: 0.3926 s/iter. ETA=0:04:55
[01/18 03:01:02] detectron2.evaluation.evaluator INFO: Inference done 352/1093. Dataloading: 0.0112 s/iter. Inference: 0.1556 s/iter. Eval: 0.2281 s/iter. Total: 0.3950 s/iter. ETA=0:04:52
[01/18 03:01:08] detectron2.evaluation.evaluator INFO: Inference done 363/1093. Dataloading: 0.0114 s/iter. Inference: 0.1559 s/iter. Eval: 0.2300 s/iter. Total: 0.3975 s/iter. ETA=0:04:50
[01/18 03:01:13] detectron2.evaluation.evaluator INFO: Inference done 378/1093. Dataloading: 0.0114 s/iter. Inference: 0.1555 s/iter. Eval: 0.2288 s/iter. Total: 0.3959 s/iter. ETA=0:04:43
[01/18 03:01:18] detectron2.evaluation.evaluator INFO: Inference done 389/1093. Dataloading: 0.0115 s/iter. Inference: 0.1559 s/iter. Eval: 0.2311 s/iter. Total: 0.3986 s/iter. ETA=0:04:40
[01/18 03:01:24] detectron2.evaluation.evaluator INFO: Inference done 400/1093. Dataloading: 0.0115 s/iter. Inference: 0.1565 s/iter. Eval: 0.2324 s/iter. Total: 0.4005 s/iter. ETA=0:04:37
[01/18 03:01:29] detectron2.evaluation.evaluator INFO: Inference done 412/1093. Dataloading: 0.0116 s/iter. Inference: 0.1566 s/iter. Eval: 0.2335 s/iter. Total: 0.4018 s/iter. ETA=0:04:33
[01/18 03:01:34] detectron2.evaluation.evaluator INFO: Inference done 425/1093. Dataloading: 0.0116 s/iter. Inference: 0.1570 s/iter. Eval: 0.2334 s/iter. Total: 0.4020 s/iter. ETA=0:04:28
[01/18 03:01:39] detectron2.evaluation.evaluator INFO: Inference done 436/1093. Dataloading: 0.0117 s/iter. Inference: 0.1575 s/iter. Eval: 0.2342 s/iter. Total: 0.4034 s/iter. ETA=0:04:25
[01/18 03:01:44] detectron2.evaluation.evaluator INFO: Inference done 451/1093. Dataloading: 0.0116 s/iter. Inference: 0.1571 s/iter. Eval: 0.2328 s/iter. Total: 0.4016 s/iter. ETA=0:04:17
[01/18 03:01:50] detectron2.evaluation.evaluator INFO: Inference done 464/1093. Dataloading: 0.0116 s/iter. Inference: 0.1572 s/iter. Eval: 0.2325 s/iter. Total: 0.4013 s/iter. ETA=0:04:12
[01/18 03:01:55] detectron2.evaluation.evaluator INFO: Inference done 476/1093. Dataloading: 0.0116 s/iter. Inference: 0.1572 s/iter. Eval: 0.2330 s/iter. Total: 0.4020 s/iter. ETA=0:04:08
[01/18 03:02:00] detectron2.evaluation.evaluator INFO: Inference done 489/1093. Dataloading: 0.0115 s/iter. Inference: 0.1575 s/iter. Eval: 0.2332 s/iter. Total: 0.4024 s/iter. ETA=0:04:03
[01/18 03:02:05] detectron2.evaluation.evaluator INFO: Inference done 500/1093. Dataloading: 0.0116 s/iter. Inference: 0.1574 s/iter. Eval: 0.2346 s/iter. Total: 0.4036 s/iter. ETA=0:03:59
[01/18 03:02:10] detectron2.evaluation.evaluator INFO: Inference done 512/1093. Dataloading: 0.0116 s/iter. Inference: 0.1576 s/iter. Eval: 0.2353 s/iter. Total: 0.4047 s/iter. ETA=0:03:55
[01/18 03:02:16] detectron2.evaluation.evaluator INFO: Inference done 523/1093. Dataloading: 0.0116 s/iter. Inference: 0.1575 s/iter. Eval: 0.2367 s/iter. Total: 0.4060 s/iter. ETA=0:03:51
[01/18 03:02:21] detectron2.evaluation.evaluator INFO: Inference done 536/1093. Dataloading: 0.0116 s/iter. Inference: 0.1574 s/iter. Eval: 0.2365 s/iter. Total: 0.4056 s/iter. ETA=0:03:45
[01/18 03:02:26] detectron2.evaluation.evaluator INFO: Inference done 549/1093. Dataloading: 0.0116 s/iter. Inference: 0.1573 s/iter. Eval: 0.2362 s/iter. Total: 0.4052 s/iter. ETA=0:03:40
[01/18 03:02:31] detectron2.evaluation.evaluator INFO: Inference done 562/1093. Dataloading: 0.0116 s/iter. Inference: 0.1574 s/iter. Eval: 0.2360 s/iter. Total: 0.4051 s/iter. ETA=0:03:35
[01/18 03:02:36] detectron2.evaluation.evaluator INFO: Inference done 573/1093. Dataloading: 0.0117 s/iter. Inference: 0.1577 s/iter. Eval: 0.2367 s/iter. Total: 0.4062 s/iter. ETA=0:03:31
[01/18 03:02:41] detectron2.evaluation.evaluator INFO: Inference done 585/1093. Dataloading: 0.0117 s/iter. Inference: 0.1577 s/iter. Eval: 0.2371 s/iter. Total: 0.4066 s/iter. ETA=0:03:26
[01/18 03:02:46] detectron2.evaluation.evaluator INFO: Inference done 595/1093. Dataloading: 0.0118 s/iter. Inference: 0.1584 s/iter. Eval: 0.2382 s/iter. Total: 0.4085 s/iter. ETA=0:03:23
[01/18 03:02:51] detectron2.evaluation.evaluator INFO: Inference done 603/1093. Dataloading: 0.0119 s/iter. Inference: 0.1606 s/iter. Eval: 0.2391 s/iter. Total: 0.4117 s/iter. ETA=0:03:21
[01/18 03:02:57] detectron2.evaluation.evaluator INFO: Inference done 612/1093. Dataloading: 0.0121 s/iter. Inference: 0.1616 s/iter. Eval: 0.2407 s/iter. Total: 0.4145 s/iter. ETA=0:03:19
[01/18 03:03:02] detectron2.evaluation.evaluator INFO: Inference done 621/1093. Dataloading: 0.0122 s/iter. Inference: 0.1632 s/iter. Eval: 0.2413 s/iter. Total: 0.4169 s/iter. ETA=0:03:16
[01/18 03:03:08] detectron2.evaluation.evaluator INFO: Inference done 630/1093. Dataloading: 0.0124 s/iter. Inference: 0.1643 s/iter. Eval: 0.2427 s/iter. Total: 0.4195 s/iter. ETA=0:03:14
[01/18 03:03:13] detectron2.evaluation.evaluator INFO: Inference done 638/1093. Dataloading: 0.0124 s/iter. Inference: 0.1661 s/iter. Eval: 0.2439 s/iter. Total: 0.4225 s/iter. ETA=0:03:12
[01/18 03:03:18] detectron2.evaluation.evaluator INFO: Inference done 649/1093. Dataloading: 0.0125 s/iter. Inference: 0.1666 s/iter. Eval: 0.2441 s/iter. Total: 0.4234 s/iter. ETA=0:03:07
[01/18 03:03:23] detectron2.evaluation.evaluator INFO: Inference done 664/1093. Dataloading: 0.0124 s/iter. Inference: 0.1659 s/iter. Eval: 0.2429 s/iter. Total: 0.4214 s/iter. ETA=0:03:00
[01/18 03:03:28] detectron2.evaluation.evaluator INFO: Inference done 681/1093. Dataloading: 0.0123 s/iter. Inference: 0.1649 s/iter. Eval: 0.2410 s/iter. Total: 0.4183 s/iter. ETA=0:02:52
[01/18 03:03:33] detectron2.evaluation.evaluator INFO: Inference done 697/1093. Dataloading: 0.0122 s/iter. Inference: 0.1641 s/iter. Eval: 0.2398 s/iter. Total: 0.4162 s/iter. ETA=0:02:44
[01/18 03:03:39] detectron2.evaluation.evaluator INFO: Inference done 715/1093. Dataloading: 0.0121 s/iter. Inference: 0.1632 s/iter. Eval: 0.2376 s/iter. Total: 0.4130 s/iter. ETA=0:02:36
[01/18 03:03:44] detectron2.evaluation.evaluator INFO: Inference done 727/1093. Dataloading: 0.0122 s/iter. Inference: 0.1632 s/iter. Eval: 0.2377 s/iter. Total: 0.4132 s/iter. ETA=0:02:31
[01/18 03:03:49] detectron2.evaluation.evaluator INFO: Inference done 742/1093. Dataloading: 0.0121 s/iter. Inference: 0.1629 s/iter. Eval: 0.2366 s/iter. Total: 0.4117 s/iter. ETA=0:02:24
[01/18 03:03:54] detectron2.evaluation.evaluator INFO: Inference done 757/1093. Dataloading: 0.0120 s/iter. Inference: 0.1624 s/iter. Eval: 0.2359 s/iter. Total: 0.4105 s/iter. ETA=0:02:17
[01/18 03:03:59] detectron2.evaluation.evaluator INFO: Inference done 770/1093. Dataloading: 0.0120 s/iter. Inference: 0.1623 s/iter. Eval: 0.2358 s/iter. Total: 0.4102 s/iter. ETA=0:02:12
[01/18 03:04:04] detectron2.evaluation.evaluator INFO: Inference done 785/1093. Dataloading: 0.0120 s/iter. Inference: 0.1619 s/iter. Eval: 0.2350 s/iter. Total: 0.4090 s/iter. ETA=0:02:05
[01/18 03:04:09] detectron2.evaluation.evaluator INFO: Inference done 800/1093. Dataloading: 0.0119 s/iter. Inference: 0.1615 s/iter. Eval: 0.2341 s/iter. Total: 0.4077 s/iter. ETA=0:01:59
[01/18 03:04:15] detectron2.evaluation.evaluator INFO: Inference done 814/1093. Dataloading: 0.0119 s/iter. Inference: 0.1612 s/iter. Eval: 0.2339 s/iter. Total: 0.4071 s/iter. ETA=0:01:53
[01/18 03:04:20] detectron2.evaluation.evaluator INFO: Inference done 828/1093. Dataloading: 0.0119 s/iter. Inference: 0.1611 s/iter. Eval: 0.2336 s/iter. Total: 0.4067 s/iter. ETA=0:01:47
[01/18 03:04:25] detectron2.evaluation.evaluator INFO: Inference done 845/1093. Dataloading: 0.0118 s/iter. Inference: 0.1606 s/iter. Eval: 0.2321 s/iter. Total: 0.4047 s/iter. ETA=0:01:40
[01/18 03:04:30] detectron2.evaluation.evaluator INFO: Inference done 859/1093. Dataloading: 0.0118 s/iter. Inference: 0.1603 s/iter. Eval: 0.2318 s/iter. Total: 0.4041 s/iter. ETA=0:01:34
[01/18 03:04:36] detectron2.evaluation.evaluator INFO: Inference done 872/1093. Dataloading: 0.0118 s/iter. Inference: 0.1602 s/iter. Eval: 0.2318 s/iter. Total: 0.4040 s/iter. ETA=0:01:29
[01/18 03:04:41] detectron2.evaluation.evaluator INFO: Inference done 885/1093. Dataloading: 0.0118 s/iter. Inference: 0.1601 s/iter. Eval: 0.2320 s/iter. Total: 0.4041 s/iter. ETA=0:01:24
[01/18 03:04:46] detectron2.evaluation.evaluator INFO: Inference done 899/1093. Dataloading: 0.0118 s/iter. Inference: 0.1599 s/iter. Eval: 0.2317 s/iter. Total: 0.4036 s/iter. ETA=0:01:18
[01/18 03:04:51] detectron2.evaluation.evaluator INFO: Inference done 911/1093. Dataloading: 0.0118 s/iter. Inference: 0.1598 s/iter. Eval: 0.2321 s/iter. Total: 0.4039 s/iter. ETA=0:01:13
[01/18 03:04:57] detectron2.evaluation.evaluator INFO: Inference done 924/1093. Dataloading: 0.0118 s/iter. Inference: 0.1597 s/iter. Eval: 0.2324 s/iter. Total: 0.4041 s/iter. ETA=0:01:08
[01/18 03:05:02] detectron2.evaluation.evaluator INFO: Inference done 936/1093. Dataloading: 0.0118 s/iter. Inference: 0.1596 s/iter. Eval: 0.2328 s/iter. Total: 0.4044 s/iter. ETA=0:01:03
[01/18 03:05:07] detectron2.evaluation.evaluator INFO: Inference done 949/1093. Dataloading: 0.0118 s/iter. Inference: 0.1595 s/iter. Eval: 0.2329 s/iter. Total: 0.4044 s/iter. ETA=0:00:58
[01/18 03:05:12] detectron2.evaluation.evaluator INFO: Inference done 965/1093. Dataloading: 0.0118 s/iter. Inference: 0.1591 s/iter. Eval: 0.2320 s/iter. Total: 0.4030 s/iter. ETA=0:00:51
[01/18 03:05:17] detectron2.evaluation.evaluator INFO: Inference done 981/1093. Dataloading: 0.0117 s/iter. Inference: 0.1589 s/iter. Eval: 0.2309 s/iter. Total: 0.4017 s/iter. ETA=0:00:44
[01/18 03:05:23] detectron2.evaluation.evaluator INFO: Inference done 995/1093. Dataloading: 0.0117 s/iter. Inference: 0.1587 s/iter. Eval: 0.2307 s/iter. Total: 0.4012 s/iter. ETA=0:00:39
[01/18 03:05:28] detectron2.evaluation.evaluator INFO: Inference done 1010/1093. Dataloading: 0.0117 s/iter. Inference: 0.1584 s/iter. Eval: 0.2303 s/iter. Total: 0.4006 s/iter. ETA=0:00:33
[01/18 03:05:33] detectron2.evaluation.evaluator INFO: Inference done 1026/1093. Dataloading: 0.0116 s/iter. Inference: 0.1581 s/iter. Eval: 0.2296 s/iter. Total: 0.3994 s/iter. ETA=0:00:26
[01/18 03:05:38] detectron2.evaluation.evaluator INFO: Inference done 1043/1093. Dataloading: 0.0116 s/iter. Inference: 0.1577 s/iter. Eval: 0.2285 s/iter. Total: 0.3979 s/iter. ETA=0:00:19
[01/18 03:05:43] detectron2.evaluation.evaluator INFO: Inference done 1057/1093. Dataloading: 0.0115 s/iter. Inference: 0.1575 s/iter. Eval: 0.2283 s/iter. Total: 0.3975 s/iter. ETA=0:00:14
[01/18 03:05:48] detectron2.evaluation.evaluator INFO: Inference done 1071/1093. Dataloading: 0.0115 s/iter. Inference: 0.1573 s/iter. Eval: 0.2280 s/iter. Total: 0.3970 s/iter. ETA=0:00:08
[01/18 03:05:54] detectron2.evaluation.evaluator INFO: Inference done 1086/1093. Dataloading: 0.0115 s/iter. Inference: 0.1572 s/iter. Eval: 0.2275 s/iter. Total: 0.3963 s/iter. ETA=0:00:02
[01/18 03:05:56] detectron2.evaluation.evaluator INFO: Total inference time: 0:07:11.031404 (0.396169 s / iter per device, on 4 devices)
[01/18 03:05:56] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:50 (0.157048 s / iter per device, on 4 devices)
[01/18 03:56:21] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 03:56:22] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 03:56:22] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 03:56:22] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 03:56:37] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0097 s/iter. Inference: 0.1575 s/iter. Eval: 0.2177 s/iter. Total: 0.3849 s/iter. ETA=0:06:56
[01/18 03:56:42] detectron2.evaluation.evaluator INFO: Inference done 24/1093. Dataloading: 0.0125 s/iter. Inference: 0.1476 s/iter. Eval: 0.2359 s/iter. Total: 0.3961 s/iter. ETA=0:07:03
[01/18 03:56:47] detectron2.evaluation.evaluator INFO: Inference done 36/1093. Dataloading: 0.0140 s/iter. Inference: 0.1469 s/iter. Eval: 0.2539 s/iter. Total: 0.4150 s/iter. ETA=0:07:18
[01/18 03:56:52] detectron2.evaluation.evaluator INFO: Inference done 49/1093. Dataloading: 0.0138 s/iter. Inference: 0.1488 s/iter. Eval: 0.2442 s/iter. Total: 0.4069 s/iter. ETA=0:07:04
[01/18 03:56:57] detectron2.evaluation.evaluator INFO: Inference done 62/1093. Dataloading: 0.0134 s/iter. Inference: 0.1485 s/iter. Eval: 0.2410 s/iter. Total: 0.4029 s/iter. ETA=0:06:55
[01/18 03:57:03] detectron2.evaluation.evaluator INFO: Inference done 74/1093. Dataloading: 0.0137 s/iter. Inference: 0.1479 s/iter. Eval: 0.2455 s/iter. Total: 0.4072 s/iter. ETA=0:06:54
[01/18 03:57:08] detectron2.evaluation.evaluator INFO: Inference done 89/1093. Dataloading: 0.0136 s/iter. Inference: 0.1474 s/iter. Eval: 0.2358 s/iter. Total: 0.3969 s/iter. ETA=0:06:38
[01/18 03:57:13] detectron2.evaluation.evaluator INFO: Inference done 103/1093. Dataloading: 0.0133 s/iter. Inference: 0.1474 s/iter. Eval: 0.2310 s/iter. Total: 0.3918 s/iter. ETA=0:06:27
[01/18 03:57:18] detectron2.evaluation.evaluator INFO: Inference done 118/1093. Dataloading: 0.0130 s/iter. Inference: 0.1475 s/iter. Eval: 0.2266 s/iter. Total: 0.3872 s/iter. ETA=0:06:17
[01/18 03:57:23] detectron2.evaluation.evaluator INFO: Inference done 130/1093. Dataloading: 0.0130 s/iter. Inference: 0.1482 s/iter. Eval: 0.2291 s/iter. Total: 0.3903 s/iter. ETA=0:06:15
[01/18 03:57:28] detectron2.evaluation.evaluator INFO: Inference done 146/1093. Dataloading: 0.0126 s/iter. Inference: 0.1469 s/iter. Eval: 0.2226 s/iter. Total: 0.3823 s/iter. ETA=0:06:02
[01/18 03:57:34] detectron2.evaluation.evaluator INFO: Inference done 160/1093. Dataloading: 0.0127 s/iter. Inference: 0.1476 s/iter. Eval: 0.2230 s/iter. Total: 0.3834 s/iter. ETA=0:05:57
[01/18 03:57:39] detectron2.evaluation.evaluator INFO: Inference done 175/1093. Dataloading: 0.0126 s/iter. Inference: 0.1469 s/iter. Eval: 0.2219 s/iter. Total: 0.3816 s/iter. ETA=0:05:50
[01/18 03:57:44] detectron2.evaluation.evaluator INFO: Inference done 189/1093. Dataloading: 0.0125 s/iter. Inference: 0.1467 s/iter. Eval: 0.2210 s/iter. Total: 0.3803 s/iter. ETA=0:05:43
[01/18 03:57:50] detectron2.evaluation.evaluator INFO: Inference done 201/1093. Dataloading: 0.0126 s/iter. Inference: 0.1469 s/iter. Eval: 0.2235 s/iter. Total: 0.3831 s/iter. ETA=0:05:41
[01/18 03:57:55] detectron2.evaluation.evaluator INFO: Inference done 215/1093. Dataloading: 0.0126 s/iter. Inference: 0.1468 s/iter. Eval: 0.2227 s/iter. Total: 0.3822 s/iter. ETA=0:05:35
[01/18 03:58:00] detectron2.evaluation.evaluator INFO: Inference done 230/1093. Dataloading: 0.0124 s/iter. Inference: 0.1469 s/iter. Eval: 0.2207 s/iter. Total: 0.3801 s/iter. ETA=0:05:28
[01/18 03:58:05] detectron2.evaluation.evaluator INFO: Inference done 244/1093. Dataloading: 0.0125 s/iter. Inference: 0.1469 s/iter. Eval: 0.2206 s/iter. Total: 0.3802 s/iter. ETA=0:05:22
[01/18 03:58:10] detectron2.evaluation.evaluator INFO: Inference done 256/1093. Dataloading: 0.0126 s/iter. Inference: 0.1474 s/iter. Eval: 0.2222 s/iter. Total: 0.3823 s/iter. ETA=0:05:20
[01/18 03:58:16] detectron2.evaluation.evaluator INFO: Inference done 271/1093. Dataloading: 0.0125 s/iter. Inference: 0.1470 s/iter. Eval: 0.2203 s/iter. Total: 0.3799 s/iter. ETA=0:05:12
[01/18 03:58:21] detectron2.evaluation.evaluator INFO: Inference done 287/1093. Dataloading: 0.0124 s/iter. Inference: 0.1468 s/iter. Eval: 0.2186 s/iter. Total: 0.3778 s/iter. ETA=0:05:04
[01/18 03:58:26] detectron2.evaluation.evaluator INFO: Inference done 301/1093. Dataloading: 0.0125 s/iter. Inference: 0.1465 s/iter. Eval: 0.2182 s/iter. Total: 0.3773 s/iter. ETA=0:04:58
[01/18 03:58:31] detectron2.evaluation.evaluator INFO: Inference done 317/1093. Dataloading: 0.0124 s/iter. Inference: 0.1464 s/iter. Eval: 0.2158 s/iter. Total: 0.3747 s/iter. ETA=0:04:50
[01/18 03:58:37] detectron2.evaluation.evaluator INFO: Inference done 332/1093. Dataloading: 0.0124 s/iter. Inference: 0.1464 s/iter. Eval: 0.2145 s/iter. Total: 0.3733 s/iter. ETA=0:04:44
[01/18 03:58:42] detectron2.evaluation.evaluator INFO: Inference done 345/1093. Dataloading: 0.0123 s/iter. Inference: 0.1464 s/iter. Eval: 0.2152 s/iter. Total: 0.3741 s/iter. ETA=0:04:39
[01/18 03:58:47] detectron2.evaluation.evaluator INFO: Inference done 358/1093. Dataloading: 0.0124 s/iter. Inference: 0.1466 s/iter. Eval: 0.2166 s/iter. Total: 0.3756 s/iter. ETA=0:04:36
[01/18 03:58:52] detectron2.evaluation.evaluator INFO: Inference done 373/1093. Dataloading: 0.0123 s/iter. Inference: 0.1464 s/iter. Eval: 0.2158 s/iter. Total: 0.3747 s/iter. ETA=0:04:29
[01/18 03:58:58] detectron2.evaluation.evaluator INFO: Inference done 386/1093. Dataloading: 0.0124 s/iter. Inference: 0.1463 s/iter. Eval: 0.2171 s/iter. Total: 0.3759 s/iter. ETA=0:04:25
[01/18 03:59:03] detectron2.evaluation.evaluator INFO: Inference done 400/1093. Dataloading: 0.0123 s/iter. Inference: 0.1463 s/iter. Eval: 0.2172 s/iter. Total: 0.3759 s/iter. ETA=0:04:20
[01/18 03:59:08] detectron2.evaluation.evaluator INFO: Inference done 412/1093. Dataloading: 0.0124 s/iter. Inference: 0.1463 s/iter. Eval: 0.2186 s/iter. Total: 0.3774 s/iter. ETA=0:04:16
[01/18 03:59:13] detectron2.evaluation.evaluator INFO: Inference done 427/1093. Dataloading: 0.0124 s/iter. Inference: 0.1459 s/iter. Eval: 0.2179 s/iter. Total: 0.3762 s/iter. ETA=0:04:10
[01/18 03:59:18] detectron2.evaluation.evaluator INFO: Inference done 442/1093. Dataloading: 0.0123 s/iter. Inference: 0.1456 s/iter. Eval: 0.2169 s/iter. Total: 0.3749 s/iter. ETA=0:04:04
[01/18 03:59:23] detectron2.evaluation.evaluator INFO: Inference done 456/1093. Dataloading: 0.0123 s/iter. Inference: 0.1459 s/iter. Eval: 0.2164 s/iter. Total: 0.3746 s/iter. ETA=0:03:58
[01/18 03:59:29] detectron2.evaluation.evaluator INFO: Inference done 470/1093. Dataloading: 0.0122 s/iter. Inference: 0.1460 s/iter. Eval: 0.2162 s/iter. Total: 0.3745 s/iter. ETA=0:03:53
[01/18 03:59:34] detectron2.evaluation.evaluator INFO: Inference done 484/1093. Dataloading: 0.0122 s/iter. Inference: 0.1462 s/iter. Eval: 0.2159 s/iter. Total: 0.3744 s/iter. ETA=0:03:48
[01/18 03:59:39] detectron2.evaluation.evaluator INFO: Inference done 497/1093. Dataloading: 0.0122 s/iter. Inference: 0.1462 s/iter. Eval: 0.2162 s/iter. Total: 0.3747 s/iter. ETA=0:03:43
[01/18 03:59:44] detectron2.evaluation.evaluator INFO: Inference done 511/1093. Dataloading: 0.0122 s/iter. Inference: 0.1461 s/iter. Eval: 0.2163 s/iter. Total: 0.3746 s/iter. ETA=0:03:38
[01/18 03:59:49] detectron2.evaluation.evaluator INFO: Inference done 524/1093. Dataloading: 0.0122 s/iter. Inference: 0.1460 s/iter. Eval: 0.2172 s/iter. Total: 0.3755 s/iter. ETA=0:03:33
[01/18 03:59:54] detectron2.evaluation.evaluator INFO: Inference done 538/1093. Dataloading: 0.0122 s/iter. Inference: 0.1460 s/iter. Eval: 0.2168 s/iter. Total: 0.3751 s/iter. ETA=0:03:28
[01/18 04:00:00] detectron2.evaluation.evaluator INFO: Inference done 553/1093. Dataloading: 0.0121 s/iter. Inference: 0.1458 s/iter. Eval: 0.2161 s/iter. Total: 0.3741 s/iter. ETA=0:03:22
[01/18 04:00:05] detectron2.evaluation.evaluator INFO: Inference done 567/1093. Dataloading: 0.0121 s/iter. Inference: 0.1456 s/iter. Eval: 0.2161 s/iter. Total: 0.3739 s/iter. ETA=0:03:16
[01/18 04:00:10] detectron2.evaluation.evaluator INFO: Inference done 579/1093. Dataloading: 0.0121 s/iter. Inference: 0.1456 s/iter. Eval: 0.2172 s/iter. Total: 0.3751 s/iter. ETA=0:03:12
[01/18 04:00:15] detectron2.evaluation.evaluator INFO: Inference done 592/1093. Dataloading: 0.0121 s/iter. Inference: 0.1456 s/iter. Eval: 0.2175 s/iter. Total: 0.3753 s/iter. ETA=0:03:08
[01/18 04:00:20] detectron2.evaluation.evaluator INFO: Inference done 607/1093. Dataloading: 0.0121 s/iter. Inference: 0.1454 s/iter. Eval: 0.2173 s/iter. Total: 0.3749 s/iter. ETA=0:03:02
[01/18 04:00:26] detectron2.evaluation.evaluator INFO: Inference done 621/1093. Dataloading: 0.0121 s/iter. Inference: 0.1455 s/iter. Eval: 0.2174 s/iter. Total: 0.3752 s/iter. ETA=0:02:57
[01/18 04:00:31] detectron2.evaluation.evaluator INFO: Inference done 634/1093. Dataloading: 0.0122 s/iter. Inference: 0.1456 s/iter. Eval: 0.2178 s/iter. Total: 0.3756 s/iter. ETA=0:02:52
[01/18 04:00:36] detectron2.evaluation.evaluator INFO: Inference done 647/1093. Dataloading: 0.0122 s/iter. Inference: 0.1455 s/iter. Eval: 0.2180 s/iter. Total: 0.3759 s/iter. ETA=0:02:47
[01/18 04:00:41] detectron2.evaluation.evaluator INFO: Inference done 661/1093. Dataloading: 0.0122 s/iter. Inference: 0.1455 s/iter. Eval: 0.2182 s/iter. Total: 0.3760 s/iter. ETA=0:02:42
[01/18 04:00:46] detectron2.evaluation.evaluator INFO: Inference done 673/1093. Dataloading: 0.0122 s/iter. Inference: 0.1458 s/iter. Eval: 0.2187 s/iter. Total: 0.3768 s/iter. ETA=0:02:38
[01/18 04:00:51] detectron2.evaluation.evaluator INFO: Inference done 687/1093. Dataloading: 0.0122 s/iter. Inference: 0.1457 s/iter. Eval: 0.2189 s/iter. Total: 0.3768 s/iter. ETA=0:02:32
[01/18 04:00:57] detectron2.evaluation.evaluator INFO: Inference done 700/1093. Dataloading: 0.0122 s/iter. Inference: 0.1457 s/iter. Eval: 0.2192 s/iter. Total: 0.3772 s/iter. ETA=0:02:28
[01/18 04:01:02] detectron2.evaluation.evaluator INFO: Inference done 715/1093. Dataloading: 0.0122 s/iter. Inference: 0.1458 s/iter. Eval: 0.2186 s/iter. Total: 0.3766 s/iter. ETA=0:02:22
[01/18 04:01:07] detectron2.evaluation.evaluator INFO: Inference done 729/1093. Dataloading: 0.0121 s/iter. Inference: 0.1458 s/iter. Eval: 0.2184 s/iter. Total: 0.3764 s/iter. ETA=0:02:17
[01/18 04:01:12] detectron2.evaluation.evaluator INFO: Inference done 745/1093. Dataloading: 0.0121 s/iter. Inference: 0.1458 s/iter. Eval: 0.2174 s/iter. Total: 0.3753 s/iter. ETA=0:02:10
[01/18 04:01:17] detectron2.evaluation.evaluator INFO: Inference done 758/1093. Dataloading: 0.0121 s/iter. Inference: 0.1458 s/iter. Eval: 0.2175 s/iter. Total: 0.3755 s/iter. ETA=0:02:05
[01/18 04:01:22] detectron2.evaluation.evaluator INFO: Inference done 772/1093. Dataloading: 0.0121 s/iter. Inference: 0.1458 s/iter. Eval: 0.2174 s/iter. Total: 0.3754 s/iter. ETA=0:02:00
[01/18 04:01:28] detectron2.evaluation.evaluator INFO: Inference done 786/1093. Dataloading: 0.0121 s/iter. Inference: 0.1458 s/iter. Eval: 0.2174 s/iter. Total: 0.3753 s/iter. ETA=0:01:55
[01/18 04:01:33] detectron2.evaluation.evaluator INFO: Inference done 801/1093. Dataloading: 0.0121 s/iter. Inference: 0.1456 s/iter. Eval: 0.2170 s/iter. Total: 0.3748 s/iter. ETA=0:01:49
[01/18 04:01:38] detectron2.evaluation.evaluator INFO: Inference done 815/1093. Dataloading: 0.0121 s/iter. Inference: 0.1457 s/iter. Eval: 0.2171 s/iter. Total: 0.3750 s/iter. ETA=0:01:44
[01/18 04:01:43] detectron2.evaluation.evaluator INFO: Inference done 828/1093. Dataloading: 0.0121 s/iter. Inference: 0.1458 s/iter. Eval: 0.2173 s/iter. Total: 0.3752 s/iter. ETA=0:01:39
[01/18 04:01:49] detectron2.evaluation.evaluator INFO: Inference done 843/1093. Dataloading: 0.0121 s/iter. Inference: 0.1459 s/iter. Eval: 0.2167 s/iter. Total: 0.3748 s/iter. ETA=0:01:33
[01/18 04:01:54] detectron2.evaluation.evaluator INFO: Inference done 859/1093. Dataloading: 0.0121 s/iter. Inference: 0.1456 s/iter. Eval: 0.2161 s/iter. Total: 0.3739 s/iter. ETA=0:01:27
[01/18 04:01:59] detectron2.evaluation.evaluator INFO: Inference done 874/1093. Dataloading: 0.0121 s/iter. Inference: 0.1453 s/iter. Eval: 0.2158 s/iter. Total: 0.3733 s/iter. ETA=0:01:21
[01/18 04:02:04] detectron2.evaluation.evaluator INFO: Inference done 886/1093. Dataloading: 0.0121 s/iter. Inference: 0.1454 s/iter. Eval: 0.2165 s/iter. Total: 0.3740 s/iter. ETA=0:01:17
[01/18 04:02:09] detectron2.evaluation.evaluator INFO: Inference done 901/1093. Dataloading: 0.0121 s/iter. Inference: 0.1452 s/iter. Eval: 0.2161 s/iter. Total: 0.3735 s/iter. ETA=0:01:11
[01/18 04:02:14] detectron2.evaluation.evaluator INFO: Inference done 915/1093. Dataloading: 0.0121 s/iter. Inference: 0.1451 s/iter. Eval: 0.2160 s/iter. Total: 0.3733 s/iter. ETA=0:01:06
[01/18 04:02:19] detectron2.evaluation.evaluator INFO: Inference done 928/1093. Dataloading: 0.0121 s/iter. Inference: 0.1452 s/iter. Eval: 0.2162 s/iter. Total: 0.3735 s/iter. ETA=0:01:01
[01/18 04:02:25] detectron2.evaluation.evaluator INFO: Inference done 943/1093. Dataloading: 0.0120 s/iter. Inference: 0.1450 s/iter. Eval: 0.2161 s/iter. Total: 0.3732 s/iter. ETA=0:00:55
[01/18 04:02:30] detectron2.evaluation.evaluator INFO: Inference done 957/1093. Dataloading: 0.0120 s/iter. Inference: 0.1449 s/iter. Eval: 0.2161 s/iter. Total: 0.3732 s/iter. ETA=0:00:50
[01/18 04:02:35] detectron2.evaluation.evaluator INFO: Inference done 972/1093. Dataloading: 0.0120 s/iter. Inference: 0.1449 s/iter. Eval: 0.2156 s/iter. Total: 0.3726 s/iter. ETA=0:00:45
[01/18 04:02:40] detectron2.evaluation.evaluator INFO: Inference done 987/1093. Dataloading: 0.0120 s/iter. Inference: 0.1448 s/iter. Eval: 0.2152 s/iter. Total: 0.3721 s/iter. ETA=0:00:39
[01/18 04:02:45] detectron2.evaluation.evaluator INFO: Inference done 1001/1093. Dataloading: 0.0120 s/iter. Inference: 0.1449 s/iter. Eval: 0.2149 s/iter. Total: 0.3719 s/iter. ETA=0:00:34
[01/18 04:02:50] detectron2.evaluation.evaluator INFO: Inference done 1016/1093. Dataloading: 0.0119 s/iter. Inference: 0.1449 s/iter. Eval: 0.2146 s/iter. Total: 0.3716 s/iter. ETA=0:00:28
[01/18 04:02:55] detectron2.evaluation.evaluator INFO: Inference done 1033/1093. Dataloading: 0.0119 s/iter. Inference: 0.1448 s/iter. Eval: 0.2137 s/iter. Total: 0.3705 s/iter. ETA=0:00:22
[01/18 04:03:01] detectron2.evaluation.evaluator INFO: Inference done 1048/1093. Dataloading: 0.0119 s/iter. Inference: 0.1448 s/iter. Eval: 0.2134 s/iter. Total: 0.3701 s/iter. ETA=0:00:16
[01/18 04:03:06] detectron2.evaluation.evaluator INFO: Inference done 1062/1093. Dataloading: 0.0119 s/iter. Inference: 0.1448 s/iter. Eval: 0.2135 s/iter. Total: 0.3703 s/iter. ETA=0:00:11
[01/18 04:03:11] detectron2.evaluation.evaluator INFO: Inference done 1077/1093. Dataloading: 0.0119 s/iter. Inference: 0.1448 s/iter. Eval: 0.2133 s/iter. Total: 0.3701 s/iter. ETA=0:00:05
[01/18 04:03:17] detectron2.evaluation.evaluator INFO: Inference done 1092/1093. Dataloading: 0.0118 s/iter. Inference: 0.1448 s/iter. Eval: 0.2131 s/iter. Total: 0.3698 s/iter. ETA=0:00:00
[01/18 04:03:17] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:42.905083 (0.370317 s / iter per device, on 4 devices)
[01/18 04:03:17] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:37 (0.144839 s / iter per device, on 4 devices)
[01/18 04:52:34] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 04:52:34] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 04:52:34] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 04:52:35] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 04:52:49] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0083 s/iter. Inference: 0.1425 s/iter. Eval: 0.2462 s/iter. Total: 0.3970 s/iter. ETA=0:07:09
[01/18 04:52:54] detectron2.evaluation.evaluator INFO: Inference done 23/1093. Dataloading: 0.0125 s/iter. Inference: 0.1431 s/iter. Eval: 0.2614 s/iter. Total: 0.4171 s/iter. ETA=0:07:26
[01/18 04:52:59] detectron2.evaluation.evaluator INFO: Inference done 36/1093. Dataloading: 0.0128 s/iter. Inference: 0.1412 s/iter. Eval: 0.2566 s/iter. Total: 0.4106 s/iter. ETA=0:07:14
[01/18 04:53:05] detectron2.evaluation.evaluator INFO: Inference done 52/1093. Dataloading: 0.0121 s/iter. Inference: 0.1383 s/iter. Eval: 0.2338 s/iter. Total: 0.3843 s/iter. ETA=0:06:40
[01/18 04:53:10] detectron2.evaluation.evaluator INFO: Inference done 67/1093. Dataloading: 0.0117 s/iter. Inference: 0.1380 s/iter. Eval: 0.2227 s/iter. Total: 0.3725 s/iter. ETA=0:06:22
[01/18 04:53:15] detectron2.evaluation.evaluator INFO: Inference done 78/1093. Dataloading: 0.0124 s/iter. Inference: 0.1395 s/iter. Eval: 0.2341 s/iter. Total: 0.3861 s/iter. ETA=0:06:31
[01/18 04:53:20] detectron2.evaluation.evaluator INFO: Inference done 95/1093. Dataloading: 0.0118 s/iter. Inference: 0.1394 s/iter. Eval: 0.2205 s/iter. Total: 0.3717 s/iter. ETA=0:06:10
[01/18 04:53:25] detectron2.evaluation.evaluator INFO: Inference done 112/1093. Dataloading: 0.0114 s/iter. Inference: 0.1383 s/iter. Eval: 0.2112 s/iter. Total: 0.3610 s/iter. ETA=0:05:54
[01/18 04:53:30] detectron2.evaluation.evaluator INFO: Inference done 127/1093. Dataloading: 0.0112 s/iter. Inference: 0.1384 s/iter. Eval: 0.2080 s/iter. Total: 0.3577 s/iter. ETA=0:05:45
[01/18 04:53:35] detectron2.evaluation.evaluator INFO: Inference done 142/1093. Dataloading: 0.0112 s/iter. Inference: 0.1390 s/iter. Eval: 0.2051 s/iter. Total: 0.3553 s/iter. ETA=0:05:37
[01/18 04:53:40] detectron2.evaluation.evaluator INFO: Inference done 158/1093. Dataloading: 0.0110 s/iter. Inference: 0.1381 s/iter. Eval: 0.2021 s/iter. Total: 0.3513 s/iter. ETA=0:05:28
[01/18 04:53:45] detectron2.evaluation.evaluator INFO: Inference done 173/1093. Dataloading: 0.0109 s/iter. Inference: 0.1379 s/iter. Eval: 0.2017 s/iter. Total: 0.3506 s/iter. ETA=0:05:22
[01/18 04:53:51] detectron2.evaluation.evaluator INFO: Inference done 188/1093. Dataloading: 0.0109 s/iter. Inference: 0.1379 s/iter. Eval: 0.2013 s/iter. Total: 0.3502 s/iter. ETA=0:05:16
[01/18 04:53:56] detectron2.evaluation.evaluator INFO: Inference done 202/1093. Dataloading: 0.0112 s/iter. Inference: 0.1381 s/iter. Eval: 0.2020 s/iter. Total: 0.3514 s/iter. ETA=0:05:13
[01/18 04:54:01] detectron2.evaluation.evaluator INFO: Inference done 217/1093. Dataloading: 0.0112 s/iter. Inference: 0.1390 s/iter. Eval: 0.2005 s/iter. Total: 0.3508 s/iter. ETA=0:05:07
[01/18 04:54:06] detectron2.evaluation.evaluator INFO: Inference done 232/1093. Dataloading: 0.0111 s/iter. Inference: 0.1396 s/iter. Eval: 0.2001 s/iter. Total: 0.3510 s/iter. ETA=0:05:02
[01/18 04:54:11] detectron2.evaluation.evaluator INFO: Inference done 246/1093. Dataloading: 0.0111 s/iter. Inference: 0.1401 s/iter. Eval: 0.2006 s/iter. Total: 0.3519 s/iter. ETA=0:04:58
[01/18 04:54:17] detectron2.evaluation.evaluator INFO: Inference done 259/1093. Dataloading: 0.0113 s/iter. Inference: 0.1401 s/iter. Eval: 0.2028 s/iter. Total: 0.3543 s/iter. ETA=0:04:55
[01/18 04:54:22] detectron2.evaluation.evaluator INFO: Inference done 274/1093. Dataloading: 0.0112 s/iter. Inference: 0.1401 s/iter. Eval: 0.2020 s/iter. Total: 0.3534 s/iter. ETA=0:04:49
[01/18 04:54:27] detectron2.evaluation.evaluator INFO: Inference done 289/1093. Dataloading: 0.0112 s/iter. Inference: 0.1404 s/iter. Eval: 0.2019 s/iter. Total: 0.3536 s/iter. ETA=0:04:44
[01/18 04:54:32] detectron2.evaluation.evaluator INFO: Inference done 304/1093. Dataloading: 0.0112 s/iter. Inference: 0.1402 s/iter. Eval: 0.2013 s/iter. Total: 0.3527 s/iter. ETA=0:04:38
[01/18 04:54:37] detectron2.evaluation.evaluator INFO: Inference done 321/1093. Dataloading: 0.0111 s/iter. Inference: 0.1402 s/iter. Eval: 0.1985 s/iter. Total: 0.3499 s/iter. ETA=0:04:30
[01/18 04:54:42] detectron2.evaluation.evaluator INFO: Inference done 336/1093. Dataloading: 0.0110 s/iter. Inference: 0.1403 s/iter. Eval: 0.1982 s/iter. Total: 0.3496 s/iter. ETA=0:04:24
[01/18 04:54:48] detectron2.evaluation.evaluator INFO: Inference done 350/1093. Dataloading: 0.0111 s/iter. Inference: 0.1404 s/iter. Eval: 0.1996 s/iter. Total: 0.3511 s/iter. ETA=0:04:20
[01/18 04:54:53] detectron2.evaluation.evaluator INFO: Inference done 364/1093. Dataloading: 0.0111 s/iter. Inference: 0.1403 s/iter. Eval: 0.2007 s/iter. Total: 0.3523 s/iter. ETA=0:04:16
[01/18 04:54:58] detectron2.evaluation.evaluator INFO: Inference done 379/1093. Dataloading: 0.0111 s/iter. Inference: 0.1402 s/iter. Eval: 0.2007 s/iter. Total: 0.3520 s/iter. ETA=0:04:11
[01/18 04:55:03] detectron2.evaluation.evaluator INFO: Inference done 392/1093. Dataloading: 0.0112 s/iter. Inference: 0.1401 s/iter. Eval: 0.2023 s/iter. Total: 0.3537 s/iter. ETA=0:04:07
[01/18 04:55:08] detectron2.evaluation.evaluator INFO: Inference done 405/1093. Dataloading: 0.0112 s/iter. Inference: 0.1401 s/iter. Eval: 0.2034 s/iter. Total: 0.3548 s/iter. ETA=0:04:04
[01/18 04:55:14] detectron2.evaluation.evaluator INFO: Inference done 420/1093. Dataloading: 0.0112 s/iter. Inference: 0.1397 s/iter. Eval: 0.2033 s/iter. Total: 0.3544 s/iter. ETA=0:03:58
[01/18 04:55:19] detectron2.evaluation.evaluator INFO: Inference done 436/1093. Dataloading: 0.0112 s/iter. Inference: 0.1398 s/iter. Eval: 0.2025 s/iter. Total: 0.3536 s/iter. ETA=0:03:52
[01/18 04:55:24] detectron2.evaluation.evaluator INFO: Inference done 451/1093. Dataloading: 0.0112 s/iter. Inference: 0.1398 s/iter. Eval: 0.2019 s/iter. Total: 0.3530 s/iter. ETA=0:03:46
[01/18 04:55:29] detectron2.evaluation.evaluator INFO: Inference done 466/1093. Dataloading: 0.0112 s/iter. Inference: 0.1400 s/iter. Eval: 0.2015 s/iter. Total: 0.3528 s/iter. ETA=0:03:41
[01/18 04:55:34] detectron2.evaluation.evaluator INFO: Inference done 480/1093. Dataloading: 0.0111 s/iter. Inference: 0.1401 s/iter. Eval: 0.2017 s/iter. Total: 0.3531 s/iter. ETA=0:03:36
[01/18 04:55:40] detectron2.evaluation.evaluator INFO: Inference done 496/1093. Dataloading: 0.0111 s/iter. Inference: 0.1398 s/iter. Eval: 0.2013 s/iter. Total: 0.3523 s/iter. ETA=0:03:30
[01/18 04:55:45] detectron2.evaluation.evaluator INFO: Inference done 510/1093. Dataloading: 0.0111 s/iter. Inference: 0.1398 s/iter. Eval: 0.2016 s/iter. Total: 0.3526 s/iter. ETA=0:03:25
[01/18 04:55:50] detectron2.evaluation.evaluator INFO: Inference done 524/1093. Dataloading: 0.0111 s/iter. Inference: 0.1399 s/iter. Eval: 0.2025 s/iter. Total: 0.3535 s/iter. ETA=0:03:21
[01/18 04:55:55] detectron2.evaluation.evaluator INFO: Inference done 539/1093. Dataloading: 0.0111 s/iter. Inference: 0.1399 s/iter. Eval: 0.2020 s/iter. Total: 0.3530 s/iter. ETA=0:03:15
[01/18 04:56:00] detectron2.evaluation.evaluator INFO: Inference done 555/1093. Dataloading: 0.0110 s/iter. Inference: 0.1397 s/iter. Eval: 0.2013 s/iter. Total: 0.3521 s/iter. ETA=0:03:09
[01/18 04:56:05] detectron2.evaluation.evaluator INFO: Inference done 570/1093. Dataloading: 0.0110 s/iter. Inference: 0.1396 s/iter. Eval: 0.2013 s/iter. Total: 0.3521 s/iter. ETA=0:03:04
[01/18 04:56:11] detectron2.evaluation.evaluator INFO: Inference done 582/1093. Dataloading: 0.0111 s/iter. Inference: 0.1398 s/iter. Eval: 0.2026 s/iter. Total: 0.3536 s/iter. ETA=0:03:00
[01/18 04:56:16] detectron2.evaluation.evaluator INFO: Inference done 595/1093. Dataloading: 0.0111 s/iter. Inference: 0.1400 s/iter. Eval: 0.2031 s/iter. Total: 0.3543 s/iter. ETA=0:02:56
[01/18 04:56:21] detectron2.evaluation.evaluator INFO: Inference done 609/1093. Dataloading: 0.0112 s/iter. Inference: 0.1401 s/iter. Eval: 0.2031 s/iter. Total: 0.3545 s/iter. ETA=0:02:51
[01/18 04:56:26] detectron2.evaluation.evaluator INFO: Inference done 625/1093. Dataloading: 0.0112 s/iter. Inference: 0.1400 s/iter. Eval: 0.2025 s/iter. Total: 0.3538 s/iter. ETA=0:02:45
[01/18 04:56:31] detectron2.evaluation.evaluator INFO: Inference done 639/1093. Dataloading: 0.0112 s/iter. Inference: 0.1400 s/iter. Eval: 0.2026 s/iter. Total: 0.3539 s/iter. ETA=0:02:40
[01/18 04:56:36] detectron2.evaluation.evaluator INFO: Inference done 652/1093. Dataloading: 0.0112 s/iter. Inference: 0.1401 s/iter. Eval: 0.2031 s/iter. Total: 0.3545 s/iter. ETA=0:02:36
[01/18 04:56:41] detectron2.evaluation.evaluator INFO: Inference done 666/1093. Dataloading: 0.0111 s/iter. Inference: 0.1401 s/iter. Eval: 0.2033 s/iter. Total: 0.3546 s/iter. ETA=0:02:31
[01/18 04:56:46] detectron2.evaluation.evaluator INFO: Inference done 681/1093. Dataloading: 0.0112 s/iter. Inference: 0.1400 s/iter. Eval: 0.2032 s/iter. Total: 0.3544 s/iter. ETA=0:02:26
[01/18 04:56:51] detectron2.evaluation.evaluator INFO: Inference done 694/1093. Dataloading: 0.0112 s/iter. Inference: 0.1401 s/iter. Eval: 0.2039 s/iter. Total: 0.3552 s/iter. ETA=0:02:21
[01/18 04:56:57] detectron2.evaluation.evaluator INFO: Inference done 709/1093. Dataloading: 0.0112 s/iter. Inference: 0.1402 s/iter. Eval: 0.2037 s/iter. Total: 0.3552 s/iter. ETA=0:02:16
[01/18 04:57:02] detectron2.evaluation.evaluator INFO: Inference done 724/1093. Dataloading: 0.0112 s/iter. Inference: 0.1401 s/iter. Eval: 0.2036 s/iter. Total: 0.3550 s/iter. ETA=0:02:10
[01/18 04:57:07] detectron2.evaluation.evaluator INFO: Inference done 738/1093. Dataloading: 0.0112 s/iter. Inference: 0.1402 s/iter. Eval: 0.2036 s/iter. Total: 0.3550 s/iter. ETA=0:02:06
[01/18 04:57:12] detectron2.evaluation.evaluator INFO: Inference done 753/1093. Dataloading: 0.0111 s/iter. Inference: 0.1403 s/iter. Eval: 0.2032 s/iter. Total: 0.3548 s/iter. ETA=0:02:00
[01/18 04:57:17] detectron2.evaluation.evaluator INFO: Inference done 767/1093. Dataloading: 0.0112 s/iter. Inference: 0.1403 s/iter. Eval: 0.2033 s/iter. Total: 0.3548 s/iter. ETA=0:01:55
[01/18 04:57:22] detectron2.evaluation.evaluator INFO: Inference done 782/1093. Dataloading: 0.0112 s/iter. Inference: 0.1402 s/iter. Eval: 0.2033 s/iter. Total: 0.3547 s/iter. ETA=0:01:50
[01/18 04:57:28] detectron2.evaluation.evaluator INFO: Inference done 797/1093. Dataloading: 0.0111 s/iter. Inference: 0.1403 s/iter. Eval: 0.2033 s/iter. Total: 0.3549 s/iter. ETA=0:01:45
[01/18 04:57:33] detectron2.evaluation.evaluator INFO: Inference done 812/1093. Dataloading: 0.0111 s/iter. Inference: 0.1404 s/iter. Eval: 0.2032 s/iter. Total: 0.3547 s/iter. ETA=0:01:39
[01/18 04:57:38] detectron2.evaluation.evaluator INFO: Inference done 827/1093. Dataloading: 0.0111 s/iter. Inference: 0.1403 s/iter. Eval: 0.2030 s/iter. Total: 0.3545 s/iter. ETA=0:01:34
[01/18 04:57:43] detectron2.evaluation.evaluator INFO: Inference done 843/1093. Dataloading: 0.0111 s/iter. Inference: 0.1403 s/iter. Eval: 0.2025 s/iter. Total: 0.3540 s/iter. ETA=0:01:28
[01/18 04:57:48] detectron2.evaluation.evaluator INFO: Inference done 857/1093. Dataloading: 0.0111 s/iter. Inference: 0.1404 s/iter. Eval: 0.2028 s/iter. Total: 0.3544 s/iter. ETA=0:01:23
[01/18 04:57:54] detectron2.evaluation.evaluator INFO: Inference done 872/1093. Dataloading: 0.0111 s/iter. Inference: 0.1403 s/iter. Eval: 0.2029 s/iter. Total: 0.3544 s/iter. ETA=0:01:18
[01/18 04:57:59] detectron2.evaluation.evaluator INFO: Inference done 886/1093. Dataloading: 0.0111 s/iter. Inference: 0.1402 s/iter. Eval: 0.2032 s/iter. Total: 0.3546 s/iter. ETA=0:01:13
[01/18 04:58:04] detectron2.evaluation.evaluator INFO: Inference done 900/1093. Dataloading: 0.0111 s/iter. Inference: 0.1403 s/iter. Eval: 0.2033 s/iter. Total: 0.3549 s/iter. ETA=0:01:08
[01/18 04:58:09] detectron2.evaluation.evaluator INFO: Inference done 913/1093. Dataloading: 0.0111 s/iter. Inference: 0.1404 s/iter. Eval: 0.2039 s/iter. Total: 0.3555 s/iter. ETA=0:01:03
[01/18 04:58:14] detectron2.evaluation.evaluator INFO: Inference done 926/1093. Dataloading: 0.0111 s/iter. Inference: 0.1404 s/iter. Eval: 0.2043 s/iter. Total: 0.3560 s/iter. ETA=0:00:59
[01/18 04:58:19] detectron2.evaluation.evaluator INFO: Inference done 939/1093. Dataloading: 0.0112 s/iter. Inference: 0.1404 s/iter. Eval: 0.2048 s/iter. Total: 0.3565 s/iter. ETA=0:00:54
[01/18 04:58:25] detectron2.evaluation.evaluator INFO: Inference done 954/1093. Dataloading: 0.0112 s/iter. Inference: 0.1403 s/iter. Eval: 0.2048 s/iter. Total: 0.3564 s/iter. ETA=0:00:49
[01/18 04:58:30] detectron2.evaluation.evaluator INFO: Inference done 970/1093. Dataloading: 0.0111 s/iter. Inference: 0.1402 s/iter. Eval: 0.2042 s/iter. Total: 0.3557 s/iter. ETA=0:00:43
[01/18 04:58:35] detectron2.evaluation.evaluator INFO: Inference done 985/1093. Dataloading: 0.0111 s/iter. Inference: 0.1403 s/iter. Eval: 0.2041 s/iter. Total: 0.3556 s/iter. ETA=0:00:38
[01/18 04:58:40] detectron2.evaluation.evaluator INFO: Inference done 1002/1093. Dataloading: 0.0111 s/iter. Inference: 0.1401 s/iter. Eval: 0.2035 s/iter. Total: 0.3548 s/iter. ETA=0:00:32
[01/18 04:58:45] detectron2.evaluation.evaluator INFO: Inference done 1016/1093. Dataloading: 0.0111 s/iter. Inference: 0.1402 s/iter. Eval: 0.2036 s/iter. Total: 0.3549 s/iter. ETA=0:00:27
[01/18 04:58:50] detectron2.evaluation.evaluator INFO: Inference done 1032/1093. Dataloading: 0.0110 s/iter. Inference: 0.1402 s/iter. Eval: 0.2030 s/iter. Total: 0.3543 s/iter. ETA=0:00:21
[01/18 04:58:55] detectron2.evaluation.evaluator INFO: Inference done 1047/1093. Dataloading: 0.0110 s/iter. Inference: 0.1402 s/iter. Eval: 0.2028 s/iter. Total: 0.3541 s/iter. ETA=0:00:16
[01/18 04:59:01] detectron2.evaluation.evaluator INFO: Inference done 1062/1093. Dataloading: 0.0110 s/iter. Inference: 0.1401 s/iter. Eval: 0.2027 s/iter. Total: 0.3540 s/iter. ETA=0:00:10
[01/18 04:59:06] detectron2.evaluation.evaluator INFO: Inference done 1077/1093. Dataloading: 0.0110 s/iter. Inference: 0.1401 s/iter. Eval: 0.2027 s/iter. Total: 0.3539 s/iter. ETA=0:00:05
[01/18 04:59:11] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:24.494073 (0.353395 s / iter per device, on 4 devices)
[01/18 04:59:11] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:32 (0.139982 s / iter per device, on 4 devices)
[01/18 05:48:23] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 05:48:24] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 05:48:24] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 05:48:25] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 05:48:39] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0091 s/iter. Inference: 0.1362 s/iter. Eval: 0.2298 s/iter. Total: 0.3751 s/iter. ETA=0:06:45
[01/18 05:48:44] detectron2.evaluation.evaluator INFO: Inference done 24/1093. Dataloading: 0.0118 s/iter. Inference: 0.1374 s/iter. Eval: 0.2370 s/iter. Total: 0.3863 s/iter. ETA=0:06:52
[01/18 05:48:50] detectron2.evaluation.evaluator INFO: Inference done 36/1093. Dataloading: 0.0130 s/iter. Inference: 0.1424 s/iter. Eval: 0.2544 s/iter. Total: 0.4099 s/iter. ETA=0:07:13
[01/18 05:48:55] detectron2.evaluation.evaluator INFO: Inference done 50/1093. Dataloading: 0.0125 s/iter. Inference: 0.1406 s/iter. Eval: 0.2439 s/iter. Total: 0.3970 s/iter. ETA=0:06:54
[01/18 05:49:00] detectron2.evaluation.evaluator INFO: Inference done 63/1093. Dataloading: 0.0124 s/iter. Inference: 0.1412 s/iter. Eval: 0.2407 s/iter. Total: 0.3944 s/iter. ETA=0:06:46
[01/18 05:49:05] detectron2.evaluation.evaluator INFO: Inference done 75/1093. Dataloading: 0.0126 s/iter. Inference: 0.1415 s/iter. Eval: 0.2478 s/iter. Total: 0.4020 s/iter. ETA=0:06:49
[01/18 05:49:10] detectron2.evaluation.evaluator INFO: Inference done 92/1093. Dataloading: 0.0122 s/iter. Inference: 0.1400 s/iter. Eval: 0.2311 s/iter. Total: 0.3834 s/iter. ETA=0:06:23
[01/18 05:49:16] detectron2.evaluation.evaluator INFO: Inference done 107/1093. Dataloading: 0.0121 s/iter. Inference: 0.1406 s/iter. Eval: 0.2255 s/iter. Total: 0.3783 s/iter. ETA=0:06:12
[01/18 05:49:21] detectron2.evaluation.evaluator INFO: Inference done 123/1093. Dataloading: 0.0117 s/iter. Inference: 0.1403 s/iter. Eval: 0.2189 s/iter. Total: 0.3711 s/iter. ETA=0:05:59
[01/18 05:49:26] detectron2.evaluation.evaluator INFO: Inference done 137/1093. Dataloading: 0.0116 s/iter. Inference: 0.1407 s/iter. Eval: 0.2172 s/iter. Total: 0.3696 s/iter. ETA=0:05:53
[01/18 05:49:31] detectron2.evaluation.evaluator INFO: Inference done 153/1093. Dataloading: 0.0115 s/iter. Inference: 0.1403 s/iter. Eval: 0.2123 s/iter. Total: 0.3641 s/iter. ETA=0:05:42
[01/18 05:49:36] detectron2.evaluation.evaluator INFO: Inference done 167/1093. Dataloading: 0.0114 s/iter. Inference: 0.1400 s/iter. Eval: 0.2124 s/iter. Total: 0.3639 s/iter. ETA=0:05:37
[01/18 05:49:41] detectron2.evaluation.evaluator INFO: Inference done 183/1093. Dataloading: 0.0114 s/iter. Inference: 0.1391 s/iter. Eval: 0.2098 s/iter. Total: 0.3603 s/iter. ETA=0:05:27
[01/18 05:49:46] detectron2.evaluation.evaluator INFO: Inference done 197/1093. Dataloading: 0.0114 s/iter. Inference: 0.1391 s/iter. Eval: 0.2101 s/iter. Total: 0.3607 s/iter. ETA=0:05:23
[01/18 05:49:51] detectron2.evaluation.evaluator INFO: Inference done 211/1093. Dataloading: 0.0115 s/iter. Inference: 0.1393 s/iter. Eval: 0.2106 s/iter. Total: 0.3615 s/iter. ETA=0:05:18
[01/18 05:49:57] detectron2.evaluation.evaluator INFO: Inference done 228/1093. Dataloading: 0.0113 s/iter. Inference: 0.1393 s/iter. Eval: 0.2063 s/iter. Total: 0.3569 s/iter. ETA=0:05:08
[01/18 05:50:02] detectron2.evaluation.evaluator INFO: Inference done 242/1093. Dataloading: 0.0112 s/iter. Inference: 0.1394 s/iter. Eval: 0.2070 s/iter. Total: 0.3577 s/iter. ETA=0:05:04
[01/18 05:50:07] detectron2.evaluation.evaluator INFO: Inference done 256/1093. Dataloading: 0.0114 s/iter. Inference: 0.1395 s/iter. Eval: 0.2080 s/iter. Total: 0.3590 s/iter. ETA=0:05:00
[01/18 05:50:12] detectron2.evaluation.evaluator INFO: Inference done 272/1093. Dataloading: 0.0114 s/iter. Inference: 0.1394 s/iter. Eval: 0.2067 s/iter. Total: 0.3576 s/iter. ETA=0:04:53
[01/18 05:50:18] detectron2.evaluation.evaluator INFO: Inference done 287/1093. Dataloading: 0.0114 s/iter. Inference: 0.1395 s/iter. Eval: 0.2065 s/iter. Total: 0.3575 s/iter. ETA=0:04:48
[01/18 05:50:23] detectron2.evaluation.evaluator INFO: Inference done 302/1093. Dataloading: 0.0114 s/iter. Inference: 0.1394 s/iter. Eval: 0.2066 s/iter. Total: 0.3574 s/iter. ETA=0:04:42
[01/18 05:50:28] detectron2.evaluation.evaluator INFO: Inference done 318/1093. Dataloading: 0.0113 s/iter. Inference: 0.1394 s/iter. Eval: 0.2046 s/iter. Total: 0.3554 s/iter. ETA=0:04:35
[01/18 05:50:33] detectron2.evaluation.evaluator INFO: Inference done 332/1093. Dataloading: 0.0113 s/iter. Inference: 0.1398 s/iter. Eval: 0.2047 s/iter. Total: 0.3559 s/iter. ETA=0:04:30
[01/18 05:50:38] detectron2.evaluation.evaluator INFO: Inference done 347/1093. Dataloading: 0.0113 s/iter. Inference: 0.1395 s/iter. Eval: 0.2044 s/iter. Total: 0.3554 s/iter. ETA=0:04:25
[01/18 05:50:44] detectron2.evaluation.evaluator INFO: Inference done 361/1093. Dataloading: 0.0113 s/iter. Inference: 0.1396 s/iter. Eval: 0.2050 s/iter. Total: 0.3561 s/iter. ETA=0:04:20
[01/18 05:50:49] detectron2.evaluation.evaluator INFO: Inference done 378/1093. Dataloading: 0.0113 s/iter. Inference: 0.1389 s/iter. Eval: 0.2038 s/iter. Total: 0.3541 s/iter. ETA=0:04:13
[01/18 05:50:54] detectron2.evaluation.evaluator INFO: Inference done 391/1093. Dataloading: 0.0114 s/iter. Inference: 0.1391 s/iter. Eval: 0.2053 s/iter. Total: 0.3559 s/iter. ETA=0:04:09
[01/18 05:50:59] detectron2.evaluation.evaluator INFO: Inference done 404/1093. Dataloading: 0.0114 s/iter. Inference: 0.1391 s/iter. Eval: 0.2064 s/iter. Total: 0.3570 s/iter. ETA=0:04:05
[01/18 05:51:04] detectron2.evaluation.evaluator INFO: Inference done 417/1093. Dataloading: 0.0114 s/iter. Inference: 0.1393 s/iter. Eval: 0.2072 s/iter. Total: 0.3580 s/iter. ETA=0:04:02
[01/18 05:51:10] detectron2.evaluation.evaluator INFO: Inference done 432/1093. Dataloading: 0.0114 s/iter. Inference: 0.1393 s/iter. Eval: 0.2069 s/iter. Total: 0.3577 s/iter. ETA=0:03:56
[01/18 05:51:15] detectron2.evaluation.evaluator INFO: Inference done 447/1093. Dataloading: 0.0114 s/iter. Inference: 0.1396 s/iter. Eval: 0.2066 s/iter. Total: 0.3577 s/iter. ETA=0:03:51
[01/18 05:51:20] detectron2.evaluation.evaluator INFO: Inference done 462/1093. Dataloading: 0.0113 s/iter. Inference: 0.1397 s/iter. Eval: 0.2060 s/iter. Total: 0.3572 s/iter. ETA=0:03:45
[01/18 05:51:26] detectron2.evaluation.evaluator INFO: Inference done 477/1093. Dataloading: 0.0113 s/iter. Inference: 0.1398 s/iter. Eval: 0.2060 s/iter. Total: 0.3572 s/iter. ETA=0:03:40
[01/18 05:51:31] detectron2.evaluation.evaluator INFO: Inference done 491/1093. Dataloading: 0.0113 s/iter. Inference: 0.1399 s/iter. Eval: 0.2063 s/iter. Total: 0.3576 s/iter. ETA=0:03:35
[01/18 05:51:36] detectron2.evaluation.evaluator INFO: Inference done 504/1093. Dataloading: 0.0114 s/iter. Inference: 0.1402 s/iter. Eval: 0.2075 s/iter. Total: 0.3591 s/iter. ETA=0:03:31
[01/18 05:51:42] detectron2.evaluation.evaluator INFO: Inference done 518/1093. Dataloading: 0.0114 s/iter. Inference: 0.1403 s/iter. Eval: 0.2080 s/iter. Total: 0.3598 s/iter. ETA=0:03:26
[01/18 05:51:47] detectron2.evaluation.evaluator INFO: Inference done 534/1093. Dataloading: 0.0113 s/iter. Inference: 0.1400 s/iter. Eval: 0.2073 s/iter. Total: 0.3587 s/iter. ETA=0:03:20
[01/18 05:51:52] detectron2.evaluation.evaluator INFO: Inference done 549/1093. Dataloading: 0.0113 s/iter. Inference: 0.1401 s/iter. Eval: 0.2069 s/iter. Total: 0.3584 s/iter. ETA=0:03:14
[01/18 05:51:57] detectron2.evaluation.evaluator INFO: Inference done 563/1093. Dataloading: 0.0113 s/iter. Inference: 0.1402 s/iter. Eval: 0.2071 s/iter. Total: 0.3587 s/iter. ETA=0:03:10
[01/18 05:52:02] detectron2.evaluation.evaluator INFO: Inference done 575/1093. Dataloading: 0.0114 s/iter. Inference: 0.1404 s/iter. Eval: 0.2086 s/iter. Total: 0.3604 s/iter. ETA=0:03:06
[01/18 05:52:07] detectron2.evaluation.evaluator INFO: Inference done 588/1093. Dataloading: 0.0114 s/iter. Inference: 0.1405 s/iter. Eval: 0.2091 s/iter. Total: 0.3610 s/iter. ETA=0:03:02
[01/18 05:52:13] detectron2.evaluation.evaluator INFO: Inference done 600/1093. Dataloading: 0.0114 s/iter. Inference: 0.1409 s/iter. Eval: 0.2100 s/iter. Total: 0.3623 s/iter. ETA=0:02:58
[01/18 05:52:18] detectron2.evaluation.evaluator INFO: Inference done 614/1093. Dataloading: 0.0114 s/iter. Inference: 0.1409 s/iter. Eval: 0.2099 s/iter. Total: 0.3623 s/iter. ETA=0:02:53
[01/18 05:52:23] detectron2.evaluation.evaluator INFO: Inference done 628/1093. Dataloading: 0.0114 s/iter. Inference: 0.1410 s/iter. Eval: 0.2102 s/iter. Total: 0.3627 s/iter. ETA=0:02:48
[01/18 05:52:28] detectron2.evaluation.evaluator INFO: Inference done 641/1093. Dataloading: 0.0114 s/iter. Inference: 0.1411 s/iter. Eval: 0.2107 s/iter. Total: 0.3633 s/iter. ETA=0:02:44
[01/18 05:52:33] detectron2.evaluation.evaluator INFO: Inference done 655/1093. Dataloading: 0.0114 s/iter. Inference: 0.1411 s/iter. Eval: 0.2110 s/iter. Total: 0.3636 s/iter. ETA=0:02:39
[01/18 05:52:39] detectron2.evaluation.evaluator INFO: Inference done 669/1093. Dataloading: 0.0114 s/iter. Inference: 0.1412 s/iter. Eval: 0.2113 s/iter. Total: 0.3640 s/iter. ETA=0:02:34
[01/18 05:52:44] detectron2.evaluation.evaluator INFO: Inference done 683/1093. Dataloading: 0.0114 s/iter. Inference: 0.1412 s/iter. Eval: 0.2117 s/iter. Total: 0.3643 s/iter. ETA=0:02:29
[01/18 05:52:49] detectron2.evaluation.evaluator INFO: Inference done 696/1093. Dataloading: 0.0114 s/iter. Inference: 0.1413 s/iter. Eval: 0.2125 s/iter. Total: 0.3653 s/iter. ETA=0:02:25
[01/18 05:52:54] detectron2.evaluation.evaluator INFO: Inference done 710/1093. Dataloading: 0.0114 s/iter. Inference: 0.1415 s/iter. Eval: 0.2122 s/iter. Total: 0.3652 s/iter. ETA=0:02:19
[01/18 05:53:00] detectron2.evaluation.evaluator INFO: Inference done 723/1093. Dataloading: 0.0114 s/iter. Inference: 0.1417 s/iter. Eval: 0.2126 s/iter. Total: 0.3658 s/iter. ETA=0:02:15
[01/18 05:53:05] detectron2.evaluation.evaluator INFO: Inference done 737/1093. Dataloading: 0.0114 s/iter. Inference: 0.1418 s/iter. Eval: 0.2128 s/iter. Total: 0.3661 s/iter. ETA=0:02:10
[01/18 05:53:10] detectron2.evaluation.evaluator INFO: Inference done 751/1093. Dataloading: 0.0114 s/iter. Inference: 0.1419 s/iter. Eval: 0.2127 s/iter. Total: 0.3661 s/iter. ETA=0:02:05
[01/18 05:53:15] detectron2.evaluation.evaluator INFO: Inference done 765/1093. Dataloading: 0.0114 s/iter. Inference: 0.1418 s/iter. Eval: 0.2129 s/iter. Total: 0.3662 s/iter. ETA=0:02:00
[01/18 05:53:20] detectron2.evaluation.evaluator INFO: Inference done 778/1093. Dataloading: 0.0114 s/iter. Inference: 0.1422 s/iter. Eval: 0.2130 s/iter. Total: 0.3666 s/iter. ETA=0:01:55
[01/18 05:53:25] detectron2.evaluation.evaluator INFO: Inference done 791/1093. Dataloading: 0.0114 s/iter. Inference: 0.1422 s/iter. Eval: 0.2132 s/iter. Total: 0.3669 s/iter. ETA=0:01:50
[01/18 05:53:30] detectron2.evaluation.evaluator INFO: Inference done 805/1093. Dataloading: 0.0114 s/iter. Inference: 0.1423 s/iter. Eval: 0.2131 s/iter. Total: 0.3668 s/iter. ETA=0:01:45
[01/18 05:53:36] detectron2.evaluation.evaluator INFO: Inference done 819/1093. Dataloading: 0.0114 s/iter. Inference: 0.1424 s/iter. Eval: 0.2133 s/iter. Total: 0.3671 s/iter. ETA=0:01:40
[01/18 05:53:41] detectron2.evaluation.evaluator INFO: Inference done 834/1093. Dataloading: 0.0114 s/iter. Inference: 0.1423 s/iter. Eval: 0.2131 s/iter. Total: 0.3669 s/iter. ETA=0:01:35
[01/18 05:53:46] detectron2.evaluation.evaluator INFO: Inference done 849/1093. Dataloading: 0.0113 s/iter. Inference: 0.1425 s/iter. Eval: 0.2126 s/iter. Total: 0.3665 s/iter. ETA=0:01:29
[01/18 05:53:52] detectron2.evaluation.evaluator INFO: Inference done 863/1093. Dataloading: 0.0113 s/iter. Inference: 0.1425 s/iter. Eval: 0.2128 s/iter. Total: 0.3667 s/iter. ETA=0:01:24
[01/18 05:53:57] detectron2.evaluation.evaluator INFO: Inference done 876/1093. Dataloading: 0.0114 s/iter. Inference: 0.1426 s/iter. Eval: 0.2134 s/iter. Total: 0.3675 s/iter. ETA=0:01:19
[01/18 05:54:02] detectron2.evaluation.evaluator INFO: Inference done 889/1093. Dataloading: 0.0114 s/iter. Inference: 0.1427 s/iter. Eval: 0.2140 s/iter. Total: 0.3682 s/iter. ETA=0:01:15
[01/18 05:54:08] detectron2.evaluation.evaluator INFO: Inference done 904/1093. Dataloading: 0.0114 s/iter. Inference: 0.1427 s/iter. Eval: 0.2139 s/iter. Total: 0.3680 s/iter. ETA=0:01:09
[01/18 05:54:13] detectron2.evaluation.evaluator INFO: Inference done 918/1093. Dataloading: 0.0114 s/iter. Inference: 0.1428 s/iter. Eval: 0.2138 s/iter. Total: 0.3681 s/iter. ETA=0:01:04
[01/18 05:54:18] detectron2.evaluation.evaluator INFO: Inference done 930/1093. Dataloading: 0.0114 s/iter. Inference: 0.1429 s/iter. Eval: 0.2147 s/iter. Total: 0.3691 s/iter. ETA=0:01:00
[01/18 05:54:24] detectron2.evaluation.evaluator INFO: Inference done 944/1093. Dataloading: 0.0114 s/iter. Inference: 0.1429 s/iter. Eval: 0.2147 s/iter. Total: 0.3691 s/iter. ETA=0:00:54
[01/18 05:54:29] detectron2.evaluation.evaluator INFO: Inference done 960/1093. Dataloading: 0.0114 s/iter. Inference: 0.1428 s/iter. Eval: 0.2142 s/iter. Total: 0.3684 s/iter. ETA=0:00:48
[01/18 05:54:34] detectron2.evaluation.evaluator INFO: Inference done 976/1093. Dataloading: 0.0113 s/iter. Inference: 0.1428 s/iter. Eval: 0.2133 s/iter. Total: 0.3675 s/iter. ETA=0:00:42
[01/18 05:54:39] detectron2.evaluation.evaluator INFO: Inference done 992/1093. Dataloading: 0.0113 s/iter. Inference: 0.1426 s/iter. Eval: 0.2127 s/iter. Total: 0.3667 s/iter. ETA=0:00:37
[01/18 05:54:44] detectron2.evaluation.evaluator INFO: Inference done 1007/1093. Dataloading: 0.0113 s/iter. Inference: 0.1425 s/iter. Eval: 0.2124 s/iter. Total: 0.3663 s/iter. ETA=0:00:31
[01/18 05:54:49] detectron2.evaluation.evaluator INFO: Inference done 1021/1093. Dataloading: 0.0113 s/iter. Inference: 0.1426 s/iter. Eval: 0.2123 s/iter. Total: 0.3663 s/iter. ETA=0:00:26
[01/18 05:54:54] detectron2.evaluation.evaluator INFO: Inference done 1037/1093. Dataloading: 0.0113 s/iter. Inference: 0.1427 s/iter. Eval: 0.2117 s/iter. Total: 0.3657 s/iter. ETA=0:00:20
[01/18 05:54:59] detectron2.evaluation.evaluator INFO: Inference done 1051/1093. Dataloading: 0.0113 s/iter. Inference: 0.1427 s/iter. Eval: 0.2117 s/iter. Total: 0.3657 s/iter. ETA=0:00:15
[01/18 05:55:05] detectron2.evaluation.evaluator INFO: Inference done 1065/1093. Dataloading: 0.0113 s/iter. Inference: 0.1427 s/iter. Eval: 0.2118 s/iter. Total: 0.3658 s/iter. ETA=0:00:10
[01/18 05:55:10] detectron2.evaluation.evaluator INFO: Inference done 1079/1093. Dataloading: 0.0113 s/iter. Inference: 0.1429 s/iter. Eval: 0.2116 s/iter. Total: 0.3659 s/iter. ETA=0:00:05
[01/18 05:55:15] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:38.139257 (0.365937 s / iter per device, on 4 devices)
[01/18 05:55:15] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:35 (0.142902 s / iter per device, on 4 devices)
[01/18 06:44:27] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 06:44:28] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 06:44:28] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 06:44:28] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 06:44:42] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0080 s/iter. Inference: 0.1334 s/iter. Eval: 0.1877 s/iter. Total: 0.3291 s/iter. ETA=0:05:56
[01/18 06:44:47] detectron2.evaluation.evaluator INFO: Inference done 23/1093. Dataloading: 0.0115 s/iter. Inference: 0.1426 s/iter. Eval: 0.2346 s/iter. Total: 0.3888 s/iter. ETA=0:06:56
[01/18 06:44:53] detectron2.evaluation.evaluator INFO: Inference done 34/1093. Dataloading: 0.0133 s/iter. Inference: 0.1461 s/iter. Eval: 0.2642 s/iter. Total: 0.4238 s/iter. ETA=0:07:28
[01/18 06:44:58] detectron2.evaluation.evaluator INFO: Inference done 48/1093. Dataloading: 0.0134 s/iter. Inference: 0.1451 s/iter. Eval: 0.2531 s/iter. Total: 0.4117 s/iter. ETA=0:07:10
[01/18 06:45:03] detectron2.evaluation.evaluator INFO: Inference done 63/1093. Dataloading: 0.0130 s/iter. Inference: 0.1431 s/iter. Eval: 0.2406 s/iter. Total: 0.3968 s/iter. ETA=0:06:48
[01/18 06:45:09] detectron2.evaluation.evaluator INFO: Inference done 76/1093. Dataloading: 0.0129 s/iter. Inference: 0.1423 s/iter. Eval: 0.2405 s/iter. Total: 0.3958 s/iter. ETA=0:06:42
[01/18 06:45:14] detectron2.evaluation.evaluator INFO: Inference done 93/1093. Dataloading: 0.0123 s/iter. Inference: 0.1410 s/iter. Eval: 0.2250 s/iter. Total: 0.3784 s/iter. ETA=0:06:18
[01/18 06:45:19] detectron2.evaluation.evaluator INFO: Inference done 109/1093. Dataloading: 0.0118 s/iter. Inference: 0.1406 s/iter. Eval: 0.2169 s/iter. Total: 0.3694 s/iter. ETA=0:06:03
[01/18 06:45:24] detectron2.evaluation.evaluator INFO: Inference done 123/1093. Dataloading: 0.0118 s/iter. Inference: 0.1414 s/iter. Eval: 0.2156 s/iter. Total: 0.3690 s/iter. ETA=0:05:57
[01/18 06:45:29] detectron2.evaluation.evaluator INFO: Inference done 138/1093. Dataloading: 0.0118 s/iter. Inference: 0.1417 s/iter. Eval: 0.2131 s/iter. Total: 0.3667 s/iter. ETA=0:05:50
[01/18 06:45:35] detectron2.evaluation.evaluator INFO: Inference done 154/1093. Dataloading: 0.0116 s/iter. Inference: 0.1414 s/iter. Eval: 0.2099 s/iter. Total: 0.3630 s/iter. ETA=0:05:40
[01/18 06:45:40] detectron2.evaluation.evaluator INFO: Inference done 168/1093. Dataloading: 0.0115 s/iter. Inference: 0.1416 s/iter. Eval: 0.2101 s/iter. Total: 0.3633 s/iter. ETA=0:05:36
[01/18 06:45:45] detectron2.evaluation.evaluator INFO: Inference done 181/1093. Dataloading: 0.0116 s/iter. Inference: 0.1421 s/iter. Eval: 0.2118 s/iter. Total: 0.3656 s/iter. ETA=0:05:33
[01/18 06:45:50] detectron2.evaluation.evaluator INFO: Inference done 194/1093. Dataloading: 0.0116 s/iter. Inference: 0.1426 s/iter. Eval: 0.2129 s/iter. Total: 0.3672 s/iter. ETA=0:05:30
[01/18 06:45:55] detectron2.evaluation.evaluator INFO: Inference done 207/1093. Dataloading: 0.0119 s/iter. Inference: 0.1425 s/iter. Eval: 0.2151 s/iter. Total: 0.3696 s/iter. ETA=0:05:27
[01/18 06:46:00] detectron2.evaluation.evaluator INFO: Inference done 223/1093. Dataloading: 0.0117 s/iter. Inference: 0.1426 s/iter. Eval: 0.2112 s/iter. Total: 0.3656 s/iter. ETA=0:05:18
[01/18 06:46:05] detectron2.evaluation.evaluator INFO: Inference done 239/1093. Dataloading: 0.0116 s/iter. Inference: 0.1420 s/iter. Eval: 0.2087 s/iter. Total: 0.3625 s/iter. ETA=0:05:09
[01/18 06:46:11] detectron2.evaluation.evaluator INFO: Inference done 253/1093. Dataloading: 0.0116 s/iter. Inference: 0.1421 s/iter. Eval: 0.2098 s/iter. Total: 0.3637 s/iter. ETA=0:05:05
[01/18 06:46:16] detectron2.evaluation.evaluator INFO: Inference done 267/1093. Dataloading: 0.0117 s/iter. Inference: 0.1420 s/iter. Eval: 0.2106 s/iter. Total: 0.3644 s/iter. ETA=0:05:00
[01/18 06:46:21] detectron2.evaluation.evaluator INFO: Inference done 282/1093. Dataloading: 0.0117 s/iter. Inference: 0.1421 s/iter. Eval: 0.2094 s/iter. Total: 0.3632 s/iter. ETA=0:04:54
[01/18 06:46:26] detectron2.evaluation.evaluator INFO: Inference done 297/1093. Dataloading: 0.0117 s/iter. Inference: 0.1416 s/iter. Eval: 0.2091 s/iter. Total: 0.3625 s/iter. ETA=0:04:48
[01/18 06:46:31] detectron2.evaluation.evaluator INFO: Inference done 314/1093. Dataloading: 0.0116 s/iter. Inference: 0.1416 s/iter. Eval: 0.2059 s/iter. Total: 0.3592 s/iter. ETA=0:04:39
[01/18 06:46:37] detectron2.evaluation.evaluator INFO: Inference done 328/1093. Dataloading: 0.0116 s/iter. Inference: 0.1422 s/iter. Eval: 0.2063 s/iter. Total: 0.3602 s/iter. ETA=0:04:35
[01/18 06:46:42] detectron2.evaluation.evaluator INFO: Inference done 342/1093. Dataloading: 0.0116 s/iter. Inference: 0.1423 s/iter. Eval: 0.2066 s/iter. Total: 0.3606 s/iter. ETA=0:04:30
[01/18 06:46:47] detectron2.evaluation.evaluator INFO: Inference done 357/1093. Dataloading: 0.0116 s/iter. Inference: 0.1418 s/iter. Eval: 0.2067 s/iter. Total: 0.3602 s/iter. ETA=0:04:25
[01/18 06:46:53] detectron2.evaluation.evaluator INFO: Inference done 371/1093. Dataloading: 0.0117 s/iter. Inference: 0.1419 s/iter. Eval: 0.2071 s/iter. Total: 0.3608 s/iter. ETA=0:04:20
[01/18 06:46:58] detectron2.evaluation.evaluator INFO: Inference done 384/1093. Dataloading: 0.0117 s/iter. Inference: 0.1421 s/iter. Eval: 0.2082 s/iter. Total: 0.3620 s/iter. ETA=0:04:16
[01/18 06:47:03] detectron2.evaluation.evaluator INFO: Inference done 398/1093. Dataloading: 0.0117 s/iter. Inference: 0.1423 s/iter. Eval: 0.2084 s/iter. Total: 0.3625 s/iter. ETA=0:04:11
[01/18 06:47:08] detectron2.evaluation.evaluator INFO: Inference done 410/1093. Dataloading: 0.0117 s/iter. Inference: 0.1423 s/iter. Eval: 0.2100 s/iter. Total: 0.3642 s/iter. ETA=0:04:08
[01/18 06:47:13] detectron2.evaluation.evaluator INFO: Inference done 423/1093. Dataloading: 0.0118 s/iter. Inference: 0.1425 s/iter. Eval: 0.2110 s/iter. Total: 0.3654 s/iter. ETA=0:04:04
[01/18 06:47:18] detectron2.evaluation.evaluator INFO: Inference done 437/1093. Dataloading: 0.0117 s/iter. Inference: 0.1426 s/iter. Eval: 0.2111 s/iter. Total: 0.3655 s/iter. ETA=0:03:59
[01/18 06:47:23] detectron2.evaluation.evaluator INFO: Inference done 453/1093. Dataloading: 0.0116 s/iter. Inference: 0.1425 s/iter. Eval: 0.2096 s/iter. Total: 0.3638 s/iter. ETA=0:03:52
[01/18 06:47:28] detectron2.evaluation.evaluator INFO: Inference done 468/1093. Dataloading: 0.0116 s/iter. Inference: 0.1422 s/iter. Eval: 0.2089 s/iter. Total: 0.3629 s/iter. ETA=0:03:46
[01/18 06:47:34] detectron2.evaluation.evaluator INFO: Inference done 483/1093. Dataloading: 0.0116 s/iter. Inference: 0.1420 s/iter. Eval: 0.2083 s/iter. Total: 0.3620 s/iter. ETA=0:03:40
[01/18 06:47:39] detectron2.evaluation.evaluator INFO: Inference done 496/1093. Dataloading: 0.0116 s/iter. Inference: 0.1421 s/iter. Eval: 0.2092 s/iter. Total: 0.3630 s/iter. ETA=0:03:36
[01/18 06:47:44] detectron2.evaluation.evaluator INFO: Inference done 510/1093. Dataloading: 0.0116 s/iter. Inference: 0.1420 s/iter. Eval: 0.2097 s/iter. Total: 0.3634 s/iter. ETA=0:03:31
[01/18 06:47:49] detectron2.evaluation.evaluator INFO: Inference done 523/1093. Dataloading: 0.0116 s/iter. Inference: 0.1421 s/iter. Eval: 0.2103 s/iter. Total: 0.3642 s/iter. ETA=0:03:27
[01/18 06:47:54] detectron2.evaluation.evaluator INFO: Inference done 537/1093. Dataloading: 0.0116 s/iter. Inference: 0.1424 s/iter. Eval: 0.2101 s/iter. Total: 0.3642 s/iter. ETA=0:03:22
[01/18 06:48:00] detectron2.evaluation.evaluator INFO: Inference done 553/1093. Dataloading: 0.0116 s/iter. Inference: 0.1423 s/iter. Eval: 0.2093 s/iter. Total: 0.3633 s/iter. ETA=0:03:16
[01/18 06:48:05] detectron2.evaluation.evaluator INFO: Inference done 567/1093. Dataloading: 0.0116 s/iter. Inference: 0.1421 s/iter. Eval: 0.2094 s/iter. Total: 0.3633 s/iter. ETA=0:03:11
[01/18 06:48:10] detectron2.evaluation.evaluator INFO: Inference done 582/1093. Dataloading: 0.0116 s/iter. Inference: 0.1419 s/iter. Eval: 0.2094 s/iter. Total: 0.3630 s/iter. ETA=0:03:05
[01/18 06:48:15] detectron2.evaluation.evaluator INFO: Inference done 596/1093. Dataloading: 0.0116 s/iter. Inference: 0.1418 s/iter. Eval: 0.2095 s/iter. Total: 0.3630 s/iter. ETA=0:03:00
[01/18 06:48:20] detectron2.evaluation.evaluator INFO: Inference done 610/1093. Dataloading: 0.0116 s/iter. Inference: 0.1419 s/iter. Eval: 0.2096 s/iter. Total: 0.3632 s/iter. ETA=0:02:55
[01/18 06:48:25] detectron2.evaluation.evaluator INFO: Inference done 625/1093. Dataloading: 0.0116 s/iter. Inference: 0.1418 s/iter. Eval: 0.2092 s/iter. Total: 0.3628 s/iter. ETA=0:02:49
[01/18 06:48:31] detectron2.evaluation.evaluator INFO: Inference done 638/1093. Dataloading: 0.0116 s/iter. Inference: 0.1420 s/iter. Eval: 0.2097 s/iter. Total: 0.3634 s/iter. ETA=0:02:45
[01/18 06:48:36] detectron2.evaluation.evaluator INFO: Inference done 652/1093. Dataloading: 0.0116 s/iter. Inference: 0.1419 s/iter. Eval: 0.2101 s/iter. Total: 0.3637 s/iter. ETA=0:02:40
[01/18 06:48:41] detectron2.evaluation.evaluator INFO: Inference done 666/1093. Dataloading: 0.0116 s/iter. Inference: 0.1418 s/iter. Eval: 0.2103 s/iter. Total: 0.3639 s/iter. ETA=0:02:35
[01/18 06:48:46] detectron2.evaluation.evaluator INFO: Inference done 680/1093. Dataloading: 0.0116 s/iter. Inference: 0.1419 s/iter. Eval: 0.2106 s/iter. Total: 0.3642 s/iter. ETA=0:02:30
[01/18 06:48:51] detectron2.evaluation.evaluator INFO: Inference done 694/1093. Dataloading: 0.0116 s/iter. Inference: 0.1417 s/iter. Eval: 0.2108 s/iter. Total: 0.3643 s/iter. ETA=0:02:25
[01/18 06:48:57] detectron2.evaluation.evaluator INFO: Inference done 708/1093. Dataloading: 0.0116 s/iter. Inference: 0.1417 s/iter. Eval: 0.2108 s/iter. Total: 0.3642 s/iter. ETA=0:02:20
[01/18 06:49:02] detectron2.evaluation.evaluator INFO: Inference done 723/1093. Dataloading: 0.0116 s/iter. Inference: 0.1416 s/iter. Eval: 0.2104 s/iter. Total: 0.3638 s/iter. ETA=0:02:14
[01/18 06:49:07] detectron2.evaluation.evaluator INFO: Inference done 738/1093. Dataloading: 0.0116 s/iter. Inference: 0.1416 s/iter. Eval: 0.2101 s/iter. Total: 0.3634 s/iter. ETA=0:02:09
[01/18 06:49:12] detectron2.evaluation.evaluator INFO: Inference done 752/1093. Dataloading: 0.0116 s/iter. Inference: 0.1417 s/iter. Eval: 0.2099 s/iter. Total: 0.3633 s/iter. ETA=0:02:03
[01/18 06:49:17] detectron2.evaluation.evaluator INFO: Inference done 766/1093. Dataloading: 0.0116 s/iter. Inference: 0.1416 s/iter. Eval: 0.2099 s/iter. Total: 0.3632 s/iter. ETA=0:01:58
[01/18 06:49:22] detectron2.evaluation.evaluator INFO: Inference done 782/1093. Dataloading: 0.0116 s/iter. Inference: 0.1415 s/iter. Eval: 0.2093 s/iter. Total: 0.3625 s/iter. ETA=0:01:52
[01/18 06:49:27] detectron2.evaluation.evaluator INFO: Inference done 797/1093. Dataloading: 0.0116 s/iter. Inference: 0.1415 s/iter. Eval: 0.2091 s/iter. Total: 0.3623 s/iter. ETA=0:01:47
[01/18 06:49:33] detectron2.evaluation.evaluator INFO: Inference done 811/1093. Dataloading: 0.0116 s/iter. Inference: 0.1415 s/iter. Eval: 0.2094 s/iter. Total: 0.3626 s/iter. ETA=0:01:42
[01/18 06:49:38] detectron2.evaluation.evaluator INFO: Inference done 826/1093. Dataloading: 0.0116 s/iter. Inference: 0.1415 s/iter. Eval: 0.2091 s/iter. Total: 0.3623 s/iter. ETA=0:01:36
[01/18 06:49:43] detectron2.evaluation.evaluator INFO: Inference done 841/1093. Dataloading: 0.0116 s/iter. Inference: 0.1415 s/iter. Eval: 0.2088 s/iter. Total: 0.3620 s/iter. ETA=0:01:31
[01/18 06:49:48] detectron2.evaluation.evaluator INFO: Inference done 856/1093. Dataloading: 0.0115 s/iter. Inference: 0.1415 s/iter. Eval: 0.2087 s/iter. Total: 0.3619 s/iter. ETA=0:01:25
[01/18 06:49:53] detectron2.evaluation.evaluator INFO: Inference done 870/1093. Dataloading: 0.0115 s/iter. Inference: 0.1414 s/iter. Eval: 0.2088 s/iter. Total: 0.3618 s/iter. ETA=0:01:20
[01/18 06:49:59] detectron2.evaluation.evaluator INFO: Inference done 884/1093. Dataloading: 0.0116 s/iter. Inference: 0.1414 s/iter. Eval: 0.2090 s/iter. Total: 0.3621 s/iter. ETA=0:01:15
[01/18 06:50:04] detectron2.evaluation.evaluator INFO: Inference done 899/1093. Dataloading: 0.0116 s/iter. Inference: 0.1413 s/iter. Eval: 0.2089 s/iter. Total: 0.3618 s/iter. ETA=0:01:10
[01/18 06:50:09] detectron2.evaluation.evaluator INFO: Inference done 913/1093. Dataloading: 0.0116 s/iter. Inference: 0.1412 s/iter. Eval: 0.2090 s/iter. Total: 0.3620 s/iter. ETA=0:01:05
[01/18 06:50:14] detectron2.evaluation.evaluator INFO: Inference done 928/1093. Dataloading: 0.0116 s/iter. Inference: 0.1410 s/iter. Eval: 0.2089 s/iter. Total: 0.3616 s/iter. ETA=0:00:59
[01/18 06:50:19] detectron2.evaluation.evaluator INFO: Inference done 940/1093. Dataloading: 0.0116 s/iter. Inference: 0.1410 s/iter. Eval: 0.2096 s/iter. Total: 0.3624 s/iter. ETA=0:00:55
[01/18 06:50:24] detectron2.evaluation.evaluator INFO: Inference done 955/1093. Dataloading: 0.0116 s/iter. Inference: 0.1410 s/iter. Eval: 0.2094 s/iter. Total: 0.3621 s/iter. ETA=0:00:49
[01/18 06:50:30] detectron2.evaluation.evaluator INFO: Inference done 970/1093. Dataloading: 0.0116 s/iter. Inference: 0.1410 s/iter. Eval: 0.2091 s/iter. Total: 0.3618 s/iter. ETA=0:00:44
[01/18 06:50:35] detectron2.evaluation.evaluator INFO: Inference done 985/1093. Dataloading: 0.0116 s/iter. Inference: 0.1411 s/iter. Eval: 0.2086 s/iter. Total: 0.3614 s/iter. ETA=0:00:39
[01/18 06:50:40] detectron2.evaluation.evaluator INFO: Inference done 999/1093. Dataloading: 0.0116 s/iter. Inference: 0.1411 s/iter. Eval: 0.2086 s/iter. Total: 0.3614 s/iter. ETA=0:00:33
[01/18 06:50:45] detectron2.evaluation.evaluator INFO: Inference done 1013/1093. Dataloading: 0.0116 s/iter. Inference: 0.1412 s/iter. Eval: 0.2086 s/iter. Total: 0.3615 s/iter. ETA=0:00:28
[01/18 06:50:50] detectron2.evaluation.evaluator INFO: Inference done 1028/1093. Dataloading: 0.0115 s/iter. Inference: 0.1412 s/iter. Eval: 0.2083 s/iter. Total: 0.3612 s/iter. ETA=0:00:23
[01/18 06:50:55] detectron2.evaluation.evaluator INFO: Inference done 1044/1093. Dataloading: 0.0115 s/iter. Inference: 0.1412 s/iter. Eval: 0.2077 s/iter. Total: 0.3605 s/iter. ETA=0:00:17
[01/18 06:51:00] detectron2.evaluation.evaluator INFO: Inference done 1059/1093. Dataloading: 0.0115 s/iter. Inference: 0.1411 s/iter. Eval: 0.2075 s/iter. Total: 0.3602 s/iter. ETA=0:00:12
[01/18 06:51:05] detectron2.evaluation.evaluator INFO: Inference done 1074/1093. Dataloading: 0.0115 s/iter. Inference: 0.1411 s/iter. Eval: 0.2074 s/iter. Total: 0.3602 s/iter. ETA=0:00:06
[01/18 06:51:11] detectron2.evaluation.evaluator INFO: Inference done 1089/1093. Dataloading: 0.0115 s/iter. Inference: 0.1412 s/iter. Eval: 0.2073 s/iter. Total: 0.3600 s/iter. ETA=0:00:01
[01/18 06:51:12] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:31.890743 (0.360194 s / iter per device, on 4 devices)
[01/18 06:51:12] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:33 (0.141113 s / iter per device, on 4 devices)
[01/18 07:40:20] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 07:40:20] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 07:40:20] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 07:40:21] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 07:40:35] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0085 s/iter. Inference: 0.1567 s/iter. Eval: 0.2153 s/iter. Total: 0.3805 s/iter. ETA=0:06:51
[01/18 07:40:40] detectron2.evaluation.evaluator INFO: Inference done 23/1093. Dataloading: 0.0116 s/iter. Inference: 0.1528 s/iter. Eval: 0.2502 s/iter. Total: 0.4147 s/iter. ETA=0:07:23
[01/18 07:40:45] detectron2.evaluation.evaluator INFO: Inference done 35/1093. Dataloading: 0.0125 s/iter. Inference: 0.1457 s/iter. Eval: 0.2601 s/iter. Total: 0.4184 s/iter. ETA=0:07:22
[01/18 07:40:50] detectron2.evaluation.evaluator INFO: Inference done 48/1093. Dataloading: 0.0126 s/iter. Inference: 0.1473 s/iter. Eval: 0.2521 s/iter. Total: 0.4121 s/iter. ETA=0:07:10
[01/18 07:40:56] detectron2.evaluation.evaluator INFO: Inference done 63/1093. Dataloading: 0.0120 s/iter. Inference: 0.1446 s/iter. Eval: 0.2395 s/iter. Total: 0.3962 s/iter. ETA=0:06:48
[01/18 07:41:01] detectron2.evaluation.evaluator INFO: Inference done 76/1093. Dataloading: 0.0121 s/iter. Inference: 0.1449 s/iter. Eval: 0.2412 s/iter. Total: 0.3983 s/iter. ETA=0:06:45
[01/18 07:41:06] detectron2.evaluation.evaluator INFO: Inference done 92/1093. Dataloading: 0.0117 s/iter. Inference: 0.1445 s/iter. Eval: 0.2291 s/iter. Total: 0.3854 s/iter. ETA=0:06:25
[01/18 07:41:11] detectron2.evaluation.evaluator INFO: Inference done 107/1093. Dataloading: 0.0114 s/iter. Inference: 0.1445 s/iter. Eval: 0.2237 s/iter. Total: 0.3796 s/iter. ETA=0:06:14
[01/18 07:41:17] detectron2.evaluation.evaluator INFO: Inference done 122/1093. Dataloading: 0.0120 s/iter. Inference: 0.1442 s/iter. Eval: 0.2181 s/iter. Total: 0.3744 s/iter. ETA=0:06:03
[01/18 07:41:22] detectron2.evaluation.evaluator INFO: Inference done 137/1093. Dataloading: 0.0118 s/iter. Inference: 0.1441 s/iter. Eval: 0.2139 s/iter. Total: 0.3699 s/iter. ETA=0:05:53
[01/18 07:41:27] detectron2.evaluation.evaluator INFO: Inference done 153/1093. Dataloading: 0.0116 s/iter. Inference: 0.1441 s/iter. Eval: 0.2095 s/iter. Total: 0.3653 s/iter. ETA=0:05:43
[01/18 07:41:32] detectron2.evaluation.evaluator INFO: Inference done 168/1093. Dataloading: 0.0115 s/iter. Inference: 0.1436 s/iter. Eval: 0.2086 s/iter. Total: 0.3638 s/iter. ETA=0:05:36
[01/18 07:41:37] detectron2.evaluation.evaluator INFO: Inference done 182/1093. Dataloading: 0.0115 s/iter. Inference: 0.1435 s/iter. Eval: 0.2087 s/iter. Total: 0.3638 s/iter. ETA=0:05:31
[01/18 07:41:43] detectron2.evaluation.evaluator INFO: Inference done 198/1093. Dataloading: 0.0114 s/iter. Inference: 0.1428 s/iter. Eval: 0.2078 s/iter. Total: 0.3620 s/iter. ETA=0:05:24
[01/18 07:41:48] detectron2.evaluation.evaluator INFO: Inference done 213/1093. Dataloading: 0.0115 s/iter. Inference: 0.1422 s/iter. Eval: 0.2073 s/iter. Total: 0.3611 s/iter. ETA=0:05:17
[01/18 07:41:53] detectron2.evaluation.evaluator INFO: Inference done 229/1093. Dataloading: 0.0113 s/iter. Inference: 0.1420 s/iter. Eval: 0.2052 s/iter. Total: 0.3586 s/iter. ETA=0:05:09
[01/18 07:41:58] detectron2.evaluation.evaluator INFO: Inference done 243/1093. Dataloading: 0.0113 s/iter. Inference: 0.1423 s/iter. Eval: 0.2054 s/iter. Total: 0.3592 s/iter. ETA=0:05:05
[01/18 07:42:03] detectron2.evaluation.evaluator INFO: Inference done 257/1093. Dataloading: 0.0114 s/iter. Inference: 0.1423 s/iter. Eval: 0.2062 s/iter. Total: 0.3601 s/iter. ETA=0:05:01
[01/18 07:42:09] detectron2.evaluation.evaluator INFO: Inference done 271/1093. Dataloading: 0.0114 s/iter. Inference: 0.1426 s/iter. Eval: 0.2068 s/iter. Total: 0.3609 s/iter. ETA=0:04:56
[01/18 07:42:14] detectron2.evaluation.evaluator INFO: Inference done 285/1093. Dataloading: 0.0113 s/iter. Inference: 0.1429 s/iter. Eval: 0.2071 s/iter. Total: 0.3614 s/iter. ETA=0:04:52
[01/18 07:42:19] detectron2.evaluation.evaluator INFO: Inference done 298/1093. Dataloading: 0.0114 s/iter. Inference: 0.1427 s/iter. Eval: 0.2087 s/iter. Total: 0.3630 s/iter. ETA=0:04:48
[01/18 07:42:24] detectron2.evaluation.evaluator INFO: Inference done 313/1093. Dataloading: 0.0113 s/iter. Inference: 0.1434 s/iter. Eval: 0.2071 s/iter. Total: 0.3620 s/iter. ETA=0:04:42
[01/18 07:42:29] detectron2.evaluation.evaluator INFO: Inference done 329/1093. Dataloading: 0.0112 s/iter. Inference: 0.1431 s/iter. Eval: 0.2052 s/iter. Total: 0.3597 s/iter. ETA=0:04:34
[01/18 07:42:34] detectron2.evaluation.evaluator INFO: Inference done 344/1093. Dataloading: 0.0112 s/iter. Inference: 0.1431 s/iter. Eval: 0.2046 s/iter. Total: 0.3591 s/iter. ETA=0:04:28
[01/18 07:42:40] detectron2.evaluation.evaluator INFO: Inference done 359/1093. Dataloading: 0.0112 s/iter. Inference: 0.1426 s/iter. Eval: 0.2044 s/iter. Total: 0.3583 s/iter. ETA=0:04:22
[01/18 07:42:45] detectron2.evaluation.evaluator INFO: Inference done 375/1093. Dataloading: 0.0111 s/iter. Inference: 0.1422 s/iter. Eval: 0.2033 s/iter. Total: 0.3567 s/iter. ETA=0:04:16
[01/18 07:42:50] detectron2.evaluation.evaluator INFO: Inference done 388/1093. Dataloading: 0.0112 s/iter. Inference: 0.1421 s/iter. Eval: 0.2049 s/iter. Total: 0.3583 s/iter. ETA=0:04:12
[01/18 07:42:55] detectron2.evaluation.evaluator INFO: Inference done 401/1093. Dataloading: 0.0113 s/iter. Inference: 0.1422 s/iter. Eval: 0.2057 s/iter. Total: 0.3593 s/iter. ETA=0:04:08
[01/18 07:43:00] detectron2.evaluation.evaluator INFO: Inference done 414/1093. Dataloading: 0.0113 s/iter. Inference: 0.1423 s/iter. Eval: 0.2073 s/iter. Total: 0.3610 s/iter. ETA=0:04:05
[01/18 07:43:06] detectron2.evaluation.evaluator INFO: Inference done 428/1093. Dataloading: 0.0113 s/iter. Inference: 0.1423 s/iter. Eval: 0.2074 s/iter. Total: 0.3611 s/iter. ETA=0:04:00
[01/18 07:43:11] detectron2.evaluation.evaluator INFO: Inference done 442/1093. Dataloading: 0.0113 s/iter. Inference: 0.1425 s/iter. Eval: 0.2079 s/iter. Total: 0.3618 s/iter. ETA=0:03:55
[01/18 07:43:16] detectron2.evaluation.evaluator INFO: Inference done 459/1093. Dataloading: 0.0112 s/iter. Inference: 0.1424 s/iter. Eval: 0.2063 s/iter. Total: 0.3600 s/iter. ETA=0:03:48
[01/18 07:43:21] detectron2.evaluation.evaluator INFO: Inference done 473/1093. Dataloading: 0.0112 s/iter. Inference: 0.1425 s/iter. Eval: 0.2065 s/iter. Total: 0.3602 s/iter. ETA=0:03:43
[01/18 07:43:26] detectron2.evaluation.evaluator INFO: Inference done 490/1093. Dataloading: 0.0111 s/iter. Inference: 0.1419 s/iter. Eval: 0.2051 s/iter. Total: 0.3582 s/iter. ETA=0:03:36
[01/18 07:43:32] detectron2.evaluation.evaluator INFO: Inference done 504/1093. Dataloading: 0.0112 s/iter. Inference: 0.1420 s/iter. Eval: 0.2057 s/iter. Total: 0.3589 s/iter. ETA=0:03:31
[01/18 07:43:37] detectron2.evaluation.evaluator INFO: Inference done 518/1093. Dataloading: 0.0112 s/iter. Inference: 0.1420 s/iter. Eval: 0.2058 s/iter. Total: 0.3591 s/iter. ETA=0:03:26
[01/18 07:43:42] detectron2.evaluation.evaluator INFO: Inference done 532/1093. Dataloading: 0.0112 s/iter. Inference: 0.1418 s/iter. Eval: 0.2061 s/iter. Total: 0.3592 s/iter. ETA=0:03:21
[01/18 07:43:47] detectron2.evaluation.evaluator INFO: Inference done 546/1093. Dataloading: 0.0111 s/iter. Inference: 0.1421 s/iter. Eval: 0.2058 s/iter. Total: 0.3592 s/iter. ETA=0:03:16
[01/18 07:43:52] detectron2.evaluation.evaluator INFO: Inference done 560/1093. Dataloading: 0.0112 s/iter. Inference: 0.1420 s/iter. Eval: 0.2061 s/iter. Total: 0.3593 s/iter. ETA=0:03:11
[01/18 07:43:57] detectron2.evaluation.evaluator INFO: Inference done 574/1093. Dataloading: 0.0111 s/iter. Inference: 0.1417 s/iter. Eval: 0.2066 s/iter. Total: 0.3596 s/iter. ETA=0:03:06
[01/18 07:44:02] detectron2.evaluation.evaluator INFO: Inference done 588/1093. Dataloading: 0.0111 s/iter. Inference: 0.1416 s/iter. Eval: 0.2069 s/iter. Total: 0.3597 s/iter. ETA=0:03:01
[01/18 07:44:08] detectron2.evaluation.evaluator INFO: Inference done 602/1093. Dataloading: 0.0111 s/iter. Inference: 0.1416 s/iter. Eval: 0.2073 s/iter. Total: 0.3601 s/iter. ETA=0:02:56
[01/18 07:44:13] detectron2.evaluation.evaluator INFO: Inference done 617/1093. Dataloading: 0.0111 s/iter. Inference: 0.1415 s/iter. Eval: 0.2071 s/iter. Total: 0.3598 s/iter. ETA=0:02:51
[01/18 07:44:18] detectron2.evaluation.evaluator INFO: Inference done 631/1093. Dataloading: 0.0112 s/iter. Inference: 0.1415 s/iter. Eval: 0.2070 s/iter. Total: 0.3598 s/iter. ETA=0:02:46
[01/18 07:44:23] detectron2.evaluation.evaluator INFO: Inference done 645/1093. Dataloading: 0.0111 s/iter. Inference: 0.1414 s/iter. Eval: 0.2072 s/iter. Total: 0.3598 s/iter. ETA=0:02:41
[01/18 07:44:28] detectron2.evaluation.evaluator INFO: Inference done 658/1093. Dataloading: 0.0112 s/iter. Inference: 0.1414 s/iter. Eval: 0.2077 s/iter. Total: 0.3604 s/iter. ETA=0:02:36
[01/18 07:44:33] detectron2.evaluation.evaluator INFO: Inference done 672/1093. Dataloading: 0.0112 s/iter. Inference: 0.1415 s/iter. Eval: 0.2078 s/iter. Total: 0.3606 s/iter. ETA=0:02:31
[01/18 07:44:38] detectron2.evaluation.evaluator INFO: Inference done 686/1093. Dataloading: 0.0112 s/iter. Inference: 0.1414 s/iter. Eval: 0.2079 s/iter. Total: 0.3605 s/iter. ETA=0:02:26
[01/18 07:44:43] detectron2.evaluation.evaluator INFO: Inference done 700/1093. Dataloading: 0.0112 s/iter. Inference: 0.1413 s/iter. Eval: 0.2081 s/iter. Total: 0.3606 s/iter. ETA=0:02:21
[01/18 07:44:49] detectron2.evaluation.evaluator INFO: Inference done 716/1093. Dataloading: 0.0111 s/iter. Inference: 0.1413 s/iter. Eval: 0.2073 s/iter. Total: 0.3598 s/iter. ETA=0:02:15
[01/18 07:44:54] detectron2.evaluation.evaluator INFO: Inference done 733/1093. Dataloading: 0.0111 s/iter. Inference: 0.1410 s/iter. Eval: 0.2066 s/iter. Total: 0.3588 s/iter. ETA=0:02:09
[01/18 07:44:59] detectron2.evaluation.evaluator INFO: Inference done 748/1093. Dataloading: 0.0111 s/iter. Inference: 0.1411 s/iter. Eval: 0.2064 s/iter. Total: 0.3586 s/iter. ETA=0:02:03
[01/18 07:45:04] detectron2.evaluation.evaluator INFO: Inference done 762/1093. Dataloading: 0.0111 s/iter. Inference: 0.1411 s/iter. Eval: 0.2065 s/iter. Total: 0.3588 s/iter. ETA=0:01:58
[01/18 07:45:09] detectron2.evaluation.evaluator INFO: Inference done 776/1093. Dataloading: 0.0111 s/iter. Inference: 0.1411 s/iter. Eval: 0.2066 s/iter. Total: 0.3589 s/iter. ETA=0:01:53
[01/18 07:45:15] detectron2.evaluation.evaluator INFO: Inference done 792/1093. Dataloading: 0.0111 s/iter. Inference: 0.1409 s/iter. Eval: 0.2063 s/iter. Total: 0.3584 s/iter. ETA=0:01:47
[01/18 07:45:20] detectron2.evaluation.evaluator INFO: Inference done 806/1093. Dataloading: 0.0111 s/iter. Inference: 0.1410 s/iter. Eval: 0.2063 s/iter. Total: 0.3585 s/iter. ETA=0:01:42
[01/18 07:45:25] detectron2.evaluation.evaluator INFO: Inference done 821/1093. Dataloading: 0.0111 s/iter. Inference: 0.1409 s/iter. Eval: 0.2061 s/iter. Total: 0.3582 s/iter. ETA=0:01:37
[01/18 07:45:30] detectron2.evaluation.evaluator INFO: Inference done 836/1093. Dataloading: 0.0111 s/iter. Inference: 0.1409 s/iter. Eval: 0.2061 s/iter. Total: 0.3582 s/iter. ETA=0:01:32
[01/18 07:45:36] detectron2.evaluation.evaluator INFO: Inference done 852/1093. Dataloading: 0.0111 s/iter. Inference: 0.1409 s/iter. Eval: 0.2056 s/iter. Total: 0.3577 s/iter. ETA=0:01:26
[01/18 07:45:41] detectron2.evaluation.evaluator INFO: Inference done 866/1093. Dataloading: 0.0111 s/iter. Inference: 0.1408 s/iter. Eval: 0.2057 s/iter. Total: 0.3578 s/iter. ETA=0:01:21
[01/18 07:45:46] detectron2.evaluation.evaluator INFO: Inference done 881/1093. Dataloading: 0.0111 s/iter. Inference: 0.1407 s/iter. Eval: 0.2055 s/iter. Total: 0.3574 s/iter. ETA=0:01:15
[01/18 07:45:51] detectron2.evaluation.evaluator INFO: Inference done 896/1093. Dataloading: 0.0111 s/iter. Inference: 0.1406 s/iter. Eval: 0.2055 s/iter. Total: 0.3573 s/iter. ETA=0:01:10
[01/18 07:45:56] detectron2.evaluation.evaluator INFO: Inference done 911/1093. Dataloading: 0.0111 s/iter. Inference: 0.1405 s/iter. Eval: 0.2055 s/iter. Total: 0.3572 s/iter. ETA=0:01:05
[01/18 07:46:02] detectron2.evaluation.evaluator INFO: Inference done 925/1093. Dataloading: 0.0111 s/iter. Inference: 0.1405 s/iter. Eval: 0.2057 s/iter. Total: 0.3574 s/iter. ETA=0:01:00
[01/18 07:46:07] detectron2.evaluation.evaluator INFO: Inference done 939/1093. Dataloading: 0.0111 s/iter. Inference: 0.1404 s/iter. Eval: 0.2059 s/iter. Total: 0.3575 s/iter. ETA=0:00:55
[01/18 07:46:12] detectron2.evaluation.evaluator INFO: Inference done 952/1093. Dataloading: 0.0111 s/iter. Inference: 0.1406 s/iter. Eval: 0.2062 s/iter. Total: 0.3579 s/iter. ETA=0:00:50
[01/18 07:46:17] detectron2.evaluation.evaluator INFO: Inference done 967/1093. Dataloading: 0.0111 s/iter. Inference: 0.1405 s/iter. Eval: 0.2059 s/iter. Total: 0.3576 s/iter. ETA=0:00:45
[01/18 07:46:22] detectron2.evaluation.evaluator INFO: Inference done 984/1093. Dataloading: 0.0111 s/iter. Inference: 0.1404 s/iter. Eval: 0.2049 s/iter. Total: 0.3565 s/iter. ETA=0:00:38
[01/18 07:46:27] detectron2.evaluation.evaluator INFO: Inference done 1000/1093. Dataloading: 0.0110 s/iter. Inference: 0.1404 s/iter. Eval: 0.2044 s/iter. Total: 0.3559 s/iter. ETA=0:00:33
[01/18 07:46:32] detectron2.evaluation.evaluator INFO: Inference done 1014/1093. Dataloading: 0.0110 s/iter. Inference: 0.1405 s/iter. Eval: 0.2046 s/iter. Total: 0.3562 s/iter. ETA=0:00:28
[01/18 07:46:37] detectron2.evaluation.evaluator INFO: Inference done 1029/1093. Dataloading: 0.0110 s/iter. Inference: 0.1405 s/iter. Eval: 0.2043 s/iter. Total: 0.3559 s/iter. ETA=0:00:22
[01/18 07:46:42] detectron2.evaluation.evaluator INFO: Inference done 1045/1093. Dataloading: 0.0110 s/iter. Inference: 0.1404 s/iter. Eval: 0.2038 s/iter. Total: 0.3553 s/iter. ETA=0:00:17
[01/18 07:46:47] detectron2.evaluation.evaluator INFO: Inference done 1058/1093. Dataloading: 0.0110 s/iter. Inference: 0.1405 s/iter. Eval: 0.2042 s/iter. Total: 0.3558 s/iter. ETA=0:00:12
[01/18 07:46:52] detectron2.evaluation.evaluator INFO: Inference done 1072/1093. Dataloading: 0.0110 s/iter. Inference: 0.1406 s/iter. Eval: 0.2042 s/iter. Total: 0.3558 s/iter. ETA=0:00:07
[01/18 07:46:58] detectron2.evaluation.evaluator INFO: Inference done 1087/1093. Dataloading: 0.0110 s/iter. Inference: 0.1406 s/iter. Eval: 0.2041 s/iter. Total: 0.3558 s/iter. ETA=0:00:02
[01/18 07:47:00] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:27.423281 (0.356088 s / iter per device, on 4 devices)
[01/18 07:47:00] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:32 (0.140605 s / iter per device, on 4 devices)
[01/18 08:36:08] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 08:36:09] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 08:36:09] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 08:36:10] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 08:36:24] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0101 s/iter. Inference: 0.1459 s/iter. Eval: 0.2085 s/iter. Total: 0.3645 s/iter. ETA=0:06:34
[01/18 08:36:29] detectron2.evaluation.evaluator INFO: Inference done 24/1093. Dataloading: 0.0119 s/iter. Inference: 0.1387 s/iter. Eval: 0.2335 s/iter. Total: 0.3842 s/iter. ETA=0:06:50
[01/18 08:36:34] detectron2.evaluation.evaluator INFO: Inference done 35/1093. Dataloading: 0.0130 s/iter. Inference: 0.1414 s/iter. Eval: 0.2577 s/iter. Total: 0.4122 s/iter. ETA=0:07:16
[01/18 08:36:39] detectron2.evaluation.evaluator INFO: Inference done 47/1093. Dataloading: 0.0133 s/iter. Inference: 0.1424 s/iter. Eval: 0.2584 s/iter. Total: 0.4142 s/iter. ETA=0:07:13
[01/18 08:36:44] detectron2.evaluation.evaluator INFO: Inference done 61/1093. Dataloading: 0.0129 s/iter. Inference: 0.1420 s/iter. Eval: 0.2455 s/iter. Total: 0.4005 s/iter. ETA=0:06:53
[01/18 08:36:50] detectron2.evaluation.evaluator INFO: Inference done 73/1093. Dataloading: 0.0131 s/iter. Inference: 0.1435 s/iter. Eval: 0.2478 s/iter. Total: 0.4046 s/iter. ETA=0:06:52
[01/18 08:36:55] detectron2.evaluation.evaluator INFO: Inference done 88/1093. Dataloading: 0.0129 s/iter. Inference: 0.1448 s/iter. Eval: 0.2375 s/iter. Total: 0.3953 s/iter. ETA=0:06:37
[01/18 08:37:00] detectron2.evaluation.evaluator INFO: Inference done 104/1093. Dataloading: 0.0126 s/iter. Inference: 0.1450 s/iter. Eval: 0.2270 s/iter. Total: 0.3847 s/iter. ETA=0:06:20
[01/18 08:37:05] detectron2.evaluation.evaluator INFO: Inference done 118/1093. Dataloading: 0.0125 s/iter. Inference: 0.1453 s/iter. Eval: 0.2238 s/iter. Total: 0.3817 s/iter. ETA=0:06:12
[01/18 08:37:10] detectron2.evaluation.evaluator INFO: Inference done 132/1093. Dataloading: 0.0124 s/iter. Inference: 0.1445 s/iter. Eval: 0.2220 s/iter. Total: 0.3790 s/iter. ETA=0:06:04
[01/18 08:37:16] detectron2.evaluation.evaluator INFO: Inference done 149/1093. Dataloading: 0.0122 s/iter. Inference: 0.1436 s/iter. Eval: 0.2156 s/iter. Total: 0.3715 s/iter. ETA=0:05:50
[01/18 08:37:21] detectron2.evaluation.evaluator INFO: Inference done 162/1093. Dataloading: 0.0122 s/iter. Inference: 0.1439 s/iter. Eval: 0.2170 s/iter. Total: 0.3733 s/iter. ETA=0:05:47
[01/18 08:37:26] detectron2.evaluation.evaluator INFO: Inference done 175/1093. Dataloading: 0.0122 s/iter. Inference: 0.1444 s/iter. Eval: 0.2177 s/iter. Total: 0.3744 s/iter. ETA=0:05:43
[01/18 08:37:31] detectron2.evaluation.evaluator INFO: Inference done 190/1093. Dataloading: 0.0120 s/iter. Inference: 0.1443 s/iter. Eval: 0.2167 s/iter. Total: 0.3731 s/iter. ETA=0:05:36
[01/18 08:37:37] detectron2.evaluation.evaluator INFO: Inference done 204/1093. Dataloading: 0.0121 s/iter. Inference: 0.1439 s/iter. Eval: 0.2186 s/iter. Total: 0.3747 s/iter. ETA=0:05:33
[01/18 08:37:42] detectron2.evaluation.evaluator INFO: Inference done 220/1093. Dataloading: 0.0119 s/iter. Inference: 0.1438 s/iter. Eval: 0.2143 s/iter. Total: 0.3701 s/iter. ETA=0:05:23
[01/18 08:37:47] detectron2.evaluation.evaluator INFO: Inference done 235/1093. Dataloading: 0.0124 s/iter. Inference: 0.1433 s/iter. Eval: 0.2121 s/iter. Total: 0.3679 s/iter. ETA=0:05:15
[01/18 08:37:52] detectron2.evaluation.evaluator INFO: Inference done 249/1093. Dataloading: 0.0124 s/iter. Inference: 0.1433 s/iter. Eval: 0.2119 s/iter. Total: 0.3677 s/iter. ETA=0:05:10
[01/18 08:37:57] detectron2.evaluation.evaluator INFO: Inference done 264/1093. Dataloading: 0.0124 s/iter. Inference: 0.1427 s/iter. Eval: 0.2117 s/iter. Total: 0.3670 s/iter. ETA=0:05:04
[01/18 08:38:03] detectron2.evaluation.evaluator INFO: Inference done 279/1093. Dataloading: 0.0124 s/iter. Inference: 0.1430 s/iter. Eval: 0.2113 s/iter. Total: 0.3667 s/iter. ETA=0:04:58
[01/18 08:38:08] detectron2.evaluation.evaluator INFO: Inference done 293/1093. Dataloading: 0.0124 s/iter. Inference: 0.1425 s/iter. Eval: 0.2117 s/iter. Total: 0.3667 s/iter. ETA=0:04:53
[01/18 08:38:13] detectron2.evaluation.evaluator INFO: Inference done 307/1093. Dataloading: 0.0124 s/iter. Inference: 0.1427 s/iter. Eval: 0.2117 s/iter. Total: 0.3669 s/iter. ETA=0:04:48
[01/18 08:38:18] detectron2.evaluation.evaluator INFO: Inference done 323/1093. Dataloading: 0.0123 s/iter. Inference: 0.1429 s/iter. Eval: 0.2095 s/iter. Total: 0.3647 s/iter. ETA=0:04:40
[01/18 08:38:23] detectron2.evaluation.evaluator INFO: Inference done 339/1093. Dataloading: 0.0122 s/iter. Inference: 0.1428 s/iter. Eval: 0.2085 s/iter. Total: 0.3635 s/iter. ETA=0:04:34
[01/18 08:38:29] detectron2.evaluation.evaluator INFO: Inference done 354/1093. Dataloading: 0.0122 s/iter. Inference: 0.1425 s/iter. Eval: 0.2084 s/iter. Total: 0.3632 s/iter. ETA=0:04:28
[01/18 08:38:34] detectron2.evaluation.evaluator INFO: Inference done 368/1093. Dataloading: 0.0122 s/iter. Inference: 0.1426 s/iter. Eval: 0.2087 s/iter. Total: 0.3636 s/iter. ETA=0:04:23
[01/18 08:38:39] detectron2.evaluation.evaluator INFO: Inference done 382/1093. Dataloading: 0.0122 s/iter. Inference: 0.1427 s/iter. Eval: 0.2094 s/iter. Total: 0.3644 s/iter. ETA=0:04:19
[01/18 08:38:45] detectron2.evaluation.evaluator INFO: Inference done 396/1093. Dataloading: 0.0122 s/iter. Inference: 0.1426 s/iter. Eval: 0.2097 s/iter. Total: 0.3646 s/iter. ETA=0:04:14
[01/18 08:38:50] detectron2.evaluation.evaluator INFO: Inference done 408/1093. Dataloading: 0.0122 s/iter. Inference: 0.1427 s/iter. Eval: 0.2111 s/iter. Total: 0.3662 s/iter. ETA=0:04:10
[01/18 08:38:55] detectron2.evaluation.evaluator INFO: Inference done 421/1093. Dataloading: 0.0123 s/iter. Inference: 0.1429 s/iter. Eval: 0.2121 s/iter. Total: 0.3674 s/iter. ETA=0:04:06
[01/18 08:39:00] detectron2.evaluation.evaluator INFO: Inference done 436/1093. Dataloading: 0.0122 s/iter. Inference: 0.1429 s/iter. Eval: 0.2115 s/iter. Total: 0.3667 s/iter. ETA=0:04:00
[01/18 08:39:05] detectron2.evaluation.evaluator INFO: Inference done 452/1093. Dataloading: 0.0122 s/iter. Inference: 0.1428 s/iter. Eval: 0.2099 s/iter. Total: 0.3650 s/iter. ETA=0:03:53
[01/18 08:39:11] detectron2.evaluation.evaluator INFO: Inference done 466/1093. Dataloading: 0.0122 s/iter. Inference: 0.1430 s/iter. Eval: 0.2103 s/iter. Total: 0.3656 s/iter. ETA=0:03:49
[01/18 08:39:16] detectron2.evaluation.evaluator INFO: Inference done 480/1093. Dataloading: 0.0122 s/iter. Inference: 0.1430 s/iter. Eval: 0.2103 s/iter. Total: 0.3656 s/iter. ETA=0:03:44
[01/18 08:39:21] detectron2.evaluation.evaluator INFO: Inference done 493/1093. Dataloading: 0.0122 s/iter. Inference: 0.1432 s/iter. Eval: 0.2107 s/iter. Total: 0.3662 s/iter. ETA=0:03:39
[01/18 08:39:26] detectron2.evaluation.evaluator INFO: Inference done 506/1093. Dataloading: 0.0122 s/iter. Inference: 0.1432 s/iter. Eval: 0.2114 s/iter. Total: 0.3669 s/iter. ETA=0:03:35
[01/18 08:39:31] detectron2.evaluation.evaluator INFO: Inference done 519/1093. Dataloading: 0.0121 s/iter. Inference: 0.1435 s/iter. Eval: 0.2124 s/iter. Total: 0.3681 s/iter. ETA=0:03:31
[01/18 08:39:36] detectron2.evaluation.evaluator INFO: Inference done 533/1093. Dataloading: 0.0122 s/iter. Inference: 0.1433 s/iter. Eval: 0.2124 s/iter. Total: 0.3680 s/iter. ETA=0:03:26
[01/18 08:39:41] detectron2.evaluation.evaluator INFO: Inference done 547/1093. Dataloading: 0.0121 s/iter. Inference: 0.1433 s/iter. Eval: 0.2124 s/iter. Total: 0.3679 s/iter. ETA=0:03:20
[01/18 08:39:47] detectron2.evaluation.evaluator INFO: Inference done 562/1093. Dataloading: 0.0121 s/iter. Inference: 0.1432 s/iter. Eval: 0.2121 s/iter. Total: 0.3675 s/iter. ETA=0:03:15
[01/18 08:39:52] detectron2.evaluation.evaluator INFO: Inference done 575/1093. Dataloading: 0.0121 s/iter. Inference: 0.1431 s/iter. Eval: 0.2130 s/iter. Total: 0.3683 s/iter. ETA=0:03:10
[01/18 08:39:57] detectron2.evaluation.evaluator INFO: Inference done 589/1093. Dataloading: 0.0121 s/iter. Inference: 0.1430 s/iter. Eval: 0.2129 s/iter. Total: 0.3681 s/iter. ETA=0:03:05
[01/18 08:40:02] detectron2.evaluation.evaluator INFO: Inference done 603/1093. Dataloading: 0.0121 s/iter. Inference: 0.1429 s/iter. Eval: 0.2128 s/iter. Total: 0.3679 s/iter. ETA=0:03:00
[01/18 08:40:07] detectron2.evaluation.evaluator INFO: Inference done 617/1093. Dataloading: 0.0121 s/iter. Inference: 0.1431 s/iter. Eval: 0.2124 s/iter. Total: 0.3677 s/iter. ETA=0:02:55
[01/18 08:40:12] detectron2.evaluation.evaluator INFO: Inference done 632/1093. Dataloading: 0.0121 s/iter. Inference: 0.1429 s/iter. Eval: 0.2119 s/iter. Total: 0.3671 s/iter. ETA=0:02:49
[01/18 08:40:17] detectron2.evaluation.evaluator INFO: Inference done 645/1093. Dataloading: 0.0121 s/iter. Inference: 0.1430 s/iter. Eval: 0.2122 s/iter. Total: 0.3675 s/iter. ETA=0:02:44
[01/18 08:40:23] detectron2.evaluation.evaluator INFO: Inference done 659/1093. Dataloading: 0.0121 s/iter. Inference: 0.1429 s/iter. Eval: 0.2126 s/iter. Total: 0.3677 s/iter. ETA=0:02:39
[01/18 08:40:28] detectron2.evaluation.evaluator INFO: Inference done 673/1093. Dataloading: 0.0121 s/iter. Inference: 0.1430 s/iter. Eval: 0.2127 s/iter. Total: 0.3679 s/iter. ETA=0:02:34
[01/18 08:40:33] detectron2.evaluation.evaluator INFO: Inference done 687/1093. Dataloading: 0.0121 s/iter. Inference: 0.1429 s/iter. Eval: 0.2130 s/iter. Total: 0.3682 s/iter. ETA=0:02:29
[01/18 08:40:38] detectron2.evaluation.evaluator INFO: Inference done 701/1093. Dataloading: 0.0121 s/iter. Inference: 0.1429 s/iter. Eval: 0.2130 s/iter. Total: 0.3681 s/iter. ETA=0:02:24
[01/18 08:40:43] detectron2.evaluation.evaluator INFO: Inference done 716/1093. Dataloading: 0.0120 s/iter. Inference: 0.1429 s/iter. Eval: 0.2124 s/iter. Total: 0.3675 s/iter. ETA=0:02:18
[01/18 08:40:49] detectron2.evaluation.evaluator INFO: Inference done 731/1093. Dataloading: 0.0120 s/iter. Inference: 0.1428 s/iter. Eval: 0.2121 s/iter. Total: 0.3671 s/iter. ETA=0:02:12
[01/18 08:40:54] detectron2.evaluation.evaluator INFO: Inference done 747/1093. Dataloading: 0.0120 s/iter. Inference: 0.1428 s/iter. Eval: 0.2114 s/iter. Total: 0.3663 s/iter. ETA=0:02:06
[01/18 08:40:59] detectron2.evaluation.evaluator INFO: Inference done 760/1093. Dataloading: 0.0120 s/iter. Inference: 0.1428 s/iter. Eval: 0.2117 s/iter. Total: 0.3666 s/iter. ETA=0:02:02
[01/18 08:41:04] detectron2.evaluation.evaluator INFO: Inference done 775/1093. Dataloading: 0.0120 s/iter. Inference: 0.1427 s/iter. Eval: 0.2115 s/iter. Total: 0.3662 s/iter. ETA=0:01:56
[01/18 08:41:09] detectron2.evaluation.evaluator INFO: Inference done 789/1093. Dataloading: 0.0120 s/iter. Inference: 0.1427 s/iter. Eval: 0.2117 s/iter. Total: 0.3665 s/iter. ETA=0:01:51
[01/18 08:41:15] detectron2.evaluation.evaluator INFO: Inference done 803/1093. Dataloading: 0.0120 s/iter. Inference: 0.1427 s/iter. Eval: 0.2117 s/iter. Total: 0.3665 s/iter. ETA=0:01:46
[01/18 08:41:20] detectron2.evaluation.evaluator INFO: Inference done 817/1093. Dataloading: 0.0119 s/iter. Inference: 0.1428 s/iter. Eval: 0.2118 s/iter. Total: 0.3666 s/iter. ETA=0:01:41
[01/18 08:41:25] detectron2.evaluation.evaluator INFO: Inference done 832/1093. Dataloading: 0.0119 s/iter. Inference: 0.1427 s/iter. Eval: 0.2115 s/iter. Total: 0.3662 s/iter. ETA=0:01:35
[01/18 08:41:30] detectron2.evaluation.evaluator INFO: Inference done 847/1093. Dataloading: 0.0119 s/iter. Inference: 0.1427 s/iter. Eval: 0.2109 s/iter. Total: 0.3657 s/iter. ETA=0:01:29
[01/18 08:41:35] detectron2.evaluation.evaluator INFO: Inference done 860/1093. Dataloading: 0.0119 s/iter. Inference: 0.1428 s/iter. Eval: 0.2113 s/iter. Total: 0.3661 s/iter. ETA=0:01:25
[01/18 08:41:40] detectron2.evaluation.evaluator INFO: Inference done 873/1093. Dataloading: 0.0119 s/iter. Inference: 0.1428 s/iter. Eval: 0.2118 s/iter. Total: 0.3667 s/iter. ETA=0:01:20
[01/18 08:41:45] detectron2.evaluation.evaluator INFO: Inference done 888/1093. Dataloading: 0.0119 s/iter. Inference: 0.1426 s/iter. Eval: 0.2115 s/iter. Total: 0.3662 s/iter. ETA=0:01:15
[01/18 08:41:50] detectron2.evaluation.evaluator INFO: Inference done 903/1093. Dataloading: 0.0119 s/iter. Inference: 0.1425 s/iter. Eval: 0.2112 s/iter. Total: 0.3657 s/iter. ETA=0:01:09
[01/18 08:41:56] detectron2.evaluation.evaluator INFO: Inference done 917/1093. Dataloading: 0.0119 s/iter. Inference: 0.1425 s/iter. Eval: 0.2113 s/iter. Total: 0.3658 s/iter. ETA=0:01:04
[01/18 08:42:01] detectron2.evaluation.evaluator INFO: Inference done 929/1093. Dataloading: 0.0119 s/iter. Inference: 0.1425 s/iter. Eval: 0.2119 s/iter. Total: 0.3665 s/iter. ETA=0:01:00
[01/18 08:42:06] detectron2.evaluation.evaluator INFO: Inference done 943/1093. Dataloading: 0.0119 s/iter. Inference: 0.1424 s/iter. Eval: 0.2122 s/iter. Total: 0.3667 s/iter. ETA=0:00:55
[01/18 08:42:11] detectron2.evaluation.evaluator INFO: Inference done 957/1093. Dataloading: 0.0119 s/iter. Inference: 0.1425 s/iter. Eval: 0.2122 s/iter. Total: 0.3667 s/iter. ETA=0:00:49
[01/18 08:42:16] detectron2.evaluation.evaluator INFO: Inference done 972/1093. Dataloading: 0.0119 s/iter. Inference: 0.1425 s/iter. Eval: 0.2117 s/iter. Total: 0.3662 s/iter. ETA=0:00:44
[01/18 08:42:21] detectron2.evaluation.evaluator INFO: Inference done 989/1093. Dataloading: 0.0119 s/iter. Inference: 0.1424 s/iter. Eval: 0.2109 s/iter. Total: 0.3653 s/iter. ETA=0:00:37
[01/18 08:42:27] detectron2.evaluation.evaluator INFO: Inference done 1005/1093. Dataloading: 0.0118 s/iter. Inference: 0.1422 s/iter. Eval: 0.2104 s/iter. Total: 0.3646 s/iter. ETA=0:00:32
[01/18 08:42:32] detectron2.evaluation.evaluator INFO: Inference done 1020/1093. Dataloading: 0.0118 s/iter. Inference: 0.1422 s/iter. Eval: 0.2102 s/iter. Total: 0.3643 s/iter. ETA=0:00:26
[01/18 08:42:37] detectron2.evaluation.evaluator INFO: Inference done 1036/1093. Dataloading: 0.0118 s/iter. Inference: 0.1422 s/iter. Eval: 0.2096 s/iter. Total: 0.3637 s/iter. ETA=0:00:20
[01/18 08:42:42] detectron2.evaluation.evaluator INFO: Inference done 1051/1093. Dataloading: 0.0118 s/iter. Inference: 0.1421 s/iter. Eval: 0.2095 s/iter. Total: 0.3635 s/iter. ETA=0:00:15
[01/18 08:42:47] detectron2.evaluation.evaluator INFO: Inference done 1065/1093. Dataloading: 0.0118 s/iter. Inference: 0.1421 s/iter. Eval: 0.2094 s/iter. Total: 0.3635 s/iter. ETA=0:00:10
[01/18 08:42:53] detectron2.evaluation.evaluator INFO: Inference done 1079/1093. Dataloading: 0.0118 s/iter. Inference: 0.1422 s/iter. Eval: 0.2094 s/iter. Total: 0.3635 s/iter. ETA=0:00:05
[01/18 08:42:57] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:35.377615 (0.363399 s / iter per device, on 4 devices)
[01/18 08:42:57] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:34 (0.142110 s / iter per device, on 4 devices)
[01/18 09:32:04] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 09:32:04] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 09:32:04] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 09:32:05] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 09:32:18] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0066 s/iter. Inference: 0.1349 s/iter. Eval: 0.1861 s/iter. Total: 0.3277 s/iter. ETA=0:05:54
[01/18 09:32:23] detectron2.evaluation.evaluator INFO: Inference done 25/1093. Dataloading: 0.0108 s/iter. Inference: 0.1339 s/iter. Eval: 0.2322 s/iter. Total: 0.3769 s/iter. ETA=0:06:42
[01/18 09:32:28] detectron2.evaluation.evaluator INFO: Inference done 37/1093. Dataloading: 0.0126 s/iter. Inference: 0.1391 s/iter. Eval: 0.2437 s/iter. Total: 0.3956 s/iter. ETA=0:06:57
[01/18 09:32:34] detectron2.evaluation.evaluator INFO: Inference done 50/1093. Dataloading: 0.0128 s/iter. Inference: 0.1415 s/iter. Eval: 0.2415 s/iter. Total: 0.3959 s/iter. ETA=0:06:52
[01/18 09:32:39] detectron2.evaluation.evaluator INFO: Inference done 65/1093. Dataloading: 0.0124 s/iter. Inference: 0.1418 s/iter. Eval: 0.2308 s/iter. Total: 0.3851 s/iter. ETA=0:06:35
[01/18 09:32:44] detectron2.evaluation.evaluator INFO: Inference done 78/1093. Dataloading: 0.0124 s/iter. Inference: 0.1414 s/iter. Eval: 0.2335 s/iter. Total: 0.3874 s/iter. ETA=0:06:33
[01/18 09:32:49] detectron2.evaluation.evaluator INFO: Inference done 95/1093. Dataloading: 0.0119 s/iter. Inference: 0.1398 s/iter. Eval: 0.2208 s/iter. Total: 0.3727 s/iter. ETA=0:06:11
[01/18 09:32:54] detectron2.evaluation.evaluator INFO: Inference done 111/1093. Dataloading: 0.0116 s/iter. Inference: 0.1394 s/iter. Eval: 0.2133 s/iter. Total: 0.3643 s/iter. ETA=0:05:57
[01/18 09:32:59] detectron2.evaluation.evaluator INFO: Inference done 125/1093. Dataloading: 0.0114 s/iter. Inference: 0.1399 s/iter. Eval: 0.2126 s/iter. Total: 0.3640 s/iter. ETA=0:05:52
[01/18 09:33:05] detectron2.evaluation.evaluator INFO: Inference done 140/1093. Dataloading: 0.0115 s/iter. Inference: 0.1413 s/iter. Eval: 0.2092 s/iter. Total: 0.3621 s/iter. ETA=0:05:45
[01/18 09:33:10] detectron2.evaluation.evaluator INFO: Inference done 154/1093. Dataloading: 0.0114 s/iter. Inference: 0.1421 s/iter. Eval: 0.2082 s/iter. Total: 0.3618 s/iter. ETA=0:05:39
[01/18 09:33:15] detectron2.evaluation.evaluator INFO: Inference done 168/1093. Dataloading: 0.0114 s/iter. Inference: 0.1422 s/iter. Eval: 0.2091 s/iter. Total: 0.3627 s/iter. ETA=0:05:35
[01/18 09:33:20] detectron2.evaluation.evaluator INFO: Inference done 183/1093. Dataloading: 0.0114 s/iter. Inference: 0.1425 s/iter. Eval: 0.2083 s/iter. Total: 0.3622 s/iter. ETA=0:05:29
[01/18 09:33:26] detectron2.evaluation.evaluator INFO: Inference done 198/1093. Dataloading: 0.0112 s/iter. Inference: 0.1425 s/iter. Eval: 0.2076 s/iter. Total: 0.3615 s/iter. ETA=0:05:23
[01/18 09:33:31] detectron2.evaluation.evaluator INFO: Inference done 212/1093. Dataloading: 0.0114 s/iter. Inference: 0.1427 s/iter. Eval: 0.2079 s/iter. Total: 0.3621 s/iter. ETA=0:05:19
[01/18 09:33:36] detectron2.evaluation.evaluator INFO: Inference done 230/1093. Dataloading: 0.0112 s/iter. Inference: 0.1417 s/iter. Eval: 0.2029 s/iter. Total: 0.3559 s/iter. ETA=0:05:07
[01/18 09:33:41] detectron2.evaluation.evaluator INFO: Inference done 245/1093. Dataloading: 0.0111 s/iter. Inference: 0.1412 s/iter. Eval: 0.2023 s/iter. Total: 0.3548 s/iter. ETA=0:05:00
[01/18 09:33:46] detectron2.evaluation.evaluator INFO: Inference done 258/1093. Dataloading: 0.0113 s/iter. Inference: 0.1412 s/iter. Eval: 0.2044 s/iter. Total: 0.3570 s/iter. ETA=0:04:58
[01/18 09:33:51] detectron2.evaluation.evaluator INFO: Inference done 271/1093. Dataloading: 0.0113 s/iter. Inference: 0.1417 s/iter. Eval: 0.2058 s/iter. Total: 0.3589 s/iter. ETA=0:04:55
[01/18 09:33:56] detectron2.evaluation.evaluator INFO: Inference done 286/1093. Dataloading: 0.0113 s/iter. Inference: 0.1421 s/iter. Eval: 0.2050 s/iter. Total: 0.3584 s/iter. ETA=0:04:49
[01/18 09:34:01] detectron2.evaluation.evaluator INFO: Inference done 300/1093. Dataloading: 0.0112 s/iter. Inference: 0.1418 s/iter. Eval: 0.2053 s/iter. Total: 0.3583 s/iter. ETA=0:04:44
[01/18 09:34:07] detectron2.evaluation.evaluator INFO: Inference done 318/1093. Dataloading: 0.0111 s/iter. Inference: 0.1414 s/iter. Eval: 0.2018 s/iter. Total: 0.3544 s/iter. ETA=0:04:34
[01/18 09:34:12] detectron2.evaluation.evaluator INFO: Inference done 335/1093. Dataloading: 0.0110 s/iter. Inference: 0.1409 s/iter. Eval: 0.1996 s/iter. Total: 0.3516 s/iter. ETA=0:04:26
[01/18 09:34:17] detectron2.evaluation.evaluator INFO: Inference done 349/1093. Dataloading: 0.0110 s/iter. Inference: 0.1408 s/iter. Eval: 0.2007 s/iter. Total: 0.3526 s/iter. ETA=0:04:22
[01/18 09:34:22] detectron2.evaluation.evaluator INFO: Inference done 363/1093. Dataloading: 0.0111 s/iter. Inference: 0.1407 s/iter. Eval: 0.2014 s/iter. Total: 0.3532 s/iter. ETA=0:04:17
[01/18 09:34:27] detectron2.evaluation.evaluator INFO: Inference done 378/1093. Dataloading: 0.0111 s/iter. Inference: 0.1406 s/iter. Eval: 0.2013 s/iter. Total: 0.3531 s/iter. ETA=0:04:12
[01/18 09:34:33] detectron2.evaluation.evaluator INFO: Inference done 391/1093. Dataloading: 0.0111 s/iter. Inference: 0.1407 s/iter. Eval: 0.2025 s/iter. Total: 0.3543 s/iter. ETA=0:04:08
[01/18 09:34:38] detectron2.evaluation.evaluator INFO: Inference done 405/1093. Dataloading: 0.0111 s/iter. Inference: 0.1405 s/iter. Eval: 0.2039 s/iter. Total: 0.3556 s/iter. ETA=0:04:04
[01/18 09:34:43] detectron2.evaluation.evaluator INFO: Inference done 417/1093. Dataloading: 0.0112 s/iter. Inference: 0.1406 s/iter. Eval: 0.2059 s/iter. Total: 0.3578 s/iter. ETA=0:04:01
[01/18 09:34:48] detectron2.evaluation.evaluator INFO: Inference done 432/1093. Dataloading: 0.0112 s/iter. Inference: 0.1405 s/iter. Eval: 0.2057 s/iter. Total: 0.3575 s/iter. ETA=0:03:56
[01/18 09:34:54] detectron2.evaluation.evaluator INFO: Inference done 448/1093. Dataloading: 0.0111 s/iter. Inference: 0.1403 s/iter. Eval: 0.2047 s/iter. Total: 0.3562 s/iter. ETA=0:03:49
[01/18 09:34:59] detectron2.evaluation.evaluator INFO: Inference done 465/1093. Dataloading: 0.0111 s/iter. Inference: 0.1399 s/iter. Eval: 0.2032 s/iter. Total: 0.3543 s/iter. ETA=0:03:42
[01/18 09:35:04] detectron2.evaluation.evaluator INFO: Inference done 480/1093. Dataloading: 0.0111 s/iter. Inference: 0.1398 s/iter. Eval: 0.2031 s/iter. Total: 0.3541 s/iter. ETA=0:03:37
[01/18 09:35:09] detectron2.evaluation.evaluator INFO: Inference done 494/1093. Dataloading: 0.0111 s/iter. Inference: 0.1399 s/iter. Eval: 0.2040 s/iter. Total: 0.3551 s/iter. ETA=0:03:32
[01/18 09:35:14] detectron2.evaluation.evaluator INFO: Inference done 507/1093. Dataloading: 0.0111 s/iter. Inference: 0.1401 s/iter. Eval: 0.2047 s/iter. Total: 0.3559 s/iter. ETA=0:03:28
[01/18 09:35:20] detectron2.evaluation.evaluator INFO: Inference done 521/1093. Dataloading: 0.0111 s/iter. Inference: 0.1401 s/iter. Eval: 0.2051 s/iter. Total: 0.3564 s/iter. ETA=0:03:23
[01/18 09:35:25] detectron2.evaluation.evaluator INFO: Inference done 537/1093. Dataloading: 0.0111 s/iter. Inference: 0.1397 s/iter. Eval: 0.2045 s/iter. Total: 0.3554 s/iter. ETA=0:03:17
[01/18 09:35:30] detectron2.evaluation.evaluator INFO: Inference done 552/1093. Dataloading: 0.0111 s/iter. Inference: 0.1399 s/iter. Eval: 0.2043 s/iter. Total: 0.3554 s/iter. ETA=0:03:12
[01/18 09:35:35] detectron2.evaluation.evaluator INFO: Inference done 566/1093. Dataloading: 0.0111 s/iter. Inference: 0.1399 s/iter. Eval: 0.2044 s/iter. Total: 0.3554 s/iter. ETA=0:03:07
[01/18 09:35:40] detectron2.evaluation.evaluator INFO: Inference done 579/1093. Dataloading: 0.0111 s/iter. Inference: 0.1400 s/iter. Eval: 0.2051 s/iter. Total: 0.3562 s/iter. ETA=0:03:03
[01/18 09:35:45] detectron2.evaluation.evaluator INFO: Inference done 594/1093. Dataloading: 0.0111 s/iter. Inference: 0.1398 s/iter. Eval: 0.2049 s/iter. Total: 0.3559 s/iter. ETA=0:02:57
[01/18 09:35:50] detectron2.evaluation.evaluator INFO: Inference done 609/1093. Dataloading: 0.0110 s/iter. Inference: 0.1397 s/iter. Eval: 0.2046 s/iter. Total: 0.3554 s/iter. ETA=0:02:52
[01/18 09:35:56] detectron2.evaluation.evaluator INFO: Inference done 625/1093. Dataloading: 0.0110 s/iter. Inference: 0.1395 s/iter. Eval: 0.2039 s/iter. Total: 0.3545 s/iter. ETA=0:02:45
[01/18 09:36:01] detectron2.evaluation.evaluator INFO: Inference done 639/1093. Dataloading: 0.0110 s/iter. Inference: 0.1396 s/iter. Eval: 0.2042 s/iter. Total: 0.3550 s/iter. ETA=0:02:41
[01/18 09:36:06] detectron2.evaluation.evaluator INFO: Inference done 654/1093. Dataloading: 0.0110 s/iter. Inference: 0.1395 s/iter. Eval: 0.2044 s/iter. Total: 0.3549 s/iter. ETA=0:02:35
[01/18 09:36:11] detectron2.evaluation.evaluator INFO: Inference done 669/1093. Dataloading: 0.0110 s/iter. Inference: 0.1394 s/iter. Eval: 0.2043 s/iter. Total: 0.3549 s/iter. ETA=0:02:30
[01/18 09:36:16] detectron2.evaluation.evaluator INFO: Inference done 683/1093. Dataloading: 0.0110 s/iter. Inference: 0.1394 s/iter. Eval: 0.2044 s/iter. Total: 0.3549 s/iter. ETA=0:02:25
[01/18 09:36:21] detectron2.evaluation.evaluator INFO: Inference done 697/1093. Dataloading: 0.0110 s/iter. Inference: 0.1393 s/iter. Eval: 0.2046 s/iter. Total: 0.3550 s/iter. ETA=0:02:20
[01/18 09:36:27] detectron2.evaluation.evaluator INFO: Inference done 713/1093. Dataloading: 0.0110 s/iter. Inference: 0.1393 s/iter. Eval: 0.2040 s/iter. Total: 0.3544 s/iter. ETA=0:02:14
[01/18 09:36:32] detectron2.evaluation.evaluator INFO: Inference done 728/1093. Dataloading: 0.0113 s/iter. Inference: 0.1392 s/iter. Eval: 0.2037 s/iter. Total: 0.3543 s/iter. ETA=0:02:09
[01/18 09:36:37] detectron2.evaluation.evaluator INFO: Inference done 743/1093. Dataloading: 0.0112 s/iter. Inference: 0.1394 s/iter. Eval: 0.2035 s/iter. Total: 0.3542 s/iter. ETA=0:02:03
[01/18 09:36:42] detectron2.evaluation.evaluator INFO: Inference done 757/1093. Dataloading: 0.0112 s/iter. Inference: 0.1395 s/iter. Eval: 0.2036 s/iter. Total: 0.3544 s/iter. ETA=0:01:59
[01/18 09:36:47] detectron2.evaluation.evaluator INFO: Inference done 771/1093. Dataloading: 0.0112 s/iter. Inference: 0.1396 s/iter. Eval: 0.2038 s/iter. Total: 0.3547 s/iter. ETA=0:01:54
[01/18 09:36:52] detectron2.evaluation.evaluator INFO: Inference done 788/1093. Dataloading: 0.0112 s/iter. Inference: 0.1392 s/iter. Eval: 0.2030 s/iter. Total: 0.3534 s/iter. ETA=0:01:47
[01/18 09:36:58] detectron2.evaluation.evaluator INFO: Inference done 803/1093. Dataloading: 0.0111 s/iter. Inference: 0.1392 s/iter. Eval: 0.2029 s/iter. Total: 0.3533 s/iter. ETA=0:01:42
[01/18 09:37:03] detectron2.evaluation.evaluator INFO: Inference done 817/1093. Dataloading: 0.0111 s/iter. Inference: 0.1392 s/iter. Eval: 0.2031 s/iter. Total: 0.3535 s/iter. ETA=0:01:37
[01/18 09:37:08] detectron2.evaluation.evaluator INFO: Inference done 831/1093. Dataloading: 0.0111 s/iter. Inference: 0.1392 s/iter. Eval: 0.2031 s/iter. Total: 0.3535 s/iter. ETA=0:01:32
[01/18 09:37:13] detectron2.evaluation.evaluator INFO: Inference done 847/1093. Dataloading: 0.0111 s/iter. Inference: 0.1392 s/iter. Eval: 0.2027 s/iter. Total: 0.3531 s/iter. ETA=0:01:26
[01/18 09:37:18] detectron2.evaluation.evaluator INFO: Inference done 862/1093. Dataloading: 0.0111 s/iter. Inference: 0.1392 s/iter. Eval: 0.2027 s/iter. Total: 0.3531 s/iter. ETA=0:01:21
[01/18 09:37:24] detectron2.evaluation.evaluator INFO: Inference done 877/1093. Dataloading: 0.0111 s/iter. Inference: 0.1391 s/iter. Eval: 0.2028 s/iter. Total: 0.3530 s/iter. ETA=0:01:16
[01/18 09:37:29] detectron2.evaluation.evaluator INFO: Inference done 892/1093. Dataloading: 0.0111 s/iter. Inference: 0.1390 s/iter. Eval: 0.2027 s/iter. Total: 0.3529 s/iter. ETA=0:01:10
[01/18 09:37:34] detectron2.evaluation.evaluator INFO: Inference done 906/1093. Dataloading: 0.0111 s/iter. Inference: 0.1390 s/iter. Eval: 0.2030 s/iter. Total: 0.3531 s/iter. ETA=0:01:06
[01/18 09:37:39] detectron2.evaluation.evaluator INFO: Inference done 922/1093. Dataloading: 0.0111 s/iter. Inference: 0.1389 s/iter. Eval: 0.2026 s/iter. Total: 0.3527 s/iter. ETA=0:01:00
[01/18 09:37:45] detectron2.evaluation.evaluator INFO: Inference done 935/1093. Dataloading: 0.0111 s/iter. Inference: 0.1390 s/iter. Eval: 0.2033 s/iter. Total: 0.3535 s/iter. ETA=0:00:55
[01/18 09:37:50] detectron2.evaluation.evaluator INFO: Inference done 948/1093. Dataloading: 0.0112 s/iter. Inference: 0.1390 s/iter. Eval: 0.2038 s/iter. Total: 0.3541 s/iter. ETA=0:00:51
[01/18 09:37:55] detectron2.evaluation.evaluator INFO: Inference done 964/1093. Dataloading: 0.0111 s/iter. Inference: 0.1390 s/iter. Eval: 0.2035 s/iter. Total: 0.3536 s/iter. ETA=0:00:45
[01/18 09:38:00] detectron2.evaluation.evaluator INFO: Inference done 981/1093. Dataloading: 0.0111 s/iter. Inference: 0.1389 s/iter. Eval: 0.2027 s/iter. Total: 0.3527 s/iter. ETA=0:00:39
[01/18 09:38:05] detectron2.evaluation.evaluator INFO: Inference done 996/1093. Dataloading: 0.0111 s/iter. Inference: 0.1389 s/iter. Eval: 0.2026 s/iter. Total: 0.3527 s/iter. ETA=0:00:34
[01/18 09:38:11] detectron2.evaluation.evaluator INFO: Inference done 1011/1093. Dataloading: 0.0111 s/iter. Inference: 0.1390 s/iter. Eval: 0.2026 s/iter. Total: 0.3528 s/iter. ETA=0:00:28
[01/18 09:38:16] detectron2.evaluation.evaluator INFO: Inference done 1027/1093. Dataloading: 0.0110 s/iter. Inference: 0.1389 s/iter. Eval: 0.2021 s/iter. Total: 0.3521 s/iter. ETA=0:00:23
[01/18 09:38:21] detectron2.evaluation.evaluator INFO: Inference done 1043/1093. Dataloading: 0.0110 s/iter. Inference: 0.1389 s/iter. Eval: 0.2015 s/iter. Total: 0.3515 s/iter. ETA=0:00:17
[01/18 09:38:26] detectron2.evaluation.evaluator INFO: Inference done 1058/1093. Dataloading: 0.0110 s/iter. Inference: 0.1389 s/iter. Eval: 0.2015 s/iter. Total: 0.3515 s/iter. ETA=0:00:12
[01/18 09:38:31] detectron2.evaluation.evaluator INFO: Inference done 1072/1093. Dataloading: 0.0110 s/iter. Inference: 0.1389 s/iter. Eval: 0.2016 s/iter. Total: 0.3516 s/iter. ETA=0:00:07
[01/18 09:38:36] detectron2.evaluation.evaluator INFO: Inference done 1088/1093. Dataloading: 0.0110 s/iter. Inference: 0.1388 s/iter. Eval: 0.2013 s/iter. Total: 0.3513 s/iter. ETA=0:00:01
[01/18 09:38:38] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:22.279194 (0.351360 s / iter per device, on 4 devices)
[01/18 09:38:38] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:30 (0.138743 s / iter per device, on 4 devices)
[01/18 10:27:44] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 10:27:45] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 10:27:45] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 10:27:46] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 10:27:59] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0103 s/iter. Inference: 0.1382 s/iter. Eval: 0.1936 s/iter. Total: 0.3422 s/iter. ETA=0:06:10
[01/18 10:28:04] detectron2.evaluation.evaluator INFO: Inference done 24/1093. Dataloading: 0.0128 s/iter. Inference: 0.1377 s/iter. Eval: 0.2311 s/iter. Total: 0.3815 s/iter. ETA=0:06:47
[01/18 10:28:10] detectron2.evaluation.evaluator INFO: Inference done 36/1093. Dataloading: 0.0136 s/iter. Inference: 0.1411 s/iter. Eval: 0.2537 s/iter. Total: 0.4085 s/iter. ETA=0:07:11
[01/18 10:28:15] detectron2.evaluation.evaluator INFO: Inference done 48/1093. Dataloading: 0.0133 s/iter. Inference: 0.1431 s/iter. Eval: 0.2548 s/iter. Total: 0.4113 s/iter. ETA=0:07:09
[01/18 10:28:20] detectron2.evaluation.evaluator INFO: Inference done 62/1093. Dataloading: 0.0128 s/iter. Inference: 0.1450 s/iter. Eval: 0.2466 s/iter. Total: 0.4045 s/iter. ETA=0:06:56
[01/18 10:28:25] detectron2.evaluation.evaluator INFO: Inference done 74/1093. Dataloading: 0.0128 s/iter. Inference: 0.1452 s/iter. Eval: 0.2496 s/iter. Total: 0.4077 s/iter. ETA=0:06:55
[01/18 10:28:30] detectron2.evaluation.evaluator INFO: Inference done 89/1093. Dataloading: 0.0127 s/iter. Inference: 0.1465 s/iter. Eval: 0.2383 s/iter. Total: 0.3975 s/iter. ETA=0:06:39
[01/18 10:28:36] detectron2.evaluation.evaluator INFO: Inference done 104/1093. Dataloading: 0.0123 s/iter. Inference: 0.1460 s/iter. Eval: 0.2296 s/iter. Total: 0.3880 s/iter. ETA=0:06:23
[01/18 10:28:41] detectron2.evaluation.evaluator INFO: Inference done 120/1093. Dataloading: 0.0120 s/iter. Inference: 0.1449 s/iter. Eval: 0.2232 s/iter. Total: 0.3802 s/iter. ETA=0:06:09
[01/18 10:28:46] detectron2.evaluation.evaluator INFO: Inference done 134/1093. Dataloading: 0.0118 s/iter. Inference: 0.1454 s/iter. Eval: 0.2216 s/iter. Total: 0.3789 s/iter. ETA=0:06:03
[01/18 10:28:51] detectron2.evaluation.evaluator INFO: Inference done 150/1093. Dataloading: 0.0117 s/iter. Inference: 0.1450 s/iter. Eval: 0.2151 s/iter. Total: 0.3719 s/iter. ETA=0:05:50
[01/18 10:28:56] detectron2.evaluation.evaluator INFO: Inference done 164/1093. Dataloading: 0.0116 s/iter. Inference: 0.1459 s/iter. Eval: 0.2146 s/iter. Total: 0.3722 s/iter. ETA=0:05:45
[01/18 10:29:01] detectron2.evaluation.evaluator INFO: Inference done 178/1093. Dataloading: 0.0116 s/iter. Inference: 0.1457 s/iter. Eval: 0.2142 s/iter. Total: 0.3717 s/iter. ETA=0:05:40
[01/18 10:29:07] detectron2.evaluation.evaluator INFO: Inference done 192/1093. Dataloading: 0.0116 s/iter. Inference: 0.1459 s/iter. Eval: 0.2152 s/iter. Total: 0.3728 s/iter. ETA=0:05:35
[01/18 10:29:12] detectron2.evaluation.evaluator INFO: Inference done 205/1093. Dataloading: 0.0118 s/iter. Inference: 0.1452 s/iter. Eval: 0.2168 s/iter. Total: 0.3739 s/iter. ETA=0:05:32
[01/18 10:29:17] detectron2.evaluation.evaluator INFO: Inference done 220/1093. Dataloading: 0.0116 s/iter. Inference: 0.1455 s/iter. Eval: 0.2146 s/iter. Total: 0.3719 s/iter. ETA=0:05:24
[01/18 10:29:22] detectron2.evaluation.evaluator INFO: Inference done 233/1093. Dataloading: 0.0116 s/iter. Inference: 0.1458 s/iter. Eval: 0.2152 s/iter. Total: 0.3727 s/iter. ETA=0:05:20
[01/18 10:29:27] detectron2.evaluation.evaluator INFO: Inference done 247/1093. Dataloading: 0.0117 s/iter. Inference: 0.1458 s/iter. Eval: 0.2158 s/iter. Total: 0.3734 s/iter. ETA=0:05:15
[01/18 10:29:33] detectron2.evaluation.evaluator INFO: Inference done 260/1093. Dataloading: 0.0119 s/iter. Inference: 0.1457 s/iter. Eval: 0.2168 s/iter. Total: 0.3744 s/iter. ETA=0:05:11
[01/18 10:29:38] detectron2.evaluation.evaluator INFO: Inference done 275/1093. Dataloading: 0.0118 s/iter. Inference: 0.1456 s/iter. Eval: 0.2157 s/iter. Total: 0.3732 s/iter. ETA=0:05:05
[01/18 10:29:43] detectron2.evaluation.evaluator INFO: Inference done 289/1093. Dataloading: 0.0118 s/iter. Inference: 0.1453 s/iter. Eval: 0.2157 s/iter. Total: 0.3729 s/iter. ETA=0:04:59
[01/18 10:29:48] detectron2.evaluation.evaluator INFO: Inference done 303/1093. Dataloading: 0.0118 s/iter. Inference: 0.1451 s/iter. Eval: 0.2151 s/iter. Total: 0.3721 s/iter. ETA=0:04:53
[01/18 10:29:53] detectron2.evaluation.evaluator INFO: Inference done 319/1093. Dataloading: 0.0117 s/iter. Inference: 0.1451 s/iter. Eval: 0.2124 s/iter. Total: 0.3693 s/iter. ETA=0:04:45
[01/18 10:29:58] detectron2.evaluation.evaluator INFO: Inference done 333/1093. Dataloading: 0.0117 s/iter. Inference: 0.1452 s/iter. Eval: 0.2119 s/iter. Total: 0.3689 s/iter. ETA=0:04:40
[01/18 10:30:03] detectron2.evaluation.evaluator INFO: Inference done 347/1093. Dataloading: 0.0116 s/iter. Inference: 0.1451 s/iter. Eval: 0.2120 s/iter. Total: 0.3689 s/iter. ETA=0:04:35
[01/18 10:30:09] detectron2.evaluation.evaluator INFO: Inference done 362/1093. Dataloading: 0.0116 s/iter. Inference: 0.1447 s/iter. Eval: 0.2117 s/iter. Total: 0.3681 s/iter. ETA=0:04:29
[01/18 10:30:14] detectron2.evaluation.evaluator INFO: Inference done 378/1093. Dataloading: 0.0115 s/iter. Inference: 0.1440 s/iter. Eval: 0.2104 s/iter. Total: 0.3660 s/iter. ETA=0:04:21
[01/18 10:30:19] detectron2.evaluation.evaluator INFO: Inference done 390/1093. Dataloading: 0.0116 s/iter. Inference: 0.1442 s/iter. Eval: 0.2124 s/iter. Total: 0.3682 s/iter. ETA=0:04:18
[01/18 10:30:24] detectron2.evaluation.evaluator INFO: Inference done 403/1093. Dataloading: 0.0116 s/iter. Inference: 0.1443 s/iter. Eval: 0.2134 s/iter. Total: 0.3695 s/iter. ETA=0:04:14
[01/18 10:30:29] detectron2.evaluation.evaluator INFO: Inference done 415/1093. Dataloading: 0.0117 s/iter. Inference: 0.1445 s/iter. Eval: 0.2150 s/iter. Total: 0.3713 s/iter. ETA=0:04:11
[01/18 10:30:34] detectron2.evaluation.evaluator INFO: Inference done 431/1093. Dataloading: 0.0117 s/iter. Inference: 0.1439 s/iter. Eval: 0.2137 s/iter. Total: 0.3694 s/iter. ETA=0:04:04
[01/18 10:30:40] detectron2.evaluation.evaluator INFO: Inference done 445/1093. Dataloading: 0.0117 s/iter. Inference: 0.1441 s/iter. Eval: 0.2138 s/iter. Total: 0.3697 s/iter. ETA=0:03:59
[01/18 10:30:45] detectron2.evaluation.evaluator INFO: Inference done 460/1093. Dataloading: 0.0116 s/iter. Inference: 0.1442 s/iter. Eval: 0.2131 s/iter. Total: 0.3690 s/iter. ETA=0:03:53
[01/18 10:30:50] detectron2.evaluation.evaluator INFO: Inference done 474/1093. Dataloading: 0.0116 s/iter. Inference: 0.1440 s/iter. Eval: 0.2133 s/iter. Total: 0.3690 s/iter. ETA=0:03:48
[01/18 10:30:55] detectron2.evaluation.evaluator INFO: Inference done 489/1093. Dataloading: 0.0115 s/iter. Inference: 0.1439 s/iter. Eval: 0.2125 s/iter. Total: 0.3679 s/iter. ETA=0:03:42
[01/18 10:31:01] detectron2.evaluation.evaluator INFO: Inference done 503/1093. Dataloading: 0.0115 s/iter. Inference: 0.1437 s/iter. Eval: 0.2130 s/iter. Total: 0.3683 s/iter. ETA=0:03:37
[01/18 10:31:06] detectron2.evaluation.evaluator INFO: Inference done 516/1093. Dataloading: 0.0116 s/iter. Inference: 0.1438 s/iter. Eval: 0.2136 s/iter. Total: 0.3692 s/iter. ETA=0:03:33
[01/18 10:31:11] detectron2.evaluation.evaluator INFO: Inference done 529/1093. Dataloading: 0.0116 s/iter. Inference: 0.1439 s/iter. Eval: 0.2143 s/iter. Total: 0.3699 s/iter. ETA=0:03:28
[01/18 10:31:16] detectron2.evaluation.evaluator INFO: Inference done 545/1093. Dataloading: 0.0116 s/iter. Inference: 0.1436 s/iter. Eval: 0.2134 s/iter. Total: 0.3687 s/iter. ETA=0:03:22
[01/18 10:31:21] detectron2.evaluation.evaluator INFO: Inference done 559/1093. Dataloading: 0.0116 s/iter. Inference: 0.1435 s/iter. Eval: 0.2134 s/iter. Total: 0.3685 s/iter. ETA=0:03:16
[01/18 10:31:26] detectron2.evaluation.evaluator INFO: Inference done 573/1093. Dataloading: 0.0115 s/iter. Inference: 0.1433 s/iter. Eval: 0.2135 s/iter. Total: 0.3684 s/iter. ETA=0:03:11
[01/18 10:31:32] detectron2.evaluation.evaluator INFO: Inference done 587/1093. Dataloading: 0.0115 s/iter. Inference: 0.1434 s/iter. Eval: 0.2138 s/iter. Total: 0.3688 s/iter. ETA=0:03:06
[01/18 10:31:37] detectron2.evaluation.evaluator INFO: Inference done 602/1093. Dataloading: 0.0115 s/iter. Inference: 0.1433 s/iter. Eval: 0.2135 s/iter. Total: 0.3685 s/iter. ETA=0:03:00
[01/18 10:31:42] detectron2.evaluation.evaluator INFO: Inference done 617/1093. Dataloading: 0.0115 s/iter. Inference: 0.1434 s/iter. Eval: 0.2130 s/iter. Total: 0.3680 s/iter. ETA=0:02:55
[01/18 10:31:47] detectron2.evaluation.evaluator INFO: Inference done 631/1093. Dataloading: 0.0115 s/iter. Inference: 0.1434 s/iter. Eval: 0.2130 s/iter. Total: 0.3680 s/iter. ETA=0:02:50
[01/18 10:31:53] detectron2.evaluation.evaluator INFO: Inference done 646/1093. Dataloading: 0.0115 s/iter. Inference: 0.1432 s/iter. Eval: 0.2127 s/iter. Total: 0.3676 s/iter. ETA=0:02:44
[01/18 10:31:58] detectron2.evaluation.evaluator INFO: Inference done 660/1093. Dataloading: 0.0115 s/iter. Inference: 0.1432 s/iter. Eval: 0.2127 s/iter. Total: 0.3676 s/iter. ETA=0:02:39
[01/18 10:32:03] detectron2.evaluation.evaluator INFO: Inference done 675/1093. Dataloading: 0.0115 s/iter. Inference: 0.1430 s/iter. Eval: 0.2121 s/iter. Total: 0.3668 s/iter. ETA=0:02:33
[01/18 10:32:08] detectron2.evaluation.evaluator INFO: Inference done 688/1093. Dataloading: 0.0115 s/iter. Inference: 0.1430 s/iter. Eval: 0.2127 s/iter. Total: 0.3674 s/iter. ETA=0:02:28
[01/18 10:32:13] detectron2.evaluation.evaluator INFO: Inference done 701/1093. Dataloading: 0.0115 s/iter. Inference: 0.1431 s/iter. Eval: 0.2132 s/iter. Total: 0.3679 s/iter. ETA=0:02:24
[01/18 10:32:18] detectron2.evaluation.evaluator INFO: Inference done 715/1093. Dataloading: 0.0115 s/iter. Inference: 0.1432 s/iter. Eval: 0.2132 s/iter. Total: 0.3680 s/iter. ETA=0:02:19
[01/18 10:32:24] detectron2.evaluation.evaluator INFO: Inference done 730/1093. Dataloading: 0.0115 s/iter. Inference: 0.1432 s/iter. Eval: 0.2130 s/iter. Total: 0.3678 s/iter. ETA=0:02:13
[01/18 10:32:29] detectron2.evaluation.evaluator INFO: Inference done 744/1093. Dataloading: 0.0115 s/iter. Inference: 0.1433 s/iter. Eval: 0.2128 s/iter. Total: 0.3676 s/iter. ETA=0:02:08
[01/18 10:32:34] detectron2.evaluation.evaluator INFO: Inference done 758/1093. Dataloading: 0.0115 s/iter. Inference: 0.1433 s/iter. Eval: 0.2129 s/iter. Total: 0.3678 s/iter. ETA=0:02:03
[01/18 10:32:39] detectron2.evaluation.evaluator INFO: Inference done 772/1093. Dataloading: 0.0115 s/iter. Inference: 0.1433 s/iter. Eval: 0.2128 s/iter. Total: 0.3676 s/iter. ETA=0:01:58
[01/18 10:32:44] detectron2.evaluation.evaluator INFO: Inference done 787/1093. Dataloading: 0.0114 s/iter. Inference: 0.1431 s/iter. Eval: 0.2125 s/iter. Total: 0.3672 s/iter. ETA=0:01:52
[01/18 10:32:49] detectron2.evaluation.evaluator INFO: Inference done 802/1093. Dataloading: 0.0114 s/iter. Inference: 0.1430 s/iter. Eval: 0.2122 s/iter. Total: 0.3667 s/iter. ETA=0:01:46
[01/18 10:32:55] detectron2.evaluation.evaluator INFO: Inference done 816/1093. Dataloading: 0.0114 s/iter. Inference: 0.1431 s/iter. Eval: 0.2123 s/iter. Total: 0.3669 s/iter. ETA=0:01:41
[01/18 10:33:00] detectron2.evaluation.evaluator INFO: Inference done 830/1093. Dataloading: 0.0114 s/iter. Inference: 0.1431 s/iter. Eval: 0.2123 s/iter. Total: 0.3669 s/iter. ETA=0:01:36
[01/18 10:33:05] detectron2.evaluation.evaluator INFO: Inference done 847/1093. Dataloading: 0.0114 s/iter. Inference: 0.1430 s/iter. Eval: 0.2113 s/iter. Total: 0.3658 s/iter. ETA=0:01:29
[01/18 10:33:10] detectron2.evaluation.evaluator INFO: Inference done 860/1093. Dataloading: 0.0114 s/iter. Inference: 0.1431 s/iter. Eval: 0.2117 s/iter. Total: 0.3663 s/iter. ETA=0:01:25
[01/18 10:33:15] detectron2.evaluation.evaluator INFO: Inference done 873/1093. Dataloading: 0.0114 s/iter. Inference: 0.1431 s/iter. Eval: 0.2120 s/iter. Total: 0.3666 s/iter. ETA=0:01:20
[01/18 10:33:20] detectron2.evaluation.evaluator INFO: Inference done 886/1093. Dataloading: 0.0114 s/iter. Inference: 0.1430 s/iter. Eval: 0.2124 s/iter. Total: 0.3669 s/iter. ETA=0:01:15
[01/18 10:33:25] detectron2.evaluation.evaluator INFO: Inference done 901/1093. Dataloading: 0.0114 s/iter. Inference: 0.1429 s/iter. Eval: 0.2121 s/iter. Total: 0.3665 s/iter. ETA=0:01:10
[01/18 10:33:31] detectron2.evaluation.evaluator INFO: Inference done 916/1093. Dataloading: 0.0114 s/iter. Inference: 0.1428 s/iter. Eval: 0.2118 s/iter. Total: 0.3662 s/iter. ETA=0:01:04
[01/18 10:33:36] detectron2.evaluation.evaluator INFO: Inference done 930/1093. Dataloading: 0.0114 s/iter. Inference: 0.1427 s/iter. Eval: 0.2122 s/iter. Total: 0.3664 s/iter. ETA=0:00:59
[01/18 10:33:41] detectron2.evaluation.evaluator INFO: Inference done 943/1093. Dataloading: 0.0114 s/iter. Inference: 0.1427 s/iter. Eval: 0.2127 s/iter. Total: 0.3669 s/iter. ETA=0:00:55
[01/18 10:33:46] detectron2.evaluation.evaluator INFO: Inference done 957/1093. Dataloading: 0.0114 s/iter. Inference: 0.1427 s/iter. Eval: 0.2126 s/iter. Total: 0.3668 s/iter. ETA=0:00:49
[01/18 10:33:51] detectron2.evaluation.evaluator INFO: Inference done 974/1093. Dataloading: 0.0114 s/iter. Inference: 0.1426 s/iter. Eval: 0.2116 s/iter. Total: 0.3656 s/iter. ETA=0:00:43
[01/18 10:33:57] detectron2.evaluation.evaluator INFO: Inference done 989/1093. Dataloading: 0.0114 s/iter. Inference: 0.1426 s/iter. Eval: 0.2114 s/iter. Total: 0.3655 s/iter. ETA=0:00:38
[01/18 10:34:02] detectron2.evaluation.evaluator INFO: Inference done 1004/1093. Dataloading: 0.0114 s/iter. Inference: 0.1426 s/iter. Eval: 0.2111 s/iter. Total: 0.3651 s/iter. ETA=0:00:32
[01/18 10:34:07] detectron2.evaluation.evaluator INFO: Inference done 1018/1093. Dataloading: 0.0113 s/iter. Inference: 0.1426 s/iter. Eval: 0.2112 s/iter. Total: 0.3653 s/iter. ETA=0:00:27
[01/18 10:34:12] detectron2.evaluation.evaluator INFO: Inference done 1034/1093. Dataloading: 0.0113 s/iter. Inference: 0.1427 s/iter. Eval: 0.2105 s/iter. Total: 0.3646 s/iter. ETA=0:00:21
[01/18 10:34:18] detectron2.evaluation.evaluator INFO: Inference done 1049/1093. Dataloading: 0.0113 s/iter. Inference: 0.1428 s/iter. Eval: 0.2102 s/iter. Total: 0.3644 s/iter. ETA=0:00:16
[01/18 10:34:23] detectron2.evaluation.evaluator INFO: Inference done 1063/1093. Dataloading: 0.0113 s/iter. Inference: 0.1427 s/iter. Eval: 0.2103 s/iter. Total: 0.3644 s/iter. ETA=0:00:10
[01/18 10:34:28] detectron2.evaluation.evaluator INFO: Inference done 1077/1093. Dataloading: 0.0113 s/iter. Inference: 0.1428 s/iter. Eval: 0.2102 s/iter. Total: 0.3644 s/iter. ETA=0:00:05
[01/18 10:34:33] detectron2.evaluation.evaluator INFO: Inference done 1091/1093. Dataloading: 0.0113 s/iter. Inference: 0.1428 s/iter. Eval: 0.2101 s/iter. Total: 0.3643 s/iter. ETA=0:00:00
[01/18 10:34:34] detectron2.evaluation.evaluator INFO: Total inference time: 0:06:36.655891 (0.364573 s / iter per device, on 4 devices)
[01/18 10:34:34] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:35 (0.142798 s / iter per device, on 4 devices)
[01/18 11:21:53] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 11:21:53] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 11:21:53] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 11:21:54] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 11:22:04] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0067 s/iter. Inference: 0.1173 s/iter. Eval: 0.1735 s/iter. Total: 0.2976 s/iter. ETA=0:05:21
[01/18 11:22:10] detectron2.evaluation.evaluator INFO: Inference done 27/1093. Dataloading: 0.0084 s/iter. Inference: 0.1142 s/iter. Eval: 0.1908 s/iter. Total: 0.3135 s/iter. ETA=0:05:34
[01/18 11:22:15] detectron2.evaluation.evaluator INFO: Inference done 44/1093. Dataloading: 0.0083 s/iter. Inference: 0.1133 s/iter. Eval: 0.1909 s/iter. Total: 0.3127 s/iter. ETA=0:05:27
[01/18 11:22:20] detectron2.evaluation.evaluator INFO: Inference done 63/1093. Dataloading: 0.0080 s/iter. Inference: 0.1141 s/iter. Eval: 0.1783 s/iter. Total: 0.3005 s/iter. ETA=0:05:09
[01/18 11:22:25] detectron2.evaluation.evaluator INFO: Inference done 81/1093. Dataloading: 0.0081 s/iter. Inference: 0.1136 s/iter. Eval: 0.1752 s/iter. Total: 0.2970 s/iter. ETA=0:05:00
[01/18 11:22:30] detectron2.evaluation.evaluator INFO: Inference done 102/1093. Dataloading: 0.0076 s/iter. Inference: 0.1131 s/iter. Eval: 0.1646 s/iter. Total: 0.2855 s/iter. ETA=0:04:42
[01/18 11:22:36] detectron2.evaluation.evaluator INFO: Inference done 122/1093. Dataloading: 0.0075 s/iter. Inference: 0.1132 s/iter. Eval: 0.1597 s/iter. Total: 0.2805 s/iter. ETA=0:04:32
[01/18 11:22:41] detectron2.evaluation.evaluator INFO: Inference done 142/1093. Dataloading: 0.0074 s/iter. Inference: 0.1133 s/iter. Eval: 0.1559 s/iter. Total: 0.2767 s/iter. ETA=0:04:23
[01/18 11:22:46] detectron2.evaluation.evaluator INFO: Inference done 162/1093. Dataloading: 0.0073 s/iter. Inference: 0.1136 s/iter. Eval: 0.1539 s/iter. Total: 0.2750 s/iter. ETA=0:04:15
[01/18 11:22:51] detectron2.evaluation.evaluator INFO: Inference done 181/1093. Dataloading: 0.0073 s/iter. Inference: 0.1137 s/iter. Eval: 0.1536 s/iter. Total: 0.2746 s/iter. ETA=0:04:10
[01/18 11:22:56] detectron2.evaluation.evaluator INFO: Inference done 200/1093. Dataloading: 0.0073 s/iter. Inference: 0.1135 s/iter. Eval: 0.1534 s/iter. Total: 0.2743 s/iter. ETA=0:04:04
[01/18 11:23:01] detectron2.evaluation.evaluator INFO: Inference done 220/1093. Dataloading: 0.0073 s/iter. Inference: 0.1137 s/iter. Eval: 0.1521 s/iter. Total: 0.2732 s/iter. ETA=0:03:58
[01/18 11:23:07] detectron2.evaluation.evaluator INFO: Inference done 240/1093. Dataloading: 0.0073 s/iter. Inference: 0.1137 s/iter. Eval: 0.1509 s/iter. Total: 0.2719 s/iter. ETA=0:03:51
[01/18 11:23:12] detectron2.evaluation.evaluator INFO: Inference done 258/1093. Dataloading: 0.0073 s/iter. Inference: 0.1136 s/iter. Eval: 0.1517 s/iter. Total: 0.2728 s/iter. ETA=0:03:47
[01/18 11:23:17] detectron2.evaluation.evaluator INFO: Inference done 277/1093. Dataloading: 0.0073 s/iter. Inference: 0.1138 s/iter. Eval: 0.1509 s/iter. Total: 0.2721 s/iter. ETA=0:03:42
[01/18 11:23:22] detectron2.evaluation.evaluator INFO: Inference done 295/1093. Dataloading: 0.0074 s/iter. Inference: 0.1138 s/iter. Eval: 0.1518 s/iter. Total: 0.2731 s/iter. ETA=0:03:37
[01/18 11:23:27] detectron2.evaluation.evaluator INFO: Inference done 316/1093. Dataloading: 0.0073 s/iter. Inference: 0.1138 s/iter. Eval: 0.1495 s/iter. Total: 0.2707 s/iter. ETA=0:03:30
[01/18 11:23:32] detectron2.evaluation.evaluator INFO: Inference done 336/1093. Dataloading: 0.0073 s/iter. Inference: 0.1138 s/iter. Eval: 0.1485 s/iter. Total: 0.2697 s/iter. ETA=0:03:24
[01/18 11:23:37] detectron2.evaluation.evaluator INFO: Inference done 354/1093. Dataloading: 0.0073 s/iter. Inference: 0.1138 s/iter. Eval: 0.1496 s/iter. Total: 0.2707 s/iter. ETA=0:03:20
[01/18 11:23:42] detectron2.evaluation.evaluator INFO: Inference done 372/1093. Dataloading: 0.0073 s/iter. Inference: 0.1140 s/iter. Eval: 0.1498 s/iter. Total: 0.2712 s/iter. ETA=0:03:15
[01/18 11:23:47] detectron2.evaluation.evaluator INFO: Inference done 389/1093. Dataloading: 0.0073 s/iter. Inference: 0.1140 s/iter. Eval: 0.1509 s/iter. Total: 0.2723 s/iter. ETA=0:03:11
[01/18 11:23:52] detectron2.evaluation.evaluator INFO: Inference done 406/1093. Dataloading: 0.0074 s/iter. Inference: 0.1143 s/iter. Eval: 0.1517 s/iter. Total: 0.2734 s/iter. ETA=0:03:07
[01/18 11:23:57] detectron2.evaluation.evaluator INFO: Inference done 424/1093. Dataloading: 0.0074 s/iter. Inference: 0.1143 s/iter. Eval: 0.1521 s/iter. Total: 0.2738 s/iter. ETA=0:03:03
[01/18 11:24:03] detectron2.evaluation.evaluator INFO: Inference done 444/1093. Dataloading: 0.0074 s/iter. Inference: 0.1143 s/iter. Eval: 0.1515 s/iter. Total: 0.2731 s/iter. ETA=0:02:57
[01/18 11:24:08] detectron2.evaluation.evaluator INFO: Inference done 464/1093. Dataloading: 0.0073 s/iter. Inference: 0.1142 s/iter. Eval: 0.1507 s/iter. Total: 0.2723 s/iter. ETA=0:02:51
[01/18 11:24:13] detectron2.evaluation.evaluator INFO: Inference done 483/1093. Dataloading: 0.0073 s/iter. Inference: 0.1143 s/iter. Eval: 0.1504 s/iter. Total: 0.2721 s/iter. ETA=0:02:45
[01/18 11:24:18] detectron2.evaluation.evaluator INFO: Inference done 501/1093. Dataloading: 0.0073 s/iter. Inference: 0.1143 s/iter. Eval: 0.1510 s/iter. Total: 0.2727 s/iter. ETA=0:02:41
[01/18 11:24:23] detectron2.evaluation.evaluator INFO: Inference done 519/1093. Dataloading: 0.0074 s/iter. Inference: 0.1145 s/iter. Eval: 0.1510 s/iter. Total: 0.2731 s/iter. ETA=0:02:36
[01/18 11:24:28] detectron2.evaluation.evaluator INFO: Inference done 538/1093. Dataloading: 0.0074 s/iter. Inference: 0.1145 s/iter. Eval: 0.1509 s/iter. Total: 0.2729 s/iter. ETA=0:02:31
[01/18 11:24:33] detectron2.evaluation.evaluator INFO: Inference done 557/1093. Dataloading: 0.0074 s/iter. Inference: 0.1144 s/iter. Eval: 0.1509 s/iter. Total: 0.2728 s/iter. ETA=0:02:26
[01/18 11:24:38] detectron2.evaluation.evaluator INFO: Inference done 575/1093. Dataloading: 0.0074 s/iter. Inference: 0.1144 s/iter. Eval: 0.1513 s/iter. Total: 0.2731 s/iter. ETA=0:02:21
[01/18 11:24:44] detectron2.evaluation.evaluator INFO: Inference done 594/1093. Dataloading: 0.0074 s/iter. Inference: 0.1143 s/iter. Eval: 0.1514 s/iter. Total: 0.2733 s/iter. ETA=0:02:16
[01/18 11:24:49] detectron2.evaluation.evaluator INFO: Inference done 613/1093. Dataloading: 0.0074 s/iter. Inference: 0.1144 s/iter. Eval: 0.1514 s/iter. Total: 0.2732 s/iter. ETA=0:02:11
[01/18 11:24:54] detectron2.evaluation.evaluator INFO: Inference done 632/1093. Dataloading: 0.0074 s/iter. Inference: 0.1143 s/iter. Eval: 0.1513 s/iter. Total: 0.2731 s/iter. ETA=0:02:05
[01/18 11:24:59] detectron2.evaluation.evaluator INFO: Inference done 650/1093. Dataloading: 0.0074 s/iter. Inference: 0.1143 s/iter. Eval: 0.1516 s/iter. Total: 0.2734 s/iter. ETA=0:02:01
[01/18 11:25:04] detectron2.evaluation.evaluator INFO: Inference done 668/1093. Dataloading: 0.0074 s/iter. Inference: 0.1143 s/iter. Eval: 0.1518 s/iter. Total: 0.2736 s/iter. ETA=0:01:56
[01/18 11:25:09] detectron2.evaluation.evaluator INFO: Inference done 687/1093. Dataloading: 0.0074 s/iter. Inference: 0.1143 s/iter. Eval: 0.1520 s/iter. Total: 0.2737 s/iter. ETA=0:01:51
[01/18 11:25:15] detectron2.evaluation.evaluator INFO: Inference done 706/1093. Dataloading: 0.0074 s/iter. Inference: 0.1143 s/iter. Eval: 0.1520 s/iter. Total: 0.2737 s/iter. ETA=0:01:45
[01/18 11:25:20] detectron2.evaluation.evaluator INFO: Inference done 725/1093. Dataloading: 0.0074 s/iter. Inference: 0.1143 s/iter. Eval: 0.1519 s/iter. Total: 0.2736 s/iter. ETA=0:01:40
[01/18 11:25:25] detectron2.evaluation.evaluator INFO: Inference done 746/1093. Dataloading: 0.0074 s/iter. Inference: 0.1143 s/iter. Eval: 0.1512 s/iter. Total: 0.2729 s/iter. ETA=0:01:34
[01/18 11:25:30] detectron2.evaluation.evaluator INFO: Inference done 765/1093. Dataloading: 0.0074 s/iter. Inference: 0.1142 s/iter. Eval: 0.1512 s/iter. Total: 0.2728 s/iter. ETA=0:01:29
[01/18 11:25:35] detectron2.evaluation.evaluator INFO: Inference done 784/1093. Dataloading: 0.0074 s/iter. Inference: 0.1143 s/iter. Eval: 0.1512 s/iter. Total: 0.2729 s/iter. ETA=0:01:24
[01/18 11:25:40] detectron2.evaluation.evaluator INFO: Inference done 803/1093. Dataloading: 0.0074 s/iter. Inference: 0.1144 s/iter. Eval: 0.1509 s/iter. Total: 0.2728 s/iter. ETA=0:01:19
[01/18 11:25:46] detectron2.evaluation.evaluator INFO: Inference done 822/1093. Dataloading: 0.0073 s/iter. Inference: 0.1146 s/iter. Eval: 0.1508 s/iter. Total: 0.2728 s/iter. ETA=0:01:13
[01/18 11:25:51] detectron2.evaluation.evaluator INFO: Inference done 842/1093. Dataloading: 0.0073 s/iter. Inference: 0.1145 s/iter. Eval: 0.1505 s/iter. Total: 0.2724 s/iter. ETA=0:01:08
[01/18 11:25:56] detectron2.evaluation.evaluator INFO: Inference done 862/1093. Dataloading: 0.0073 s/iter. Inference: 0.1144 s/iter. Eval: 0.1504 s/iter. Total: 0.2722 s/iter. ETA=0:01:02
[01/18 11:26:01] detectron2.evaluation.evaluator INFO: Inference done 881/1093. Dataloading: 0.0073 s/iter. Inference: 0.1143 s/iter. Eval: 0.1506 s/iter. Total: 0.2723 s/iter. ETA=0:00:57
[01/18 11:26:06] detectron2.evaluation.evaluator INFO: Inference done 900/1093. Dataloading: 0.0073 s/iter. Inference: 0.1144 s/iter. Eval: 0.1506 s/iter. Total: 0.2724 s/iter. ETA=0:00:52
[01/18 11:26:12] detectron2.evaluation.evaluator INFO: Inference done 919/1093. Dataloading: 0.0073 s/iter. Inference: 0.1144 s/iter. Eval: 0.1507 s/iter. Total: 0.2725 s/iter. ETA=0:00:47
[01/18 11:26:17] detectron2.evaluation.evaluator INFO: Inference done 936/1093. Dataloading: 0.0073 s/iter. Inference: 0.1144 s/iter. Eval: 0.1511 s/iter. Total: 0.2730 s/iter. ETA=0:00:42
[01/18 11:26:22] detectron2.evaluation.evaluator INFO: Inference done 954/1093. Dataloading: 0.0073 s/iter. Inference: 0.1145 s/iter. Eval: 0.1512 s/iter. Total: 0.2731 s/iter. ETA=0:00:37
[01/18 11:26:27] detectron2.evaluation.evaluator INFO: Inference done 975/1093. Dataloading: 0.0073 s/iter. Inference: 0.1145 s/iter. Eval: 0.1505 s/iter. Total: 0.2725 s/iter. ETA=0:00:32
[01/18 11:26:32] detectron2.evaluation.evaluator INFO: Inference done 995/1093. Dataloading: 0.0073 s/iter. Inference: 0.1145 s/iter. Eval: 0.1503 s/iter. Total: 0.2721 s/iter. ETA=0:00:26
[01/18 11:26:37] detectron2.evaluation.evaluator INFO: Inference done 1014/1093. Dataloading: 0.0073 s/iter. Inference: 0.1144 s/iter. Eval: 0.1501 s/iter. Total: 0.2720 s/iter. ETA=0:00:21
[01/18 11:26:42] detectron2.evaluation.evaluator INFO: Inference done 1034/1093. Dataloading: 0.0075 s/iter. Inference: 0.1145 s/iter. Eval: 0.1496 s/iter. Total: 0.2716 s/iter. ETA=0:00:16
[01/18 11:26:47] detectron2.evaluation.evaluator INFO: Inference done 1054/1093. Dataloading: 0.0074 s/iter. Inference: 0.1144 s/iter. Eval: 0.1494 s/iter. Total: 0.2714 s/iter. ETA=0:00:10
[01/18 11:26:53] detectron2.evaluation.evaluator INFO: Inference done 1074/1093. Dataloading: 0.0074 s/iter. Inference: 0.1144 s/iter. Eval: 0.1493 s/iter. Total: 0.2711 s/iter. ETA=0:00:05
[01/18 11:26:58] detectron2.evaluation.evaluator INFO: Total inference time: 0:04:54.815214 (0.270970 s / iter per device, on 4 devices)
[01/18 11:26:58] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:04 (0.114265 s / iter per device, on 4 devices)
[01/18 12:12:03] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 12:12:03] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 12:12:03] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 12:12:04] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 12:12:14] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0061 s/iter. Inference: 0.1095 s/iter. Eval: 0.1597 s/iter. Total: 0.2753 s/iter. ETA=0:04:57
[01/18 12:12:19] detectron2.evaluation.evaluator INFO: Inference done 27/1093. Dataloading: 0.0088 s/iter. Inference: 0.1136 s/iter. Eval: 0.1886 s/iter. Total: 0.3110 s/iter. ETA=0:05:31
[01/18 12:12:24] detectron2.evaluation.evaluator INFO: Inference done 44/1093. Dataloading: 0.0087 s/iter. Inference: 0.1125 s/iter. Eval: 0.1827 s/iter. Total: 0.3040 s/iter. ETA=0:05:18
[01/18 12:12:30] detectron2.evaluation.evaluator INFO: Inference done 63/1093. Dataloading: 0.0083 s/iter. Inference: 0.1123 s/iter. Eval: 0.1729 s/iter. Total: 0.2936 s/iter. ETA=0:05:02
[01/18 12:12:35] detectron2.evaluation.evaluator INFO: Inference done 80/1093. Dataloading: 0.0082 s/iter. Inference: 0.1128 s/iter. Eval: 0.1729 s/iter. Total: 0.2939 s/iter. ETA=0:04:57
[01/18 12:12:40] detectron2.evaluation.evaluator INFO: Inference done 101/1093. Dataloading: 0.0078 s/iter. Inference: 0.1130 s/iter. Eval: 0.1628 s/iter. Total: 0.2837 s/iter. ETA=0:04:41
[01/18 12:12:45] detectron2.evaluation.evaluator INFO: Inference done 122/1093. Dataloading: 0.0075 s/iter. Inference: 0.1128 s/iter. Eval: 0.1569 s/iter. Total: 0.2773 s/iter. ETA=0:04:29
[01/18 12:12:50] detectron2.evaluation.evaluator INFO: Inference done 143/1093. Dataloading: 0.0074 s/iter. Inference: 0.1125 s/iter. Eval: 0.1528 s/iter. Total: 0.2728 s/iter. ETA=0:04:19
[01/18 12:12:56] detectron2.evaluation.evaluator INFO: Inference done 163/1093. Dataloading: 0.0073 s/iter. Inference: 0.1126 s/iter. Eval: 0.1520 s/iter. Total: 0.2720 s/iter. ETA=0:04:12
[01/18 12:13:01] detectron2.evaluation.evaluator INFO: Inference done 182/1093. Dataloading: 0.0073 s/iter. Inference: 0.1128 s/iter. Eval: 0.1513 s/iter. Total: 0.2715 s/iter. ETA=0:04:07
[01/18 12:13:06] detectron2.evaluation.evaluator INFO: Inference done 201/1093. Dataloading: 0.0073 s/iter. Inference: 0.1125 s/iter. Eval: 0.1516 s/iter. Total: 0.2715 s/iter. ETA=0:04:02
[01/18 12:13:11] detectron2.evaluation.evaluator INFO: Inference done 222/1093. Dataloading: 0.0073 s/iter. Inference: 0.1123 s/iter. Eval: 0.1494 s/iter. Total: 0.2691 s/iter. ETA=0:03:54
[01/18 12:13:16] detectron2.evaluation.evaluator INFO: Inference done 242/1093. Dataloading: 0.0073 s/iter. Inference: 0.1125 s/iter. Eval: 0.1489 s/iter. Total: 0.2688 s/iter. ETA=0:03:48
[01/18 12:13:21] detectron2.evaluation.evaluator INFO: Inference done 259/1093. Dataloading: 0.0074 s/iter. Inference: 0.1128 s/iter. Eval: 0.1504 s/iter. Total: 0.2707 s/iter. ETA=0:03:45
[01/18 12:13:26] detectron2.evaluation.evaluator INFO: Inference done 279/1093. Dataloading: 0.0074 s/iter. Inference: 0.1127 s/iter. Eval: 0.1494 s/iter. Total: 0.2696 s/iter. ETA=0:03:39
[01/18 12:13:32] detectron2.evaluation.evaluator INFO: Inference done 297/1093. Dataloading: 0.0074 s/iter. Inference: 0.1128 s/iter. Eval: 0.1503 s/iter. Total: 0.2706 s/iter. ETA=0:03:35
[01/18 12:13:37] detectron2.evaluation.evaluator INFO: Inference done 319/1093. Dataloading: 0.0074 s/iter. Inference: 0.1127 s/iter. Eval: 0.1478 s/iter. Total: 0.2679 s/iter. ETA=0:03:27
[01/18 12:13:42] detectron2.evaluation.evaluator INFO: Inference done 339/1093. Dataloading: 0.0073 s/iter. Inference: 0.1128 s/iter. Eval: 0.1470 s/iter. Total: 0.2672 s/iter. ETA=0:03:21
[01/18 12:13:47] detectron2.evaluation.evaluator INFO: Inference done 356/1093. Dataloading: 0.0074 s/iter. Inference: 0.1131 s/iter. Eval: 0.1484 s/iter. Total: 0.2689 s/iter. ETA=0:03:18
[01/18 12:13:52] detectron2.evaluation.evaluator INFO: Inference done 374/1093. Dataloading: 0.0074 s/iter. Inference: 0.1135 s/iter. Eval: 0.1484 s/iter. Total: 0.2694 s/iter. ETA=0:03:13
[01/18 12:13:57] detectron2.evaluation.evaluator INFO: Inference done 391/1093. Dataloading: 0.0077 s/iter. Inference: 0.1135 s/iter. Eval: 0.1495 s/iter. Total: 0.2708 s/iter. ETA=0:03:10
[01/18 12:14:02] detectron2.evaluation.evaluator INFO: Inference done 408/1093. Dataloading: 0.0077 s/iter. Inference: 0.1137 s/iter. Eval: 0.1504 s/iter. Total: 0.2719 s/iter. ETA=0:03:06
[01/18 12:14:07] detectron2.evaluation.evaluator INFO: Inference done 425/1093. Dataloading: 0.0078 s/iter. Inference: 0.1141 s/iter. Eval: 0.1508 s/iter. Total: 0.2728 s/iter. ETA=0:03:02
[01/18 12:14:12] detectron2.evaluation.evaluator INFO: Inference done 445/1093. Dataloading: 0.0077 s/iter. Inference: 0.1142 s/iter. Eval: 0.1500 s/iter. Total: 0.2720 s/iter. ETA=0:02:56
[01/18 12:14:17] detectron2.evaluation.evaluator INFO: Inference done 465/1093. Dataloading: 0.0077 s/iter. Inference: 0.1142 s/iter. Eval: 0.1491 s/iter. Total: 0.2711 s/iter. ETA=0:02:50
[01/18 12:14:22] detectron2.evaluation.evaluator INFO: Inference done 485/1093. Dataloading: 0.0077 s/iter. Inference: 0.1142 s/iter. Eval: 0.1487 s/iter. Total: 0.2706 s/iter. ETA=0:02:44
[01/18 12:14:28] detectron2.evaluation.evaluator INFO: Inference done 503/1093. Dataloading: 0.0076 s/iter. Inference: 0.1140 s/iter. Eval: 0.1492 s/iter. Total: 0.2710 s/iter. ETA=0:02:39
[01/18 12:14:33] detectron2.evaluation.evaluator INFO: Inference done 522/1093. Dataloading: 0.0076 s/iter. Inference: 0.1139 s/iter. Eval: 0.1496 s/iter. Total: 0.2712 s/iter. ETA=0:02:34
[01/18 12:14:38] detectron2.evaluation.evaluator INFO: Inference done 541/1093. Dataloading: 0.0076 s/iter. Inference: 0.1139 s/iter. Eval: 0.1494 s/iter. Total: 0.2711 s/iter. ETA=0:02:29
[01/18 12:14:43] detectron2.evaluation.evaluator INFO: Inference done 560/1093. Dataloading: 0.0076 s/iter. Inference: 0.1138 s/iter. Eval: 0.1494 s/iter. Total: 0.2709 s/iter. ETA=0:02:24
[01/18 12:14:48] detectron2.evaluation.evaluator INFO: Inference done 578/1093. Dataloading: 0.0076 s/iter. Inference: 0.1138 s/iter. Eval: 0.1500 s/iter. Total: 0.2716 s/iter. ETA=0:02:19
[01/18 12:14:53] detectron2.evaluation.evaluator INFO: Inference done 597/1093. Dataloading: 0.0076 s/iter. Inference: 0.1137 s/iter. Eval: 0.1501 s/iter. Total: 0.2715 s/iter. ETA=0:02:14
[01/18 12:14:58] detectron2.evaluation.evaluator INFO: Inference done 616/1093. Dataloading: 0.0076 s/iter. Inference: 0.1137 s/iter. Eval: 0.1499 s/iter. Total: 0.2713 s/iter. ETA=0:02:09
[01/18 12:15:03] detectron2.evaluation.evaluator INFO: Inference done 635/1093. Dataloading: 0.0076 s/iter. Inference: 0.1137 s/iter. Eval: 0.1498 s/iter. Total: 0.2712 s/iter. ETA=0:02:04
[01/18 12:15:08] detectron2.evaluation.evaluator INFO: Inference done 653/1093. Dataloading: 0.0076 s/iter. Inference: 0.1137 s/iter. Eval: 0.1501 s/iter. Total: 0.2714 s/iter. ETA=0:01:59
[01/18 12:15:14] detectron2.evaluation.evaluator INFO: Inference done 671/1093. Dataloading: 0.0076 s/iter. Inference: 0.1139 s/iter. Eval: 0.1502 s/iter. Total: 0.2717 s/iter. ETA=0:01:54
[01/18 12:15:19] detectron2.evaluation.evaluator INFO: Inference done 688/1093. Dataloading: 0.0076 s/iter. Inference: 0.1141 s/iter. Eval: 0.1506 s/iter. Total: 0.2723 s/iter. ETA=0:01:50
[01/18 12:15:24] detectron2.evaluation.evaluator INFO: Inference done 705/1093. Dataloading: 0.0078 s/iter. Inference: 0.1142 s/iter. Eval: 0.1508 s/iter. Total: 0.2728 s/iter. ETA=0:01:45
[01/18 12:15:29] detectron2.evaluation.evaluator INFO: Inference done 725/1093. Dataloading: 0.0078 s/iter. Inference: 0.1142 s/iter. Eval: 0.1505 s/iter. Total: 0.2726 s/iter. ETA=0:01:40
[01/18 12:15:34] detectron2.evaluation.evaluator INFO: Inference done 745/1093. Dataloading: 0.0077 s/iter. Inference: 0.1143 s/iter. Eval: 0.1500 s/iter. Total: 0.2721 s/iter. ETA=0:01:34
[01/18 12:15:39] detectron2.evaluation.evaluator INFO: Inference done 764/1093. Dataloading: 0.0077 s/iter. Inference: 0.1144 s/iter. Eval: 0.1500 s/iter. Total: 0.2722 s/iter. ETA=0:01:29
[01/18 12:15:44] detectron2.evaluation.evaluator INFO: Inference done 783/1093. Dataloading: 0.0077 s/iter. Inference: 0.1144 s/iter. Eval: 0.1499 s/iter. Total: 0.2721 s/iter. ETA=0:01:24
[01/18 12:15:49] detectron2.evaluation.evaluator INFO: Inference done 803/1093. Dataloading: 0.0077 s/iter. Inference: 0.1143 s/iter. Eval: 0.1498 s/iter. Total: 0.2718 s/iter. ETA=0:01:18
[01/18 12:15:55] detectron2.evaluation.evaluator INFO: Inference done 823/1093. Dataloading: 0.0077 s/iter. Inference: 0.1142 s/iter. Eval: 0.1496 s/iter. Total: 0.2716 s/iter. ETA=0:01:13
[01/18 12:16:00] detectron2.evaluation.evaluator INFO: Inference done 843/1093. Dataloading: 0.0076 s/iter. Inference: 0.1141 s/iter. Eval: 0.1493 s/iter. Total: 0.2711 s/iter. ETA=0:01:07
[01/18 12:16:05] detectron2.evaluation.evaluator INFO: Inference done 862/1093. Dataloading: 0.0076 s/iter. Inference: 0.1141 s/iter. Eval: 0.1492 s/iter. Total: 0.2710 s/iter. ETA=0:01:02
[01/18 12:16:10] detectron2.evaluation.evaluator INFO: Inference done 880/1093. Dataloading: 0.0076 s/iter. Inference: 0.1140 s/iter. Eval: 0.1495 s/iter. Total: 0.2712 s/iter. ETA=0:00:57
[01/18 12:16:15] detectron2.evaluation.evaluator INFO: Inference done 899/1093. Dataloading: 0.0076 s/iter. Inference: 0.1140 s/iter. Eval: 0.1495 s/iter. Total: 0.2711 s/iter. ETA=0:00:52
[01/18 12:16:20] detectron2.evaluation.evaluator INFO: Inference done 918/1093. Dataloading: 0.0076 s/iter. Inference: 0.1139 s/iter. Eval: 0.1495 s/iter. Total: 0.2711 s/iter. ETA=0:00:47
[01/18 12:16:25] detectron2.evaluation.evaluator INFO: Inference done 935/1093. Dataloading: 0.0076 s/iter. Inference: 0.1140 s/iter. Eval: 0.1499 s/iter. Total: 0.2716 s/iter. ETA=0:00:42
[01/18 12:16:30] detectron2.evaluation.evaluator INFO: Inference done 954/1093. Dataloading: 0.0076 s/iter. Inference: 0.1139 s/iter. Eval: 0.1500 s/iter. Total: 0.2715 s/iter. ETA=0:00:37
[01/18 12:16:35] detectron2.evaluation.evaluator INFO: Inference done 975/1093. Dataloading: 0.0076 s/iter. Inference: 0.1139 s/iter. Eval: 0.1494 s/iter. Total: 0.2709 s/iter. ETA=0:00:31
[01/18 12:16:40] detectron2.evaluation.evaluator INFO: Inference done 995/1093. Dataloading: 0.0076 s/iter. Inference: 0.1138 s/iter. Eval: 0.1491 s/iter. Total: 0.2705 s/iter. ETA=0:00:26
[01/18 12:16:45] detectron2.evaluation.evaluator INFO: Inference done 1015/1093. Dataloading: 0.0075 s/iter. Inference: 0.1138 s/iter. Eval: 0.1488 s/iter. Total: 0.2702 s/iter. ETA=0:00:21
[01/18 12:16:51] detectron2.evaluation.evaluator INFO: Inference done 1037/1093. Dataloading: 0.0075 s/iter. Inference: 0.1137 s/iter. Eval: 0.1482 s/iter. Total: 0.2695 s/iter. ETA=0:00:15
[01/18 12:16:56] detectron2.evaluation.evaluator INFO: Inference done 1056/1093. Dataloading: 0.0077 s/iter. Inference: 0.1137 s/iter. Eval: 0.1481 s/iter. Total: 0.2696 s/iter. ETA=0:00:09
[01/18 12:17:01] detectron2.evaluation.evaluator INFO: Inference done 1076/1093. Dataloading: 0.0077 s/iter. Inference: 0.1137 s/iter. Eval: 0.1480 s/iter. Total: 0.2694 s/iter. ETA=0:00:04
[01/18 12:17:06] detectron2.evaluation.evaluator INFO: Total inference time: 0:04:53.040501 (0.269339 s / iter per device, on 4 devices)
[01/18 12:17:06] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:03 (0.113629 s / iter per device, on 4 devices)
[01/18 13:04:44] detectron2.engine.hooks INFO: Overall training speed: 39998 iterations in 16:13:40 (1.4606 s / it)
[01/18 13:04:44] detectron2.engine.hooks INFO: Total training time: 18:33:12 (2:19:32 on hooks)
[01/18 13:04:44] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 13:04:45] detectron2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 13:04:45] detectron2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 13:04:45] detectron2.evaluation.evaluator INFO: Start inference on 1093 batches
[01/18 13:04:56] detectron2.evaluation.evaluator INFO: Inference done 11/1093. Dataloading: 0.0088 s/iter. Inference: 0.1325 s/iter. Eval: 0.1788 s/iter. Total: 0.3201 s/iter. ETA=0:05:46
[01/18 13:05:01] detectron2.evaluation.evaluator INFO: Inference done 27/1093. Dataloading: 0.0107 s/iter. Inference: 0.1216 s/iter. Eval: 0.1972 s/iter. Total: 0.3295 s/iter. ETA=0:05:51
[01/18 13:05:07] detectron2.evaluation.evaluator INFO: Inference done 43/1093. Dataloading: 0.0117 s/iter. Inference: 0.1226 s/iter. Eval: 0.1903 s/iter. Total: 0.3247 s/iter. ETA=0:05:40
[01/18 13:05:12] detectron2.evaluation.evaluator INFO: Inference done 61/1093. Dataloading: 0.0114 s/iter. Inference: 0.1221 s/iter. Eval: 0.1800 s/iter. Total: 0.3137 s/iter. ETA=0:05:23
[01/18 13:05:17] detectron2.evaluation.evaluator INFO: Inference done 78/1093. Dataloading: 0.0113 s/iter. Inference: 0.1204 s/iter. Eval: 0.1802 s/iter. Total: 0.3120 s/iter. ETA=0:05:16
[01/18 13:05:22] detectron2.evaluation.evaluator INFO: Inference done 98/1093. Dataloading: 0.0105 s/iter. Inference: 0.1192 s/iter. Eval: 0.1696 s/iter. Total: 0.2993 s/iter. ETA=0:04:57
[01/18 13:05:27] detectron2.evaluation.evaluator INFO: Inference done 118/1093. Dataloading: 0.0099 s/iter. Inference: 0.1184 s/iter. Eval: 0.1632 s/iter. Total: 0.2915 s/iter. ETA=0:04:44
[01/18 13:05:32] detectron2.evaluation.evaluator INFO: Inference done 137/1093. Dataloading: 0.0099 s/iter. Inference: 0.1178 s/iter. Eval: 0.1608 s/iter. Total: 0.2886 s/iter. ETA=0:04:35
[01/18 13:05:37] detectron2.evaluation.evaluator INFO: Inference done 156/1093. Dataloading: 0.0097 s/iter. Inference: 0.1181 s/iter. Eval: 0.1577 s/iter. Total: 0.2855 s/iter. ETA=0:04:27
[01/18 13:05:42] detectron2.evaluation.evaluator INFO: Inference done 174/1093. Dataloading: 0.0096 s/iter. Inference: 0.1182 s/iter. Eval: 0.1577 s/iter. Total: 0.2856 s/iter. ETA=0:04:22
[01/18 13:05:48] detectron2.evaluation.evaluator INFO: Inference done 192/1093. Dataloading: 0.0096 s/iter. Inference: 0.1181 s/iter. Eval: 0.1573 s/iter. Total: 0.2851 s/iter. ETA=0:04:16
[01/18 13:05:53] detectron2.evaluation.evaluator INFO: Inference done 208/1093. Dataloading: 0.0097 s/iter. Inference: 0.1182 s/iter. Eval: 0.1598 s/iter. Total: 0.2879 s/iter. ETA=0:04:14
[01/18 13:05:58] detectron2.evaluation.evaluator INFO: Inference done 229/1093. Dataloading: 0.0096 s/iter. Inference: 0.1180 s/iter. Eval: 0.1559 s/iter. Total: 0.2836 s/iter. ETA=0:04:05
[01/18 13:06:03] detectron2.evaluation.evaluator INFO: Inference done 247/1093. Dataloading: 0.0096 s/iter. Inference: 0.1180 s/iter. Eval: 0.1560 s/iter. Total: 0.2837 s/iter. ETA=0:04:00
[01/18 13:06:08] detectron2.evaluation.evaluator INFO: Inference done 264/1093. Dataloading: 0.0098 s/iter. Inference: 0.1181 s/iter. Eval: 0.1571 s/iter. Total: 0.2851 s/iter. ETA=0:03:56
[01/18 13:06:13] detectron2.evaluation.evaluator INFO: Inference done 283/1093. Dataloading: 0.0098 s/iter. Inference: 0.1181 s/iter. Eval: 0.1558 s/iter. Total: 0.2837 s/iter. ETA=0:03:49
[01/18 13:06:18] detectron2.evaluation.evaluator INFO: Inference done 300/1093. Dataloading: 0.0098 s/iter. Inference: 0.1185 s/iter. Eval: 0.1562 s/iter. Total: 0.2845 s/iter. ETA=0:03:45
[01/18 13:06:23] detectron2.evaluation.evaluator INFO: Inference done 320/1093. Dataloading: 0.0097 s/iter. Inference: 0.1186 s/iter. Eval: 0.1540 s/iter. Total: 0.2824 s/iter. ETA=0:03:38
[01/18 13:06:28] detectron2.evaluation.evaluator INFO: Inference done 339/1093. Dataloading: 0.0096 s/iter. Inference: 0.1187 s/iter. Eval: 0.1534 s/iter. Total: 0.2817 s/iter. ETA=0:03:32
[01/18 13:06:34] detectron2.evaluation.evaluator INFO: Inference done 357/1093. Dataloading: 0.0096 s/iter. Inference: 0.1184 s/iter. Eval: 0.1543 s/iter. Total: 0.2824 s/iter. ETA=0:03:27
[01/18 13:06:39] detectron2.evaluation.evaluator INFO: Inference done 376/1093. Dataloading: 0.0096 s/iter. Inference: 0.1182 s/iter. Eval: 0.1538 s/iter. Total: 0.2816 s/iter. ETA=0:03:21
[01/18 13:06:44] detectron2.evaluation.evaluator INFO: Inference done 392/1093. Dataloading: 0.0096 s/iter. Inference: 0.1182 s/iter. Eval: 0.1551 s/iter. Total: 0.2830 s/iter. ETA=0:03:18
[01/18 13:06:49] detectron2.evaluation.evaluator INFO: Inference done 409/1093. Dataloading: 0.0096 s/iter. Inference: 0.1180 s/iter. Eval: 0.1563 s/iter. Total: 0.2839 s/iter. ETA=0:03:14
[01/18 13:06:54] detectron2.evaluation.evaluator INFO: Inference done 427/1093. Dataloading: 0.0096 s/iter. Inference: 0.1179 s/iter. Eval: 0.1567 s/iter. Total: 0.2842 s/iter. ETA=0:03:09
[01/18 13:06:59] detectron2.evaluation.evaluator INFO: Inference done 447/1093. Dataloading: 0.0095 s/iter. Inference: 0.1178 s/iter. Eval: 0.1557 s/iter. Total: 0.2831 s/iter. ETA=0:03:02
[01/18 13:07:04] detectron2.evaluation.evaluator INFO: Inference done 466/1093. Dataloading: 0.0095 s/iter. Inference: 0.1178 s/iter. Eval: 0.1550 s/iter. Total: 0.2824 s/iter. ETA=0:02:57
[01/18 13:07:10] detectron2.evaluation.evaluator INFO: Inference done 485/1093. Dataloading: 0.0095 s/iter. Inference: 0.1178 s/iter. Eval: 0.1548 s/iter. Total: 0.2821 s/iter. ETA=0:02:51
[01/18 13:07:15] detectron2.evaluation.evaluator INFO: Inference done 502/1093. Dataloading: 0.0095 s/iter. Inference: 0.1178 s/iter. Eval: 0.1555 s/iter. Total: 0.2828 s/iter. ETA=0:02:47
[01/18 13:07:20] detectron2.evaluation.evaluator INFO: Inference done 520/1093. Dataloading: 0.0095 s/iter. Inference: 0.1177 s/iter. Eval: 0.1557 s/iter. Total: 0.2830 s/iter. ETA=0:02:42
[01/18 13:07:25] detectron2.evaluation.evaluator INFO: Inference done 539/1093. Dataloading: 0.0095 s/iter. Inference: 0.1176 s/iter. Eval: 0.1553 s/iter. Total: 0.2824 s/iter. ETA=0:02:36
[01/18 13:07:30] detectron2.evaluation.evaluator INFO: Inference done 558/1093. Dataloading: 0.0094 s/iter. Inference: 0.1175 s/iter. Eval: 0.1551 s/iter. Total: 0.2821 s/iter. ETA=0:02:30
[01/18 13:07:35] detectron2.evaluation.evaluator INFO: Inference done 575/1093. Dataloading: 0.0095 s/iter. Inference: 0.1174 s/iter. Eval: 0.1557 s/iter. Total: 0.2826 s/iter. ETA=0:02:26
[01/18 13:07:41] detectron2.evaluation.evaluator INFO: Inference done 594/1093. Dataloading: 0.0094 s/iter. Inference: 0.1173 s/iter. Eval: 0.1556 s/iter. Total: 0.2823 s/iter. ETA=0:02:20
[01/18 13:07:46] detectron2.evaluation.evaluator INFO: Inference done 613/1093. Dataloading: 0.0094 s/iter. Inference: 0.1172 s/iter. Eval: 0.1553 s/iter. Total: 0.2820 s/iter. ETA=0:02:15
[01/18 13:07:51] detectron2.evaluation.evaluator INFO: Inference done 632/1093. Dataloading: 0.0094 s/iter. Inference: 0.1172 s/iter. Eval: 0.1551 s/iter. Total: 0.2818 s/iter. ETA=0:02:09
[01/18 13:07:56] detectron2.evaluation.evaluator INFO: Inference done 650/1093. Dataloading: 0.0095 s/iter. Inference: 0.1171 s/iter. Eval: 0.1553 s/iter. Total: 0.2820 s/iter. ETA=0:02:04
[01/18 13:08:01] detectron2.evaluation.evaluator INFO: Inference done 669/1093. Dataloading: 0.0094 s/iter. Inference: 0.1170 s/iter. Eval: 0.1552 s/iter. Total: 0.2817 s/iter. ETA=0:01:59
[01/18 13:08:06] detectron2.evaluation.evaluator INFO: Inference done 687/1093. Dataloading: 0.0094 s/iter. Inference: 0.1170 s/iter. Eval: 0.1554 s/iter. Total: 0.2819 s/iter. ETA=0:01:54
[01/18 13:08:12] detectron2.evaluation.evaluator INFO: Inference done 706/1093. Dataloading: 0.0094 s/iter. Inference: 0.1168 s/iter. Eval: 0.1553 s/iter. Total: 0.2816 s/iter. ETA=0:01:48
[01/18 13:08:17] detectron2.evaluation.evaluator INFO: Inference done 724/1093. Dataloading: 0.0094 s/iter. Inference: 0.1171 s/iter. Eval: 0.1550 s/iter. Total: 0.2816 s/iter. ETA=0:01:43
[01/18 13:08:22] detectron2.evaluation.evaluator INFO: Inference done 744/1093. Dataloading: 0.0094 s/iter. Inference: 0.1171 s/iter. Eval: 0.1545 s/iter. Total: 0.2810 s/iter. ETA=0:01:38
[01/18 13:08:27] detectron2.evaluation.evaluator INFO: Inference done 762/1093. Dataloading: 0.0094 s/iter. Inference: 0.1171 s/iter. Eval: 0.1544 s/iter. Total: 0.2809 s/iter. ETA=0:01:32
[01/18 13:08:32] detectron2.evaluation.evaluator INFO: Inference done 780/1093. Dataloading: 0.0093 s/iter. Inference: 0.1171 s/iter. Eval: 0.1543 s/iter. Total: 0.2809 s/iter. ETA=0:01:27
[01/18 13:08:37] detectron2.evaluation.evaluator INFO: Inference done 799/1093. Dataloading: 0.0093 s/iter. Inference: 0.1171 s/iter. Eval: 0.1541 s/iter. Total: 0.2806 s/iter. ETA=0:01:22
[01/18 13:08:42] detectron2.evaluation.evaluator INFO: Inference done 818/1093. Dataloading: 0.0093 s/iter. Inference: 0.1172 s/iter. Eval: 0.1540 s/iter. Total: 0.2806 s/iter. ETA=0:01:17
[01/18 13:08:47] detectron2.evaluation.evaluator INFO: Inference done 837/1093. Dataloading: 0.0093 s/iter. Inference: 0.1171 s/iter. Eval: 0.1537 s/iter. Total: 0.2802 s/iter. ETA=0:01:11
[01/18 13:08:53] detectron2.evaluation.evaluator INFO: Inference done 857/1093. Dataloading: 0.0093 s/iter. Inference: 0.1171 s/iter. Eval: 0.1533 s/iter. Total: 0.2798 s/iter. ETA=0:01:06
[01/18 13:08:58] detectron2.evaluation.evaluator INFO: Inference done 875/1093. Dataloading: 0.0093 s/iter. Inference: 0.1170 s/iter. Eval: 0.1536 s/iter. Total: 0.2799 s/iter. ETA=0:01:01
[01/18 13:09:03] detectron2.evaluation.evaluator INFO: Inference done 893/1093. Dataloading: 0.0093 s/iter. Inference: 0.1170 s/iter. Eval: 0.1537 s/iter. Total: 0.2801 s/iter. ETA=0:00:56
[01/18 13:09:08] detectron2.evaluation.evaluator INFO: Inference done 911/1093. Dataloading: 0.0093 s/iter. Inference: 0.1170 s/iter. Eval: 0.1538 s/iter. Total: 0.2802 s/iter. ETA=0:00:50
[01/18 13:09:13] detectron2.evaluation.evaluator INFO: Inference done 929/1093. Dataloading: 0.0093 s/iter. Inference: 0.1170 s/iter. Eval: 0.1541 s/iter. Total: 0.2804 s/iter. ETA=0:00:45
[01/18 13:09:18] detectron2.evaluation.evaluator INFO: Inference done 947/1093. Dataloading: 0.0093 s/iter. Inference: 0.1169 s/iter. Eval: 0.1543 s/iter. Total: 0.2806 s/iter. ETA=0:00:40
[01/18 13:09:24] detectron2.evaluation.evaluator INFO: Inference done 967/1093. Dataloading: 0.0093 s/iter. Inference: 0.1168 s/iter. Eval: 0.1539 s/iter. Total: 0.2801 s/iter. ETA=0:00:35
[01/18 13:09:29] detectron2.evaluation.evaluator INFO: Inference done 987/1093. Dataloading: 0.0092 s/iter. Inference: 0.1168 s/iter. Eval: 0.1534 s/iter. Total: 0.2795 s/iter. ETA=0:00:29
[01/18 13:09:34] detectron2.evaluation.evaluator INFO: Inference done 1007/1093. Dataloading: 0.0092 s/iter. Inference: 0.1167 s/iter. Eval: 0.1530 s/iter. Total: 0.2790 s/iter. ETA=0:00:23
[01/18 13:09:39] detectron2.evaluation.evaluator INFO: Inference done 1026/1093. Dataloading: 0.0092 s/iter. Inference: 0.1168 s/iter. Eval: 0.1528 s/iter. Total: 0.2789 s/iter. ETA=0:00:18
[01/18 13:09:44] detectron2.evaluation.evaluator INFO: Inference done 1046/1093. Dataloading: 0.0091 s/iter. Inference: 0.1168 s/iter. Eval: 0.1525 s/iter. Total: 0.2786 s/iter. ETA=0:00:13
[01/18 13:09:50] detectron2.evaluation.evaluator INFO: Inference done 1065/1093. Dataloading: 0.0092 s/iter. Inference: 0.1168 s/iter. Eval: 0.1525 s/iter. Total: 0.2786 s/iter. ETA=0:00:07
[01/18 13:09:55] detectron2.evaluation.evaluator INFO: Inference done 1084/1093. Dataloading: 0.0091 s/iter. Inference: 0.1168 s/iter. Eval: 0.1524 s/iter. Total: 0.2785 s/iter. ETA=0:00:02
[01/18 13:09:57] detectron2.evaluation.evaluator INFO: Total inference time: 0:05:03.107681 (0.278592 s / iter per device, on 4 devices)
[01/18 13:09:57] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:07 (0.116798 s / iter per device, on 4 devices)
