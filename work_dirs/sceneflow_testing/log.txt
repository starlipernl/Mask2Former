[01/18 15:24:22] detectron2 INFO: Rank of current process: 0. World size: 4
[01/18 15:24:25] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/18 15:24:25] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/18 15:24:25] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/18 15:24:25] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_testing[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/18 15:24:25] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_testing/config.yaml
[01/18 15:24:25] d2.utils.env INFO: Using a generated random seed 25793653
[01/18 15:26:29] detectron2 INFO: Rank of current process: 0. World size: 4
[01/18 15:26:32] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/18 15:26:32] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/18 15:26:32] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/18 15:26:32] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_testing[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/18 15:26:32] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_testing/config.yaml
[01/18 15:26:32] d2.utils.env INFO: Using a generated random seed 32524841
[01/18 15:26:34] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/18 15:26:34] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 15:26:38] d2.data.build INFO: Using training sampler TrainingSampler
[01/18 15:26:38] d2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/18 15:26:38] d2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/18 15:26:38] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/18 15:26:38] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/18 15:26:38] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/18 15:26:38] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/18 15:26:38] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/18 15:26:38] d2.engine.train_loop INFO: Starting training from iteration 0
[01/18 15:27:45] d2.utils.events INFO:  eta: 23:21:53  iter: 19  total_loss: 148.7  loss_ce: 9.791  loss_mask: 0.5657  loss_dice: 4.905  loss_ce_0: 9.344  loss_mask_0: 0.3541  loss_dice_0: 4.863  loss_ce_1: 9.164  loss_mask_1: 0.3584  loss_dice_1: 4.885  loss_ce_2: 9.473  loss_mask_2: 0.3838  loss_dice_2: 4.888  loss_ce_3: 9.688  loss_mask_3: 0.485  loss_dice_3: 4.895  loss_ce_4: 9.735  loss_mask_4: 0.4916  loss_dice_4: 4.9  loss_ce_5: 9.796  loss_mask_5: 0.5786  loss_dice_5: 4.905  loss_ce_6: 9.808  loss_mask_6: 0.563  loss_dice_6: 4.907  loss_ce_7: 9.797  loss_mask_7: 0.5806  loss_dice_7: 4.906  loss_ce_8: 9.837  loss_mask_8: 0.5932  loss_dice_8: 4.904  time: 2.5904  data_time: 0.5314  lr: 9.9957e-06  max_mem: 20418M
[01/18 15:28:18] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 15:28:19] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 15:28:19] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 15:32:07] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 24.755617408821045, 'error_1pix': 0.0009001004568917805, 'error_3pix': 0.0008823351885737523, 'mIoU': 0.009387302246720904, 'fwIoU': 0.04291167643502538, 'IoU-0': nan, 'IoU-1': 0.15245698091000429, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.0, 'IoU-32': 1.6499050504604091, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.521598615148463, 'pACC': 1.6651633868562241, 'ACC-0': nan, 'ACC-1': 0.15263471431199596, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.0, 'ACC-32': 99.9942993941929, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/18 15:32:07] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/18 15:32:07] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/18 15:32:07] d2.evaluation.testing INFO: copypaste: 24.7556,0.0009,0.0009,0.0094,0.0429,0.5216,1.6652
[01/18 15:32:07] d2.utils.events INFO:  eta: 21:56:43  iter: 39  total_loss: 134.3  loss_ce: 9.257  loss_mask: 0.5213  loss_dice: 4.505  loss_ce_0: 9.122  loss_mask_0: 0.3045  loss_dice_0: 4.473  loss_ce_1: 8.144  loss_mask_1: 0.2978  loss_dice_1: 4.447  loss_ce_2: 7.985  loss_mask_2: 0.2953  loss_dice_2: 4.451  loss_ce_3: 7.971  loss_mask_3: 0.2994  loss_dice_3: 4.443  loss_ce_4: 8.062  loss_mask_4: 0.3026  loss_dice_4: 4.448  loss_ce_5: 8.409  loss_mask_5: 0.3141  loss_dice_5: 4.447  loss_ce_6: 8.818  loss_mask_6: 0.3364  loss_dice_6: 4.458  loss_ce_7: 9.03  loss_mask_7: 0.4251  loss_dice_7: 4.434  loss_ce_8: 9.202  loss_mask_8: 0.4718  loss_dice_8: 4.448  time: 2.1167  data_time: 0.0733  lr: 9.9912e-06  max_mem: 20418M
[01/18 15:32:37] d2.utils.events INFO:  eta: 18:11:58  iter: 59  total_loss: 114.4  loss_ce: 7.523  loss_mask: 0.3136  loss_dice: 4.479  loss_ce_0: 9.021  loss_mask_0: 0.3238  loss_dice_0: 4.462  loss_ce_1: 7.326  loss_mask_1: 0.329  loss_dice_1: 4.44  loss_ce_2: 6.545  loss_mask_2: 0.3221  loss_dice_2: 4.443  loss_ce_3: 6.061  loss_mask_3: 0.3317  loss_dice_3: 4.454  loss_ce_4: 5.818  loss_mask_4: 0.3348  loss_dice_4: 4.472  loss_ce_5: 5.822  loss_mask_5: 0.3309  loss_dice_5: 4.465  loss_ce_6: 5.836  loss_mask_6: 0.3292  loss_dice_6: 4.453  loss_ce_7: 5.99  loss_mask_7: 0.3291  loss_dice_7: 4.462  loss_ce_8: 6.573  loss_mask_8: 0.3281  loss_dice_8: 4.469  time: 1.8958  data_time: 0.0626  lr: 9.9867e-06  max_mem: 20418M
[01/18 15:33:06] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 15:33:07] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 15:33:07] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 15:34:11] d2.engine.hooks INFO: Overall training speed: 77 iterations in 0:02:19 (1.8097 s / it)
[01/18 15:34:11] d2.engine.hooks INFO: Total training time: 0:07:12 (0:04:53 on hooks)
[01/18 15:34:11] d2.utils.events INFO:  eta: 17:30:14  iter: 79  total_loss: 94.57  loss_ce: 3.357  loss_mask: 0.3609  loss_dice: 4.548  loss_ce_0: 8.915  loss_mask_0: 0.3246  loss_dice_0: 4.491  loss_ce_1: 6.677  loss_mask_1: 0.3339  loss_dice_1: 4.489  loss_ce_2: 5.367  loss_mask_2: 0.3351  loss_dice_2: 4.524  loss_ce_3: 4.459  loss_mask_3: 0.3482  loss_dice_3: 4.519  loss_ce_4: 3.886  loss_mask_4: 0.3569  loss_dice_4: 4.535  loss_ce_5: 3.492  loss_mask_5: 0.3587  loss_dice_5: 4.539  loss_ce_6: 3.323  loss_mask_6: 0.3537  loss_dice_6: 4.538  loss_ce_7: 3.234  loss_mask_7: 0.3568  loss_dice_7: 4.538  loss_ce_8: 3.252  loss_mask_8: 0.359  loss_dice_8: 4.553  time: 1.7865  data_time: 0.0639  lr: 9.9822e-06  max_mem: 20856M
[01/18 15:34:31] detectron2 INFO: Rank of current process: 0. World size: 4
[01/18 15:34:34] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/18 15:34:34] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/18 15:34:34] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/18 15:34:34] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_testing[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/18 15:34:34] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_testing/config.yaml
[01/18 15:34:34] d2.utils.env INFO: Using a generated random seed 34987087
[01/18 15:34:36] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/18 15:34:36] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 15:34:39] d2.data.build INFO: Using training sampler TrainingSampler
[01/18 15:34:39] d2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/18 15:34:40] d2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/18 15:34:40] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/18 15:34:40] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/18 15:34:40] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/18 15:34:40] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/18 15:34:40] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/18 15:34:40] d2.engine.train_loop INFO: Starting training from iteration 0
[01/18 15:35:42] d2.utils.events INFO:  eta: 21:29:49  iter: 19  total_loss: 149.8  loss_ce: 10.05  loss_mask: 0.5638  loss_dice: 4.905  loss_ce_0: 9.25  loss_mask_0: 0.3637  loss_dice_0: 4.864  loss_ce_1: 9.329  loss_mask_1: 0.383  loss_dice_1: 4.889  loss_ce_2: 9.655  loss_mask_2: 0.4015  loss_dice_2: 4.916  loss_ce_3: 9.792  loss_mask_3: 0.4509  loss_dice_3: 4.901  loss_ce_4: 9.926  loss_mask_4: 0.4917  loss_dice_4: 4.9  loss_ce_5: 9.919  loss_mask_5: 0.5749  loss_dice_5: 4.894  loss_ce_6: 9.962  loss_mask_6: 0.5658  loss_dice_6: 4.894  loss_ce_7: 9.985  loss_mask_7: 0.5862  loss_dice_7: 4.892  loss_ce_8: 9.991  loss_mask_8: 0.5557  loss_dice_8: 4.901  time: 2.3679  data_time: 0.5024  lr: 9.9957e-06  max_mem: 20567M
[01/18 15:36:12] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 15:36:13] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 15:36:13] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 15:39:35] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 24.903189849589666, 'error_1pix': 0.9508715261778037, 'error_3pix': 0.8891594611091346, 'mIoU': 0.013095013012390133, 'fwIoU': 0.039290305492746126, 'IoU-0': nan, 'IoU-1': 0.00017217710305093663, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.8790605026288191, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 1.6350098186470354, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5135593117024132, 'pACC': 1.5970174734241824, 'ACC-0': nan, 'ACC-1': 0.00017217946945277508, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 5.019923785132305, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 93.58329188226156, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/18 15:39:35] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/18 15:39:35] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/18 15:39:35] d2.evaluation.testing INFO: copypaste: 24.9032,0.9509,0.8892,0.0131,0.0393,0.5136,1.5970
[01/18 15:39:35] d2.utils.events INFO:  eta: 19:03:55  iter: 39  total_loss: 131.2  loss_ce: 9.205  loss_mask: 0.4392  loss_dice: 4.444  loss_ce_0: 9.01  loss_mask_0: 0.2923  loss_dice_0: 4.423  loss_ce_1: 7.941  loss_mask_1: 0.2858  loss_dice_1: 4.412  loss_ce_2: 7.782  loss_mask_2: 0.2861  loss_dice_2: 4.41  loss_ce_3: 7.719  loss_mask_3: 0.2913  loss_dice_3: 4.42  loss_ce_4: 7.819  loss_mask_4: 0.3006  loss_dice_4: 4.408  loss_ce_5: 7.886  loss_mask_5: 0.31  loss_dice_5: 4.403  loss_ce_6: 8.327  loss_mask_6: 0.3087  loss_dice_6: 4.434  loss_ce_7: 8.787  loss_mask_7: 0.3252  loss_dice_7: 4.439  loss_ce_8: 9.101  loss_mask_8: 0.3773  loss_dice_8: 4.457  time: 1.9240  data_time: 0.0821  lr: 9.9912e-06  max_mem: 20832M
[01/18 15:39:55] d2.engine.hooks INFO: Overall training speed: 51 iterations in 0:01:33 (1.8276 s / it)
[01/18 15:39:55] d2.engine.hooks INFO: Total training time: 0:04:56 (0:03:23 on hooks)
[01/18 15:39:55] d2.utils.events INFO:  eta: 17:05:28  iter: 53  total_loss: 116.6  loss_ce: 7.83  loss_mask: 0.3037  loss_dice: 4.484  loss_ce_0: 8.978  loss_mask_0: 0.3196  loss_dice_0: 4.476  loss_ce_1: 7.409  loss_mask_1: 0.3155  loss_dice_1: 4.463  loss_ce_2: 6.85  loss_mask_2: 0.3205  loss_dice_2: 4.471  loss_ce_3: 6.401  loss_mask_3: 0.3283  loss_dice_3: 4.479  loss_ce_4: 6.168  loss_mask_4: 0.3359  loss_dice_4: 4.481  loss_ce_5: 6.017  loss_mask_5: 0.3423  loss_dice_5: 4.491  loss_ce_6: 6.118  loss_mask_6: 0.3324  loss_dice_6: 4.473  loss_ce_7: 6.368  loss_mask_7: 0.3316  loss_dice_7: 4.478  loss_ce_8: 6.914  loss_mask_8: 0.3171  loss_dice_8: 4.474  time: 1.8024  data_time: 0.0802  lr: 9.9883e-06  max_mem: 20832M
[01/18 15:41:01] detectron2 INFO: Rank of current process: 0. World size: 4
[01/18 15:41:05] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5,6,7     Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/18 15:41:05] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/18 15:41:05] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/18 15:41:05] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_testing[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/18 15:41:05] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_testing/config.yaml
[01/18 15:41:05] d2.utils.env INFO: Using a generated random seed 5869712
[01/18 15:41:06] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/18 15:41:07] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 15:41:14] d2.data.build INFO: Using training sampler TrainingSampler
[01/18 15:41:16] d2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/18 15:41:16] d2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/18 15:41:16] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/18 15:41:16] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/18 15:41:17] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/18 15:41:17] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/18 15:41:17] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/18 15:41:17] d2.engine.train_loop INFO: Starting training from iteration 0
[01/18 15:42:21] d2.utils.events INFO:  eta: 19:48:35  iter: 19  total_loss: 148.6  loss_ce: 9.822  loss_mask: 0.576  loss_dice: 4.91  loss_ce_0: 9.325  loss_mask_0: 0.3451  loss_dice_0: 4.883  loss_ce_1: 9.218  loss_mask_1: 0.3722  loss_dice_1: 4.892  loss_ce_2: 9.444  loss_mask_2: 0.4288  loss_dice_2: 4.904  loss_ce_3: 9.649  loss_mask_3: 0.4287  loss_dice_3: 4.91  loss_ce_4: 9.728  loss_mask_4: 0.4341  loss_dice_4: 4.913  loss_ce_5: 9.773  loss_mask_5: 0.5107  loss_dice_5: 4.91  loss_ce_6: 9.812  loss_mask_6: 0.5241  loss_dice_6: 4.91  loss_ce_7: 9.781  loss_mask_7: 0.5936  loss_dice_7: 4.904  loss_ce_8: 9.772  loss_mask_8: 0.5794  loss_dice_8: 4.912  time: 2.2105  data_time: 0.8214  lr: 9.9957e-05  max_mem: 18248M
[01/18 15:42:49] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 15:42:51] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 15:42:51] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 16:57:34] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 150, in train
    self.after_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 180, in after_step
    h.after_step()
  File "/home/nstarli/detectron2/detectron2/engine/hooks.py", line 552, in after_step
    self._do_eval()
  File "/home/nstarli/detectron2/detectron2/engine/hooks.py", line 525, in _do_eval
    results = self._func()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 453, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/home/nstarli/Mask2Former/train_net_stereo.py", line 281, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/home/nstarli/Mask2Former/train_net_stereo.py", line 415, in inference_on_dataset
    results = evaluator.evaluate()
  File "/home/nstarli/Mask2Former/train_net_stereo.py", line 536, in evaluate
    conf_matrix_list = all_gather(self._conf_matrix)
  File "/home/nstarli/detectron2/detectron2/utils/comm.py", line 120, in all_gather
    dist.all_gather_object(output, data, group=group)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1527, in all_gather_object
    all_gather(object_size_list, local_size, group=group)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1914, in all_gather
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1623448278899/work/third_party/gloo/gloo/transport/tcp/unbound_buffer.cc:136] Timed out waiting 1800000ms for send operation to complete
[01/18 16:58:56] detectron2 INFO: Rank of current process: 0. World size: 4
[01/18 16:59:01] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5,6,7     Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/18 16:59:01] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/18 16:59:01] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/18 16:59:01] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_testing[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/18 16:59:01] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_testing/config.yaml
[01/18 16:59:01] d2.utils.env INFO: Using a generated random seed 1887145
[01/18 16:59:03] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/18 16:59:03] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 16:59:11] d2.data.build INFO: Using training sampler TrainingSampler
[01/18 16:59:11] d2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/18 16:59:11] d2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/18 16:59:11] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/18 16:59:11] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/18 16:59:12] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/18 16:59:12] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/18 16:59:12] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/18 16:59:12] d2.engine.train_loop INFO: Starting training from iteration 0
[01/18 17:00:16] d2.utils.events INFO:  eta: 20:10:55  iter: 19  total_loss: 145.3  loss_ce: 9.808  loss_mask: 0.5402  loss_dice: 4.645  loss_ce_0: 9.08  loss_mask_0: 0.3313  loss_dice_0: 4.75  loss_ce_1: 8.858  loss_mask_1: 0.3532  loss_dice_1: 4.726  loss_ce_2: 9.238  loss_mask_2: 0.3679  loss_dice_2: 4.748  loss_ce_3: 9.497  loss_mask_3: 0.4147  loss_dice_3: 4.698  loss_ce_4: 9.54  loss_mask_4: 0.4865  loss_dice_4: 4.581  loss_ce_5: 9.677  loss_mask_5: 0.5158  loss_dice_5: 4.589  loss_ce_6: 9.731  loss_mask_6: 0.5363  loss_dice_6: 4.574  loss_ce_7: 9.726  loss_mask_7: 0.5665  loss_dice_7: 4.55  loss_ce_8: 9.743  loss_mask_8: 0.5369  loss_dice_8: 4.596  time: 2.1932  data_time: 0.8187  lr: 9.9957e-05  max_mem: 18183M
[01/18 17:00:45] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 17:00:46] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 17:00:46] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 17:35:01] detectron2 INFO: Rank of current process: 0. World size: 4
[01/18 17:35:05] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5,6,7     Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/18 17:35:05] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/18 17:35:05] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/18 17:35:05] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_testing[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/18 17:35:05] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_testing/config.yaml
[01/18 17:35:05] d2.utils.env INFO: Using a generated random seed 5867686
[01/18 17:35:06] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/18 17:35:07] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 17:35:15] d2.data.build INFO: Using training sampler TrainingSampler
[01/18 17:35:16] d2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/18 17:35:16] d2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/18 17:35:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/18 17:35:17] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/18 17:35:17] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/18 17:35:17] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/18 17:35:17] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/18 17:35:17] d2.engine.train_loop INFO: Starting training from iteration 0
[01/18 17:36:20] d2.utils.events INFO:  eta: 19:37:40  iter: 19  total_loss: 147.3  loss_ce: 9.667  loss_mask: 0.332  loss_dice: 4.913  loss_ce_0: 9.355  loss_mask_0: 0.3506  loss_dice_0: 4.869  loss_ce_1: 9.056  loss_mask_1: 0.3548  loss_dice_1: 4.891  loss_ce_2: 9.221  loss_mask_2: 0.3794  loss_dice_2: 4.906  loss_ce_3: 9.411  loss_mask_3: 0.3696  loss_dice_3: 4.917  loss_ce_4: 9.619  loss_mask_4: 0.4119  loss_dice_4: 4.917  loss_ce_5: 9.591  loss_mask_5: 0.4138  loss_dice_5: 4.91  loss_ce_6: 9.695  loss_mask_6: 0.3997  loss_dice_6: 4.916  loss_ce_7: 9.708  loss_mask_7: 0.3801  loss_dice_7: 4.913  loss_ce_8: 9.674  loss_mask_8: 0.3527  loss_dice_8: 4.911  time: 2.1450  data_time: 0.7915  lr: 9.9957e-05  max_mem: 18004M
[01/18 17:36:49] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 17:36:50] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 17:36:50] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 18:03:03] detectron2 INFO: Rank of current process: 0. World size: 4
[01/18 18:03:06] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/18 18:03:06] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/18 18:03:06] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/18 18:03:06] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_testing[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/18 18:03:06] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_testing/config.yaml
[01/18 18:03:06] d2.utils.env INFO: Using a generated random seed 6690482
[01/18 18:03:07] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/18 18:03:07] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 18:03:10] d2.data.build INFO: Using training sampler TrainingSampler
[01/18 18:03:11] d2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/18 18:03:11] d2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/18 18:03:11] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/18 18:03:11] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/18 18:03:11] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/18 18:03:11] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/18 18:03:11] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/18 18:03:11] d2.engine.train_loop INFO: Starting training from iteration 0
[01/18 18:03:52] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 18:03:52] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 18:03:52] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 18:07:14] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 27.740259724199166, 'error_1pix': 0.9709016994758313, 'error_3pix': 0.933658717566624, 'mIoU': 0.004938085867519111, 'fwIoU': 0.008989172871779444, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.9481124865636694, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5208333333333333, 'pACC': 0.9481124865636694, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 100.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/18 18:07:14] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/18 18:07:14] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/18 18:07:14] d2.evaluation.testing INFO: copypaste: 27.7403,0.9709,0.9337,0.0049,0.0090,0.5208,0.9481
[01/18 18:07:32] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 18:07:33] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 18:07:33] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 18:10:51] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 26.94154431472764, 'error_1pix': 0.968679242269625, 'error_3pix': 0.927771088859792, 'mIoU': 0.005256656523866859, 'fwIoU': 0.010186421874245963, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 1.009278052582437, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5208333333333333, 'pACC': 1.009278052582437, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 100.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/18 18:10:51] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/18 18:10:51] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/18 18:10:51] d2.evaluation.testing INFO: copypaste: 26.9415,0.9687,0.9278,0.0053,0.0102,0.5208,1.0093
[01/18 18:10:51] d2.utils.events INFO:  eta: 20:23:00  iter: 19  total_loss: 149.3  loss_ce: 9.952  loss_mask: 0.5243  loss_dice: 4.912  loss_ce_0: 9.345  loss_mask_0: 0.3536  loss_dice_0: 4.857  loss_ce_1: 9.411  loss_mask_1: 0.3672  loss_dice_1: 4.866  loss_ce_2: 9.391  loss_mask_2: 0.4529  loss_dice_2: 4.858  loss_ce_3: 9.701  loss_mask_3: 0.4314  loss_dice_3: 4.893  loss_ce_4: 9.814  loss_mask_4: 0.5175  loss_dice_4: 4.901  loss_ce_5: 9.897  loss_mask_5: 0.6238  loss_dice_5: 4.901  loss_ce_6: 9.84  loss_mask_6: 0.5176  loss_dice_6: 4.903  loss_ce_7: 9.9  loss_mask_7: 0.5591  loss_dice_7: 4.909  loss_ce_8: 9.896  loss_mask_8: 0.5711  loss_dice_8: 4.91  time: 2.2455  data_time: 0.4815  lr: 9.9957e-06  max_mem: 20907M
[01/18 18:11:06] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 18:11:07] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 18:11:07] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 18:14:26] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 25.345160459132607, 'error_1pix': 0.9558054809528369, 'error_3pix': 0.8935189496426155, 'mIoU': 0.0074839327862486135, 'fwIoU': 0.020647249901231412, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 1.4369150949597338, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5208333333333333, 'pACC': 1.4369150949597338, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 100.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/18 18:14:26] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/18 18:14:26] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/18 18:14:26] d2.evaluation.testing INFO: copypaste: 25.3452,0.9558,0.8935,0.0075,0.0206,0.5208,1.4369
[01/18 18:14:41] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 18:14:41] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 18:14:41] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 18:15:36] d2.engine.hooks INFO: Overall training speed: 37 iterations in 0:01:09 (1.8854 s / it)
[01/18 18:15:36] d2.engine.hooks INFO: Total training time: 0:12:06 (0:10:56 on hooks)
[01/18 18:15:36] d2.utils.events INFO:  eta: 18:54:04  iter: 39  total_loss: 132.2  loss_ce: 9.115  loss_mask: 0.4643  loss_dice: 4.498  loss_ce_0: 9.123  loss_mask_0: 0.2992  loss_dice_0: 4.455  loss_ce_1: 8.063  loss_mask_1: 0.305  loss_dice_1: 4.428  loss_ce_2: 7.875  loss_mask_2: 0.3052  loss_dice_2: 4.446  loss_ce_3: 7.8  loss_mask_3: 0.3148  loss_dice_3: 4.44  loss_ce_4: 7.841  loss_mask_4: 0.3142  loss_dice_4: 4.451  loss_ce_5: 8.067  loss_mask_5: 0.3028  loss_dice_5: 4.456  loss_ce_6: 8.356  loss_mask_6: 0.3202  loss_dice_6: 4.44  loss_ce_7: 8.883  loss_mask_7: 0.3314  loss_dice_7: 4.457  loss_ce_8: 9.025  loss_mask_8: 0.3884  loss_dice_8: 4.471  time: 1.8358  data_time: 0.0624  lr: 9.9912e-06  max_mem: 20907M
[01/18 18:16:19] detectron2 INFO: Rank of current process: 0. World size: 4
[01/18 18:16:22] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/18 18:16:22] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/18 18:16:22] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/18 18:16:22] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_testing[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m40000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/18 18:16:22] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_testing/config.yaml
[01/18 18:16:22] d2.utils.env INFO: Using a generated random seed 22707292
[01/18 18:16:24] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/18 18:16:24] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 18:16:26] d2.data.build INFO: Using training sampler TrainingSampler
[01/18 18:16:26] d2.data.common INFO: Serializing 22390 elements to byte tensors and concatenating them all ...
[01/18 18:16:27] d2.data.common INFO: Serialized dataset takes 7.73 MiB
[01/18 18:16:27] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/18 18:16:27] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/18 18:16:27] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/18 18:16:27] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/18 18:16:27] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/18 18:16:27] d2.engine.train_loop INFO: Starting training from iteration 0
[01/18 18:17:25] d2.utils.events INFO:  eta: 20:08:28  iter: 19  total_loss: 148.7  loss_ce: 9.876  loss_mask: 0.5882  loss_dice: 4.913  loss_ce_0: 9.257  loss_mask_0: 0.3248  loss_dice_0: 4.864  loss_ce_1: 9.311  loss_mask_1: 0.3403  loss_dice_1: 4.881  loss_ce_2: 9.557  loss_mask_2: 0.3604  loss_dice_2: 4.895  loss_ce_3: 9.702  loss_mask_3: 0.4327  loss_dice_3: 4.891  loss_ce_4: 9.779  loss_mask_4: 0.4147  loss_dice_4: 4.901  loss_ce_5: 9.828  loss_mask_5: 0.4488  loss_dice_5: 4.911  loss_ce_6: 9.871  loss_mask_6: 0.5266  loss_dice_6: 4.911  loss_ce_7: 9.899  loss_mask_7: 0.5241  loss_dice_7: 4.909  loss_ce_8: 9.853  loss_mask_8: 0.5205  loss_dice_8: 4.912  time: 2.2303  data_time: 0.4531  lr: 9.9957e-06  max_mem: 20333M
[01/18 18:17:54] d2.utils.events INFO:  eta: 18:30:23  iter: 39  total_loss: 130.3  loss_ce: 9.169  loss_mask: 0.4747  loss_dice: 4.472  loss_ce_0: 9.048  loss_mask_0: 0.2879  loss_dice_0: 4.452  loss_ce_1: 8.007  loss_mask_1: 0.2972  loss_dice_1: 4.443  loss_ce_2: 7.891  loss_mask_2: 0.2893  loss_dice_2: 4.446  loss_ce_3: 7.784  loss_mask_3: 0.3007  loss_dice_3: 4.439  loss_ce_4: 7.804  loss_mask_4: 0.2976  loss_dice_4: 4.441  loss_ce_5: 7.895  loss_mask_5: 0.3033  loss_dice_5: 4.442  loss_ce_6: 8.254  loss_mask_6: 0.3093  loss_dice_6: 4.444  loss_ce_7: 8.718  loss_mask_7: 0.3156  loss_dice_7: 4.463  loss_ce_8: 9.098  loss_mask_8: 0.3621  loss_dice_8: 4.471  time: 1.8391  data_time: 0.0664  lr: 9.9912e-06  max_mem: 20333M
[01/18 18:18:24] d2.utils.events INFO:  eta: 16:34:18  iter: 59  total_loss: 110.7  loss_ce: 6.296  loss_mask: 0.3061  loss_dice: 4.532  loss_ce_0: 8.901  loss_mask_0: 0.3132  loss_dice_0: 4.516  loss_ce_1: 7.356  loss_mask_1: 0.3174  loss_dice_1: 4.517  loss_ce_2: 6.622  loss_mask_2: 0.3225  loss_dice_2: 4.523  loss_ce_3: 6.041  loss_mask_3: 0.328  loss_dice_3: 4.524  loss_ce_4: 5.549  loss_mask_4: 0.3357  loss_dice_4: 4.536  loss_ce_5: 5.347  loss_mask_5: 0.3376  loss_dice_5: 4.527  loss_ce_6: 5.289  loss_mask_6: 0.3367  loss_dice_6: 4.53  loss_ce_7: 5.361  loss_mask_7: 0.3329  loss_dice_7: 4.528  loss_ce_8: 5.619  loss_mask_8: 0.3227  loss_dice_8: 4.53  time: 1.7061  data_time: 0.0629  lr: 9.9867e-06  max_mem: 20453M
[01/18 18:18:52] d2.utils.events INFO:  eta: 16:08:44  iter: 79  total_loss: 91.54  loss_ce: 2.781  loss_mask: 0.3616  loss_dice: 4.569  loss_ce_0: 8.826  loss_mask_0: 0.3236  loss_dice_0: 4.523  loss_ce_1: 6.491  loss_mask_1: 0.3249  loss_dice_1: 4.525  loss_ce_2: 5.232  loss_mask_2: 0.3455  loss_dice_2: 4.536  loss_ce_3: 4.197  loss_mask_3: 0.3643  loss_dice_3: 4.546  loss_ce_4: 3.454  loss_mask_4: 0.3653  loss_dice_4: 4.559  loss_ce_5: 3.032  loss_mask_5: 0.367  loss_dice_5: 4.571  loss_ce_6: 2.773  loss_mask_6: 0.3648  loss_dice_6: 4.573  loss_ce_7: 2.647  loss_mask_7: 0.3646  loss_dice_7: 4.573  loss_ce_8: 2.639  loss_mask_8: 0.3648  loss_dice_8: 4.568  time: 1.6279  data_time: 0.0624  lr: 9.9822e-06  max_mem: 20597M
[01/18 18:19:20] d2.utils.events INFO:  eta: 16:06:28  iter: 99  total_loss: 81.43  loss_ce: 1.779  loss_mask: 0.3918  loss_dice: 4.585  loss_ce_0: 8.632  loss_mask_0: 0.3241  loss_dice_0: 4.502  loss_ce_1: 5.761  loss_mask_1: 0.3321  loss_dice_1: 4.517  loss_ce_2: 4.035  loss_mask_2: 0.3494  loss_dice_2: 4.538  loss_ce_3: 2.85  loss_mask_3: 0.3609  loss_dice_3: 4.557  loss_ce_4: 2.257  loss_mask_4: 0.3618  loss_dice_4: 4.572  loss_ce_5: 1.958  loss_mask_5: 0.3598  loss_dice_5: 4.567  loss_ce_6: 1.82  loss_mask_6: 0.3676  loss_dice_6: 4.583  loss_ce_7: 1.766  loss_mask_7: 0.3708  loss_dice_7: 4.583  loss_ce_8: 1.777  loss_mask_8: 0.385  loss_dice_8: 4.582  time: 1.5891  data_time: 0.0630  lr: 9.9777e-06  max_mem: 20597M
[01/18 18:19:49] d2.utils.events INFO:  eta: 16:00:18  iter: 119  total_loss: 76.05  loss_ce: 1.437  loss_mask: 0.3804  loss_dice: 4.622  loss_ce_0: 8.43  loss_mask_0: 0.3367  loss_dice_0: 4.545  loss_ce_1: 4.685  loss_mask_1: 0.3542  loss_dice_1: 4.582  loss_ce_2: 2.745  loss_mask_2: 0.3654  loss_dice_2: 4.606  loss_ce_3: 1.929  loss_mask_3: 0.3719  loss_dice_3: 4.612  loss_ce_4: 1.606  loss_mask_4: 0.3725  loss_dice_4: 4.613  loss_ce_5: 1.495  loss_mask_5: 0.3766  loss_dice_5: 4.609  loss_ce_6: 1.404  loss_mask_6: 0.3801  loss_dice_6: 4.616  loss_ce_7: 1.37  loss_mask_7: 0.3847  loss_dice_7: 4.621  loss_ce_8: 1.404  loss_mask_8: 0.3862  loss_dice_8: 4.621  time: 1.5611  data_time: 0.0628  lr: 9.9732e-06  max_mem: 20597M
[01/18 18:20:17] d2.utils.events INFO:  eta: 15:53:16  iter: 139  total_loss: 72.85  loss_ce: 1.239  loss_mask: 0.4049  loss_dice: 4.6  loss_ce_0: 8.221  loss_mask_0: 0.3509  loss_dice_0: 4.516  loss_ce_1: 3.429  loss_mask_1: 0.3662  loss_dice_1: 4.577  loss_ce_2: 1.933  loss_mask_2: 0.3836  loss_dice_2: 4.606  loss_ce_3: 1.492  loss_mask_3: 0.3927  loss_dice_3: 4.599  loss_ce_4: 1.329  loss_mask_4: 0.3956  loss_dice_4: 4.601  loss_ce_5: 1.24  loss_mask_5: 0.4  loss_dice_5: 4.6  loss_ce_6: 1.236  loss_mask_6: 0.4038  loss_dice_6: 4.6  loss_ce_7: 1.201  loss_mask_7: 0.4093  loss_dice_7: 4.6  loss_ce_8: 1.191  loss_mask_8: 0.4072  loss_dice_8: 4.602  time: 1.5403  data_time: 0.0589  lr: 9.9687e-06  max_mem: 20597M
[01/18 18:20:46] d2.utils.events INFO:  eta: 15:50:58  iter: 159  total_loss: 69.41  loss_ce: 0.9488  loss_mask: 0.4198  loss_dice: 4.648  loss_ce_0: 7.923  loss_mask_0: 0.3645  loss_dice_0: 4.546  loss_ce_1: 2.565  loss_mask_1: 0.3791  loss_dice_1: 4.63  loss_ce_2: 1.464  loss_mask_2: 0.4031  loss_dice_2: 4.647  loss_ce_3: 1.18  loss_mask_3: 0.4156  loss_dice_3: 4.642  loss_ce_4: 1.053  loss_mask_4: 0.4115  loss_dice_4: 4.64  loss_ce_5: 1.01  loss_mask_5: 0.4197  loss_dice_5: 4.647  loss_ce_6: 0.9838  loss_mask_6: 0.4202  loss_dice_6: 4.643  loss_ce_7: 0.9353  loss_mask_7: 0.4243  loss_dice_7: 4.645  loss_ce_8: 0.9279  loss_mask_8: 0.4233  loss_dice_8: 4.646  time: 1.5257  data_time: 0.0666  lr: 9.9642e-06  max_mem: 20597M
[01/18 18:21:14] d2.utils.events INFO:  eta: 15:48:03  iter: 179  total_loss: 67.84  loss_ce: 0.997  loss_mask: 0.4286  loss_dice: 4.642  loss_ce_0: 7.594  loss_mask_0: 0.3766  loss_dice_0: 4.536  loss_ce_1: 2.03  loss_mask_1: 0.3984  loss_dice_1: 4.613  loss_ce_2: 1.305  loss_mask_2: 0.4248  loss_dice_2: 4.631  loss_ce_3: 1.097  loss_mask_3: 0.4375  loss_dice_3: 4.629  loss_ce_4: 1.012  loss_mask_4: 0.4349  loss_dice_4: 4.64  loss_ce_5: 1.003  loss_mask_5: 0.4387  loss_dice_5: 4.63  loss_ce_6: 0.9618  loss_mask_6: 0.4392  loss_dice_6: 4.631  loss_ce_7: 0.9642  loss_mask_7: 0.4368  loss_dice_7: 4.632  loss_ce_8: 0.9605  loss_mask_8: 0.435  loss_dice_8: 4.63  time: 1.5127  data_time: 0.0617  lr: 9.9597e-06  max_mem: 21013M
[01/18 18:21:43] d2.utils.events INFO:  eta: 15:47:11  iter: 199  total_loss: 66.51  loss_ce: 0.8207  loss_mask: 0.436  loss_dice: 4.665  loss_ce_0: 7.185  loss_mask_0: 0.3664  loss_dice_0: 4.569  loss_ce_1: 1.686  loss_mask_1: 0.4109  loss_dice_1: 4.651  loss_ce_2: 1.036  loss_mask_2: 0.438  loss_dice_2: 4.665  loss_ce_3: 0.8616  loss_mask_3: 0.442  loss_dice_3: 4.662  loss_ce_4: 0.862  loss_mask_4: 0.4343  loss_dice_4: 4.666  loss_ce_5: 0.8309  loss_mask_5: 0.4347  loss_dice_5: 4.665  loss_ce_6: 0.8225  loss_mask_6: 0.4343  loss_dice_6: 4.671  loss_ce_7: 0.8162  loss_mask_7: 0.4349  loss_dice_7: 4.666  loss_ce_8: 0.8144  loss_mask_8: 0.435  loss_dice_8: 4.672  time: 1.5040  data_time: 0.0697  lr: 9.9552e-06  max_mem: 21013M
[01/18 18:22:11] d2.utils.events INFO:  eta: 15:45:15  iter: 219  total_loss: 65.28  loss_ce: 0.782  loss_mask: 0.453  loss_dice: 4.656  loss_ce_0: 6.801  loss_mask_0: 0.392  loss_dice_0: 4.547  loss_ce_1: 1.35  loss_mask_1: 0.4294  loss_dice_1: 4.636  loss_ce_2: 0.9401  loss_mask_2: 0.451  loss_dice_2: 4.645  loss_ce_3: 0.8386  loss_mask_3: 0.4565  loss_dice_3: 4.648  loss_ce_4: 0.7873  loss_mask_4: 0.4555  loss_dice_4: 4.65  loss_ce_5: 0.775  loss_mask_5: 0.4497  loss_dice_5: 4.655  loss_ce_6: 0.7686  loss_mask_6: 0.4523  loss_dice_6: 4.659  loss_ce_7: 0.7607  loss_mask_7: 0.448  loss_dice_7: 4.647  loss_ce_8: 0.7521  loss_mask_8: 0.4531  loss_dice_8: 4.646  time: 1.4937  data_time: 0.0611  lr: 9.9507e-06  max_mem: 21013M
[01/18 18:22:39] d2.utils.events INFO:  eta: 15:44:44  iter: 239  total_loss: 64.28  loss_ce: 0.7831  loss_mask: 0.4586  loss_dice: 4.653  loss_ce_0: 6.439  loss_mask_0: 0.3935  loss_dice_0: 4.56  loss_ce_1: 1.211  loss_mask_1: 0.4387  loss_dice_1: 4.647  loss_ce_2: 0.8631  loss_mask_2: 0.4572  loss_dice_2: 4.649  loss_ce_3: 0.7836  loss_mask_3: 0.4646  loss_dice_3: 4.646  loss_ce_4: 0.7548  loss_mask_4: 0.4626  loss_dice_4: 4.655  loss_ce_5: 0.7111  loss_mask_5: 0.4583  loss_dice_5: 4.652  loss_ce_6: 0.7329  loss_mask_6: 0.4617  loss_dice_6: 4.647  loss_ce_7: 0.6979  loss_mask_7: 0.4605  loss_dice_7: 4.655  loss_ce_8: 0.7455  loss_mask_8: 0.4584  loss_dice_8: 4.647  time: 1.4874  data_time: 0.0619  lr: 9.9462e-06  max_mem: 21013M
[01/18 18:23:07] d2.utils.events INFO:  eta: 15:42:31  iter: 259  total_loss: 63.34  loss_ce: 0.7039  loss_mask: 0.4641  loss_dice: 4.635  loss_ce_0: 5.963  loss_mask_0: 0.3962  loss_dice_0: 4.534  loss_ce_1: 1.058  loss_mask_1: 0.4566  loss_dice_1: 4.625  loss_ce_2: 0.7729  loss_mask_2: 0.4707  loss_dice_2: 4.634  loss_ce_3: 0.7298  loss_mask_3: 0.4773  loss_dice_3: 4.639  loss_ce_4: 0.7327  loss_mask_4: 0.4793  loss_dice_4: 4.64  loss_ce_5: 0.7056  loss_mask_5: 0.4728  loss_dice_5: 4.633  loss_ce_6: 0.6904  loss_mask_6: 0.4711  loss_dice_6: 4.634  loss_ce_7: 0.706  loss_mask_7: 0.4744  loss_dice_7: 4.637  loss_ce_8: 0.665  loss_mask_8: 0.4671  loss_dice_8: 4.628  time: 1.4793  data_time: 0.0553  lr: 9.9417e-06  max_mem: 21013M
[01/18 18:23:35] d2.utils.events INFO:  eta: 15:41:15  iter: 279  total_loss: 63.13  loss_ce: 0.663  loss_mask: 0.4661  loss_dice: 4.657  loss_ce_0: 5.583  loss_mask_0: 0.407  loss_dice_0: 4.559  loss_ce_1: 0.9756  loss_mask_1: 0.4573  loss_dice_1: 4.649  loss_ce_2: 0.7521  loss_mask_2: 0.469  loss_dice_2: 4.651  loss_ce_3: 0.7102  loss_mask_3: 0.4689  loss_dice_3: 4.652  loss_ce_4: 0.7063  loss_mask_4: 0.4665  loss_dice_4: 4.65  loss_ce_5: 0.7002  loss_mask_5: 0.4624  loss_dice_5: 4.648  loss_ce_6: 0.7273  loss_mask_6: 0.4594  loss_dice_6: 4.65  loss_ce_7: 0.6984  loss_mask_7: 0.4588  loss_dice_7: 4.65  loss_ce_8: 0.6662  loss_mask_8: 0.4664  loss_dice_8: 4.651  time: 1.4738  data_time: 0.0589  lr: 9.9372e-06  max_mem: 21013M
[01/18 18:24:03] d2.utils.events INFO:  eta: 15:39:58  iter: 299  total_loss: 62.48  loss_ce: 0.6882  loss_mask: 0.4551  loss_dice: 4.645  loss_ce_0: 5.021  loss_mask_0: 0.4059  loss_dice_0: 4.572  loss_ce_1: 0.976  loss_mask_1: 0.4601  loss_dice_1: 4.644  loss_ce_2: 0.7549  loss_mask_2: 0.465  loss_dice_2: 4.647  loss_ce_3: 0.7238  loss_mask_3: 0.4644  loss_dice_3: 4.647  loss_ce_4: 0.7056  loss_mask_4: 0.4604  loss_dice_4: 4.644  loss_ce_5: 0.6855  loss_mask_5: 0.4642  loss_dice_5: 4.649  loss_ce_6: 0.6657  loss_mask_6: 0.4665  loss_dice_6: 4.652  loss_ce_7: 0.6537  loss_mask_7: 0.4607  loss_dice_7: 4.656  loss_ce_8: 0.6461  loss_mask_8: 0.4591  loss_dice_8: 4.656  time: 1.4703  data_time: 0.0660  lr: 9.9327e-06  max_mem: 21013M
[01/18 18:24:32] d2.utils.events INFO:  eta: 15:38:37  iter: 319  total_loss: 62.21  loss_ce: 0.6706  loss_mask: 0.4611  loss_dice: 4.67  loss_ce_0: 4.739  loss_mask_0: 0.4202  loss_dice_0: 4.59  loss_ce_1: 0.8822  loss_mask_1: 0.457  loss_dice_1: 4.665  loss_ce_2: 0.7173  loss_mask_2: 0.4604  loss_dice_2: 4.658  loss_ce_3: 0.674  loss_mask_3: 0.4581  loss_dice_3: 4.669  loss_ce_4: 0.6657  loss_mask_4: 0.4621  loss_dice_4: 4.666  loss_ce_5: 0.6445  loss_mask_5: 0.4584  loss_dice_5: 4.667  loss_ce_6: 0.6688  loss_mask_6: 0.4603  loss_dice_6: 4.661  loss_ce_7: 0.6393  loss_mask_7: 0.4638  loss_dice_7: 4.66  loss_ce_8: 0.6497  loss_mask_8: 0.4577  loss_dice_8: 4.671  time: 1.4663  data_time: 0.0590  lr: 9.9282e-06  max_mem: 21013M
[01/18 18:25:00] d2.utils.events INFO:  eta: 15:37:47  iter: 339  total_loss: 60.68  loss_ce: 0.6048  loss_mask: 0.4515  loss_dice: 4.634  loss_ce_0: 4.266  loss_mask_0: 0.4053  loss_dice_0: 4.568  loss_ce_1: 0.8472  loss_mask_1: 0.4486  loss_dice_1: 4.63  loss_ce_2: 0.6851  loss_mask_2: 0.4542  loss_dice_2: 4.639  loss_ce_3: 0.6475  loss_mask_3: 0.4518  loss_dice_3: 4.628  loss_ce_4: 0.6362  loss_mask_4: 0.4513  loss_dice_4: 4.632  loss_ce_5: 0.5902  loss_mask_5: 0.4527  loss_dice_5: 4.638  loss_ce_6: 0.5812  loss_mask_6: 0.4526  loss_dice_6: 4.637  loss_ce_7: 0.6  loss_mask_7: 0.4462  loss_dice_7: 4.632  loss_ce_8: 0.589  loss_mask_8: 0.4486  loss_dice_8: 4.633  time: 1.4631  data_time: 0.0647  lr: 9.9237e-06  max_mem: 21013M
[01/18 18:25:28] d2.utils.events INFO:  eta: 15:37:08  iter: 359  total_loss: 60.6  loss_ce: 0.5804  loss_mask: 0.4778  loss_dice: 4.656  loss_ce_0: 3.957  loss_mask_0: 0.4234  loss_dice_0: 4.601  loss_ce_1: 0.7891  loss_mask_1: 0.469  loss_dice_1: 4.644  loss_ce_2: 0.6432  loss_mask_2: 0.4689  loss_dice_2: 4.648  loss_ce_3: 0.6224  loss_mask_3: 0.4681  loss_dice_3: 4.656  loss_ce_4: 0.6148  loss_mask_4: 0.4676  loss_dice_4: 4.654  loss_ce_5: 0.5886  loss_mask_5: 0.4713  loss_dice_5: 4.652  loss_ce_6: 0.5696  loss_mask_6: 0.4702  loss_dice_6: 4.65  loss_ce_7: 0.5588  loss_mask_7: 0.4698  loss_dice_7: 4.647  loss_ce_8: 0.5706  loss_mask_8: 0.4719  loss_dice_8: 4.648  time: 1.4601  data_time: 0.0667  lr: 9.9192e-06  max_mem: 21013M
[01/18 18:25:56] d2.utils.events INFO:  eta: 15:36:20  iter: 379  total_loss: 60.04  loss_ce: 0.5713  loss_mask: 0.4651  loss_dice: 4.642  loss_ce_0: 3.669  loss_mask_0: 0.4246  loss_dice_0: 4.588  loss_ce_1: 0.7666  loss_mask_1: 0.4669  loss_dice_1: 4.637  loss_ce_2: 0.6341  loss_mask_2: 0.4658  loss_dice_2: 4.641  loss_ce_3: 0.5982  loss_mask_3: 0.4671  loss_dice_3: 4.635  loss_ce_4: 0.594  loss_mask_4: 0.4653  loss_dice_4: 4.641  loss_ce_5: 0.5726  loss_mask_5: 0.4688  loss_dice_5: 4.63  loss_ce_6: 0.5476  loss_mask_6: 0.4698  loss_dice_6: 4.627  loss_ce_7: 0.5444  loss_mask_7: 0.4677  loss_dice_7: 4.641  loss_ce_8: 0.5338  loss_mask_8: 0.4631  loss_dice_8: 4.636  time: 1.4572  data_time: 0.0579  lr: 9.9147e-06  max_mem: 21111M
[01/18 18:26:24] d2.utils.events INFO:  eta: 15:35:05  iter: 399  total_loss: 59.94  loss_ce: 0.5807  loss_mask: 0.4729  loss_dice: 4.649  loss_ce_0: 3.405  loss_mask_0: 0.4325  loss_dice_0: 4.603  loss_ce_1: 0.6732  loss_mask_1: 0.4759  loss_dice_1: 4.649  loss_ce_2: 0.6046  loss_mask_2: 0.4799  loss_dice_2: 4.635  loss_ce_3: 0.5841  loss_mask_3: 0.4778  loss_dice_3: 4.639  loss_ce_4: 0.5739  loss_mask_4: 0.4756  loss_dice_4: 4.641  loss_ce_5: 0.5606  loss_mask_5: 0.4793  loss_dice_5: 4.641  loss_ce_6: 0.5574  loss_mask_6: 0.4775  loss_dice_6: 4.639  loss_ce_7: 0.5602  loss_mask_7: 0.4754  loss_dice_7: 4.639  loss_ce_8: 0.5667  loss_mask_8: 0.4773  loss_dice_8: 4.64  time: 1.4544  data_time: 0.0614  lr: 9.9102e-06  max_mem: 21111M
[01/18 18:26:52] d2.utils.events INFO:  eta: 15:34:01  iter: 419  total_loss: 59.82  loss_ce: 0.5756  loss_mask: 0.4802  loss_dice: 4.664  loss_ce_0: 3.297  loss_mask_0: 0.447  loss_dice_0: 4.62  loss_ce_1: 0.7475  loss_mask_1: 0.4876  loss_dice_1: 4.653  loss_ce_2: 0.6192  loss_mask_2: 0.4876  loss_dice_2: 4.655  loss_ce_3: 0.5757  loss_mask_3: 0.4855  loss_dice_3: 4.653  loss_ce_4: 0.5713  loss_mask_4: 0.4842  loss_dice_4: 4.651  loss_ce_5: 0.5639  loss_mask_5: 0.483  loss_dice_5: 4.662  loss_ce_6: 0.5507  loss_mask_6: 0.4818  loss_dice_6: 4.652  loss_ce_7: 0.5451  loss_mask_7: 0.4799  loss_dice_7: 4.653  loss_ce_8: 0.5542  loss_mask_8: 0.4804  loss_dice_8: 4.662  time: 1.4515  data_time: 0.0574  lr: 9.9057e-06  max_mem: 21111M
[01/18 18:27:21] d2.utils.events INFO:  eta: 15:33:48  iter: 439  total_loss: 59.58  loss_ce: 0.5868  loss_mask: 0.4644  loss_dice: 4.638  loss_ce_0: 3.172  loss_mask_0: 0.4295  loss_dice_0: 4.618  loss_ce_1: 0.7195  loss_mask_1: 0.469  loss_dice_1: 4.649  loss_ce_2: 0.6273  loss_mask_2: 0.4727  loss_dice_2: 4.648  loss_ce_3: 0.5829  loss_mask_3: 0.4727  loss_dice_3: 4.643  loss_ce_4: 0.5978  loss_mask_4: 0.4719  loss_dice_4: 4.642  loss_ce_5: 0.5723  loss_mask_5: 0.4693  loss_dice_5: 4.646  loss_ce_6: 0.5646  loss_mask_6: 0.4694  loss_dice_6: 4.644  loss_ce_7: 0.581  loss_mask_7: 0.4661  loss_dice_7: 4.644  loss_ce_8: 0.5716  loss_mask_8: 0.4672  loss_dice_8: 4.645  time: 1.4503  data_time: 0.0656  lr: 9.9012e-06  max_mem: 21111M
[01/18 18:27:49] d2.utils.events INFO:  eta: 15:32:39  iter: 459  total_loss: 59.19  loss_ce: 0.5469  loss_mask: 0.4795  loss_dice: 4.635  loss_ce_0: 2.942  loss_mask_0: 0.4481  loss_dice_0: 4.609  loss_ce_1: 0.6696  loss_mask_1: 0.4811  loss_dice_1: 4.637  loss_ce_2: 0.5786  loss_mask_2: 0.4832  loss_dice_2: 4.634  loss_ce_3: 0.5505  loss_mask_3: 0.483  loss_dice_3: 4.633  loss_ce_4: 0.5396  loss_mask_4: 0.4821  loss_dice_4: 4.63  loss_ce_5: 0.5317  loss_mask_5: 0.4835  loss_dice_5: 4.635  loss_ce_6: 0.5278  loss_mask_6: 0.4772  loss_dice_6: 4.633  loss_ce_7: 0.5313  loss_mask_7: 0.4775  loss_dice_7: 4.628  loss_ce_8: 0.527  loss_mask_8: 0.4793  loss_dice_8: 4.626  time: 1.4482  data_time: 0.0593  lr: 9.8967e-06  max_mem: 21111M
[01/18 18:28:18] d2.utils.events INFO:  eta: 15:32:36  iter: 479  total_loss: 59.37  loss_ce: 0.5784  loss_mask: 0.4678  loss_dice: 4.632  loss_ce_0: 2.925  loss_mask_0: 0.4382  loss_dice_0: 4.604  loss_ce_1: 0.6995  loss_mask_1: 0.4747  loss_dice_1: 4.629  loss_ce_2: 0.6139  loss_mask_2: 0.4766  loss_dice_2: 4.632  loss_ce_3: 0.579  loss_mask_3: 0.4737  loss_dice_3: 4.625  loss_ce_4: 0.5805  loss_mask_4: 0.4711  loss_dice_4: 4.632  loss_ce_5: 0.5682  loss_mask_5: 0.4731  loss_dice_5: 4.631  loss_ce_6: 0.5583  loss_mask_6: 0.4705  loss_dice_6: 4.631  loss_ce_7: 0.5729  loss_mask_7: 0.4677  loss_dice_7: 4.633  loss_ce_8: 0.5594  loss_mask_8: 0.4707  loss_dice_8: 4.628  time: 1.4475  data_time: 0.0601  lr: 9.8922e-06  max_mem: 21111M
[01/18 18:28:46] d2.utils.events INFO:  eta: 15:32:11  iter: 499  total_loss: 59.17  loss_ce: 0.5737  loss_mask: 0.4816  loss_dice: 4.631  loss_ce_0: 2.839  loss_mask_0: 0.4561  loss_dice_0: 4.609  loss_ce_1: 0.6548  loss_mask_1: 0.4835  loss_dice_1: 4.634  loss_ce_2: 0.5789  loss_mask_2: 0.4831  loss_dice_2: 4.636  loss_ce_3: 0.5844  loss_mask_3: 0.485  loss_dice_3: 4.623  loss_ce_4: 0.5811  loss_mask_4: 0.4814  loss_dice_4: 4.622  loss_ce_5: 0.5618  loss_mask_5: 0.4841  loss_dice_5: 4.632  loss_ce_6: 0.5664  loss_mask_6: 0.4856  loss_dice_6: 4.635  loss_ce_7: 0.5648  loss_mask_7: 0.486  loss_dice_7: 4.627  loss_ce_8: 0.5738  loss_mask_8: 0.4854  loss_dice_8: 4.627  time: 1.4469  data_time: 0.0642  lr: 9.8877e-06  max_mem: 21111M
[01/18 18:29:14] d2.utils.events INFO:  eta: 15:31:14  iter: 519  total_loss: 58.77  loss_ce: 0.547  loss_mask: 0.4871  loss_dice: 4.622  loss_ce_0: 2.753  loss_mask_0: 0.4581  loss_dice_0: 4.599  loss_ce_1: 0.651  loss_mask_1: 0.4824  loss_dice_1: 4.628  loss_ce_2: 0.5556  loss_mask_2: 0.4833  loss_dice_2: 4.621  loss_ce_3: 0.5402  loss_mask_3: 0.4841  loss_dice_3: 4.621  loss_ce_4: 0.5438  loss_mask_4: 0.4798  loss_dice_4: 4.618  loss_ce_5: 0.5226  loss_mask_5: 0.4797  loss_dice_5: 4.619  loss_ce_6: 0.5187  loss_mask_6: 0.481  loss_dice_6: 4.62  loss_ce_7: 0.5204  loss_mask_7: 0.4819  loss_dice_7: 4.62  loss_ce_8: 0.5327  loss_mask_8: 0.4842  loss_dice_8: 4.624  time: 1.4449  data_time: 0.0536  lr: 9.8831e-06  max_mem: 21111M
[01/18 18:29:43] d2.utils.events INFO:  eta: 15:31:27  iter: 539  total_loss: 58.89  loss_ce: 0.5936  loss_mask: 0.4724  loss_dice: 4.627  loss_ce_0: 2.641  loss_mask_0: 0.4595  loss_dice_0: 4.614  loss_ce_1: 0.6892  loss_mask_1: 0.4834  loss_dice_1: 4.635  loss_ce_2: 0.6019  loss_mask_2: 0.4796  loss_dice_2: 4.633  loss_ce_3: 0.5702  loss_mask_3: 0.4811  loss_dice_3: 4.629  loss_ce_4: 0.5727  loss_mask_4: 0.475  loss_dice_4: 4.633  loss_ce_5: 0.5581  loss_mask_5: 0.4737  loss_dice_5: 4.627  loss_ce_6: 0.5514  loss_mask_6: 0.4743  loss_dice_6: 4.629  loss_ce_7: 0.5508  loss_mask_7: 0.4732  loss_dice_7: 4.633  loss_ce_8: 0.565  loss_mask_8: 0.4729  loss_dice_8: 4.625  time: 1.4446  data_time: 0.0658  lr: 9.8786e-06  max_mem: 21111M
[01/18 18:30:11] d2.utils.events INFO:  eta: 15:30:29  iter: 559  total_loss: 58.81  loss_ce: 0.5463  loss_mask: 0.4651  loss_dice: 4.641  loss_ce_0: 2.597  loss_mask_0: 0.4487  loss_dice_0: 4.632  loss_ce_1: 0.6493  loss_mask_1: 0.4742  loss_dice_1: 4.652  loss_ce_2: 0.5663  loss_mask_2: 0.4715  loss_dice_2: 4.648  loss_ce_3: 0.5531  loss_mask_3: 0.4731  loss_dice_3: 4.647  loss_ce_4: 0.5656  loss_mask_4: 0.4717  loss_dice_4: 4.645  loss_ce_5: 0.5393  loss_mask_5: 0.4675  loss_dice_5: 4.636  loss_ce_6: 0.5361  loss_mask_6: 0.4703  loss_dice_6: 4.646  loss_ce_7: 0.525  loss_mask_7: 0.4673  loss_dice_7: 4.642  loss_ce_8: 0.5384  loss_mask_8: 0.4657  loss_dice_8: 4.635  time: 1.4430  data_time: 0.0653  lr: 9.8741e-06  max_mem: 21111M
[01/18 18:30:39] d2.utils.events INFO:  eta: 15:29:49  iter: 579  total_loss: 58.64  loss_ce: 0.5365  loss_mask: 0.4918  loss_dice: 4.624  loss_ce_0: 2.563  loss_mask_0: 0.471  loss_dice_0: 4.616  loss_ce_1: 0.6082  loss_mask_1: 0.4922  loss_dice_1: 4.638  loss_ce_2: 0.5612  loss_mask_2: 0.488  loss_dice_2: 4.628  loss_ce_3: 0.5532  loss_mask_3: 0.4865  loss_dice_3: 4.628  loss_ce_4: 0.5504  loss_mask_4: 0.4885  loss_dice_4: 4.628  loss_ce_5: 0.5398  loss_mask_5: 0.4829  loss_dice_5: 4.622  loss_ce_6: 0.5347  loss_mask_6: 0.4853  loss_dice_6: 4.624  loss_ce_7: 0.5302  loss_mask_7: 0.4892  loss_dice_7: 4.62  loss_ce_8: 0.5519  loss_mask_8: 0.4949  loss_dice_8: 4.629  time: 1.4415  data_time: 0.0628  lr: 9.8696e-06  max_mem: 21111M
[01/18 18:31:08] d2.utils.events INFO:  eta: 15:29:21  iter: 599  total_loss: 58.58  loss_ce: 0.5337  loss_mask: 0.4701  loss_dice: 4.63  loss_ce_0: 2.485  loss_mask_0: 0.4574  loss_dice_0: 4.607  loss_ce_1: 0.6371  loss_mask_1: 0.4761  loss_dice_1: 4.633  loss_ce_2: 0.5606  loss_mask_2: 0.474  loss_dice_2: 4.63  loss_ce_3: 0.5408  loss_mask_3: 0.4728  loss_dice_3: 4.631  loss_ce_4: 0.5474  loss_mask_4: 0.4719  loss_dice_4: 4.633  loss_ce_5: 0.5339  loss_mask_5: 0.4712  loss_dice_5: 4.62  loss_ce_6: 0.5413  loss_mask_6: 0.4751  loss_dice_6: 4.63  loss_ce_7: 0.5527  loss_mask_7: 0.4745  loss_dice_7: 4.625  loss_ce_8: 0.5383  loss_mask_8: 0.4687  loss_dice_8: 4.634  time: 1.4409  data_time: 0.0697  lr: 9.8651e-06  max_mem: 21111M
[01/18 18:31:36] d2.utils.events INFO:  eta: 15:28:53  iter: 619  total_loss: 58.21  loss_ce: 0.5155  loss_mask: 0.4812  loss_dice: 4.618  loss_ce_0: 2.41  loss_mask_0: 0.4649  loss_dice_0: 4.605  loss_ce_1: 0.6081  loss_mask_1: 0.4799  loss_dice_1: 4.625  loss_ce_2: 0.5435  loss_mask_2: 0.4792  loss_dice_2: 4.618  loss_ce_3: 0.5291  loss_mask_3: 0.4787  loss_dice_3: 4.613  loss_ce_4: 0.5309  loss_mask_4: 0.4781  loss_dice_4: 4.622  loss_ce_5: 0.5295  loss_mask_5: 0.4796  loss_dice_5: 4.619  loss_ce_6: 0.511  loss_mask_6: 0.4807  loss_dice_6: 4.619  loss_ce_7: 0.5265  loss_mask_7: 0.479  loss_dice_7: 4.611  loss_ce_8: 0.5262  loss_mask_8: 0.4754  loss_dice_8: 4.608  time: 1.4403  data_time: 0.0645  lr: 9.8606e-06  max_mem: 21111M
[01/18 18:32:05] d2.utils.events INFO:  eta: 15:28:24  iter: 639  total_loss: 58.29  loss_ce: 0.5268  loss_mask: 0.4828  loss_dice: 4.61  loss_ce_0: 2.442  loss_mask_0: 0.4703  loss_dice_0: 4.62  loss_ce_1: 0.6026  loss_mask_1: 0.481  loss_dice_1: 4.626  loss_ce_2: 0.5462  loss_mask_2: 0.4773  loss_dice_2: 4.616  loss_ce_3: 0.5193  loss_mask_3: 0.4797  loss_dice_3: 4.611  loss_ce_4: 0.5105  loss_mask_4: 0.4818  loss_dice_4: 4.617  loss_ce_5: 0.5186  loss_mask_5: 0.4809  loss_dice_5: 4.613  loss_ce_6: 0.5194  loss_mask_6: 0.4786  loss_dice_6: 4.615  loss_ce_7: 0.5212  loss_mask_7: 0.48  loss_dice_7: 4.613  loss_ce_8: 0.5273  loss_mask_8: 0.4831  loss_dice_8: 4.607  time: 1.4393  data_time: 0.0665  lr: 9.8561e-06  max_mem: 21111M
[01/18 18:32:33] d2.utils.events INFO:  eta: 15:27:43  iter: 659  total_loss: 58.02  loss_ce: 0.5125  loss_mask: 0.4914  loss_dice: 4.595  loss_ce_0: 2.355  loss_mask_0: 0.4729  loss_dice_0: 4.601  loss_ce_1: 0.5801  loss_mask_1: 0.4861  loss_dice_1: 4.609  loss_ce_2: 0.5264  loss_mask_2: 0.4857  loss_dice_2: 4.605  loss_ce_3: 0.5254  loss_mask_3: 0.4885  loss_dice_3: 4.6  loss_ce_4: 0.5167  loss_mask_4: 0.4896  loss_dice_4: 4.6  loss_ce_5: 0.5005  loss_mask_5: 0.4896  loss_dice_5: 4.605  loss_ce_6: 0.5064  loss_mask_6: 0.491  loss_dice_6: 4.596  loss_ce_7: 0.5125  loss_mask_7: 0.4922  loss_dice_7: 4.605  loss_ce_8: 0.5188  loss_mask_8: 0.4893  loss_dice_8: 4.596  time: 1.4383  data_time: 0.0584  lr: 9.8516e-06  max_mem: 21111M
[01/18 18:33:01] d2.utils.events INFO:  eta: 15:27:28  iter: 679  total_loss: 57.93  loss_ce: 0.4849  loss_mask: 0.4831  loss_dice: 4.636  loss_ce_0: 2.377  loss_mask_0: 0.4771  loss_dice_0: 4.632  loss_ce_1: 0.5775  loss_mask_1: 0.4849  loss_dice_1: 4.64  loss_ce_2: 0.5076  loss_mask_2: 0.4825  loss_dice_2: 4.641  loss_ce_3: 0.4872  loss_mask_3: 0.483  loss_dice_3: 4.635  loss_ce_4: 0.4909  loss_mask_4: 0.4835  loss_dice_4: 4.634  loss_ce_5: 0.4829  loss_mask_5: 0.4829  loss_dice_5: 4.633  loss_ce_6: 0.4773  loss_mask_6: 0.4848  loss_dice_6: 4.631  loss_ce_7: 0.4723  loss_mask_7: 0.4845  loss_dice_7: 4.631  loss_ce_8: 0.4784  loss_mask_8: 0.4844  loss_dice_8: 4.631  time: 1.4378  data_time: 0.0732  lr: 9.8471e-06  max_mem: 21111M
[01/18 18:33:30] d2.utils.events INFO:  eta: 15:26:59  iter: 699  total_loss: 57.78  loss_ce: 0.4733  loss_mask: 0.4988  loss_dice: 4.612  loss_ce_0: 2.332  loss_mask_0: 0.4989  loss_dice_0: 4.626  loss_ce_1: 0.5422  loss_mask_1: 0.4949  loss_dice_1: 4.628  loss_ce_2: 0.491  loss_mask_2: 0.4958  loss_dice_2: 4.621  loss_ce_3: 0.4973  loss_mask_3: 0.5002  loss_dice_3: 4.614  loss_ce_4: 0.4808  loss_mask_4: 0.4963  loss_dice_4: 4.616  loss_ce_5: 0.4763  loss_mask_5: 0.4983  loss_dice_5: 4.607  loss_ce_6: 0.4762  loss_mask_6: 0.4971  loss_dice_6: 4.611  loss_ce_7: 0.4717  loss_mask_7: 0.4989  loss_dice_7: 4.608  loss_ce_8: 0.4745  loss_mask_8: 0.4994  loss_dice_8: 4.618  time: 1.4373  data_time: 0.0709  lr: 9.8426e-06  max_mem: 21111M
[01/18 18:33:58] d2.utils.events INFO:  eta: 15:26:57  iter: 719  total_loss: 57.8  loss_ce: 0.5135  loss_mask: 0.4869  loss_dice: 4.605  loss_ce_0: 2.274  loss_mask_0: 0.4812  loss_dice_0: 4.621  loss_ce_1: 0.5697  loss_mask_1: 0.4945  loss_dice_1: 4.617  loss_ce_2: 0.5343  loss_mask_2: 0.4911  loss_dice_2: 4.61  loss_ce_3: 0.5141  loss_mask_3: 0.4902  loss_dice_3: 4.614  loss_ce_4: 0.4992  loss_mask_4: 0.4898  loss_dice_4: 4.606  loss_ce_5: 0.4986  loss_mask_5: 0.4892  loss_dice_5: 4.603  loss_ce_6: 0.493  loss_mask_6: 0.4914  loss_dice_6: 4.611  loss_ce_7: 0.5018  loss_mask_7: 0.4891  loss_dice_7: 4.61  loss_ce_8: 0.5075  loss_mask_8: 0.4899  loss_dice_8: 4.608  time: 1.4373  data_time: 0.0734  lr: 9.8381e-06  max_mem: 21111M
[01/18 18:34:27] d2.utils.events INFO:  eta: 15:26:07  iter: 739  total_loss: 57.71  loss_ce: 0.4746  loss_mask: 0.4978  loss_dice: 4.588  loss_ce_0: 2.306  loss_mask_0: 0.4919  loss_dice_0: 4.609  loss_ce_1: 0.5454  loss_mask_1: 0.4974  loss_dice_1: 4.608  loss_ce_2: 0.4989  loss_mask_2: 0.4958  loss_dice_2: 4.595  loss_ce_3: 0.4857  loss_mask_3: 0.4976  loss_dice_3: 4.594  loss_ce_4: 0.4837  loss_mask_4: 0.4993  loss_dice_4: 4.591  loss_ce_5: 0.462  loss_mask_5: 0.5016  loss_dice_5: 4.585  loss_ce_6: 0.4578  loss_mask_6: 0.499  loss_dice_6: 4.586  loss_ce_7: 0.4745  loss_mask_7: 0.4988  loss_dice_7: 4.589  loss_ce_8: 0.4658  loss_mask_8: 0.4992  loss_dice_8: 4.596  time: 1.4367  data_time: 0.0715  lr: 9.8336e-06  max_mem: 21111M
[01/18 18:34:55] d2.utils.events INFO:  eta: 15:25:45  iter: 759  total_loss: 58.01  loss_ce: 0.4974  loss_mask: 0.4962  loss_dice: 4.602  loss_ce_0: 2.21  loss_mask_0: 0.5019  loss_dice_0: 4.631  loss_ce_1: 0.5476  loss_mask_1: 0.4995  loss_dice_1: 4.616  loss_ce_2: 0.5233  loss_mask_2: 0.4996  loss_dice_2: 4.608  loss_ce_3: 0.5201  loss_mask_3: 0.4981  loss_dice_3: 4.604  loss_ce_4: 0.5123  loss_mask_4: 0.4961  loss_dice_4: 4.603  loss_ce_5: 0.5078  loss_mask_5: 0.4946  loss_dice_5: 4.601  loss_ce_6: 0.51  loss_mask_6: 0.5003  loss_dice_6: 4.604  loss_ce_7: 0.4776  loss_mask_7: 0.5012  loss_dice_7: 4.602  loss_ce_8: 0.5002  loss_mask_8: 0.5003  loss_dice_8: 4.593  time: 1.4364  data_time: 0.0660  lr: 9.8291e-06  max_mem: 21111M
[01/18 18:35:24] d2.utils.events INFO:  eta: 15:25:06  iter: 779  total_loss: 57.89  loss_ce: 0.4622  loss_mask: 0.5087  loss_dice: 4.598  loss_ce_0: 2.243  loss_mask_0: 0.5023  loss_dice_0: 4.621  loss_ce_1: 0.5511  loss_mask_1: 0.5137  loss_dice_1: 4.605  loss_ce_2: 0.4917  loss_mask_2: 0.5108  loss_dice_2: 4.595  loss_ce_3: 0.5073  loss_mask_3: 0.5091  loss_dice_3: 4.596  loss_ce_4: 0.4983  loss_mask_4: 0.509  loss_dice_4: 4.592  loss_ce_5: 0.4915  loss_mask_5: 0.5089  loss_dice_5: 4.59  loss_ce_6: 0.4781  loss_mask_6: 0.5136  loss_dice_6: 4.59  loss_ce_7: 0.4746  loss_mask_7: 0.5129  loss_dice_7: 4.589  loss_ce_8: 0.4866  loss_mask_8: 0.5142  loss_dice_8: 4.593  time: 1.4358  data_time: 0.0610  lr: 9.8246e-06  max_mem: 21111M
[01/18 18:35:52] d2.utils.events INFO:  eta: 15:24:38  iter: 799  total_loss: 57.76  loss_ce: 0.4883  loss_mask: 0.5195  loss_dice: 4.59  loss_ce_0: 2.187  loss_mask_0: 0.5125  loss_dice_0: 4.616  loss_ce_1: 0.522  loss_mask_1: 0.5188  loss_dice_1: 4.609  loss_ce_2: 0.4781  loss_mask_2: 0.5182  loss_dice_2: 4.606  loss_ce_3: 0.4848  loss_mask_3: 0.5212  loss_dice_3: 4.595  loss_ce_4: 0.4893  loss_mask_4: 0.5197  loss_dice_4: 4.591  loss_ce_5: 0.4903  loss_mask_5: 0.5185  loss_dice_5: 4.593  loss_ce_6: 0.4804  loss_mask_6: 0.518  loss_dice_6: 4.594  loss_ce_7: 0.4795  loss_mask_7: 0.5165  loss_dice_7: 4.595  loss_ce_8: 0.4975  loss_mask_8: 0.5179  loss_dice_8: 4.6  time: 1.4349  data_time: 0.0673  lr: 9.82e-06  max_mem: 21111M
[01/18 18:36:21] d2.utils.events INFO:  eta: 15:24:21  iter: 819  total_loss: 57.52  loss_ce: 0.491  loss_mask: 0.503  loss_dice: 4.575  loss_ce_0: 2.162  loss_mask_0: 0.4954  loss_dice_0: 4.597  loss_ce_1: 0.5398  loss_mask_1: 0.4996  loss_dice_1: 4.593  loss_ce_2: 0.4907  loss_mask_2: 0.5005  loss_dice_2: 4.588  loss_ce_3: 0.4788  loss_mask_3: 0.504  loss_dice_3: 4.579  loss_ce_4: 0.4848  loss_mask_4: 0.5024  loss_dice_4: 4.579  loss_ce_5: 0.4793  loss_mask_5: 0.5012  loss_dice_5: 4.574  loss_ce_6: 0.4868  loss_mask_6: 0.5017  loss_dice_6: 4.573  loss_ce_7: 0.496  loss_mask_7: 0.5013  loss_dice_7: 4.574  loss_ce_8: 0.4835  loss_mask_8: 0.5029  loss_dice_8: 4.576  time: 1.4349  data_time: 0.0722  lr: 9.8155e-06  max_mem: 21111M
[01/18 18:36:49] d2.utils.events INFO:  eta: 15:24:07  iter: 839  total_loss: 57.45  loss_ce: 0.4278  loss_mask: 0.4967  loss_dice: 4.615  loss_ce_0: 2.117  loss_mask_0: 0.4952  loss_dice_0: 4.647  loss_ce_1: 0.4659  loss_mask_1: 0.4996  loss_dice_1: 4.626  loss_ce_2: 0.4393  loss_mask_2: 0.4964  loss_dice_2: 4.622  loss_ce_3: 0.439  loss_mask_3: 0.4968  loss_dice_3: 4.615  loss_ce_4: 0.4415  loss_mask_4: 0.497  loss_dice_4: 4.613  loss_ce_5: 0.4277  loss_mask_5: 0.4959  loss_dice_5: 4.618  loss_ce_6: 0.4214  loss_mask_6: 0.4992  loss_dice_6: 4.617  loss_ce_7: 0.4298  loss_mask_7: 0.5016  loss_dice_7: 4.614  loss_ce_8: 0.4243  loss_mask_8: 0.4973  loss_dice_8: 4.616  time: 1.4345  data_time: 0.0710  lr: 9.811e-06  max_mem: 21111M
[01/18 18:37:17] d2.utils.events INFO:  eta: 15:23:24  iter: 859  total_loss: 57.19  loss_ce: 0.4648  loss_mask: 0.5108  loss_dice: 4.589  loss_ce_0: 2.005  loss_mask_0: 0.5038  loss_dice_0: 4.614  loss_ce_1: 0.4781  loss_mask_1: 0.5104  loss_dice_1: 4.602  loss_ce_2: 0.4564  loss_mask_2: 0.5091  loss_dice_2: 4.589  loss_ce_3: 0.4527  loss_mask_3: 0.511  loss_dice_3: 4.587  loss_ce_4: 0.456  loss_mask_4: 0.51  loss_dice_4: 4.59  loss_ce_5: 0.4552  loss_mask_5: 0.5094  loss_dice_5: 4.588  loss_ce_6: 0.4539  loss_mask_6: 0.5058  loss_dice_6: 4.591  loss_ce_7: 0.4558  loss_mask_7: 0.5087  loss_dice_7: 4.584  loss_ce_8: 0.4599  loss_mask_8: 0.5123  loss_dice_8: 4.592  time: 1.4339  data_time: 0.0665  lr: 9.8065e-06  max_mem: 21111M
[01/18 18:37:46] d2.utils.events INFO:  eta: 15:22:53  iter: 879  total_loss: 57.19  loss_ce: 0.4734  loss_mask: 0.5101  loss_dice: 4.585  loss_ce_0: 2.04  loss_mask_0: 0.511  loss_dice_0: 4.613  loss_ce_1: 0.5031  loss_mask_1: 0.5137  loss_dice_1: 4.594  loss_ce_2: 0.4866  loss_mask_2: 0.5082  loss_dice_2: 4.589  loss_ce_3: 0.468  loss_mask_3: 0.5123  loss_dice_3: 4.584  loss_ce_4: 0.4712  loss_mask_4: 0.5096  loss_dice_4: 4.575  loss_ce_5: 0.4686  loss_mask_5: 0.5108  loss_dice_5: 4.585  loss_ce_6: 0.4704  loss_mask_6: 0.5114  loss_dice_6: 4.584  loss_ce_7: 0.456  loss_mask_7: 0.5119  loss_dice_7: 4.588  loss_ce_8: 0.477  loss_mask_8: 0.5096  loss_dice_8: 4.582  time: 1.4335  data_time: 0.0631  lr: 9.802e-06  max_mem: 21111M
[01/18 18:38:14] d2.utils.events INFO:  eta: 15:22:28  iter: 899  total_loss: 57.35  loss_ce: 0.4561  loss_mask: 0.504  loss_dice: 4.591  loss_ce_0: 2.064  loss_mask_0: 0.5001  loss_dice_0: 4.621  loss_ce_1: 0.5059  loss_mask_1: 0.5055  loss_dice_1: 4.597  loss_ce_2: 0.4834  loss_mask_2: 0.5032  loss_dice_2: 4.595  loss_ce_3: 0.4759  loss_mask_3: 0.5009  loss_dice_3: 4.596  loss_ce_4: 0.4806  loss_mask_4: 0.5015  loss_dice_4: 4.599  loss_ce_5: 0.4767  loss_mask_5: 0.5024  loss_dice_5: 4.587  loss_ce_6: 0.4651  loss_mask_6: 0.5039  loss_dice_6: 4.596  loss_ce_7: 0.4572  loss_mask_7: 0.5028  loss_dice_7: 4.592  loss_ce_8: 0.4587  loss_mask_8: 0.5034  loss_dice_8: 4.59  time: 1.4330  data_time: 0.0685  lr: 9.7975e-06  max_mem: 21111M
[01/18 18:38:42] d2.utils.events INFO:  eta: 15:21:57  iter: 919  total_loss: 57.15  loss_ce: 0.4113  loss_mask: 0.5163  loss_dice: 4.585  loss_ce_0: 2.038  loss_mask_0: 0.5166  loss_dice_0: 4.618  loss_ce_1: 0.4877  loss_mask_1: 0.5189  loss_dice_1: 4.602  loss_ce_2: 0.4426  loss_mask_2: 0.5179  loss_dice_2: 4.595  loss_ce_3: 0.4227  loss_mask_3: 0.5198  loss_dice_3: 4.583  loss_ce_4: 0.4273  loss_mask_4: 0.5141  loss_dice_4: 4.581  loss_ce_5: 0.4166  loss_mask_5: 0.5125  loss_dice_5: 4.581  loss_ce_6: 0.4223  loss_mask_6: 0.5172  loss_dice_6: 4.575  loss_ce_7: 0.4139  loss_mask_7: 0.5205  loss_dice_7: 4.584  loss_ce_8: 0.4144  loss_mask_8: 0.518  loss_dice_8: 4.584  time: 1.4325  data_time: 0.0608  lr: 9.793e-06  max_mem: 21111M
[01/18 18:39:11] d2.utils.events INFO:  eta: 15:21:31  iter: 939  total_loss: 57.18  loss_ce: 0.4606  loss_mask: 0.5217  loss_dice: 4.572  loss_ce_0: 1.974  loss_mask_0: 0.524  loss_dice_0: 4.615  loss_ce_1: 0.4775  loss_mask_1: 0.5196  loss_dice_1: 4.585  loss_ce_2: 0.4628  loss_mask_2: 0.5212  loss_dice_2: 4.578  loss_ce_3: 0.4695  loss_mask_3: 0.52  loss_dice_3: 4.57  loss_ce_4: 0.4588  loss_mask_4: 0.522  loss_dice_4: 4.569  loss_ce_5: 0.4568  loss_mask_5: 0.5213  loss_dice_5: 4.565  loss_ce_6: 0.4546  loss_mask_6: 0.5256  loss_dice_6: 4.561  loss_ce_7: 0.4466  loss_mask_7: 0.5244  loss_dice_7: 4.57  loss_ce_8: 0.4476  loss_mask_8: 0.524  loss_dice_8: 4.561  time: 1.4322  data_time: 0.0723  lr: 9.7885e-06  max_mem: 21157M
[01/18 18:39:39] d2.utils.events INFO:  eta: 15:20:52  iter: 959  total_loss: 57.07  loss_ce: 0.4567  loss_mask: 0.5271  loss_dice: 4.574  loss_ce_0: 1.978  loss_mask_0: 0.5165  loss_dice_0: 4.615  loss_ce_1: 0.5038  loss_mask_1: 0.5206  loss_dice_1: 4.584  loss_ce_2: 0.4832  loss_mask_2: 0.522  loss_dice_2: 4.576  loss_ce_3: 0.4676  loss_mask_3: 0.5229  loss_dice_3: 4.568  loss_ce_4: 0.4591  loss_mask_4: 0.5254  loss_dice_4: 4.56  loss_ce_5: 0.4553  loss_mask_5: 0.5262  loss_dice_5: 4.568  loss_ce_6: 0.4477  loss_mask_6: 0.5252  loss_dice_6: 4.572  loss_ce_7: 0.457  loss_mask_7: 0.5259  loss_dice_7: 4.572  loss_ce_8: 0.4625  loss_mask_8: 0.5261  loss_dice_8: 4.567  time: 1.4315  data_time: 0.0603  lr: 9.784e-06  max_mem: 21164M
[01/18 18:40:07] d2.utils.events INFO:  eta: 15:20:23  iter: 979  total_loss: 57.17  loss_ce: 0.4476  loss_mask: 0.5171  loss_dice: 4.578  loss_ce_0: 1.984  loss_mask_0: 0.5094  loss_dice_0: 4.621  loss_ce_1: 0.4868  loss_mask_1: 0.513  loss_dice_1: 4.595  loss_ce_2: 0.4725  loss_mask_2: 0.513  loss_dice_2: 4.579  loss_ce_3: 0.4662  loss_mask_3: 0.5143  loss_dice_3: 4.575  loss_ce_4: 0.4631  loss_mask_4: 0.5154  loss_dice_4: 4.58  loss_ce_5: 0.4536  loss_mask_5: 0.5132  loss_dice_5: 4.58  loss_ce_6: 0.4482  loss_mask_6: 0.5151  loss_dice_6: 4.582  loss_ce_7: 0.4534  loss_mask_7: 0.5142  loss_dice_7: 4.58  loss_ce_8: 0.4666  loss_mask_8: 0.5153  loss_dice_8: 4.581  time: 1.4309  data_time: 0.0618  lr: 9.7795e-06  max_mem: 21164M
[01/18 18:40:35] d2.utils.events INFO:  eta: 15:19:59  iter: 999  total_loss: 57.02  loss_ce: 0.4561  loss_mask: 0.5222  loss_dice: 4.56  loss_ce_0: 1.94  loss_mask_0: 0.5163  loss_dice_0: 4.595  loss_ce_1: 0.4825  loss_mask_1: 0.5243  loss_dice_1: 4.573  loss_ce_2: 0.4461  loss_mask_2: 0.5243  loss_dice_2: 4.568  loss_ce_3: 0.4508  loss_mask_3: 0.5232  loss_dice_3: 4.551  loss_ce_4: 0.4485  loss_mask_4: 0.5242  loss_dice_4: 4.553  loss_ce_5: 0.4487  loss_mask_5: 0.5229  loss_dice_5: 4.558  loss_ce_6: 0.446  loss_mask_6: 0.5221  loss_dice_6: 4.554  loss_ce_7: 0.4506  loss_mask_7: 0.5199  loss_dice_7: 4.559  loss_ce_8: 0.4467  loss_mask_8: 0.5214  loss_dice_8: 4.56  time: 1.4308  data_time: 0.0715  lr: 9.7749e-06  max_mem: 21164M
[01/18 18:41:04] d2.utils.events INFO:  eta: 15:19:14  iter: 1019  total_loss: 56.9  loss_ce: 0.4511  loss_mask: 0.5052  loss_dice: 4.581  loss_ce_0: 1.843  loss_mask_0: 0.4972  loss_dice_0: 4.609  loss_ce_1: 0.4593  loss_mask_1: 0.5072  loss_dice_1: 4.594  loss_ce_2: 0.4603  loss_mask_2: 0.5032  loss_dice_2: 4.582  loss_ce_3: 0.4516  loss_mask_3: 0.5039  loss_dice_3: 4.577  loss_ce_4: 0.4483  loss_mask_4: 0.5043  loss_dice_4: 4.573  loss_ce_5: 0.4484  loss_mask_5: 0.5024  loss_dice_5: 4.584  loss_ce_6: 0.4456  loss_mask_6: 0.5039  loss_dice_6: 4.581  loss_ce_7: 0.4505  loss_mask_7: 0.5064  loss_dice_7: 4.573  loss_ce_8: 0.4271  loss_mask_8: 0.5042  loss_dice_8: 4.58  time: 1.4309  data_time: 0.0650  lr: 9.7704e-06  max_mem: 21164M
[01/18 18:41:32] d2.utils.events INFO:  eta: 15:18:19  iter: 1039  total_loss: 57.14  loss_ce: 0.4801  loss_mask: 0.517  loss_dice: 4.584  loss_ce_0: 1.876  loss_mask_0: 0.5082  loss_dice_0: 4.599  loss_ce_1: 0.4975  loss_mask_1: 0.5091  loss_dice_1: 4.585  loss_ce_2: 0.4789  loss_mask_2: 0.5064  loss_dice_2: 4.579  loss_ce_3: 0.4862  loss_mask_3: 0.5067  loss_dice_3: 4.572  loss_ce_4: 0.4815  loss_mask_4: 0.5107  loss_dice_4: 4.576  loss_ce_5: 0.4768  loss_mask_5: 0.5123  loss_dice_5: 4.569  loss_ce_6: 0.4785  loss_mask_6: 0.5118  loss_dice_6: 4.572  loss_ce_7: 0.4692  loss_mask_7: 0.5122  loss_dice_7: 4.58  loss_ce_8: 0.4767  loss_mask_8: 0.5139  loss_dice_8: 4.577  time: 1.4307  data_time: 0.0633  lr: 9.7659e-06  max_mem: 21164M
[01/18 18:42:01] d2.utils.events INFO:  eta: 15:17:18  iter: 1059  total_loss: 56.63  loss_ce: 0.4494  loss_mask: 0.5187  loss_dice: 4.558  loss_ce_0: 1.895  loss_mask_0: 0.5022  loss_dice_0: 4.587  loss_ce_1: 0.4919  loss_mask_1: 0.514  loss_dice_1: 4.569  loss_ce_2: 0.4559  loss_mask_2: 0.5147  loss_dice_2: 4.562  loss_ce_3: 0.4307  loss_mask_3: 0.5149  loss_dice_3: 4.553  loss_ce_4: 0.4421  loss_mask_4: 0.5167  loss_dice_4: 4.557  loss_ce_5: 0.452  loss_mask_5: 0.5169  loss_dice_5: 4.56  loss_ce_6: 0.44  loss_mask_6: 0.5152  loss_dice_6: 4.561  loss_ce_7: 0.4512  loss_mask_7: 0.5142  loss_dice_7: 4.559  loss_ce_8: 0.4493  loss_mask_8: 0.5176  loss_dice_8: 4.554  time: 1.4305  data_time: 0.0645  lr: 9.7614e-06  max_mem: 21164M
[01/18 18:42:29] d2.utils.events INFO:  eta: 15:17:05  iter: 1079  total_loss: 56.76  loss_ce: 0.4351  loss_mask: 0.5282  loss_dice: 4.557  loss_ce_0: 1.857  loss_mask_0: 0.5205  loss_dice_0: 4.594  loss_ce_1: 0.474  loss_mask_1: 0.5245  loss_dice_1: 4.578  loss_ce_2: 0.4465  loss_mask_2: 0.523  loss_dice_2: 4.568  loss_ce_3: 0.4534  loss_mask_3: 0.525  loss_dice_3: 4.561  loss_ce_4: 0.4416  loss_mask_4: 0.5243  loss_dice_4: 4.562  loss_ce_5: 0.4411  loss_mask_5: 0.5279  loss_dice_5: 4.559  loss_ce_6: 0.436  loss_mask_6: 0.5279  loss_dice_6: 4.56  loss_ce_7: 0.4402  loss_mask_7: 0.527  loss_dice_7: 4.562  loss_ce_8: 0.4469  loss_mask_8: 0.5267  loss_dice_8: 4.556  time: 1.4302  data_time: 0.0709  lr: 9.7569e-06  max_mem: 21164M
[01/18 18:42:58] d2.utils.events INFO:  eta: 15:16:14  iter: 1099  total_loss: 56.81  loss_ce: 0.4806  loss_mask: 0.5244  loss_dice: 4.537  loss_ce_0: 1.829  loss_mask_0: 0.5183  loss_dice_0: 4.57  loss_ce_1: 0.4979  loss_mask_1: 0.5241  loss_dice_1: 4.555  loss_ce_2: 0.474  loss_mask_2: 0.5235  loss_dice_2: 4.539  loss_ce_3: 0.4634  loss_mask_3: 0.5249  loss_dice_3: 4.545  loss_ce_4: 0.4719  loss_mask_4: 0.5227  loss_dice_4: 4.531  loss_ce_5: 0.4684  loss_mask_5: 0.5245  loss_dice_5: 4.535  loss_ce_6: 0.4636  loss_mask_6: 0.5249  loss_dice_6: 4.535  loss_ce_7: 0.4731  loss_mask_7: 0.5275  loss_dice_7: 4.545  loss_ce_8: 0.4656  loss_mask_8: 0.5281  loss_dice_8: 4.538  time: 1.4299  data_time: 0.0595  lr: 9.7524e-06  max_mem: 21164M
[01/18 18:43:26] d2.utils.events INFO:  eta: 15:15:41  iter: 1119  total_loss: 56.78  loss_ce: 0.4396  loss_mask: 0.5277  loss_dice: 4.562  loss_ce_0: 1.82  loss_mask_0: 0.5203  loss_dice_0: 4.6  loss_ce_1: 0.4607  loss_mask_1: 0.525  loss_dice_1: 4.584  loss_ce_2: 0.4444  loss_mask_2: 0.5248  loss_dice_2: 4.574  loss_ce_3: 0.4502  loss_mask_3: 0.5269  loss_dice_3: 4.561  loss_ce_4: 0.4374  loss_mask_4: 0.5278  loss_dice_4: 4.565  loss_ce_5: 0.4421  loss_mask_5: 0.5293  loss_dice_5: 4.562  loss_ce_6: 0.445  loss_mask_6: 0.5288  loss_dice_6: 4.558  loss_ce_7: 0.4419  loss_mask_7: 0.529  loss_dice_7: 4.559  loss_ce_8: 0.4415  loss_mask_8: 0.5272  loss_dice_8: 4.562  time: 1.4297  data_time: 0.0717  lr: 9.7479e-06  max_mem: 21164M
[01/18 18:43:54] d2.utils.events INFO:  eta: 15:15:04  iter: 1139  total_loss: 56.49  loss_ce: 0.4766  loss_mask: 0.523  loss_dice: 4.523  loss_ce_0: 1.742  loss_mask_0: 0.5157  loss_dice_0: 4.572  loss_ce_1: 0.4687  loss_mask_1: 0.5195  loss_dice_1: 4.542  loss_ce_2: 0.4427  loss_mask_2: 0.517  loss_dice_2: 4.54  loss_ce_3: 0.4392  loss_mask_3: 0.5194  loss_dice_3: 4.533  loss_ce_4: 0.4569  loss_mask_4: 0.5203  loss_dice_4: 4.524  loss_ce_5: 0.4486  loss_mask_5: 0.5177  loss_dice_5: 4.528  loss_ce_6: 0.465  loss_mask_6: 0.5187  loss_dice_6: 4.53  loss_ce_7: 0.4493  loss_mask_7: 0.5207  loss_dice_7: 4.528  loss_ce_8: 0.4518  loss_mask_8: 0.5192  loss_dice_8: 4.532  time: 1.4296  data_time: 0.0604  lr: 9.7434e-06  max_mem: 21164M
[01/18 18:44:22] d2.utils.events INFO:  eta: 15:14:17  iter: 1159  total_loss: 56.83  loss_ce: 0.4616  loss_mask: 0.5442  loss_dice: 4.554  loss_ce_0: 1.738  loss_mask_0: 0.5301  loss_dice_0: 4.584  loss_ce_1: 0.4734  loss_mask_1: 0.5385  loss_dice_1: 4.562  loss_ce_2: 0.4482  loss_mask_2: 0.5382  loss_dice_2: 4.557  loss_ce_3: 0.4524  loss_mask_3: 0.5382  loss_dice_3: 4.547  loss_ce_4: 0.4467  loss_mask_4: 0.5402  loss_dice_4: 4.54  loss_ce_5: 0.4522  loss_mask_5: 0.5416  loss_dice_5: 4.543  loss_ce_6: 0.4561  loss_mask_6: 0.5461  loss_dice_6: 4.547  loss_ce_7: 0.4738  loss_mask_7: 0.5454  loss_dice_7: 4.543  loss_ce_8: 0.4603  loss_mask_8: 0.5445  loss_dice_8: 4.54  time: 1.4289  data_time: 0.0586  lr: 9.7388e-06  max_mem: 21164M
[01/18 18:44:50] d2.utils.events INFO:  eta: 15:13:26  iter: 1179  total_loss: 56.51  loss_ce: 0.4544  loss_mask: 0.5237  loss_dice: 4.529  loss_ce_0: 1.769  loss_mask_0: 0.5168  loss_dice_0: 4.566  loss_ce_1: 0.4784  loss_mask_1: 0.5222  loss_dice_1: 4.548  loss_ce_2: 0.4524  loss_mask_2: 0.5207  loss_dice_2: 4.54  loss_ce_3: 0.4451  loss_mask_3: 0.5235  loss_dice_3: 4.533  loss_ce_4: 0.4555  loss_mask_4: 0.5244  loss_dice_4: 4.532  loss_ce_5: 0.4578  loss_mask_5: 0.5225  loss_dice_5: 4.534  loss_ce_6: 0.4601  loss_mask_6: 0.5205  loss_dice_6: 4.529  loss_ce_7: 0.4581  loss_mask_7: 0.5236  loss_dice_7: 4.527  loss_ce_8: 0.4474  loss_mask_8: 0.5231  loss_dice_8: 4.524  time: 1.4283  data_time: 0.0602  lr: 9.7343e-06  max_mem: 21164M
[01/18 18:45:18] d2.utils.events INFO:  eta: 15:12:35  iter: 1199  total_loss: 56.38  loss_ce: 0.4388  loss_mask: 0.5386  loss_dice: 4.545  loss_ce_0: 1.737  loss_mask_0: 0.5161  loss_dice_0: 4.578  loss_ce_1: 0.457  loss_mask_1: 0.5298  loss_dice_1: 4.553  loss_ce_2: 0.4487  loss_mask_2: 0.5308  loss_dice_2: 4.542  loss_ce_3: 0.4504  loss_mask_3: 0.5345  loss_dice_3: 4.532  loss_ce_4: 0.454  loss_mask_4: 0.5327  loss_dice_4: 4.533  loss_ce_5: 0.4474  loss_mask_5: 0.5337  loss_dice_5: 4.542  loss_ce_6: 0.4336  loss_mask_6: 0.5388  loss_dice_6: 4.533  loss_ce_7: 0.4367  loss_mask_7: 0.535  loss_dice_7: 4.541  loss_ce_8: 0.4284  loss_mask_8: 0.537  loss_dice_8: 4.538  time: 1.4279  data_time: 0.0606  lr: 9.7298e-06  max_mem: 21164M
[01/18 18:45:47] d2.utils.events INFO:  eta: 15:12:14  iter: 1219  total_loss: 56.36  loss_ce: 0.4754  loss_mask: 0.5267  loss_dice: 4.525  loss_ce_0: 1.72  loss_mask_0: 0.5147  loss_dice_0: 4.573  loss_ce_1: 0.4807  loss_mask_1: 0.518  loss_dice_1: 4.546  loss_ce_2: 0.475  loss_mask_2: 0.5211  loss_dice_2: 4.541  loss_ce_3: 0.4699  loss_mask_3: 0.5212  loss_dice_3: 4.527  loss_ce_4: 0.4585  loss_mask_4: 0.5238  loss_dice_4: 4.534  loss_ce_5: 0.4566  loss_mask_5: 0.5263  loss_dice_5: 4.524  loss_ce_6: 0.4669  loss_mask_6: 0.5276  loss_dice_6: 4.522  loss_ce_7: 0.4744  loss_mask_7: 0.5287  loss_dice_7: 4.523  loss_ce_8: 0.4676  loss_mask_8: 0.5304  loss_dice_8: 4.522  time: 1.4276  data_time: 0.0596  lr: 9.7253e-06  max_mem: 21164M
[01/18 18:46:15] d2.utils.events INFO:  eta: 15:11:31  iter: 1239  total_loss: 56.55  loss_ce: 0.4552  loss_mask: 0.5402  loss_dice: 4.535  loss_ce_0: 1.71  loss_mask_0: 0.5343  loss_dice_0: 4.579  loss_ce_1: 0.4677  loss_mask_1: 0.5364  loss_dice_1: 4.557  loss_ce_2: 0.4391  loss_mask_2: 0.5353  loss_dice_2: 4.547  loss_ce_3: 0.4159  loss_mask_3: 0.5381  loss_dice_3: 4.536  loss_ce_4: 0.4291  loss_mask_4: 0.5415  loss_dice_4: 4.537  loss_ce_5: 0.4295  loss_mask_5: 0.5395  loss_dice_5: 4.532  loss_ce_6: 0.4328  loss_mask_6: 0.5424  loss_dice_6: 4.539  loss_ce_7: 0.4323  loss_mask_7: 0.5406  loss_dice_7: 4.539  loss_ce_8: 0.4518  loss_mask_8: 0.5394  loss_dice_8: 4.537  time: 1.4273  data_time: 0.0631  lr: 9.7208e-06  max_mem: 21164M
[01/18 18:46:43] d2.utils.events INFO:  eta: 15:11:24  iter: 1259  total_loss: 56.29  loss_ce: 0.4584  loss_mask: 0.5296  loss_dice: 4.516  loss_ce_0: 1.695  loss_mask_0: 0.5219  loss_dice_0: 4.555  loss_ce_1: 0.4603  loss_mask_1: 0.5264  loss_dice_1: 4.533  loss_ce_2: 0.4675  loss_mask_2: 0.5289  loss_dice_2: 4.517  loss_ce_3: 0.447  loss_mask_3: 0.5317  loss_dice_3: 4.526  loss_ce_4: 0.4651  loss_mask_4: 0.532  loss_dice_4: 4.523  loss_ce_5: 0.4656  loss_mask_5: 0.5329  loss_dice_5: 4.516  loss_ce_6: 0.4704  loss_mask_6: 0.5305  loss_dice_6: 4.514  loss_ce_7: 0.4695  loss_mask_7: 0.53  loss_dice_7: 4.514  loss_ce_8: 0.4555  loss_mask_8: 0.5298  loss_dice_8: 4.513  time: 1.4269  data_time: 0.0681  lr: 9.7163e-06  max_mem: 21164M
[01/18 18:47:11] d2.utils.events INFO:  eta: 15:10:49  iter: 1279  total_loss: 56.24  loss_ce: 0.4376  loss_mask: 0.5388  loss_dice: 4.517  loss_ce_0: 1.618  loss_mask_0: 0.5312  loss_dice_0: 4.555  loss_ce_1: 0.4485  loss_mask_1: 0.5347  loss_dice_1: 4.526  loss_ce_2: 0.4271  loss_mask_2: 0.5399  loss_dice_2: 4.516  loss_ce_3: 0.4311  loss_mask_3: 0.539  loss_dice_3: 4.517  loss_ce_4: 0.4318  loss_mask_4: 0.5417  loss_dice_4: 4.512  loss_ce_5: 0.4302  loss_mask_5: 0.5409  loss_dice_5: 4.514  loss_ce_6: 0.4377  loss_mask_6: 0.5429  loss_dice_6: 4.512  loss_ce_7: 0.4426  loss_mask_7: 0.5388  loss_dice_7: 4.516  loss_ce_8: 0.4251  loss_mask_8: 0.5424  loss_dice_8: 4.511  time: 1.4265  data_time: 0.0608  lr: 9.7118e-06  max_mem: 21164M
[01/18 18:47:40] d2.utils.events INFO:  eta: 15:10:45  iter: 1299  total_loss: 56.14  loss_ce: 0.4384  loss_mask: 0.5195  loss_dice: 4.525  loss_ce_0: 1.594  loss_mask_0: 0.495  loss_dice_0: 4.562  loss_ce_1: 0.4782  loss_mask_1: 0.5125  loss_dice_1: 4.541  loss_ce_2: 0.4356  loss_mask_2: 0.5141  loss_dice_2: 4.534  loss_ce_3: 0.4347  loss_mask_3: 0.5168  loss_dice_3: 4.528  loss_ce_4: 0.4407  loss_mask_4: 0.5131  loss_dice_4: 4.525  loss_ce_5: 0.4345  loss_mask_5: 0.5172  loss_dice_5: 4.522  loss_ce_6: 0.4397  loss_mask_6: 0.5177  loss_dice_6: 4.513  loss_ce_7: 0.4471  loss_mask_7: 0.5189  loss_dice_7: 4.52  loss_ce_8: 0.4373  loss_mask_8: 0.52  loss_dice_8: 4.522  time: 1.4264  data_time: 0.0647  lr: 9.7072e-06  max_mem: 21164M
[01/18 18:48:08] d2.utils.events INFO:  eta: 15:10:31  iter: 1319  total_loss: 56.49  loss_ce: 0.4557  loss_mask: 0.5379  loss_dice: 4.514  loss_ce_0: 1.611  loss_mask_0: 0.5329  loss_dice_0: 4.554  loss_ce_1: 0.492  loss_mask_1: 0.5384  loss_dice_1: 4.531  loss_ce_2: 0.4665  loss_mask_2: 0.541  loss_dice_2: 4.515  loss_ce_3: 0.454  loss_mask_3: 0.5425  loss_dice_3: 4.515  loss_ce_4: 0.4525  loss_mask_4: 0.5425  loss_dice_4: 4.513  loss_ce_5: 0.4633  loss_mask_5: 0.542  loss_dice_5: 4.507  loss_ce_6: 0.4507  loss_mask_6: 0.5398  loss_dice_6: 4.515  loss_ce_7: 0.4583  loss_mask_7: 0.5378  loss_dice_7: 4.518  loss_ce_8: 0.4523  loss_mask_8: 0.5407  loss_dice_8: 4.504  time: 1.4260  data_time: 0.0624  lr: 9.7027e-06  max_mem: 21164M
[01/18 18:48:35] d2.utils.events INFO:  eta: 15:09:25  iter: 1339  total_loss: 55.95  loss_ce: 0.4581  loss_mask: 0.5406  loss_dice: 4.5  loss_ce_0: 1.635  loss_mask_0: 0.5311  loss_dice_0: 4.543  loss_ce_1: 0.4546  loss_mask_1: 0.5423  loss_dice_1: 4.518  loss_ce_2: 0.4391  loss_mask_2: 0.5485  loss_dice_2: 4.509  loss_ce_3: 0.423  loss_mask_3: 0.5465  loss_dice_3: 4.499  loss_ce_4: 0.4193  loss_mask_4: 0.549  loss_dice_4: 4.504  loss_ce_5: 0.4256  loss_mask_5: 0.549  loss_dice_5: 4.499  loss_ce_6: 0.446  loss_mask_6: 0.5474  loss_dice_6: 4.508  loss_ce_7: 0.429  loss_mask_7: 0.5414  loss_dice_7: 4.505  loss_ce_8: 0.448  loss_mask_8: 0.539  loss_dice_8: 4.5  time: 1.4254  data_time: 0.0615  lr: 9.6982e-06  max_mem: 21164M
[01/18 18:49:03] d2.utils.events INFO:  eta: 15:08:43  iter: 1359  total_loss: 55.79  loss_ce: 0.4459  loss_mask: 0.5442  loss_dice: 4.483  loss_ce_0: 1.61  loss_mask_0: 0.5291  loss_dice_0: 4.527  loss_ce_1: 0.478  loss_mask_1: 0.5374  loss_dice_1: 4.5  loss_ce_2: 0.4514  loss_mask_2: 0.5417  loss_dice_2: 4.484  loss_ce_3: 0.4439  loss_mask_3: 0.5418  loss_dice_3: 4.485  loss_ce_4: 0.4331  loss_mask_4: 0.5424  loss_dice_4: 4.486  loss_ce_5: 0.4385  loss_mask_5: 0.5438  loss_dice_5: 4.485  loss_ce_6: 0.4344  loss_mask_6: 0.5421  loss_dice_6: 4.473  loss_ce_7: 0.4368  loss_mask_7: 0.5444  loss_dice_7: 4.474  loss_ce_8: 0.4365  loss_mask_8: 0.5428  loss_dice_8: 4.484  time: 1.4250  data_time: 0.0600  lr: 9.6937e-06  max_mem: 21164M
[01/18 18:49:31] d2.utils.events INFO:  eta: 15:08:13  iter: 1379  total_loss: 56.15  loss_ce: 0.4354  loss_mask: 0.5444  loss_dice: 4.509  loss_ce_0: 1.586  loss_mask_0: 0.5279  loss_dice_0: 4.551  loss_ce_1: 0.4596  loss_mask_1: 0.5393  loss_dice_1: 4.525  loss_ce_2: 0.4358  loss_mask_2: 0.5451  loss_dice_2: 4.511  loss_ce_3: 0.4434  loss_mask_3: 0.5421  loss_dice_3: 4.509  loss_ce_4: 0.4458  loss_mask_4: 0.5444  loss_dice_4: 4.51  loss_ce_5: 0.4549  loss_mask_5: 0.5419  loss_dice_5: 4.508  loss_ce_6: 0.4372  loss_mask_6: 0.5438  loss_dice_6: 4.509  loss_ce_7: 0.4483  loss_mask_7: 0.5412  loss_dice_7: 4.503  loss_ce_8: 0.4521  loss_mask_8: 0.5455  loss_dice_8: 4.496  time: 1.4246  data_time: 0.0615  lr: 9.6892e-06  max_mem: 21164M
[01/18 18:50:00] d2.utils.events INFO:  eta: 15:07:47  iter: 1399  total_loss: 56.09  loss_ce: 0.4252  loss_mask: 0.5454  loss_dice: 4.511  loss_ce_0: 1.534  loss_mask_0: 0.5396  loss_dice_0: 4.55  loss_ce_1: 0.4481  loss_mask_1: 0.5466  loss_dice_1: 4.517  loss_ce_2: 0.4216  loss_mask_2: 0.5479  loss_dice_2: 4.515  loss_ce_3: 0.4257  loss_mask_3: 0.5478  loss_dice_3: 4.513  loss_ce_4: 0.4292  loss_mask_4: 0.5465  loss_dice_4: 4.514  loss_ce_5: 0.4421  loss_mask_5: 0.5485  loss_dice_5: 4.504  loss_ce_6: 0.4403  loss_mask_6: 0.5483  loss_dice_6: 4.508  loss_ce_7: 0.4386  loss_mask_7: 0.5466  loss_dice_7: 4.505  loss_ce_8: 0.439  loss_mask_8: 0.546  loss_dice_8: 4.505  time: 1.4244  data_time: 0.0672  lr: 9.6847e-06  max_mem: 21164M
[01/18 18:50:28] d2.utils.events INFO:  eta: 15:07:24  iter: 1419  total_loss: 55.66  loss_ce: 0.4628  loss_mask: 0.5385  loss_dice: 4.465  loss_ce_0: 1.539  loss_mask_0: 0.5233  loss_dice_0: 4.521  loss_ce_1: 0.4711  loss_mask_1: 0.5303  loss_dice_1: 4.479  loss_ce_2: 0.4624  loss_mask_2: 0.5309  loss_dice_2: 4.478  loss_ce_3: 0.4564  loss_mask_3: 0.5309  loss_dice_3: 4.465  loss_ce_4: 0.4599  loss_mask_4: 0.534  loss_dice_4: 4.462  loss_ce_5: 0.4568  loss_mask_5: 0.5346  loss_dice_5: 4.471  loss_ce_6: 0.463  loss_mask_6: 0.5377  loss_dice_6: 4.462  loss_ce_7: 0.4666  loss_mask_7: 0.5357  loss_dice_7: 4.47  loss_ce_8: 0.4658  loss_mask_8: 0.5386  loss_dice_8: 4.466  time: 1.4241  data_time: 0.0576  lr: 9.6802e-06  max_mem: 21164M
[01/18 18:50:55] d2.utils.events INFO:  eta: 15:06:23  iter: 1439  total_loss: 55.96  loss_ce: 0.4295  loss_mask: 0.566  loss_dice: 4.465  loss_ce_0: 1.582  loss_mask_0: 0.5518  loss_dice_0: 4.524  loss_ce_1: 0.453  loss_mask_1: 0.5615  loss_dice_1: 4.495  loss_ce_2: 0.4304  loss_mask_2: 0.5623  loss_dice_2: 4.478  loss_ce_3: 0.4212  loss_mask_3: 0.5633  loss_dice_3: 4.471  loss_ce_4: 0.4203  loss_mask_4: 0.5628  loss_dice_4: 4.465  loss_ce_5: 0.4184  loss_mask_5: 0.5667  loss_dice_5: 4.464  loss_ce_6: 0.4286  loss_mask_6: 0.5664  loss_dice_6: 4.471  loss_ce_7: 0.4332  loss_mask_7: 0.5646  loss_dice_7: 4.467  loss_ce_8: 0.4336  loss_mask_8: 0.5663  loss_dice_8: 4.462  time: 1.4235  data_time: 0.0619  lr: 9.6756e-06  max_mem: 21164M
[01/18 18:51:23] d2.utils.events INFO:  eta: 15:06:03  iter: 1459  total_loss: 55.63  loss_ce: 0.4248  loss_mask: 0.5411  loss_dice: 4.484  loss_ce_0: 1.484  loss_mask_0: 0.5236  loss_dice_0: 4.539  loss_ce_1: 0.4335  loss_mask_1: 0.5402  loss_dice_1: 4.504  loss_ce_2: 0.4218  loss_mask_2: 0.5426  loss_dice_2: 4.493  loss_ce_3: 0.4335  loss_mask_3: 0.5449  loss_dice_3: 4.474  loss_ce_4: 0.4188  loss_mask_4: 0.5509  loss_dice_4: 4.481  loss_ce_5: 0.422  loss_mask_5: 0.544  loss_dice_5: 4.481  loss_ce_6: 0.4293  loss_mask_6: 0.5437  loss_dice_6: 4.48  loss_ce_7: 0.4366  loss_mask_7: 0.5462  loss_dice_7: 4.48  loss_ce_8: 0.4337  loss_mask_8: 0.5451  loss_dice_8: 4.485  time: 1.4232  data_time: 0.0620  lr: 9.6711e-06  max_mem: 21164M
[01/18 18:51:52] d2.utils.events INFO:  eta: 15:05:17  iter: 1479  total_loss: 55.51  loss_ce: 0.4415  loss_mask: 0.541  loss_dice: 4.461  loss_ce_0: 1.487  loss_mask_0: 0.5242  loss_dice_0: 4.525  loss_ce_1: 0.4466  loss_mask_1: 0.5376  loss_dice_1: 4.484  loss_ce_2: 0.4412  loss_mask_2: 0.5389  loss_dice_2: 4.475  loss_ce_3: 0.4278  loss_mask_3: 0.5425  loss_dice_3: 4.466  loss_ce_4: 0.4235  loss_mask_4: 0.5409  loss_dice_4: 4.472  loss_ce_5: 0.4232  loss_mask_5: 0.5446  loss_dice_5: 4.472  loss_ce_6: 0.4505  loss_mask_6: 0.5446  loss_dice_6: 4.469  loss_ce_7: 0.4435  loss_mask_7: 0.5437  loss_dice_7: 4.463  loss_ce_8: 0.4401  loss_mask_8: 0.5429  loss_dice_8: 4.464  time: 1.4230  data_time: 0.0622  lr: 9.6666e-06  max_mem: 21164M
[01/18 18:52:20] d2.utils.events INFO:  eta: 15:04:35  iter: 1499  total_loss: 55.69  loss_ce: 0.4793  loss_mask: 0.5565  loss_dice: 4.444  loss_ce_0: 1.517  loss_mask_0: 0.539  loss_dice_0: 4.491  loss_ce_1: 0.4752  loss_mask_1: 0.5534  loss_dice_1: 4.455  loss_ce_2: 0.4722  loss_mask_2: 0.5552  loss_dice_2: 4.444  loss_ce_3: 0.4536  loss_mask_3: 0.555  loss_dice_3: 4.439  loss_ce_4: 0.4642  loss_mask_4: 0.5548  loss_dice_4: 4.446  loss_ce_5: 0.4749  loss_mask_5: 0.5533  loss_dice_5: 4.444  loss_ce_6: 0.4756  loss_mask_6: 0.5548  loss_dice_6: 4.448  loss_ce_7: 0.4689  loss_mask_7: 0.5556  loss_dice_7: 4.447  loss_ce_8: 0.4672  loss_mask_8: 0.5574  loss_dice_8: 4.439  time: 1.4226  data_time: 0.0660  lr: 9.6621e-06  max_mem: 21164M
[01/18 18:52:48] d2.utils.events INFO:  eta: 15:04:47  iter: 1519  total_loss: 55.59  loss_ce: 0.4313  loss_mask: 0.5289  loss_dice: 4.477  loss_ce_0: 1.4  loss_mask_0: 0.5126  loss_dice_0: 4.527  loss_ce_1: 0.4734  loss_mask_1: 0.5224  loss_dice_1: 4.494  loss_ce_2: 0.4584  loss_mask_2: 0.5231  loss_dice_2: 4.485  loss_ce_3: 0.4384  loss_mask_3: 0.5235  loss_dice_3: 4.478  loss_ce_4: 0.4447  loss_mask_4: 0.5225  loss_dice_4: 4.468  loss_ce_5: 0.4398  loss_mask_5: 0.5245  loss_dice_5: 4.471  loss_ce_6: 0.4413  loss_mask_6: 0.5246  loss_dice_6: 4.471  loss_ce_7: 0.4473  loss_mask_7: 0.5238  loss_dice_7: 4.469  loss_ce_8: 0.4431  loss_mask_8: 0.526  loss_dice_8: 4.467  time: 1.4227  data_time: 0.0691  lr: 9.6576e-06  max_mem: 21164M
[01/18 18:53:16] d2.utils.events INFO:  eta: 15:03:46  iter: 1539  total_loss: 55.49  loss_ce: 0.4411  loss_mask: 0.5462  loss_dice: 4.449  loss_ce_0: 1.436  loss_mask_0: 0.5357  loss_dice_0: 4.507  loss_ce_1: 0.4593  loss_mask_1: 0.5427  loss_dice_1: 4.468  loss_ce_2: 0.4529  loss_mask_2: 0.5451  loss_dice_2: 4.455  loss_ce_3: 0.4438  loss_mask_3: 0.5498  loss_dice_3: 4.45  loss_ce_4: 0.4431  loss_mask_4: 0.5497  loss_dice_4: 4.44  loss_ce_5: 0.4408  loss_mask_5: 0.5518  loss_dice_5: 4.438  loss_ce_6: 0.4442  loss_mask_6: 0.5493  loss_dice_6: 4.452  loss_ce_7: 0.446  loss_mask_7: 0.5473  loss_dice_7: 4.444  loss_ce_8: 0.4447  loss_mask_8: 0.5507  loss_dice_8: 4.443  time: 1.4225  data_time: 0.0632  lr: 9.653e-06  max_mem: 21164M
[01/18 18:53:45] d2.utils.events INFO:  eta: 15:03:18  iter: 1559  total_loss: 55.29  loss_ce: 0.413  loss_mask: 0.5513  loss_dice: 4.469  loss_ce_0: 1.393  loss_mask_0: 0.5347  loss_dice_0: 4.512  loss_ce_1: 0.4388  loss_mask_1: 0.5428  loss_dice_1: 4.48  loss_ce_2: 0.4167  loss_mask_2: 0.5469  loss_dice_2: 4.475  loss_ce_3: 0.4093  loss_mask_3: 0.5482  loss_dice_3: 4.467  loss_ce_4: 0.4026  loss_mask_4: 0.5522  loss_dice_4: 4.465  loss_ce_5: 0.4062  loss_mask_5: 0.5535  loss_dice_5: 4.463  loss_ce_6: 0.4145  loss_mask_6: 0.5533  loss_dice_6: 4.463  loss_ce_7: 0.4209  loss_mask_7: 0.5508  loss_dice_7: 4.459  loss_ce_8: 0.4178  loss_mask_8: 0.5512  loss_dice_8: 4.467  time: 1.4222  data_time: 0.0618  lr: 9.6485e-06  max_mem: 21164M
[01/18 18:54:13] d2.utils.events INFO:  eta: 15:02:50  iter: 1579  total_loss: 55.39  loss_ce: 0.4306  loss_mask: 0.5298  loss_dice: 4.468  loss_ce_0: 1.4  loss_mask_0: 0.518  loss_dice_0: 4.521  loss_ce_1: 0.4658  loss_mask_1: 0.5242  loss_dice_1: 4.485  loss_ce_2: 0.4399  loss_mask_2: 0.5267  loss_dice_2: 4.475  loss_ce_3: 0.4347  loss_mask_3: 0.527  loss_dice_3: 4.471  loss_ce_4: 0.4421  loss_mask_4: 0.5281  loss_dice_4: 4.471  loss_ce_5: 0.4478  loss_mask_5: 0.5254  loss_dice_5: 4.47  loss_ce_6: 0.4305  loss_mask_6: 0.5279  loss_dice_6: 4.46  loss_ce_7: 0.4337  loss_mask_7: 0.5283  loss_dice_7: 4.474  loss_ce_8: 0.4363  loss_mask_8: 0.5306  loss_dice_8: 4.469  time: 1.4221  data_time: 0.0613  lr: 9.644e-06  max_mem: 21164M
[01/18 18:54:41] d2.utils.events INFO:  eta: 15:02:05  iter: 1599  total_loss: 55.28  loss_ce: 0.4505  loss_mask: 0.548  loss_dice: 4.438  loss_ce_0: 1.395  loss_mask_0: 0.5399  loss_dice_0: 4.49  loss_ce_1: 0.4696  loss_mask_1: 0.5464  loss_dice_1: 4.453  loss_ce_2: 0.4401  loss_mask_2: 0.549  loss_dice_2: 4.444  loss_ce_3: 0.4441  loss_mask_3: 0.5487  loss_dice_3: 4.436  loss_ce_4: 0.4436  loss_mask_4: 0.5502  loss_dice_4: 4.431  loss_ce_5: 0.4543  loss_mask_5: 0.5488  loss_dice_5: 4.436  loss_ce_6: 0.4448  loss_mask_6: 0.5489  loss_dice_6: 4.432  loss_ce_7: 0.4423  loss_mask_7: 0.5481  loss_dice_7: 4.433  loss_ce_8: 0.4529  loss_mask_8: 0.5492  loss_dice_8: 4.428  time: 1.4216  data_time: 0.0685  lr: 9.6395e-06  max_mem: 21164M
[01/18 18:55:08] d2.utils.events INFO:  eta: 15:01:07  iter: 1619  total_loss: 54.99  loss_ce: 0.4106  loss_mask: 0.5447  loss_dice: 4.433  loss_ce_0: 1.352  loss_mask_0: 0.5318  loss_dice_0: 4.496  loss_ce_1: 0.4323  loss_mask_1: 0.539  loss_dice_1: 4.461  loss_ce_2: 0.4089  loss_mask_2: 0.5424  loss_dice_2: 4.445  loss_ce_3: 0.4009  loss_mask_3: 0.5468  loss_dice_3: 4.44  loss_ce_4: 0.4011  loss_mask_4: 0.5492  loss_dice_4: 4.439  loss_ce_5: 0.3991  loss_mask_5: 0.5494  loss_dice_5: 4.439  loss_ce_6: 0.4129  loss_mask_6: 0.5499  loss_dice_6: 4.44  loss_ce_7: 0.4097  loss_mask_7: 0.5468  loss_dice_7: 4.43  loss_ce_8: 0.402  loss_mask_8: 0.5462  loss_dice_8: 4.431  time: 1.4211  data_time: 0.0649  lr: 9.635e-06  max_mem: 21164M
[01/18 18:55:36] d2.utils.events INFO:  eta: 15:00:09  iter: 1639  total_loss: 55.32  loss_ce: 0.4385  loss_mask: 0.5571  loss_dice: 4.423  loss_ce_0: 1.361  loss_mask_0: 0.5424  loss_dice_0: 4.489  loss_ce_1: 0.4686  loss_mask_1: 0.5461  loss_dice_1: 4.447  loss_ce_2: 0.4456  loss_mask_2: 0.5501  loss_dice_2: 4.444  loss_ce_3: 0.4343  loss_mask_3: 0.5494  loss_dice_3: 4.428  loss_ce_4: 0.4454  loss_mask_4: 0.5494  loss_dice_4: 4.433  loss_ce_5: 0.4357  loss_mask_5: 0.5531  loss_dice_5: 4.43  loss_ce_6: 0.4444  loss_mask_6: 0.5527  loss_dice_6: 4.429  loss_ce_7: 0.4369  loss_mask_7: 0.5574  loss_dice_7: 4.43  loss_ce_8: 0.4392  loss_mask_8: 0.5606  loss_dice_8: 4.43  time: 1.4207  data_time: 0.0677  lr: 9.6305e-06  max_mem: 21164M
[01/18 18:56:04] d2.utils.events INFO:  eta: 14:59:09  iter: 1659  total_loss: 55.14  loss_ce: 0.4436  loss_mask: 0.541  loss_dice: 4.426  loss_ce_0: 1.372  loss_mask_0: 0.5212  loss_dice_0: 4.481  loss_ce_1: 0.4732  loss_mask_1: 0.5352  loss_dice_1: 4.445  loss_ce_2: 0.4428  loss_mask_2: 0.5373  loss_dice_2: 4.433  loss_ce_3: 0.4352  loss_mask_3: 0.5404  loss_dice_3: 4.43  loss_ce_4: 0.4337  loss_mask_4: 0.5394  loss_dice_4: 4.425  loss_ce_5: 0.4354  loss_mask_5: 0.5408  loss_dice_5: 4.427  loss_ce_6: 0.4405  loss_mask_6: 0.5377  loss_dice_6: 4.419  loss_ce_7: 0.4365  loss_mask_7: 0.5405  loss_dice_7: 4.43  loss_ce_8: 0.4502  loss_mask_8: 0.5393  loss_dice_8: 4.425  time: 1.4203  data_time: 0.0563  lr: 9.6259e-06  max_mem: 21164M
[01/18 18:56:32] d2.utils.events INFO:  eta: 14:58:10  iter: 1679  total_loss: 55.15  loss_ce: 0.4706  loss_mask: 0.5511  loss_dice: 4.41  loss_ce_0: 1.359  loss_mask_0: 0.536  loss_dice_0: 4.479  loss_ce_1: 0.4795  loss_mask_1: 0.5454  loss_dice_1: 4.436  loss_ce_2: 0.4582  loss_mask_2: 0.5479  loss_dice_2: 4.42  loss_ce_3: 0.4506  loss_mask_3: 0.5478  loss_dice_3: 4.409  loss_ce_4: 0.466  loss_mask_4: 0.5472  loss_dice_4: 4.403  loss_ce_5: 0.4632  loss_mask_5: 0.5499  loss_dice_5: 4.409  loss_ce_6: 0.4563  loss_mask_6: 0.5512  loss_dice_6: 4.402  loss_ce_7: 0.4682  loss_mask_7: 0.5495  loss_dice_7: 4.404  loss_ce_8: 0.4675  loss_mask_8: 0.5535  loss_dice_8: 4.405  time: 1.4200  data_time: 0.0634  lr: 9.6214e-06  max_mem: 21164M
[01/18 18:57:00] d2.utils.events INFO:  eta: 14:57:35  iter: 1699  total_loss: 55.06  loss_ce: 0.4635  loss_mask: 0.5426  loss_dice: 4.414  loss_ce_0: 1.305  loss_mask_0: 0.5324  loss_dice_0: 4.476  loss_ce_1: 0.4619  loss_mask_1: 0.5385  loss_dice_1: 4.431  loss_ce_2: 0.4446  loss_mask_2: 0.5417  loss_dice_2: 4.424  loss_ce_3: 0.4497  loss_mask_3: 0.5428  loss_dice_3: 4.415  loss_ce_4: 0.4513  loss_mask_4: 0.5426  loss_dice_4: 4.411  loss_ce_5: 0.4499  loss_mask_5: 0.5425  loss_dice_5: 4.405  loss_ce_6: 0.4421  loss_mask_6: 0.5452  loss_dice_6: 4.411  loss_ce_7: 0.4519  loss_mask_7: 0.5515  loss_dice_7: 4.414  loss_ce_8: 0.4431  loss_mask_8: 0.5444  loss_dice_8: 4.411  time: 1.4198  data_time: 0.0599  lr: 9.6169e-06  max_mem: 21164M
[01/18 18:57:28] d2.utils.events INFO:  eta: 14:56:22  iter: 1719  total_loss: 55  loss_ce: 0.4351  loss_mask: 0.5612  loss_dice: 4.41  loss_ce_0: 1.306  loss_mask_0: 0.5434  loss_dice_0: 4.471  loss_ce_1: 0.4524  loss_mask_1: 0.5546  loss_dice_1: 4.429  loss_ce_2: 0.4204  loss_mask_2: 0.5599  loss_dice_2: 4.421  loss_ce_3: 0.4138  loss_mask_3: 0.5591  loss_dice_3: 4.419  loss_ce_4: 0.4267  loss_mask_4: 0.5626  loss_dice_4: 4.411  loss_ce_5: 0.4297  loss_mask_5: 0.5598  loss_dice_5: 4.406  loss_ce_6: 0.4273  loss_mask_6: 0.5629  loss_dice_6: 4.414  loss_ce_7: 0.424  loss_mask_7: 0.5573  loss_dice_7: 4.41  loss_ce_8: 0.4381  loss_mask_8: 0.5575  loss_dice_8: 4.399  time: 1.4193  data_time: 0.0616  lr: 9.6124e-06  max_mem: 21164M
[01/18 18:57:55] d2.utils.events INFO:  eta: 14:55:11  iter: 1739  total_loss: 54.9  loss_ce: 0.4484  loss_mask: 0.5519  loss_dice: 4.411  loss_ce_0: 1.28  loss_mask_0: 0.5408  loss_dice_0: 4.487  loss_ce_1: 0.4535  loss_mask_1: 0.5492  loss_dice_1: 4.434  loss_ce_2: 0.4534  loss_mask_2: 0.5518  loss_dice_2: 4.418  loss_ce_3: 0.4361  loss_mask_3: 0.5496  loss_dice_3: 4.414  loss_ce_4: 0.4309  loss_mask_4: 0.548  loss_dice_4: 4.407  loss_ce_5: 0.4352  loss_mask_5: 0.5485  loss_dice_5: 4.412  loss_ce_6: 0.435  loss_mask_6: 0.5505  loss_dice_6: 4.405  loss_ce_7: 0.4313  loss_mask_7: 0.5499  loss_dice_7: 4.411  loss_ce_8: 0.4351  loss_mask_8: 0.5505  loss_dice_8: 4.408  time: 1.4188  data_time: 0.0540  lr: 9.6079e-06  max_mem: 21164M
[01/18 18:58:23] d2.utils.events INFO:  eta: 14:54:04  iter: 1759  total_loss: 54.89  loss_ce: 0.4448  loss_mask: 0.5519  loss_dice: 4.438  loss_ce_0: 1.277  loss_mask_0: 0.5346  loss_dice_0: 4.495  loss_ce_1: 0.4324  loss_mask_1: 0.552  loss_dice_1: 4.46  loss_ce_2: 0.427  loss_mask_2: 0.5577  loss_dice_2: 4.446  loss_ce_3: 0.4197  loss_mask_3: 0.5597  loss_dice_3: 4.44  loss_ce_4: 0.4182  loss_mask_4: 0.555  loss_dice_4: 4.435  loss_ce_5: 0.4254  loss_mask_5: 0.5564  loss_dice_5: 4.432  loss_ce_6: 0.4335  loss_mask_6: 0.5533  loss_dice_6: 4.438  loss_ce_7: 0.4217  loss_mask_7: 0.5517  loss_dice_7: 4.44  loss_ce_8: 0.4423  loss_mask_8: 0.5516  loss_dice_8: 4.434  time: 1.4185  data_time: 0.0600  lr: 9.6033e-06  max_mem: 21164M
[01/18 18:58:51] d2.utils.events INFO:  eta: 14:53:21  iter: 1779  total_loss: 54.77  loss_ce: 0.4346  loss_mask: 0.5455  loss_dice: 4.411  loss_ce_0: 1.255  loss_mask_0: 0.5289  loss_dice_0: 4.462  loss_ce_1: 0.4494  loss_mask_1: 0.5429  loss_dice_1: 4.429  loss_ce_2: 0.4292  loss_mask_2: 0.5476  loss_dice_2: 4.414  loss_ce_3: 0.4248  loss_mask_3: 0.5479  loss_dice_3: 4.413  loss_ce_4: 0.4302  loss_mask_4: 0.5441  loss_dice_4: 4.415  loss_ce_5: 0.4291  loss_mask_5: 0.5454  loss_dice_5: 4.413  loss_ce_6: 0.4274  loss_mask_6: 0.5462  loss_dice_6: 4.415  loss_ce_7: 0.433  loss_mask_7: 0.5462  loss_dice_7: 4.407  loss_ce_8: 0.4404  loss_mask_8: 0.5445  loss_dice_8: 4.409  time: 1.4183  data_time: 0.0627  lr: 9.5988e-06  max_mem: 21164M
[01/18 18:59:19] d2.utils.events INFO:  eta: 14:52:35  iter: 1799  total_loss: 54.82  loss_ce: 0.4471  loss_mask: 0.5611  loss_dice: 4.412  loss_ce_0: 1.256  loss_mask_0: 0.5421  loss_dice_0: 4.467  loss_ce_1: 0.4485  loss_mask_1: 0.5497  loss_dice_1: 4.432  loss_ce_2: 0.4296  loss_mask_2: 0.5529  loss_dice_2: 4.42  loss_ce_3: 0.4326  loss_mask_3: 0.5539  loss_dice_3: 4.411  loss_ce_4: 0.4292  loss_mask_4: 0.5591  loss_dice_4: 4.411  loss_ce_5: 0.4241  loss_mask_5: 0.5601  loss_dice_5: 4.41  loss_ce_6: 0.4312  loss_mask_6: 0.5575  loss_dice_6: 4.405  loss_ce_7: 0.4516  loss_mask_7: 0.5574  loss_dice_7: 4.409  loss_ce_8: 0.4357  loss_mask_8: 0.5629  loss_dice_8: 4.407  time: 1.4179  data_time: 0.0597  lr: 9.5943e-06  max_mem: 21164M
[01/18 18:59:47] d2.utils.events INFO:  eta: 14:51:35  iter: 1819  total_loss: 54.72  loss_ce: 0.4522  loss_mask: 0.5382  loss_dice: 4.397  loss_ce_0: 1.24  loss_mask_0: 0.5198  loss_dice_0: 4.457  loss_ce_1: 0.4645  loss_mask_1: 0.5276  loss_dice_1: 4.418  loss_ce_2: 0.4519  loss_mask_2: 0.5329  loss_dice_2: 4.406  loss_ce_3: 0.4442  loss_mask_3: 0.537  loss_dice_3: 4.399  loss_ce_4: 0.4538  loss_mask_4: 0.5383  loss_dice_4: 4.4  loss_ce_5: 0.4685  loss_mask_5: 0.5382  loss_dice_5: 4.398  loss_ce_6: 0.4493  loss_mask_6: 0.5419  loss_dice_6: 4.401  loss_ce_7: 0.4598  loss_mask_7: 0.5394  loss_dice_7: 4.406  loss_ce_8: 0.4688  loss_mask_8: 0.5403  loss_dice_8: 4.399  time: 1.4178  data_time: 0.0583  lr: 9.5898e-06  max_mem: 21164M
[01/18 19:00:15] d2.utils.events INFO:  eta: 14:50:36  iter: 1839  total_loss: 54.71  loss_ce: 0.4189  loss_mask: 0.5534  loss_dice: 4.41  loss_ce_0: 1.222  loss_mask_0: 0.5494  loss_dice_0: 4.47  loss_ce_1: 0.4377  loss_mask_1: 0.553  loss_dice_1: 4.432  loss_ce_2: 0.4212  loss_mask_2: 0.556  loss_dice_2: 4.423  loss_ce_3: 0.4138  loss_mask_3: 0.554  loss_dice_3: 4.414  loss_ce_4: 0.4214  loss_mask_4: 0.5541  loss_dice_4: 4.413  loss_ce_5: 0.4017  loss_mask_5: 0.5543  loss_dice_5: 4.414  loss_ce_6: 0.4181  loss_mask_6: 0.5522  loss_dice_6: 4.41  loss_ce_7: 0.4139  loss_mask_7: 0.5557  loss_dice_7: 4.411  loss_ce_8: 0.4284  loss_mask_8: 0.5535  loss_dice_8: 4.413  time: 1.4173  data_time: 0.0576  lr: 9.5853e-06  max_mem: 21164M
[01/18 19:00:43] d2.utils.events INFO:  eta: 14:49:56  iter: 1859  total_loss: 54.66  loss_ce: 0.4413  loss_mask: 0.5518  loss_dice: 4.385  loss_ce_0: 1.228  loss_mask_0: 0.5347  loss_dice_0: 4.451  loss_ce_1: 0.4535  loss_mask_1: 0.5423  loss_dice_1: 4.412  loss_ce_2: 0.4378  loss_mask_2: 0.5452  loss_dice_2: 4.4  loss_ce_3: 0.4201  loss_mask_3: 0.5482  loss_dice_3: 4.388  loss_ce_4: 0.4473  loss_mask_4: 0.5468  loss_dice_4: 4.396  loss_ce_5: 0.44  loss_mask_5: 0.5504  loss_dice_5: 4.388  loss_ce_6: 0.4404  loss_mask_6: 0.5512  loss_dice_6: 4.387  loss_ce_7: 0.4447  loss_mask_7: 0.5509  loss_dice_7: 4.386  loss_ce_8: 0.4285  loss_mask_8: 0.5509  loss_dice_8: 4.388  time: 1.4172  data_time: 0.0604  lr: 9.5807e-06  max_mem: 21164M
[01/18 19:01:10] d2.utils.events INFO:  eta: 14:48:47  iter: 1879  total_loss: 54.51  loss_ce: 0.4409  loss_mask: 0.5607  loss_dice: 4.375  loss_ce_0: 1.211  loss_mask_0: 0.5375  loss_dice_0: 4.44  loss_ce_1: 0.4364  loss_mask_1: 0.5534  loss_dice_1: 4.398  loss_ce_2: 0.4257  loss_mask_2: 0.5581  loss_dice_2: 4.381  loss_ce_3: 0.4325  loss_mask_3: 0.5592  loss_dice_3: 4.375  loss_ce_4: 0.4327  loss_mask_4: 0.5611  loss_dice_4: 4.367  loss_ce_5: 0.4394  loss_mask_5: 0.563  loss_dice_5: 4.377  loss_ce_6: 0.4329  loss_mask_6: 0.5575  loss_dice_6: 4.37  loss_ce_7: 0.4384  loss_mask_7: 0.5568  loss_dice_7: 4.371  loss_ce_8: 0.4365  loss_mask_8: 0.5593  loss_dice_8: 4.364  time: 1.4167  data_time: 0.0559  lr: 9.5762e-06  max_mem: 21164M
[01/18 19:01:38] d2.utils.events INFO:  eta: 14:48:05  iter: 1899  total_loss: 54.8  loss_ce: 0.4461  loss_mask: 0.5529  loss_dice: 4.389  loss_ce_0: 1.182  loss_mask_0: 0.5389  loss_dice_0: 4.466  loss_ce_1: 0.451  loss_mask_1: 0.5409  loss_dice_1: 4.422  loss_ce_2: 0.441  loss_mask_2: 0.5435  loss_dice_2: 4.404  loss_ce_3: 0.4315  loss_mask_3: 0.5501  loss_dice_3: 4.401  loss_ce_4: 0.422  loss_mask_4: 0.5505  loss_dice_4: 4.394  loss_ce_5: 0.4396  loss_mask_5: 0.5516  loss_dice_5: 4.393  loss_ce_6: 0.4541  loss_mask_6: 0.555  loss_dice_6: 4.392  loss_ce_7: 0.4482  loss_mask_7: 0.5571  loss_dice_7: 4.381  loss_ce_8: 0.4439  loss_mask_8: 0.5556  loss_dice_8: 4.386  time: 1.4165  data_time: 0.0594  lr: 9.5717e-06  max_mem: 21164M
[01/18 19:02:06] d2.utils.events INFO:  eta: 14:47:16  iter: 1919  total_loss: 54.78  loss_ce: 0.4307  loss_mask: 0.5385  loss_dice: 4.411  loss_ce_0: 1.178  loss_mask_0: 0.5249  loss_dice_0: 4.468  loss_ce_1: 0.4434  loss_mask_1: 0.5357  loss_dice_1: 4.427  loss_ce_2: 0.428  loss_mask_2: 0.5418  loss_dice_2: 4.419  loss_ce_3: 0.4228  loss_mask_3: 0.54  loss_dice_3: 4.415  loss_ce_4: 0.443  loss_mask_4: 0.5422  loss_dice_4: 4.403  loss_ce_5: 0.411  loss_mask_5: 0.5433  loss_dice_5: 4.418  loss_ce_6: 0.4282  loss_mask_6: 0.5438  loss_dice_6: 4.411  loss_ce_7: 0.4225  loss_mask_7: 0.541  loss_dice_7: 4.408  loss_ce_8: 0.4278  loss_mask_8: 0.54  loss_dice_8: 4.401  time: 1.4162  data_time: 0.0650  lr: 9.5672e-06  max_mem: 21164M
[01/18 19:02:34] d2.utils.events INFO:  eta: 14:46:14  iter: 1939  total_loss: 54.57  loss_ce: 0.431  loss_mask: 0.5686  loss_dice: 4.376  loss_ce_0: 1.138  loss_mask_0: 0.5523  loss_dice_0: 4.443  loss_ce_1: 0.4361  loss_mask_1: 0.5611  loss_dice_1: 4.396  loss_ce_2: 0.4168  loss_mask_2: 0.5644  loss_dice_2: 4.392  loss_ce_3: 0.4343  loss_mask_3: 0.5675  loss_dice_3: 4.377  loss_ce_4: 0.4256  loss_mask_4: 0.5641  loss_dice_4: 4.382  loss_ce_5: 0.4207  loss_mask_5: 0.5687  loss_dice_5: 4.381  loss_ce_6: 0.4294  loss_mask_6: 0.5653  loss_dice_6: 4.37  loss_ce_7: 0.4363  loss_mask_7: 0.5656  loss_dice_7: 4.372  loss_ce_8: 0.425  loss_mask_8: 0.5689  loss_dice_8: 4.369  time: 1.4159  data_time: 0.0648  lr: 9.5626e-06  max_mem: 21164M
[01/18 19:03:02] d2.utils.events INFO:  eta: 14:45:42  iter: 1959  total_loss: 54.49  loss_ce: 0.4411  loss_mask: 0.5578  loss_dice: 4.37  loss_ce_0: 1.147  loss_mask_0: 0.5347  loss_dice_0: 4.448  loss_ce_1: 0.4626  loss_mask_1: 0.5518  loss_dice_1: 4.393  loss_ce_2: 0.4469  loss_mask_2: 0.5565  loss_dice_2: 4.381  loss_ce_3: 0.4308  loss_mask_3: 0.5529  loss_dice_3: 4.376  loss_ce_4: 0.4436  loss_mask_4: 0.5559  loss_dice_4: 4.377  loss_ce_5: 0.4383  loss_mask_5: 0.5544  loss_dice_5: 4.381  loss_ce_6: 0.4461  loss_mask_6: 0.5589  loss_dice_6: 4.38  loss_ce_7: 0.4485  loss_mask_7: 0.5584  loss_dice_7: 4.369  loss_ce_8: 0.4305  loss_mask_8: 0.5583  loss_dice_8: 4.376  time: 1.4156  data_time: 0.0582  lr: 9.5581e-06  max_mem: 21164M
[01/18 19:03:30] d2.utils.events INFO:  eta: 14:45:03  iter: 1979  total_loss: 54.36  loss_ce: 0.4401  loss_mask: 0.5556  loss_dice: 4.362  loss_ce_0: 1.167  loss_mask_0: 0.539  loss_dice_0: 4.42  loss_ce_1: 0.4483  loss_mask_1: 0.5514  loss_dice_1: 4.381  loss_ce_2: 0.4367  loss_mask_2: 0.5521  loss_dice_2: 4.363  loss_ce_3: 0.4506  loss_mask_3: 0.5527  loss_dice_3: 4.368  loss_ce_4: 0.423  loss_mask_4: 0.5578  loss_dice_4: 4.354  loss_ce_5: 0.4366  loss_mask_5: 0.5569  loss_dice_5: 4.353  loss_ce_6: 0.4666  loss_mask_6: 0.5584  loss_dice_6: 4.343  loss_ce_7: 0.4543  loss_mask_7: 0.5568  loss_dice_7: 4.35  loss_ce_8: 0.442  loss_mask_8: 0.5585  loss_dice_8: 4.351  time: 1.4155  data_time: 0.0602  lr: 9.5536e-06  max_mem: 21164M
[01/18 19:03:57] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 19:03:58] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 19:03:58] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 19:09:47] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 6.2365482947694355, 'error_1pix': 0.650094262862326, 'error_3pix': 0.4129088560289183, 'mIoU': 3.443860534390054, 'fwIoU': 13.665656707402462, 'IoU-0': nan, 'IoU-1': 91.28783079534425, 'IoU-2': 27.61200266319029, 'IoU-3': 17.59045512456921, 'IoU-4': 20.526467915537346, 'IoU-5': 14.312352409714855, 'IoU-6': 5.120170152428217, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 2.738406518935066, 'IoU-10': 8.983298229445182, 'IoU-11': 16.749190549437834, 'IoU-12': 13.774525166147242, 'IoU-13': 10.613671238442555, 'IoU-14': 6.193863097737391, 'IoU-15': 3.1794400673138483, 'IoU-16': 5.697983163561295, 'IoU-17': 5.514736052302636, 'IoU-18': 2.685739856567203, 'IoU-19': 1.3440580301230025, 'IoU-20': 0.9867186031558904, 'IoU-21': 3.485676168967808, 'IoU-22': 4.272875766185901, 'IoU-23': 2.6021650864224672, 'IoU-24': 3.0277961579762986, 'IoU-25': 5.804027433517724, 'IoU-26': 4.087174221189902, 'IoU-27': 3.8625301982189932, 'IoU-28': 4.5532671754255585, 'IoU-29': 1.5068550545618766, 'IoU-30': 5.74546009422667, 'IoU-31': 6.46311056433932, 'IoU-32': 2.9090913030258854, 'IoU-33': 4.746565036657739, 'IoU-34': 3.6274760403712705, 'IoU-35': 4.332871436251957, 'IoU-36': 6.383787987394017, 'IoU-37': 3.4951256452518447, 'IoU-38': 4.289008050406484, 'IoU-39': 5.055674267201308, 'IoU-40': 6.104335327984773, 'IoU-41': 5.9653234433615765, 'IoU-42': 5.690604947396124, 'IoU-43': 2.950604025113475, 'IoU-44': 3.599523168764575, 'IoU-45': 6.410301169115519, 'IoU-46': 2.0793276216113132, 'IoU-47': 4.177141851153814, 'IoU-48': 5.834406558299123, 'IoU-49': 5.38605692817468, 'IoU-50': 2.588328785926001, 'IoU-51': 5.4642166750265835, 'IoU-52': 7.199989369042539, 'IoU-53': 1.4959252949703754, 'IoU-54': 5.372030214962537, 'IoU-55': 5.119144887750732, 'IoU-56': 3.8499457982481924, 'IoU-57': 3.1866667609132198, 'IoU-58': 7.05401475943515, 'IoU-59': 5.062029200607917, 'IoU-60': 5.734331218307607, 'IoU-61': 3.9305592158398635, 'IoU-62': 2.9345998827159283, 'IoU-63': 4.95754490576069, 'IoU-64': 5.793390768675832, 'IoU-65': 3.812963949862992, 'IoU-66': 3.6919123005985757, 'IoU-67': 4.319005422742442, 'IoU-68': 3.0143460143546017, 'IoU-69': 5.263983702565855, 'IoU-70': 4.891482324115047, 'IoU-71': 3.8835156193666265, 'IoU-72': 1.7141194632919674, 'IoU-73': 3.910174165323351, 'IoU-74': 5.225688170756952, 'IoU-75': 2.246678519435647, 'IoU-76': 2.172484297365774, 'IoU-77': 4.9964189721161425, 'IoU-78': 3.1760137015999295, 'IoU-79': 5.303324608604979, 'IoU-80': 5.217378588639848, 'IoU-81': 2.8393933700786897, 'IoU-82': 3.256534348061307, 'IoU-83': 5.2153784303114765, 'IoU-84': 3.1738329234061604, 'IoU-85': 2.773112177564108, 'IoU-86': 3.598225101544455, 'IoU-87': 5.19798986590332, 'IoU-88': 4.151730436211756, 'IoU-89': 5.978709781913954, 'IoU-90': 1.4261846898753503, 'IoU-91': 2.487101904174337, 'IoU-92': 4.221796589589491, 'IoU-93': 4.853399074709187, 'IoU-94': 2.049911065888976, 'IoU-95': 4.621592916665853, 'IoU-96': 2.620693846547313, 'IoU-97': 3.474896881676628, 'IoU-98': 2.0447956645853247, 'IoU-99': 2.1466936012279256, 'IoU-100': 2.5651379234330665, 'IoU-101': 3.4299368031637676, 'IoU-102': 0.9247707802868965, 'IoU-103': 1.058226782971984, 'IoU-104': 2.211406565163486, 'IoU-105': 1.2542671392826898, 'IoU-106': 3.4286829990414462, 'IoU-107': 2.237829991259163, 'IoU-108': 1.3968932524421664, 'IoU-109': 1.5908322788043605, 'IoU-110': 3.504391765320928, 'IoU-111': 1.1527416973003297, 'IoU-112': 2.483040599315888, 'IoU-113': 2.3421184168903104, 'IoU-114': 2.3254649141009036, 'IoU-115': 2.9945888077284457, 'IoU-116': 1.5142500614199446, 'IoU-117': 1.1747702582080373, 'IoU-118': 0.573071536644677, 'IoU-119': 1.3217351483677726, 'IoU-120': 1.4760520718993975, 'IoU-121': 1.290680062253349, 'IoU-122': 2.1104722741704105, 'IoU-123': 1.7959022603715284, 'IoU-124': 1.2323172398249242, 'IoU-125': 0.41227783869611373, 'IoU-126': 2.435233077085542, 'IoU-127': 1.259794994716626, 'IoU-128': 0.6473938022023996, 'IoU-129': 1.1858109602370737, 'IoU-130': 1.206115361658256, 'IoU-131': 0.26920614343161986, 'IoU-132': 1.8527907708000775, 'IoU-133': 0.7168723907542567, 'IoU-134': 2.5526104373116927, 'IoU-135': 1.3451131875549447, 'IoU-136': 2.2156615998159745, 'IoU-137': 0.7244368078991108, 'IoU-138': 1.958723781817222, 'IoU-139': 1.3128085735574369, 'IoU-140': 0.6910008746244819, 'IoU-141': 2.452141470430478, 'IoU-142': 0.023269770119165718, 'IoU-143': 0.22515183901154762, 'IoU-144': 0.20467831307147827, 'IoU-145': 0.0002680749537570705, 'IoU-146': 0.08239958226488264, 'IoU-147': 0.9138849497296228, 'IoU-148': 0.31334581782024806, 'IoU-149': 0.0, 'IoU-150': 1.4292084534302685, 'IoU-151': 1.4370796093550031, 'IoU-152': 2.482312601971855, 'IoU-153': 1.1512924852157789, 'IoU-154': 0.2575048123067786, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 6.476439897158954, 'pACC': 18.904311414462, 'ACC-0': nan, 'ACC-1': 98.6164503552572, 'ACC-2': 35.24987205201936, 'ACC-3': 23.577415187948727, 'ACC-4': 38.377470877802764, 'ACC-5': 32.10040985223541, 'ACC-6': 8.095895915576275, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 3.1760622239848475, 'ACC-10': 14.233826373294796, 'ACC-11': 36.580284591200964, 'ACC-12': 31.60858907789606, 'ACC-13': 28.192400609463252, 'ACC-14': 13.166374317647112, 'ACC-15': 4.617465663357228, 'ACC-16': 13.842636152161417, 'ACC-17': 23.817093780691618, 'ACC-18': 4.727804390880962, 'ACC-19': 1.6606138053132022, 'ACC-20': 1.1525239584031277, 'ACC-21': 7.287437044667443, 'ACC-22': 7.155579380587594, 'ACC-23': 3.987319225106157, 'ACC-24': 4.900584097677488, 'ACC-25': 14.261238290396763, 'ACC-26': 7.7258176958170806, 'ACC-27': 6.181266946867087, 'ACC-28': 9.801504541287418, 'ACC-29': 1.8427894921655672, 'ACC-30': 12.4042531186213, 'ACC-31': 14.263625119766738, 'ACC-32': 4.506656418208135, 'ACC-33': 8.739552995716979, 'ACC-34': 6.107930591686041, 'ACC-35': 7.828675765837717, 'ACC-36': 13.047948824130465, 'ACC-37': 5.0108928931048125, 'ACC-38': 6.616412127642027, 'ACC-39': 7.901859347902104, 'ACC-40': 11.1592653304215, 'ACC-41': 14.617999157477687, 'ACC-42': 10.686068256318435, 'ACC-43': 3.9124688304450843, 'ACC-44': 5.37988011974832, 'ACC-45': 12.423051976051402, 'ACC-46': 2.931405490935204, 'ACC-47': 6.5994346691308925, 'ACC-48': 11.793692219184996, 'ACC-49': 10.68004870615369, 'ACC-50': 3.500024159273756, 'ACC-51': 11.45306050049654, 'ACC-52': 16.706299765661093, 'ACC-53': 2.0182608073402384, 'ACC-54': 10.315853709907847, 'ACC-55': 8.520131475594964, 'ACC-56': 5.811658906599082, 'ACC-57': 4.76108593872595, 'ACC-58': 19.39999174347589, 'ACC-59': 8.99939409651362, 'ACC-60': 12.759455357275359, 'ACC-61': 6.00796074351468, 'ACC-62': 4.683634613672545, 'ACC-63': 13.643066948811141, 'ACC-64': 14.393146742773396, 'ACC-65': 6.741148244189709, 'ACC-66': 5.651144650251775, 'ACC-67': 6.741892227317482, 'ACC-68': 4.430167758668804, 'ACC-69': 11.950580862974933, 'ACC-70': 9.383576789362632, 'ACC-71': 6.294589524159728, 'ACC-72': 2.600857768785519, 'ACC-73': 8.05896969329996, 'ACC-74': 16.04836537245513, 'ACC-75': 3.509722748512404, 'ACC-76': 3.248404297456662, 'ACC-77': 10.645587586421005, 'ACC-78': 6.831311159634702, 'ACC-79': 14.297371179509147, 'ACC-80': 14.124509260020007, 'ACC-81': 4.412493061072534, 'ACC-82': 8.101280178686311, 'ACC-83': 13.334896665905777, 'ACC-84': 4.662985072155388, 'ACC-85': 4.06287770110537, 'ACC-86': 6.0661798057260015, 'ACC-87': 14.544629040735488, 'ACC-88': 8.82314792308023, 'ACC-89': 19.71321627542226, 'ACC-90': 1.9969527763708856, 'ACC-91': 3.442261745519882, 'ACC-92': 8.556439985842669, 'ACC-93': 12.960187604109718, 'ACC-94': 3.8974026337364465, 'ACC-95': 14.521970982374736, 'ACC-96': 4.552788745266549, 'ACC-97': 6.9678636371652045, 'ACC-98': 3.521158925685826, 'ACC-99': 3.651785280394197, 'ACC-100': 5.173470802751011, 'ACC-101': 8.75065125324337, 'ACC-102': 1.2583371091980065, 'ACC-103': 1.2900491168414094, 'ACC-104': 3.991392243181427, 'ACC-105': 1.7471359714124526, 'ACC-106': 9.251070594044322, 'ACC-107': 3.94863234251052, 'ACC-108': 1.7999810414857063, 'ACC-109': 2.237786027445027, 'ACC-110': 6.866407581186023, 'ACC-111': 1.4514173358392244, 'ACC-112': 4.18874650576328, 'ACC-113': 4.824314553673139, 'ACC-114': 5.566697048138172, 'ACC-115': 9.916520078781591, 'ACC-116': 2.8148488188010834, 'ACC-117': 2.041344437595584, 'ACC-118': 0.7097460340253189, 'ACC-119': 1.822231429310365, 'ACC-120': 2.885422925956771, 'ACC-121': 1.6875247260321573, 'ACC-122': 3.935907233906045, 'ACC-123': 3.75901229402233, 'ACC-124': 2.534120433583489, 'ACC-125': 0.4623309835179358, 'ACC-126': 6.018497436224374, 'ACC-127': 1.7018428356493378, 'ACC-128': 0.8455392241163765, 'ACC-129': 1.5141579320251086, 'ACC-130': 1.7202038989482593, 'ACC-131': 0.29367726603013333, 'ACC-132': 2.476098561389752, 'ACC-133': 0.9166003252430819, 'ACC-134': 5.71015941404567, 'ACC-135': 2.4325865116013907, 'ACC-136': 6.555962891352964, 'ACC-137': 0.9853329639288758, 'ACC-138': 4.710384039393863, 'ACC-139': 1.8547197670348015, 'ACC-140': 1.2040179762029, 'ACC-141': 8.260188272441297, 'ACC-142': 0.024889503703296154, 'ACC-143': 0.2483706293643455, 'ACC-144': 0.21823104693140796, 'ACC-145': 0.0002683423153469443, 'ACC-146': 0.09056224440839825, 'ACC-147': 1.5186869244918444, 'ACC-148': 0.36214974369113284, 'ACC-149': 0.0, 'ACC-150': 6.5544517510258915, 'ACC-151': 7.545484677863715, 'ACC-152': 8.522152538943962, 'ACC-153': 2.121466131662361, 'ACC-154': 0.2850879510418979, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/18 19:09:47] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/18 19:09:47] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/18 19:09:47] d2.evaluation.testing INFO: copypaste: 6.2365,0.6501,0.4129,3.4439,13.6657,6.4764,18.9043
[01/18 19:09:47] d2.utils.events INFO:  eta: 14:44:12  iter: 1999  total_loss: 54.23  loss_ce: 0.4414  loss_mask: 0.5628  loss_dice: 4.348  loss_ce_0: 1.129  loss_mask_0: 0.5418  loss_dice_0: 4.427  loss_ce_1: 0.4397  loss_mask_1: 0.5555  loss_dice_1: 4.379  loss_ce_2: 0.4174  loss_mask_2: 0.5623  loss_dice_2: 4.365  loss_ce_3: 0.4159  loss_mask_3: 0.5618  loss_dice_3: 4.357  loss_ce_4: 0.4102  loss_mask_4: 0.5601  loss_dice_4: 4.352  loss_ce_5: 0.4264  loss_mask_5: 0.5619  loss_dice_5: 4.355  loss_ce_6: 0.4321  loss_mask_6: 0.5631  loss_dice_6: 4.35  loss_ce_7: 0.4354  loss_mask_7: 0.5629  loss_dice_7: 4.35  loss_ce_8: 0.4447  loss_mask_8: 0.5602  loss_dice_8: 4.354  time: 1.4151  data_time: 0.0582  lr: 9.5491e-06  max_mem: 21164M
[01/18 19:10:15] d2.utils.events INFO:  eta: 14:43:17  iter: 2019  total_loss: 54.38  loss_ce: 0.4331  loss_mask: 0.5648  loss_dice: 4.374  loss_ce_0: 1.129  loss_mask_0: 0.5521  loss_dice_0: 4.441  loss_ce_1: 0.4376  loss_mask_1: 0.5601  loss_dice_1: 4.4  loss_ce_2: 0.4026  loss_mask_2: 0.5636  loss_dice_2: 4.39  loss_ce_3: 0.4338  loss_mask_3: 0.562  loss_dice_3: 4.383  loss_ce_4: 0.4319  loss_mask_4: 0.5645  loss_dice_4: 4.376  loss_ce_5: 0.4286  loss_mask_5: 0.5679  loss_dice_5: 4.376  loss_ce_6: 0.4329  loss_mask_6: 0.5675  loss_dice_6: 4.368  loss_ce_7: 0.441  loss_mask_7: 0.5681  loss_dice_7: 4.379  loss_ce_8: 0.4402  loss_mask_8: 0.5675  loss_dice_8: 4.374  time: 1.4149  data_time: 0.0613  lr: 9.5446e-06  max_mem: 21164M
[01/18 19:10:43] d2.utils.events INFO:  eta: 14:42:33  iter: 2039  total_loss: 54.17  loss_ce: 0.4465  loss_mask: 0.5573  loss_dice: 4.335  loss_ce_0: 1.173  loss_mask_0: 0.5402  loss_dice_0: 4.412  loss_ce_1: 0.4711  loss_mask_1: 0.5566  loss_dice_1: 4.367  loss_ce_2: 0.4475  loss_mask_2: 0.5571  loss_dice_2: 4.346  loss_ce_3: 0.4443  loss_mask_3: 0.5583  loss_dice_3: 4.33  loss_ce_4: 0.4414  loss_mask_4: 0.5572  loss_dice_4: 4.339  loss_ce_5: 0.4305  loss_mask_5: 0.5574  loss_dice_5: 4.336  loss_ce_6: 0.4397  loss_mask_6: 0.5567  loss_dice_6: 4.338  loss_ce_7: 0.4454  loss_mask_7: 0.5584  loss_dice_7: 4.332  loss_ce_8: 0.4429  loss_mask_8: 0.5548  loss_dice_8: 4.333  time: 1.4148  data_time: 0.0587  lr: 9.54e-06  max_mem: 21164M
[01/18 19:11:11] d2.utils.events INFO:  eta: 14:41:23  iter: 2059  total_loss: 54.22  loss_ce: 0.4255  loss_mask: 0.5548  loss_dice: 4.354  loss_ce_0: 1.089  loss_mask_0: 0.5334  loss_dice_0: 4.421  loss_ce_1: 0.4497  loss_mask_1: 0.5478  loss_dice_1: 4.374  loss_ce_2: 0.4401  loss_mask_2: 0.5497  loss_dice_2: 4.364  loss_ce_3: 0.4307  loss_mask_3: 0.5517  loss_dice_3: 4.348  loss_ce_4: 0.4319  loss_mask_4: 0.5533  loss_dice_4: 4.358  loss_ce_5: 0.4383  loss_mask_5: 0.5566  loss_dice_5: 4.351  loss_ce_6: 0.4244  loss_mask_6: 0.552  loss_dice_6: 4.348  loss_ce_7: 0.4285  loss_mask_7: 0.5501  loss_dice_7: 4.344  loss_ce_8: 0.4251  loss_mask_8: 0.5534  loss_dice_8: 4.348  time: 1.4144  data_time: 0.0582  lr: 9.5355e-06  max_mem: 21164M
[01/18 19:11:38] d2.utils.events INFO:  eta: 14:40:32  iter: 2079  total_loss: 54.06  loss_ce: 0.4466  loss_mask: 0.5483  loss_dice: 4.328  loss_ce_0: 1.131  loss_mask_0: 0.5361  loss_dice_0: 4.403  loss_ce_1: 0.4452  loss_mask_1: 0.5453  loss_dice_1: 4.35  loss_ce_2: 0.4463  loss_mask_2: 0.5477  loss_dice_2: 4.341  loss_ce_3: 0.4222  loss_mask_3: 0.5458  loss_dice_3: 4.328  loss_ce_4: 0.4151  loss_mask_4: 0.548  loss_dice_4: 4.329  loss_ce_5: 0.4261  loss_mask_5: 0.5483  loss_dice_5: 4.331  loss_ce_6: 0.4404  loss_mask_6: 0.5497  loss_dice_6: 4.33  loss_ce_7: 0.4312  loss_mask_7: 0.5509  loss_dice_7: 4.325  loss_ce_8: 0.4399  loss_mask_8: 0.548  loss_dice_8: 4.33  time: 1.4140  data_time: 0.0561  lr: 9.531e-06  max_mem: 21164M
[01/18 19:12:06] d2.utils.events INFO:  eta: 14:39:51  iter: 2099  total_loss: 54.03  loss_ce: 0.4415  loss_mask: 0.5556  loss_dice: 4.323  loss_ce_0: 1.083  loss_mask_0: 0.54  loss_dice_0: 4.398  loss_ce_1: 0.4662  loss_mask_1: 0.5544  loss_dice_1: 4.351  loss_ce_2: 0.4433  loss_mask_2: 0.5542  loss_dice_2: 4.334  loss_ce_3: 0.4459  loss_mask_3: 0.5531  loss_dice_3: 4.328  loss_ce_4: 0.4308  loss_mask_4: 0.5531  loss_dice_4: 4.328  loss_ce_5: 0.432  loss_mask_5: 0.5515  loss_dice_5: 4.328  loss_ce_6: 0.4549  loss_mask_6: 0.5519  loss_dice_6: 4.319  loss_ce_7: 0.452  loss_mask_7: 0.5511  loss_dice_7: 4.322  loss_ce_8: 0.4468  loss_mask_8: 0.554  loss_dice_8: 4.321  time: 1.4137  data_time: 0.0582  lr: 9.5265e-06  max_mem: 21164M
[01/18 19:12:34] d2.utils.events INFO:  eta: 14:38:48  iter: 2119  total_loss: 53.96  loss_ce: 0.4526  loss_mask: 0.5583  loss_dice: 4.319  loss_ce_0: 1.069  loss_mask_0: 0.5436  loss_dice_0: 4.392  loss_ce_1: 0.4631  loss_mask_1: 0.554  loss_dice_1: 4.346  loss_ce_2: 0.4325  loss_mask_2: 0.5576  loss_dice_2: 4.331  loss_ce_3: 0.4265  loss_mask_3: 0.5597  loss_dice_3: 4.327  loss_ce_4: 0.4422  loss_mask_4: 0.563  loss_dice_4: 4.321  loss_ce_5: 0.4372  loss_mask_5: 0.5617  loss_dice_5: 4.319  loss_ce_6: 0.4317  loss_mask_6: 0.5575  loss_dice_6: 4.324  loss_ce_7: 0.4413  loss_mask_7: 0.5559  loss_dice_7: 4.315  loss_ce_8: 0.4378  loss_mask_8: 0.5592  loss_dice_8: 4.316  time: 1.4133  data_time: 0.0545  lr: 9.5219e-06  max_mem: 21164M
[01/18 19:13:02] d2.utils.events INFO:  eta: 14:37:54  iter: 2139  total_loss: 54.18  loss_ce: 0.4845  loss_mask: 0.5407  loss_dice: 4.331  loss_ce_0: 1.119  loss_mask_0: 0.5223  loss_dice_0: 4.416  loss_ce_1: 0.4874  loss_mask_1: 0.5303  loss_dice_1: 4.363  loss_ce_2: 0.4641  loss_mask_2: 0.5323  loss_dice_2: 4.346  loss_ce_3: 0.4477  loss_mask_3: 0.5354  loss_dice_3: 4.338  loss_ce_4: 0.4579  loss_mask_4: 0.5392  loss_dice_4: 4.331  loss_ce_5: 0.4661  loss_mask_5: 0.5396  loss_dice_5: 4.337  loss_ce_6: 0.4679  loss_mask_6: 0.5411  loss_dice_6: 4.325  loss_ce_7: 0.4703  loss_mask_7: 0.5418  loss_dice_7: 4.328  loss_ce_8: 0.4779  loss_mask_8: 0.5438  loss_dice_8: 4.33  time: 1.4132  data_time: 0.0611  lr: 9.5174e-06  max_mem: 21164M
[01/18 19:13:30] d2.utils.events INFO:  eta: 14:37:44  iter: 2159  total_loss: 54.04  loss_ce: 0.4533  loss_mask: 0.5602  loss_dice: 4.327  loss_ce_0: 1.067  loss_mask_0: 0.5371  loss_dice_0: 4.402  loss_ce_1: 0.4717  loss_mask_1: 0.5519  loss_dice_1: 4.356  loss_ce_2: 0.4529  loss_mask_2: 0.5594  loss_dice_2: 4.329  loss_ce_3: 0.4506  loss_mask_3: 0.5585  loss_dice_3: 4.327  loss_ce_4: 0.4449  loss_mask_4: 0.5581  loss_dice_4: 4.323  loss_ce_5: 0.4489  loss_mask_5: 0.5613  loss_dice_5: 4.328  loss_ce_6: 0.4735  loss_mask_6: 0.5622  loss_dice_6: 4.324  loss_ce_7: 0.4463  loss_mask_7: 0.5588  loss_dice_7: 4.327  loss_ce_8: 0.4469  loss_mask_8: 0.5587  loss_dice_8: 4.322  time: 1.4130  data_time: 0.0586  lr: 9.5129e-06  max_mem: 21164M
[01/18 19:13:57] d2.utils.events INFO:  eta: 14:37:16  iter: 2179  total_loss: 54.18  loss_ce: 0.4271  loss_mask: 0.5534  loss_dice: 4.355  loss_ce_0: 1.064  loss_mask_0: 0.5419  loss_dice_0: 4.424  loss_ce_1: 0.458  loss_mask_1: 0.5461  loss_dice_1: 4.372  loss_ce_2: 0.4436  loss_mask_2: 0.5531  loss_dice_2: 4.36  loss_ce_3: 0.4487  loss_mask_3: 0.555  loss_dice_3: 4.349  loss_ce_4: 0.4432  loss_mask_4: 0.5538  loss_dice_4: 4.351  loss_ce_5: 0.4288  loss_mask_5: 0.5526  loss_dice_5: 4.361  loss_ce_6: 0.44  loss_mask_6: 0.5513  loss_dice_6: 4.348  loss_ce_7: 0.4276  loss_mask_7: 0.5526  loss_dice_7: 4.353  loss_ce_8: 0.4313  loss_mask_8: 0.5539  loss_dice_8: 4.35  time: 1.4127  data_time: 0.0657  lr: 9.5084e-06  max_mem: 21164M
[01/18 19:14:25] d2.utils.events INFO:  eta: 14:36:41  iter: 2199  total_loss: 53.66  loss_ce: 0.4189  loss_mask: 0.5478  loss_dice: 4.304  loss_ce_0: 1.036  loss_mask_0: 0.5251  loss_dice_0: 4.378  loss_ce_1: 0.4421  loss_mask_1: 0.5431  loss_dice_1: 4.333  loss_ce_2: 0.4252  loss_mask_2: 0.5511  loss_dice_2: 4.319  loss_ce_3: 0.4227  loss_mask_3: 0.5474  loss_dice_3: 4.31  loss_ce_4: 0.4179  loss_mask_4: 0.5496  loss_dice_4: 4.302  loss_ce_5: 0.4155  loss_mask_5: 0.5514  loss_dice_5: 4.309  loss_ce_6: 0.4279  loss_mask_6: 0.5479  loss_dice_6: 4.298  loss_ce_7: 0.4264  loss_mask_7: 0.5473  loss_dice_7: 4.304  loss_ce_8: 0.4172  loss_mask_8: 0.5491  loss_dice_8: 4.313  time: 1.4126  data_time: 0.0575  lr: 9.5038e-06  max_mem: 21164M
[01/18 19:14:53] d2.utils.events INFO:  eta: 14:36:03  iter: 2219  total_loss: 53.6  loss_ce: 0.4433  loss_mask: 0.54  loss_dice: 4.328  loss_ce_0: 1.003  loss_mask_0: 0.5204  loss_dice_0: 4.402  loss_ce_1: 0.4514  loss_mask_1: 0.5381  loss_dice_1: 4.347  loss_ce_2: 0.4263  loss_mask_2: 0.543  loss_dice_2: 4.334  loss_ce_3: 0.4195  loss_mask_3: 0.5422  loss_dice_3: 4.323  loss_ce_4: 0.4261  loss_mask_4: 0.543  loss_dice_4: 4.319  loss_ce_5: 0.418  loss_mask_5: 0.5398  loss_dice_5: 4.33  loss_ce_6: 0.4287  loss_mask_6: 0.5412  loss_dice_6: 4.329  loss_ce_7: 0.4212  loss_mask_7: 0.5441  loss_dice_7: 4.322  loss_ce_8: 0.4157  loss_mask_8: 0.5427  loss_dice_8: 4.327  time: 1.4125  data_time: 0.0647  lr: 9.4993e-06  max_mem: 21164M
[01/18 19:15:21] d2.utils.events INFO:  eta: 14:35:18  iter: 2239  total_loss: 53.57  loss_ce: 0.443  loss_mask: 0.5606  loss_dice: 4.291  loss_ce_0: 1.041  loss_mask_0: 0.5421  loss_dice_0: 4.385  loss_ce_1: 0.4523  loss_mask_1: 0.5526  loss_dice_1: 4.328  loss_ce_2: 0.4329  loss_mask_2: 0.5571  loss_dice_2: 4.309  loss_ce_3: 0.4331  loss_mask_3: 0.5594  loss_dice_3: 4.308  loss_ce_4: 0.4346  loss_mask_4: 0.5603  loss_dice_4: 4.299  loss_ce_5: 0.4305  loss_mask_5: 0.563  loss_dice_5: 4.299  loss_ce_6: 0.4342  loss_mask_6: 0.5616  loss_dice_6: 4.297  loss_ce_7: 0.4483  loss_mask_7: 0.5602  loss_dice_7: 4.297  loss_ce_8: 0.4413  loss_mask_8: 0.5636  loss_dice_8: 4.291  time: 1.4122  data_time: 0.0607  lr: 9.4948e-06  max_mem: 21164M
[01/18 19:15:49] d2.utils.events INFO:  eta: 14:35:03  iter: 2259  total_loss: 53.49  loss_ce: 0.426  loss_mask: 0.5593  loss_dice: 4.295  loss_ce_0: 1.026  loss_mask_0: 0.5364  loss_dice_0: 4.38  loss_ce_1: 0.4599  loss_mask_1: 0.5453  loss_dice_1: 4.329  loss_ce_2: 0.4204  loss_mask_2: 0.554  loss_dice_2: 4.304  loss_ce_3: 0.4324  loss_mask_3: 0.5566  loss_dice_3: 4.294  loss_ce_4: 0.43  loss_mask_4: 0.5538  loss_dice_4: 4.302  loss_ce_5: 0.4246  loss_mask_5: 0.5586  loss_dice_5: 4.292  loss_ce_6: 0.427  loss_mask_6: 0.5582  loss_dice_6: 4.296  loss_ce_7: 0.439  loss_mask_7: 0.5581  loss_dice_7: 4.288  loss_ce_8: 0.4323  loss_mask_8: 0.5593  loss_dice_8: 4.299  time: 1.4122  data_time: 0.0623  lr: 9.4903e-06  max_mem: 21164M
[01/18 19:16:17] d2.utils.events INFO:  eta: 14:34:39  iter: 2279  total_loss: 53.59  loss_ce: 0.4265  loss_mask: 0.558  loss_dice: 4.298  loss_ce_0: 1  loss_mask_0: 0.5401  loss_dice_0: 4.382  loss_ce_1: 0.43  loss_mask_1: 0.5525  loss_dice_1: 4.322  loss_ce_2: 0.4212  loss_mask_2: 0.5587  loss_dice_2: 4.295  loss_ce_3: 0.4199  loss_mask_3: 0.5544  loss_dice_3: 4.305  loss_ce_4: 0.4178  loss_mask_4: 0.5551  loss_dice_4: 4.305  loss_ce_5: 0.4246  loss_mask_5: 0.5528  loss_dice_5: 4.303  loss_ce_6: 0.4371  loss_mask_6: 0.5582  loss_dice_6: 4.295  loss_ce_7: 0.4223  loss_mask_7: 0.5573  loss_dice_7: 4.293  loss_ce_8: 0.421  loss_mask_8: 0.5603  loss_dice_8: 4.303  time: 1.4119  data_time: 0.0624  lr: 9.4857e-06  max_mem: 21164M
[01/18 19:16:45] d2.utils.events INFO:  eta: 14:34:10  iter: 2299  total_loss: 53.67  loss_ce: 0.4307  loss_mask: 0.5565  loss_dice: 4.3  loss_ce_0: 1.012  loss_mask_0: 0.5337  loss_dice_0: 4.383  loss_ce_1: 0.4425  loss_mask_1: 0.552  loss_dice_1: 4.342  loss_ce_2: 0.4295  loss_mask_2: 0.5545  loss_dice_2: 4.319  loss_ce_3: 0.4277  loss_mask_3: 0.5569  loss_dice_3: 4.314  loss_ce_4: 0.4091  loss_mask_4: 0.5581  loss_dice_4: 4.308  loss_ce_5: 0.4318  loss_mask_5: 0.561  loss_dice_5: 4.304  loss_ce_6: 0.423  loss_mask_6: 0.5572  loss_dice_6: 4.308  loss_ce_7: 0.4315  loss_mask_7: 0.552  loss_dice_7: 4.307  loss_ce_8: 0.4246  loss_mask_8: 0.5557  loss_dice_8: 4.307  time: 1.4119  data_time: 0.0574  lr: 9.4812e-06  max_mem: 21164M
[01/18 19:17:13] d2.utils.events INFO:  eta: 14:33:18  iter: 2319  total_loss: 53.71  loss_ce: 0.4516  loss_mask: 0.5578  loss_dice: 4.306  loss_ce_0: 1.008  loss_mask_0: 0.5403  loss_dice_0: 4.379  loss_ce_1: 0.4733  loss_mask_1: 0.559  loss_dice_1: 4.329  loss_ce_2: 0.4436  loss_mask_2: 0.5608  loss_dice_2: 4.317  loss_ce_3: 0.4459  loss_mask_3: 0.5603  loss_dice_3: 4.31  loss_ce_4: 0.4472  loss_mask_4: 0.5572  loss_dice_4: 4.306  loss_ce_5: 0.4418  loss_mask_5: 0.5587  loss_dice_5: 4.301  loss_ce_6: 0.4603  loss_mask_6: 0.5563  loss_dice_6: 4.302  loss_ce_7: 0.4569  loss_mask_7: 0.5576  loss_dice_7: 4.3  loss_ce_8: 0.4605  loss_mask_8: 0.5591  loss_dice_8: 4.306  time: 1.4116  data_time: 0.0537  lr: 9.4767e-06  max_mem: 21164M
[01/18 19:17:40] d2.utils.events INFO:  eta: 14:33:12  iter: 2339  total_loss: 53.35  loss_ce: 0.4374  loss_mask: 0.5647  loss_dice: 4.285  loss_ce_0: 0.9883  loss_mask_0: 0.544  loss_dice_0: 4.359  loss_ce_1: 0.4599  loss_mask_1: 0.5546  loss_dice_1: 4.31  loss_ce_2: 0.4294  loss_mask_2: 0.561  loss_dice_2: 4.298  loss_ce_3: 0.4329  loss_mask_3: 0.566  loss_dice_3: 4.287  loss_ce_4: 0.4259  loss_mask_4: 0.5692  loss_dice_4: 4.284  loss_ce_5: 0.4365  loss_mask_5: 0.5644  loss_dice_5: 4.28  loss_ce_6: 0.451  loss_mask_6: 0.5639  loss_dice_6: 4.282  loss_ce_7: 0.4316  loss_mask_7: 0.5659  loss_dice_7: 4.283  loss_ce_8: 0.4463  loss_mask_8: 0.5712  loss_dice_8: 4.274  time: 1.4113  data_time: 0.0596  lr: 9.4722e-06  max_mem: 21164M
[01/18 19:18:08] d2.utils.events INFO:  eta: 14:32:35  iter: 2359  total_loss: 53.39  loss_ce: 0.4426  loss_mask: 0.5521  loss_dice: 4.283  loss_ce_0: 0.9756  loss_mask_0: 0.5296  loss_dice_0: 4.356  loss_ce_1: 0.4338  loss_mask_1: 0.545  loss_dice_1: 4.304  loss_ce_2: 0.4238  loss_mask_2: 0.5469  loss_dice_2: 4.293  loss_ce_3: 0.4167  loss_mask_3: 0.5507  loss_dice_3: 4.283  loss_ce_4: 0.4108  loss_mask_4: 0.5528  loss_dice_4: 4.28  loss_ce_5: 0.431  loss_mask_5: 0.5508  loss_dice_5: 4.279  loss_ce_6: 0.4318  loss_mask_6: 0.5505  loss_dice_6: 4.272  loss_ce_7: 0.4283  loss_mask_7: 0.5494  loss_dice_7: 4.275  loss_ce_8: 0.4355  loss_mask_8: 0.5504  loss_dice_8: 4.278  time: 1.4110  data_time: 0.0605  lr: 9.4676e-06  max_mem: 21164M
[01/18 19:18:36] d2.utils.events INFO:  eta: 14:31:45  iter: 2379  total_loss: 53.54  loss_ce: 0.456  loss_mask: 0.5564  loss_dice: 4.271  loss_ce_0: 0.9935  loss_mask_0: 0.5325  loss_dice_0: 4.357  loss_ce_1: 0.4738  loss_mask_1: 0.5481  loss_dice_1: 4.294  loss_ce_2: 0.4587  loss_mask_2: 0.5526  loss_dice_2: 4.287  loss_ce_3: 0.4426  loss_mask_3: 0.5549  loss_dice_3: 4.278  loss_ce_4: 0.4626  loss_mask_4: 0.5553  loss_dice_4: 4.279  loss_ce_5: 0.4405  loss_mask_5: 0.5554  loss_dice_5: 4.27  loss_ce_6: 0.4528  loss_mask_6: 0.5559  loss_dice_6: 4.269  loss_ce_7: 0.4538  loss_mask_7: 0.5556  loss_dice_7: 4.269  loss_ce_8: 0.4526  loss_mask_8: 0.5563  loss_dice_8: 4.268  time: 1.4108  data_time: 0.0567  lr: 9.4631e-06  max_mem: 21164M
[01/18 19:19:04] d2.utils.events INFO:  eta: 14:31:17  iter: 2399  total_loss: 53.2  loss_ce: 0.4318  loss_mask: 0.5388  loss_dice: 4.292  loss_ce_0: 0.9731  loss_mask_0: 0.5211  loss_dice_0: 4.371  loss_ce_1: 0.435  loss_mask_1: 0.5381  loss_dice_1: 4.321  loss_ce_2: 0.426  loss_mask_2: 0.5404  loss_dice_2: 4.302  loss_ce_3: 0.4188  loss_mask_3: 0.5395  loss_dice_3: 4.297  loss_ce_4: 0.4279  loss_mask_4: 0.5381  loss_dice_4: 4.296  loss_ce_5: 0.4186  loss_mask_5: 0.537  loss_dice_5: 4.288  loss_ce_6: 0.4293  loss_mask_6: 0.5369  loss_dice_6: 4.29  loss_ce_7: 0.4141  loss_mask_7: 0.5379  loss_dice_7: 4.289  loss_ce_8: 0.4218  loss_mask_8: 0.5408  loss_dice_8: 4.29  time: 1.4108  data_time: 0.0566  lr: 9.4586e-06  max_mem: 21164M
[01/18 19:19:32] d2.utils.events INFO:  eta: 14:30:30  iter: 2419  total_loss: 53.19  loss_ce: 0.4733  loss_mask: 0.5642  loss_dice: 4.236  loss_ce_0: 0.9745  loss_mask_0: 0.5409  loss_dice_0: 4.331  loss_ce_1: 0.4795  loss_mask_1: 0.5554  loss_dice_1: 4.274  loss_ce_2: 0.4514  loss_mask_2: 0.5612  loss_dice_2: 4.249  loss_ce_3: 0.4452  loss_mask_3: 0.5581  loss_dice_3: 4.241  loss_ce_4: 0.4473  loss_mask_4: 0.5591  loss_dice_4: 4.236  loss_ce_5: 0.4484  loss_mask_5: 0.5603  loss_dice_5: 4.234  loss_ce_6: 0.4588  loss_mask_6: 0.5611  loss_dice_6: 4.231  loss_ce_7: 0.4601  loss_mask_7: 0.5593  loss_dice_7: 4.235  loss_ce_8: 0.4704  loss_mask_8: 0.5608  loss_dice_8: 4.237  time: 1.4105  data_time: 0.0608  lr: 9.454e-06  max_mem: 21164M
[01/18 19:19:59] d2.utils.events INFO:  eta: 14:30:17  iter: 2439  total_loss: 53.28  loss_ce: 0.4668  loss_mask: 0.5617  loss_dice: 4.262  loss_ce_0: 0.9462  loss_mask_0: 0.5391  loss_dice_0: 4.342  loss_ce_1: 0.4517  loss_mask_1: 0.5535  loss_dice_1: 4.286  loss_ce_2: 0.4457  loss_mask_2: 0.5584  loss_dice_2: 4.276  loss_ce_3: 0.436  loss_mask_3: 0.5598  loss_dice_3: 4.269  loss_ce_4: 0.4355  loss_mask_4: 0.5601  loss_dice_4: 4.266  loss_ce_5: 0.4369  loss_mask_5: 0.5623  loss_dice_5: 4.269  loss_ce_6: 0.4276  loss_mask_6: 0.5623  loss_dice_6: 4.265  loss_ce_7: 0.4437  loss_mask_7: 0.5638  loss_dice_7: 4.264  loss_ce_8: 0.4412  loss_mask_8: 0.56  loss_dice_8: 4.264  time: 1.4103  data_time: 0.0596  lr: 9.4495e-06  max_mem: 21164M
[01/18 19:20:27] d2.utils.events INFO:  eta: 14:29:29  iter: 2459  total_loss: 53.09  loss_ce: 0.4163  loss_mask: 0.5613  loss_dice: 4.272  loss_ce_0: 0.915  loss_mask_0: 0.5449  loss_dice_0: 4.346  loss_ce_1: 0.4206  loss_mask_1: 0.553  loss_dice_1: 4.306  loss_ce_2: 0.4158  loss_mask_2: 0.5554  loss_dice_2: 4.278  loss_ce_3: 0.4135  loss_mask_3: 0.5555  loss_dice_3: 4.272  loss_ce_4: 0.4107  loss_mask_4: 0.5595  loss_dice_4: 4.269  loss_ce_5: 0.4069  loss_mask_5: 0.559  loss_dice_5: 4.27  loss_ce_6: 0.4206  loss_mask_6: 0.5593  loss_dice_6: 4.267  loss_ce_7: 0.4091  loss_mask_7: 0.5594  loss_dice_7: 4.269  loss_ce_8: 0.4208  loss_mask_8: 0.5622  loss_dice_8: 4.268  time: 1.4101  data_time: 0.0545  lr: 9.445e-06  max_mem: 21164M
[01/18 19:20:55] d2.utils.events INFO:  eta: 14:28:55  iter: 2479  total_loss: 53.03  loss_ce: 0.4278  loss_mask: 0.5519  loss_dice: 4.234  loss_ce_0: 1.006  loss_mask_0: 0.5274  loss_dice_0: 4.325  loss_ce_1: 0.4725  loss_mask_1: 0.5478  loss_dice_1: 4.267  loss_ce_2: 0.4503  loss_mask_2: 0.5512  loss_dice_2: 4.237  loss_ce_3: 0.442  loss_mask_3: 0.5498  loss_dice_3: 4.24  loss_ce_4: 0.4644  loss_mask_4: 0.5512  loss_dice_4: 4.242  loss_ce_5: 0.4398  loss_mask_5: 0.555  loss_dice_5: 4.237  loss_ce_6: 0.437  loss_mask_6: 0.5538  loss_dice_6: 4.238  loss_ce_7: 0.451  loss_mask_7: 0.5526  loss_dice_7: 4.243  loss_ce_8: 0.452  loss_mask_8: 0.5512  loss_dice_8: 4.236  time: 1.4099  data_time: 0.0562  lr: 9.4405e-06  max_mem: 21164M
[01/18 19:21:24] d2.utils.events INFO:  eta: 14:28:51  iter: 2499  total_loss: 52.89  loss_ce: 0.4343  loss_mask: 0.5544  loss_dice: 4.265  loss_ce_0: 0.91  loss_mask_0: 0.532  loss_dice_0: 4.347  loss_ce_1: 0.4411  loss_mask_1: 0.5487  loss_dice_1: 4.284  loss_ce_2: 0.4359  loss_mask_2: 0.553  loss_dice_2: 4.271  loss_ce_3: 0.4254  loss_mask_3: 0.5541  loss_dice_3: 4.262  loss_ce_4: 0.4254  loss_mask_4: 0.5531  loss_dice_4: 4.262  loss_ce_5: 0.4325  loss_mask_5: 0.5531  loss_dice_5: 4.251  loss_ce_6: 0.4125  loss_mask_6: 0.5537  loss_dice_6: 4.257  loss_ce_7: 0.4311  loss_mask_7: 0.552  loss_dice_7: 4.257  loss_ce_8: 0.4276  loss_mask_8: 0.5534  loss_dice_8: 4.257  time: 1.4101  data_time: 0.0682  lr: 9.4359e-06  max_mem: 21164M
[01/18 19:21:53] d2.utils.events INFO:  eta: 14:28:39  iter: 2519  total_loss: 53.04  loss_ce: 0.4173  loss_mask: 0.5512  loss_dice: 4.251  loss_ce_0: 0.9114  loss_mask_0: 0.533  loss_dice_0: 4.334  loss_ce_1: 0.4485  loss_mask_1: 0.5495  loss_dice_1: 4.279  loss_ce_2: 0.4258  loss_mask_2: 0.5526  loss_dice_2: 4.267  loss_ce_3: 0.4218  loss_mask_3: 0.5542  loss_dice_3: 4.254  loss_ce_4: 0.4223  loss_mask_4: 0.5509  loss_dice_4: 4.254  loss_ce_5: 0.4132  loss_mask_5: 0.553  loss_dice_5: 4.248  loss_ce_6: 0.4284  loss_mask_6: 0.551  loss_dice_6: 4.251  loss_ce_7: 0.4371  loss_mask_7: 0.5514  loss_dice_7: 4.248  loss_ce_8: 0.4217  loss_mask_8: 0.5519  loss_dice_8: 4.249  time: 1.4104  data_time: 0.0607  lr: 9.4314e-06  max_mem: 21164M
[01/18 19:22:23] d2.utils.events INFO:  eta: 14:28:58  iter: 2539  total_loss: 52.6  loss_ce: 0.4336  loss_mask: 0.5605  loss_dice: 4.22  loss_ce_0: 0.9636  loss_mask_0: 0.5348  loss_dice_0: 4.317  loss_ce_1: 0.4493  loss_mask_1: 0.5544  loss_dice_1: 4.258  loss_ce_2: 0.4328  loss_mask_2: 0.5594  loss_dice_2: 4.234  loss_ce_3: 0.4405  loss_mask_3: 0.5575  loss_dice_3: 4.227  loss_ce_4: 0.4372  loss_mask_4: 0.558  loss_dice_4: 4.218  loss_ce_5: 0.4218  loss_mask_5: 0.5553  loss_dice_5: 4.22  loss_ce_6: 0.4273  loss_mask_6: 0.5576  loss_dice_6: 4.21  loss_ce_7: 0.4375  loss_mask_7: 0.555  loss_dice_7: 4.218  loss_ce_8: 0.4317  loss_mask_8: 0.5579  loss_dice_8: 4.222  time: 1.4112  data_time: 0.0879  lr: 9.4269e-06  max_mem: 21164M
[01/18 19:22:53] d2.utils.events INFO:  eta: 14:29:00  iter: 2559  total_loss: 53.34  loss_ce: 0.4577  loss_mask: 0.5599  loss_dice: 4.237  loss_ce_0: 0.9357  loss_mask_0: 0.5381  loss_dice_0: 4.331  loss_ce_1: 0.4679  loss_mask_1: 0.5525  loss_dice_1: 4.273  loss_ce_2: 0.4569  loss_mask_2: 0.5551  loss_dice_2: 4.257  loss_ce_3: 0.4472  loss_mask_3: 0.559  loss_dice_3: 4.248  loss_ce_4: 0.45  loss_mask_4: 0.5625  loss_dice_4: 4.24  loss_ce_5: 0.4521  loss_mask_5: 0.5637  loss_dice_5: 4.243  loss_ce_6: 0.4733  loss_mask_6: 0.5615  loss_dice_6: 4.236  loss_ce_7: 0.4591  loss_mask_7: 0.5583  loss_dice_7: 4.247  loss_ce_8: 0.4697  loss_mask_8: 0.5614  loss_dice_8: 4.243  time: 1.4119  data_time: 0.0788  lr: 9.4223e-06  max_mem: 21164M
[01/18 19:23:25] d2.utils.events INFO:  eta: 14:28:55  iter: 2579  total_loss: 52.88  loss_ce: 0.4061  loss_mask: 0.5648  loss_dice: 4.243  loss_ce_0: 0.8966  loss_mask_0: 0.5411  loss_dice_0: 4.326  loss_ce_1: 0.421  loss_mask_1: 0.5565  loss_dice_1: 4.269  loss_ce_2: 0.3999  loss_mask_2: 0.5611  loss_dice_2: 4.253  loss_ce_3: 0.3954  loss_mask_3: 0.5618  loss_dice_3: 4.247  loss_ce_4: 0.3879  loss_mask_4: 0.5643  loss_dice_4: 4.245  loss_ce_5: 0.3986  loss_mask_5: 0.563  loss_dice_5: 4.246  loss_ce_6: 0.4059  loss_mask_6: 0.5623  loss_dice_6: 4.248  loss_ce_7: 0.4055  loss_mask_7: 0.563  loss_dice_7: 4.246  loss_ce_8: 0.3992  loss_mask_8: 0.5627  loss_dice_8: 4.238  time: 1.4132  data_time: 0.0797  lr: 9.4178e-06  max_mem: 21164M
[01/18 19:23:57] d2.utils.events INFO:  eta: 14:29:36  iter: 2599  total_loss: 52.98  loss_ce: 0.4918  loss_mask: 0.5646  loss_dice: 4.238  loss_ce_0: 0.9487  loss_mask_0: 0.5372  loss_dice_0: 4.31  loss_ce_1: 0.4779  loss_mask_1: 0.5609  loss_dice_1: 4.253  loss_ce_2: 0.4766  loss_mask_2: 0.5604  loss_dice_2: 4.254  loss_ce_3: 0.4679  loss_mask_3: 0.5687  loss_dice_3: 4.244  loss_ce_4: 0.4664  loss_mask_4: 0.5662  loss_dice_4: 4.247  loss_ce_5: 0.4684  loss_mask_5: 0.5659  loss_dice_5: 4.243  loss_ce_6: 0.478  loss_mask_6: 0.5645  loss_dice_6: 4.239  loss_ce_7: 0.4845  loss_mask_7: 0.5681  loss_dice_7: 4.236  loss_ce_8: 0.4927  loss_mask_8: 0.5675  loss_dice_8: 4.238  time: 1.4147  data_time: 0.0856  lr: 9.4133e-06  max_mem: 21164M
[01/18 19:24:30] d2.utils.events INFO:  eta: 14:29:58  iter: 2619  total_loss: 52.94  loss_ce: 0.4761  loss_mask: 0.5461  loss_dice: 4.235  loss_ce_0: 0.9416  loss_mask_0: 0.5286  loss_dice_0: 4.326  loss_ce_1: 0.4755  loss_mask_1: 0.5466  loss_dice_1: 4.262  loss_ce_2: 0.4552  loss_mask_2: 0.5475  loss_dice_2: 4.248  loss_ce_3: 0.4513  loss_mask_3: 0.5504  loss_dice_3: 4.232  loss_ce_4: 0.4594  loss_mask_4: 0.5485  loss_dice_4: 4.233  loss_ce_5: 0.4712  loss_mask_5: 0.5489  loss_dice_5: 4.236  loss_ce_6: 0.4542  loss_mask_6: 0.5499  loss_dice_6: 4.227  loss_ce_7: 0.46  loss_mask_7: 0.5453  loss_dice_7: 4.234  loss_ce_8: 0.4765  loss_mask_8: 0.5454  loss_dice_8: 4.225  time: 1.4167  data_time: 0.0942  lr: 9.4087e-06  max_mem: 21164M
[01/18 19:25:04] d2.utils.events INFO:  eta: 14:30:25  iter: 2639  total_loss: 52.67  loss_ce: 0.4294  loss_mask: 0.549  loss_dice: 4.222  loss_ce_0: 0.9031  loss_mask_0: 0.5267  loss_dice_0: 4.321  loss_ce_1: 0.4388  loss_mask_1: 0.5454  loss_dice_1: 4.249  loss_ce_2: 0.4271  loss_mask_2: 0.5491  loss_dice_2: 4.239  loss_ce_3: 0.4364  loss_mask_3: 0.5488  loss_dice_3: 4.234  loss_ce_4: 0.4243  loss_mask_4: 0.5519  loss_dice_4: 4.232  loss_ce_5: 0.423  loss_mask_5: 0.5456  loss_dice_5: 4.235  loss_ce_6: 0.4273  loss_mask_6: 0.5458  loss_dice_6: 4.225  loss_ce_7: 0.4278  loss_mask_7: 0.549  loss_dice_7: 4.22  loss_ce_8: 0.4367  loss_mask_8: 0.5491  loss_dice_8: 4.217  time: 1.4187  data_time: 0.0924  lr: 9.4042e-06  max_mem: 21164M
[01/18 19:25:38] d2.utils.events INFO:  eta: 14:30:23  iter: 2659  total_loss: 52.7  loss_ce: 0.4188  loss_mask: 0.5472  loss_dice: 4.224  loss_ce_0: 0.891  loss_mask_0: 0.5239  loss_dice_0: 4.324  loss_ce_1: 0.4251  loss_mask_1: 0.5362  loss_dice_1: 4.266  loss_ce_2: 0.4155  loss_mask_2: 0.5441  loss_dice_2: 4.245  loss_ce_3: 0.4148  loss_mask_3: 0.5472  loss_dice_3: 4.233  loss_ce_4: 0.4067  loss_mask_4: 0.547  loss_dice_4: 4.224  loss_ce_5: 0.4194  loss_mask_5: 0.5479  loss_dice_5: 4.219  loss_ce_6: 0.4175  loss_mask_6: 0.5439  loss_dice_6: 4.23  loss_ce_7: 0.4235  loss_mask_7: 0.542  loss_dice_7: 4.228  loss_ce_8: 0.4182  loss_mask_8: 0.5455  loss_dice_8: 4.223  time: 1.4207  data_time: 0.0924  lr: 9.3997e-06  max_mem: 21164M
[01/18 19:26:11] d2.utils.events INFO:  eta: 14:30:53  iter: 2679  total_loss: 52.84  loss_ce: 0.4454  loss_mask: 0.5462  loss_dice: 4.209  loss_ce_0: 0.9055  loss_mask_0: 0.5304  loss_dice_0: 4.298  loss_ce_1: 0.4422  loss_mask_1: 0.5533  loss_dice_1: 4.232  loss_ce_2: 0.4438  loss_mask_2: 0.5557  loss_dice_2: 4.216  loss_ce_3: 0.4372  loss_mask_3: 0.5507  loss_dice_3: 4.213  loss_ce_4: 0.4559  loss_mask_4: 0.5502  loss_dice_4: 4.214  loss_ce_5: 0.4424  loss_mask_5: 0.5541  loss_dice_5: 4.204  loss_ce_6: 0.4421  loss_mask_6: 0.5514  loss_dice_6: 4.212  loss_ce_7: 0.4525  loss_mask_7: 0.5497  loss_dice_7: 4.202  loss_ce_8: 0.4465  loss_mask_8: 0.5477  loss_dice_8: 4.212  time: 1.4225  data_time: 0.0918  lr: 9.3952e-06  max_mem: 21164M
[01/18 19:26:44] d2.utils.events INFO:  eta: 14:31:10  iter: 2699  total_loss: 52.81  loss_ce: 0.4647  loss_mask: 0.5373  loss_dice: 4.215  loss_ce_0: 0.9157  loss_mask_0: 0.5179  loss_dice_0: 4.32  loss_ce_1: 0.4466  loss_mask_1: 0.5309  loss_dice_1: 4.253  loss_ce_2: 0.449  loss_mask_2: 0.5336  loss_dice_2: 4.233  loss_ce_3: 0.4476  loss_mask_3: 0.5353  loss_dice_3: 4.226  loss_ce_4: 0.46  loss_mask_4: 0.5316  loss_dice_4: 4.207  loss_ce_5: 0.4481  loss_mask_5: 0.534  loss_dice_5: 4.212  loss_ce_6: 0.4577  loss_mask_6: 0.5314  loss_dice_6: 4.212  loss_ce_7: 0.4589  loss_mask_7: 0.5326  loss_dice_7: 4.21  loss_ce_8: 0.4502  loss_mask_8: 0.535  loss_dice_8: 4.213  time: 1.4240  data_time: 0.0789  lr: 9.3906e-06  max_mem: 21164M
[01/18 19:27:16] d2.utils.events INFO:  eta: 14:31:51  iter: 2719  total_loss: 52.8  loss_ce: 0.4136  loss_mask: 0.5676  loss_dice: 4.235  loss_ce_0: 0.8533  loss_mask_0: 0.5479  loss_dice_0: 4.311  loss_ce_1: 0.4163  loss_mask_1: 0.5621  loss_dice_1: 4.26  loss_ce_2: 0.4097  loss_mask_2: 0.5633  loss_dice_2: 4.243  loss_ce_3: 0.3986  loss_mask_3: 0.5654  loss_dice_3: 4.238  loss_ce_4: 0.4106  loss_mask_4: 0.5639  loss_dice_4: 4.231  loss_ce_5: 0.4053  loss_mask_5: 0.5672  loss_dice_5: 4.23  loss_ce_6: 0.4162  loss_mask_6: 0.567  loss_dice_6: 4.228  loss_ce_7: 0.4197  loss_mask_7: 0.5642  loss_dice_7: 4.224  loss_ce_8: 0.4198  loss_mask_8: 0.5666  loss_dice_8: 4.233  time: 1.4253  data_time: 0.0954  lr: 9.3861e-06  max_mem: 21164M
[01/18 19:27:47] d2.utils.events INFO:  eta: 14:32:13  iter: 2739  total_loss: 52.22  loss_ce: 0.4203  loss_mask: 0.5396  loss_dice: 4.207  loss_ce_0: 0.891  loss_mask_0: 0.5243  loss_dice_0: 4.295  loss_ce_1: 0.4158  loss_mask_1: 0.5371  loss_dice_1: 4.226  loss_ce_2: 0.399  loss_mask_2: 0.5417  loss_dice_2: 4.221  loss_ce_3: 0.3975  loss_mask_3: 0.5432  loss_dice_3: 4.213  loss_ce_4: 0.4076  loss_mask_4: 0.5397  loss_dice_4: 4.206  loss_ce_5: 0.4029  loss_mask_5: 0.5374  loss_dice_5: 4.206  loss_ce_6: 0.4117  loss_mask_6: 0.5372  loss_dice_6: 4.207  loss_ce_7: 0.4176  loss_mask_7: 0.5385  loss_dice_7: 4.2  loss_ce_8: 0.414  loss_mask_8: 0.5383  loss_dice_8: 4.204  time: 1.4263  data_time: 0.0930  lr: 9.3816e-06  max_mem: 21164M
[01/18 19:28:17] d2.utils.events INFO:  eta: 14:32:47  iter: 2759  total_loss: 52.74  loss_ce: 0.4437  loss_mask: 0.5643  loss_dice: 4.208  loss_ce_0: 0.889  loss_mask_0: 0.5354  loss_dice_0: 4.301  loss_ce_1: 0.4478  loss_mask_1: 0.5563  loss_dice_1: 4.238  loss_ce_2: 0.4311  loss_mask_2: 0.5589  loss_dice_2: 4.223  loss_ce_3: 0.4271  loss_mask_3: 0.5634  loss_dice_3: 4.212  loss_ce_4: 0.4502  loss_mask_4: 0.562  loss_dice_4: 4.213  loss_ce_5: 0.4442  loss_mask_5: 0.5616  loss_dice_5: 4.216  loss_ce_6: 0.4286  loss_mask_6: 0.5661  loss_dice_6: 4.207  loss_ce_7: 0.4303  loss_mask_7: 0.5638  loss_dice_7: 4.205  loss_ce_8: 0.4388  loss_mask_8: 0.5646  loss_dice_8: 4.208  time: 1.4268  data_time: 0.0830  lr: 9.377e-06  max_mem: 21164M
[01/18 19:28:46] d2.utils.events INFO:  eta: 14:32:42  iter: 2779  total_loss: 52.32  loss_ce: 0.4288  loss_mask: 0.5458  loss_dice: 4.212  loss_ce_0: 0.8493  loss_mask_0: 0.5258  loss_dice_0: 4.302  loss_ce_1: 0.4385  loss_mask_1: 0.5429  loss_dice_1: 4.234  loss_ce_2: 0.4188  loss_mask_2: 0.5469  loss_dice_2: 4.224  loss_ce_3: 0.4142  loss_mask_3: 0.5445  loss_dice_3: 4.215  loss_ce_4: 0.429  loss_mask_4: 0.5458  loss_dice_4: 4.211  loss_ce_5: 0.4231  loss_mask_5: 0.5501  loss_dice_5: 4.213  loss_ce_6: 0.4332  loss_mask_6: 0.5431  loss_dice_6: 4.209  loss_ce_7: 0.4328  loss_mask_7: 0.5433  loss_dice_7: 4.207  loss_ce_8: 0.4408  loss_mask_8: 0.5421  loss_dice_8: 4.218  time: 1.4269  data_time: 0.0665  lr: 9.3725e-06  max_mem: 21164M
[01/18 19:29:14] d2.utils.events INFO:  eta: 14:32:48  iter: 2799  total_loss: 52.52  loss_ce: 0.4306  loss_mask: 0.5443  loss_dice: 4.207  loss_ce_0: 0.8665  loss_mask_0: 0.5271  loss_dice_0: 4.286  loss_ce_1: 0.4422  loss_mask_1: 0.545  loss_dice_1: 4.227  loss_ce_2: 0.4264  loss_mask_2: 0.5465  loss_dice_2: 4.218  loss_ce_3: 0.4098  loss_mask_3: 0.5458  loss_dice_3: 4.214  loss_ce_4: 0.4213  loss_mask_4: 0.5464  loss_dice_4: 4.204  loss_ce_5: 0.4098  loss_mask_5: 0.5491  loss_dice_5: 4.207  loss_ce_6: 0.4162  loss_mask_6: 0.5486  loss_dice_6: 4.208  loss_ce_7: 0.4191  loss_mask_7: 0.5456  loss_dice_7: 4.2  loss_ce_8: 0.426  loss_mask_8: 0.5484  loss_dice_8: 4.203  time: 1.4267  data_time: 0.0645  lr: 9.368e-06  max_mem: 21164M
[01/18 19:29:42] d2.utils.events INFO:  eta: 14:31:38  iter: 2819  total_loss: 52.32  loss_ce: 0.4057  loss_mask: 0.5549  loss_dice: 4.219  loss_ce_0: 0.851  loss_mask_0: 0.5322  loss_dice_0: 4.304  loss_ce_1: 0.4186  loss_mask_1: 0.549  loss_dice_1: 4.255  loss_ce_2: 0.392  loss_mask_2: 0.5524  loss_dice_2: 4.23  loss_ce_3: 0.4013  loss_mask_3: 0.5544  loss_dice_3: 4.218  loss_ce_4: 0.3899  loss_mask_4: 0.5541  loss_dice_4: 4.216  loss_ce_5: 0.3973  loss_mask_5: 0.5554  loss_dice_5: 4.211  loss_ce_6: 0.4066  loss_mask_6: 0.5563  loss_dice_6: 4.209  loss_ce_7: 0.4038  loss_mask_7: 0.5554  loss_dice_7: 4.218  loss_ce_8: 0.4038  loss_mask_8: 0.5541  loss_dice_8: 4.212  time: 1.4265  data_time: 0.0577  lr: 9.3634e-06  max_mem: 21164M
[01/18 19:30:10] d2.utils.events INFO:  eta: 14:31:22  iter: 2839  total_loss: 51.97  loss_ce: 0.4188  loss_mask: 0.5471  loss_dice: 4.178  loss_ce_0: 0.8683  loss_mask_0: 0.5245  loss_dice_0: 4.275  loss_ce_1: 0.4285  loss_mask_1: 0.5414  loss_dice_1: 4.204  loss_ce_2: 0.4147  loss_mask_2: 0.5459  loss_dice_2: 4.195  loss_ce_3: 0.4044  loss_mask_3: 0.5446  loss_dice_3: 4.175  loss_ce_4: 0.4303  loss_mask_4: 0.5452  loss_dice_4: 4.184  loss_ce_5: 0.4312  loss_mask_5: 0.5472  loss_dice_5: 4.181  loss_ce_6: 0.4058  loss_mask_6: 0.5483  loss_dice_6: 4.171  loss_ce_7: 0.4194  loss_mask_7: 0.5464  loss_dice_7: 4.166  loss_ce_8: 0.421  loss_mask_8: 0.5494  loss_dice_8: 4.169  time: 1.4262  data_time: 0.0555  lr: 9.3589e-06  max_mem: 21164M
[01/18 19:30:38] d2.utils.events INFO:  eta: 14:30:49  iter: 2859  total_loss: 52.01  loss_ce: 0.4349  loss_mask: 0.5477  loss_dice: 4.156  loss_ce_0: 0.865  loss_mask_0: 0.5226  loss_dice_0: 4.262  loss_ce_1: 0.4408  loss_mask_1: 0.5411  loss_dice_1: 4.196  loss_ce_2: 0.4222  loss_mask_2: 0.545  loss_dice_2: 4.173  loss_ce_3: 0.4284  loss_mask_3: 0.545  loss_dice_3: 4.163  loss_ce_4: 0.4229  loss_mask_4: 0.5482  loss_dice_4: 4.165  loss_ce_5: 0.4266  loss_mask_5: 0.5472  loss_dice_5: 4.164  loss_ce_6: 0.4324  loss_mask_6: 0.549  loss_dice_6: 4.161  loss_ce_7: 0.4338  loss_mask_7: 0.5469  loss_dice_7: 4.159  loss_ce_8: 0.431  loss_mask_8: 0.5466  loss_dice_8: 4.162  time: 1.4260  data_time: 0.0617  lr: 9.3544e-06  max_mem: 21164M
[01/18 19:31:05] d2.utils.events INFO:  eta: 14:30:24  iter: 2879  total_loss: 51.53  loss_ce: 0.3921  loss_mask: 0.536  loss_dice: 4.145  loss_ce_0: 0.8082  loss_mask_0: 0.5153  loss_dice_0: 4.257  loss_ce_1: 0.4264  loss_mask_1: 0.5294  loss_dice_1: 4.188  loss_ce_2: 0.4081  loss_mask_2: 0.5299  loss_dice_2: 4.162  loss_ce_3: 0.3944  loss_mask_3: 0.5353  loss_dice_3: 4.163  loss_ce_4: 0.4023  loss_mask_4: 0.5353  loss_dice_4: 4.155  loss_ce_5: 0.3835  loss_mask_5: 0.5362  loss_dice_5: 4.153  loss_ce_6: 0.386  loss_mask_6: 0.537  loss_dice_6: 4.149  loss_ce_7: 0.4016  loss_mask_7: 0.5348  loss_dice_7: 4.144  loss_ce_8: 0.3994  loss_mask_8: 0.5365  loss_dice_8: 4.146  time: 1.4257  data_time: 0.0594  lr: 9.3498e-06  max_mem: 21164M
[01/18 19:31:33] d2.utils.events INFO:  eta: 14:29:46  iter: 2899  total_loss: 51.8  loss_ce: 0.4018  loss_mask: 0.549  loss_dice: 4.136  loss_ce_0: 0.8345  loss_mask_0: 0.5289  loss_dice_0: 4.248  loss_ce_1: 0.4249  loss_mask_1: 0.5443  loss_dice_1: 4.172  loss_ce_2: 0.4046  loss_mask_2: 0.5467  loss_dice_2: 4.151  loss_ce_3: 0.4115  loss_mask_3: 0.5458  loss_dice_3: 4.147  loss_ce_4: 0.4115  loss_mask_4: 0.5467  loss_dice_4: 4.14  loss_ce_5: 0.4206  loss_mask_5: 0.5476  loss_dice_5: 4.137  loss_ce_6: 0.4152  loss_mask_6: 0.5451  loss_dice_6: 4.142  loss_ce_7: 0.4055  loss_mask_7: 0.5474  loss_dice_7: 4.131  loss_ce_8: 0.4132  loss_mask_8: 0.5474  loss_dice_8: 4.133  time: 1.4254  data_time: 0.0574  lr: 9.3453e-06  max_mem: 21164M
[01/18 19:32:01] d2.utils.events INFO:  eta: 14:29:18  iter: 2919  total_loss: 51.98  loss_ce: 0.42  loss_mask: 0.5593  loss_dice: 4.164  loss_ce_0: 0.8512  loss_mask_0: 0.5308  loss_dice_0: 4.274  loss_ce_1: 0.4358  loss_mask_1: 0.5468  loss_dice_1: 4.199  loss_ce_2: 0.435  loss_mask_2: 0.5507  loss_dice_2: 4.185  loss_ce_3: 0.4036  loss_mask_3: 0.5546  loss_dice_3: 4.176  loss_ce_4: 0.4043  loss_mask_4: 0.5573  loss_dice_4: 4.168  loss_ce_5: 0.4072  loss_mask_5: 0.558  loss_dice_5: 4.174  loss_ce_6: 0.4166  loss_mask_6: 0.556  loss_dice_6: 4.174  loss_ce_7: 0.4172  loss_mask_7: 0.5543  loss_dice_7: 4.166  loss_ce_8: 0.4236  loss_mask_8: 0.5555  loss_dice_8: 4.164  time: 1.4251  data_time: 0.0602  lr: 9.3408e-06  max_mem: 21164M
[01/18 19:32:29] d2.utils.events INFO:  eta: 14:28:48  iter: 2939  total_loss: 51.78  loss_ce: 0.419  loss_mask: 0.5479  loss_dice: 4.135  loss_ce_0: 0.8142  loss_mask_0: 0.5293  loss_dice_0: 4.245  loss_ce_1: 0.4193  loss_mask_1: 0.547  loss_dice_1: 4.175  loss_ce_2: 0.4259  loss_mask_2: 0.5486  loss_dice_2: 4.156  loss_ce_3: 0.425  loss_mask_3: 0.548  loss_dice_3: 4.146  loss_ce_4: 0.417  loss_mask_4: 0.5484  loss_dice_4: 4.137  loss_ce_5: 0.4061  loss_mask_5: 0.548  loss_dice_5: 4.142  loss_ce_6: 0.4087  loss_mask_6: 0.5506  loss_dice_6: 4.137  loss_ce_7: 0.4279  loss_mask_7: 0.5503  loss_dice_7: 4.134  loss_ce_8: 0.4135  loss_mask_8: 0.5509  loss_dice_8: 4.134  time: 1.4248  data_time: 0.0652  lr: 9.3362e-06  max_mem: 21164M
[01/18 19:32:56] d2.utils.events INFO:  eta: 14:28:21  iter: 2959  total_loss: 51.99  loss_ce: 0.4341  loss_mask: 0.5567  loss_dice: 4.146  loss_ce_0: 0.8587  loss_mask_0: 0.5344  loss_dice_0: 4.25  loss_ce_1: 0.4496  loss_mask_1: 0.5489  loss_dice_1: 4.183  loss_ce_2: 0.4394  loss_mask_2: 0.5542  loss_dice_2: 4.153  loss_ce_3: 0.4249  loss_mask_3: 0.5564  loss_dice_3: 4.144  loss_ce_4: 0.4305  loss_mask_4: 0.5576  loss_dice_4: 4.14  loss_ce_5: 0.4171  loss_mask_5: 0.5566  loss_dice_5: 4.15  loss_ce_6: 0.4273  loss_mask_6: 0.5602  loss_dice_6: 4.15  loss_ce_7: 0.4293  loss_mask_7: 0.5584  loss_dice_7: 4.138  loss_ce_8: 0.4279  loss_mask_8: 0.5571  loss_dice_8: 4.142  time: 1.4245  data_time: 0.0633  lr: 9.3317e-06  max_mem: 21164M
[01/18 19:33:24] d2.utils.events INFO:  eta: 14:27:32  iter: 2979  total_loss: 51.64  loss_ce: 0.4011  loss_mask: 0.5677  loss_dice: 4.119  loss_ce_0: 0.8043  loss_mask_0: 0.5379  loss_dice_0: 4.226  loss_ce_1: 0.4236  loss_mask_1: 0.5581  loss_dice_1: 4.157  loss_ce_2: 0.4057  loss_mask_2: 0.563  loss_dice_2: 4.142  loss_ce_3: 0.393  loss_mask_3: 0.5642  loss_dice_3: 4.136  loss_ce_4: 0.3978  loss_mask_4: 0.5643  loss_dice_4: 4.122  loss_ce_5: 0.3993  loss_mask_5: 0.5677  loss_dice_5: 4.124  loss_ce_6: 0.4048  loss_mask_6: 0.5624  loss_dice_6: 4.123  loss_ce_7: 0.4041  loss_mask_7: 0.5644  loss_dice_7: 4.128  loss_ce_8: 0.4178  loss_mask_8: 0.5653  loss_dice_8: 4.124  time: 1.4241  data_time: 0.0589  lr: 9.3272e-06  max_mem: 21164M
[01/18 19:33:52] d2.utils.events INFO:  eta: 14:27:35  iter: 2999  total_loss: 51.73  loss_ce: 0.4325  loss_mask: 0.5352  loss_dice: 4.132  loss_ce_0: 0.8458  loss_mask_0: 0.5137  loss_dice_0: 4.239  loss_ce_1: 0.445  loss_mask_1: 0.5294  loss_dice_1: 4.172  loss_ce_2: 0.4082  loss_mask_2: 0.5319  loss_dice_2: 4.152  loss_ce_3: 0.4238  loss_mask_3: 0.5344  loss_dice_3: 4.141  loss_ce_4: 0.4234  loss_mask_4: 0.5367  loss_dice_4: 4.136  loss_ce_5: 0.4257  loss_mask_5: 0.5357  loss_dice_5: 4.135  loss_ce_6: 0.4325  loss_mask_6: 0.5337  loss_dice_6: 4.137  loss_ce_7: 0.4233  loss_mask_7: 0.5357  loss_dice_7: 4.134  loss_ce_8: 0.426  loss_mask_8: 0.5379  loss_dice_8: 4.126  time: 1.4240  data_time: 0.0580  lr: 9.3226e-06  max_mem: 21164M
[01/18 19:34:19] d2.utils.events INFO:  eta: 14:26:52  iter: 3019  total_loss: 52.01  loss_ce: 0.4185  loss_mask: 0.5665  loss_dice: 4.136  loss_ce_0: 0.8185  loss_mask_0: 0.5461  loss_dice_0: 4.235  loss_ce_1: 0.425  loss_mask_1: 0.5625  loss_dice_1: 4.164  loss_ce_2: 0.4161  loss_mask_2: 0.5675  loss_dice_2: 4.144  loss_ce_3: 0.4231  loss_mask_3: 0.5664  loss_dice_3: 4.142  loss_ce_4: 0.4113  loss_mask_4: 0.5654  loss_dice_4: 4.138  loss_ce_5: 0.4011  loss_mask_5: 0.5673  loss_dice_5: 4.133  loss_ce_6: 0.4272  loss_mask_6: 0.5659  loss_dice_6: 4.138  loss_ce_7: 0.4331  loss_mask_7: 0.5668  loss_dice_7: 4.133  loss_ce_8: 0.4197  loss_mask_8: 0.5658  loss_dice_8: 4.14  time: 1.4236  data_time: 0.0543  lr: 9.3181e-06  max_mem: 21164M
[01/18 19:34:47] d2.utils.events INFO:  eta: 14:26:10  iter: 3039  total_loss: 51.73  loss_ce: 0.433  loss_mask: 0.5584  loss_dice: 4.127  loss_ce_0: 0.8242  loss_mask_0: 0.529  loss_dice_0: 4.234  loss_ce_1: 0.4311  loss_mask_1: 0.5518  loss_dice_1: 4.159  loss_ce_2: 0.4252  loss_mask_2: 0.5581  loss_dice_2: 4.14  loss_ce_3: 0.4182  loss_mask_3: 0.5589  loss_dice_3: 4.142  loss_ce_4: 0.4272  loss_mask_4: 0.5584  loss_dice_4: 4.135  loss_ce_5: 0.4199  loss_mask_5: 0.5652  loss_dice_5: 4.13  loss_ce_6: 0.4322  loss_mask_6: 0.5599  loss_dice_6: 4.128  loss_ce_7: 0.4274  loss_mask_7: 0.5599  loss_dice_7: 4.131  loss_ce_8: 0.4239  loss_mask_8: 0.5592  loss_dice_8: 4.124  time: 1.4234  data_time: 0.0562  lr: 9.3136e-06  max_mem: 21164M
[01/18 19:35:15] d2.utils.events INFO:  eta: 14:25:49  iter: 3059  total_loss: 51.5  loss_ce: 0.4217  loss_mask: 0.5625  loss_dice: 4.109  loss_ce_0: 0.8491  loss_mask_0: 0.5409  loss_dice_0: 4.21  loss_ce_1: 0.4465  loss_mask_1: 0.5592  loss_dice_1: 4.14  loss_ce_2: 0.4043  loss_mask_2: 0.5592  loss_dice_2: 4.127  loss_ce_3: 0.4021  loss_mask_3: 0.5592  loss_dice_3: 4.118  loss_ce_4: 0.4144  loss_mask_4: 0.563  loss_dice_4: 4.109  loss_ce_5: 0.3983  loss_mask_5: 0.5616  loss_dice_5: 4.109  loss_ce_6: 0.4021  loss_mask_6: 0.5598  loss_dice_6: 4.107  loss_ce_7: 0.3969  loss_mask_7: 0.5633  loss_dice_7: 4.11  loss_ce_8: 0.4172  loss_mask_8: 0.5621  loss_dice_8: 4.106  time: 1.4231  data_time: 0.0607  lr: 9.309e-06  max_mem: 21164M
[01/18 19:35:43] d2.utils.events INFO:  eta: 14:25:40  iter: 3079  total_loss: 51.75  loss_ce: 0.454  loss_mask: 0.5421  loss_dice: 4.13  loss_ce_0: 0.8347  loss_mask_0: 0.5165  loss_dice_0: 4.23  loss_ce_1: 0.4496  loss_mask_1: 0.537  loss_dice_1: 4.165  loss_ce_2: 0.4308  loss_mask_2: 0.5462  loss_dice_2: 4.145  loss_ce_3: 0.4239  loss_mask_3: 0.5441  loss_dice_3: 4.135  loss_ce_4: 0.4317  loss_mask_4: 0.5421  loss_dice_4: 4.127  loss_ce_5: 0.4113  loss_mask_5: 0.5434  loss_dice_5: 4.13  loss_ce_6: 0.4386  loss_mask_6: 0.5416  loss_dice_6: 4.127  loss_ce_7: 0.4242  loss_mask_7: 0.542  loss_dice_7: 4.128  loss_ce_8: 0.436  loss_mask_8: 0.5423  loss_dice_8: 4.129  time: 1.4229  data_time: 0.0583  lr: 9.3045e-06  max_mem: 21164M
[01/18 19:36:10] d2.utils.events INFO:  eta: 14:25:04  iter: 3099  total_loss: 51.27  loss_ce: 0.4397  loss_mask: 0.5411  loss_dice: 4.115  loss_ce_0: 0.8326  loss_mask_0: 0.5302  loss_dice_0: 4.221  loss_ce_1: 0.4461  loss_mask_1: 0.5399  loss_dice_1: 4.16  loss_ce_2: 0.4325  loss_mask_2: 0.5396  loss_dice_2: 4.14  loss_ce_3: 0.4217  loss_mask_3: 0.5408  loss_dice_3: 4.116  loss_ce_4: 0.438  loss_mask_4: 0.5397  loss_dice_4: 4.123  loss_ce_5: 0.4262  loss_mask_5: 0.5446  loss_dice_5: 4.127  loss_ce_6: 0.4271  loss_mask_6: 0.5399  loss_dice_6: 4.118  loss_ce_7: 0.4373  loss_mask_7: 0.5382  loss_dice_7: 4.116  loss_ce_8: 0.4281  loss_mask_8: 0.5399  loss_dice_8: 4.127  time: 1.4226  data_time: 0.0639  lr: 9.2999e-06  max_mem: 21164M
[01/18 19:36:38] d2.utils.events INFO:  eta: 14:24:39  iter: 3119  total_loss: 51.68  loss_ce: 0.4218  loss_mask: 0.5564  loss_dice: 4.122  loss_ce_0: 0.8301  loss_mask_0: 0.5405  loss_dice_0: 4.232  loss_ce_1: 0.425  loss_mask_1: 0.5558  loss_dice_1: 4.158  loss_ce_2: 0.4122  loss_mask_2: 0.5589  loss_dice_2: 4.146  loss_ce_3: 0.3956  loss_mask_3: 0.5605  loss_dice_3: 4.129  loss_ce_4: 0.4015  loss_mask_4: 0.5576  loss_dice_4: 4.13  loss_ce_5: 0.414  loss_mask_5: 0.5584  loss_dice_5: 4.119  loss_ce_6: 0.4101  loss_mask_6: 0.5564  loss_dice_6: 4.12  loss_ce_7: 0.4164  loss_mask_7: 0.5576  loss_dice_7: 4.121  loss_ce_8: 0.4112  loss_mask_8: 0.556  loss_dice_8: 4.127  time: 1.4223  data_time: 0.0636  lr: 9.2954e-06  max_mem: 21164M
[01/18 19:37:06] d2.utils.events INFO:  eta: 14:24:03  iter: 3139  total_loss: 51.45  loss_ce: 0.4168  loss_mask: 0.5403  loss_dice: 4.126  loss_ce_0: 0.829  loss_mask_0: 0.5212  loss_dice_0: 4.245  loss_ce_1: 0.4295  loss_mask_1: 0.5368  loss_dice_1: 4.152  loss_ce_2: 0.3979  loss_mask_2: 0.5387  loss_dice_2: 4.139  loss_ce_3: 0.3995  loss_mask_3: 0.5401  loss_dice_3: 4.128  loss_ce_4: 0.4116  loss_mask_4: 0.5396  loss_dice_4: 4.115  loss_ce_5: 0.4177  loss_mask_5: 0.5413  loss_dice_5: 4.121  loss_ce_6: 0.4073  loss_mask_6: 0.5421  loss_dice_6: 4.121  loss_ce_7: 0.4205  loss_mask_7: 0.5444  loss_dice_7: 4.125  loss_ce_8: 0.4183  loss_mask_8: 0.545  loss_dice_8: 4.117  time: 1.4221  data_time: 0.0580  lr: 9.2909e-06  max_mem: 21164M
[01/18 19:37:33] d2.utils.events INFO:  eta: 14:23:21  iter: 3159  total_loss: 51.48  loss_ce: 0.4097  loss_mask: 0.5518  loss_dice: 4.102  loss_ce_0: 0.7812  loss_mask_0: 0.5253  loss_dice_0: 4.221  loss_ce_1: 0.4179  loss_mask_1: 0.5493  loss_dice_1: 4.138  loss_ce_2: 0.3793  loss_mask_2: 0.5513  loss_dice_2: 4.126  loss_ce_3: 0.4065  loss_mask_3: 0.5514  loss_dice_3: 4.112  loss_ce_4: 0.4068  loss_mask_4: 0.5499  loss_dice_4: 4.11  loss_ce_5: 0.405  loss_mask_5: 0.5524  loss_dice_5: 4.112  loss_ce_6: 0.405  loss_mask_6: 0.5508  loss_dice_6: 4.115  loss_ce_7: 0.4123  loss_mask_7: 0.5508  loss_dice_7: 4.109  loss_ce_8: 0.4253  loss_mask_8: 0.5509  loss_dice_8: 4.106  time: 1.4218  data_time: 0.0580  lr: 9.2863e-06  max_mem: 21164M
[01/18 19:38:01] d2.utils.events INFO:  eta: 14:23:07  iter: 3179  total_loss: 51.41  loss_ce: 0.4117  loss_mask: 0.5419  loss_dice: 4.11  loss_ce_0: 0.8307  loss_mask_0: 0.5179  loss_dice_0: 4.22  loss_ce_1: 0.4504  loss_mask_1: 0.5357  loss_dice_1: 4.145  loss_ce_2: 0.4297  loss_mask_2: 0.5425  loss_dice_2: 4.127  loss_ce_3: 0.4216  loss_mask_3: 0.5418  loss_dice_3: 4.121  loss_ce_4: 0.4238  loss_mask_4: 0.5421  loss_dice_4: 4.111  loss_ce_5: 0.4326  loss_mask_5: 0.5423  loss_dice_5: 4.113  loss_ce_6: 0.4307  loss_mask_6: 0.5412  loss_dice_6: 4.115  loss_ce_7: 0.4302  loss_mask_7: 0.5398  loss_dice_7: 4.111  loss_ce_8: 0.4186  loss_mask_8: 0.5408  loss_dice_8: 4.108  time: 1.4216  data_time: 0.0570  lr: 9.2818e-06  max_mem: 21164M
[01/18 19:38:29] d2.utils.events INFO:  eta: 14:22:33  iter: 3199  total_loss: 51.61  loss_ce: 0.4288  loss_mask: 0.5678  loss_dice: 4.119  loss_ce_0: 0.7894  loss_mask_0: 0.5418  loss_dice_0: 4.217  loss_ce_1: 0.4427  loss_mask_1: 0.5629  loss_dice_1: 4.142  loss_ce_2: 0.4336  loss_mask_2: 0.5621  loss_dice_2: 4.128  loss_ce_3: 0.4248  loss_mask_3: 0.5624  loss_dice_3: 4.117  loss_ce_4: 0.4292  loss_mask_4: 0.5649  loss_dice_4: 4.124  loss_ce_5: 0.4223  loss_mask_5: 0.5645  loss_dice_5: 4.117  loss_ce_6: 0.4482  loss_mask_6: 0.5655  loss_dice_6: 4.118  loss_ce_7: 0.4265  loss_mask_7: 0.5663  loss_dice_7: 4.112  loss_ce_8: 0.4334  loss_mask_8: 0.5696  loss_dice_8: 4.119  time: 1.4213  data_time: 0.0590  lr: 9.2773e-06  max_mem: 21164M
[01/18 19:38:57] d2.utils.events INFO:  eta: 14:22:04  iter: 3219  total_loss: 50.94  loss_ce: 0.4294  loss_mask: 0.5424  loss_dice: 4.085  loss_ce_0: 0.8271  loss_mask_0: 0.5188  loss_dice_0: 4.203  loss_ce_1: 0.4305  loss_mask_1: 0.531  loss_dice_1: 4.118  loss_ce_2: 0.4182  loss_mask_2: 0.5362  loss_dice_2: 4.092  loss_ce_3: 0.4186  loss_mask_3: 0.536  loss_dice_3: 4.084  loss_ce_4: 0.3944  loss_mask_4: 0.5384  loss_dice_4: 4.084  loss_ce_5: 0.4045  loss_mask_5: 0.5388  loss_dice_5: 4.088  loss_ce_6: 0.4275  loss_mask_6: 0.5407  loss_dice_6: 4.087  loss_ce_7: 0.4081  loss_mask_7: 0.5381  loss_dice_7: 4.088  loss_ce_8: 0.4128  loss_mask_8: 0.542  loss_dice_8: 4.087  time: 1.4212  data_time: 0.0649  lr: 9.2727e-06  max_mem: 21164M
[01/18 19:39:24] d2.utils.events INFO:  eta: 14:21:10  iter: 3239  total_loss: 51.19  loss_ce: 0.4129  loss_mask: 0.5567  loss_dice: 4.1  loss_ce_0: 0.802  loss_mask_0: 0.533  loss_dice_0: 4.21  loss_ce_1: 0.4178  loss_mask_1: 0.5492  loss_dice_1: 4.14  loss_ce_2: 0.3843  loss_mask_2: 0.5558  loss_dice_2: 4.128  loss_ce_3: 0.4  loss_mask_3: 0.5585  loss_dice_3: 4.123  loss_ce_4: 0.3958  loss_mask_4: 0.5585  loss_dice_4: 4.109  loss_ce_5: 0.3961  loss_mask_5: 0.5602  loss_dice_5: 4.109  loss_ce_6: 0.3864  loss_mask_6: 0.5591  loss_dice_6: 4.106  loss_ce_7: 0.4019  loss_mask_7: 0.5584  loss_dice_7: 4.104  loss_ce_8: 0.3892  loss_mask_8: 0.5589  loss_dice_8: 4.105  time: 1.4208  data_time: 0.0585  lr: 9.2682e-06  max_mem: 21164M
[01/18 19:39:52] d2.utils.events INFO:  eta: 14:20:00  iter: 3259  total_loss: 51.05  loss_ce: 0.4124  loss_mask: 0.5525  loss_dice: 4.1  loss_ce_0: 0.7762  loss_mask_0: 0.5318  loss_dice_0: 4.213  loss_ce_1: 0.428  loss_mask_1: 0.5473  loss_dice_1: 4.119  loss_ce_2: 0.4049  loss_mask_2: 0.5517  loss_dice_2: 4.105  loss_ce_3: 0.4062  loss_mask_3: 0.5574  loss_dice_3: 4.102  loss_ce_4: 0.3905  loss_mask_4: 0.5559  loss_dice_4: 4.094  loss_ce_5: 0.3961  loss_mask_5: 0.5589  loss_dice_5: 4.088  loss_ce_6: 0.3979  loss_mask_6: 0.5527  loss_dice_6: 4.094  loss_ce_7: 0.3987  loss_mask_7: 0.5548  loss_dice_7: 4.093  loss_ce_8: 0.3974  loss_mask_8: 0.5542  loss_dice_8: 4.095  time: 1.4206  data_time: 0.0556  lr: 9.2636e-06  max_mem: 21164M
[01/18 19:40:19] d2.utils.events INFO:  eta: 14:19:35  iter: 3279  total_loss: 51.07  loss_ce: 0.4404  loss_mask: 0.5432  loss_dice: 4.088  loss_ce_0: 0.7937  loss_mask_0: 0.529  loss_dice_0: 4.205  loss_ce_1: 0.4579  loss_mask_1: 0.5395  loss_dice_1: 4.133  loss_ce_2: 0.4404  loss_mask_2: 0.5402  loss_dice_2: 4.113  loss_ce_3: 0.4307  loss_mask_3: 0.54  loss_dice_3: 4.105  loss_ce_4: 0.4152  loss_mask_4: 0.5417  loss_dice_4: 4.105  loss_ce_5: 0.412  loss_mask_5: 0.5431  loss_dice_5: 4.105  loss_ce_6: 0.4275  loss_mask_6: 0.5412  loss_dice_6: 4.091  loss_ce_7: 0.4337  loss_mask_7: 0.5439  loss_dice_7: 4.09  loss_ce_8: 0.4422  loss_mask_8: 0.5441  loss_dice_8: 4.093  time: 1.4204  data_time: 0.0590  lr: 9.2591e-06  max_mem: 21164M
[01/18 19:40:47] d2.utils.events INFO:  eta: 14:18:42  iter: 3299  total_loss: 51.22  loss_ce: 0.3933  loss_mask: 0.5442  loss_dice: 4.103  loss_ce_0: 0.8015  loss_mask_0: 0.5186  loss_dice_0: 4.211  loss_ce_1: 0.4174  loss_mask_1: 0.5388  loss_dice_1: 4.138  loss_ce_2: 0.387  loss_mask_2: 0.5418  loss_dice_2: 4.112  loss_ce_3: 0.3936  loss_mask_3: 0.5416  loss_dice_3: 4.105  loss_ce_4: 0.3946  loss_mask_4: 0.5442  loss_dice_4: 4.104  loss_ce_5: 0.4013  loss_mask_5: 0.546  loss_dice_5: 4.107  loss_ce_6: 0.4077  loss_mask_6: 0.5478  loss_dice_6: 4.105  loss_ce_7: 0.4006  loss_mask_7: 0.5421  loss_dice_7: 4.099  loss_ce_8: 0.3998  loss_mask_8: 0.5431  loss_dice_8: 4.102  time: 1.4201  data_time: 0.0552  lr: 9.2546e-06  max_mem: 21164M
[01/18 19:41:15] d2.utils.events INFO:  eta: 14:18:19  iter: 3319  total_loss: 51.62  loss_ce: 0.4515  loss_mask: 0.556  loss_dice: 4.116  loss_ce_0: 0.8046  loss_mask_0: 0.5374  loss_dice_0: 4.209  loss_ce_1: 0.4571  loss_mask_1: 0.5544  loss_dice_1: 4.141  loss_ce_2: 0.4429  loss_mask_2: 0.5592  loss_dice_2: 4.13  loss_ce_3: 0.4385  loss_mask_3: 0.5586  loss_dice_3: 4.117  loss_ce_4: 0.4476  loss_mask_4: 0.555  loss_dice_4: 4.118  loss_ce_5: 0.4398  loss_mask_5: 0.558  loss_dice_5: 4.121  loss_ce_6: 0.4496  loss_mask_6: 0.5551  loss_dice_6: 4.121  loss_ce_7: 0.4547  loss_mask_7: 0.5563  loss_dice_7: 4.114  loss_ce_8: 0.4458  loss_mask_8: 0.5538  loss_dice_8: 4.117  time: 1.4199  data_time: 0.0635  lr: 9.25e-06  max_mem: 21164M
[01/18 19:41:43] d2.utils.events INFO:  eta: 14:17:46  iter: 3339  total_loss: 51.08  loss_ce: 0.4224  loss_mask: 0.5326  loss_dice: 4.104  loss_ce_0: 0.7726  loss_mask_0: 0.5141  loss_dice_0: 4.206  loss_ce_1: 0.4425  loss_mask_1: 0.5328  loss_dice_1: 4.123  loss_ce_2: 0.4105  loss_mask_2: 0.5347  loss_dice_2: 4.111  loss_ce_3: 0.4129  loss_mask_3: 0.5333  loss_dice_3: 4.106  loss_ce_4: 0.4216  loss_mask_4: 0.5362  loss_dice_4: 4.106  loss_ce_5: 0.4154  loss_mask_5: 0.5384  loss_dice_5: 4.097  loss_ce_6: 0.4068  loss_mask_6: 0.5363  loss_dice_6: 4.107  loss_ce_7: 0.4076  loss_mask_7: 0.5338  loss_dice_7: 4.107  loss_ce_8: 0.4189  loss_mask_8: 0.5329  loss_dice_8: 4.101  time: 1.4197  data_time: 0.0667  lr: 9.2455e-06  max_mem: 21164M
[01/18 19:42:10] d2.utils.events INFO:  eta: 14:17:18  iter: 3359  total_loss: 51.16  loss_ce: 0.4465  loss_mask: 0.5519  loss_dice: 4.078  loss_ce_0: 0.7768  loss_mask_0: 0.5293  loss_dice_0: 4.197  loss_ce_1: 0.4492  loss_mask_1: 0.5442  loss_dice_1: 4.112  loss_ce_2: 0.4378  loss_mask_2: 0.5464  loss_dice_2: 4.087  loss_ce_3: 0.4371  loss_mask_3: 0.5489  loss_dice_3: 4.084  loss_ce_4: 0.4344  loss_mask_4: 0.5495  loss_dice_4: 4.078  loss_ce_5: 0.4168  loss_mask_5: 0.5525  loss_dice_5: 4.085  loss_ce_6: 0.4283  loss_mask_6: 0.5487  loss_dice_6: 4.084  loss_ce_7: 0.442  loss_mask_7: 0.5522  loss_dice_7: 4.068  loss_ce_8: 0.4408  loss_mask_8: 0.5515  loss_dice_8: 4.074  time: 1.4194  data_time: 0.0553  lr: 9.2409e-06  max_mem: 21164M
[01/18 19:42:38] d2.utils.events INFO:  eta: 14:16:50  iter: 3379  total_loss: 50.93  loss_ce: 0.4297  loss_mask: 0.5386  loss_dice: 4.084  loss_ce_0: 0.7625  loss_mask_0: 0.5171  loss_dice_0: 4.208  loss_ce_1: 0.4203  loss_mask_1: 0.5289  loss_dice_1: 4.108  loss_ce_2: 0.3938  loss_mask_2: 0.5288  loss_dice_2: 4.1  loss_ce_3: 0.4193  loss_mask_3: 0.5332  loss_dice_3: 4.084  loss_ce_4: 0.4005  loss_mask_4: 0.5387  loss_dice_4: 4.086  loss_ce_5: 0.4146  loss_mask_5: 0.5373  loss_dice_5: 4.079  loss_ce_6: 0.4123  loss_mask_6: 0.5371  loss_dice_6: 4.087  loss_ce_7: 0.4248  loss_mask_7: 0.5377  loss_dice_7: 4.084  loss_ce_8: 0.4178  loss_mask_8: 0.5371  loss_dice_8: 4.087  time: 1.4192  data_time: 0.0623  lr: 9.2364e-06  max_mem: 21164M
[01/18 19:43:05] d2.utils.events INFO:  eta: 14:16:15  iter: 3399  total_loss: 51.18  loss_ce: 0.4195  loss_mask: 0.5443  loss_dice: 4.09  loss_ce_0: 0.8131  loss_mask_0: 0.5206  loss_dice_0: 4.196  loss_ce_1: 0.4458  loss_mask_1: 0.54  loss_dice_1: 4.111  loss_ce_2: 0.4171  loss_mask_2: 0.545  loss_dice_2: 4.094  loss_ce_3: 0.4072  loss_mask_3: 0.5436  loss_dice_3: 4.09  loss_ce_4: 0.4119  loss_mask_4: 0.545  loss_dice_4: 4.084  loss_ce_5: 0.4078  loss_mask_5: 0.547  loss_dice_5: 4.082  loss_ce_6: 0.4053  loss_mask_6: 0.5442  loss_dice_6: 4.082  loss_ce_7: 0.4237  loss_mask_7: 0.546  loss_dice_7: 4.082  loss_ce_8: 0.4107  loss_mask_8: 0.5467  loss_dice_8: 4.084  time: 1.4189  data_time: 0.0570  lr: 9.2319e-06  max_mem: 21164M
[01/18 19:43:33] d2.utils.events INFO:  eta: 14:15:37  iter: 3419  total_loss: 50.62  loss_ce: 0.3809  loss_mask: 0.5568  loss_dice: 4.065  loss_ce_0: 0.7665  loss_mask_0: 0.5286  loss_dice_0: 4.179  loss_ce_1: 0.4038  loss_mask_1: 0.5485  loss_dice_1: 4.105  loss_ce_2: 0.3903  loss_mask_2: 0.5533  loss_dice_2: 4.078  loss_ce_3: 0.3789  loss_mask_3: 0.5535  loss_dice_3: 4.071  loss_ce_4: 0.3822  loss_mask_4: 0.5557  loss_dice_4: 4.077  loss_ce_5: 0.3681  loss_mask_5: 0.5564  loss_dice_5: 4.071  loss_ce_6: 0.3765  loss_mask_6: 0.5563  loss_dice_6: 4.069  loss_ce_7: 0.375  loss_mask_7: 0.5556  loss_dice_7: 4.069  loss_ce_8: 0.3731  loss_mask_8: 0.5551  loss_dice_8: 4.076  time: 1.4187  data_time: 0.0546  lr: 9.2273e-06  max_mem: 21164M
[01/18 19:44:01] d2.utils.events INFO:  eta: 14:16:05  iter: 3439  total_loss: 50.83  loss_ce: 0.4175  loss_mask: 0.5468  loss_dice: 4.066  loss_ce_0: 0.7921  loss_mask_0: 0.5201  loss_dice_0: 4.178  loss_ce_1: 0.4418  loss_mask_1: 0.5338  loss_dice_1: 4.093  loss_ce_2: 0.4033  loss_mask_2: 0.5395  loss_dice_2: 4.079  loss_ce_3: 0.4203  loss_mask_3: 0.5433  loss_dice_3: 4.065  loss_ce_4: 0.4209  loss_mask_4: 0.5453  loss_dice_4: 4.07  loss_ce_5: 0.4117  loss_mask_5: 0.544  loss_dice_5: 4.066  loss_ce_6: 0.4094  loss_mask_6: 0.5449  loss_dice_6: 4.063  loss_ce_7: 0.4177  loss_mask_7: 0.5452  loss_dice_7: 4.062  loss_ce_8: 0.4336  loss_mask_8: 0.5464  loss_dice_8: 4.063  time: 1.4186  data_time: 0.0635  lr: 9.2228e-06  max_mem: 21164M
[01/18 19:44:29] d2.utils.events INFO:  eta: 14:16:28  iter: 3459  total_loss: 51.01  loss_ce: 0.4302  loss_mask: 0.5394  loss_dice: 4.062  loss_ce_0: 0.7942  loss_mask_0: 0.514  loss_dice_0: 4.178  loss_ce_1: 0.4473  loss_mask_1: 0.5315  loss_dice_1: 4.094  loss_ce_2: 0.427  loss_mask_2: 0.5383  loss_dice_2: 4.071  loss_ce_3: 0.4271  loss_mask_3: 0.539  loss_dice_3: 4.071  loss_ce_4: 0.4231  loss_mask_4: 0.5379  loss_dice_4: 4.074  loss_ce_5: 0.4093  loss_mask_5: 0.5398  loss_dice_5: 4.064  loss_ce_6: 0.4347  loss_mask_6: 0.5363  loss_dice_6: 4.063  loss_ce_7: 0.4278  loss_mask_7: 0.5354  loss_dice_7: 4.069  loss_ce_8: 0.426  loss_mask_8: 0.534  loss_dice_8: 4.07  time: 1.4184  data_time: 0.0600  lr: 9.2182e-06  max_mem: 21164M
[01/18 19:44:57] d2.utils.events INFO:  eta: 14:16:43  iter: 3479  total_loss: 51.13  loss_ce: 0.4291  loss_mask: 0.5283  loss_dice: 4.084  loss_ce_0: 0.7862  loss_mask_0: 0.5094  loss_dice_0: 4.189  loss_ce_1: 0.4509  loss_mask_1: 0.531  loss_dice_1: 4.108  loss_ce_2: 0.4459  loss_mask_2: 0.5288  loss_dice_2: 4.098  loss_ce_3: 0.4445  loss_mask_3: 0.5292  loss_dice_3: 4.091  loss_ce_4: 0.4308  loss_mask_4: 0.5294  loss_dice_4: 4.078  loss_ce_5: 0.4137  loss_mask_5: 0.532  loss_dice_5: 4.086  loss_ce_6: 0.4395  loss_mask_6: 0.5312  loss_dice_6: 4.082  loss_ce_7: 0.4288  loss_mask_7: 0.5292  loss_dice_7: 4.077  loss_ce_8: 0.4181  loss_mask_8: 0.53  loss_dice_8: 4.081  time: 1.4183  data_time: 0.0551  lr: 9.2137e-06  max_mem: 21164M
[01/18 19:45:24] d2.utils.events INFO:  eta: 14:13:59  iter: 3499  total_loss: 50.73  loss_ce: 0.4228  loss_mask: 0.5537  loss_dice: 4.054  loss_ce_0: 0.7707  loss_mask_0: 0.5205  loss_dice_0: 4.164  loss_ce_1: 0.4485  loss_mask_1: 0.5372  loss_dice_1: 4.089  loss_ce_2: 0.4255  loss_mask_2: 0.5468  loss_dice_2: 4.07  loss_ce_3: 0.4248  loss_mask_3: 0.5483  loss_dice_3: 4.061  loss_ce_4: 0.4168  loss_mask_4: 0.552  loss_dice_4: 4.059  loss_ce_5: 0.4158  loss_mask_5: 0.5512  loss_dice_5: 4.06  loss_ce_6: 0.4165  loss_mask_6: 0.5513  loss_dice_6: 4.056  loss_ce_7: 0.4354  loss_mask_7: 0.5523  loss_dice_7: 4.056  loss_ce_8: 0.4424  loss_mask_8: 0.5509  loss_dice_8: 4.054  time: 1.4181  data_time: 0.0537  lr: 9.2092e-06  max_mem: 21164M
[01/18 19:45:52] d2.utils.events INFO:  eta: 14:12:07  iter: 3519  total_loss: 50.54  loss_ce: 0.391  loss_mask: 0.5633  loss_dice: 4.058  loss_ce_0: 0.7719  loss_mask_0: 0.5298  loss_dice_0: 4.161  loss_ce_1: 0.4072  loss_mask_1: 0.5577  loss_dice_1: 4.078  loss_ce_2: 0.392  loss_mask_2: 0.5622  loss_dice_2: 4.07  loss_ce_3: 0.3864  loss_mask_3: 0.5695  loss_dice_3: 4.058  loss_ce_4: 0.3893  loss_mask_4: 0.5652  loss_dice_4: 4.056  loss_ce_5: 0.3876  loss_mask_5: 0.5647  loss_dice_5: 4.056  loss_ce_6: 0.3919  loss_mask_6: 0.5621  loss_dice_6: 4.064  loss_ce_7: 0.3986  loss_mask_7: 0.5659  loss_dice_7: 4.058  loss_ce_8: 0.3798  loss_mask_8: 0.566  loss_dice_8: 4.057  time: 1.4178  data_time: 0.0564  lr: 9.2046e-06  max_mem: 21164M
[01/18 19:46:20] d2.utils.events INFO:  eta: 14:10:32  iter: 3539  total_loss: 50.56  loss_ce: 0.4057  loss_mask: 0.5364  loss_dice: 4.078  loss_ce_0: 0.7667  loss_mask_0: 0.515  loss_dice_0: 4.175  loss_ce_1: 0.3974  loss_mask_1: 0.5324  loss_dice_1: 4.101  loss_ce_2: 0.4113  loss_mask_2: 0.5339  loss_dice_2: 4.083  loss_ce_3: 0.3902  loss_mask_3: 0.5331  loss_dice_3: 4.081  loss_ce_4: 0.398  loss_mask_4: 0.5321  loss_dice_4: 4.071  loss_ce_5: 0.4183  loss_mask_5: 0.536  loss_dice_5: 4.075  loss_ce_6: 0.4084  loss_mask_6: 0.5331  loss_dice_6: 4.074  loss_ce_7: 0.3998  loss_mask_7: 0.533  loss_dice_7: 4.073  loss_ce_8: 0.4022  loss_mask_8: 0.5337  loss_dice_8: 4.081  time: 1.4177  data_time: 0.0580  lr: 9.2001e-06  max_mem: 21164M
[01/18 19:46:48] d2.utils.events INFO:  eta: 14:09:25  iter: 3559  total_loss: 51.08  loss_ce: 0.4172  loss_mask: 0.5384  loss_dice: 4.095  loss_ce_0: 0.7395  loss_mask_0: 0.5206  loss_dice_0: 4.18  loss_ce_1: 0.399  loss_mask_1: 0.5351  loss_dice_1: 4.111  loss_ce_2: 0.4037  loss_mask_2: 0.5386  loss_dice_2: 4.097  loss_ce_3: 0.4078  loss_mask_3: 0.5391  loss_dice_3: 4.099  loss_ce_4: 0.4004  loss_mask_4: 0.5406  loss_dice_4: 4.085  loss_ce_5: 0.4043  loss_mask_5: 0.5425  loss_dice_5: 4.084  loss_ce_6: 0.3986  loss_mask_6: 0.5373  loss_dice_6: 4.081  loss_ce_7: 0.4123  loss_mask_7: 0.5397  loss_dice_7: 4.085  loss_ce_8: 0.4001  loss_mask_8: 0.5366  loss_dice_8: 4.089  time: 1.4176  data_time: 0.0626  lr: 9.1955e-06  max_mem: 21164M
[01/18 19:47:15] d2.utils.events INFO:  eta: 14:07:42  iter: 3579  total_loss: 50.58  loss_ce: 0.4099  loss_mask: 0.5472  loss_dice: 4.064  loss_ce_0: 0.7545  loss_mask_0: 0.5256  loss_dice_0: 4.174  loss_ce_1: 0.4368  loss_mask_1: 0.5439  loss_dice_1: 4.078  loss_ce_2: 0.4273  loss_mask_2: 0.544  loss_dice_2: 4.075  loss_ce_3: 0.4081  loss_mask_3: 0.5472  loss_dice_3: 4.072  loss_ce_4: 0.4093  loss_mask_4: 0.5465  loss_dice_4: 4.061  loss_ce_5: 0.4214  loss_mask_5: 0.5491  loss_dice_5: 4.067  loss_ce_6: 0.4149  loss_mask_6: 0.5467  loss_dice_6: 4.068  loss_ce_7: 0.4004  loss_mask_7: 0.5459  loss_dice_7: 4.057  loss_ce_8: 0.4145  loss_mask_8: 0.5478  loss_dice_8: 4.059  time: 1.4174  data_time: 0.0531  lr: 9.191e-06  max_mem: 21164M
[01/18 19:47:43] d2.utils.events INFO:  eta: 14:06:00  iter: 3599  total_loss: 50.69  loss_ce: 0.4205  loss_mask: 0.5393  loss_dice: 4.057  loss_ce_0: 0.7828  loss_mask_0: 0.5162  loss_dice_0: 4.171  loss_ce_1: 0.4333  loss_mask_1: 0.5363  loss_dice_1: 4.088  loss_ce_2: 0.4325  loss_mask_2: 0.5352  loss_dice_2: 4.063  loss_ce_3: 0.4168  loss_mask_3: 0.5356  loss_dice_3: 4.063  loss_ce_4: 0.4283  loss_mask_4: 0.5365  loss_dice_4: 4.064  loss_ce_5: 0.416  loss_mask_5: 0.5396  loss_dice_5: 4.055  loss_ce_6: 0.418  loss_mask_6: 0.5378  loss_dice_6: 4.053  loss_ce_7: 0.4197  loss_mask_7: 0.5391  loss_dice_7: 4.058  loss_ce_8: 0.4266  loss_mask_8: 0.5413  loss_dice_8: 4.055  time: 1.4172  data_time: 0.0620  lr: 9.1865e-06  max_mem: 21164M
[01/18 19:48:11] d2.utils.events INFO:  eta: 14:04:49  iter: 3619  total_loss: 50.88  loss_ce: 0.4285  loss_mask: 0.5434  loss_dice: 4.06  loss_ce_0: 0.7606  loss_mask_0: 0.5141  loss_dice_0: 4.178  loss_ce_1: 0.4459  loss_mask_1: 0.5318  loss_dice_1: 4.091  loss_ce_2: 0.4275  loss_mask_2: 0.539  loss_dice_2: 4.079  loss_ce_3: 0.4451  loss_mask_3: 0.5406  loss_dice_3: 4.065  loss_ce_4: 0.4429  loss_mask_4: 0.5421  loss_dice_4: 4.059  loss_ce_5: 0.4239  loss_mask_5: 0.5433  loss_dice_5: 4.056  loss_ce_6: 0.408  loss_mask_6: 0.5415  loss_dice_6: 4.059  loss_ce_7: 0.4203  loss_mask_7: 0.5414  loss_dice_7: 4.064  loss_ce_8: 0.4163  loss_mask_8: 0.5426  loss_dice_8: 4.063  time: 1.4171  data_time: 0.0523  lr: 9.1819e-06  max_mem: 21164M
[01/18 19:48:39] d2.utils.events INFO:  eta: 14:02:48  iter: 3639  total_loss: 50.51  loss_ce: 0.4191  loss_mask: 0.5447  loss_dice: 4.05  loss_ce_0: 0.7184  loss_mask_0: 0.5243  loss_dice_0: 4.155  loss_ce_1: 0.417  loss_mask_1: 0.5367  loss_dice_1: 4.073  loss_ce_2: 0.4166  loss_mask_2: 0.5397  loss_dice_2: 4.058  loss_ce_3: 0.4284  loss_mask_3: 0.5409  loss_dice_3: 4.049  loss_ce_4: 0.4018  loss_mask_4: 0.5444  loss_dice_4: 4.053  loss_ce_5: 0.4387  loss_mask_5: 0.5462  loss_dice_5: 4.042  loss_ce_6: 0.4295  loss_mask_6: 0.5427  loss_dice_6: 4.042  loss_ce_7: 0.4184  loss_mask_7: 0.5427  loss_dice_7: 4.038  loss_ce_8: 0.4222  loss_mask_8: 0.5442  loss_dice_8: 4.041  time: 1.4169  data_time: 0.0641  lr: 9.1774e-06  max_mem: 21164M
[01/18 19:49:07] d2.utils.events INFO:  eta: 14:01:38  iter: 3659  total_loss: 50.51  loss_ce: 0.4114  loss_mask: 0.5365  loss_dice: 4.026  loss_ce_0: 0.7442  loss_mask_0: 0.5144  loss_dice_0: 4.142  loss_ce_1: 0.4383  loss_mask_1: 0.5335  loss_dice_1: 4.064  loss_ce_2: 0.416  loss_mask_2: 0.5382  loss_dice_2: 4.039  loss_ce_3: 0.4151  loss_mask_3: 0.5376  loss_dice_3: 4.045  loss_ce_4: 0.4146  loss_mask_4: 0.5363  loss_dice_4: 4.035  loss_ce_5: 0.4157  loss_mask_5: 0.5355  loss_dice_5: 4.036  loss_ce_6: 0.4211  loss_mask_6: 0.5348  loss_dice_6: 4.033  loss_ce_7: 0.4257  loss_mask_7: 0.5336  loss_dice_7: 4.031  loss_ce_8: 0.4162  loss_mask_8: 0.5355  loss_dice_8: 4.027  time: 1.4168  data_time: 0.0562  lr: 9.1728e-06  max_mem: 21164M
[01/18 19:49:34] d2.utils.events INFO:  eta: 14:00:18  iter: 3679  total_loss: 50.32  loss_ce: 0.4511  loss_mask: 0.547  loss_dice: 4.019  loss_ce_0: 0.7516  loss_mask_0: 0.5271  loss_dice_0: 4.136  loss_ce_1: 0.433  loss_mask_1: 0.5447  loss_dice_1: 4.051  loss_ce_2: 0.4432  loss_mask_2: 0.5463  loss_dice_2: 4.036  loss_ce_3: 0.4257  loss_mask_3: 0.5466  loss_dice_3: 4.018  loss_ce_4: 0.4472  loss_mask_4: 0.5463  loss_dice_4: 4.019  loss_ce_5: 0.4391  loss_mask_5: 0.5497  loss_dice_5: 4.022  loss_ce_6: 0.4422  loss_mask_6: 0.5491  loss_dice_6: 4.02  loss_ce_7: 0.4316  loss_mask_7: 0.5493  loss_dice_7: 4.015  loss_ce_8: 0.4329  loss_mask_8: 0.549  loss_dice_8: 4.022  time: 1.4165  data_time: 0.0609  lr: 9.1683e-06  max_mem: 21164M
[01/18 19:50:02] d2.utils.events INFO:  eta: 13:59:12  iter: 3699  total_loss: 50.78  loss_ce: 0.4046  loss_mask: 0.5504  loss_dice: 4.043  loss_ce_0: 0.7423  loss_mask_0: 0.5233  loss_dice_0: 4.161  loss_ce_1: 0.4236  loss_mask_1: 0.5467  loss_dice_1: 4.081  loss_ce_2: 0.4173  loss_mask_2: 0.5471  loss_dice_2: 4.055  loss_ce_3: 0.4147  loss_mask_3: 0.5515  loss_dice_3: 4.047  loss_ce_4: 0.4437  loss_mask_4: 0.5545  loss_dice_4: 4.041  loss_ce_5: 0.4136  loss_mask_5: 0.55  loss_dice_5: 4.042  loss_ce_6: 0.4098  loss_mask_6: 0.5486  loss_dice_6: 4.047  loss_ce_7: 0.4344  loss_mask_7: 0.55  loss_dice_7: 4.041  loss_ce_8: 0.4194  loss_mask_8: 0.5528  loss_dice_8: 4.042  time: 1.4163  data_time: 0.0538  lr: 9.1637e-06  max_mem: 21164M
[01/18 19:50:30] d2.utils.events INFO:  eta: 13:57:51  iter: 3719  total_loss: 50.6  loss_ce: 0.4408  loss_mask: 0.543  loss_dice: 4.034  loss_ce_0: 0.747  loss_mask_0: 0.5189  loss_dice_0: 4.143  loss_ce_1: 0.4278  loss_mask_1: 0.5367  loss_dice_1: 4.059  loss_ce_2: 0.4319  loss_mask_2: 0.5392  loss_dice_2: 4.054  loss_ce_3: 0.4302  loss_mask_3: 0.5445  loss_dice_3: 4.053  loss_ce_4: 0.4297  loss_mask_4: 0.5455  loss_dice_4: 4.037  loss_ce_5: 0.442  loss_mask_5: 0.5463  loss_dice_5: 4.041  loss_ce_6: 0.4578  loss_mask_6: 0.5448  loss_dice_6: 4.038  loss_ce_7: 0.4332  loss_mask_7: 0.5433  loss_dice_7: 4.041  loss_ce_8: 0.4378  loss_mask_8: 0.5436  loss_dice_8: 4.041  time: 1.4161  data_time: 0.0562  lr: 9.1592e-06  max_mem: 21164M
[01/18 19:50:58] d2.utils.events INFO:  eta: 13:56:42  iter: 3739  total_loss: 50.64  loss_ce: 0.4279  loss_mask: 0.5417  loss_dice: 4.03  loss_ce_0: 0.7578  loss_mask_0: 0.5219  loss_dice_0: 4.137  loss_ce_1: 0.445  loss_mask_1: 0.5387  loss_dice_1: 4.07  loss_ce_2: 0.4434  loss_mask_2: 0.5407  loss_dice_2: 4.038  loss_ce_3: 0.4364  loss_mask_3: 0.5397  loss_dice_3: 4.035  loss_ce_4: 0.4322  loss_mask_4: 0.5382  loss_dice_4: 4.034  loss_ce_5: 0.4393  loss_mask_5: 0.5423  loss_dice_5: 4.024  loss_ce_6: 0.4404  loss_mask_6: 0.5392  loss_dice_6: 4.026  loss_ce_7: 0.4345  loss_mask_7: 0.5406  loss_dice_7: 4.026  loss_ce_8: 0.4297  loss_mask_8: 0.5412  loss_dice_8: 4.026  time: 1.4160  data_time: 0.0652  lr: 9.1547e-06  max_mem: 21164M
[01/18 19:51:26] d2.utils.events INFO:  eta: 13:55:42  iter: 3759  total_loss: 50.4  loss_ce: 0.4016  loss_mask: 0.5481  loss_dice: 4.058  loss_ce_0: 0.7283  loss_mask_0: 0.5184  loss_dice_0: 4.162  loss_ce_1: 0.4157  loss_mask_1: 0.5423  loss_dice_1: 4.088  loss_ce_2: 0.4059  loss_mask_2: 0.5457  loss_dice_2: 4.068  loss_ce_3: 0.4067  loss_mask_3: 0.5471  loss_dice_3: 4.053  loss_ce_4: 0.3981  loss_mask_4: 0.5471  loss_dice_4: 4.054  loss_ce_5: 0.3885  loss_mask_5: 0.5482  loss_dice_5: 4.054  loss_ce_6: 0.3923  loss_mask_6: 0.5473  loss_dice_6: 4.056  loss_ce_7: 0.4039  loss_mask_7: 0.5481  loss_dice_7: 4.056  loss_ce_8: 0.4004  loss_mask_8: 0.5472  loss_dice_8: 4.06  time: 1.4159  data_time: 0.0635  lr: 9.1501e-06  max_mem: 21164M
[01/18 19:51:53] d2.utils.events INFO:  eta: 13:54:45  iter: 3779  total_loss: 50.4  loss_ce: 0.4151  loss_mask: 0.5451  loss_dice: 4.038  loss_ce_0: 0.738  loss_mask_0: 0.5208  loss_dice_0: 4.133  loss_ce_1: 0.4023  loss_mask_1: 0.5423  loss_dice_1: 4.056  loss_ce_2: 0.4187  loss_mask_2: 0.5445  loss_dice_2: 4.039  loss_ce_3: 0.4049  loss_mask_3: 0.5445  loss_dice_3: 4.042  loss_ce_4: 0.4039  loss_mask_4: 0.5434  loss_dice_4: 4.044  loss_ce_5: 0.4176  loss_mask_5: 0.5456  loss_dice_5: 4.04  loss_ce_6: 0.417  loss_mask_6: 0.5465  loss_dice_6: 4.033  loss_ce_7: 0.4151  loss_mask_7: 0.5459  loss_dice_7: 4.028  loss_ce_8: 0.4139  loss_mask_8: 0.5466  loss_dice_8: 4.038  time: 1.4158  data_time: 0.0649  lr: 9.1456e-06  max_mem: 21164M
[01/18 19:52:21] d2.utils.events INFO:  eta: 13:54:17  iter: 3799  total_loss: 49.94  loss_ce: 0.4122  loss_mask: 0.5388  loss_dice: 4.008  loss_ce_0: 0.7654  loss_mask_0: 0.5125  loss_dice_0: 4.131  loss_ce_1: 0.4371  loss_mask_1: 0.534  loss_dice_1: 4.04  loss_ce_2: 0.4069  loss_mask_2: 0.5307  loss_dice_2: 4.018  loss_ce_3: 0.4019  loss_mask_3: 0.5334  loss_dice_3: 4.019  loss_ce_4: 0.4196  loss_mask_4: 0.5327  loss_dice_4: 4.008  loss_ce_5: 0.412  loss_mask_5: 0.5373  loss_dice_5: 4.017  loss_ce_6: 0.4102  loss_mask_6: 0.5368  loss_dice_6: 4.009  loss_ce_7: 0.4149  loss_mask_7: 0.5365  loss_dice_7: 4.01  loss_ce_8: 0.4203  loss_mask_8: 0.5396  loss_dice_8: 4.007  time: 1.4156  data_time: 0.0561  lr: 9.141e-06  max_mem: 21164M
[01/18 19:52:49] d2.utils.events INFO:  eta: 13:53:58  iter: 3819  total_loss: 50.07  loss_ce: 0.3957  loss_mask: 0.5386  loss_dice: 4.005  loss_ce_0: 0.7242  loss_mask_0: 0.5064  loss_dice_0: 4.131  loss_ce_1: 0.428  loss_mask_1: 0.5311  loss_dice_1: 4.046  loss_ce_2: 0.4005  loss_mask_2: 0.5357  loss_dice_2: 4.018  loss_ce_3: 0.3876  loss_mask_3: 0.5397  loss_dice_3: 4.018  loss_ce_4: 0.3939  loss_mask_4: 0.538  loss_dice_4: 4.017  loss_ce_5: 0.3877  loss_mask_5: 0.5358  loss_dice_5: 4.009  loss_ce_6: 0.3867  loss_mask_6: 0.5363  loss_dice_6: 4.003  loss_ce_7: 0.3945  loss_mask_7: 0.5375  loss_dice_7: 4.007  loss_ce_8: 0.3855  loss_mask_8: 0.5392  loss_dice_8: 4.013  time: 1.4155  data_time: 0.0620  lr: 9.1365e-06  max_mem: 21164M
[01/18 19:53:17] d2.utils.events INFO:  eta: 13:53:11  iter: 3839  total_loss: 50.58  loss_ce: 0.4177  loss_mask: 0.5601  loss_dice: 4.019  loss_ce_0: 0.7667  loss_mask_0: 0.5342  loss_dice_0: 4.131  loss_ce_1: 0.4323  loss_mask_1: 0.5567  loss_dice_1: 4.05  loss_ce_2: 0.4116  loss_mask_2: 0.5639  loss_dice_2: 4.032  loss_ce_3: 0.4051  loss_mask_3: 0.5607  loss_dice_3: 4.022  loss_ce_4: 0.4195  loss_mask_4: 0.5562  loss_dice_4: 4.021  loss_ce_5: 0.4089  loss_mask_5: 0.5602  loss_dice_5: 4.018  loss_ce_6: 0.4244  loss_mask_6: 0.5627  loss_dice_6: 4.013  loss_ce_7: 0.4151  loss_mask_7: 0.5585  loss_dice_7: 4.021  loss_ce_8: 0.4191  loss_mask_8: 0.5597  loss_dice_8: 4.017  time: 1.4153  data_time: 0.0561  lr: 9.1319e-06  max_mem: 21164M
[01/18 19:53:45] d2.utils.events INFO:  eta: 13:52:58  iter: 3859  total_loss: 50.87  loss_ce: 0.4157  loss_mask: 0.5435  loss_dice: 4.089  loss_ce_0: 0.7601  loss_mask_0: 0.52  loss_dice_0: 4.184  loss_ce_1: 0.4404  loss_mask_1: 0.5429  loss_dice_1: 4.111  loss_ce_2: 0.4146  loss_mask_2: 0.5424  loss_dice_2: 4.099  loss_ce_3: 0.4164  loss_mask_3: 0.5424  loss_dice_3: 4.088  loss_ce_4: 0.4067  loss_mask_4: 0.5389  loss_dice_4: 4.089  loss_ce_5: 0.4183  loss_mask_5: 0.5423  loss_dice_5: 4.084  loss_ce_6: 0.4209  loss_mask_6: 0.5414  loss_dice_6: 4.086  loss_ce_7: 0.4083  loss_mask_7: 0.5387  loss_dice_7: 4.094  loss_ce_8: 0.4258  loss_mask_8: 0.5414  loss_dice_8: 4.086  time: 1.4152  data_time: 0.0586  lr: 9.1274e-06  max_mem: 21164M
[01/18 19:54:13] d2.utils.events INFO:  eta: 13:52:24  iter: 3879  total_loss: 50.28  loss_ce: 0.426  loss_mask: 0.5307  loss_dice: 4.033  loss_ce_0: 0.7416  loss_mask_0: 0.5115  loss_dice_0: 4.145  loss_ce_1: 0.4514  loss_mask_1: 0.5312  loss_dice_1: 4.073  loss_ce_2: 0.4404  loss_mask_2: 0.5323  loss_dice_2: 4.045  loss_ce_3: 0.4304  loss_mask_3: 0.5324  loss_dice_3: 4.032  loss_ce_4: 0.4233  loss_mask_4: 0.5291  loss_dice_4: 4.04  loss_ce_5: 0.4224  loss_mask_5: 0.5303  loss_dice_5: 4.034  loss_ce_6: 0.4092  loss_mask_6: 0.5336  loss_dice_6: 4.034  loss_ce_7: 0.4029  loss_mask_7: 0.5289  loss_dice_7: 4.034  loss_ce_8: 0.4057  loss_mask_8: 0.5305  loss_dice_8: 4.034  time: 1.4151  data_time: 0.0646  lr: 9.1228e-06  max_mem: 21164M
[01/18 19:54:41] d2.utils.events INFO:  eta: 13:52:29  iter: 3899  total_loss: 50.55  loss_ce: 0.4214  loss_mask: 0.5254  loss_dice: 4.03  loss_ce_0: 0.733  loss_mask_0: 0.507  loss_dice_0: 4.133  loss_ce_1: 0.4336  loss_mask_1: 0.5283  loss_dice_1: 4.055  loss_ce_2: 0.4052  loss_mask_2: 0.525  loss_dice_2: 4.033  loss_ce_3: 0.4207  loss_mask_3: 0.5245  loss_dice_3: 4.027  loss_ce_4: 0.4166  loss_mask_4: 0.5257  loss_dice_4: 4.028  loss_ce_5: 0.4091  loss_mask_5: 0.5284  loss_dice_5: 4.029  loss_ce_6: 0.4211  loss_mask_6: 0.5262  loss_dice_6: 4.04  loss_ce_7: 0.4107  loss_mask_7: 0.5234  loss_dice_7: 4.028  loss_ce_8: 0.4226  loss_mask_8: 0.5284  loss_dice_8: 4.03  time: 1.4150  data_time: 0.0604  lr: 9.1183e-06  max_mem: 21164M
[01/18 19:55:09] d2.utils.events INFO:  eta: 13:52:10  iter: 3919  total_loss: 50.35  loss_ce: 0.4448  loss_mask: 0.514  loss_dice: 4.01  loss_ce_0: 0.7453  loss_mask_0: 0.4963  loss_dice_0: 4.138  loss_ce_1: 0.455  loss_mask_1: 0.5095  loss_dice_1: 4.057  loss_ce_2: 0.4428  loss_mask_2: 0.5136  loss_dice_2: 4.023  loss_ce_3: 0.4328  loss_mask_3: 0.5132  loss_dice_3: 4.011  loss_ce_4: 0.4386  loss_mask_4: 0.516  loss_dice_4: 4.016  loss_ce_5: 0.4228  loss_mask_5: 0.5198  loss_dice_5: 4.012  loss_ce_6: 0.4491  loss_mask_6: 0.5183  loss_dice_6: 4.001  loss_ce_7: 0.4506  loss_mask_7: 0.5177  loss_dice_7: 4.011  loss_ce_8: 0.4442  loss_mask_8: 0.5164  loss_dice_8: 4.006  time: 1.4150  data_time: 0.0635  lr: 9.1137e-06  max_mem: 21164M
[01/18 19:55:37] d2.utils.events INFO:  eta: 13:52:00  iter: 3939  total_loss: 49.89  loss_ce: 0.4242  loss_mask: 0.5414  loss_dice: 3.979  loss_ce_0: 0.7583  loss_mask_0: 0.5092  loss_dice_0: 4.085  loss_ce_1: 0.4262  loss_mask_1: 0.5375  loss_dice_1: 4.005  loss_ce_2: 0.4295  loss_mask_2: 0.5377  loss_dice_2: 3.985  loss_ce_3: 0.4143  loss_mask_3: 0.5411  loss_dice_3: 3.978  loss_ce_4: 0.4368  loss_mask_4: 0.5372  loss_dice_4: 3.974  loss_ce_5: 0.4159  loss_mask_5: 0.5376  loss_dice_5: 3.967  loss_ce_6: 0.4166  loss_mask_6: 0.5411  loss_dice_6: 3.966  loss_ce_7: 0.4306  loss_mask_7: 0.5376  loss_dice_7: 3.975  loss_ce_8: 0.4295  loss_mask_8: 0.54  loss_dice_8: 3.969  time: 1.4148  data_time: 0.0569  lr: 9.1092e-06  max_mem: 21164M
[01/18 19:56:04] d2.utils.events INFO:  eta: 13:51:32  iter: 3959  total_loss: 50.28  loss_ce: 0.429  loss_mask: 0.5513  loss_dice: 3.999  loss_ce_0: 0.7317  loss_mask_0: 0.5292  loss_dice_0: 4.112  loss_ce_1: 0.4581  loss_mask_1: 0.5479  loss_dice_1: 4.028  loss_ce_2: 0.4421  loss_mask_2: 0.5518  loss_dice_2: 4.014  loss_ce_3: 0.4346  loss_mask_3: 0.5493  loss_dice_3: 4.003  loss_ce_4: 0.4177  loss_mask_4: 0.553  loss_dice_4: 4  loss_ce_5: 0.4297  loss_mask_5: 0.556  loss_dice_5: 4  loss_ce_6: 0.4232  loss_mask_6: 0.5519  loss_dice_6: 4  loss_ce_7: 0.4295  loss_mask_7: 0.5536  loss_dice_7: 3.991  loss_ce_8: 0.4429  loss_mask_8: 0.5524  loss_dice_8: 3.99  time: 1.4147  data_time: 0.0581  lr: 9.1046e-06  max_mem: 21164M
[01/18 19:56:32] d2.utils.events INFO:  eta: 13:51:10  iter: 3979  total_loss: 49.78  loss_ce: 0.4008  loss_mask: 0.5403  loss_dice: 4  loss_ce_0: 0.7443  loss_mask_0: 0.5137  loss_dice_0: 4.112  loss_ce_1: 0.4131  loss_mask_1: 0.5334  loss_dice_1: 4.027  loss_ce_2: 0.4079  loss_mask_2: 0.5407  loss_dice_2: 4.011  loss_ce_3: 0.4068  loss_mask_3: 0.5435  loss_dice_3: 4  loss_ce_4: 0.3956  loss_mask_4: 0.5413  loss_dice_4: 3.991  loss_ce_5: 0.3986  loss_mask_5: 0.5405  loss_dice_5: 3.995  loss_ce_6: 0.4038  loss_mask_6: 0.5394  loss_dice_6: 3.993  loss_ce_7: 0.4104  loss_mask_7: 0.5387  loss_dice_7: 3.993  loss_ce_8: 0.3968  loss_mask_8: 0.541  loss_dice_8: 3.994  time: 1.4145  data_time: 0.0596  lr: 9.1001e-06  max_mem: 21164M
[01/18 19:57:00] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 19:57:01] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 19:57:01] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 20:02:52] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.9056732712017306, 'error_1pix': 0.44176204717590717, 'error_3pix': 0.19463902840803146, 'mIoU': 6.9239840839765, 'fwIoU': 19.401897063338225, 'IoU-0': nan, 'IoU-1': 94.43307520879604, 'IoU-2': 36.5473814843251, 'IoU-3': 34.64959251852547, 'IoU-4': 21.192107028301766, 'IoU-5': 18.263704536730156, 'IoU-6': 16.107289621647816, 'IoU-7': 16.126239290343214, 'IoU-8': 2.8649980827112067, 'IoU-9': 4.0277746706131445, 'IoU-10': 3.1669944042152136, 'IoU-11': 19.741559262456583, 'IoU-12': 16.711981238566523, 'IoU-13': 13.62309547202352, 'IoU-14': 12.582219298671443, 'IoU-15': 12.07475544881664, 'IoU-16': 10.241406441785204, 'IoU-17': 9.032424826349304, 'IoU-18': 12.790916963964472, 'IoU-19': 5.767645229002478, 'IoU-20': 5.491763990328953, 'IoU-21': 12.490701069622903, 'IoU-22': 6.698505616121825, 'IoU-23': 7.6934401130608885, 'IoU-24': 11.10824473315114, 'IoU-25': 11.161096517711892, 'IoU-26': 11.748935678229003, 'IoU-27': 10.133421897132614, 'IoU-28': 14.954250685767025, 'IoU-29': 10.492383973886984, 'IoU-30': 11.84580093802333, 'IoU-31': 13.708681285945659, 'IoU-32': 15.606860496002465, 'IoU-33': 12.660291991240669, 'IoU-34': 14.201157336025878, 'IoU-35': 10.605547039885524, 'IoU-36': 15.942218203091214, 'IoU-37': 13.334259124249625, 'IoU-38': 15.3364262718434, 'IoU-39': 8.605718855718699, 'IoU-40': 15.459858847837701, 'IoU-41': 13.53132137823627, 'IoU-42': 13.025556090921652, 'IoU-43': 10.310808682440808, 'IoU-44': 12.552141261853086, 'IoU-45': 13.566912342060489, 'IoU-46': 12.314326188835857, 'IoU-47': 10.59819464275336, 'IoU-48': 12.48956040280448, 'IoU-49': 9.721810942208545, 'IoU-50': 13.710576315986955, 'IoU-51': 11.646649707598867, 'IoU-52': 12.750211407813996, 'IoU-53': 9.320142212161162, 'IoU-54': 11.855052228045727, 'IoU-55': 11.368548583770595, 'IoU-56': 9.35130547778951, 'IoU-57': 12.717961604378353, 'IoU-58': 11.680156956844504, 'IoU-59': 13.783215932647572, 'IoU-60': 10.571551245440563, 'IoU-61': 11.335412860292388, 'IoU-62': 4.343706898515664, 'IoU-63': 13.5043681837068, 'IoU-64': 11.512917137449135, 'IoU-65': 5.211436093992964, 'IoU-66': 8.557082357555661, 'IoU-67': 11.487117650761462, 'IoU-68': 5.8526402016760075, 'IoU-69': 12.26246114821429, 'IoU-70': 10.585627938470168, 'IoU-71': 8.397788237373833, 'IoU-72': 7.529810157838068, 'IoU-73': 10.897876744433264, 'IoU-74': 5.8427869418899325, 'IoU-75': 10.082821320918173, 'IoU-76': 6.834532294967367, 'IoU-77': 7.4370700025994205, 'IoU-78': 9.863326169619956, 'IoU-79': 6.775068762523491, 'IoU-80': 10.537077093548854, 'IoU-81': 4.380033673202113, 'IoU-82': 8.337873348879382, 'IoU-83': 6.113265119921848, 'IoU-84': 5.1961966121456005, 'IoU-85': 8.23166823513455, 'IoU-86': 8.249481596300742, 'IoU-87': 3.808065157274094, 'IoU-88': 8.137710544559974, 'IoU-89': 5.98045383515167, 'IoU-90': 3.637206226163541, 'IoU-91': 8.06196221831937, 'IoU-92': 9.003015879228334, 'IoU-93': 3.790199677846559, 'IoU-94': 2.7259797454814167, 'IoU-95': 9.754659588150474, 'IoU-96': 6.293005275791414, 'IoU-97': 6.181492128376341, 'IoU-98': 4.855113236812966, 'IoU-99': 9.499549375885932, 'IoU-100': 4.394681465867704, 'IoU-101': 6.326659874379841, 'IoU-102': 5.060490340690374, 'IoU-103': 6.99679191181089, 'IoU-104': 7.3371359025883, 'IoU-105': 4.006319094560658, 'IoU-106': 2.7227979289229123, 'IoU-107': 6.3003076879044775, 'IoU-108': 6.151677415470703, 'IoU-109': 5.454800097103696, 'IoU-110': 7.2984678101041425, 'IoU-111': 1.401464496714606, 'IoU-112': 1.505197502716093, 'IoU-113': 6.126273507573685, 'IoU-114': 3.891025402385526, 'IoU-115': 5.191481710736857, 'IoU-116': 6.0561581960354065, 'IoU-117': 4.411858841823392, 'IoU-118': 2.8788501290330863, 'IoU-119': 3.8058025958079424, 'IoU-120': 2.247271155359162, 'IoU-121': 3.9084803916781414, 'IoU-122': 2.7151026161204244, 'IoU-123': 2.921857248535139, 'IoU-124': 3.473465027184823, 'IoU-125': 3.688753675635026, 'IoU-126': 1.2337647404132013, 'IoU-127': 3.226218842507765, 'IoU-128': 0.9189036851928128, 'IoU-129': 2.4819056472841576, 'IoU-130': 1.5278517346015814, 'IoU-131': 2.2899405362388157, 'IoU-132': 2.9893222799261734, 'IoU-133': 2.1488370754909987, 'IoU-134': 2.6934338468668813, 'IoU-135': 2.803669246469064, 'IoU-136': 3.2753783517858217, 'IoU-137': 1.9068747710049934, 'IoU-138': 1.2999177836769922, 'IoU-139': 2.640613655974061, 'IoU-140': 0.23100786996945272, 'IoU-141': 1.4412178002955662, 'IoU-142': 1.4459883507867284, 'IoU-143': 2.0530635953282843, 'IoU-144': 1.7756544523001214, 'IoU-145': 1.1332601726519043, 'IoU-146': 1.7472078327852372, 'IoU-147': 2.799654493947127, 'IoU-148': 1.1620058749625441, 'IoU-149': 0.911641557399249, 'IoU-150': 2.317968249268643, 'IoU-151': 0.340433724817531, 'IoU-152': 0.18152653981671799, 'IoU-153': 0.5095751404752163, 'IoU-154': 1.741096877865812, 'IoU-155': 1.568817587923468, 'IoU-156': 1.878728124143256, 'IoU-157': 0.5231386689468841, 'IoU-158': 0.7197943444730077, 'IoU-159': 0.0199961415895806, 'IoU-160': 0.0, 'IoU-161': 0.9103051772699556, 'IoU-162': 0.0, 'IoU-163': 1.1274006138794095, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 1.7302180577711996, 'IoU-167': 1.1673124053001414, 'IoU-168': 1.713800375299463, 'IoU-169': 0.0, 'IoU-170': 0.39924242161617496, 'IoU-171': 0.07989620322316307, 'IoU-172': 0.01514681460663905, 'IoU-173': 0.0, 'IoU-174': 0.11949290737829794, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.002228647028909604, 'IoU-180': 0.15243286080494253, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.016629125156842884, 'IoU-189': 1.2502254199028673, 'IoU-190': 1.1869719312185036, 'IoU-191': 0.14347057082056563, 'IoU-192': 0.0, 'mACC': 12.398175375807474, 'pACC': 27.781672328783824, 'ACC-0': nan, 'ACC-1': 98.12591972081493, 'ACC-2': 46.89343412380039, 'ACC-3': 48.18556167403426, 'ACC-4': 33.42733430150307, 'ACC-5': 31.9864655649948, 'ACC-6': 28.087203817624605, 'ACC-7': 27.946479684668425, 'ACC-8': 3.2729380490291113, 'ACC-9': 4.476534117619442, 'ACC-10': 3.5285793192532457, 'ACC-11': 32.621513084929845, 'ACC-12': 28.775216799917665, 'ACC-13': 24.763917646268478, 'ACC-14': 24.194380946936782, 'ACC-15': 22.263677195294335, 'ACC-16': 20.627968044120646, 'ACC-17': 17.731664725061705, 'ACC-18': 23.32084567834262, 'ACC-19': 7.765262665277523, 'ACC-20': 7.683510504648808, 'ACC-21': 29.114097385121596, 'ACC-22': 9.621236290268753, 'ACC-23': 16.462144757925834, 'ACC-24': 23.20726489083952, 'ACC-25': 20.470880914541123, 'ACC-26': 21.424572345638843, 'ACC-27': 17.850751688801033, 'ACC-28': 30.133189982754878, 'ACC-29': 18.25585445929599, 'ACC-30': 21.7875506998179, 'ACC-31': 24.61700575037495, 'ACC-32': 28.18884066081336, 'ACC-33': 20.792065462737508, 'ACC-34': 29.496699071219982, 'ACC-35': 18.15964343964269, 'ACC-36': 29.301242896411633, 'ACC-37': 22.774507147161206, 'ACC-38': 35.24576064433091, 'ACC-39': 12.552322678959202, 'ACC-40': 26.300504296048434, 'ACC-41': 28.374392102814404, 'ACC-42': 23.735930176279844, 'ACC-43': 17.43234917314008, 'ACC-44': 25.138632513882968, 'ACC-45': 23.21896204707901, 'ACC-46': 19.75877004368304, 'ACC-47': 18.806949344597292, 'ACC-48': 21.9872839957749, 'ACC-49': 14.182968074259495, 'ACC-50': 23.911064297481758, 'ACC-51': 18.638889659807635, 'ACC-52': 21.11549814263944, 'ACC-53': 14.56464405791849, 'ACC-54': 19.234660656316606, 'ACC-55': 24.738009207268153, 'ACC-56': 13.746934615428138, 'ACC-57': 21.858688692874427, 'ACC-58': 22.146352708181468, 'ACC-59': 27.352916519186472, 'ACC-60': 20.211215929438815, 'ACC-61': 20.847211686396854, 'ACC-62': 5.981203948341527, 'ACC-63': 27.739638347447936, 'ACC-64': 22.40877305474867, 'ACC-65': 7.249030237594881, 'ACC-66': 13.057581854032104, 'ACC-67': 31.68540904573101, 'ACC-68': 8.653524094900684, 'ACC-69': 25.6798748527572, 'ACC-70': 17.604385046717887, 'ACC-71': 14.351838324677063, 'ACC-72': 12.718106066477972, 'ACC-73': 21.86205149986586, 'ACC-74': 9.090064395590247, 'ACC-75': 20.274466851362668, 'ACC-76': 9.870765780478267, 'ACC-77': 13.601471419473537, 'ACC-78': 18.982466508406702, 'ACC-79': 12.12657464530766, 'ACC-80': 20.567283971845903, 'ACC-81': 5.667837835741598, 'ACC-82': 17.398310391857404, 'ACC-83': 9.090292917847467, 'ACC-84': 8.018883492629532, 'ACC-85': 18.808814904412543, 'ACC-86': 15.287809048688267, 'ACC-87': 5.587182107275305, 'ACC-88': 17.36849593398862, 'ACC-89': 11.611253170715269, 'ACC-90': 5.3329018864857085, 'ACC-91': 18.41750532944009, 'ACC-92': 19.658696840153695, 'ACC-93': 5.302382426640538, 'ACC-94': 3.5229965381424693, 'ACC-95': 28.294529840809147, 'ACC-96': 11.19118502002292, 'ACC-97': 10.914358218670673, 'ACC-98': 8.706312952468398, 'ACC-99': 27.77785062869917, 'ACC-100': 6.2514242016564125, 'ACC-101': 10.371734491575406, 'ACC-102': 8.413638423198913, 'ACC-103': 14.704189099839427, 'ACC-104': 16.26179877523917, 'ACC-105': 7.473533099173016, 'ACC-106': 3.7961346644860137, 'ACC-107': 12.931390850662941, 'ACC-108': 12.792216065157595, 'ACC-109': 9.937362062586908, 'ACC-110': 16.87508223760971, 'ACC-111': 1.6103076235058595, 'ACC-112': 1.683106011922279, 'ACC-113': 12.126448440461143, 'ACC-114': 6.551501331816325, 'ACC-115': 13.826432426743644, 'ACC-116': 14.930371597774533, 'ACC-117': 7.5882786437970084, 'ACC-118': 4.142382511293418, 'ACC-119': 5.620584189742646, 'ACC-120': 3.6673290532966476, 'ACC-121': 8.72554706133237, 'ACC-122': 5.40519120269467, 'ACC-123': 4.655948952866665, 'ACC-124': 7.6141880484854045, 'ACC-125': 9.144810047826594, 'ACC-126': 1.801701290539987, 'ACC-127': 5.586270780962349, 'ACC-128': 1.421713374094849, 'ACC-129': 3.7795274602320967, 'ACC-130': 2.161331431239568, 'ACC-131': 6.287644221854932, 'ACC-132': 9.211596009557224, 'ACC-133': 5.4887831962277245, 'ACC-134': 4.983644980611805, 'ACC-135': 5.487785759078729, 'ACC-136': 7.8927215337308985, 'ACC-137': 6.137075003606273, 'ACC-138': 2.0166510140366016, 'ACC-139': 5.695333399466941, 'ACC-140': 0.24126741175476696, 'ACC-141': 2.004160642543243, 'ACC-142': 4.28667119044313, 'ACC-143': 3.649358900052388, 'ACC-144': 3.293050541516245, 'ACC-145': 1.6654218564815848, 'ACC-146': 4.80619588311896, 'ACC-147': 8.176916441578001, 'ACC-148': 1.8540926247872014, 'ACC-149': 1.3961497623391468, 'ACC-150': 5.7447866342717235, 'ACC-151': 0.45604577723352124, 'ACC-152': 0.19830231303526874, 'ACC-153': 0.8743060517781565, 'ACC-154': 7.91823564844006, 'ACC-155': 5.208510512420409, 'ACC-156': 13.846561564764363, 'ACC-157': 0.6986211317580672, 'ACC-158': 0.7844177765608967, 'ACC-159': 0.02013116446027214, 'ACC-160': 0.0, 'ACC-161': 1.4086840767586786, 'ACC-162': 0.0, 'ACC-163': 1.586750783821257, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 9.07874524682912, 'ACC-167': 1.9940347457818495, 'ACC-168': 5.083866657289542, 'ACC-169': 0.0, 'ACC-170': 0.6131365617502166, 'ACC-171': 0.08596478015609588, 'ACC-172': 0.015372078379079156, 'ACC-173': 0.0, 'ACC-174': 0.12880232477944234, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.002231776027073472, 'ACC-180': 0.15958887872938468, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.016645817360074252, 'ACC-189': 2.064587018414925, 'ACC-190': 1.988377333179622, 'ACC-191': 0.14799347471451876, 'ACC-192': 0.0})])
[01/18 20:02:52] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/18 20:02:52] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/18 20:02:52] d2.evaluation.testing INFO: copypaste: 3.9057,0.4418,0.1946,6.9240,19.4019,12.3982,27.7817
[01/18 20:02:52] d2.utils.events INFO:  eta: 13:50:19  iter: 3999  total_loss: 50.39  loss_ce: 0.4192  loss_mask: 0.5446  loss_dice: 3.977  loss_ce_0: 0.721  loss_mask_0: 0.5136  loss_dice_0: 4.097  loss_ce_1: 0.4378  loss_mask_1: 0.5367  loss_dice_1: 3.999  loss_ce_2: 0.4314  loss_mask_2: 0.5378  loss_dice_2: 3.992  loss_ce_3: 0.4142  loss_mask_3: 0.5374  loss_dice_3: 3.981  loss_ce_4: 0.4125  loss_mask_4: 0.5407  loss_dice_4: 3.975  loss_ce_5: 0.4078  loss_mask_5: 0.5413  loss_dice_5: 3.98  loss_ce_6: 0.4013  loss_mask_6: 0.5411  loss_dice_6: 3.985  loss_ce_7: 0.4019  loss_mask_7: 0.5436  loss_dice_7: 3.981  loss_ce_8: 0.4157  loss_mask_8: 0.5453  loss_dice_8: 3.98  time: 1.4144  data_time: 0.0560  lr: 9.0956e-06  max_mem: 21164M
[01/18 20:03:21] d2.utils.events INFO:  eta: 13:50:15  iter: 4019  total_loss: 50.07  loss_ce: 0.4315  loss_mask: 0.5383  loss_dice: 4  loss_ce_0: 0.7557  loss_mask_0: 0.4999  loss_dice_0: 4.12  loss_ce_1: 0.4584  loss_mask_1: 0.5296  loss_dice_1: 4.033  loss_ce_2: 0.4202  loss_mask_2: 0.536  loss_dice_2: 4.013  loss_ce_3: 0.4155  loss_mask_3: 0.5371  loss_dice_3: 4.01  loss_ce_4: 0.4156  loss_mask_4: 0.5345  loss_dice_4: 4.011  loss_ce_5: 0.4213  loss_mask_5: 0.5401  loss_dice_5: 3.997  loss_ce_6: 0.4208  loss_mask_6: 0.5375  loss_dice_6: 4.001  loss_ce_7: 0.4215  loss_mask_7: 0.5347  loss_dice_7: 3.999  loss_ce_8: 0.4406  loss_mask_8: 0.5376  loss_dice_8: 4.001  time: 1.4143  data_time: 0.0591  lr: 9.091e-06  max_mem: 21164M
[01/18 20:03:57] d2.utils.events INFO:  eta: 13:50:06  iter: 4039  total_loss: 49.88  loss_ce: 0.4009  loss_mask: 0.5439  loss_dice: 4.002  loss_ce_0: 0.7302  loss_mask_0: 0.5235  loss_dice_0: 4.114  loss_ce_1: 0.405  loss_mask_1: 0.541  loss_dice_1: 4.035  loss_ce_2: 0.3939  loss_mask_2: 0.5385  loss_dice_2: 4.016  loss_ce_3: 0.3946  loss_mask_3: 0.5405  loss_dice_3: 4.008  loss_ce_4: 0.3932  loss_mask_4: 0.5437  loss_dice_4: 4.005  loss_ce_5: 0.4019  loss_mask_5: 0.5452  loss_dice_5: 4  loss_ce_6: 0.4066  loss_mask_6: 0.5435  loss_dice_6: 4.001  loss_ce_7: 0.4017  loss_mask_7: 0.5421  loss_dice_7: 3.999  loss_ce_8: 0.4116  loss_mask_8: 0.5426  loss_dice_8: 4.001  time: 1.4162  data_time: 0.0693  lr: 9.0865e-06  max_mem: 21164M
[01/18 20:04:24] d2.utils.events INFO:  eta: 13:49:33  iter: 4059  total_loss: 49.51  loss_ce: 0.4044  loss_mask: 0.5425  loss_dice: 3.951  loss_ce_0: 0.7152  loss_mask_0: 0.5123  loss_dice_0: 4.078  loss_ce_1: 0.4148  loss_mask_1: 0.5367  loss_dice_1: 3.982  loss_ce_2: 0.3996  loss_mask_2: 0.5376  loss_dice_2: 3.967  loss_ce_3: 0.3985  loss_mask_3: 0.5389  loss_dice_3: 3.962  loss_ce_4: 0.3937  loss_mask_4: 0.5425  loss_dice_4: 3.96  loss_ce_5: 0.3932  loss_mask_5: 0.5425  loss_dice_5: 3.963  loss_ce_6: 0.3873  loss_mask_6: 0.5448  loss_dice_6: 3.95  loss_ce_7: 0.3954  loss_mask_7: 0.5441  loss_dice_7: 3.956  loss_ce_8: 0.3986  loss_mask_8: 0.5436  loss_dice_8: 3.96  time: 1.4160  data_time: 0.0544  lr: 9.0819e-06  max_mem: 21164M
[01/18 20:04:52] d2.utils.events INFO:  eta: 13:48:46  iter: 4079  total_loss: 50.12  loss_ce: 0.4249  loss_mask: 0.5457  loss_dice: 3.97  loss_ce_0: 0.7235  loss_mask_0: 0.527  loss_dice_0: 4.099  loss_ce_1: 0.4413  loss_mask_1: 0.5434  loss_dice_1: 4  loss_ce_2: 0.4161  loss_mask_2: 0.5439  loss_dice_2: 3.996  loss_ce_3: 0.425  loss_mask_3: 0.54  loss_dice_3: 3.987  loss_ce_4: 0.4121  loss_mask_4: 0.5453  loss_dice_4: 3.978  loss_ce_5: 0.4157  loss_mask_5: 0.5447  loss_dice_5: 3.982  loss_ce_6: 0.4138  loss_mask_6: 0.5448  loss_dice_6: 3.977  loss_ce_7: 0.4276  loss_mask_7: 0.5456  loss_dice_7: 3.973  loss_ce_8: 0.4092  loss_mask_8: 0.5455  loss_dice_8: 3.973  time: 1.4159  data_time: 0.0531  lr: 9.0774e-06  max_mem: 21164M
[01/18 20:05:26] d2.utils.events INFO:  eta: 13:48:48  iter: 4099  total_loss: 50.08  loss_ce: 0.4041  loss_mask: 0.5314  loss_dice: 3.985  loss_ce_0: 0.7355  loss_mask_0: 0.5108  loss_dice_0: 4.113  loss_ce_1: 0.422  loss_mask_1: 0.526  loss_dice_1: 4.022  loss_ce_2: 0.4013  loss_mask_2: 0.5281  loss_dice_2: 3.993  loss_ce_3: 0.4029  loss_mask_3: 0.5284  loss_dice_3: 3.988  loss_ce_4: 0.4253  loss_mask_4: 0.5289  loss_dice_4: 3.985  loss_ce_5: 0.4198  loss_mask_5: 0.529  loss_dice_5: 3.988  loss_ce_6: 0.4031  loss_mask_6: 0.5324  loss_dice_6: 3.989  loss_ce_7: 0.4097  loss_mask_7: 0.528  loss_dice_7: 3.986  loss_ce_8: 0.4094  loss_mask_8: 0.5272  loss_dice_8: 3.993  time: 1.4174  data_time: 0.0648  lr: 9.0728e-06  max_mem: 21164M
[01/18 20:05:54] d2.utils.events INFO:  eta: 13:48:32  iter: 4119  total_loss: 50.14  loss_ce: 0.4072  loss_mask: 0.5484  loss_dice: 4.004  loss_ce_0: 0.7124  loss_mask_0: 0.5235  loss_dice_0: 4.114  loss_ce_1: 0.4286  loss_mask_1: 0.5447  loss_dice_1: 4.02  loss_ce_2: 0.4186  loss_mask_2: 0.5466  loss_dice_2: 4.011  loss_ce_3: 0.415  loss_mask_3: 0.5461  loss_dice_3: 4.002  loss_ce_4: 0.3985  loss_mask_4: 0.5469  loss_dice_4: 4.001  loss_ce_5: 0.4118  loss_mask_5: 0.546  loss_dice_5: 3.996  loss_ce_6: 0.3998  loss_mask_6: 0.5467  loss_dice_6: 4  loss_ce_7: 0.4068  loss_mask_7: 0.5474  loss_dice_7: 4.001  loss_ce_8: 0.4012  loss_mask_8: 0.5475  loss_dice_8: 4.001  time: 1.4172  data_time: 0.0525  lr: 9.0683e-06  max_mem: 21164M
[01/18 20:06:22] d2.utils.events INFO:  eta: 13:48:04  iter: 4139  total_loss: 49.55  loss_ce: 0.3946  loss_mask: 0.5413  loss_dice: 3.976  loss_ce_0: 0.7298  loss_mask_0: 0.5243  loss_dice_0: 4.091  loss_ce_1: 0.4423  loss_mask_1: 0.5412  loss_dice_1: 3.998  loss_ce_2: 0.415  loss_mask_2: 0.543  loss_dice_2: 3.982  loss_ce_3: 0.3989  loss_mask_3: 0.5418  loss_dice_3: 3.962  loss_ce_4: 0.4065  loss_mask_4: 0.5429  loss_dice_4: 3.971  loss_ce_5: 0.4021  loss_mask_5: 0.5392  loss_dice_5: 3.977  loss_ce_6: 0.3909  loss_mask_6: 0.5381  loss_dice_6: 3.967  loss_ce_7: 0.4083  loss_mask_7: 0.5359  loss_dice_7: 3.968  loss_ce_8: 0.4064  loss_mask_8: 0.5389  loss_dice_8: 3.972  time: 1.4170  data_time: 0.0544  lr: 9.0637e-06  max_mem: 21164M
[01/18 20:06:50] d2.utils.events INFO:  eta: 13:47:43  iter: 4159  total_loss: 49.75  loss_ce: 0.4154  loss_mask: 0.5283  loss_dice: 3.967  loss_ce_0: 0.7449  loss_mask_0: 0.5025  loss_dice_0: 4.107  loss_ce_1: 0.4335  loss_mask_1: 0.5271  loss_dice_1: 4.004  loss_ce_2: 0.4381  loss_mask_2: 0.5263  loss_dice_2: 3.981  loss_ce_3: 0.4307  loss_mask_3: 0.5281  loss_dice_3: 3.978  loss_ce_4: 0.4348  loss_mask_4: 0.5289  loss_dice_4: 3.969  loss_ce_5: 0.4334  loss_mask_5: 0.5284  loss_dice_5: 3.965  loss_ce_6: 0.403  loss_mask_6: 0.5301  loss_dice_6: 3.964  loss_ce_7: 0.4153  loss_mask_7: 0.5288  loss_dice_7: 3.968  loss_ce_8: 0.4208  loss_mask_8: 0.5302  loss_dice_8: 3.968  time: 1.4169  data_time: 0.0558  lr: 9.0592e-06  max_mem: 21164M
[01/18 20:07:17] d2.utils.events INFO:  eta: 13:47:09  iter: 4179  total_loss: 49.77  loss_ce: 0.3946  loss_mask: 0.5246  loss_dice: 4  loss_ce_0: 0.713  loss_mask_0: 0.5032  loss_dice_0: 4.108  loss_ce_1: 0.4096  loss_mask_1: 0.522  loss_dice_1: 4.021  loss_ce_2: 0.3972  loss_mask_2: 0.5225  loss_dice_2: 4.001  loss_ce_3: 0.4057  loss_mask_3: 0.5241  loss_dice_3: 3.994  loss_ce_4: 0.4119  loss_mask_4: 0.5246  loss_dice_4: 3.997  loss_ce_5: 0.4004  loss_mask_5: 0.5237  loss_dice_5: 3.988  loss_ce_6: 0.3974  loss_mask_6: 0.5222  loss_dice_6: 3.99  loss_ce_7: 0.3992  loss_mask_7: 0.5257  loss_dice_7: 3.996  loss_ce_8: 0.4018  loss_mask_8: 0.5256  loss_dice_8: 4.001  time: 1.4167  data_time: 0.0578  lr: 9.0546e-06  max_mem: 21164M
[01/18 20:07:45] d2.utils.events INFO:  eta: 13:46:50  iter: 4199  total_loss: 49.53  loss_ce: 0.4028  loss_mask: 0.5393  loss_dice: 3.966  loss_ce_0: 0.7381  loss_mask_0: 0.5205  loss_dice_0: 4.085  loss_ce_1: 0.4251  loss_mask_1: 0.5407  loss_dice_1: 3.993  loss_ce_2: 0.3831  loss_mask_2: 0.5424  loss_dice_2: 3.979  loss_ce_3: 0.3949  loss_mask_3: 0.5432  loss_dice_3: 3.966  loss_ce_4: 0.3901  loss_mask_4: 0.5431  loss_dice_4: 3.959  loss_ce_5: 0.3818  loss_mask_5: 0.5415  loss_dice_5: 3.958  loss_ce_6: 0.3919  loss_mask_6: 0.5402  loss_dice_6: 3.961  loss_ce_7: 0.4  loss_mask_7: 0.5394  loss_dice_7: 3.955  loss_ce_8: 0.4098  loss_mask_8: 0.5394  loss_dice_8: 3.965  time: 1.4166  data_time: 0.0552  lr: 9.0501e-06  max_mem: 21164M
[01/18 20:08:12] d2.utils.events INFO:  eta: 13:46:13  iter: 4219  total_loss: 49.56  loss_ce: 0.4263  loss_mask: 0.54  loss_dice: 3.935  loss_ce_0: 0.7191  loss_mask_0: 0.5166  loss_dice_0: 4.065  loss_ce_1: 0.4278  loss_mask_1: 0.5361  loss_dice_1: 3.973  loss_ce_2: 0.4274  loss_mask_2: 0.5388  loss_dice_2: 3.952  loss_ce_3: 0.4171  loss_mask_3: 0.5368  loss_dice_3: 3.937  loss_ce_4: 0.4206  loss_mask_4: 0.5396  loss_dice_4: 3.932  loss_ce_5: 0.4209  loss_mask_5: 0.541  loss_dice_5: 3.936  loss_ce_6: 0.4231  loss_mask_6: 0.5387  loss_dice_6: 3.925  loss_ce_7: 0.4246  loss_mask_7: 0.539  loss_dice_7: 3.928  loss_ce_8: 0.4395  loss_mask_8: 0.5383  loss_dice_8: 3.93  time: 1.4163  data_time: 0.0582  lr: 9.0455e-06  max_mem: 21164M
[01/18 20:08:40] d2.utils.events INFO:  eta: 13:45:53  iter: 4239  total_loss: 49.33  loss_ce: 0.418  loss_mask: 0.5339  loss_dice: 3.915  loss_ce_0: 0.7273  loss_mask_0: 0.516  loss_dice_0: 4.041  loss_ce_1: 0.4517  loss_mask_1: 0.5338  loss_dice_1: 3.941  loss_ce_2: 0.4303  loss_mask_2: 0.5371  loss_dice_2: 3.921  loss_ce_3: 0.4258  loss_mask_3: 0.5355  loss_dice_3: 3.907  loss_ce_4: 0.4219  loss_mask_4: 0.5337  loss_dice_4: 3.911  loss_ce_5: 0.4091  loss_mask_5: 0.5334  loss_dice_5: 3.914  loss_ce_6: 0.4224  loss_mask_6: 0.5349  loss_dice_6: 3.91  loss_ce_7: 0.4363  loss_mask_7: 0.5357  loss_dice_7: 3.907  loss_ce_8: 0.4086  loss_mask_8: 0.5356  loss_dice_8: 3.915  time: 1.4161  data_time: 0.0547  lr: 9.041e-06  max_mem: 21164M
[01/18 20:09:08] d2.utils.events INFO:  eta: 13:45:39  iter: 4259  total_loss: 49.11  loss_ce: 0.394  loss_mask: 0.5282  loss_dice: 3.912  loss_ce_0: 0.7289  loss_mask_0: 0.5031  loss_dice_0: 4.057  loss_ce_1: 0.4359  loss_mask_1: 0.5226  loss_dice_1: 3.954  loss_ce_2: 0.3961  loss_mask_2: 0.5285  loss_dice_2: 3.928  loss_ce_3: 0.3975  loss_mask_3: 0.5277  loss_dice_3: 3.923  loss_ce_4: 0.4013  loss_mask_4: 0.5296  loss_dice_4: 3.917  loss_ce_5: 0.3959  loss_mask_5: 0.5282  loss_dice_5: 3.91  loss_ce_6: 0.3908  loss_mask_6: 0.5244  loss_dice_6: 3.918  loss_ce_7: 0.3874  loss_mask_7: 0.5271  loss_dice_7: 3.918  loss_ce_8: 0.396  loss_mask_8: 0.5284  loss_dice_8: 3.913  time: 1.4160  data_time: 0.0555  lr: 9.0364e-06  max_mem: 21164M
[01/18 20:09:35] d2.utils.events INFO:  eta: 13:44:50  iter: 4279  total_loss: 49.14  loss_ce: 0.405  loss_mask: 0.5426  loss_dice: 3.901  loss_ce_0: 0.721  loss_mask_0: 0.513  loss_dice_0: 4.034  loss_ce_1: 0.413  loss_mask_1: 0.5365  loss_dice_1: 3.929  loss_ce_2: 0.4057  loss_mask_2: 0.5413  loss_dice_2: 3.905  loss_ce_3: 0.4097  loss_mask_3: 0.5429  loss_dice_3: 3.897  loss_ce_4: 0.4099  loss_mask_4: 0.5411  loss_dice_4: 3.896  loss_ce_5: 0.4048  loss_mask_5: 0.5413  loss_dice_5: 3.893  loss_ce_6: 0.408  loss_mask_6: 0.5416  loss_dice_6: 3.893  loss_ce_7: 0.3967  loss_mask_7: 0.541  loss_dice_7: 3.901  loss_ce_8: 0.4052  loss_mask_8: 0.5402  loss_dice_8: 3.903  time: 1.4158  data_time: 0.0520  lr: 9.0319e-06  max_mem: 21164M
[01/18 20:10:03] d2.utils.events INFO:  eta: 13:44:22  iter: 4299  total_loss: 49.08  loss_ce: 0.4211  loss_mask: 0.5244  loss_dice: 3.933  loss_ce_0: 0.7083  loss_mask_0: 0.5033  loss_dice_0: 4.061  loss_ce_1: 0.4162  loss_mask_1: 0.5228  loss_dice_1: 3.96  loss_ce_2: 0.4035  loss_mask_2: 0.5263  loss_dice_2: 3.947  loss_ce_3: 0.3984  loss_mask_3: 0.5255  loss_dice_3: 3.934  loss_ce_4: 0.4097  loss_mask_4: 0.5261  loss_dice_4: 3.924  loss_ce_5: 0.3959  loss_mask_5: 0.5262  loss_dice_5: 3.934  loss_ce_6: 0.4099  loss_mask_6: 0.5261  loss_dice_6: 3.934  loss_ce_7: 0.4118  loss_mask_7: 0.5264  loss_dice_7: 3.933  loss_ce_8: 0.4219  loss_mask_8: 0.5252  loss_dice_8: 3.93  time: 1.4156  data_time: 0.0558  lr: 9.0273e-06  max_mem: 21164M
[01/18 20:10:31] d2.utils.events INFO:  eta: 13:44:01  iter: 4319  total_loss: 49.09  loss_ce: 0.4187  loss_mask: 0.5378  loss_dice: 3.92  loss_ce_0: 0.7474  loss_mask_0: 0.5106  loss_dice_0: 4.051  loss_ce_1: 0.4166  loss_mask_1: 0.5322  loss_dice_1: 3.957  loss_ce_2: 0.4198  loss_mask_2: 0.5315  loss_dice_2: 3.933  loss_ce_3: 0.3974  loss_mask_3: 0.536  loss_dice_3: 3.921  loss_ce_4: 0.4084  loss_mask_4: 0.5335  loss_dice_4: 3.915  loss_ce_5: 0.4064  loss_mask_5: 0.5371  loss_dice_5: 3.92  loss_ce_6: 0.4117  loss_mask_6: 0.5363  loss_dice_6: 3.919  loss_ce_7: 0.4114  loss_mask_7: 0.5363  loss_dice_7: 3.917  loss_ce_8: 0.4104  loss_mask_8: 0.5368  loss_dice_8: 3.918  time: 1.4155  data_time: 0.0523  lr: 9.0228e-06  max_mem: 21164M
[01/18 20:10:58] d2.utils.events INFO:  eta: 13:43:34  iter: 4339  total_loss: 49.1  loss_ce: 0.409  loss_mask: 0.5304  loss_dice: 3.918  loss_ce_0: 0.7  loss_mask_0: 0.5026  loss_dice_0: 4.025  loss_ce_1: 0.4034  loss_mask_1: 0.5323  loss_dice_1: 3.937  loss_ce_2: 0.3878  loss_mask_2: 0.5374  loss_dice_2: 3.924  loss_ce_3: 0.3825  loss_mask_3: 0.5333  loss_dice_3: 3.913  loss_ce_4: 0.385  loss_mask_4: 0.5356  loss_dice_4: 3.911  loss_ce_5: 0.3919  loss_mask_5: 0.5345  loss_dice_5: 3.916  loss_ce_6: 0.3782  loss_mask_6: 0.534  loss_dice_6: 3.913  loss_ce_7: 0.3936  loss_mask_7: 0.5316  loss_dice_7: 3.911  loss_ce_8: 0.4048  loss_mask_8: 0.5344  loss_dice_8: 3.916  time: 1.4153  data_time: 0.0562  lr: 9.0182e-06  max_mem: 21164M
[01/18 20:11:26] d2.utils.events INFO:  eta: 13:43:21  iter: 4359  total_loss: 49.06  loss_ce: 0.4041  loss_mask: 0.5292  loss_dice: 3.922  loss_ce_0: 0.6883  loss_mask_0: 0.5052  loss_dice_0: 4.056  loss_ce_1: 0.4128  loss_mask_1: 0.5289  loss_dice_1: 3.96  loss_ce_2: 0.4059  loss_mask_2: 0.5274  loss_dice_2: 3.934  loss_ce_3: 0.3929  loss_mask_3: 0.5297  loss_dice_3: 3.924  loss_ce_4: 0.4073  loss_mask_4: 0.5297  loss_dice_4: 3.922  loss_ce_5: 0.3987  loss_mask_5: 0.5314  loss_dice_5: 3.92  loss_ce_6: 0.4032  loss_mask_6: 0.5295  loss_dice_6: 3.924  loss_ce_7: 0.3953  loss_mask_7: 0.5276  loss_dice_7: 3.92  loss_ce_8: 0.3943  loss_mask_8: 0.5297  loss_dice_8: 3.926  time: 1.4152  data_time: 0.0505  lr: 9.0137e-06  max_mem: 21164M
[01/18 20:11:54] d2.utils.events INFO:  eta: 13:42:59  iter: 4379  total_loss: 49.14  loss_ce: 0.3794  loss_mask: 0.5448  loss_dice: 3.908  loss_ce_0: 0.7122  loss_mask_0: 0.51  loss_dice_0: 4.06  loss_ce_1: 0.4057  loss_mask_1: 0.5401  loss_dice_1: 3.949  loss_ce_2: 0.3999  loss_mask_2: 0.5444  loss_dice_2: 3.934  loss_ce_3: 0.3803  loss_mask_3: 0.5422  loss_dice_3: 3.922  loss_ce_4: 0.3775  loss_mask_4: 0.5423  loss_dice_4: 3.927  loss_ce_5: 0.3747  loss_mask_5: 0.544  loss_dice_5: 3.918  loss_ce_6: 0.3889  loss_mask_6: 0.5412  loss_dice_6: 3.914  loss_ce_7: 0.3735  loss_mask_7: 0.5417  loss_dice_7: 3.915  loss_ce_8: 0.372  loss_mask_8: 0.5426  loss_dice_8: 3.916  time: 1.4151  data_time: 0.0572  lr: 9.0091e-06  max_mem: 21164M
[01/18 20:12:22] d2.utils.events INFO:  eta: 13:42:58  iter: 4399  total_loss: 49.41  loss_ce: 0.4094  loss_mask: 0.5284  loss_dice: 3.951  loss_ce_0: 0.7046  loss_mask_0: 0.4973  loss_dice_0: 4.066  loss_ce_1: 0.4181  loss_mask_1: 0.5235  loss_dice_1: 3.983  loss_ce_2: 0.415  loss_mask_2: 0.5256  loss_dice_2: 3.975  loss_ce_3: 0.3977  loss_mask_3: 0.5328  loss_dice_3: 3.954  loss_ce_4: 0.4033  loss_mask_4: 0.5323  loss_dice_4: 3.953  loss_ce_5: 0.4134  loss_mask_5: 0.5318  loss_dice_5: 3.956  loss_ce_6: 0.4133  loss_mask_6: 0.5284  loss_dice_6: 3.957  loss_ce_7: 0.4036  loss_mask_7: 0.5306  loss_dice_7: 3.957  loss_ce_8: 0.3955  loss_mask_8: 0.5288  loss_dice_8: 3.956  time: 1.4150  data_time: 0.0620  lr: 9.0045e-06  max_mem: 21164M
[01/18 20:12:50] d2.utils.events INFO:  eta: 13:42:04  iter: 4419  total_loss: 48.26  loss_ce: 0.3775  loss_mask: 0.5328  loss_dice: 3.875  loss_ce_0: 0.6919  loss_mask_0: 0.5012  loss_dice_0: 4.018  loss_ce_1: 0.39  loss_mask_1: 0.5295  loss_dice_1: 3.916  loss_ce_2: 0.3648  loss_mask_2: 0.5348  loss_dice_2: 3.896  loss_ce_3: 0.3703  loss_mask_3: 0.5327  loss_dice_3: 3.881  loss_ce_4: 0.3551  loss_mask_4: 0.5318  loss_dice_4: 3.88  loss_ce_5: 0.3543  loss_mask_5: 0.5375  loss_dice_5: 3.884  loss_ce_6: 0.3809  loss_mask_6: 0.5353  loss_dice_6: 3.883  loss_ce_7: 0.3643  loss_mask_7: 0.5366  loss_dice_7: 3.879  loss_ce_8: 0.3506  loss_mask_8: 0.5333  loss_dice_8: 3.879  time: 1.4148  data_time: 0.0512  lr: 9e-06  max_mem: 21164M
[01/18 20:13:18] d2.utils.events INFO:  eta: 13:41:42  iter: 4439  total_loss: 48.89  loss_ce: 0.3851  loss_mask: 0.5287  loss_dice: 3.951  loss_ce_0: 0.6807  loss_mask_0: 0.5018  loss_dice_0: 4.072  loss_ce_1: 0.412  loss_mask_1: 0.5281  loss_dice_1: 3.978  loss_ce_2: 0.3955  loss_mask_2: 0.5305  loss_dice_2: 3.96  loss_ce_3: 0.3923  loss_mask_3: 0.5293  loss_dice_3: 3.957  loss_ce_4: 0.3991  loss_mask_4: 0.5265  loss_dice_4: 3.945  loss_ce_5: 0.3819  loss_mask_5: 0.5247  loss_dice_5: 3.943  loss_ce_6: 0.3925  loss_mask_6: 0.5235  loss_dice_6: 3.947  loss_ce_7: 0.3969  loss_mask_7: 0.527  loss_dice_7: 3.951  loss_ce_8: 0.3987  loss_mask_8: 0.5299  loss_dice_8: 3.946  time: 1.4148  data_time: 0.0564  lr: 8.9954e-06  max_mem: 21164M
[01/18 20:13:46] d2.utils.events INFO:  eta: 13:41:26  iter: 4459  total_loss: 49.26  loss_ce: 0.3994  loss_mask: 0.5273  loss_dice: 3.933  loss_ce_0: 0.6914  loss_mask_0: 0.5121  loss_dice_0: 4.064  loss_ce_1: 0.3998  loss_mask_1: 0.5326  loss_dice_1: 3.968  loss_ce_2: 0.3822  loss_mask_2: 0.5333  loss_dice_2: 3.941  loss_ce_3: 0.3873  loss_mask_3: 0.5348  loss_dice_3: 3.94  loss_ce_4: 0.4077  loss_mask_4: 0.5345  loss_dice_4: 3.933  loss_ce_5: 0.3952  loss_mask_5: 0.5321  loss_dice_5: 3.935  loss_ce_6: 0.397  loss_mask_6: 0.5322  loss_dice_6: 3.936  loss_ce_7: 0.3924  loss_mask_7: 0.5296  loss_dice_7: 3.932  loss_ce_8: 0.4005  loss_mask_8: 0.528  loss_dice_8: 3.934  time: 1.4147  data_time: 0.0516  lr: 8.9909e-06  max_mem: 21164M
[01/18 20:14:13] d2.utils.events INFO:  eta: 13:40:41  iter: 4479  total_loss: 48.71  loss_ce: 0.3939  loss_mask: 0.5226  loss_dice: 3.889  loss_ce_0: 0.7211  loss_mask_0: 0.4933  loss_dice_0: 4.028  loss_ce_1: 0.4275  loss_mask_1: 0.5147  loss_dice_1: 3.918  loss_ce_2: 0.4087  loss_mask_2: 0.5171  loss_dice_2: 3.896  loss_ce_3: 0.3906  loss_mask_3: 0.5183  loss_dice_3: 3.891  loss_ce_4: 0.4109  loss_mask_4: 0.5218  loss_dice_4: 3.885  loss_ce_5: 0.4014  loss_mask_5: 0.524  loss_dice_5: 3.889  loss_ce_6: 0.4033  loss_mask_6: 0.5182  loss_dice_6: 3.897  loss_ce_7: 0.3943  loss_mask_7: 0.5208  loss_dice_7: 3.881  loss_ce_8: 0.3949  loss_mask_8: 0.5214  loss_dice_8: 3.881  time: 1.4146  data_time: 0.0551  lr: 8.9863e-06  max_mem: 21164M
[01/18 20:14:41] d2.utils.events INFO:  eta: 13:40:49  iter: 4499  total_loss: 48.64  loss_ce: 0.4049  loss_mask: 0.5259  loss_dice: 3.891  loss_ce_0: 0.6651  loss_mask_0: 0.4966  loss_dice_0: 4.019  loss_ce_1: 0.409  loss_mask_1: 0.5254  loss_dice_1: 3.919  loss_ce_2: 0.3888  loss_mask_2: 0.5297  loss_dice_2: 3.904  loss_ce_3: 0.4005  loss_mask_3: 0.5292  loss_dice_3: 3.898  loss_ce_4: 0.3948  loss_mask_4: 0.5242  loss_dice_4: 3.897  loss_ce_5: 0.3861  loss_mask_5: 0.5286  loss_dice_5: 3.883  loss_ce_6: 0.3962  loss_mask_6: 0.5287  loss_dice_6: 3.881  loss_ce_7: 0.3932  loss_mask_7: 0.5296  loss_dice_7: 3.886  loss_ce_8: 0.3983  loss_mask_8: 0.5287  loss_dice_8: 3.893  time: 1.4144  data_time: 0.0568  lr: 8.9818e-06  max_mem: 21164M
[01/18 20:15:09] d2.utils.events INFO:  eta: 13:40:11  iter: 4519  total_loss: 48.52  loss_ce: 0.3925  loss_mask: 0.5306  loss_dice: 3.885  loss_ce_0: 0.6898  loss_mask_0: 0.5038  loss_dice_0: 4.029  loss_ce_1: 0.4151  loss_mask_1: 0.525  loss_dice_1: 3.935  loss_ce_2: 0.4077  loss_mask_2: 0.529  loss_dice_2: 3.902  loss_ce_3: 0.396  loss_mask_3: 0.5261  loss_dice_3: 3.893  loss_ce_4: 0.3904  loss_mask_4: 0.5278  loss_dice_4: 3.888  loss_ce_5: 0.3911  loss_mask_5: 0.5303  loss_dice_5: 3.885  loss_ce_6: 0.3871  loss_mask_6: 0.5284  loss_dice_6: 3.889  loss_ce_7: 0.3927  loss_mask_7: 0.5271  loss_dice_7: 3.889  loss_ce_8: 0.386  loss_mask_8: 0.5284  loss_dice_8: 3.881  time: 1.4143  data_time: 0.0599  lr: 8.9772e-06  max_mem: 21164M
[01/18 20:15:37] d2.utils.events INFO:  eta: 13:39:24  iter: 4539  total_loss: 48.44  loss_ce: 0.3917  loss_mask: 0.5228  loss_dice: 3.879  loss_ce_0: 0.7206  loss_mask_0: 0.4968  loss_dice_0: 4.013  loss_ce_1: 0.415  loss_mask_1: 0.5204  loss_dice_1: 3.934  loss_ce_2: 0.4021  loss_mask_2: 0.5217  loss_dice_2: 3.903  loss_ce_3: 0.4  loss_mask_3: 0.5211  loss_dice_3: 3.883  loss_ce_4: 0.3863  loss_mask_4: 0.521  loss_dice_4: 3.89  loss_ce_5: 0.3824  loss_mask_5: 0.5206  loss_dice_5: 3.893  loss_ce_6: 0.3899  loss_mask_6: 0.5223  loss_dice_6: 3.874  loss_ce_7: 0.3992  loss_mask_7: 0.5243  loss_dice_7: 3.872  loss_ce_8: 0.3908  loss_mask_8: 0.5231  loss_dice_8: 3.883  time: 1.4142  data_time: 0.0527  lr: 8.9727e-06  max_mem: 21164M
[01/18 20:16:05] d2.utils.events INFO:  eta: 13:38:56  iter: 4559  total_loss: 48.93  loss_ce: 0.3858  loss_mask: 0.5366  loss_dice: 3.895  loss_ce_0: 0.7085  loss_mask_0: 0.5108  loss_dice_0: 4.031  loss_ce_1: 0.4216  loss_mask_1: 0.5345  loss_dice_1: 3.944  loss_ce_2: 0.395  loss_mask_2: 0.5393  loss_dice_2: 3.904  loss_ce_3: 0.3932  loss_mask_3: 0.5382  loss_dice_3: 3.908  loss_ce_4: 0.3973  loss_mask_4: 0.5359  loss_dice_4: 3.906  loss_ce_5: 0.3994  loss_mask_5: 0.5377  loss_dice_5: 3.893  loss_ce_6: 0.3736  loss_mask_6: 0.5342  loss_dice_6: 3.9  loss_ce_7: 0.398  loss_mask_7: 0.5344  loss_dice_7: 3.895  loss_ce_8: 0.3854  loss_mask_8: 0.535  loss_dice_8: 3.904  time: 1.4141  data_time: 0.0578  lr: 8.9681e-06  max_mem: 21164M
[01/18 20:16:32] d2.utils.events INFO:  eta: 13:38:01  iter: 4579  total_loss: 48.28  loss_ce: 0.3901  loss_mask: 0.5446  loss_dice: 3.869  loss_ce_0: 0.6869  loss_mask_0: 0.5152  loss_dice_0: 3.998  loss_ce_1: 0.3928  loss_mask_1: 0.5367  loss_dice_1: 3.896  loss_ce_2: 0.3983  loss_mask_2: 0.544  loss_dice_2: 3.882  loss_ce_3: 0.3839  loss_mask_3: 0.5459  loss_dice_3: 3.879  loss_ce_4: 0.3961  loss_mask_4: 0.5487  loss_dice_4: 3.868  loss_ce_5: 0.3884  loss_mask_5: 0.5473  loss_dice_5: 3.867  loss_ce_6: 0.3869  loss_mask_6: 0.5467  loss_dice_6: 3.863  loss_ce_7: 0.3918  loss_mask_7: 0.5486  loss_dice_7: 3.87  loss_ce_8: 0.3965  loss_mask_8: 0.5466  loss_dice_8: 3.868  time: 1.4139  data_time: 0.0538  lr: 8.9636e-06  max_mem: 21164M
[01/18 20:17:00] d2.utils.events INFO:  eta: 13:37:30  iter: 4599  total_loss: 48.52  loss_ce: 0.3897  loss_mask: 0.5205  loss_dice: 3.88  loss_ce_0: 0.6578  loss_mask_0: 0.5003  loss_dice_0: 4.013  loss_ce_1: 0.3943  loss_mask_1: 0.519  loss_dice_1: 3.914  loss_ce_2: 0.3883  loss_mask_2: 0.5223  loss_dice_2: 3.896  loss_ce_3: 0.387  loss_mask_3: 0.5232  loss_dice_3: 3.89  loss_ce_4: 0.3856  loss_mask_4: 0.5226  loss_dice_4: 3.888  loss_ce_5: 0.3804  loss_mask_5: 0.5216  loss_dice_5: 3.889  loss_ce_6: 0.3866  loss_mask_6: 0.5221  loss_dice_6: 3.89  loss_ce_7: 0.3782  loss_mask_7: 0.5232  loss_dice_7: 3.88  loss_ce_8: 0.3872  loss_mask_8: 0.5242  loss_dice_8: 3.882  time: 1.4138  data_time: 0.0530  lr: 8.959e-06  max_mem: 21164M
[01/18 20:17:28] d2.utils.events INFO:  eta: 13:36:56  iter: 4619  total_loss: 48.6  loss_ce: 0.3889  loss_mask: 0.5226  loss_dice: 3.878  loss_ce_0: 0.6979  loss_mask_0: 0.4989  loss_dice_0: 4.01  loss_ce_1: 0.4128  loss_mask_1: 0.5199  loss_dice_1: 3.92  loss_ce_2: 0.388  loss_mask_2: 0.5177  loss_dice_2: 3.9  loss_ce_3: 0.3808  loss_mask_3: 0.5174  loss_dice_3: 3.884  loss_ce_4: 0.3781  loss_mask_4: 0.5203  loss_dice_4: 3.884  loss_ce_5: 0.3736  loss_mask_5: 0.5209  loss_dice_5: 3.886  loss_ce_6: 0.3866  loss_mask_6: 0.5221  loss_dice_6: 3.88  loss_ce_7: 0.3721  loss_mask_7: 0.5239  loss_dice_7: 3.877  loss_ce_8: 0.3748  loss_mask_8: 0.524  loss_dice_8: 3.881  time: 1.4137  data_time: 0.0526  lr: 8.9545e-06  max_mem: 21164M
[01/18 20:17:56] d2.utils.events INFO:  eta: 13:37:11  iter: 4639  total_loss: 48.76  loss_ce: 0.395  loss_mask: 0.5169  loss_dice: 3.893  loss_ce_0: 0.6991  loss_mask_0: 0.4966  loss_dice_0: 4.038  loss_ce_1: 0.4194  loss_mask_1: 0.5148  loss_dice_1: 3.937  loss_ce_2: 0.4022  loss_mask_2: 0.5181  loss_dice_2: 3.915  loss_ce_3: 0.3889  loss_mask_3: 0.5192  loss_dice_3: 3.908  loss_ce_4: 0.3878  loss_mask_4: 0.5175  loss_dice_4: 3.901  loss_ce_5: 0.3932  loss_mask_5: 0.5167  loss_dice_5: 3.901  loss_ce_6: 0.4012  loss_mask_6: 0.5161  loss_dice_6: 3.903  loss_ce_7: 0.3896  loss_mask_7: 0.518  loss_dice_7: 3.898  loss_ce_8: 0.3874  loss_mask_8: 0.516  loss_dice_8: 3.896  time: 1.4137  data_time: 0.0594  lr: 8.9499e-06  max_mem: 21164M
[01/18 20:18:23] d2.utils.events INFO:  eta: 13:36:27  iter: 4659  total_loss: 48.14  loss_ce: 0.3768  loss_mask: 0.5264  loss_dice: 3.858  loss_ce_0: 0.6818  loss_mask_0: 0.4973  loss_dice_0: 4.001  loss_ce_1: 0.4177  loss_mask_1: 0.5191  loss_dice_1: 3.908  loss_ce_2: 0.3868  loss_mask_2: 0.5227  loss_dice_2: 3.88  loss_ce_3: 0.3701  loss_mask_3: 0.5284  loss_dice_3: 3.877  loss_ce_4: 0.3749  loss_mask_4: 0.5254  loss_dice_4: 3.871  loss_ce_5: 0.3843  loss_mask_5: 0.5276  loss_dice_5: 3.869  loss_ce_6: 0.3729  loss_mask_6: 0.5293  loss_dice_6: 3.864  loss_ce_7: 0.3659  loss_mask_7: 0.5291  loss_dice_7: 3.864  loss_ce_8: 0.3843  loss_mask_8: 0.525  loss_dice_8: 3.864  time: 1.4135  data_time: 0.0551  lr: 8.9453e-06  max_mem: 21164M
[01/18 20:18:51] d2.utils.events INFO:  eta: 13:36:20  iter: 4679  total_loss: 48.51  loss_ce: 0.3933  loss_mask: 0.5255  loss_dice: 3.87  loss_ce_0: 0.6989  loss_mask_0: 0.4904  loss_dice_0: 4.015  loss_ce_1: 0.4169  loss_mask_1: 0.5111  loss_dice_1: 3.904  loss_ce_2: 0.41  loss_mask_2: 0.5178  loss_dice_2: 3.88  loss_ce_3: 0.3966  loss_mask_3: 0.5217  loss_dice_3: 3.868  loss_ce_4: 0.3987  loss_mask_4: 0.5211  loss_dice_4: 3.87  loss_ce_5: 0.4025  loss_mask_5: 0.521  loss_dice_5: 3.873  loss_ce_6: 0.3895  loss_mask_6: 0.5201  loss_dice_6: 3.872  loss_ce_7: 0.3955  loss_mask_7: 0.5193  loss_dice_7: 3.874  loss_ce_8: 0.3998  loss_mask_8: 0.5225  loss_dice_8: 3.87  time: 1.4134  data_time: 0.0563  lr: 8.9408e-06  max_mem: 21164M
[01/18 20:19:19] d2.utils.events INFO:  eta: 13:36:21  iter: 4699  total_loss: 48.11  loss_ce: 0.3994  loss_mask: 0.512  loss_dice: 3.887  loss_ce_0: 0.7011  loss_mask_0: 0.4935  loss_dice_0: 4.007  loss_ce_1: 0.4257  loss_mask_1: 0.5118  loss_dice_1: 3.907  loss_ce_2: 0.4014  loss_mask_2: 0.5117  loss_dice_2: 3.884  loss_ce_3: 0.3961  loss_mask_3: 0.512  loss_dice_3: 3.888  loss_ce_4: 0.3931  loss_mask_4: 0.5111  loss_dice_4: 3.883  loss_ce_5: 0.3949  loss_mask_5: 0.5108  loss_dice_5: 3.892  loss_ce_6: 0.3918  loss_mask_6: 0.5127  loss_dice_6: 3.886  loss_ce_7: 0.3953  loss_mask_7: 0.5115  loss_dice_7: 3.879  loss_ce_8: 0.3881  loss_mask_8: 0.51  loss_dice_8: 3.887  time: 1.4133  data_time: 0.0560  lr: 8.9362e-06  max_mem: 21164M
[01/18 20:19:47] d2.utils.events INFO:  eta: 13:35:44  iter: 4719  total_loss: 48.42  loss_ce: 0.3924  loss_mask: 0.5316  loss_dice: 3.86  loss_ce_0: 0.6497  loss_mask_0: 0.5119  loss_dice_0: 4.005  loss_ce_1: 0.4155  loss_mask_1: 0.5313  loss_dice_1: 3.902  loss_ce_2: 0.3976  loss_mask_2: 0.5324  loss_dice_2: 3.886  loss_ce_3: 0.3814  loss_mask_3: 0.5309  loss_dice_3: 3.871  loss_ce_4: 0.3896  loss_mask_4: 0.5291  loss_dice_4: 3.869  loss_ce_5: 0.4185  loss_mask_5: 0.5313  loss_dice_5: 3.861  loss_ce_6: 0.3964  loss_mask_6: 0.5325  loss_dice_6: 3.86  loss_ce_7: 0.3878  loss_mask_7: 0.5311  loss_dice_7: 3.866  loss_ce_8: 0.3949  loss_mask_8: 0.5327  loss_dice_8: 3.863  time: 1.4132  data_time: 0.0578  lr: 8.9317e-06  max_mem: 21164M
[01/18 20:20:14] d2.utils.events INFO:  eta: 13:34:57  iter: 4739  total_loss: 48.06  loss_ce: 0.3801  loss_mask: 0.5293  loss_dice: 3.852  loss_ce_0: 0.6504  loss_mask_0: 0.4925  loss_dice_0: 4.003  loss_ce_1: 0.4014  loss_mask_1: 0.5222  loss_dice_1: 3.895  loss_ce_2: 0.3907  loss_mask_2: 0.5249  loss_dice_2: 3.876  loss_ce_3: 0.3862  loss_mask_3: 0.5252  loss_dice_3: 3.868  loss_ce_4: 0.3901  loss_mask_4: 0.5281  loss_dice_4: 3.865  loss_ce_5: 0.385  loss_mask_5: 0.528  loss_dice_5: 3.863  loss_ce_6: 0.3846  loss_mask_6: 0.5265  loss_dice_6: 3.858  loss_ce_7: 0.3977  loss_mask_7: 0.5281  loss_dice_7: 3.853  loss_ce_8: 0.389  loss_mask_8: 0.5302  loss_dice_8: 3.857  time: 1.4130  data_time: 0.0537  lr: 8.9271e-06  max_mem: 21164M
[01/18 20:20:42] d2.utils.events INFO:  eta: 13:34:30  iter: 4759  total_loss: 48.26  loss_ce: 0.4003  loss_mask: 0.5398  loss_dice: 3.861  loss_ce_0: 0.6946  loss_mask_0: 0.5115  loss_dice_0: 3.991  loss_ce_1: 0.4393  loss_mask_1: 0.5343  loss_dice_1: 3.885  loss_ce_2: 0.4031  loss_mask_2: 0.539  loss_dice_2: 3.866  loss_ce_3: 0.4192  loss_mask_3: 0.5373  loss_dice_3: 3.868  loss_ce_4: 0.405  loss_mask_4: 0.5359  loss_dice_4: 3.862  loss_ce_5: 0.4052  loss_mask_5: 0.54  loss_dice_5: 3.865  loss_ce_6: 0.4049  loss_mask_6: 0.5415  loss_dice_6: 3.853  loss_ce_7: 0.4079  loss_mask_7: 0.5416  loss_dice_7: 3.855  loss_ce_8: 0.3954  loss_mask_8: 0.5396  loss_dice_8: 3.859  time: 1.4129  data_time: 0.0563  lr: 8.9226e-06  max_mem: 21164M
[01/18 20:21:10] d2.utils.events INFO:  eta: 13:34:15  iter: 4779  total_loss: 48.02  loss_ce: 0.3807  loss_mask: 0.527  loss_dice: 3.841  loss_ce_0: 0.6415  loss_mask_0: 0.5011  loss_dice_0: 3.979  loss_ce_1: 0.4  loss_mask_1: 0.5231  loss_dice_1: 3.878  loss_ce_2: 0.3857  loss_mask_2: 0.5225  loss_dice_2: 3.861  loss_ce_3: 0.3759  loss_mask_3: 0.5262  loss_dice_3: 3.854  loss_ce_4: 0.3824  loss_mask_4: 0.5272  loss_dice_4: 3.844  loss_ce_5: 0.3813  loss_mask_5: 0.5255  loss_dice_5: 3.848  loss_ce_6: 0.3906  loss_mask_6: 0.5271  loss_dice_6: 3.846  loss_ce_7: 0.3876  loss_mask_7: 0.5274  loss_dice_7: 3.845  loss_ce_8: 0.377  loss_mask_8: 0.5289  loss_dice_8: 3.843  time: 1.4128  data_time: 0.0612  lr: 8.918e-06  max_mem: 21164M
[01/18 20:21:37] d2.utils.events INFO:  eta: 13:33:13  iter: 4799  total_loss: 47.93  loss_ce: 0.3861  loss_mask: 0.5285  loss_dice: 3.83  loss_ce_0: 0.6734  loss_mask_0: 0.5024  loss_dice_0: 3.975  loss_ce_1: 0.4066  loss_mask_1: 0.5286  loss_dice_1: 3.862  loss_ce_2: 0.3986  loss_mask_2: 0.5313  loss_dice_2: 3.827  loss_ce_3: 0.3935  loss_mask_3: 0.5281  loss_dice_3: 3.828  loss_ce_4: 0.3844  loss_mask_4: 0.5299  loss_dice_4: 3.831  loss_ce_5: 0.3798  loss_mask_5: 0.5304  loss_dice_5: 3.829  loss_ce_6: 0.365  loss_mask_6: 0.5249  loss_dice_6: 3.822  loss_ce_7: 0.378  loss_mask_7: 0.5268  loss_dice_7: 3.827  loss_ce_8: 0.3881  loss_mask_8: 0.5274  loss_dice_8: 3.825  time: 1.4126  data_time: 0.0549  lr: 8.9134e-06  max_mem: 21164M
[01/18 20:22:05] d2.utils.events INFO:  eta: 13:32:34  iter: 4819  total_loss: 48.88  loss_ce: 0.4127  loss_mask: 0.5341  loss_dice: 3.885  loss_ce_0: 0.7265  loss_mask_0: 0.5026  loss_dice_0: 4.013  loss_ce_1: 0.4031  loss_mask_1: 0.5248  loss_dice_1: 3.916  loss_ce_2: 0.4223  loss_mask_2: 0.529  loss_dice_2: 3.891  loss_ce_3: 0.4068  loss_mask_3: 0.5292  loss_dice_3: 3.881  loss_ce_4: 0.4033  loss_mask_4: 0.5316  loss_dice_4: 3.887  loss_ce_5: 0.4092  loss_mask_5: 0.5361  loss_dice_5: 3.884  loss_ce_6: 0.4254  loss_mask_6: 0.5374  loss_dice_6: 3.876  loss_ce_7: 0.4141  loss_mask_7: 0.5321  loss_dice_7: 3.887  loss_ce_8: 0.4165  loss_mask_8: 0.5344  loss_dice_8: 3.878  time: 1.4125  data_time: 0.0530  lr: 8.9089e-06  max_mem: 21164M
[01/18 20:22:33] d2.utils.events INFO:  eta: 13:33:07  iter: 4839  total_loss: 48.84  loss_ce: 0.4107  loss_mask: 0.5153  loss_dice: 3.901  loss_ce_0: 0.7113  loss_mask_0: 0.4942  loss_dice_0: 4.019  loss_ce_1: 0.4466  loss_mask_1: 0.5161  loss_dice_1: 3.93  loss_ce_2: 0.4425  loss_mask_2: 0.5164  loss_dice_2: 3.908  loss_ce_3: 0.4098  loss_mask_3: 0.5168  loss_dice_3: 3.907  loss_ce_4: 0.4207  loss_mask_4: 0.5145  loss_dice_4: 3.9  loss_ce_5: 0.42  loss_mask_5: 0.5136  loss_dice_5: 3.903  loss_ce_6: 0.4251  loss_mask_6: 0.5142  loss_dice_6: 3.901  loss_ce_7: 0.4252  loss_mask_7: 0.5165  loss_dice_7: 3.896  loss_ce_8: 0.4179  loss_mask_8: 0.5166  loss_dice_8: 3.898  time: 1.4125  data_time: 0.0563  lr: 8.9043e-06  max_mem: 21164M
[01/18 20:23:01] d2.utils.events INFO:  eta: 13:32:39  iter: 4859  total_loss: 48.61  loss_ce: 0.4184  loss_mask: 0.5218  loss_dice: 3.88  loss_ce_0: 0.7238  loss_mask_0: 0.4949  loss_dice_0: 4.011  loss_ce_1: 0.4435  loss_mask_1: 0.5191  loss_dice_1: 3.92  loss_ce_2: 0.4209  loss_mask_2: 0.5227  loss_dice_2: 3.901  loss_ce_3: 0.4167  loss_mask_3: 0.5234  loss_dice_3: 3.88  loss_ce_4: 0.414  loss_mask_4: 0.5247  loss_dice_4: 3.879  loss_ce_5: 0.4159  loss_mask_5: 0.5235  loss_dice_5: 3.877  loss_ce_6: 0.4179  loss_mask_6: 0.5219  loss_dice_6: 3.871  loss_ce_7: 0.4096  loss_mask_7: 0.5211  loss_dice_7: 3.88  loss_ce_8: 0.4261  loss_mask_8: 0.5218  loss_dice_8: 3.879  time: 1.4124  data_time: 0.0560  lr: 8.8998e-06  max_mem: 21164M
[01/18 20:23:29] d2.utils.events INFO:  eta: 13:32:11  iter: 4879  total_loss: 48.26  loss_ce: 0.3997  loss_mask: 0.5247  loss_dice: 3.867  loss_ce_0: 0.6962  loss_mask_0: 0.5017  loss_dice_0: 4.007  loss_ce_1: 0.433  loss_mask_1: 0.5198  loss_dice_1: 3.906  loss_ce_2: 0.4054  loss_mask_2: 0.5262  loss_dice_2: 3.877  loss_ce_3: 0.4044  loss_mask_3: 0.5267  loss_dice_3: 3.875  loss_ce_4: 0.3922  loss_mask_4: 0.5288  loss_dice_4: 3.871  loss_ce_5: 0.3937  loss_mask_5: 0.5264  loss_dice_5: 3.865  loss_ce_6: 0.3849  loss_mask_6: 0.5251  loss_dice_6: 3.865  loss_ce_7: 0.3827  loss_mask_7: 0.5252  loss_dice_7: 3.87  loss_ce_8: 0.3858  loss_mask_8: 0.5282  loss_dice_8: 3.868  time: 1.4123  data_time: 0.0561  lr: 8.8952e-06  max_mem: 21164M
[01/18 20:23:57] d2.utils.events INFO:  eta: 13:31:52  iter: 4899  total_loss: 48.62  loss_ce: 0.3838  loss_mask: 0.513  loss_dice: 3.895  loss_ce_0: 0.6939  loss_mask_0: 0.4897  loss_dice_0: 4.029  loss_ce_1: 0.4104  loss_mask_1: 0.5102  loss_dice_1: 3.93  loss_ce_2: 0.4024  loss_mask_2: 0.5133  loss_dice_2: 3.911  loss_ce_3: 0.3982  loss_mask_3: 0.5146  loss_dice_3: 3.903  loss_ce_4: 0.4063  loss_mask_4: 0.5148  loss_dice_4: 3.899  loss_ce_5: 0.4076  loss_mask_5: 0.5149  loss_dice_5: 3.896  loss_ce_6: 0.4023  loss_mask_6: 0.5164  loss_dice_6: 3.891  loss_ce_7: 0.3998  loss_mask_7: 0.518  loss_dice_7: 3.893  loss_ce_8: 0.4193  loss_mask_8: 0.5141  loss_dice_8: 3.892  time: 1.4123  data_time: 0.0546  lr: 8.8907e-06  max_mem: 21164M
[01/18 20:24:25] d2.utils.events INFO:  eta: 13:31:25  iter: 4919  total_loss: 48.08  loss_ce: 0.3893  loss_mask: 0.513  loss_dice: 3.845  loss_ce_0: 0.6868  loss_mask_0: 0.4869  loss_dice_0: 3.984  loss_ce_1: 0.3958  loss_mask_1: 0.5072  loss_dice_1: 3.876  loss_ce_2: 0.403  loss_mask_2: 0.5076  loss_dice_2: 3.855  loss_ce_3: 0.3914  loss_mask_3: 0.5094  loss_dice_3: 3.853  loss_ce_4: 0.3853  loss_mask_4: 0.5081  loss_dice_4: 3.84  loss_ce_5: 0.3761  loss_mask_5: 0.5063  loss_dice_5: 3.845  loss_ce_6: 0.3826  loss_mask_6: 0.5064  loss_dice_6: 3.84  loss_ce_7: 0.3817  loss_mask_7: 0.5084  loss_dice_7: 3.848  loss_ce_8: 0.3741  loss_mask_8: 0.5067  loss_dice_8: 3.847  time: 1.4122  data_time: 0.0500  lr: 8.8861e-06  max_mem: 21164M
[01/18 20:24:53] d2.utils.events INFO:  eta: 13:30:59  iter: 4939  total_loss: 48.3  loss_ce: 0.4037  loss_mask: 0.5228  loss_dice: 3.85  loss_ce_0: 0.6908  loss_mask_0: 0.4983  loss_dice_0: 3.991  loss_ce_1: 0.4104  loss_mask_1: 0.5166  loss_dice_1: 3.883  loss_ce_2: 0.4126  loss_mask_2: 0.5182  loss_dice_2: 3.869  loss_ce_3: 0.4018  loss_mask_3: 0.5211  loss_dice_3: 3.85  loss_ce_4: 0.4027  loss_mask_4: 0.5209  loss_dice_4: 3.855  loss_ce_5: 0.4055  loss_mask_5: 0.5239  loss_dice_5: 3.851  loss_ce_6: 0.4098  loss_mask_6: 0.5248  loss_dice_6: 3.852  loss_ce_7: 0.4026  loss_mask_7: 0.523  loss_dice_7: 3.853  loss_ce_8: 0.4053  loss_mask_8: 0.5227  loss_dice_8: 3.846  time: 1.4121  data_time: 0.0561  lr: 8.8815e-06  max_mem: 21164M
[01/18 20:25:21] d2.utils.events INFO:  eta: 13:30:30  iter: 4959  total_loss: 47.76  loss_ce: 0.3879  loss_mask: 0.5294  loss_dice: 3.83  loss_ce_0: 0.67  loss_mask_0: 0.5061  loss_dice_0: 3.965  loss_ce_1: 0.4006  loss_mask_1: 0.5306  loss_dice_1: 3.858  loss_ce_2: 0.3791  loss_mask_2: 0.5285  loss_dice_2: 3.833  loss_ce_3: 0.3842  loss_mask_3: 0.5277  loss_dice_3: 3.823  loss_ce_4: 0.3691  loss_mask_4: 0.5259  loss_dice_4: 3.829  loss_ce_5: 0.3793  loss_mask_5: 0.5275  loss_dice_5: 3.825  loss_ce_6: 0.3799  loss_mask_6: 0.5257  loss_dice_6: 3.833  loss_ce_7: 0.3798  loss_mask_7: 0.5287  loss_dice_7: 3.832  loss_ce_8: 0.3936  loss_mask_8: 0.5283  loss_dice_8: 3.822  time: 1.4120  data_time: 0.0534  lr: 8.877e-06  max_mem: 21164M
[01/18 20:25:48] d2.utils.events INFO:  eta: 13:29:59  iter: 4979  total_loss: 47.69  loss_ce: 0.3984  loss_mask: 0.5347  loss_dice: 3.8  loss_ce_0: 0.6851  loss_mask_0: 0.5199  loss_dice_0: 3.948  loss_ce_1: 0.413  loss_mask_1: 0.5359  loss_dice_1: 3.83  loss_ce_2: 0.4096  loss_mask_2: 0.537  loss_dice_2: 3.811  loss_ce_3: 0.3916  loss_mask_3: 0.5299  loss_dice_3: 3.806  loss_ce_4: 0.3977  loss_mask_4: 0.5359  loss_dice_4: 3.801  loss_ce_5: 0.3986  loss_mask_5: 0.5332  loss_dice_5: 3.796  loss_ce_6: 0.4068  loss_mask_6: 0.5377  loss_dice_6: 3.799  loss_ce_7: 0.3939  loss_mask_7: 0.5378  loss_dice_7: 3.801  loss_ce_8: 0.4037  loss_mask_8: 0.534  loss_dice_8: 3.799  time: 1.4118  data_time: 0.0570  lr: 8.8724e-06  max_mem: 21164M
[01/18 20:26:16] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/sceneflow_testing/model_0004999.pth
[01/18 20:26:17] d2.utils.events INFO:  eta: 13:28:57  iter: 4999  total_loss: 47.29  loss_ce: 0.3738  loss_mask: 0.5334  loss_dice: 3.768  loss_ce_0: 0.6637  loss_mask_0: 0.5016  loss_dice_0: 3.918  loss_ce_1: 0.3906  loss_mask_1: 0.5279  loss_dice_1: 3.803  loss_ce_2: 0.38  loss_mask_2: 0.5307  loss_dice_2: 3.785  loss_ce_3: 0.3699  loss_mask_3: 0.5342  loss_dice_3: 3.772  loss_ce_4: 0.357  loss_mask_4: 0.5316  loss_dice_4: 3.773  loss_ce_5: 0.3724  loss_mask_5: 0.5292  loss_dice_5: 3.77  loss_ce_6: 0.3678  loss_mask_6: 0.5327  loss_dice_6: 3.768  loss_ce_7: 0.362  loss_mask_7: 0.5299  loss_dice_7: 3.771  loss_ce_8: 0.38  loss_mask_8: 0.5306  loss_dice_8: 3.769  time: 1.4117  data_time: 0.0504  lr: 8.8679e-06  max_mem: 21164M
[01/18 20:26:44] d2.utils.events INFO:  eta: 13:28:29  iter: 5019  total_loss: 47.81  loss_ce: 0.3744  loss_mask: 0.5286  loss_dice: 3.838  loss_ce_0: 0.6759  loss_mask_0: 0.5096  loss_dice_0: 3.976  loss_ce_1: 0.4061  loss_mask_1: 0.5284  loss_dice_1: 3.874  loss_ce_2: 0.3897  loss_mask_2: 0.5278  loss_dice_2: 3.853  loss_ce_3: 0.3821  loss_mask_3: 0.5287  loss_dice_3: 3.843  loss_ce_4: 0.3692  loss_mask_4: 0.5286  loss_dice_4: 3.834  loss_ce_5: 0.3673  loss_mask_5: 0.5299  loss_dice_5: 3.836  loss_ce_6: 0.3637  loss_mask_6: 0.5298  loss_dice_6: 3.837  loss_ce_7: 0.375  loss_mask_7: 0.5283  loss_dice_7: 3.836  loss_ce_8: 0.3768  loss_mask_8: 0.5295  loss_dice_8: 3.829  time: 1.4115  data_time: 0.0562  lr: 8.8633e-06  max_mem: 21164M
[01/18 20:27:12] d2.utils.events INFO:  eta: 13:27:12  iter: 5039  total_loss: 48.37  loss_ce: 0.4073  loss_mask: 0.5293  loss_dice: 3.827  loss_ce_0: 0.6677  loss_mask_0: 0.4958  loss_dice_0: 3.972  loss_ce_1: 0.4268  loss_mask_1: 0.5206  loss_dice_1: 3.869  loss_ce_2: 0.4099  loss_mask_2: 0.5262  loss_dice_2: 3.85  loss_ce_3: 0.4141  loss_mask_3: 0.5271  loss_dice_3: 3.834  loss_ce_4: 0.3989  loss_mask_4: 0.5304  loss_dice_4: 3.832  loss_ce_5: 0.4127  loss_mask_5: 0.5298  loss_dice_5: 3.834  loss_ce_6: 0.3995  loss_mask_6: 0.5278  loss_dice_6: 3.832  loss_ce_7: 0.3999  loss_mask_7: 0.5279  loss_dice_7: 3.828  loss_ce_8: 0.4093  loss_mask_8: 0.5295  loss_dice_8: 3.825  time: 1.4114  data_time: 0.0539  lr: 8.8587e-06  max_mem: 21164M
[01/18 20:27:40] d2.utils.events INFO:  eta: 13:27:33  iter: 5059  total_loss: 47.88  loss_ce: 0.3979  loss_mask: 0.5109  loss_dice: 3.813  loss_ce_0: 0.685  loss_mask_0: 0.4824  loss_dice_0: 3.953  loss_ce_1: 0.4244  loss_mask_1: 0.5096  loss_dice_1: 3.85  loss_ce_2: 0.4083  loss_mask_2: 0.5075  loss_dice_2: 3.822  loss_ce_3: 0.4127  loss_mask_3: 0.5115  loss_dice_3: 3.817  loss_ce_4: 0.4078  loss_mask_4: 0.5099  loss_dice_4: 3.81  loss_ce_5: 0.3933  loss_mask_5: 0.5094  loss_dice_5: 3.814  loss_ce_6: 0.4046  loss_mask_6: 0.5085  loss_dice_6: 3.81  loss_ce_7: 0.406  loss_mask_7: 0.5095  loss_dice_7: 3.804  loss_ce_8: 0.3981  loss_mask_8: 0.5104  loss_dice_8: 3.813  time: 1.4113  data_time: 0.0530  lr: 8.8542e-06  max_mem: 21164M
[01/18 20:28:09] d2.utils.events INFO:  eta: 13:27:50  iter: 5079  total_loss: 48.08  loss_ce: 0.3864  loss_mask: 0.5258  loss_dice: 3.826  loss_ce_0: 0.6986  loss_mask_0: 0.5102  loss_dice_0: 3.958  loss_ce_1: 0.4379  loss_mask_1: 0.5294  loss_dice_1: 3.85  loss_ce_2: 0.4114  loss_mask_2: 0.5298  loss_dice_2: 3.83  loss_ce_3: 0.4007  loss_mask_3: 0.5262  loss_dice_3: 3.822  loss_ce_4: 0.3937  loss_mask_4: 0.5278  loss_dice_4: 3.827  loss_ce_5: 0.3906  loss_mask_5: 0.526  loss_dice_5: 3.824  loss_ce_6: 0.3856  loss_mask_6: 0.527  loss_dice_6: 3.822  loss_ce_7: 0.4013  loss_mask_7: 0.5302  loss_dice_7: 3.814  loss_ce_8: 0.3779  loss_mask_8: 0.5278  loss_dice_8: 3.818  time: 1.4114  data_time: 0.0566  lr: 8.8496e-06  max_mem: 21164M
[01/18 20:28:37] d2.utils.events INFO:  eta: 13:27:15  iter: 5099  total_loss: 48.03  loss_ce: 0.4002  loss_mask: 0.5261  loss_dice: 3.826  loss_ce_0: 0.6871  loss_mask_0: 0.4979  loss_dice_0: 3.964  loss_ce_1: 0.4213  loss_mask_1: 0.526  loss_dice_1: 3.843  loss_ce_2: 0.4083  loss_mask_2: 0.5259  loss_dice_2: 3.84  loss_ce_3: 0.4017  loss_mask_3: 0.5266  loss_dice_3: 3.839  loss_ce_4: 0.3963  loss_mask_4: 0.5251  loss_dice_4: 3.825  loss_ce_5: 0.394  loss_mask_5: 0.5248  loss_dice_5: 3.833  loss_ce_6: 0.4029  loss_mask_6: 0.5264  loss_dice_6: 3.824  loss_ce_7: 0.3976  loss_mask_7: 0.5243  loss_dice_7: 3.83  loss_ce_8: 0.4048  loss_mask_8: 0.526  loss_dice_8: 3.825  time: 1.4114  data_time: 0.0584  lr: 8.845e-06  max_mem: 21164M
[01/18 20:29:05] d2.utils.events INFO:  eta: 13:27:21  iter: 5119  total_loss: 48  loss_ce: 0.3783  loss_mask: 0.5234  loss_dice: 3.851  loss_ce_0: 0.6717  loss_mask_0: 0.4975  loss_dice_0: 3.984  loss_ce_1: 0.3993  loss_mask_1: 0.5158  loss_dice_1: 3.886  loss_ce_2: 0.3778  loss_mask_2: 0.5164  loss_dice_2: 3.869  loss_ce_3: 0.3964  loss_mask_3: 0.5159  loss_dice_3: 3.862  loss_ce_4: 0.405  loss_mask_4: 0.5154  loss_dice_4: 3.865  loss_ce_5: 0.4025  loss_mask_5: 0.5198  loss_dice_5: 3.859  loss_ce_6: 0.3805  loss_mask_6: 0.5183  loss_dice_6: 3.857  loss_ce_7: 0.397  loss_mask_7: 0.5209  loss_dice_7: 3.859  loss_ce_8: 0.3905  loss_mask_8: 0.5231  loss_dice_8: 3.848  time: 1.4114  data_time: 0.0593  lr: 8.8405e-06  max_mem: 21164M
[01/18 20:29:34] d2.utils.events INFO:  eta: 13:27:08  iter: 5139  total_loss: 48.1  loss_ce: 0.4055  loss_mask: 0.5329  loss_dice: 3.8  loss_ce_0: 0.6709  loss_mask_0: 0.5062  loss_dice_0: 3.943  loss_ce_1: 0.4333  loss_mask_1: 0.5328  loss_dice_1: 3.832  loss_ce_2: 0.4057  loss_mask_2: 0.5328  loss_dice_2: 3.818  loss_ce_3: 0.3863  loss_mask_3: 0.5354  loss_dice_3: 3.806  loss_ce_4: 0.4132  loss_mask_4: 0.5322  loss_dice_4: 3.8  loss_ce_5: 0.3921  loss_mask_5: 0.5302  loss_dice_5: 3.8  loss_ce_6: 0.4007  loss_mask_6: 0.5333  loss_dice_6: 3.798  loss_ce_7: 0.4079  loss_mask_7: 0.5312  loss_dice_7: 3.8  loss_ce_8: 0.4025  loss_mask_8: 0.5339  loss_dice_8: 3.803  time: 1.4115  data_time: 0.0593  lr: 8.8359e-06  max_mem: 21164M
[01/18 20:30:03] d2.utils.events INFO:  eta: 13:27:12  iter: 5159  total_loss: 47.91  loss_ce: 0.403  loss_mask: 0.5161  loss_dice: 3.808  loss_ce_0: 0.6738  loss_mask_0: 0.4908  loss_dice_0: 3.949  loss_ce_1: 0.4256  loss_mask_1: 0.5117  loss_dice_1: 3.842  loss_ce_2: 0.4136  loss_mask_2: 0.5134  loss_dice_2: 3.837  loss_ce_3: 0.3997  loss_mask_3: 0.5156  loss_dice_3: 3.813  loss_ce_4: 0.4017  loss_mask_4: 0.5157  loss_dice_4: 3.817  loss_ce_5: 0.3997  loss_mask_5: 0.5186  loss_dice_5: 3.818  loss_ce_6: 0.4041  loss_mask_6: 0.5184  loss_dice_6: 3.826  loss_ce_7: 0.4077  loss_mask_7: 0.5209  loss_dice_7: 3.817  loss_ce_8: 0.4119  loss_mask_8: 0.5155  loss_dice_8: 3.807  time: 1.4116  data_time: 0.0613  lr: 8.8314e-06  max_mem: 21164M
[01/18 20:30:31] d2.utils.events INFO:  eta: 13:27:17  iter: 5179  total_loss: 48.19  loss_ce: 0.4088  loss_mask: 0.5388  loss_dice: 3.829  loss_ce_0: 0.6577  loss_mask_0: 0.516  loss_dice_0: 3.96  loss_ce_1: 0.4322  loss_mask_1: 0.539  loss_dice_1: 3.853  loss_ce_2: 0.4158  loss_mask_2: 0.5408  loss_dice_2: 3.841  loss_ce_3: 0.4082  loss_mask_3: 0.5405  loss_dice_3: 3.83  loss_ce_4: 0.422  loss_mask_4: 0.5386  loss_dice_4: 3.824  loss_ce_5: 0.4253  loss_mask_5: 0.5381  loss_dice_5: 3.835  loss_ce_6: 0.3941  loss_mask_6: 0.5412  loss_dice_6: 3.831  loss_ce_7: 0.4046  loss_mask_7: 0.5364  loss_dice_7: 3.829  loss_ce_8: 0.4002  loss_mask_8: 0.537  loss_dice_8: 3.825  time: 1.4117  data_time: 0.0554  lr: 8.8268e-06  max_mem: 21164M
[01/18 20:31:01] d2.utils.events INFO:  eta: 13:27:14  iter: 5199  total_loss: 47.77  loss_ce: 0.3872  loss_mask: 0.5154  loss_dice: 3.808  loss_ce_0: 0.6743  loss_mask_0: 0.4925  loss_dice_0: 3.958  loss_ce_1: 0.4117  loss_mask_1: 0.515  loss_dice_1: 3.851  loss_ce_2: 0.3886  loss_mask_2: 0.5162  loss_dice_2: 3.833  loss_ce_3: 0.3827  loss_mask_3: 0.5158  loss_dice_3: 3.813  loss_ce_4: 0.391  loss_mask_4: 0.5169  loss_dice_4: 3.813  loss_ce_5: 0.393  loss_mask_5: 0.5161  loss_dice_5: 3.808  loss_ce_6: 0.406  loss_mask_6: 0.517  loss_dice_6: 3.799  loss_ce_7: 0.3943  loss_mask_7: 0.5138  loss_dice_7: 3.812  loss_ce_8: 0.382  loss_mask_8: 0.5167  loss_dice_8: 3.808  time: 1.4120  data_time: 0.0748  lr: 8.8222e-06  max_mem: 21164M
[01/18 20:31:30] d2.utils.events INFO:  eta: 13:27:35  iter: 5219  total_loss: 47.55  loss_ce: 0.3799  loss_mask: 0.5372  loss_dice: 3.771  loss_ce_0: 0.6827  loss_mask_0: 0.5059  loss_dice_0: 3.913  loss_ce_1: 0.3939  loss_mask_1: 0.5343  loss_dice_1: 3.806  loss_ce_2: 0.3681  loss_mask_2: 0.5345  loss_dice_2: 3.783  loss_ce_3: 0.3656  loss_mask_3: 0.5372  loss_dice_3: 3.775  loss_ce_4: 0.3838  loss_mask_4: 0.5335  loss_dice_4: 3.774  loss_ce_5: 0.3875  loss_mask_5: 0.5354  loss_dice_5: 3.772  loss_ce_6: 0.3754  loss_mask_6: 0.5372  loss_dice_6: 3.77  loss_ce_7: 0.3798  loss_mask_7: 0.5358  loss_dice_7: 3.769  loss_ce_8: 0.372  loss_mask_8: 0.5376  loss_dice_8: 3.77  time: 1.4122  data_time: 0.0681  lr: 8.8177e-06  max_mem: 21164M
[01/18 20:32:00] d2.utils.events INFO:  eta: 13:28:12  iter: 5239  total_loss: 47.8  loss_ce: 0.3881  loss_mask: 0.5219  loss_dice: 3.826  loss_ce_0: 0.6933  loss_mask_0: 0.4883  loss_dice_0: 3.953  loss_ce_1: 0.4251  loss_mask_1: 0.5128  loss_dice_1: 3.853  loss_ce_2: 0.3962  loss_mask_2: 0.5164  loss_dice_2: 3.839  loss_ce_3: 0.3966  loss_mask_3: 0.5194  loss_dice_3: 3.831  loss_ce_4: 0.3995  loss_mask_4: 0.5171  loss_dice_4: 3.824  loss_ce_5: 0.3962  loss_mask_5: 0.5208  loss_dice_5: 3.82  loss_ce_6: 0.3927  loss_mask_6: 0.5201  loss_dice_6: 3.82  loss_ce_7: 0.4003  loss_mask_7: 0.5199  loss_dice_7: 3.821  loss_ce_8: 0.4065  loss_mask_8: 0.5213  loss_dice_8: 3.829  time: 1.4125  data_time: 0.0693  lr: 8.8131e-06  max_mem: 21164M
[01/18 20:32:30] d2.utils.events INFO:  eta: 13:28:07  iter: 5259  total_loss: 47.98  loss_ce: 0.4205  loss_mask: 0.5179  loss_dice: 3.814  loss_ce_0: 0.6769  loss_mask_0: 0.4953  loss_dice_0: 3.944  loss_ce_1: 0.4425  loss_mask_1: 0.5173  loss_dice_1: 3.85  loss_ce_2: 0.4391  loss_mask_2: 0.5168  loss_dice_2: 3.833  loss_ce_3: 0.4142  loss_mask_3: 0.5151  loss_dice_3: 3.819  loss_ce_4: 0.4246  loss_mask_4: 0.5152  loss_dice_4: 3.818  loss_ce_5: 0.4179  loss_mask_5: 0.5172  loss_dice_5: 3.821  loss_ce_6: 0.41  loss_mask_6: 0.5163  loss_dice_6: 3.82  loss_ce_7: 0.4297  loss_mask_7: 0.518  loss_dice_7: 3.819  loss_ce_8: 0.4227  loss_mask_8: 0.5173  loss_dice_8: 3.819  time: 1.4127  data_time: 0.0642  lr: 8.8085e-06  max_mem: 21164M
[01/18 20:32:59] d2.utils.events INFO:  eta: 13:28:26  iter: 5279  total_loss: 47.98  loss_ce: 0.4475  loss_mask: 0.5138  loss_dice: 3.793  loss_ce_0: 0.7362  loss_mask_0: 0.4959  loss_dice_0: 3.918  loss_ce_1: 0.4358  loss_mask_1: 0.5142  loss_dice_1: 3.822  loss_ce_2: 0.4325  loss_mask_2: 0.5099  loss_dice_2: 3.809  loss_ce_3: 0.4577  loss_mask_3: 0.5097  loss_dice_3: 3.798  loss_ce_4: 0.4473  loss_mask_4: 0.5123  loss_dice_4: 3.798  loss_ce_5: 0.4387  loss_mask_5: 0.5136  loss_dice_5: 3.796  loss_ce_6: 0.4406  loss_mask_6: 0.5119  loss_dice_6: 3.796  loss_ce_7: 0.4438  loss_mask_7: 0.514  loss_dice_7: 3.79  loss_ce_8: 0.4464  loss_mask_8: 0.5144  loss_dice_8: 3.793  time: 1.4129  data_time: 0.0694  lr: 8.804e-06  max_mem: 21164M
[01/18 20:33:30] d2.utils.events INFO:  eta: 13:29:21  iter: 5299  total_loss: 47.91  loss_ce: 0.3921  loss_mask: 0.5009  loss_dice: 3.834  loss_ce_0: 0.681  loss_mask_0: 0.479  loss_dice_0: 3.969  loss_ce_1: 0.4144  loss_mask_1: 0.4968  loss_dice_1: 3.876  loss_ce_2: 0.4005  loss_mask_2: 0.4984  loss_dice_2: 3.842  loss_ce_3: 0.4016  loss_mask_3: 0.5006  loss_dice_3: 3.84  loss_ce_4: 0.3978  loss_mask_4: 0.5006  loss_dice_4: 3.836  loss_ce_5: 0.4002  loss_mask_5: 0.502  loss_dice_5: 3.839  loss_ce_6: 0.3904  loss_mask_6: 0.5003  loss_dice_6: 3.843  loss_ce_7: 0.3898  loss_mask_7: 0.5011  loss_dice_7: 3.842  loss_ce_8: 0.3876  loss_mask_8: 0.5015  loss_dice_8: 3.845  time: 1.4133  data_time: 0.0724  lr: 8.7994e-06  max_mem: 21164M
[01/18 20:34:00] d2.utils.events INFO:  eta: 13:29:16  iter: 5319  total_loss: 47.29  loss_ce: 0.3848  loss_mask: 0.5051  loss_dice: 3.772  loss_ce_0: 0.6312  loss_mask_0: 0.4803  loss_dice_0: 3.926  loss_ce_1: 0.3874  loss_mask_1: 0.4993  loss_dice_1: 3.815  loss_ce_2: 0.388  loss_mask_2: 0.5034  loss_dice_2: 3.781  loss_ce_3: 0.384  loss_mask_3: 0.5053  loss_dice_3: 3.772  loss_ce_4: 0.3658  loss_mask_4: 0.5026  loss_dice_4: 3.77  loss_ce_5: 0.388  loss_mask_5: 0.5017  loss_dice_5: 3.771  loss_ce_6: 0.3881  loss_mask_6: 0.5033  loss_dice_6: 3.78  loss_ce_7: 0.389  loss_mask_7: 0.503  loss_dice_7: 3.769  loss_ce_8: 0.3869  loss_mask_8: 0.503  loss_dice_8: 3.772  time: 1.4136  data_time: 0.0742  lr: 8.7949e-06  max_mem: 21164M
[01/18 20:34:29] d2.utils.events INFO:  eta: 13:30:10  iter: 5339  total_loss: 47.55  loss_ce: 0.4013  loss_mask: 0.5063  loss_dice: 3.775  loss_ce_0: 0.6918  loss_mask_0: 0.4783  loss_dice_0: 3.933  loss_ce_1: 0.4224  loss_mask_1: 0.5027  loss_dice_1: 3.804  loss_ce_2: 0.3958  loss_mask_2: 0.5021  loss_dice_2: 3.797  loss_ce_3: 0.4005  loss_mask_3: 0.5042  loss_dice_3: 3.783  loss_ce_4: 0.4007  loss_mask_4: 0.5044  loss_dice_4: 3.774  loss_ce_5: 0.4266  loss_mask_5: 0.5036  loss_dice_5: 3.776  loss_ce_6: 0.3964  loss_mask_6: 0.5022  loss_dice_6: 3.782  loss_ce_7: 0.4141  loss_mask_7: 0.5043  loss_dice_7: 3.778  loss_ce_8: 0.4086  loss_mask_8: 0.5047  loss_dice_8: 3.775  time: 1.4139  data_time: 0.0704  lr: 8.7903e-06  max_mem: 21164M
[01/18 20:34:59] d2.utils.events INFO:  eta: 13:30:23  iter: 5359  total_loss: 47.28  loss_ce: 0.3909  loss_mask: 0.5221  loss_dice: 3.771  loss_ce_0: 0.6904  loss_mask_0: 0.4944  loss_dice_0: 3.912  loss_ce_1: 0.436  loss_mask_1: 0.5179  loss_dice_1: 3.8  loss_ce_2: 0.4175  loss_mask_2: 0.5209  loss_dice_2: 3.775  loss_ce_3: 0.4046  loss_mask_3: 0.5165  loss_dice_3: 3.765  loss_ce_4: 0.4092  loss_mask_4: 0.5198  loss_dice_4: 3.765  loss_ce_5: 0.3889  loss_mask_5: 0.52  loss_dice_5: 3.772  loss_ce_6: 0.3776  loss_mask_6: 0.5245  loss_dice_6: 3.764  loss_ce_7: 0.3891  loss_mask_7: 0.5218  loss_dice_7: 3.769  loss_ce_8: 0.3803  loss_mask_8: 0.5195  loss_dice_8: 3.767  time: 1.4142  data_time: 0.0808  lr: 8.7857e-06  max_mem: 21164M
[01/18 20:35:29] d2.utils.events INFO:  eta: 13:31:01  iter: 5379  total_loss: 47.27  loss_ce: 0.3708  loss_mask: 0.5205  loss_dice: 3.789  loss_ce_0: 0.6884  loss_mask_0: 0.4907  loss_dice_0: 3.927  loss_ce_1: 0.4044  loss_mask_1: 0.5147  loss_dice_1: 3.82  loss_ce_2: 0.3825  loss_mask_2: 0.5215  loss_dice_2: 3.795  loss_ce_3: 0.3703  loss_mask_3: 0.5229  loss_dice_3: 3.797  loss_ce_4: 0.3727  loss_mask_4: 0.5201  loss_dice_4: 3.791  loss_ce_5: 0.3663  loss_mask_5: 0.5226  loss_dice_5: 3.784  loss_ce_6: 0.3813  loss_mask_6: 0.5186  loss_dice_6: 3.788  loss_ce_7: 0.3911  loss_mask_7: 0.5203  loss_dice_7: 3.785  loss_ce_8: 0.378  loss_mask_8: 0.5194  loss_dice_8: 3.785  time: 1.4144  data_time: 0.0692  lr: 8.7812e-06  max_mem: 21164M
[01/18 20:35:59] d2.utils.events INFO:  eta: 13:31:03  iter: 5399  total_loss: 47.53  loss_ce: 0.3749  loss_mask: 0.5163  loss_dice: 3.794  loss_ce_0: 0.653  loss_mask_0: 0.4902  loss_dice_0: 3.956  loss_ce_1: 0.3965  loss_mask_1: 0.5057  loss_dice_1: 3.85  loss_ce_2: 0.3646  loss_mask_2: 0.5082  loss_dice_2: 3.815  loss_ce_3: 0.3756  loss_mask_3: 0.5109  loss_dice_3: 3.814  loss_ce_4: 0.3705  loss_mask_4: 0.5131  loss_dice_4: 3.797  loss_ce_5: 0.3778  loss_mask_5: 0.5159  loss_dice_5: 3.803  loss_ce_6: 0.3886  loss_mask_6: 0.5152  loss_dice_6: 3.798  loss_ce_7: 0.373  loss_mask_7: 0.5162  loss_dice_7: 3.805  loss_ce_8: 0.384  loss_mask_8: 0.517  loss_dice_8: 3.794  time: 1.4147  data_time: 0.0678  lr: 8.7766e-06  max_mem: 21164M
[01/18 20:36:29] d2.utils.events INFO:  eta: 13:31:54  iter: 5419  total_loss: 47.43  loss_ce: 0.3924  loss_mask: 0.5186  loss_dice: 3.776  loss_ce_0: 0.7178  loss_mask_0: 0.4844  loss_dice_0: 3.9  loss_ce_1: 0.4198  loss_mask_1: 0.5123  loss_dice_1: 3.805  loss_ce_2: 0.4162  loss_mask_2: 0.5162  loss_dice_2: 3.775  loss_ce_3: 0.3971  loss_mask_3: 0.5155  loss_dice_3: 3.779  loss_ce_4: 0.4028  loss_mask_4: 0.5183  loss_dice_4: 3.777  loss_ce_5: 0.4044  loss_mask_5: 0.5196  loss_dice_5: 3.778  loss_ce_6: 0.4005  loss_mask_6: 0.519  loss_dice_6: 3.776  loss_ce_7: 0.3907  loss_mask_7: 0.5185  loss_dice_7: 3.767  loss_ce_8: 0.3971  loss_mask_8: 0.5197  loss_dice_8: 3.773  time: 1.4150  data_time: 0.0667  lr: 8.772e-06  max_mem: 21164M
[01/18 20:36:58] d2.utils.events INFO:  eta: 13:32:10  iter: 5439  total_loss: 47.22  loss_ce: 0.3883  loss_mask: 0.5115  loss_dice: 3.805  loss_ce_0: 0.6695  loss_mask_0: 0.4932  loss_dice_0: 3.905  loss_ce_1: 0.4298  loss_mask_1: 0.5129  loss_dice_1: 3.822  loss_ce_2: 0.3993  loss_mask_2: 0.5112  loss_dice_2: 3.811  loss_ce_3: 0.3927  loss_mask_3: 0.5128  loss_dice_3: 3.799  loss_ce_4: 0.3778  loss_mask_4: 0.5096  loss_dice_4: 3.804  loss_ce_5: 0.3963  loss_mask_5: 0.5085  loss_dice_5: 3.797  loss_ce_6: 0.3911  loss_mask_6: 0.5134  loss_dice_6: 3.792  loss_ce_7: 0.3903  loss_mask_7: 0.5134  loss_dice_7: 3.8  loss_ce_8: 0.4065  loss_mask_8: 0.5116  loss_dice_8: 3.793  time: 1.4152  data_time: 0.0672  lr: 8.7675e-06  max_mem: 21164M
[01/18 20:37:28] d2.utils.events INFO:  eta: 13:32:43  iter: 5459  total_loss: 47.67  loss_ce: 0.3928  loss_mask: 0.5058  loss_dice: 3.817  loss_ce_0: 0.6845  loss_mask_0: 0.4892  loss_dice_0: 3.949  loss_ce_1: 0.4291  loss_mask_1: 0.5102  loss_dice_1: 3.847  loss_ce_2: 0.4187  loss_mask_2: 0.5052  loss_dice_2: 3.824  loss_ce_3: 0.4018  loss_mask_3: 0.5061  loss_dice_3: 3.82  loss_ce_4: 0.3844  loss_mask_4: 0.5064  loss_dice_4: 3.822  loss_ce_5: 0.3816  loss_mask_5: 0.5075  loss_dice_5: 3.82  loss_ce_6: 0.387  loss_mask_6: 0.5055  loss_dice_6: 3.818  loss_ce_7: 0.384  loss_mask_7: 0.5068  loss_dice_7: 3.815  loss_ce_8: 0.3929  loss_mask_8: 0.5036  loss_dice_8: 3.81  time: 1.4155  data_time: 0.0699  lr: 8.7629e-06  max_mem: 21164M
[01/18 20:37:58] d2.utils.events INFO:  eta: 13:33:44  iter: 5479  total_loss: 48.71  loss_ce: 0.3859  loss_mask: 0.5314  loss_dice: 3.824  loss_ce_0: 0.6611  loss_mask_0: 0.5079  loss_dice_0: 3.946  loss_ce_1: 0.4357  loss_mask_1: 0.5381  loss_dice_1: 3.857  loss_ce_2: 0.4188  loss_mask_2: 0.5361  loss_dice_2: 3.833  loss_ce_3: 0.3893  loss_mask_3: 0.5341  loss_dice_3: 3.834  loss_ce_4: 0.3895  loss_mask_4: 0.532  loss_dice_4: 3.829  loss_ce_5: 0.3904  loss_mask_5: 0.5312  loss_dice_5: 3.835  loss_ce_6: 0.3752  loss_mask_6: 0.5321  loss_dice_6: 3.824  loss_ce_7: 0.3904  loss_mask_7: 0.5305  loss_dice_7: 3.84  loss_ce_8: 0.3841  loss_mask_8: 0.5326  loss_dice_8: 3.831  time: 1.4157  data_time: 0.0667  lr: 8.7583e-06  max_mem: 21164M
[01/18 20:38:27] d2.utils.events INFO:  eta: 13:34:38  iter: 5499  total_loss: 47.51  loss_ce: 0.3838  loss_mask: 0.5178  loss_dice: 3.785  loss_ce_0: 0.6775  loss_mask_0: 0.5055  loss_dice_0: 3.917  loss_ce_1: 0.4239  loss_mask_1: 0.5225  loss_dice_1: 3.811  loss_ce_2: 0.4031  loss_mask_2: 0.519  loss_dice_2: 3.806  loss_ce_3: 0.3897  loss_mask_3: 0.5172  loss_dice_3: 3.78  loss_ce_4: 0.382  loss_mask_4: 0.5197  loss_dice_4: 3.781  loss_ce_5: 0.3868  loss_mask_5: 0.5215  loss_dice_5: 3.784  loss_ce_6: 0.3777  loss_mask_6: 0.5204  loss_dice_6: 3.783  loss_ce_7: 0.3777  loss_mask_7: 0.5202  loss_dice_7: 3.777  loss_ce_8: 0.3823  loss_mask_8: 0.5212  loss_dice_8: 3.777  time: 1.4159  data_time: 0.0635  lr: 8.7538e-06  max_mem: 21164M
[01/18 20:38:57] d2.utils.events INFO:  eta: 13:35:35  iter: 5519  total_loss: 47.65  loss_ce: 0.4052  loss_mask: 0.5071  loss_dice: 3.786  loss_ce_0: 0.6982  loss_mask_0: 0.4858  loss_dice_0: 3.921  loss_ce_1: 0.4315  loss_mask_1: 0.5067  loss_dice_1: 3.811  loss_ce_2: 0.4224  loss_mask_2: 0.5089  loss_dice_2: 3.793  loss_ce_3: 0.4091  loss_mask_3: 0.5095  loss_dice_3: 3.787  loss_ce_4: 0.3977  loss_mask_4: 0.5073  loss_dice_4: 3.791  loss_ce_5: 0.3946  loss_mask_5: 0.5111  loss_dice_5: 3.778  loss_ce_6: 0.3978  loss_mask_6: 0.5106  loss_dice_6: 3.786  loss_ce_7: 0.4094  loss_mask_7: 0.5104  loss_dice_7: 3.788  loss_ce_8: 0.402  loss_mask_8: 0.5106  loss_dice_8: 3.784  time: 1.4162  data_time: 0.0771  lr: 8.7492e-06  max_mem: 21164M
[01/18 20:39:27] d2.utils.events INFO:  eta: 13:36:04  iter: 5539  total_loss: 47.56  loss_ce: 0.4068  loss_mask: 0.5179  loss_dice: 3.759  loss_ce_0: 0.668  loss_mask_0: 0.4906  loss_dice_0: 3.914  loss_ce_1: 0.4085  loss_mask_1: 0.5179  loss_dice_1: 3.811  loss_ce_2: 0.4101  loss_mask_2: 0.5178  loss_dice_2: 3.799  loss_ce_3: 0.4035  loss_mask_3: 0.5198  loss_dice_3: 3.78  loss_ce_4: 0.3942  loss_mask_4: 0.521  loss_dice_4: 3.763  loss_ce_5: 0.404  loss_mask_5: 0.5193  loss_dice_5: 3.767  loss_ce_6: 0.4074  loss_mask_6: 0.5205  loss_dice_6: 3.77  loss_ce_7: 0.3939  loss_mask_7: 0.5206  loss_dice_7: 3.766  loss_ce_8: 0.4035  loss_mask_8: 0.5201  loss_dice_8: 3.766  time: 1.4164  data_time: 0.0690  lr: 8.7446e-06  max_mem: 21164M
[01/18 20:39:57] d2.utils.events INFO:  eta: 13:36:58  iter: 5559  total_loss: 47.23  loss_ce: 0.3811  loss_mask: 0.5113  loss_dice: 3.775  loss_ce_0: 0.6705  loss_mask_0: 0.4829  loss_dice_0: 3.914  loss_ce_1: 0.3877  loss_mask_1: 0.5061  loss_dice_1: 3.805  loss_ce_2: 0.381  loss_mask_2: 0.5115  loss_dice_2: 3.793  loss_ce_3: 0.3807  loss_mask_3: 0.5098  loss_dice_3: 3.782  loss_ce_4: 0.3949  loss_mask_4: 0.5113  loss_dice_4: 3.78  loss_ce_5: 0.3761  loss_mask_5: 0.5118  loss_dice_5: 3.781  loss_ce_6: 0.3772  loss_mask_6: 0.5119  loss_dice_6: 3.775  loss_ce_7: 0.3695  loss_mask_7: 0.5115  loss_dice_7: 3.775  loss_ce_8: 0.3661  loss_mask_8: 0.5146  loss_dice_8: 3.779  time: 1.4168  data_time: 0.0700  lr: 8.7401e-06  max_mem: 21164M
[01/18 20:40:27] d2.utils.events INFO:  eta: 13:37:41  iter: 5579  total_loss: 47.22  loss_ce: 0.4045  loss_mask: 0.519  loss_dice: 3.748  loss_ce_0: 0.6568  loss_mask_0: 0.4873  loss_dice_0: 3.877  loss_ce_1: 0.421  loss_mask_1: 0.5123  loss_dice_1: 3.787  loss_ce_2: 0.4165  loss_mask_2: 0.5149  loss_dice_2: 3.761  loss_ce_3: 0.3895  loss_mask_3: 0.5173  loss_dice_3: 3.75  loss_ce_4: 0.41  loss_mask_4: 0.5175  loss_dice_4: 3.749  loss_ce_5: 0.3947  loss_mask_5: 0.5173  loss_dice_5: 3.755  loss_ce_6: 0.4228  loss_mask_6: 0.5166  loss_dice_6: 3.741  loss_ce_7: 0.4109  loss_mask_7: 0.5165  loss_dice_7: 3.749  loss_ce_8: 0.422  loss_mask_8: 0.5177  loss_dice_8: 3.742  time: 1.4170  data_time: 0.0700  lr: 8.7355e-06  max_mem: 21164M
[01/18 20:40:56] d2.utils.events INFO:  eta: 13:38:36  iter: 5599  total_loss: 47.26  loss_ce: 0.4128  loss_mask: 0.5188  loss_dice: 3.765  loss_ce_0: 0.6652  loss_mask_0: 0.4973  loss_dice_0: 3.891  loss_ce_1: 0.4244  loss_mask_1: 0.5154  loss_dice_1: 3.799  loss_ce_2: 0.4226  loss_mask_2: 0.518  loss_dice_2: 3.781  loss_ce_3: 0.3979  loss_mask_3: 0.5176  loss_dice_3: 3.767  loss_ce_4: 0.3919  loss_mask_4: 0.519  loss_dice_4: 3.77  loss_ce_5: 0.399  loss_mask_5: 0.5197  loss_dice_5: 3.769  loss_ce_6: 0.4044  loss_mask_6: 0.5181  loss_dice_6: 3.768  loss_ce_7: 0.4125  loss_mask_7: 0.5178  loss_dice_7: 3.768  loss_ce_8: 0.3952  loss_mask_8: 0.5168  loss_dice_8: 3.764  time: 1.4172  data_time: 0.0687  lr: 8.7309e-06  max_mem: 21164M
[01/18 20:41:26] d2.utils.events INFO:  eta: 13:39:01  iter: 5619  total_loss: 46.68  loss_ce: 0.3872  loss_mask: 0.5185  loss_dice: 3.73  loss_ce_0: 0.6692  loss_mask_0: 0.4914  loss_dice_0: 3.87  loss_ce_1: 0.418  loss_mask_1: 0.5166  loss_dice_1: 3.766  loss_ce_2: 0.375  loss_mask_2: 0.5202  loss_dice_2: 3.745  loss_ce_3: 0.3661  loss_mask_3: 0.5192  loss_dice_3: 3.728  loss_ce_4: 0.3706  loss_mask_4: 0.5177  loss_dice_4: 3.734  loss_ce_5: 0.3792  loss_mask_5: 0.5171  loss_dice_5: 3.728  loss_ce_6: 0.37  loss_mask_6: 0.5204  loss_dice_6: 3.735  loss_ce_7: 0.3736  loss_mask_7: 0.5151  loss_dice_7: 3.736  loss_ce_8: 0.3721  loss_mask_8: 0.5174  loss_dice_8: 3.735  time: 1.4174  data_time: 0.0731  lr: 8.7264e-06  max_mem: 21164M
[01/18 20:41:56] d2.utils.events INFO:  eta: 13:39:37  iter: 5639  total_loss: 46.6  loss_ce: 0.3679  loss_mask: 0.5063  loss_dice: 3.74  loss_ce_0: 0.6552  loss_mask_0: 0.4752  loss_dice_0: 3.874  loss_ce_1: 0.3913  loss_mask_1: 0.4999  loss_dice_1: 3.777  loss_ce_2: 0.38  loss_mask_2: 0.5044  loss_dice_2: 3.758  loss_ce_3: 0.3706  loss_mask_3: 0.5039  loss_dice_3: 3.744  loss_ce_4: 0.38  loss_mask_4: 0.5044  loss_dice_4: 3.747  loss_ce_5: 0.3525  loss_mask_5: 0.5047  loss_dice_5: 3.751  loss_ce_6: 0.3653  loss_mask_6: 0.5063  loss_dice_6: 3.743  loss_ce_7: 0.3532  loss_mask_7: 0.5061  loss_dice_7: 3.741  loss_ce_8: 0.3532  loss_mask_8: 0.506  loss_dice_8: 3.74  time: 1.4176  data_time: 0.0709  lr: 8.7218e-06  max_mem: 21308M
[01/18 20:42:25] d2.utils.events INFO:  eta: 13:41:17  iter: 5659  total_loss: 47.38  loss_ce: 0.3753  loss_mask: 0.5131  loss_dice: 3.764  loss_ce_0: 0.6628  loss_mask_0: 0.4905  loss_dice_0: 3.893  loss_ce_1: 0.4073  loss_mask_1: 0.5158  loss_dice_1: 3.807  loss_ce_2: 0.4094  loss_mask_2: 0.5151  loss_dice_2: 3.784  loss_ce_3: 0.4019  loss_mask_3: 0.5195  loss_dice_3: 3.772  loss_ce_4: 0.3895  loss_mask_4: 0.5124  loss_dice_4: 3.778  loss_ce_5: 0.3949  loss_mask_5: 0.5132  loss_dice_5: 3.774  loss_ce_6: 0.3951  loss_mask_6: 0.5148  loss_dice_6: 3.767  loss_ce_7: 0.3863  loss_mask_7: 0.5162  loss_dice_7: 3.762  loss_ce_8: 0.3845  loss_mask_8: 0.5143  loss_dice_8: 3.774  time: 1.4178  data_time: 0.0714  lr: 8.7172e-06  max_mem: 21308M
[01/18 20:42:55] d2.utils.events INFO:  eta: 13:43:15  iter: 5679  total_loss: 46.79  loss_ce: 0.3743  loss_mask: 0.5031  loss_dice: 3.724  loss_ce_0: 0.6644  loss_mask_0: 0.4729  loss_dice_0: 3.875  loss_ce_1: 0.3882  loss_mask_1: 0.5072  loss_dice_1: 3.778  loss_ce_2: 0.403  loss_mask_2: 0.5066  loss_dice_2: 3.748  loss_ce_3: 0.3604  loss_mask_3: 0.5057  loss_dice_3: 3.744  loss_ce_4: 0.3742  loss_mask_4: 0.5039  loss_dice_4: 3.733  loss_ce_5: 0.3741  loss_mask_5: 0.5043  loss_dice_5: 3.732  loss_ce_6: 0.3689  loss_mask_6: 0.5021  loss_dice_6: 3.73  loss_ce_7: 0.371  loss_mask_7: 0.5048  loss_dice_7: 3.733  loss_ce_8: 0.3743  loss_mask_8: 0.5025  loss_dice_8: 3.716  time: 1.4181  data_time: 0.0618  lr: 8.7126e-06  max_mem: 21308M
[01/18 20:43:25] d2.utils.events INFO:  eta: 13:45:02  iter: 5699  total_loss: 46.48  loss_ce: 0.3851  loss_mask: 0.5191  loss_dice: 3.725  loss_ce_0: 0.6683  loss_mask_0: 0.4915  loss_dice_0: 3.862  loss_ce_1: 0.4017  loss_mask_1: 0.5192  loss_dice_1: 3.766  loss_ce_2: 0.3928  loss_mask_2: 0.5181  loss_dice_2: 3.744  loss_ce_3: 0.3925  loss_mask_3: 0.5212  loss_dice_3: 3.733  loss_ce_4: 0.398  loss_mask_4: 0.5201  loss_dice_4: 3.735  loss_ce_5: 0.3872  loss_mask_5: 0.5175  loss_dice_5: 3.729  loss_ce_6: 0.3912  loss_mask_6: 0.5179  loss_dice_6: 3.734  loss_ce_7: 0.3795  loss_mask_7: 0.5168  loss_dice_7: 3.731  loss_ce_8: 0.3797  loss_mask_8: 0.5167  loss_dice_8: 3.727  time: 1.4183  data_time: 0.0663  lr: 8.7081e-06  max_mem: 21308M
[01/18 20:43:55] d2.utils.events INFO:  eta: 13:45:59  iter: 5719  total_loss: 46.5  loss_ce: 0.358  loss_mask: 0.5012  loss_dice: 3.744  loss_ce_0: 0.6558  loss_mask_0: 0.4733  loss_dice_0: 3.891  loss_ce_1: 0.3746  loss_mask_1: 0.5  loss_dice_1: 3.791  loss_ce_2: 0.3734  loss_mask_2: 0.5063  loss_dice_2: 3.763  loss_ce_3: 0.3578  loss_mask_3: 0.5059  loss_dice_3: 3.75  loss_ce_4: 0.3711  loss_mask_4: 0.5035  loss_dice_4: 3.746  loss_ce_5: 0.3643  loss_mask_5: 0.5047  loss_dice_5: 3.747  loss_ce_6: 0.3555  loss_mask_6: 0.5042  loss_dice_6: 3.746  loss_ce_7: 0.3412  loss_mask_7: 0.5043  loss_dice_7: 3.751  loss_ce_8: 0.3629  loss_mask_8: 0.5056  loss_dice_8: 3.739  time: 1.4186  data_time: 0.0724  lr: 8.7035e-06  max_mem: 21308M
[01/18 20:44:24] d2.utils.events INFO:  eta: 13:46:13  iter: 5739  total_loss: 46.53  loss_ce: 0.378  loss_mask: 0.5038  loss_dice: 3.724  loss_ce_0: 0.6598  loss_mask_0: 0.476  loss_dice_0: 3.875  loss_ce_1: 0.4048  loss_mask_1: 0.4973  loss_dice_1: 3.775  loss_ce_2: 0.3884  loss_mask_2: 0.4991  loss_dice_2: 3.75  loss_ce_3: 0.3679  loss_mask_3: 0.5027  loss_dice_3: 3.734  loss_ce_4: 0.3763  loss_mask_4: 0.5024  loss_dice_4: 3.731  loss_ce_5: 0.3715  loss_mask_5: 0.5034  loss_dice_5: 3.732  loss_ce_6: 0.3697  loss_mask_6: 0.5016  loss_dice_6: 3.722  loss_ce_7: 0.3836  loss_mask_7: 0.5011  loss_dice_7: 3.722  loss_ce_8: 0.3656  loss_mask_8: 0.5011  loss_dice_8: 3.728  time: 1.4188  data_time: 0.0602  lr: 8.6989e-06  max_mem: 21308M
[01/18 20:44:54] d2.utils.events INFO:  eta: 13:47:26  iter: 5759  total_loss: 46.64  loss_ce: 0.3822  loss_mask: 0.5128  loss_dice: 3.709  loss_ce_0: 0.6845  loss_mask_0: 0.4837  loss_dice_0: 3.838  loss_ce_1: 0.4052  loss_mask_1: 0.5136  loss_dice_1: 3.746  loss_ce_2: 0.3995  loss_mask_2: 0.5127  loss_dice_2: 3.726  loss_ce_3: 0.373  loss_mask_3: 0.5099  loss_dice_3: 3.723  loss_ce_4: 0.3726  loss_mask_4: 0.5133  loss_dice_4: 3.712  loss_ce_5: 0.3807  loss_mask_5: 0.5139  loss_dice_5: 3.717  loss_ce_6: 0.3751  loss_mask_6: 0.5146  loss_dice_6: 3.714  loss_ce_7: 0.3805  loss_mask_7: 0.5142  loss_dice_7: 3.72  loss_ce_8: 0.396  loss_mask_8: 0.5137  loss_dice_8: 3.711  time: 1.4189  data_time: 0.0760  lr: 8.6944e-06  max_mem: 21308M
[01/18 20:45:23] d2.utils.events INFO:  eta: 13:48:21  iter: 5779  total_loss: 46.46  loss_ce: 0.3827  loss_mask: 0.5123  loss_dice: 3.731  loss_ce_0: 0.6673  loss_mask_0: 0.4833  loss_dice_0: 3.864  loss_ce_1: 0.3866  loss_mask_1: 0.5062  loss_dice_1: 3.776  loss_ce_2: 0.3911  loss_mask_2: 0.5073  loss_dice_2: 3.753  loss_ce_3: 0.378  loss_mask_3: 0.5085  loss_dice_3: 3.734  loss_ce_4: 0.378  loss_mask_4: 0.5104  loss_dice_4: 3.729  loss_ce_5: 0.3759  loss_mask_5: 0.5126  loss_dice_5: 3.731  loss_ce_6: 0.3824  loss_mask_6: 0.5083  loss_dice_6: 3.725  loss_ce_7: 0.3781  loss_mask_7: 0.5107  loss_dice_7: 3.726  loss_ce_8: 0.3709  loss_mask_8: 0.5116  loss_dice_8: 3.72  time: 1.4192  data_time: 0.0702  lr: 8.6898e-06  max_mem: 21308M
[01/18 20:45:53] d2.utils.events INFO:  eta: 13:48:50  iter: 5799  total_loss: 46.61  loss_ce: 0.3748  loss_mask: 0.4845  loss_dice: 3.726  loss_ce_0: 0.6598  loss_mask_0: 0.4647  loss_dice_0: 3.871  loss_ce_1: 0.4003  loss_mask_1: 0.4883  loss_dice_1: 3.764  loss_ce_2: 0.378  loss_mask_2: 0.4913  loss_dice_2: 3.746  loss_ce_3: 0.3822  loss_mask_3: 0.489  loss_dice_3: 3.733  loss_ce_4: 0.3688  loss_mask_4: 0.4889  loss_dice_4: 3.737  loss_ce_5: 0.3681  loss_mask_5: 0.4848  loss_dice_5: 3.74  loss_ce_6: 0.3805  loss_mask_6: 0.4869  loss_dice_6: 3.727  loss_ce_7: 0.3713  loss_mask_7: 0.4883  loss_dice_7: 3.723  loss_ce_8: 0.3665  loss_mask_8: 0.4865  loss_dice_8: 3.725  time: 1.4194  data_time: 0.0688  lr: 8.6852e-06  max_mem: 21308M
[01/18 20:46:23] d2.utils.events INFO:  eta: 13:48:58  iter: 5819  total_loss: 46.31  loss_ce: 0.3721  loss_mask: 0.5056  loss_dice: 3.71  loss_ce_0: 0.6489  loss_mask_0: 0.488  loss_dice_0: 3.86  loss_ce_1: 0.3868  loss_mask_1: 0.5092  loss_dice_1: 3.758  loss_ce_2: 0.3787  loss_mask_2: 0.5067  loss_dice_2: 3.727  loss_ce_3: 0.3766  loss_mask_3: 0.51  loss_dice_3: 3.713  loss_ce_4: 0.3836  loss_mask_4: 0.5108  loss_dice_4: 3.707  loss_ce_5: 0.3746  loss_mask_5: 0.5092  loss_dice_5: 3.712  loss_ce_6: 0.3468  loss_mask_6: 0.5068  loss_dice_6: 3.707  loss_ce_7: 0.378  loss_mask_7: 0.5039  loss_dice_7: 3.704  loss_ce_8: 0.3718  loss_mask_8: 0.5061  loss_dice_8: 3.705  time: 1.4196  data_time: 0.0646  lr: 8.6807e-06  max_mem: 21308M
[01/18 20:46:52] d2.utils.events INFO:  eta: 13:49:14  iter: 5839  total_loss: 46.6  loss_ce: 0.4043  loss_mask: 0.5272  loss_dice: 3.699  loss_ce_0: 0.6906  loss_mask_0: 0.4995  loss_dice_0: 3.839  loss_ce_1: 0.4025  loss_mask_1: 0.5265  loss_dice_1: 3.731  loss_ce_2: 0.3919  loss_mask_2: 0.5269  loss_dice_2: 3.72  loss_ce_3: 0.3917  loss_mask_3: 0.5263  loss_dice_3: 3.706  loss_ce_4: 0.3917  loss_mask_4: 0.5251  loss_dice_4: 3.709  loss_ce_5: 0.3917  loss_mask_5: 0.5286  loss_dice_5: 3.712  loss_ce_6: 0.3857  loss_mask_6: 0.5267  loss_dice_6: 3.701  loss_ce_7: 0.3975  loss_mask_7: 0.5266  loss_dice_7: 3.7  loss_ce_8: 0.3842  loss_mask_8: 0.5263  loss_dice_8: 3.7  time: 1.4198  data_time: 0.0710  lr: 8.6761e-06  max_mem: 21308M
[01/18 20:47:22] d2.utils.events INFO:  eta: 13:50:28  iter: 5859  total_loss: 46.88  loss_ce: 0.3981  loss_mask: 0.5021  loss_dice: 3.737  loss_ce_0: 0.6568  loss_mask_0: 0.476  loss_dice_0: 3.864  loss_ce_1: 0.434  loss_mask_1: 0.5004  loss_dice_1: 3.777  loss_ce_2: 0.412  loss_mask_2: 0.5052  loss_dice_2: 3.743  loss_ce_3: 0.4095  loss_mask_3: 0.5041  loss_dice_3: 3.744  loss_ce_4: 0.3877  loss_mask_4: 0.5052  loss_dice_4: 3.739  loss_ce_5: 0.4005  loss_mask_5: 0.5046  loss_dice_5: 3.743  loss_ce_6: 0.3869  loss_mask_6: 0.5042  loss_dice_6: 3.743  loss_ce_7: 0.3847  loss_mask_7: 0.5035  loss_dice_7: 3.737  loss_ce_8: 0.4057  loss_mask_8: 0.505  loss_dice_8: 3.746  time: 1.4201  data_time: 0.0681  lr: 8.6715e-06  max_mem: 21308M
[01/18 20:47:52] d2.utils.events INFO:  eta: 13:50:32  iter: 5879  total_loss: 46.48  loss_ce: 0.3809  loss_mask: 0.5177  loss_dice: 3.703  loss_ce_0: 0.615  loss_mask_0: 0.4937  loss_dice_0: 3.842  loss_ce_1: 0.3781  loss_mask_1: 0.5182  loss_dice_1: 3.753  loss_ce_2: 0.3918  loss_mask_2: 0.5164  loss_dice_2: 3.713  loss_ce_3: 0.3719  loss_mask_3: 0.5158  loss_dice_3: 3.715  loss_ce_4: 0.3797  loss_mask_4: 0.5161  loss_dice_4: 3.71  loss_ce_5: 0.3894  loss_mask_5: 0.5156  loss_dice_5: 3.705  loss_ce_6: 0.3806  loss_mask_6: 0.5189  loss_dice_6: 3.695  loss_ce_7: 0.3839  loss_mask_7: 0.5194  loss_dice_7: 3.701  loss_ce_8: 0.3675  loss_mask_8: 0.517  loss_dice_8: 3.712  time: 1.4202  data_time: 0.0719  lr: 8.6669e-06  max_mem: 21308M
[01/18 20:48:22] d2.utils.events INFO:  eta: 13:51:08  iter: 5899  total_loss: 46.07  loss_ce: 0.3653  loss_mask: 0.5024  loss_dice: 3.696  loss_ce_0: 0.6402  loss_mask_0: 0.475  loss_dice_0: 3.827  loss_ce_1: 0.3923  loss_mask_1: 0.5017  loss_dice_1: 3.734  loss_ce_2: 0.3875  loss_mask_2: 0.5022  loss_dice_2: 3.7  loss_ce_3: 0.3579  loss_mask_3: 0.5012  loss_dice_3: 3.702  loss_ce_4: 0.346  loss_mask_4: 0.499  loss_dice_4: 3.699  loss_ce_5: 0.352  loss_mask_5: 0.4994  loss_dice_5: 3.695  loss_ce_6: 0.3612  loss_mask_6: 0.5003  loss_dice_6: 3.693  loss_ce_7: 0.349  loss_mask_7: 0.5003  loss_dice_7: 3.694  loss_ce_8: 0.3528  loss_mask_8: 0.5029  loss_dice_8: 3.686  time: 1.4204  data_time: 0.0693  lr: 8.6624e-06  max_mem: 21308M
[01/18 20:48:51] d2.utils.events INFO:  eta: 13:51:13  iter: 5919  total_loss: 46.66  loss_ce: 0.4023  loss_mask: 0.5008  loss_dice: 3.697  loss_ce_0: 0.6875  loss_mask_0: 0.4752  loss_dice_0: 3.849  loss_ce_1: 0.4161  loss_mask_1: 0.4945  loss_dice_1: 3.747  loss_ce_2: 0.4037  loss_mask_2: 0.4982  loss_dice_2: 3.718  loss_ce_3: 0.3941  loss_mask_3: 0.5016  loss_dice_3: 3.707  loss_ce_4: 0.4022  loss_mask_4: 0.502  loss_dice_4: 3.711  loss_ce_5: 0.3905  loss_mask_5: 0.5011  loss_dice_5: 3.713  loss_ce_6: 0.3906  loss_mask_6: 0.5001  loss_dice_6: 3.705  loss_ce_7: 0.3891  loss_mask_7: 0.5018  loss_dice_7: 3.708  loss_ce_8: 0.3972  loss_mask_8: 0.4997  loss_dice_8: 3.704  time: 1.4206  data_time: 0.0658  lr: 8.6578e-06  max_mem: 21308M
[01/18 20:49:21] d2.utils.events INFO:  eta: 13:52:07  iter: 5939  total_loss: 46.42  loss_ce: 0.3927  loss_mask: 0.5018  loss_dice: 3.702  loss_ce_0: 0.699  loss_mask_0: 0.4758  loss_dice_0: 3.853  loss_ce_1: 0.4161  loss_mask_1: 0.4969  loss_dice_1: 3.739  loss_ce_2: 0.4039  loss_mask_2: 0.5022  loss_dice_2: 3.714  loss_ce_3: 0.3744  loss_mask_3: 0.4998  loss_dice_3: 3.711  loss_ce_4: 0.3801  loss_mask_4: 0.5009  loss_dice_4: 3.71  loss_ce_5: 0.3996  loss_mask_5: 0.503  loss_dice_5: 3.697  loss_ce_6: 0.3821  loss_mask_6: 0.5022  loss_dice_6: 3.712  loss_ce_7: 0.3958  loss_mask_7: 0.5024  loss_dice_7: 3.71  loss_ce_8: 0.3828  loss_mask_8: 0.5018  loss_dice_8: 3.701  time: 1.4208  data_time: 0.0711  lr: 8.6532e-06  max_mem: 21308M
[01/18 20:49:50] d2.utils.events INFO:  eta: 13:51:51  iter: 5959  total_loss: 46.22  loss_ce: 0.3823  loss_mask: 0.5029  loss_dice: 3.692  loss_ce_0: 0.6787  loss_mask_0: 0.4784  loss_dice_0: 3.823  loss_ce_1: 0.4212  loss_mask_1: 0.5043  loss_dice_1: 3.729  loss_ce_2: 0.3879  loss_mask_2: 0.5086  loss_dice_2: 3.705  loss_ce_3: 0.381  loss_mask_3: 0.5066  loss_dice_3: 3.693  loss_ce_4: 0.3844  loss_mask_4: 0.5072  loss_dice_4: 3.687  loss_ce_5: 0.3869  loss_mask_5: 0.5052  loss_dice_5: 3.688  loss_ce_6: 0.3893  loss_mask_6: 0.5035  loss_dice_6: 3.696  loss_ce_7: 0.3889  loss_mask_7: 0.5057  loss_dice_7: 3.686  loss_ce_8: 0.3947  loss_mask_8: 0.5051  loss_dice_8: 3.686  time: 1.4210  data_time: 0.0718  lr: 8.6486e-06  max_mem: 21308M
[01/18 20:50:21] d2.utils.events INFO:  eta: 13:52:04  iter: 5979  total_loss: 46.5  loss_ce: 0.3656  loss_mask: 0.4945  loss_dice: 3.728  loss_ce_0: 0.6787  loss_mask_0: 0.4658  loss_dice_0: 3.851  loss_ce_1: 0.3864  loss_mask_1: 0.4945  loss_dice_1: 3.764  loss_ce_2: 0.3769  loss_mask_2: 0.4959  loss_dice_2: 3.745  loss_ce_3: 0.3842  loss_mask_3: 0.5003  loss_dice_3: 3.73  loss_ce_4: 0.3689  loss_mask_4: 0.4949  loss_dice_4: 3.732  loss_ce_5: 0.3774  loss_mask_5: 0.4948  loss_dice_5: 3.733  loss_ce_6: 0.3848  loss_mask_6: 0.4906  loss_dice_6: 3.728  loss_ce_7: 0.3756  loss_mask_7: 0.49  loss_dice_7: 3.729  loss_ce_8: 0.3723  loss_mask_8: 0.4922  loss_dice_8: 3.724  time: 1.4213  data_time: 0.0748  lr: 8.6441e-06  max_mem: 21308M
[01/18 20:50:50] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 20:50:51] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 20:50:51] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 20:57:46] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 3.0815127000209444, 'error_1pix': 0.3136457029875549, 'error_3pix': 0.13320035740065786, 'mIoU': 10.291716640451646, 'fwIoU': 25.056776588078904, 'IoU-0': nan, 'IoU-1': 94.53048739286587, 'IoU-2': 43.313714609583116, 'IoU-3': 47.11826003913601, 'IoU-4': 44.61735260413428, 'IoU-5': 38.0637547283854, 'IoU-6': 34.55095323893809, 'IoU-7': 28.593177981892715, 'IoU-8': 7.66121634720254, 'IoU-9': 11.123617655212811, 'IoU-10': 15.609882263401689, 'IoU-11': 23.7320879932148, 'IoU-12': 18.967826081440858, 'IoU-13': 21.63729764756741, 'IoU-14': 17.45224837209054, 'IoU-15': 22.37775833629048, 'IoU-16': 17.356966476513374, 'IoU-17': 18.1625439326375, 'IoU-18': 19.526061409199308, 'IoU-19': 16.038911854728084, 'IoU-20': 17.807889838551283, 'IoU-21': 21.196480775128006, 'IoU-22': 19.942313773638055, 'IoU-23': 19.51312302114669, 'IoU-24': 19.901309848851135, 'IoU-25': 19.99852081721337, 'IoU-26': 18.913266396503246, 'IoU-27': 20.552431241983758, 'IoU-28': 19.856553388295673, 'IoU-29': 19.747135410030925, 'IoU-30': 21.51726490247557, 'IoU-31': 22.037629662771952, 'IoU-32': 21.71054159248036, 'IoU-33': 21.316935958754378, 'IoU-34': 19.768296454254795, 'IoU-35': 21.591215883510497, 'IoU-36': 21.844269726620137, 'IoU-37': 19.800548645065557, 'IoU-38': 19.36779429107612, 'IoU-39': 20.12197454447715, 'IoU-40': 18.6350374152189, 'IoU-41': 20.340756567265984, 'IoU-42': 19.52253617607167, 'IoU-43': 18.659473108040494, 'IoU-44': 20.67186089489779, 'IoU-45': 17.04510254214814, 'IoU-46': 19.37686127089691, 'IoU-47': 15.810521660140104, 'IoU-48': 20.270620658115728, 'IoU-49': 16.84343761899456, 'IoU-50': 19.792449974950323, 'IoU-51': 16.2799023536737, 'IoU-52': 17.824808010801085, 'IoU-53': 19.950421468557312, 'IoU-54': 13.849275779504252, 'IoU-55': 19.83789414051649, 'IoU-56': 16.880670613717967, 'IoU-57': 16.5404383205546, 'IoU-58': 15.30021065138764, 'IoU-59': 16.324863407832243, 'IoU-60': 12.046545156489156, 'IoU-61': 14.691169470105967, 'IoU-62': 15.498227982699689, 'IoU-63': 15.37888948844126, 'IoU-64': 16.23296911318601, 'IoU-65': 13.341950491863608, 'IoU-66': 13.944812888268329, 'IoU-67': 13.679410456687313, 'IoU-68': 12.30476446903034, 'IoU-69': 14.04965935039398, 'IoU-70': 13.829605580409945, 'IoU-71': 13.997455337175039, 'IoU-72': 10.529744355514385, 'IoU-73': 10.913734811242374, 'IoU-74': 14.29473275472935, 'IoU-75': 10.340246249519105, 'IoU-76': 12.237816287174773, 'IoU-77': 10.956595954352283, 'IoU-78': 11.114029003876889, 'IoU-79': 6.464118930821515, 'IoU-80': 9.095282972791528, 'IoU-81': 10.076053496731395, 'IoU-82': 8.727645486974497, 'IoU-83': 10.562397315004743, 'IoU-84': 7.609809189951862, 'IoU-85': 9.554713363201678, 'IoU-86': 8.260234706662517, 'IoU-87': 9.019352158212362, 'IoU-88': 6.570188253784297, 'IoU-89': 9.740429945801482, 'IoU-90': 9.299015560528828, 'IoU-91': 8.616478286666004, 'IoU-92': 8.43393992426743, 'IoU-93': 10.193975366360986, 'IoU-94': 4.612159770669709, 'IoU-95': 10.58383714650895, 'IoU-96': 9.22043936508701, 'IoU-97': 6.348827186616088, 'IoU-98': 11.846481074754601, 'IoU-99': 8.033462407054676, 'IoU-100': 8.52784065248685, 'IoU-101': 5.707602777864177, 'IoU-102': 8.671365596661996, 'IoU-103': 8.81752063950539, 'IoU-104': 10.499479591466505, 'IoU-105': 7.205412521756582, 'IoU-106': 8.071402101767308, 'IoU-107': 3.528073053323303, 'IoU-108': 10.729467846374193, 'IoU-109': 6.729563375563679, 'IoU-110': 7.0735771707838495, 'IoU-111': 6.415847929969947, 'IoU-112': 6.568968661290936, 'IoU-113': 5.335470485322645, 'IoU-114': 4.913530452973016, 'IoU-115': 3.3049901693254724, 'IoU-116': 4.9714441766305315, 'IoU-117': 3.596771402384701, 'IoU-118': 4.822404680193494, 'IoU-119': 3.777427937946867, 'IoU-120': 4.480416593814255, 'IoU-121': 3.3192217008597513, 'IoU-122': 3.0841998270596345, 'IoU-123': 3.4528728064412166, 'IoU-124': 1.8605709841315927, 'IoU-125': 3.4362261550228186, 'IoU-126': 5.181672947934239, 'IoU-127': 3.4477014011897733, 'IoU-128': 1.6272796226202793, 'IoU-129': 2.6818101298004935, 'IoU-130': 3.029493595018801, 'IoU-131': 2.5789155146866416, 'IoU-132': 2.9064042398559202, 'IoU-133': 1.3756525661287566, 'IoU-134': 3.7982584118967084, 'IoU-135': 3.3705612526654285, 'IoU-136': 4.695945340300995, 'IoU-137': 2.442262900581227, 'IoU-138': 1.534358651881601, 'IoU-139': 2.140950452246224, 'IoU-140': 2.5685990362277007, 'IoU-141': 3.937560973912408, 'IoU-142': 1.5573331756147328, 'IoU-143': 1.463058345901748, 'IoU-144': 1.2639665935978779, 'IoU-145': 1.936957802286415, 'IoU-146': 2.418945125781869, 'IoU-147': 0.9657453387198234, 'IoU-148': 2.375706363578181, 'IoU-149': 2.00301128616928, 'IoU-150': 0.4317217989144387, 'IoU-151': 1.9214938987264907, 'IoU-152': 1.5992137028656845, 'IoU-153': 0.2293287576733992, 'IoU-154': 0.8103593980653655, 'IoU-155': 0.7114021268215833, 'IoU-156': 0.14440907516954427, 'IoU-157': 1.3092528424025078, 'IoU-158': 0.5296061510179964, 'IoU-159': 1.6710006706184106, 'IoU-160': 1.6117412374457722, 'IoU-161': 1.344473263738154, 'IoU-162': 0.9207184991873005, 'IoU-163': 1.5824068814412076, 'IoU-164': 1.4847537328922236, 'IoU-165': 1.0723237611294596, 'IoU-166': 0.7262451223708389, 'IoU-167': 0.12667269711039383, 'IoU-168': 1.4671930925314998, 'IoU-169': 0.0, 'IoU-170': 1.313667219882207, 'IoU-171': 0.4485537320154772, 'IoU-172': 0.8487741979460147, 'IoU-173': 1.5198345547609868, 'IoU-174': 0.020954271741388773, 'IoU-175': 2.0650214617348053, 'IoU-176': 0.0, 'IoU-177': 0.048140788278260994, 'IoU-178': 0.699866400284359, 'IoU-179': 0.0, 'IoU-180': 0.04092722450608742, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.09327579005986357, 'IoU-185': 0.0, 'IoU-186': 0.016344867361401363, 'IoU-187': 0.0, 'IoU-188': 0.03200590878315997, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.01613259956025656, 'IoU-192': 0.0, 'mACC': 17.401273960898113, 'pACC': 36.05842304626676, 'ACC-0': nan, 'ACC-1': 97.9231734079678, 'ACC-2': 64.8289490811412, 'ACC-3': 58.14613946588223, 'ACC-4': 67.3510902637257, 'ACC-5': 56.55045506696988, 'ACC-6': 54.00586716611737, 'ACC-7': 47.559899508114825, 'ACC-8': 8.833601497723102, 'ACC-9': 13.725192226078994, 'ACC-10': 22.304424641940273, 'ACC-11': 39.06939230829605, 'ACC-12': 28.008638115718682, 'ACC-13': 41.006193204210476, 'ACC-14': 28.135646091333218, 'ACC-15': 40.37235549142063, 'ACC-16': 26.79022898352062, 'ACC-17': 35.54951327049878, 'ACC-18': 32.106526566947494, 'ACC-19': 28.246356748313023, 'ACC-20': 26.72136975752894, 'ACC-21': 37.23548643653572, 'ACC-22': 29.719352205287127, 'ACC-23': 34.48064734361595, 'ACC-24': 35.855325796119054, 'ACC-25': 34.68494286370832, 'ACC-26': 35.668948655628476, 'ACC-27': 32.01514796516357, 'ACC-28': 32.60909417168714, 'ACC-29': 31.521008555623055, 'ACC-30': 34.32137871517639, 'ACC-31': 39.29710742048248, 'ACC-32': 34.41908580148, 'ACC-33': 39.54713701643833, 'ACC-34': 31.28070899301226, 'ACC-35': 33.47361147333828, 'ACC-36': 38.76507063416084, 'ACC-37': 32.862440998072934, 'ACC-38': 34.00339545010835, 'ACC-39': 31.873566684371173, 'ACC-40': 27.57326384978405, 'ACC-41': 35.04139760237017, 'ACC-42': 32.98438512535838, 'ACC-43': 31.600040732356703, 'ACC-44': 33.65717009986101, 'ACC-45': 25.617526351218068, 'ACC-46': 35.530762282382135, 'ACC-47': 24.74616108917932, 'ACC-48': 35.54761387785395, 'ACC-49': 27.09637798946413, 'ACC-50': 33.587936601167875, 'ACC-51': 28.566853336261484, 'ACC-52': 26.567739831551922, 'ACC-53': 35.52174609821285, 'ACC-54': 20.794922795771782, 'ACC-55': 36.5319767293925, 'ACC-56': 27.874417486338242, 'ACC-57': 28.435529531252858, 'ACC-58': 25.33107137820505, 'ACC-59': 30.79341043848561, 'ACC-60': 18.413906305108167, 'ACC-61': 25.219410418180267, 'ACC-62': 26.66204821092965, 'ACC-63': 26.369782282448462, 'ACC-64': 28.690469069881264, 'ACC-65': 24.1207347393796, 'ACC-66': 22.474142805222012, 'ACC-67': 23.877726740535827, 'ACC-68': 20.60648431261145, 'ACC-69': 24.50477113800716, 'ACC-70': 24.084725917635712, 'ACC-71': 25.668471426594635, 'ACC-72': 21.46975536484128, 'ACC-73': 22.42025547066189, 'ACC-74': 26.875466965248474, 'ACC-75': 17.70431312852243, 'ACC-76': 27.57629654670779, 'ACC-77': 24.740035617451024, 'ACC-78': 24.034639721210453, 'ACC-79': 10.367612063666243, 'ACC-80': 17.400628160443983, 'ACC-81': 20.741326756171908, 'ACC-82': 14.264493003920578, 'ACC-83': 21.480222934044317, 'ACC-84': 13.309496084444925, 'ACC-85': 18.738846895739567, 'ACC-86': 14.52871390565681, 'ACC-87': 18.825359282521394, 'ACC-88': 10.49980104182194, 'ACC-89': 17.378985568432675, 'ACC-90': 18.409896911299114, 'ACC-91': 14.343086124786053, 'ACC-92': 13.639826181648681, 'ACC-93': 21.68882296777315, 'ACC-94': 5.993538514685525, 'ACC-95': 23.589412249857556, 'ACC-96': 14.281227450590512, 'ACC-97': 10.59796477520571, 'ACC-98': 23.25597979057983, 'ACC-99': 12.968458207954756, 'ACC-100': 15.442724995479045, 'ACC-101': 8.045986646514356, 'ACC-102': 18.3343452650657, 'ACC-103': 15.86346462642864, 'ACC-104': 22.70303238975923, 'ACC-105': 13.02026202697909, 'ACC-106': 13.49038963041397, 'ACC-107': 4.894091397638909, 'ACC-108': 25.655429831802607, 'ACC-109': 12.603592148924921, 'ACC-110': 18.251434961605387, 'ACC-111': 12.134485742338871, 'ACC-112': 13.485735105993237, 'ACC-113': 10.421176923437036, 'ACC-114': 11.066265743001907, 'ACC-115': 5.368536977733676, 'ACC-116': 9.050788330600495, 'ACC-117': 6.7648214657401144, 'ACC-118': 13.26537338712691, 'ACC-119': 6.92504558151983, 'ACC-120': 7.259941948927706, 'ACC-121': 5.56683761599944, 'ACC-122': 6.022200835951579, 'ACC-123': 6.158655848295435, 'ACC-124': 3.0177917970316996, 'ACC-125': 6.670542538692552, 'ACC-126': 11.867708266924106, 'ACC-127': 7.929298002971713, 'ACC-128': 2.416540735292862, 'ACC-129': 3.885579385513809, 'ACC-130': 5.610187724272075, 'ACC-131': 5.338027916287026, 'ACC-132': 5.135299065389242, 'ACC-133': 2.1250348717739356, 'ACC-134': 6.003205514864283, 'ACC-135': 7.2721766147882105, 'ACC-136': 12.204010203130823, 'ACC-137': 8.834414451957196, 'ACC-138': 2.152210193669569, 'ACC-139': 3.473818059885895, 'ACC-140': 3.8360110454589877, 'ACC-141': 7.61858756957547, 'ACC-142': 2.299528147408741, 'ACC-143': 2.078980781828328, 'ACC-144': 1.9712996389891695, 'ACC-145': 4.185424539904738, 'ACC-146': 6.474423705192936, 'ACC-147': 1.1446791639236646, 'ACC-148': 4.798531630120593, 'ACC-149': 4.456179030067876, 'ACC-150': 0.4890510720662408, 'ACC-151': 7.567865984995999, 'ACC-152': 2.139599770719536, 'ACC-153': 0.24059161948734858, 'ACC-154': 1.0493537967304123, 'ACC-155': 0.8548967985741859, 'ACC-156': 0.16767179248514935, 'ACC-157': 3.23723039525923, 'ACC-158': 0.6147757888987525, 'ACC-159': 3.2039740619869743, 'ACC-160': 5.392933086006424, 'ACC-161': 3.9617835468171205, 'ACC-162': 2.1429570277981917, 'ACC-163': 2.7126100827464543, 'ACC-164': 2.8014104560199646, 'ACC-165': 1.9934757819373816, 'ACC-166': 0.8326967791758653, 'ACC-167': 0.13184705741340047, 'ACC-168': 2.9643434840706098, 'ACC-169': 0.0, 'ACC-170': 7.7819540866306065, 'ACC-171': 0.6805545095690924, 'ACC-172': 1.1069748490573028, 'ACC-173': 3.54520927327255, 'ACC-174': 0.021995187154810702, 'ACC-175': 3.5943344075107375, 'ACC-176': 0.0, 'ACC-177': 0.04908935554534398, 'ACC-178': 0.8823455557251053, 'ACC-179': 0.0, 'ACC-180': 0.0427545802431508, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.09480751950983098, 'ACC-185': 0.0, 'ACC-186': 0.016524516480844544, 'ACC-187': 0.0, 'ACC-188': 0.03278721601226746, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.016182707993474717, 'ACC-192': 0.0})])
[01/18 20:57:46] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/18 20:57:46] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/18 20:57:46] d2.evaluation.testing INFO: copypaste: 3.0815,0.3136,0.1332,10.2917,25.0568,17.4013,36.0584
[01/18 20:57:46] d2.utils.events INFO:  eta: 13:52:09  iter: 5999  total_loss: 46.65  loss_ce: 0.3893  loss_mask: 0.514  loss_dice: 3.699  loss_ce_0: 0.6899  loss_mask_0: 0.4898  loss_dice_0: 3.835  loss_ce_1: 0.4062  loss_mask_1: 0.5138  loss_dice_1: 3.738  loss_ce_2: 0.404  loss_mask_2: 0.514  loss_dice_2: 3.718  loss_ce_3: 0.3911  loss_mask_3: 0.5124  loss_dice_3: 3.708  loss_ce_4: 0.3878  loss_mask_4: 0.5127  loss_dice_4: 3.703  loss_ce_5: 0.3919  loss_mask_5: 0.5151  loss_dice_5: 3.696  loss_ce_6: 0.3984  loss_mask_6: 0.5126  loss_dice_6: 3.695  loss_ce_7: 0.3926  loss_mask_7: 0.5129  loss_dice_7: 3.695  loss_ce_8: 0.4007  loss_mask_8: 0.5147  loss_dice_8: 3.698  time: 1.4215  data_time: 0.0611  lr: 8.6395e-06  max_mem: 21308M
[01/18 20:58:16] d2.utils.events INFO:  eta: 13:53:02  iter: 6019  total_loss: 46.47  loss_ce: 0.4123  loss_mask: 0.5138  loss_dice: 3.677  loss_ce_0: 0.7014  loss_mask_0: 0.4827  loss_dice_0: 3.824  loss_ce_1: 0.415  loss_mask_1: 0.5089  loss_dice_1: 3.73  loss_ce_2: 0.4052  loss_mask_2: 0.5105  loss_dice_2: 3.691  loss_ce_3: 0.419  loss_mask_3: 0.5104  loss_dice_3: 3.687  loss_ce_4: 0.4035  loss_mask_4: 0.5103  loss_dice_4: 3.682  loss_ce_5: 0.4072  loss_mask_5: 0.5132  loss_dice_5: 3.685  loss_ce_6: 0.4034  loss_mask_6: 0.5115  loss_dice_6: 3.683  loss_ce_7: 0.4032  loss_mask_7: 0.5148  loss_dice_7: 3.676  loss_ce_8: 0.3979  loss_mask_8: 0.5129  loss_dice_8: 3.68  time: 1.4217  data_time: 0.0777  lr: 8.6349e-06  max_mem: 21308M
[01/18 20:58:46] d2.utils.events INFO:  eta: 13:53:32  iter: 6039  total_loss: 46.38  loss_ce: 0.396  loss_mask: 0.5033  loss_dice: 3.668  loss_ce_0: 0.671  loss_mask_0: 0.4688  loss_dice_0: 3.83  loss_ce_1: 0.4093  loss_mask_1: 0.501  loss_dice_1: 3.722  loss_ce_2: 0.4114  loss_mask_2: 0.5019  loss_dice_2: 3.686  loss_ce_3: 0.3872  loss_mask_3: 0.5024  loss_dice_3: 3.677  loss_ce_4: 0.4069  loss_mask_4: 0.5029  loss_dice_4: 3.674  loss_ce_5: 0.4102  loss_mask_5: 0.5018  loss_dice_5: 3.686  loss_ce_6: 0.4024  loss_mask_6: 0.5057  loss_dice_6: 3.668  loss_ce_7: 0.391  loss_mask_7: 0.5029  loss_dice_7: 3.682  loss_ce_8: 0.3917  loss_mask_8: 0.5041  loss_dice_8: 3.671  time: 1.4219  data_time: 0.0655  lr: 8.6304e-06  max_mem: 21308M
[01/18 20:59:16] d2.utils.events INFO:  eta: 13:53:42  iter: 6059  total_loss: 46.32  loss_ce: 0.3682  loss_mask: 0.5111  loss_dice: 3.712  loss_ce_0: 0.668  loss_mask_0: 0.4932  loss_dice_0: 3.83  loss_ce_1: 0.3856  loss_mask_1: 0.518  loss_dice_1: 3.743  loss_ce_2: 0.3768  loss_mask_2: 0.5128  loss_dice_2: 3.712  loss_ce_3: 0.3842  loss_mask_3: 0.5104  loss_dice_3: 3.705  loss_ce_4: 0.3834  loss_mask_4: 0.5118  loss_dice_4: 3.702  loss_ce_5: 0.3683  loss_mask_5: 0.5126  loss_dice_5: 3.711  loss_ce_6: 0.3616  loss_mask_6: 0.5089  loss_dice_6: 3.71  loss_ce_7: 0.3646  loss_mask_7: 0.5121  loss_dice_7: 3.708  loss_ce_8: 0.363  loss_mask_8: 0.5098  loss_dice_8: 3.707  time: 1.4221  data_time: 0.0666  lr: 8.6258e-06  max_mem: 21308M
[01/18 20:59:46] d2.utils.events INFO:  eta: 13:53:43  iter: 6079  total_loss: 46.25  loss_ce: 0.3701  loss_mask: 0.5071  loss_dice: 3.705  loss_ce_0: 0.6576  loss_mask_0: 0.4736  loss_dice_0: 3.852  loss_ce_1: 0.3926  loss_mask_1: 0.4986  loss_dice_1: 3.748  loss_ce_2: 0.3888  loss_mask_2: 0.5024  loss_dice_2: 3.714  loss_ce_3: 0.3705  loss_mask_3: 0.5049  loss_dice_3: 3.702  loss_ce_4: 0.3704  loss_mask_4: 0.5046  loss_dice_4: 3.706  loss_ce_5: 0.3775  loss_mask_5: 0.5047  loss_dice_5: 3.708  loss_ce_6: 0.3645  loss_mask_6: 0.5052  loss_dice_6: 3.7  loss_ce_7: 0.3818  loss_mask_7: 0.5043  loss_dice_7: 3.707  loss_ce_8: 0.3703  loss_mask_8: 0.5058  loss_dice_8: 3.701  time: 1.4224  data_time: 0.0743  lr: 8.6212e-06  max_mem: 21588M
[01/18 21:00:16] d2.utils.events INFO:  eta: 13:54:07  iter: 6099  total_loss: 45.96  loss_ce: 0.3611  loss_mask: 0.5072  loss_dice: 3.699  loss_ce_0: 0.6239  loss_mask_0: 0.4795  loss_dice_0: 3.841  loss_ce_1: 0.3782  loss_mask_1: 0.5048  loss_dice_1: 3.729  loss_ce_2: 0.3592  loss_mask_2: 0.506  loss_dice_2: 3.707  loss_ce_3: 0.3519  loss_mask_3: 0.5079  loss_dice_3: 3.7  loss_ce_4: 0.3536  loss_mask_4: 0.507  loss_dice_4: 3.692  loss_ce_5: 0.3579  loss_mask_5: 0.508  loss_dice_5: 3.698  loss_ce_6: 0.3561  loss_mask_6: 0.5089  loss_dice_6: 3.701  loss_ce_7: 0.3595  loss_mask_7: 0.5081  loss_dice_7: 3.689  loss_ce_8: 0.3523  loss_mask_8: 0.5066  loss_dice_8: 3.693  time: 1.4226  data_time: 0.0768  lr: 8.6166e-06  max_mem: 21588M
[01/18 21:00:46] d2.utils.events INFO:  eta: 13:54:25  iter: 6119  total_loss: 45.83  loss_ce: 0.3797  loss_mask: 0.5275  loss_dice: 3.645  loss_ce_0: 0.6528  loss_mask_0: 0.4898  loss_dice_0: 3.792  loss_ce_1: 0.3818  loss_mask_1: 0.5221  loss_dice_1: 3.673  loss_ce_2: 0.3885  loss_mask_2: 0.5252  loss_dice_2: 3.651  loss_ce_3: 0.372  loss_mask_3: 0.5243  loss_dice_3: 3.643  loss_ce_4: 0.3822  loss_mask_4: 0.5228  loss_dice_4: 3.647  loss_ce_5: 0.3718  loss_mask_5: 0.5262  loss_dice_5: 3.643  loss_ce_6: 0.3735  loss_mask_6: 0.5249  loss_dice_6: 3.64  loss_ce_7: 0.3718  loss_mask_7: 0.5235  loss_dice_7: 3.652  loss_ce_8: 0.3666  loss_mask_8: 0.5232  loss_dice_8: 3.651  time: 1.4229  data_time: 0.0678  lr: 8.6121e-06  max_mem: 21588M
[01/18 21:01:15] d2.utils.events INFO:  eta: 13:54:36  iter: 6139  total_loss: 46.2  loss_ce: 0.3831  loss_mask: 0.5145  loss_dice: 3.676  loss_ce_0: 0.6624  loss_mask_0: 0.4764  loss_dice_0: 3.812  loss_ce_1: 0.4174  loss_mask_1: 0.5038  loss_dice_1: 3.704  loss_ce_2: 0.3902  loss_mask_2: 0.5065  loss_dice_2: 3.69  loss_ce_3: 0.3876  loss_mask_3: 0.5096  loss_dice_3: 3.672  loss_ce_4: 0.3872  loss_mask_4: 0.5108  loss_dice_4: 3.668  loss_ce_5: 0.3683  loss_mask_5: 0.5097  loss_dice_5: 3.681  loss_ce_6: 0.3801  loss_mask_6: 0.512  loss_dice_6: 3.671  loss_ce_7: 0.3932  loss_mask_7: 0.5128  loss_dice_7: 3.67  loss_ce_8: 0.3828  loss_mask_8: 0.5135  loss_dice_8: 3.665  time: 1.4231  data_time: 0.0758  lr: 8.6075e-06  max_mem: 21588M
[01/18 21:01:45] d2.utils.events INFO:  eta: 13:54:21  iter: 6159  total_loss: 46.05  loss_ce: 0.3837  loss_mask: 0.5039  loss_dice: 3.661  loss_ce_0: 0.658  loss_mask_0: 0.4741  loss_dice_0: 3.81  loss_ce_1: 0.3921  loss_mask_1: 0.5  loss_dice_1: 3.706  loss_ce_2: 0.3929  loss_mask_2: 0.503  loss_dice_2: 3.678  loss_ce_3: 0.3735  loss_mask_3: 0.5009  loss_dice_3: 3.667  loss_ce_4: 0.3856  loss_mask_4: 0.5031  loss_dice_4: 3.668  loss_ce_5: 0.3896  loss_mask_5: 0.5031  loss_dice_5: 3.673  loss_ce_6: 0.384  loss_mask_6: 0.5004  loss_dice_6: 3.66  loss_ce_7: 0.3797  loss_mask_7: 0.5035  loss_dice_7: 3.657  loss_ce_8: 0.3912  loss_mask_8: 0.5025  loss_dice_8: 3.662  time: 1.4232  data_time: 0.0784  lr: 8.6029e-06  max_mem: 21588M
[01/18 21:02:15] d2.utils.events INFO:  eta: 13:54:29  iter: 6179  total_loss: 46.45  loss_ce: 0.4027  loss_mask: 0.5016  loss_dice: 3.683  loss_ce_0: 0.6863  loss_mask_0: 0.4838  loss_dice_0: 3.841  loss_ce_1: 0.3861  loss_mask_1: 0.5014  loss_dice_1: 3.715  loss_ce_2: 0.3922  loss_mask_2: 0.5041  loss_dice_2: 3.701  loss_ce_3: 0.3767  loss_mask_3: 0.5026  loss_dice_3: 3.697  loss_ce_4: 0.3758  loss_mask_4: 0.5022  loss_dice_4: 3.691  loss_ce_5: 0.387  loss_mask_5: 0.5018  loss_dice_5: 3.693  loss_ce_6: 0.3871  loss_mask_6: 0.5021  loss_dice_6: 3.681  loss_ce_7: 0.393  loss_mask_7: 0.5008  loss_dice_7: 3.684  loss_ce_8: 0.3818  loss_mask_8: 0.5009  loss_dice_8: 3.683  time: 1.4235  data_time: 0.0709  lr: 8.5983e-06  max_mem: 21588M
[01/18 21:02:45] d2.utils.events INFO:  eta: 13:53:56  iter: 6199  total_loss: 45.66  loss_ce: 0.3772  loss_mask: 0.5005  loss_dice: 3.626  loss_ce_0: 0.6416  loss_mask_0: 0.4678  loss_dice_0: 3.766  loss_ce_1: 0.426  loss_mask_1: 0.4932  loss_dice_1: 3.672  loss_ce_2: 0.4127  loss_mask_2: 0.4958  loss_dice_2: 3.65  loss_ce_3: 0.3795  loss_mask_3: 0.4947  loss_dice_3: 3.634  loss_ce_4: 0.3792  loss_mask_4: 0.4988  loss_dice_4: 3.631  loss_ce_5: 0.3932  loss_mask_5: 0.499  loss_dice_5: 3.627  loss_ce_6: 0.3895  loss_mask_6: 0.5005  loss_dice_6: 3.624  loss_ce_7: 0.3917  loss_mask_7: 0.4985  loss_dice_7: 3.626  loss_ce_8: 0.3862  loss_mask_8: 0.5015  loss_dice_8: 3.627  time: 1.4236  data_time: 0.0671  lr: 8.5937e-06  max_mem: 21588M
[01/18 21:03:14] d2.utils.events INFO:  eta: 13:53:33  iter: 6219  total_loss: 46.16  loss_ce: 0.3838  loss_mask: 0.5005  loss_dice: 3.681  loss_ce_0: 0.6196  loss_mask_0: 0.4722  loss_dice_0: 3.823  loss_ce_1: 0.3811  loss_mask_1: 0.4944  loss_dice_1: 3.721  loss_ce_2: 0.3901  loss_mask_2: 0.4969  loss_dice_2: 3.694  loss_ce_3: 0.3703  loss_mask_3: 0.4968  loss_dice_3: 3.685  loss_ce_4: 0.3837  loss_mask_4: 0.4976  loss_dice_4: 3.69  loss_ce_5: 0.3828  loss_mask_5: 0.4949  loss_dice_5: 3.694  loss_ce_6: 0.3817  loss_mask_6: 0.4961  loss_dice_6: 3.68  loss_ce_7: 0.3811  loss_mask_7: 0.4943  loss_dice_7: 3.679  loss_ce_8: 0.3741  loss_mask_8: 0.4976  loss_dice_8: 3.69  time: 1.4238  data_time: 0.0753  lr: 8.5892e-06  max_mem: 21588M
[01/18 21:03:45] d2.utils.events INFO:  eta: 13:53:04  iter: 6239  total_loss: 45.92  loss_ce: 0.3804  loss_mask: 0.4943  loss_dice: 3.688  loss_ce_0: 0.6527  loss_mask_0: 0.4615  loss_dice_0: 3.829  loss_ce_1: 0.3922  loss_mask_1: 0.4874  loss_dice_1: 3.721  loss_ce_2: 0.38  loss_mask_2: 0.4887  loss_dice_2: 3.689  loss_ce_3: 0.3826  loss_mask_3: 0.4883  loss_dice_3: 3.684  loss_ce_4: 0.3833  loss_mask_4: 0.4905  loss_dice_4: 3.681  loss_ce_5: 0.3823  loss_mask_5: 0.4926  loss_dice_5: 3.672  loss_ce_6: 0.3886  loss_mask_6: 0.4935  loss_dice_6: 3.681  loss_ce_7: 0.3806  loss_mask_7: 0.493  loss_dice_7: 3.687  loss_ce_8: 0.3799  loss_mask_8: 0.4957  loss_dice_8: 3.685  time: 1.4241  data_time: 0.0789  lr: 8.5846e-06  max_mem: 21588M
[01/18 21:04:14] d2.utils.events INFO:  eta: 13:52:27  iter: 6259  total_loss: 46.13  loss_ce: 0.3799  loss_mask: 0.5127  loss_dice: 3.669  loss_ce_0: 0.6182  loss_mask_0: 0.4784  loss_dice_0: 3.807  loss_ce_1: 0.399  loss_mask_1: 0.5042  loss_dice_1: 3.711  loss_ce_2: 0.3895  loss_mask_2: 0.5078  loss_dice_2: 3.681  loss_ce_3: 0.3883  loss_mask_3: 0.5125  loss_dice_3: 3.669  loss_ce_4: 0.3815  loss_mask_4: 0.5105  loss_dice_4: 3.665  loss_ce_5: 0.3777  loss_mask_5: 0.5116  loss_dice_5: 3.675  loss_ce_6: 0.3912  loss_mask_6: 0.5096  loss_dice_6: 3.68  loss_ce_7: 0.3967  loss_mask_7: 0.5118  loss_dice_7: 3.667  loss_ce_8: 0.3738  loss_mask_8: 0.5108  loss_dice_8: 3.67  time: 1.4243  data_time: 0.0706  lr: 8.58e-06  max_mem: 21588M
[01/18 21:04:44] d2.utils.events INFO:  eta: 13:52:09  iter: 6279  total_loss: 46.12  loss_ce: 0.375  loss_mask: 0.4853  loss_dice: 3.712  loss_ce_0: 0.6257  loss_mask_0: 0.46  loss_dice_0: 3.834  loss_ce_1: 0.3855  loss_mask_1: 0.4921  loss_dice_1: 3.739  loss_ce_2: 0.393  loss_mask_2: 0.491  loss_dice_2: 3.723  loss_ce_3: 0.3876  loss_mask_3: 0.4887  loss_dice_3: 3.714  loss_ce_4: 0.3922  loss_mask_4: 0.4906  loss_dice_4: 3.707  loss_ce_5: 0.3771  loss_mask_5: 0.4929  loss_dice_5: 3.71  loss_ce_6: 0.3805  loss_mask_6: 0.4884  loss_dice_6: 3.698  loss_ce_7: 0.3833  loss_mask_7: 0.4886  loss_dice_7: 3.699  loss_ce_8: 0.3889  loss_mask_8: 0.4859  loss_dice_8: 3.705  time: 1.4245  data_time: 0.0677  lr: 8.5754e-06  max_mem: 21588M
[01/18 21:05:12] d2.utils.events INFO:  eta: 13:50:52  iter: 6299  total_loss: 45.79  loss_ce: 0.3786  loss_mask: 0.5195  loss_dice: 3.649  loss_ce_0: 0.6698  loss_mask_0: 0.4875  loss_dice_0: 3.807  loss_ce_1: 0.3749  loss_mask_1: 0.5195  loss_dice_1: 3.702  loss_ce_2: 0.3613  loss_mask_2: 0.5176  loss_dice_2: 3.67  loss_ce_3: 0.3561  loss_mask_3: 0.518  loss_dice_3: 3.662  loss_ce_4: 0.3508  loss_mask_4: 0.5182  loss_dice_4: 3.653  loss_ce_5: 0.3651  loss_mask_5: 0.5197  loss_dice_5: 3.657  loss_ce_6: 0.3529  loss_mask_6: 0.5182  loss_dice_6: 3.658  loss_ce_7: 0.3576  loss_mask_7: 0.5182  loss_dice_7: 3.651  loss_ce_8: 0.3632  loss_mask_8: 0.5188  loss_dice_8: 3.651  time: 1.4244  data_time: 0.0655  lr: 8.5709e-06  max_mem: 21588M
[01/18 21:05:41] d2.utils.events INFO:  eta: 13:49:29  iter: 6319  total_loss: 46.21  loss_ce: 0.3565  loss_mask: 0.518  loss_dice: 3.701  loss_ce_0: 0.6667  loss_mask_0: 0.4825  loss_dice_0: 3.815  loss_ce_1: 0.3941  loss_mask_1: 0.5181  loss_dice_1: 3.737  loss_ce_2: 0.3653  loss_mask_2: 0.5183  loss_dice_2: 3.72  loss_ce_3: 0.3569  loss_mask_3: 0.5158  loss_dice_3: 3.706  loss_ce_4: 0.3528  loss_mask_4: 0.5165  loss_dice_4: 3.702  loss_ce_5: 0.3641  loss_mask_5: 0.5181  loss_dice_5: 3.704  loss_ce_6: 0.3592  loss_mask_6: 0.5161  loss_dice_6: 3.702  loss_ce_7: 0.3545  loss_mask_7: 0.5153  loss_dice_7: 3.711  loss_ce_8: 0.3464  loss_mask_8: 0.5154  loss_dice_8: 3.697  time: 1.4245  data_time: 0.0601  lr: 8.5663e-06  max_mem: 21588M
[01/18 21:06:09] d2.utils.events INFO:  eta: 13:48:38  iter: 6339  total_loss: 45.97  loss_ce: 0.3809  loss_mask: 0.504  loss_dice: 3.66  loss_ce_0: 0.6431  loss_mask_0: 0.4744  loss_dice_0: 3.795  loss_ce_1: 0.391  loss_mask_1: 0.5031  loss_dice_1: 3.692  loss_ce_2: 0.386  loss_mask_2: 0.5041  loss_dice_2: 3.666  loss_ce_3: 0.3813  loss_mask_3: 0.5049  loss_dice_3: 3.66  loss_ce_4: 0.3709  loss_mask_4: 0.5048  loss_dice_4: 3.674  loss_ce_5: 0.3783  loss_mask_5: 0.5042  loss_dice_5: 3.659  loss_ce_6: 0.3646  loss_mask_6: 0.5063  loss_dice_6: 3.663  loss_ce_7: 0.3752  loss_mask_7: 0.5059  loss_dice_7: 3.662  loss_ce_8: 0.3829  loss_mask_8: 0.5058  loss_dice_8: 3.659  time: 1.4245  data_time: 0.0590  lr: 8.5617e-06  max_mem: 21588M
[01/18 21:06:38] d2.utils.events INFO:  eta: 13:47:34  iter: 6359  total_loss: 46.28  loss_ce: 0.358  loss_mask: 0.5012  loss_dice: 3.681  loss_ce_0: 0.6747  loss_mask_0: 0.478  loss_dice_0: 3.813  loss_ce_1: 0.3918  loss_mask_1: 0.4992  loss_dice_1: 3.712  loss_ce_2: 0.3743  loss_mask_2: 0.5027  loss_dice_2: 3.692  loss_ce_3: 0.3857  loss_mask_3: 0.4984  loss_dice_3: 3.686  loss_ce_4: 0.3931  loss_mask_4: 0.4998  loss_dice_4: 3.682  loss_ce_5: 0.3762  loss_mask_5: 0.4998  loss_dice_5: 3.68  loss_ce_6: 0.3733  loss_mask_6: 0.4997  loss_dice_6: 3.681  loss_ce_7: 0.3675  loss_mask_7: 0.5019  loss_dice_7: 3.683  loss_ce_8: 0.3609  loss_mask_8: 0.5031  loss_dice_8: 3.68  time: 1.4244  data_time: 0.0566  lr: 8.5571e-06  max_mem: 21588M
[01/18 21:07:06] d2.utils.events INFO:  eta: 13:46:44  iter: 6379  total_loss: 45.49  loss_ce: 0.3466  loss_mask: 0.5006  loss_dice: 3.648  loss_ce_0: 0.6397  loss_mask_0: 0.4717  loss_dice_0: 3.791  loss_ce_1: 0.361  loss_mask_1: 0.4959  loss_dice_1: 3.69  loss_ce_2: 0.3564  loss_mask_2: 0.5  loss_dice_2: 3.661  loss_ce_3: 0.3408  loss_mask_3: 0.5005  loss_dice_3: 3.663  loss_ce_4: 0.355  loss_mask_4: 0.5012  loss_dice_4: 3.656  loss_ce_5: 0.3341  loss_mask_5: 0.5026  loss_dice_5: 3.651  loss_ce_6: 0.3514  loss_mask_6: 0.5024  loss_dice_6: 3.645  loss_ce_7: 0.3373  loss_mask_7: 0.5017  loss_dice_7: 3.654  loss_ce_8: 0.3314  loss_mask_8: 0.5017  loss_dice_8: 3.659  time: 1.4243  data_time: 0.0555  lr: 8.5525e-06  max_mem: 21588M
[01/18 21:07:34] d2.utils.events INFO:  eta: 13:45:24  iter: 6399  total_loss: 45.94  loss_ce: 0.3691  loss_mask: 0.5036  loss_dice: 3.659  loss_ce_0: 0.6709  loss_mask_0: 0.4762  loss_dice_0: 3.809  loss_ce_1: 0.3861  loss_mask_1: 0.5022  loss_dice_1: 3.702  loss_ce_2: 0.383  loss_mask_2: 0.5025  loss_dice_2: 3.674  loss_ce_3: 0.3837  loss_mask_3: 0.5056  loss_dice_3: 3.671  loss_ce_4: 0.3663  loss_mask_4: 0.5045  loss_dice_4: 3.665  loss_ce_5: 0.3663  loss_mask_5: 0.5015  loss_dice_5: 3.672  loss_ce_6: 0.3452  loss_mask_6: 0.5026  loss_dice_6: 3.662  loss_ce_7: 0.3543  loss_mask_7: 0.5046  loss_dice_7: 3.661  loss_ce_8: 0.3791  loss_mask_8: 0.5042  loss_dice_8: 3.661  time: 1.4242  data_time: 0.0589  lr: 8.548e-06  max_mem: 21588M
[01/18 21:08:01] d2.utils.events INFO:  eta: 13:44:31  iter: 6419  total_loss: 46.32  loss_ce: 0.4102  loss_mask: 0.5015  loss_dice: 3.655  loss_ce_0: 0.6632  loss_mask_0: 0.4847  loss_dice_0: 3.803  loss_ce_1: 0.4237  loss_mask_1: 0.4997  loss_dice_1: 3.693  loss_ce_2: 0.421  loss_mask_2: 0.5035  loss_dice_2: 3.671  loss_ce_3: 0.3962  loss_mask_3: 0.5016  loss_dice_3: 3.668  loss_ce_4: 0.3973  loss_mask_4: 0.5014  loss_dice_4: 3.665  loss_ce_5: 0.4023  loss_mask_5: 0.5036  loss_dice_5: 3.67  loss_ce_6: 0.399  loss_mask_6: 0.5028  loss_dice_6: 3.67  loss_ce_7: 0.3963  loss_mask_7: 0.503  loss_dice_7: 3.666  loss_ce_8: 0.3996  loss_mask_8: 0.5034  loss_dice_8: 3.662  time: 1.4241  data_time: 0.0527  lr: 8.5434e-06  max_mem: 21588M
[01/18 21:08:29] d2.utils.events INFO:  eta: 13:42:45  iter: 6439  total_loss: 45.71  loss_ce: 0.3818  loss_mask: 0.5051  loss_dice: 3.671  loss_ce_0: 0.621  loss_mask_0: 0.4751  loss_dice_0: 3.815  loss_ce_1: 0.398  loss_mask_1: 0.5015  loss_dice_1: 3.706  loss_ce_2: 0.3899  loss_mask_2: 0.502  loss_dice_2: 3.689  loss_ce_3: 0.3742  loss_mask_3: 0.5021  loss_dice_3: 3.681  loss_ce_4: 0.372  loss_mask_4: 0.5041  loss_dice_4: 3.674  loss_ce_5: 0.3551  loss_mask_5: 0.5062  loss_dice_5: 3.674  loss_ce_6: 0.3754  loss_mask_6: 0.5024  loss_dice_6: 3.667  loss_ce_7: 0.3786  loss_mask_7: 0.5043  loss_dice_7: 3.664  loss_ce_8: 0.3767  loss_mask_8: 0.5022  loss_dice_8: 3.66  time: 1.4240  data_time: 0.0538  lr: 8.5388e-06  max_mem: 21588M
[01/18 21:08:57] d2.utils.events INFO:  eta: 13:40:45  iter: 6459  total_loss: 45.11  loss_ce: 0.3756  loss_mask: 0.4991  loss_dice: 3.618  loss_ce_0: 0.6453  loss_mask_0: 0.4676  loss_dice_0: 3.753  loss_ce_1: 0.4024  loss_mask_1: 0.4955  loss_dice_1: 3.655  loss_ce_2: 0.3605  loss_mask_2: 0.5014  loss_dice_2: 3.634  loss_ce_3: 0.3596  loss_mask_3: 0.5003  loss_dice_3: 3.623  loss_ce_4: 0.3643  loss_mask_4: 0.5004  loss_dice_4: 3.619  loss_ce_5: 0.3652  loss_mask_5: 0.5005  loss_dice_5: 3.622  loss_ce_6: 0.3649  loss_mask_6: 0.4998  loss_dice_6: 3.621  loss_ce_7: 0.3802  loss_mask_7: 0.5001  loss_dice_7: 3.621  loss_ce_8: 0.381  loss_mask_8: 0.4984  loss_dice_8: 3.62  time: 1.4238  data_time: 0.0572  lr: 8.5342e-06  max_mem: 21588M
[01/18 21:09:25] d2.utils.events INFO:  eta: 13:39:37  iter: 6479  total_loss: 45.86  loss_ce: 0.3769  loss_mask: 0.482  loss_dice: 3.668  loss_ce_0: 0.6338  loss_mask_0: 0.459  loss_dice_0: 3.803  loss_ce_1: 0.3894  loss_mask_1: 0.4821  loss_dice_1: 3.695  loss_ce_2: 0.3963  loss_mask_2: 0.4837  loss_dice_2: 3.677  loss_ce_3: 0.36  loss_mask_3: 0.4836  loss_dice_3: 3.67  loss_ce_4: 0.3851  loss_mask_4: 0.4859  loss_dice_4: 3.669  loss_ce_5: 0.3783  loss_mask_5: 0.4847  loss_dice_5: 3.664  loss_ce_6: 0.3732  loss_mask_6: 0.4838  loss_dice_6: 3.671  loss_ce_7: 0.3795  loss_mask_7: 0.4819  loss_dice_7: 3.668  loss_ce_8: 0.3794  loss_mask_8: 0.4816  loss_dice_8: 3.662  time: 1.4238  data_time: 0.0551  lr: 8.5297e-06  max_mem: 21588M
[01/18 21:09:52] d2.utils.events INFO:  eta: 13:38:29  iter: 6499  total_loss: 45.52  loss_ce: 0.3767  loss_mask: 0.5015  loss_dice: 3.611  loss_ce_0: 0.6408  loss_mask_0: 0.4757  loss_dice_0: 3.728  loss_ce_1: 0.3996  loss_mask_1: 0.5058  loss_dice_1: 3.626  loss_ce_2: 0.3691  loss_mask_2: 0.5054  loss_dice_2: 3.614  loss_ce_3: 0.3662  loss_mask_3: 0.5026  loss_dice_3: 3.605  loss_ce_4: 0.3597  loss_mask_4: 0.4991  loss_dice_4: 3.601  loss_ce_5: 0.3698  loss_mask_5: 0.4984  loss_dice_5: 3.612  loss_ce_6: 0.3602  loss_mask_6: 0.4993  loss_dice_6: 3.609  loss_ce_7: 0.3734  loss_mask_7: 0.5012  loss_dice_7: 3.609  loss_ce_8: 0.377  loss_mask_8: 0.5004  loss_dice_8: 3.605  time: 1.4236  data_time: 0.0541  lr: 8.5251e-06  max_mem: 21588M
[01/18 21:10:20] d2.utils.events INFO:  eta: 13:36:49  iter: 6519  total_loss: 45.43  loss_ce: 0.3915  loss_mask: 0.4923  loss_dice: 3.636  loss_ce_0: 0.6593  loss_mask_0: 0.4673  loss_dice_0: 3.772  loss_ce_1: 0.3844  loss_mask_1: 0.4928  loss_dice_1: 3.657  loss_ce_2: 0.384  loss_mask_2: 0.494  loss_dice_2: 3.645  loss_ce_3: 0.3762  loss_mask_3: 0.4933  loss_dice_3: 3.632  loss_ce_4: 0.3639  loss_mask_4: 0.4918  loss_dice_4: 3.635  loss_ce_5: 0.3778  loss_mask_5: 0.4928  loss_dice_5: 3.625  loss_ce_6: 0.3799  loss_mask_6: 0.4907  loss_dice_6: 3.628  loss_ce_7: 0.3719  loss_mask_7: 0.4922  loss_dice_7: 3.631  loss_ce_8: 0.3794  loss_mask_8: 0.4918  loss_dice_8: 3.632  time: 1.4235  data_time: 0.0581  lr: 8.5205e-06  max_mem: 21588M
[01/18 21:10:48] d2.utils.events INFO:  eta: 13:35:40  iter: 6539  total_loss: 45.22  loss_ce: 0.38  loss_mask: 0.501  loss_dice: 3.632  loss_ce_0: 0.6224  loss_mask_0: 0.4696  loss_dice_0: 3.78  loss_ce_1: 0.3552  loss_mask_1: 0.5028  loss_dice_1: 3.669  loss_ce_2: 0.3536  loss_mask_2: 0.5049  loss_dice_2: 3.642  loss_ce_3: 0.3661  loss_mask_3: 0.5039  loss_dice_3: 3.633  loss_ce_4: 0.3781  loss_mask_4: 0.5018  loss_dice_4: 3.629  loss_ce_5: 0.3661  loss_mask_5: 0.5039  loss_dice_5: 3.635  loss_ce_6: 0.3727  loss_mask_6: 0.5053  loss_dice_6: 3.634  loss_ce_7: 0.3612  loss_mask_7: 0.5029  loss_dice_7: 3.629  loss_ce_8: 0.3602  loss_mask_8: 0.5026  loss_dice_8: 3.628  time: 1.4234  data_time: 0.0510  lr: 8.5159e-06  max_mem: 21588M
[01/18 21:11:15] d2.utils.events INFO:  eta: 13:33:41  iter: 6559  total_loss: 45.81  loss_ce: 0.3803  loss_mask: 0.5042  loss_dice: 3.654  loss_ce_0: 0.6126  loss_mask_0: 0.4786  loss_dice_0: 3.793  loss_ce_1: 0.3841  loss_mask_1: 0.5051  loss_dice_1: 3.688  loss_ce_2: 0.3754  loss_mask_2: 0.5037  loss_dice_2: 3.666  loss_ce_3: 0.3806  loss_mask_3: 0.5059  loss_dice_3: 3.66  loss_ce_4: 0.3852  loss_mask_4: 0.5063  loss_dice_4: 3.666  loss_ce_5: 0.3786  loss_mask_5: 0.5051  loss_dice_5: 3.661  loss_ce_6: 0.3755  loss_mask_6: 0.5041  loss_dice_6: 3.662  loss_ce_7: 0.3784  loss_mask_7: 0.5052  loss_dice_7: 3.663  loss_ce_8: 0.3684  loss_mask_8: 0.5055  loss_dice_8: 3.658  time: 1.4232  data_time: 0.0513  lr: 8.5113e-06  max_mem: 21588M
[01/18 21:11:43] d2.utils.events INFO:  eta: 13:32:02  iter: 6579  total_loss: 45.9  loss_ce: 0.3873  loss_mask: 0.5135  loss_dice: 3.643  loss_ce_0: 0.6762  loss_mask_0: 0.4835  loss_dice_0: 3.766  loss_ce_1: 0.392  loss_mask_1: 0.5097  loss_dice_1: 3.675  loss_ce_2: 0.3807  loss_mask_2: 0.5103  loss_dice_2: 3.653  loss_ce_3: 0.375  loss_mask_3: 0.5126  loss_dice_3: 3.651  loss_ce_4: 0.377  loss_mask_4: 0.5091  loss_dice_4: 3.653  loss_ce_5: 0.3952  loss_mask_5: 0.5108  loss_dice_5: 3.639  loss_ce_6: 0.3877  loss_mask_6: 0.5103  loss_dice_6: 3.643  loss_ce_7: 0.3773  loss_mask_7: 0.5138  loss_dice_7: 3.637  loss_ce_8: 0.3979  loss_mask_8: 0.514  loss_dice_8: 3.647  time: 1.4231  data_time: 0.0586  lr: 8.5067e-06  max_mem: 21588M
[01/18 21:12:11] d2.utils.events INFO:  eta: 13:30:21  iter: 6599  total_loss: 45.3  loss_ce: 0.3607  loss_mask: 0.5146  loss_dice: 3.601  loss_ce_0: 0.6131  loss_mask_0: 0.4795  loss_dice_0: 3.756  loss_ce_1: 0.3723  loss_mask_1: 0.5107  loss_dice_1: 3.641  loss_ce_2: 0.3788  loss_mask_2: 0.5083  loss_dice_2: 3.622  loss_ce_3: 0.3642  loss_mask_3: 0.5131  loss_dice_3: 3.611  loss_ce_4: 0.3749  loss_mask_4: 0.5123  loss_dice_4: 3.606  loss_ce_5: 0.3497  loss_mask_5: 0.5127  loss_dice_5: 3.609  loss_ce_6: 0.3655  loss_mask_6: 0.5129  loss_dice_6: 3.6  loss_ce_7: 0.3787  loss_mask_7: 0.5136  loss_dice_7: 3.596  loss_ce_8: 0.3719  loss_mask_8: 0.5118  loss_dice_8: 3.601  time: 1.4230  data_time: 0.0570  lr: 8.5022e-06  max_mem: 21588M
[01/18 21:12:38] d2.utils.events INFO:  eta: 13:28:35  iter: 6619  total_loss: 45.48  loss_ce: 0.3599  loss_mask: 0.5031  loss_dice: 3.617  loss_ce_0: 0.6347  loss_mask_0: 0.4795  loss_dice_0: 3.75  loss_ce_1: 0.3918  loss_mask_1: 0.5008  loss_dice_1: 3.65  loss_ce_2: 0.3672  loss_mask_2: 0.501  loss_dice_2: 3.632  loss_ce_3: 0.3544  loss_mask_3: 0.4996  loss_dice_3: 3.615  loss_ce_4: 0.3465  loss_mask_4: 0.5014  loss_dice_4: 3.614  loss_ce_5: 0.3587  loss_mask_5: 0.5041  loss_dice_5: 3.619  loss_ce_6: 0.3534  loss_mask_6: 0.5  loss_dice_6: 3.621  loss_ce_7: 0.3527  loss_mask_7: 0.503  loss_dice_7: 3.628  loss_ce_8: 0.3564  loss_mask_8: 0.5046  loss_dice_8: 3.616  time: 1.4229  data_time: 0.0561  lr: 8.4976e-06  max_mem: 21588M
[01/18 21:13:06] d2.utils.events INFO:  eta: 13:27:21  iter: 6639  total_loss: 45.89  loss_ce: 0.393  loss_mask: 0.4923  loss_dice: 3.647  loss_ce_0: 0.6798  loss_mask_0: 0.4585  loss_dice_0: 3.792  loss_ce_1: 0.4159  loss_mask_1: 0.4842  loss_dice_1: 3.686  loss_ce_2: 0.3894  loss_mask_2: 0.4883  loss_dice_2: 3.663  loss_ce_3: 0.3791  loss_mask_3: 0.4892  loss_dice_3: 3.663  loss_ce_4: 0.3855  loss_mask_4: 0.4916  loss_dice_4: 3.66  loss_ce_5: 0.3815  loss_mask_5: 0.4892  loss_dice_5: 3.657  loss_ce_6: 0.384  loss_mask_6: 0.4925  loss_dice_6: 3.647  loss_ce_7: 0.3823  loss_mask_7: 0.4929  loss_dice_7: 3.657  loss_ce_8: 0.3959  loss_mask_8: 0.4908  loss_dice_8: 3.652  time: 1.4228  data_time: 0.0566  lr: 8.493e-06  max_mem: 21588M
[01/18 21:13:35] d2.utils.events INFO:  eta: 13:25:56  iter: 6659  total_loss: 46.11  loss_ce: 0.3906  loss_mask: 0.4905  loss_dice: 3.665  loss_ce_0: 0.6998  loss_mask_0: 0.4738  loss_dice_0: 3.795  loss_ce_1: 0.4176  loss_mask_1: 0.4952  loss_dice_1: 3.707  loss_ce_2: 0.3878  loss_mask_2: 0.4929  loss_dice_2: 3.681  loss_ce_3: 0.3668  loss_mask_3: 0.4915  loss_dice_3: 3.68  loss_ce_4: 0.3875  loss_mask_4: 0.4932  loss_dice_4: 3.669  loss_ce_5: 0.3841  loss_mask_5: 0.4914  loss_dice_5: 3.666  loss_ce_6: 0.3754  loss_mask_6: 0.4915  loss_dice_6: 3.675  loss_ce_7: 0.3808  loss_mask_7: 0.4899  loss_dice_7: 3.671  loss_ce_8: 0.3932  loss_mask_8: 0.4916  loss_dice_8: 3.662  time: 1.4227  data_time: 0.0630  lr: 8.4884e-06  max_mem: 21588M
[01/18 21:14:03] d2.utils.events INFO:  eta: 13:24:39  iter: 6679  total_loss: 45.53  loss_ce: 0.3936  loss_mask: 0.4938  loss_dice: 3.636  loss_ce_0: 0.6286  loss_mask_0: 0.466  loss_dice_0: 3.782  loss_ce_1: 0.3966  loss_mask_1: 0.4957  loss_dice_1: 3.676  loss_ce_2: 0.3886  loss_mask_2: 0.4977  loss_dice_2: 3.659  loss_ce_3: 0.3785  loss_mask_3: 0.4989  loss_dice_3: 3.65  loss_ce_4: 0.3773  loss_mask_4: 0.497  loss_dice_4: 3.642  loss_ce_5: 0.3745  loss_mask_5: 0.4957  loss_dice_5: 3.639  loss_ce_6: 0.3692  loss_mask_6: 0.4962  loss_dice_6: 3.642  loss_ce_7: 0.3819  loss_mask_7: 0.4939  loss_dice_7: 3.643  loss_ce_8: 0.3782  loss_mask_8: 0.4951  loss_dice_8: 3.651  time: 1.4227  data_time: 0.0572  lr: 8.4838e-06  max_mem: 21588M
[01/18 21:14:31] d2.utils.events INFO:  eta: 13:22:38  iter: 6699  total_loss: 46.07  loss_ce: 0.3484  loss_mask: 0.4933  loss_dice: 3.674  loss_ce_0: 0.6345  loss_mask_0: 0.471  loss_dice_0: 3.795  loss_ce_1: 0.3793  loss_mask_1: 0.4909  loss_dice_1: 3.703  loss_ce_2: 0.3606  loss_mask_2: 0.4917  loss_dice_2: 3.691  loss_ce_3: 0.3667  loss_mask_3: 0.4915  loss_dice_3: 3.684  loss_ce_4: 0.3591  loss_mask_4: 0.4916  loss_dice_4: 3.694  loss_ce_5: 0.3511  loss_mask_5: 0.4929  loss_dice_5: 3.681  loss_ce_6: 0.3472  loss_mask_6: 0.4918  loss_dice_6: 3.686  loss_ce_7: 0.3609  loss_mask_7: 0.4905  loss_dice_7: 3.678  loss_ce_8: 0.3562  loss_mask_8: 0.494  loss_dice_8: 3.679  time: 1.4226  data_time: 0.0564  lr: 8.4793e-06  max_mem: 21588M
[01/18 21:14:59] d2.utils.events INFO:  eta: 13:20:34  iter: 6719  total_loss: 45.49  loss_ce: 0.3806  loss_mask: 0.5022  loss_dice: 3.593  loss_ce_0: 0.651  loss_mask_0: 0.4783  loss_dice_0: 3.75  loss_ce_1: 0.379  loss_mask_1: 0.5021  loss_dice_1: 3.636  loss_ce_2: 0.3961  loss_mask_2: 0.5021  loss_dice_2: 3.61  loss_ce_3: 0.3753  loss_mask_3: 0.504  loss_dice_3: 3.601  loss_ce_4: 0.3945  loss_mask_4: 0.505  loss_dice_4: 3.597  loss_ce_5: 0.3901  loss_mask_5: 0.5035  loss_dice_5: 3.6  loss_ce_6: 0.3727  loss_mask_6: 0.5046  loss_dice_6: 3.595  loss_ce_7: 0.3976  loss_mask_7: 0.5058  loss_dice_7: 3.591  loss_ce_8: 0.3961  loss_mask_8: 0.5012  loss_dice_8: 3.595  time: 1.4225  data_time: 0.0498  lr: 8.4747e-06  max_mem: 21588M
[01/18 21:15:26] d2.utils.events INFO:  eta: 13:18:35  iter: 6739  total_loss: 45.43  loss_ce: 0.3782  loss_mask: 0.4844  loss_dice: 3.648  loss_ce_0: 0.635  loss_mask_0: 0.4623  loss_dice_0: 3.786  loss_ce_1: 0.3937  loss_mask_1: 0.4833  loss_dice_1: 3.693  loss_ce_2: 0.3653  loss_mask_2: 0.4822  loss_dice_2: 3.669  loss_ce_3: 0.3649  loss_mask_3: 0.4844  loss_dice_3: 3.649  loss_ce_4: 0.367  loss_mask_4: 0.4838  loss_dice_4: 3.654  loss_ce_5: 0.3777  loss_mask_5: 0.485  loss_dice_5: 3.65  loss_ce_6: 0.3645  loss_mask_6: 0.4856  loss_dice_6: 3.645  loss_ce_7: 0.3759  loss_mask_7: 0.4876  loss_dice_7: 3.645  loss_ce_8: 0.3826  loss_mask_8: 0.483  loss_dice_8: 3.649  time: 1.4224  data_time: 0.0531  lr: 8.4701e-06  max_mem: 21588M
[01/18 21:15:54] d2.utils.events INFO:  eta: 13:17:10  iter: 6759  total_loss: 46.05  loss_ce: 0.4139  loss_mask: 0.5062  loss_dice: 3.646  loss_ce_0: 0.6718  loss_mask_0: 0.4813  loss_dice_0: 3.777  loss_ce_1: 0.402  loss_mask_1: 0.5125  loss_dice_1: 3.677  loss_ce_2: 0.3891  loss_mask_2: 0.5118  loss_dice_2: 3.658  loss_ce_3: 0.3788  loss_mask_3: 0.5075  loss_dice_3: 3.649  loss_ce_4: 0.3968  loss_mask_4: 0.5074  loss_dice_4: 3.646  loss_ce_5: 0.4009  loss_mask_5: 0.5072  loss_dice_5: 3.65  loss_ce_6: 0.4013  loss_mask_6: 0.5036  loss_dice_6: 3.654  loss_ce_7: 0.3903  loss_mask_7: 0.5022  loss_dice_7: 3.645  loss_ce_8: 0.4171  loss_mask_8: 0.5053  loss_dice_8: 3.647  time: 1.4223  data_time: 0.0501  lr: 8.4655e-06  max_mem: 21588M
[01/18 21:16:22] d2.utils.events INFO:  eta: 13:14:59  iter: 6779  total_loss: 45.68  loss_ce: 0.3911  loss_mask: 0.5034  loss_dice: 3.625  loss_ce_0: 0.6621  loss_mask_0: 0.4764  loss_dice_0: 3.767  loss_ce_1: 0.4139  loss_mask_1: 0.5063  loss_dice_1: 3.653  loss_ce_2: 0.3894  loss_mask_2: 0.5037  loss_dice_2: 3.632  loss_ce_3: 0.3999  loss_mask_3: 0.5047  loss_dice_3: 3.618  loss_ce_4: 0.396  loss_mask_4: 0.5032  loss_dice_4: 3.621  loss_ce_5: 0.3821  loss_mask_5: 0.5042  loss_dice_5: 3.614  loss_ce_6: 0.3796  loss_mask_6: 0.5045  loss_dice_6: 3.62  loss_ce_7: 0.3885  loss_mask_7: 0.5042  loss_dice_7: 3.615  loss_ce_8: 0.3833  loss_mask_8: 0.5025  loss_dice_8: 3.615  time: 1.4222  data_time: 0.0523  lr: 8.4609e-06  max_mem: 21588M
[01/18 21:16:50] d2.utils.events INFO:  eta: 13:12:52  iter: 6799  total_loss: 45.87  loss_ce: 0.3738  loss_mask: 0.4936  loss_dice: 3.633  loss_ce_0: 0.6525  loss_mask_0: 0.4683  loss_dice_0: 3.776  loss_ce_1: 0.3995  loss_mask_1: 0.4984  loss_dice_1: 3.682  loss_ce_2: 0.3919  loss_mask_2: 0.5005  loss_dice_2: 3.66  loss_ce_3: 0.3749  loss_mask_3: 0.4978  loss_dice_3: 3.639  loss_ce_4: 0.3784  loss_mask_4: 0.4972  loss_dice_4: 3.646  loss_ce_5: 0.365  loss_mask_5: 0.4956  loss_dice_5: 3.646  loss_ce_6: 0.3873  loss_mask_6: 0.4958  loss_dice_6: 3.645  loss_ce_7: 0.379  loss_mask_7: 0.4951  loss_dice_7: 3.637  loss_ce_8: 0.3754  loss_mask_8: 0.494  loss_dice_8: 3.634  time: 1.4221  data_time: 0.0568  lr: 8.4563e-06  max_mem: 21588M
[01/18 21:17:18] d2.utils.events INFO:  eta: 13:10:51  iter: 6819  total_loss: 45.09  loss_ce: 0.3679  loss_mask: 0.4874  loss_dice: 3.585  loss_ce_0: 0.6198  loss_mask_0: 0.4636  loss_dice_0: 3.726  loss_ce_1: 0.376  loss_mask_1: 0.486  loss_dice_1: 3.625  loss_ce_2: 0.3644  loss_mask_2: 0.4865  loss_dice_2: 3.601  loss_ce_3: 0.3683  loss_mask_3: 0.4868  loss_dice_3: 3.589  loss_ce_4: 0.3606  loss_mask_4: 0.4858  loss_dice_4: 3.586  loss_ce_5: 0.3642  loss_mask_5: 0.4884  loss_dice_5: 3.577  loss_ce_6: 0.368  loss_mask_6: 0.4891  loss_dice_6: 3.583  loss_ce_7: 0.367  loss_mask_7: 0.4893  loss_dice_7: 3.572  loss_ce_8: 0.3623  loss_mask_8: 0.49  loss_dice_8: 3.573  time: 1.4220  data_time: 0.0596  lr: 8.4517e-06  max_mem: 21588M
[01/18 21:17:46] d2.utils.events INFO:  eta: 13:09:37  iter: 6839  total_loss: 46.14  loss_ce: 0.3905  loss_mask: 0.5183  loss_dice: 3.671  loss_ce_0: 0.6605  loss_mask_0: 0.4909  loss_dice_0: 3.798  loss_ce_1: 0.398  loss_mask_1: 0.5126  loss_dice_1: 3.698  loss_ce_2: 0.3975  loss_mask_2: 0.5128  loss_dice_2: 3.681  loss_ce_3: 0.377  loss_mask_3: 0.5135  loss_dice_3: 3.667  loss_ce_4: 0.387  loss_mask_4: 0.5141  loss_dice_4: 3.672  loss_ce_5: 0.3905  loss_mask_5: 0.5135  loss_dice_5: 3.673  loss_ce_6: 0.3863  loss_mask_6: 0.5162  loss_dice_6: 3.67  loss_ce_7: 0.3954  loss_mask_7: 0.5163  loss_dice_7: 3.681  loss_ce_8: 0.4035  loss_mask_8: 0.5183  loss_dice_8: 3.677  time: 1.4219  data_time: 0.0581  lr: 8.4472e-06  max_mem: 21588M
[01/18 21:18:13] d2.utils.events INFO:  eta: 13:07:43  iter: 6859  total_loss: 45.41  loss_ce: 0.3595  loss_mask: 0.4961  loss_dice: 3.632  loss_ce_0: 0.6803  loss_mask_0: 0.4705  loss_dice_0: 3.757  loss_ce_1: 0.407  loss_mask_1: 0.5037  loss_dice_1: 3.659  loss_ce_2: 0.3828  loss_mask_2: 0.5029  loss_dice_2: 3.64  loss_ce_3: 0.382  loss_mask_3: 0.4989  loss_dice_3: 3.639  loss_ce_4: 0.3639  loss_mask_4: 0.5006  loss_dice_4: 3.631  loss_ce_5: 0.383  loss_mask_5: 0.4999  loss_dice_5: 3.633  loss_ce_6: 0.3668  loss_mask_6: 0.499  loss_dice_6: 3.625  loss_ce_7: 0.3735  loss_mask_7: 0.497  loss_dice_7: 3.628  loss_ce_8: 0.3612  loss_mask_8: 0.497  loss_dice_8: 3.635  time: 1.4218  data_time: 0.0507  lr: 8.4426e-06  max_mem: 21588M
[01/18 21:18:41] d2.utils.events INFO:  eta: 13:06:06  iter: 6879  total_loss: 45.33  loss_ce: 0.3991  loss_mask: 0.4948  loss_dice: 3.618  loss_ce_0: 0.6598  loss_mask_0: 0.4727  loss_dice_0: 3.77  loss_ce_1: 0.3912  loss_mask_1: 0.4959  loss_dice_1: 3.664  loss_ce_2: 0.404  loss_mask_2: 0.4929  loss_dice_2: 3.641  loss_ce_3: 0.3951  loss_mask_3: 0.495  loss_dice_3: 3.628  loss_ce_4: 0.4048  loss_mask_4: 0.4971  loss_dice_4: 3.623  loss_ce_5: 0.4113  loss_mask_5: 0.4974  loss_dice_5: 3.622  loss_ce_6: 0.4148  loss_mask_6: 0.4983  loss_dice_6: 3.621  loss_ce_7: 0.4054  loss_mask_7: 0.4971  loss_dice_7: 3.616  loss_ce_8: 0.3954  loss_mask_8: 0.4965  loss_dice_8: 3.629  time: 1.4218  data_time: 0.0577  lr: 8.438e-06  max_mem: 21588M
[01/18 21:19:09] d2.utils.events INFO:  eta: 13:03:53  iter: 6899  total_loss: 45.49  loss_ce: 0.3605  loss_mask: 0.4936  loss_dice: 3.623  loss_ce_0: 0.633  loss_mask_0: 0.4606  loss_dice_0: 3.763  loss_ce_1: 0.3879  loss_mask_1: 0.4857  loss_dice_1: 3.671  loss_ce_2: 0.3753  loss_mask_2: 0.4893  loss_dice_2: 3.641  loss_ce_3: 0.3658  loss_mask_3: 0.4909  loss_dice_3: 3.628  loss_ce_4: 0.3628  loss_mask_4: 0.49  loss_dice_4: 3.63  loss_ce_5: 0.3594  loss_mask_5: 0.4904  loss_dice_5: 3.63  loss_ce_6: 0.3497  loss_mask_6: 0.4921  loss_dice_6: 3.623  loss_ce_7: 0.3555  loss_mask_7: 0.4915  loss_dice_7: 3.618  loss_ce_8: 0.3566  loss_mask_8: 0.4947  loss_dice_8: 3.62  time: 1.4217  data_time: 0.0534  lr: 8.4334e-06  max_mem: 21588M
[01/18 21:19:37] d2.utils.events INFO:  eta: 13:02:40  iter: 6919  total_loss: 45.7  loss_ce: 0.368  loss_mask: 0.4949  loss_dice: 3.647  loss_ce_0: 0.6181  loss_mask_0: 0.465  loss_dice_0: 3.786  loss_ce_1: 0.3787  loss_mask_1: 0.4932  loss_dice_1: 3.693  loss_ce_2: 0.3804  loss_mask_2: 0.4905  loss_dice_2: 3.67  loss_ce_3: 0.3793  loss_mask_3: 0.4918  loss_dice_3: 3.648  loss_ce_4: 0.3624  loss_mask_4: 0.492  loss_dice_4: 3.652  loss_ce_5: 0.3732  loss_mask_5: 0.4919  loss_dice_5: 3.645  loss_ce_6: 0.3582  loss_mask_6: 0.4921  loss_dice_6: 3.649  loss_ce_7: 0.3833  loss_mask_7: 0.4924  loss_dice_7: 3.65  loss_ce_8: 0.3824  loss_mask_8: 0.4943  loss_dice_8: 3.646  time: 1.4215  data_time: 0.0553  lr: 8.4288e-06  max_mem: 21588M
[01/18 21:20:05] d2.utils.events INFO:  eta: 13:01:28  iter: 6939  total_loss: 45.5  loss_ce: 0.3919  loss_mask: 0.4935  loss_dice: 3.636  loss_ce_0: 0.6379  loss_mask_0: 0.4698  loss_dice_0: 3.756  loss_ce_1: 0.3641  loss_mask_1: 0.4953  loss_dice_1: 3.652  loss_ce_2: 0.3683  loss_mask_2: 0.4974  loss_dice_2: 3.646  loss_ce_3: 0.3752  loss_mask_3: 0.4965  loss_dice_3: 3.644  loss_ce_4: 0.3505  loss_mask_4: 0.4959  loss_dice_4: 3.638  loss_ce_5: 0.3695  loss_mask_5: 0.4938  loss_dice_5: 3.637  loss_ce_6: 0.3777  loss_mask_6: 0.4926  loss_dice_6: 3.642  loss_ce_7: 0.3889  loss_mask_7: 0.4968  loss_dice_7: 3.637  loss_ce_8: 0.3588  loss_mask_8: 0.4945  loss_dice_8: 3.642  time: 1.4215  data_time: 0.0578  lr: 8.4242e-06  max_mem: 21588M
[01/18 21:20:33] d2.utils.events INFO:  eta: 13:00:01  iter: 6959  total_loss: 45.31  loss_ce: 0.407  loss_mask: 0.4934  loss_dice: 3.581  loss_ce_0: 0.6701  loss_mask_0: 0.4659  loss_dice_0: 3.726  loss_ce_1: 0.4111  loss_mask_1: 0.4932  loss_dice_1: 3.618  loss_ce_2: 0.4061  loss_mask_2: 0.4947  loss_dice_2: 3.595  loss_ce_3: 0.4163  loss_mask_3: 0.4963  loss_dice_3: 3.591  loss_ce_4: 0.4057  loss_mask_4: 0.4948  loss_dice_4: 3.584  loss_ce_5: 0.4013  loss_mask_5: 0.4946  loss_dice_5: 3.581  loss_ce_6: 0.3918  loss_mask_6: 0.4946  loss_dice_6: 3.588  loss_ce_7: 0.4084  loss_mask_7: 0.492  loss_dice_7: 3.586  loss_ce_8: 0.4086  loss_mask_8: 0.4929  loss_dice_8: 3.585  time: 1.4214  data_time: 0.0548  lr: 8.4196e-06  max_mem: 21588M
[01/18 21:21:01] d2.utils.events INFO:  eta: 12:58:18  iter: 6979  total_loss: 46.06  loss_ce: 0.394  loss_mask: 0.5092  loss_dice: 3.646  loss_ce_0: 0.6311  loss_mask_0: 0.4728  loss_dice_0: 3.771  loss_ce_1: 0.3978  loss_mask_1: 0.4989  loss_dice_1: 3.69  loss_ce_2: 0.3911  loss_mask_2: 0.4977  loss_dice_2: 3.665  loss_ce_3: 0.3929  loss_mask_3: 0.499  loss_dice_3: 3.65  loss_ce_4: 0.4056  loss_mask_4: 0.5035  loss_dice_4: 3.65  loss_ce_5: 0.4023  loss_mask_5: 0.5045  loss_dice_5: 3.644  loss_ce_6: 0.3952  loss_mask_6: 0.509  loss_dice_6: 3.639  loss_ce_7: 0.3966  loss_mask_7: 0.5099  loss_dice_7: 3.637  loss_ce_8: 0.4175  loss_mask_8: 0.508  loss_dice_8: 3.64  time: 1.4213  data_time: 0.0583  lr: 8.4151e-06  max_mem: 21588M
[01/18 21:21:29] d2.utils.events INFO:  eta: 12:57:02  iter: 6999  total_loss: 45.82  loss_ce: 0.4087  loss_mask: 0.5173  loss_dice: 3.616  loss_ce_0: 0.635  loss_mask_0: 0.4817  loss_dice_0: 3.743  loss_ce_1: 0.3994  loss_mask_1: 0.5192  loss_dice_1: 3.658  loss_ce_2: 0.3972  loss_mask_2: 0.5183  loss_dice_2: 3.633  loss_ce_3: 0.3875  loss_mask_3: 0.5151  loss_dice_3: 3.619  loss_ce_4: 0.4141  loss_mask_4: 0.517  loss_dice_4: 3.623  loss_ce_5: 0.3934  loss_mask_5: 0.5166  loss_dice_5: 3.628  loss_ce_6: 0.3939  loss_mask_6: 0.5179  loss_dice_6: 3.616  loss_ce_7: 0.3974  loss_mask_7: 0.521  loss_dice_7: 3.62  loss_ce_8: 0.3949  loss_mask_8: 0.5184  loss_dice_8: 3.618  time: 1.4213  data_time: 0.0566  lr: 8.4105e-06  max_mem: 21588M
[01/18 21:21:57] d2.utils.events INFO:  eta: 12:55:44  iter: 7019  total_loss: 45.29  loss_ce: 0.3722  loss_mask: 0.4755  loss_dice: 3.619  loss_ce_0: 0.6447  loss_mask_0: 0.4557  loss_dice_0: 3.772  loss_ce_1: 0.3669  loss_mask_1: 0.4778  loss_dice_1: 3.68  loss_ce_2: 0.3753  loss_mask_2: 0.4778  loss_dice_2: 3.653  loss_ce_3: 0.3785  loss_mask_3: 0.4759  loss_dice_3: 3.64  loss_ce_4: 0.3592  loss_mask_4: 0.4768  loss_dice_4: 3.63  loss_ce_5: 0.3729  loss_mask_5: 0.4748  loss_dice_5: 3.628  loss_ce_6: 0.3731  loss_mask_6: 0.4758  loss_dice_6: 3.625  loss_ce_7: 0.3764  loss_mask_7: 0.4758  loss_dice_7: 3.626  loss_ce_8: 0.3626  loss_mask_8: 0.4752  loss_dice_8: 3.63  time: 1.4212  data_time: 0.0535  lr: 8.4059e-06  max_mem: 21588M
[01/18 21:22:24] d2.utils.events INFO:  eta: 12:53:38  iter: 7039  total_loss: 44.59  loss_ce: 0.3594  loss_mask: 0.4929  loss_dice: 3.565  loss_ce_0: 0.6263  loss_mask_0: 0.4672  loss_dice_0: 3.726  loss_ce_1: 0.3693  loss_mask_1: 0.4889  loss_dice_1: 3.611  loss_ce_2: 0.3661  loss_mask_2: 0.4924  loss_dice_2: 3.581  loss_ce_3: 0.364  loss_mask_3: 0.4946  loss_dice_3: 3.582  loss_ce_4: 0.3584  loss_mask_4: 0.4921  loss_dice_4: 3.568  loss_ce_5: 0.3504  loss_mask_5: 0.4933  loss_dice_5: 3.567  loss_ce_6: 0.3562  loss_mask_6: 0.4918  loss_dice_6: 3.57  loss_ce_7: 0.3585  loss_mask_7: 0.4927  loss_dice_7: 3.568  loss_ce_8: 0.3472  loss_mask_8: 0.4926  loss_dice_8: 3.566  time: 1.4211  data_time: 0.0526  lr: 8.4013e-06  max_mem: 21588M
[01/18 21:22:52] d2.utils.events INFO:  eta: 12:51:38  iter: 7059  total_loss: 44.77  loss_ce: 0.3671  loss_mask: 0.5012  loss_dice: 3.555  loss_ce_0: 0.6223  loss_mask_0: 0.4747  loss_dice_0: 3.703  loss_ce_1: 0.3862  loss_mask_1: 0.5071  loss_dice_1: 3.589  loss_ce_2: 0.3811  loss_mask_2: 0.5057  loss_dice_2: 3.565  loss_ce_3: 0.3656  loss_mask_3: 0.4994  loss_dice_3: 3.552  loss_ce_4: 0.3683  loss_mask_4: 0.4956  loss_dice_4: 3.557  loss_ce_5: 0.3592  loss_mask_5: 0.4988  loss_dice_5: 3.557  loss_ce_6: 0.3558  loss_mask_6: 0.5008  loss_dice_6: 3.558  loss_ce_7: 0.3681  loss_mask_7: 0.4985  loss_dice_7: 3.548  loss_ce_8: 0.3711  loss_mask_8: 0.5001  loss_dice_8: 3.549  time: 1.4209  data_time: 0.0522  lr: 8.3967e-06  max_mem: 21588M
[01/18 21:23:20] d2.utils.events INFO:  eta: 12:49:53  iter: 7079  total_loss: 44.91  loss_ce: 0.3882  loss_mask: 0.5006  loss_dice: 3.557  loss_ce_0: 0.6419  loss_mask_0: 0.4702  loss_dice_0: 3.714  loss_ce_1: 0.4094  loss_mask_1: 0.4987  loss_dice_1: 3.602  loss_ce_2: 0.3912  loss_mask_2: 0.4999  loss_dice_2: 3.586  loss_ce_3: 0.3782  loss_mask_3: 0.5004  loss_dice_3: 3.566  loss_ce_4: 0.372  loss_mask_4: 0.5019  loss_dice_4: 3.568  loss_ce_5: 0.3785  loss_mask_5: 0.5  loss_dice_5: 3.57  loss_ce_6: 0.3721  loss_mask_6: 0.5017  loss_dice_6: 3.566  loss_ce_7: 0.3743  loss_mask_7: 0.4997  loss_dice_7: 3.566  loss_ce_8: 0.3681  loss_mask_8: 0.4999  loss_dice_8: 3.56  time: 1.4208  data_time: 0.0543  lr: 8.3921e-06  max_mem: 21588M
[01/18 21:23:48] d2.utils.events INFO:  eta: 12:47:24  iter: 7099  total_loss: 44.77  loss_ce: 0.3464  loss_mask: 0.4724  loss_dice: 3.564  loss_ce_0: 0.6206  loss_mask_0: 0.449  loss_dice_0: 3.731  loss_ce_1: 0.3529  loss_mask_1: 0.4745  loss_dice_1: 3.62  loss_ce_2: 0.3581  loss_mask_2: 0.4764  loss_dice_2: 3.59  loss_ce_3: 0.3528  loss_mask_3: 0.475  loss_dice_3: 3.572  loss_ce_4: 0.351  loss_mask_4: 0.4739  loss_dice_4: 3.583  loss_ce_5: 0.3504  loss_mask_5: 0.4718  loss_dice_5: 3.574  loss_ce_6: 0.3433  loss_mask_6: 0.4719  loss_dice_6: 3.575  loss_ce_7: 0.3538  loss_mask_7: 0.4728  loss_dice_7: 3.567  loss_ce_8: 0.3495  loss_mask_8: 0.4724  loss_dice_8: 3.566  time: 1.4208  data_time: 0.0570  lr: 8.3875e-06  max_mem: 21588M
[01/18 21:24:16] d2.utils.events INFO:  eta: 12:46:00  iter: 7119  total_loss: 45.23  loss_ce: 0.3748  loss_mask: 0.4817  loss_dice: 3.605  loss_ce_0: 0.6511  loss_mask_0: 0.4571  loss_dice_0: 3.738  loss_ce_1: 0.3952  loss_mask_1: 0.4796  loss_dice_1: 3.639  loss_ce_2: 0.3832  loss_mask_2: 0.4786  loss_dice_2: 3.612  loss_ce_3: 0.3808  loss_mask_3: 0.4792  loss_dice_3: 3.614  loss_ce_4: 0.3716  loss_mask_4: 0.484  loss_dice_4: 3.606  loss_ce_5: 0.3777  loss_mask_5: 0.4829  loss_dice_5: 3.618  loss_ce_6: 0.3787  loss_mask_6: 0.4803  loss_dice_6: 3.609  loss_ce_7: 0.3707  loss_mask_7: 0.4812  loss_dice_7: 3.605  loss_ce_8: 0.3787  loss_mask_8: 0.4814  loss_dice_8: 3.609  time: 1.4207  data_time: 0.0589  lr: 8.3829e-06  max_mem: 21588M
[01/18 21:24:43] d2.utils.events INFO:  eta: 12:44:41  iter: 7139  total_loss: 44.81  loss_ce: 0.3662  loss_mask: 0.4923  loss_dice: 3.582  loss_ce_0: 0.639  loss_mask_0: 0.4655  loss_dice_0: 3.74  loss_ce_1: 0.3918  loss_mask_1: 0.4883  loss_dice_1: 3.633  loss_ce_2: 0.375  loss_mask_2: 0.4852  loss_dice_2: 3.611  loss_ce_3: 0.3893  loss_mask_3: 0.4866  loss_dice_3: 3.593  loss_ce_4: 0.3866  loss_mask_4: 0.4867  loss_dice_4: 3.593  loss_ce_5: 0.388  loss_mask_5: 0.4885  loss_dice_5: 3.586  loss_ce_6: 0.3621  loss_mask_6: 0.4868  loss_dice_6: 3.593  loss_ce_7: 0.3735  loss_mask_7: 0.4902  loss_dice_7: 3.593  loss_ce_8: 0.3754  loss_mask_8: 0.4916  loss_dice_8: 3.581  time: 1.4206  data_time: 0.0551  lr: 8.3784e-06  max_mem: 21588M
[01/18 21:25:11] d2.utils.events INFO:  eta: 12:43:04  iter: 7159  total_loss: 44.96  loss_ce: 0.3579  loss_mask: 0.4873  loss_dice: 3.567  loss_ce_0: 0.6415  loss_mask_0: 0.4547  loss_dice_0: 3.737  loss_ce_1: 0.3841  loss_mask_1: 0.4843  loss_dice_1: 3.606  loss_ce_2: 0.3605  loss_mask_2: 0.486  loss_dice_2: 3.578  loss_ce_3: 0.3576  loss_mask_3: 0.4868  loss_dice_3: 3.577  loss_ce_4: 0.3619  loss_mask_4: 0.4864  loss_dice_4: 3.576  loss_ce_5: 0.3622  loss_mask_5: 0.4894  loss_dice_5: 3.567  loss_ce_6: 0.3623  loss_mask_6: 0.4867  loss_dice_6: 3.573  loss_ce_7: 0.3681  loss_mask_7: 0.4871  loss_dice_7: 3.574  loss_ce_8: 0.3645  loss_mask_8: 0.4876  loss_dice_8: 3.577  time: 1.4205  data_time: 0.0536  lr: 8.3738e-06  max_mem: 21588M
[01/18 21:25:39] d2.utils.events INFO:  eta: 12:42:05  iter: 7179  total_loss: 44.9  loss_ce: 0.3697  loss_mask: 0.489  loss_dice: 3.597  loss_ce_0: 0.6288  loss_mask_0: 0.4651  loss_dice_0: 3.731  loss_ce_1: 0.3827  loss_mask_1: 0.4858  loss_dice_1: 3.635  loss_ce_2: 0.3705  loss_mask_2: 0.4863  loss_dice_2: 3.607  loss_ce_3: 0.3584  loss_mask_3: 0.4861  loss_dice_3: 3.597  loss_ce_4: 0.3544  loss_mask_4: 0.4868  loss_dice_4: 3.604  loss_ce_5: 0.3487  loss_mask_5: 0.4891  loss_dice_5: 3.602  loss_ce_6: 0.3533  loss_mask_6: 0.4878  loss_dice_6: 3.598  loss_ce_7: 0.3512  loss_mask_7: 0.4905  loss_dice_7: 3.6  loss_ce_8: 0.3568  loss_mask_8: 0.4899  loss_dice_8: 3.596  time: 1.4205  data_time: 0.0595  lr: 8.3692e-06  max_mem: 21588M
[01/18 21:26:07] d2.utils.events INFO:  eta: 12:41:11  iter: 7199  total_loss: 44.64  loss_ce: 0.371  loss_mask: 0.4802  loss_dice: 3.553  loss_ce_0: 0.6365  loss_mask_0: 0.4566  loss_dice_0: 3.69  loss_ce_1: 0.3999  loss_mask_1: 0.4834  loss_dice_1: 3.584  loss_ce_2: 0.3527  loss_mask_2: 0.4786  loss_dice_2: 3.562  loss_ce_3: 0.3658  loss_mask_3: 0.4788  loss_dice_3: 3.548  loss_ce_4: 0.3553  loss_mask_4: 0.4779  loss_dice_4: 3.552  loss_ce_5: 0.3467  loss_mask_5: 0.4797  loss_dice_5: 3.56  loss_ce_6: 0.3432  loss_mask_6: 0.4801  loss_dice_6: 3.56  loss_ce_7: 0.3551  loss_mask_7: 0.477  loss_dice_7: 3.559  loss_ce_8: 0.3559  loss_mask_8: 0.4784  loss_dice_8: 3.553  time: 1.4204  data_time: 0.0545  lr: 8.3646e-06  max_mem: 21588M
[01/18 21:26:35] d2.utils.events INFO:  eta: 12:40:15  iter: 7219  total_loss: 44.43  loss_ce: 0.3811  loss_mask: 0.4945  loss_dice: 3.544  loss_ce_0: 0.6502  loss_mask_0: 0.4682  loss_dice_0: 3.689  loss_ce_1: 0.3895  loss_mask_1: 0.4933  loss_dice_1: 3.592  loss_ce_2: 0.3822  loss_mask_2: 0.4956  loss_dice_2: 3.566  loss_ce_3: 0.3831  loss_mask_3: 0.4947  loss_dice_3: 3.555  loss_ce_4: 0.3743  loss_mask_4: 0.4934  loss_dice_4: 3.551  loss_ce_5: 0.3758  loss_mask_5: 0.4923  loss_dice_5: 3.553  loss_ce_6: 0.3743  loss_mask_6: 0.4932  loss_dice_6: 3.556  loss_ce_7: 0.3802  loss_mask_7: 0.4945  loss_dice_7: 3.545  loss_ce_8: 0.3824  loss_mask_8: 0.495  loss_dice_8: 3.544  time: 1.4203  data_time: 0.0528  lr: 8.36e-06  max_mem: 21588M
[01/18 21:27:03] d2.utils.events INFO:  eta: 12:38:47  iter: 7239  total_loss: 44.88  loss_ce: 0.3895  loss_mask: 0.4858  loss_dice: 3.565  loss_ce_0: 0.666  loss_mask_0: 0.4624  loss_dice_0: 3.716  loss_ce_1: 0.4162  loss_mask_1: 0.4869  loss_dice_1: 3.61  loss_ce_2: 0.3978  loss_mask_2: 0.4803  loss_dice_2: 3.594  loss_ce_3: 0.3834  loss_mask_3: 0.4819  loss_dice_3: 3.589  loss_ce_4: 0.3818  loss_mask_4: 0.4858  loss_dice_4: 3.581  loss_ce_5: 0.395  loss_mask_5: 0.4868  loss_dice_5: 3.573  loss_ce_6: 0.3864  loss_mask_6: 0.4851  loss_dice_6: 3.569  loss_ce_7: 0.3964  loss_mask_7: 0.488  loss_dice_7: 3.576  loss_ce_8: 0.3873  loss_mask_8: 0.4855  loss_dice_8: 3.577  time: 1.4202  data_time: 0.0552  lr: 8.3554e-06  max_mem: 21588M
[01/18 21:27:30] d2.utils.events INFO:  eta: 12:37:34  iter: 7259  total_loss: 44.72  loss_ce: 0.37  loss_mask: 0.4833  loss_dice: 3.529  loss_ce_0: 0.6271  loss_mask_0: 0.4541  loss_dice_0: 3.685  loss_ce_1: 0.371  loss_mask_1: 0.4855  loss_dice_1: 3.567  loss_ce_2: 0.3812  loss_mask_2: 0.4815  loss_dice_2: 3.538  loss_ce_3: 0.3659  loss_mask_3: 0.4853  loss_dice_3: 3.529  loss_ce_4: 0.3705  loss_mask_4: 0.4841  loss_dice_4: 3.533  loss_ce_5: 0.3599  loss_mask_5: 0.4832  loss_dice_5: 3.532  loss_ce_6: 0.3559  loss_mask_6: 0.4841  loss_dice_6: 3.525  loss_ce_7: 0.36  loss_mask_7: 0.4833  loss_dice_7: 3.521  loss_ce_8: 0.3654  loss_mask_8: 0.4823  loss_dice_8: 3.528  time: 1.4201  data_time: 0.0643  lr: 8.3508e-06  max_mem: 21588M
[01/18 21:27:58] d2.utils.events INFO:  eta: 12:36:41  iter: 7279  total_loss: 44.12  loss_ce: 0.3566  loss_mask: 0.4911  loss_dice: 3.507  loss_ce_0: 0.6081  loss_mask_0: 0.4634  loss_dice_0: 3.667  loss_ce_1: 0.3693  loss_mask_1: 0.492  loss_dice_1: 3.549  loss_ce_2: 0.3684  loss_mask_2: 0.4913  loss_dice_2: 3.522  loss_ce_3: 0.3588  loss_mask_3: 0.4891  loss_dice_3: 3.512  loss_ce_4: 0.3475  loss_mask_4: 0.4882  loss_dice_4: 3.513  loss_ce_5: 0.354  loss_mask_5: 0.4866  loss_dice_5: 3.511  loss_ce_6: 0.3451  loss_mask_6: 0.4888  loss_dice_6: 3.506  loss_ce_7: 0.3421  loss_mask_7: 0.4896  loss_dice_7: 3.507  loss_ce_8: 0.3534  loss_mask_8: 0.4896  loss_dice_8: 3.497  time: 1.4200  data_time: 0.0527  lr: 8.3462e-06  max_mem: 21588M
[01/18 21:28:26] d2.utils.events INFO:  eta: 12:35:41  iter: 7299  total_loss: 43.91  loss_ce: 0.3672  loss_mask: 0.4987  loss_dice: 3.501  loss_ce_0: 0.6077  loss_mask_0: 0.469  loss_dice_0: 3.671  loss_ce_1: 0.3502  loss_mask_1: 0.4981  loss_dice_1: 3.548  loss_ce_2: 0.3641  loss_mask_2: 0.5035  loss_dice_2: 3.525  loss_ce_3: 0.3581  loss_mask_3: 0.5002  loss_dice_3: 3.514  loss_ce_4: 0.3505  loss_mask_4: 0.501  loss_dice_4: 3.511  loss_ce_5: 0.3446  loss_mask_5: 0.5005  loss_dice_5: 3.517  loss_ce_6: 0.3404  loss_mask_6: 0.502  loss_dice_6: 3.508  loss_ce_7: 0.3648  loss_mask_7: 0.5  loss_dice_7: 3.507  loss_ce_8: 0.3541  loss_mask_8: 0.4991  loss_dice_8: 3.505  time: 1.4198  data_time: 0.0542  lr: 8.3416e-06  max_mem: 21588M
[01/18 21:28:53] d2.utils.events INFO:  eta: 12:34:40  iter: 7319  total_loss: 44.4  loss_ce: 0.3392  loss_mask: 0.4835  loss_dice: 3.572  loss_ce_0: 0.6732  loss_mask_0: 0.4638  loss_dice_0: 3.689  loss_ce_1: 0.3785  loss_mask_1: 0.4863  loss_dice_1: 3.595  loss_ce_2: 0.3623  loss_mask_2: 0.4887  loss_dice_2: 3.574  loss_ce_3: 0.3652  loss_mask_3: 0.4836  loss_dice_3: 3.57  loss_ce_4: 0.346  loss_mask_4: 0.4863  loss_dice_4: 3.565  loss_ce_5: 0.3555  loss_mask_5: 0.486  loss_dice_5: 3.566  loss_ce_6: 0.3469  loss_mask_6: 0.4835  loss_dice_6: 3.568  loss_ce_7: 0.3487  loss_mask_7: 0.4853  loss_dice_7: 3.574  loss_ce_8: 0.3304  loss_mask_8: 0.4855  loss_dice_8: 3.566  time: 1.4197  data_time: 0.0552  lr: 8.337e-06  max_mem: 21588M
[01/18 21:29:21] d2.utils.events INFO:  eta: 12:33:43  iter: 7339  total_loss: 44.5  loss_ce: 0.3797  loss_mask: 0.4776  loss_dice: 3.556  loss_ce_0: 0.6348  loss_mask_0: 0.4532  loss_dice_0: 3.717  loss_ce_1: 0.3675  loss_mask_1: 0.4792  loss_dice_1: 3.603  loss_ce_2: 0.3762  loss_mask_2: 0.4794  loss_dice_2: 3.578  loss_ce_3: 0.3644  loss_mask_3: 0.48  loss_dice_3: 3.573  loss_ce_4: 0.3618  loss_mask_4: 0.479  loss_dice_4: 3.569  loss_ce_5: 0.3613  loss_mask_5: 0.4787  loss_dice_5: 3.563  loss_ce_6: 0.3623  loss_mask_6: 0.4768  loss_dice_6: 3.557  loss_ce_7: 0.3642  loss_mask_7: 0.4792  loss_dice_7: 3.557  loss_ce_8: 0.3649  loss_mask_8: 0.4791  loss_dice_8: 3.555  time: 1.4196  data_time: 0.0575  lr: 8.3324e-06  max_mem: 21588M
[01/18 21:29:49] d2.utils.events INFO:  eta: 12:33:01  iter: 7359  total_loss: 44.6  loss_ce: 0.3752  loss_mask: 0.4916  loss_dice: 3.518  loss_ce_0: 0.6381  loss_mask_0: 0.464  loss_dice_0: 3.672  loss_ce_1: 0.3842  loss_mask_1: 0.4956  loss_dice_1: 3.565  loss_ce_2: 0.3896  loss_mask_2: 0.4926  loss_dice_2: 3.54  loss_ce_3: 0.3692  loss_mask_3: 0.4933  loss_dice_3: 3.522  loss_ce_4: 0.3674  loss_mask_4: 0.4941  loss_dice_4: 3.529  loss_ce_5: 0.3661  loss_mask_5: 0.4932  loss_dice_5: 3.521  loss_ce_6: 0.3649  loss_mask_6: 0.4919  loss_dice_6: 3.522  loss_ce_7: 0.3589  loss_mask_7: 0.4933  loss_dice_7: 3.522  loss_ce_8: 0.3696  loss_mask_8: 0.4917  loss_dice_8: 3.517  time: 1.4195  data_time: 0.0535  lr: 8.3279e-06  max_mem: 21588M
[01/18 21:30:16] d2.utils.events INFO:  eta: 12:32:31  iter: 7379  total_loss: 44.25  loss_ce: 0.3769  loss_mask: 0.4827  loss_dice: 3.507  loss_ce_0: 0.615  loss_mask_0: 0.4551  loss_dice_0: 3.658  loss_ce_1: 0.3808  loss_mask_1: 0.4799  loss_dice_1: 3.554  loss_ce_2: 0.3946  loss_mask_2: 0.4836  loss_dice_2: 3.521  loss_ce_3: 0.3793  loss_mask_3: 0.4844  loss_dice_3: 3.512  loss_ce_4: 0.3861  loss_mask_4: 0.4837  loss_dice_4: 3.516  loss_ce_5: 0.3836  loss_mask_5: 0.4827  loss_dice_5: 3.51  loss_ce_6: 0.3877  loss_mask_6: 0.4819  loss_dice_6: 3.501  loss_ce_7: 0.3728  loss_mask_7: 0.4814  loss_dice_7: 3.506  loss_ce_8: 0.3822  loss_mask_8: 0.4834  loss_dice_8: 3.504  time: 1.4194  data_time: 0.0558  lr: 8.3233e-06  max_mem: 21588M
[01/18 21:30:44] d2.utils.events INFO:  eta: 12:31:49  iter: 7399  total_loss: 44.61  loss_ce: 0.3613  loss_mask: 0.4746  loss_dice: 3.577  loss_ce_0: 0.6593  loss_mask_0: 0.4553  loss_dice_0: 3.728  loss_ce_1: 0.3796  loss_mask_1: 0.4723  loss_dice_1: 3.617  loss_ce_2: 0.3513  loss_mask_2: 0.4744  loss_dice_2: 3.598  loss_ce_3: 0.3408  loss_mask_3: 0.4773  loss_dice_3: 3.588  loss_ce_4: 0.3576  loss_mask_4: 0.474  loss_dice_4: 3.587  loss_ce_5: 0.3674  loss_mask_5: 0.4728  loss_dice_5: 3.582  loss_ce_6: 0.3424  loss_mask_6: 0.4766  loss_dice_6: 3.584  loss_ce_7: 0.349  loss_mask_7: 0.4739  loss_dice_7: 3.585  loss_ce_8: 0.3608  loss_mask_8: 0.475  loss_dice_8: 3.583  time: 1.4194  data_time: 0.0547  lr: 8.3187e-06  max_mem: 21588M
[01/18 21:31:12] d2.utils.events INFO:  eta: 12:31:16  iter: 7419  total_loss: 44.6  loss_ce: 0.3755  loss_mask: 0.4962  loss_dice: 3.52  loss_ce_0: 0.6197  loss_mask_0: 0.4653  loss_dice_0: 3.663  loss_ce_1: 0.3956  loss_mask_1: 0.4915  loss_dice_1: 3.557  loss_ce_2: 0.3735  loss_mask_2: 0.4905  loss_dice_2: 3.537  loss_ce_3: 0.3712  loss_mask_3: 0.4915  loss_dice_3: 3.526  loss_ce_4: 0.3728  loss_mask_4: 0.495  loss_dice_4: 3.526  loss_ce_5: 0.3807  loss_mask_5: 0.4936  loss_dice_5: 3.526  loss_ce_6: 0.3646  loss_mask_6: 0.4935  loss_dice_6: 3.53  loss_ce_7: 0.3673  loss_mask_7: 0.496  loss_dice_7: 3.523  loss_ce_8: 0.3521  loss_mask_8: 0.4961  loss_dice_8: 3.529  time: 1.4192  data_time: 0.0554  lr: 8.3141e-06  max_mem: 21588M
[01/18 21:31:40] d2.utils.events INFO:  eta: 12:30:58  iter: 7439  total_loss: 44.98  loss_ce: 0.4031  loss_mask: 0.4985  loss_dice: 3.559  loss_ce_0: 0.6626  loss_mask_0: 0.4706  loss_dice_0: 3.71  loss_ce_1: 0.4033  loss_mask_1: 0.5055  loss_dice_1: 3.59  loss_ce_2: 0.3995  loss_mask_2: 0.5024  loss_dice_2: 3.574  loss_ce_3: 0.377  loss_mask_3: 0.4979  loss_dice_3: 3.563  loss_ce_4: 0.3891  loss_mask_4: 0.4957  loss_dice_4: 3.568  loss_ce_5: 0.3859  loss_mask_5: 0.4933  loss_dice_5: 3.569  loss_ce_6: 0.3772  loss_mask_6: 0.4936  loss_dice_6: 3.562  loss_ce_7: 0.3798  loss_mask_7: 0.4965  loss_dice_7: 3.57  loss_ce_8: 0.3787  loss_mask_8: 0.4967  loss_dice_8: 3.564  time: 1.4191  data_time: 0.0513  lr: 8.3095e-06  max_mem: 21588M
[01/18 21:32:07] d2.utils.events INFO:  eta: 12:30:45  iter: 7459  total_loss: 44.72  loss_ce: 0.387  loss_mask: 0.4883  loss_dice: 3.572  loss_ce_0: 0.6655  loss_mask_0: 0.4707  loss_dice_0: 3.684  loss_ce_1: 0.3984  loss_mask_1: 0.4913  loss_dice_1: 3.613  loss_ce_2: 0.3857  loss_mask_2: 0.4904  loss_dice_2: 3.586  loss_ce_3: 0.3717  loss_mask_3: 0.4864  loss_dice_3: 3.573  loss_ce_4: 0.376  loss_mask_4: 0.4859  loss_dice_4: 3.579  loss_ce_5: 0.376  loss_mask_5: 0.4865  loss_dice_5: 3.572  loss_ce_6: 0.3724  loss_mask_6: 0.4842  loss_dice_6: 3.58  loss_ce_7: 0.3763  loss_mask_7: 0.486  loss_dice_7: 3.568  loss_ce_8: 0.3831  loss_mask_8: 0.4846  loss_dice_8: 3.567  time: 1.4191  data_time: 0.0568  lr: 8.3049e-06  max_mem: 21588M
[01/18 21:32:35] d2.utils.events INFO:  eta: 12:30:13  iter: 7479  total_loss: 44.94  loss_ce: 0.3811  loss_mask: 0.4894  loss_dice: 3.556  loss_ce_0: 0.6303  loss_mask_0: 0.4669  loss_dice_0: 3.704  loss_ce_1: 0.3903  loss_mask_1: 0.493  loss_dice_1: 3.594  loss_ce_2: 0.3808  loss_mask_2: 0.4943  loss_dice_2: 3.571  loss_ce_3: 0.3775  loss_mask_3: 0.4901  loss_dice_3: 3.56  loss_ce_4: 0.3908  loss_mask_4: 0.49  loss_dice_4: 3.567  loss_ce_5: 0.3763  loss_mask_5: 0.4925  loss_dice_5: 3.565  loss_ce_6: 0.3786  loss_mask_6: 0.492  loss_dice_6: 3.556  loss_ce_7: 0.3919  loss_mask_7: 0.4899  loss_dice_7: 3.558  loss_ce_8: 0.3866  loss_mask_8: 0.4928  loss_dice_8: 3.557  time: 1.4190  data_time: 0.0526  lr: 8.3003e-06  max_mem: 21588M
[01/18 21:33:03] d2.utils.events INFO:  eta: 12:29:52  iter: 7499  total_loss: 44.39  loss_ce: 0.3678  loss_mask: 0.474  loss_dice: 3.526  loss_ce_0: 0.6555  loss_mask_0: 0.4527  loss_dice_0: 3.689  loss_ce_1: 0.4121  loss_mask_1: 0.4751  loss_dice_1: 3.574  loss_ce_2: 0.3516  loss_mask_2: 0.4724  loss_dice_2: 3.539  loss_ce_3: 0.3592  loss_mask_3: 0.4695  loss_dice_3: 3.533  loss_ce_4: 0.3533  loss_mask_4: 0.4718  loss_dice_4: 3.531  loss_ce_5: 0.3619  loss_mask_5: 0.4741  loss_dice_5: 3.536  loss_ce_6: 0.3409  loss_mask_6: 0.4745  loss_dice_6: 3.541  loss_ce_7: 0.3702  loss_mask_7: 0.4734  loss_dice_7: 3.531  loss_ce_8: 0.3618  loss_mask_8: 0.4732  loss_dice_8: 3.534  time: 1.4189  data_time: 0.0554  lr: 8.2957e-06  max_mem: 21588M
[01/18 21:33:31] d2.utils.events INFO:  eta: 12:29:27  iter: 7519  total_loss: 44.49  loss_ce: 0.3795  loss_mask: 0.4795  loss_dice: 3.545  loss_ce_0: 0.6381  loss_mask_0: 0.4533  loss_dice_0: 3.701  loss_ce_1: 0.3792  loss_mask_1: 0.4793  loss_dice_1: 3.59  loss_ce_2: 0.3775  loss_mask_2: 0.4735  loss_dice_2: 3.558  loss_ce_3: 0.3604  loss_mask_3: 0.4752  loss_dice_3: 3.552  loss_ce_4: 0.3701  loss_mask_4: 0.4758  loss_dice_4: 3.544  loss_ce_5: 0.3781  loss_mask_5: 0.4792  loss_dice_5: 3.545  loss_ce_6: 0.3484  loss_mask_6: 0.4812  loss_dice_6: 3.548  loss_ce_7: 0.381  loss_mask_7: 0.4802  loss_dice_7: 3.55  loss_ce_8: 0.3877  loss_mask_8: 0.479  loss_dice_8: 3.543  time: 1.4188  data_time: 0.0546  lr: 8.2911e-06  max_mem: 21588M
[01/18 21:33:59] d2.utils.events INFO:  eta: 12:29:35  iter: 7539  total_loss: 44.58  loss_ce: 0.3745  loss_mask: 0.4961  loss_dice: 3.519  loss_ce_0: 0.6431  loss_mask_0: 0.4662  loss_dice_0: 3.654  loss_ce_1: 0.3844  loss_mask_1: 0.4905  loss_dice_1: 3.562  loss_ce_2: 0.3839  loss_mask_2: 0.4939  loss_dice_2: 3.531  loss_ce_3: 0.3577  loss_mask_3: 0.497  loss_dice_3: 3.528  loss_ce_4: 0.371  loss_mask_4: 0.4988  loss_dice_4: 3.527  loss_ce_5: 0.3723  loss_mask_5: 0.4971  loss_dice_5: 3.529  loss_ce_6: 0.3606  loss_mask_6: 0.4991  loss_dice_6: 3.53  loss_ce_7: 0.3678  loss_mask_7: 0.5002  loss_dice_7: 3.518  loss_ce_8: 0.381  loss_mask_8: 0.4979  loss_dice_8: 3.526  time: 1.4188  data_time: 0.0589  lr: 8.2865e-06  max_mem: 21588M
[01/18 21:34:27] d2.utils.events INFO:  eta: 12:29:14  iter: 7559  total_loss: 44.05  loss_ce: 0.3706  loss_mask: 0.4934  loss_dice: 3.488  loss_ce_0: 0.6217  loss_mask_0: 0.4624  loss_dice_0: 3.652  loss_ce_1: 0.3755  loss_mask_1: 0.4863  loss_dice_1: 3.533  loss_ce_2: 0.3719  loss_mask_2: 0.4875  loss_dice_2: 3.5  loss_ce_3: 0.3741  loss_mask_3: 0.4904  loss_dice_3: 3.497  loss_ce_4: 0.3723  loss_mask_4: 0.4909  loss_dice_4: 3.5  loss_ce_5: 0.3691  loss_mask_5: 0.4928  loss_dice_5: 3.492  loss_ce_6: 0.3687  loss_mask_6: 0.4931  loss_dice_6: 3.493  loss_ce_7: 0.3767  loss_mask_7: 0.4975  loss_dice_7: 3.484  loss_ce_8: 0.3748  loss_mask_8: 0.494  loss_dice_8: 3.489  time: 1.4187  data_time: 0.0534  lr: 8.2819e-06  max_mem: 21588M
[01/18 21:34:55] d2.utils.events INFO:  eta: 12:28:57  iter: 7579  total_loss: 44.44  loss_ce: 0.3983  loss_mask: 0.4839  loss_dice: 3.529  loss_ce_0: 0.6556  loss_mask_0: 0.4654  loss_dice_0: 3.66  loss_ce_1: 0.4033  loss_mask_1: 0.4971  loss_dice_1: 3.553  loss_ce_2: 0.3746  loss_mask_2: 0.494  loss_dice_2: 3.536  loss_ce_3: 0.3781  loss_mask_3: 0.487  loss_dice_3: 3.536  loss_ce_4: 0.3775  loss_mask_4: 0.4838  loss_dice_4: 3.528  loss_ce_5: 0.384  loss_mask_5: 0.483  loss_dice_5: 3.523  loss_ce_6: 0.3801  loss_mask_6: 0.486  loss_dice_6: 3.521  loss_ce_7: 0.4024  loss_mask_7: 0.4836  loss_dice_7: 3.54  loss_ce_8: 0.3967  loss_mask_8: 0.4837  loss_dice_8: 3.526  time: 1.4186  data_time: 0.0534  lr: 8.2773e-06  max_mem: 21588M
[01/18 21:35:23] d2.utils.events INFO:  eta: 12:29:09  iter: 7599  total_loss: 44.18  loss_ce: 0.3927  loss_mask: 0.4693  loss_dice: 3.533  loss_ce_0: 0.6617  loss_mask_0: 0.4415  loss_dice_0: 3.665  loss_ce_1: 0.3765  loss_mask_1: 0.4703  loss_dice_1: 3.562  loss_ce_2: 0.3697  loss_mask_2: 0.4657  loss_dice_2: 3.536  loss_ce_3: 0.3708  loss_mask_3: 0.467  loss_dice_3: 3.538  loss_ce_4: 0.3815  loss_mask_4: 0.4679  loss_dice_4: 3.521  loss_ce_5: 0.3726  loss_mask_5: 0.4679  loss_dice_5: 3.529  loss_ce_6: 0.3766  loss_mask_6: 0.4685  loss_dice_6: 3.528  loss_ce_7: 0.3727  loss_mask_7: 0.4686  loss_dice_7: 3.531  loss_ce_8: 0.3892  loss_mask_8: 0.4683  loss_dice_8: 3.529  time: 1.4186  data_time: 0.0562  lr: 8.2727e-06  max_mem: 21588M
[01/18 21:35:50] d2.utils.events INFO:  eta: 12:28:33  iter: 7619  total_loss: 43.82  loss_ce: 0.3718  loss_mask: 0.4857  loss_dice: 3.481  loss_ce_0: 0.6002  loss_mask_0: 0.4554  loss_dice_0: 3.65  loss_ce_1: 0.3577  loss_mask_1: 0.4872  loss_dice_1: 3.538  loss_ce_2: 0.3491  loss_mask_2: 0.4854  loss_dice_2: 3.501  loss_ce_3: 0.3437  loss_mask_3: 0.484  loss_dice_3: 3.494  loss_ce_4: 0.3485  loss_mask_4: 0.4853  loss_dice_4: 3.494  loss_ce_5: 0.3579  loss_mask_5: 0.4847  loss_dice_5: 3.487  loss_ce_6: 0.352  loss_mask_6: 0.4863  loss_dice_6: 3.491  loss_ce_7: 0.3632  loss_mask_7: 0.4881  loss_dice_7: 3.491  loss_ce_8: 0.3634  loss_mask_8: 0.4861  loss_dice_8: 3.491  time: 1.4185  data_time: 0.0512  lr: 8.2681e-06  max_mem: 21588M
[01/18 21:36:19] d2.utils.events INFO:  eta: 12:28:00  iter: 7639  total_loss: 44.48  loss_ce: 0.3468  loss_mask: 0.4948  loss_dice: 3.537  loss_ce_0: 0.6161  loss_mask_0: 0.4574  loss_dice_0: 3.687  loss_ce_1: 0.3671  loss_mask_1: 0.493  loss_dice_1: 3.575  loss_ce_2: 0.3549  loss_mask_2: 0.495  loss_dice_2: 3.555  loss_ce_3: 0.3415  loss_mask_3: 0.4937  loss_dice_3: 3.542  loss_ce_4: 0.3602  loss_mask_4: 0.4908  loss_dice_4: 3.538  loss_ce_5: 0.3462  loss_mask_5: 0.4938  loss_dice_5: 3.538  loss_ce_6: 0.3464  loss_mask_6: 0.4904  loss_dice_6: 3.537  loss_ce_7: 0.3462  loss_mask_7: 0.4881  loss_dice_7: 3.535  loss_ce_8: 0.3517  loss_mask_8: 0.4926  loss_dice_8: 3.534  time: 1.4184  data_time: 0.0640  lr: 8.2635e-06  max_mem: 21588M
[01/18 21:36:47] d2.utils.events INFO:  eta: 12:27:33  iter: 7659  total_loss: 44.09  loss_ce: 0.3757  loss_mask: 0.4915  loss_dice: 3.496  loss_ce_0: 0.6454  loss_mask_0: 0.4498  loss_dice_0: 3.656  loss_ce_1: 0.3721  loss_mask_1: 0.4832  loss_dice_1: 3.539  loss_ce_2: 0.3637  loss_mask_2: 0.489  loss_dice_2: 3.511  loss_ce_3: 0.3559  loss_mask_3: 0.484  loss_dice_3: 3.513  loss_ce_4: 0.373  loss_mask_4: 0.4842  loss_dice_4: 3.508  loss_ce_5: 0.3794  loss_mask_5: 0.4851  loss_dice_5: 3.503  loss_ce_6: 0.3661  loss_mask_6: 0.4847  loss_dice_6: 3.506  loss_ce_7: 0.3722  loss_mask_7: 0.4868  loss_dice_7: 3.503  loss_ce_8: 0.3715  loss_mask_8: 0.4921  loss_dice_8: 3.492  time: 1.4185  data_time: 0.0616  lr: 8.2589e-06  max_mem: 21588M
[01/18 21:37:15] d2.utils.events INFO:  eta: 12:26:49  iter: 7679  total_loss: 43.64  loss_ce: 0.3639  loss_mask: 0.4757  loss_dice: 3.473  loss_ce_0: 0.6405  loss_mask_0: 0.4447  loss_dice_0: 3.624  loss_ce_1: 0.403  loss_mask_1: 0.4754  loss_dice_1: 3.499  loss_ce_2: 0.3801  loss_mask_2: 0.4738  loss_dice_2: 3.475  loss_ce_3: 0.3938  loss_mask_3: 0.4736  loss_dice_3: 3.462  loss_ce_4: 0.3801  loss_mask_4: 0.4721  loss_dice_4: 3.471  loss_ce_5: 0.3855  loss_mask_5: 0.4732  loss_dice_5: 3.464  loss_ce_6: 0.383  loss_mask_6: 0.476  loss_dice_6: 3.464  loss_ce_7: 0.3801  loss_mask_7: 0.4756  loss_dice_7: 3.469  loss_ce_8: 0.3701  loss_mask_8: 0.475  loss_dice_8: 3.475  time: 1.4184  data_time: 0.0589  lr: 8.2543e-06  max_mem: 21588M
[01/18 21:37:44] d2.utils.events INFO:  eta: 12:26:37  iter: 7699  total_loss: 44.36  loss_ce: 0.3781  loss_mask: 0.4673  loss_dice: 3.564  loss_ce_0: 0.6577  loss_mask_0: 0.4423  loss_dice_0: 3.709  loss_ce_1: 0.3961  loss_mask_1: 0.4674  loss_dice_1: 3.603  loss_ce_2: 0.3674  loss_mask_2: 0.4707  loss_dice_2: 3.578  loss_ce_3: 0.3666  loss_mask_3: 0.4684  loss_dice_3: 3.577  loss_ce_4: 0.3575  loss_mask_4: 0.4686  loss_dice_4: 3.576  loss_ce_5: 0.3842  loss_mask_5: 0.4717  loss_dice_5: 3.566  loss_ce_6: 0.3829  loss_mask_6: 0.4675  loss_dice_6: 3.568  loss_ce_7: 0.3675  loss_mask_7: 0.4644  loss_dice_7: 3.572  loss_ce_8: 0.3853  loss_mask_8: 0.4678  loss_dice_8: 3.565  time: 1.4184  data_time: 0.0661  lr: 8.2497e-06  max_mem: 21588M
[01/18 21:38:12] d2.utils.events INFO:  eta: 12:26:37  iter: 7719  total_loss: 44.37  loss_ce: 0.387  loss_mask: 0.4842  loss_dice: 3.518  loss_ce_0: 0.6001  loss_mask_0: 0.4611  loss_dice_0: 3.662  loss_ce_1: 0.4053  loss_mask_1: 0.4912  loss_dice_1: 3.558  loss_ce_2: 0.4067  loss_mask_2: 0.489  loss_dice_2: 3.529  loss_ce_3: 0.3951  loss_mask_3: 0.487  loss_dice_3: 3.532  loss_ce_4: 0.399  loss_mask_4: 0.4844  loss_dice_4: 3.524  loss_ce_5: 0.3971  loss_mask_5: 0.4831  loss_dice_5: 3.525  loss_ce_6: 0.3901  loss_mask_6: 0.4845  loss_dice_6: 3.524  loss_ce_7: 0.3939  loss_mask_7: 0.4828  loss_dice_7: 3.526  loss_ce_8: 0.4038  loss_mask_8: 0.4824  loss_dice_8: 3.524  time: 1.4184  data_time: 0.0600  lr: 8.2451e-06  max_mem: 21588M
[01/18 21:38:40] d2.utils.events INFO:  eta: 12:26:20  iter: 7739  total_loss: 44.61  loss_ce: 0.3808  loss_mask: 0.4773  loss_dice: 3.516  loss_ce_0: 0.6673  loss_mask_0: 0.4517  loss_dice_0: 3.686  loss_ce_1: 0.4098  loss_mask_1: 0.4778  loss_dice_1: 3.559  loss_ce_2: 0.4115  loss_mask_2: 0.4764  loss_dice_2: 3.53  loss_ce_3: 0.3817  loss_mask_3: 0.4798  loss_dice_3: 3.516  loss_ce_4: 0.3972  loss_mask_4: 0.4784  loss_dice_4: 3.52  loss_ce_5: 0.3926  loss_mask_5: 0.4789  loss_dice_5: 3.518  loss_ce_6: 0.3857  loss_mask_6: 0.479  loss_dice_6: 3.517  loss_ce_7: 0.3899  loss_mask_7: 0.4802  loss_dice_7: 3.519  loss_ce_8: 0.3766  loss_mask_8: 0.4794  loss_dice_8: 3.512  time: 1.4184  data_time: 0.0627  lr: 8.2405e-06  max_mem: 21588M
[01/18 21:39:08] d2.utils.events INFO:  eta: 12:26:04  iter: 7759  total_loss: 44.23  loss_ce: 0.3676  loss_mask: 0.4769  loss_dice: 3.508  loss_ce_0: 0.6168  loss_mask_0: 0.4489  loss_dice_0: 3.641  loss_ce_1: 0.401  loss_mask_1: 0.4807  loss_dice_1: 3.538  loss_ce_2: 0.3697  loss_mask_2: 0.48  loss_dice_2: 3.52  loss_ce_3: 0.3571  loss_mask_3: 0.4765  loss_dice_3: 3.51  loss_ce_4: 0.3665  loss_mask_4: 0.4764  loss_dice_4: 3.515  loss_ce_5: 0.3713  loss_mask_5: 0.4779  loss_dice_5: 3.508  loss_ce_6: 0.3763  loss_mask_6: 0.4772  loss_dice_6: 3.506  loss_ce_7: 0.3582  loss_mask_7: 0.4761  loss_dice_7: 3.508  loss_ce_8: 0.358  loss_mask_8: 0.477  loss_dice_8: 3.506  time: 1.4183  data_time: 0.0589  lr: 8.2359e-06  max_mem: 21588M
[01/18 21:39:36] d2.utils.events INFO:  eta: 12:25:42  iter: 7779  total_loss: 44.24  loss_ce: 0.3766  loss_mask: 0.4747  loss_dice: 3.527  loss_ce_0: 0.6113  loss_mask_0: 0.4447  loss_dice_0: 3.683  loss_ce_1: 0.3748  loss_mask_1: 0.4729  loss_dice_1: 3.578  loss_ce_2: 0.3705  loss_mask_2: 0.4701  loss_dice_2: 3.552  loss_ce_3: 0.3573  loss_mask_3: 0.4702  loss_dice_3: 3.541  loss_ce_4: 0.3703  loss_mask_4: 0.4719  loss_dice_4: 3.538  loss_ce_5: 0.3768  loss_mask_5: 0.472  loss_dice_5: 3.531  loss_ce_6: 0.3647  loss_mask_6: 0.4726  loss_dice_6: 3.538  loss_ce_7: 0.3728  loss_mask_7: 0.4729  loss_dice_7: 3.534  loss_ce_8: 0.3744  loss_mask_8: 0.4727  loss_dice_8: 3.529  time: 1.4182  data_time: 0.0584  lr: 8.2314e-06  max_mem: 21588M
[01/18 21:40:04] d2.utils.events INFO:  eta: 12:25:19  iter: 7799  total_loss: 43.95  loss_ce: 0.3546  loss_mask: 0.475  loss_dice: 3.547  loss_ce_0: 0.6287  loss_mask_0: 0.4545  loss_dice_0: 3.678  loss_ce_1: 0.3459  loss_mask_1: 0.4758  loss_dice_1: 3.58  loss_ce_2: 0.3445  loss_mask_2: 0.4744  loss_dice_2: 3.552  loss_ce_3: 0.3532  loss_mask_3: 0.4741  loss_dice_3: 3.547  loss_ce_4: 0.3523  loss_mask_4: 0.4752  loss_dice_4: 3.541  loss_ce_5: 0.3425  loss_mask_5: 0.4737  loss_dice_5: 3.556  loss_ce_6: 0.3415  loss_mask_6: 0.4746  loss_dice_6: 3.551  loss_ce_7: 0.3364  loss_mask_7: 0.4764  loss_dice_7: 3.546  loss_ce_8: 0.347  loss_mask_8: 0.4756  loss_dice_8: 3.54  time: 1.4182  data_time: 0.0596  lr: 8.2268e-06  max_mem: 21588M
[01/18 21:40:32] d2.utils.events INFO:  eta: 12:24:58  iter: 7819  total_loss: 44.71  loss_ce: 0.4012  loss_mask: 0.471  loss_dice: 3.536  loss_ce_0: 0.6566  loss_mask_0: 0.4497  loss_dice_0: 3.692  loss_ce_1: 0.3952  loss_mask_1: 0.4684  loss_dice_1: 3.59  loss_ce_2: 0.3738  loss_mask_2: 0.4713  loss_dice_2: 3.561  loss_ce_3: 0.3816  loss_mask_3: 0.4709  loss_dice_3: 3.542  loss_ce_4: 0.3777  loss_mask_4: 0.4715  loss_dice_4: 3.535  loss_ce_5: 0.3887  loss_mask_5: 0.4717  loss_dice_5: 3.536  loss_ce_6: 0.3807  loss_mask_6: 0.471  loss_dice_6: 3.536  loss_ce_7: 0.3845  loss_mask_7: 0.4721  loss_dice_7: 3.533  loss_ce_8: 0.3888  loss_mask_8: 0.4699  loss_dice_8: 3.535  time: 1.4182  data_time: 0.0614  lr: 8.2222e-06  max_mem: 21588M
[01/18 21:41:00] d2.utils.events INFO:  eta: 12:24:36  iter: 7839  total_loss: 44.02  loss_ce: 0.3567  loss_mask: 0.48  loss_dice: 3.541  loss_ce_0: 0.625  loss_mask_0: 0.4555  loss_dice_0: 3.683  loss_ce_1: 0.3532  loss_mask_1: 0.4769  loss_dice_1: 3.59  loss_ce_2: 0.3581  loss_mask_2: 0.477  loss_dice_2: 3.548  loss_ce_3: 0.352  loss_mask_3: 0.477  loss_dice_3: 3.537  loss_ce_4: 0.3647  loss_mask_4: 0.4798  loss_dice_4: 3.544  loss_ce_5: 0.351  loss_mask_5: 0.4798  loss_dice_5: 3.545  loss_ce_6: 0.3586  loss_mask_6: 0.4804  loss_dice_6: 3.534  loss_ce_7: 0.3557  loss_mask_7: 0.4811  loss_dice_7: 3.543  loss_ce_8: 0.3551  loss_mask_8: 0.4821  loss_dice_8: 3.538  time: 1.4181  data_time: 0.0588  lr: 8.2176e-06  max_mem: 21588M
[01/18 21:41:29] d2.utils.events INFO:  eta: 12:24:13  iter: 7859  total_loss: 44.16  loss_ce: 0.4089  loss_mask: 0.4592  loss_dice: 3.518  loss_ce_0: 0.6254  loss_mask_0: 0.4374  loss_dice_0: 3.666  loss_ce_1: 0.4223  loss_mask_1: 0.4633  loss_dice_1: 3.55  loss_ce_2: 0.3919  loss_mask_2: 0.4618  loss_dice_2: 3.536  loss_ce_3: 0.3703  loss_mask_3: 0.4609  loss_dice_3: 3.532  loss_ce_4: 0.3845  loss_mask_4: 0.462  loss_dice_4: 3.524  loss_ce_5: 0.4151  loss_mask_5: 0.4598  loss_dice_5: 3.519  loss_ce_6: 0.4033  loss_mask_6: 0.4577  loss_dice_6: 3.519  loss_ce_7: 0.3991  loss_mask_7: 0.4574  loss_dice_7: 3.522  loss_ce_8: 0.3978  loss_mask_8: 0.4603  loss_dice_8: 3.519  time: 1.4181  data_time: 0.0646  lr: 8.213e-06  max_mem: 21588M
[01/18 21:41:56] d2.utils.events INFO:  eta: 12:23:32  iter: 7879  total_loss: 44.61  loss_ce: 0.4101  loss_mask: 0.4752  loss_dice: 3.522  loss_ce_0: 0.6343  loss_mask_0: 0.4526  loss_dice_0: 3.669  loss_ce_1: 0.3925  loss_mask_1: 0.4788  loss_dice_1: 3.553  loss_ce_2: 0.3944  loss_mask_2: 0.4831  loss_dice_2: 3.531  loss_ce_3: 0.3975  loss_mask_3: 0.4823  loss_dice_3: 3.527  loss_ce_4: 0.3953  loss_mask_4: 0.4819  loss_dice_4: 3.521  loss_ce_5: 0.3965  loss_mask_5: 0.4799  loss_dice_5: 3.515  loss_ce_6: 0.4075  loss_mask_6: 0.4792  loss_dice_6: 3.52  loss_ce_7: 0.4114  loss_mask_7: 0.4786  loss_dice_7: 3.524  loss_ce_8: 0.4076  loss_mask_8: 0.4773  loss_dice_8: 3.505  time: 1.4180  data_time: 0.0614  lr: 8.2084e-06  max_mem: 21588M
[01/18 21:42:24] d2.utils.events INFO:  eta: 12:23:16  iter: 7899  total_loss: 44.03  loss_ce: 0.3635  loss_mask: 0.4718  loss_dice: 3.517  loss_ce_0: 0.6137  loss_mask_0: 0.4499  loss_dice_0: 3.662  loss_ce_1: 0.3732  loss_mask_1: 0.4732  loss_dice_1: 3.558  loss_ce_2: 0.3817  loss_mask_2: 0.4751  loss_dice_2: 3.526  loss_ce_3: 0.3569  loss_mask_3: 0.472  loss_dice_3: 3.517  loss_ce_4: 0.3629  loss_mask_4: 0.4679  loss_dice_4: 3.515  loss_ce_5: 0.3807  loss_mask_5: 0.4705  loss_dice_5: 3.516  loss_ce_6: 0.3627  loss_mask_6: 0.4709  loss_dice_6: 3.515  loss_ce_7: 0.3538  loss_mask_7: 0.4716  loss_dice_7: 3.513  loss_ce_8: 0.3545  loss_mask_8: 0.4718  loss_dice_8: 3.518  time: 1.4180  data_time: 0.0554  lr: 8.2038e-06  max_mem: 21588M
[01/18 21:42:53] d2.utils.events INFO:  eta: 12:23:14  iter: 7919  total_loss: 44.3  loss_ce: 0.3794  loss_mask: 0.4709  loss_dice: 3.578  loss_ce_0: 0.6332  loss_mask_0: 0.4392  loss_dice_0: 3.714  loss_ce_1: 0.3828  loss_mask_1: 0.4697  loss_dice_1: 3.614  loss_ce_2: 0.3787  loss_mask_2: 0.4677  loss_dice_2: 3.589  loss_ce_3: 0.3648  loss_mask_3: 0.4685  loss_dice_3: 3.567  loss_ce_4: 0.3698  loss_mask_4: 0.4694  loss_dice_4: 3.57  loss_ce_5: 0.3821  loss_mask_5: 0.4698  loss_dice_5: 3.578  loss_ce_6: 0.374  loss_mask_6: 0.4696  loss_dice_6: 3.573  loss_ce_7: 0.3936  loss_mask_7: 0.4711  loss_dice_7: 3.567  loss_ce_8: 0.3873  loss_mask_8: 0.4701  loss_dice_8: 3.565  time: 1.4180  data_time: 0.0561  lr: 8.1992e-06  max_mem: 21588M
[01/18 21:43:21] d2.utils.events INFO:  eta: 12:22:25  iter: 7939  total_loss: 44.17  loss_ce: 0.4051  loss_mask: 0.4815  loss_dice: 3.511  loss_ce_0: 0.6437  loss_mask_0: 0.4624  loss_dice_0: 3.668  loss_ce_1: 0.4087  loss_mask_1: 0.4905  loss_dice_1: 3.532  loss_ce_2: 0.4004  loss_mask_2: 0.4846  loss_dice_2: 3.522  loss_ce_3: 0.4055  loss_mask_3: 0.4846  loss_dice_3: 3.512  loss_ce_4: 0.3924  loss_mask_4: 0.4808  loss_dice_4: 3.508  loss_ce_5: 0.3999  loss_mask_5: 0.4817  loss_dice_5: 3.516  loss_ce_6: 0.3886  loss_mask_6: 0.4832  loss_dice_6: 3.499  loss_ce_7: 0.3965  loss_mask_7: 0.4801  loss_dice_7: 3.508  loss_ce_8: 0.3998  loss_mask_8: 0.4817  loss_dice_8: 3.505  time: 1.4179  data_time: 0.0570  lr: 8.1946e-06  max_mem: 21588M
[01/18 21:43:48] d2.utils.events INFO:  eta: 12:21:54  iter: 7959  total_loss: 43.6  loss_ce: 0.3783  loss_mask: 0.4777  loss_dice: 3.447  loss_ce_0: 0.6112  loss_mask_0: 0.4487  loss_dice_0: 3.605  loss_ce_1: 0.3762  loss_mask_1: 0.4779  loss_dice_1: 3.484  loss_ce_2: 0.3716  loss_mask_2: 0.4789  loss_dice_2: 3.46  loss_ce_3: 0.3652  loss_mask_3: 0.4801  loss_dice_3: 3.459  loss_ce_4: 0.3833  loss_mask_4: 0.4803  loss_dice_4: 3.458  loss_ce_5: 0.3904  loss_mask_5: 0.4784  loss_dice_5: 3.454  loss_ce_6: 0.3746  loss_mask_6: 0.4796  loss_dice_6: 3.45  loss_ce_7: 0.3673  loss_mask_7: 0.4779  loss_dice_7: 3.451  loss_ce_8: 0.3839  loss_mask_8: 0.4802  loss_dice_8: 3.448  time: 1.4178  data_time: 0.0565  lr: 8.19e-06  max_mem: 21588M
[01/18 21:44:16] d2.utils.events INFO:  eta: 12:21:26  iter: 7979  total_loss: 43.75  loss_ce: 0.373  loss_mask: 0.4771  loss_dice: 3.461  loss_ce_0: 0.6478  loss_mask_0: 0.453  loss_dice_0: 3.614  loss_ce_1: 0.3771  loss_mask_1: 0.4801  loss_dice_1: 3.504  loss_ce_2: 0.3841  loss_mask_2: 0.4776  loss_dice_2: 3.484  loss_ce_3: 0.3883  loss_mask_3: 0.4761  loss_dice_3: 3.471  loss_ce_4: 0.391  loss_mask_4: 0.4749  loss_dice_4: 3.466  loss_ce_5: 0.3842  loss_mask_5: 0.4763  loss_dice_5: 3.462  loss_ce_6: 0.3888  loss_mask_6: 0.475  loss_dice_6: 3.463  loss_ce_7: 0.3838  loss_mask_7: 0.4766  loss_dice_7: 3.46  loss_ce_8: 0.3763  loss_mask_8: 0.4763  loss_dice_8: 3.46  time: 1.4177  data_time: 0.0545  lr: 8.1854e-06  max_mem: 21588M
[01/18 21:44:44] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 21:44:44] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 21:44:44] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 21:50:31] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.8107619434062245, 'error_1pix': 0.2500566142738435, 'error_3pix': 0.11445873197451151, 'mIoU': 12.626175429450745, 'fwIoU': 30.367371176534753, 'IoU-0': nan, 'IoU-1': 94.63600256776667, 'IoU-2': 42.43142190797023, 'IoU-3': 49.98292303438704, 'IoU-4': 42.12259604810104, 'IoU-5': 37.53591491046011, 'IoU-6': 36.6534587580533, 'IoU-7': 29.98866817679519, 'IoU-8': 17.038226569029053, 'IoU-9': 17.89374137637009, 'IoU-10': 24.14547282309676, 'IoU-11': 30.455985872630997, 'IoU-12': 30.453552237534133, 'IoU-13': 30.642062494399845, 'IoU-14': 31.228512776330692, 'IoU-15': 30.666141559434962, 'IoU-16': 29.51408665842307, 'IoU-17': 27.96333381552345, 'IoU-18': 25.80753152728952, 'IoU-19': 29.25370757380776, 'IoU-20': 27.583592248296334, 'IoU-21': 29.02781380569855, 'IoU-22': 31.48128699992475, 'IoU-23': 26.781814794479498, 'IoU-24': 28.834575307074612, 'IoU-25': 28.239436921247968, 'IoU-26': 26.807200479810824, 'IoU-27': 27.701434128151664, 'IoU-28': 29.244525321525845, 'IoU-29': 29.646219838963496, 'IoU-30': 27.34012359031074, 'IoU-31': 29.68389727798973, 'IoU-32': 29.3017272822863, 'IoU-33': 29.97775707080159, 'IoU-34': 28.70151531665171, 'IoU-35': 28.338189085592308, 'IoU-36': 29.08980340701867, 'IoU-37': 27.2288316098035, 'IoU-38': 27.401753066584305, 'IoU-39': 25.70067063552405, 'IoU-40': 28.034165759569934, 'IoU-41': 23.27195293305011, 'IoU-42': 22.461662538009392, 'IoU-43': 21.3889834671018, 'IoU-44': 22.01459558595383, 'IoU-45': 23.75562881606262, 'IoU-46': 21.041353613896874, 'IoU-47': 23.450245773294085, 'IoU-48': 23.564123667291838, 'IoU-49': 22.76666767064922, 'IoU-50': 25.474179453110985, 'IoU-51': 21.97313555866086, 'IoU-52': 21.63642240290553, 'IoU-53': 21.360110863901756, 'IoU-54': 21.119885330302207, 'IoU-55': 19.38234649003542, 'IoU-56': 19.377275906423566, 'IoU-57': 21.362344835319053, 'IoU-58': 19.46463770220857, 'IoU-59': 19.214819852860657, 'IoU-60': 18.080229255365452, 'IoU-61': 16.617483668701144, 'IoU-62': 19.792136496331512, 'IoU-63': 15.971987629127593, 'IoU-64': 17.571009017049242, 'IoU-65': 16.180344089301794, 'IoU-66': 15.794007023864886, 'IoU-67': 17.119116854858053, 'IoU-68': 14.936283456158858, 'IoU-69': 17.133041539513272, 'IoU-70': 14.5216095148826, 'IoU-71': 13.125669806742316, 'IoU-72': 14.27161208786057, 'IoU-73': 14.372699262820493, 'IoU-74': 14.272245618100762, 'IoU-75': 12.734741306134806, 'IoU-76': 14.930014622631466, 'IoU-77': 14.379363965472896, 'IoU-78': 13.340670663797106, 'IoU-79': 14.419902814410454, 'IoU-80': 10.373620458151226, 'IoU-81': 14.740654823904475, 'IoU-82': 11.325252318985928, 'IoU-83': 12.129074111164497, 'IoU-84': 9.983660888422143, 'IoU-85': 11.331112675172262, 'IoU-86': 6.380746143797136, 'IoU-87': 8.643610129860285, 'IoU-88': 8.313778730948929, 'IoU-89': 6.1688690520019716, 'IoU-90': 7.466849162005547, 'IoU-91': 8.435672962747265, 'IoU-92': 7.073231501775934, 'IoU-93': 5.121197967201303, 'IoU-94': 7.839901110482805, 'IoU-95': 6.372813558473727, 'IoU-96': 6.727694466983437, 'IoU-97': 7.2573303636691735, 'IoU-98': 5.54566000113964, 'IoU-99': 6.599162120428545, 'IoU-100': 3.843936894001444, 'IoU-101': 7.259255202299649, 'IoU-102': 5.9686470563152705, 'IoU-103': 6.713859980535757, 'IoU-104': 6.06876639418751, 'IoU-105': 5.156125769529239, 'IoU-106': 8.384461964642787, 'IoU-107': 5.792311216627098, 'IoU-108': 5.812798992521932, 'IoU-109': 7.935369683686323, 'IoU-110': 9.878122848429301, 'IoU-111': 6.321163159210635, 'IoU-112': 9.001215808433424, 'IoU-113': 5.989295438725791, 'IoU-114': 8.142939419695342, 'IoU-115': 5.114645186068444, 'IoU-116': 7.169584874462921, 'IoU-117': 5.460815184435662, 'IoU-118': 7.570203714919671, 'IoU-119': 6.051738645301725, 'IoU-120': 7.139848681511084, 'IoU-121': 3.2086317461403677, 'IoU-122': 6.331635940731315, 'IoU-123': 5.030038699225944, 'IoU-124': 6.0915445719984005, 'IoU-125': 5.874631833167534, 'IoU-126': 4.052263446752658, 'IoU-127': 4.837816739683587, 'IoU-128': 1.7529979287875979, 'IoU-129': 4.013375237802773, 'IoU-130': 3.8205825654319723, 'IoU-131': 5.056893544276978, 'IoU-132': 4.463741799819723, 'IoU-133': 3.6583306835332374, 'IoU-134': 4.240035994835869, 'IoU-135': 3.4051094773244395, 'IoU-136': 4.592021093072483, 'IoU-137': 2.8576733616027217, 'IoU-138': 3.668975522073549, 'IoU-139': 4.147034254958436, 'IoU-140': 3.4138953475970046, 'IoU-141': 2.24459267716666, 'IoU-142': 2.67282501703642, 'IoU-143': 2.2923153367960847, 'IoU-144': 3.4713802625667456, 'IoU-145': 0.8564649785204129, 'IoU-146': 2.866693755559101, 'IoU-147': 2.3501008789890503, 'IoU-148': 1.8076026770770481, 'IoU-149': 1.4246176217542583, 'IoU-150': 0.8857049038530845, 'IoU-151': 2.6217544534225152, 'IoU-152': 0.7623720586683549, 'IoU-153': 1.7262971358071173, 'IoU-154': 0.3700953747476741, 'IoU-155': 1.8946933190927124, 'IoU-156': 2.028181701980023, 'IoU-157': 1.205124049479623, 'IoU-158': 1.905108527180427, 'IoU-159': 2.1376138765242514, 'IoU-160': 1.4874752512408824, 'IoU-161': 1.1385217678578052, 'IoU-162': 1.3348500023057466, 'IoU-163': 1.6007041177797012, 'IoU-164': 0.06174584060357327, 'IoU-165': 0.751678669324424, 'IoU-166': 0.7044543885065953, 'IoU-167': 0.5817088995953273, 'IoU-168': 2.2946987955620473, 'IoU-169': 1.462171855340984, 'IoU-170': 0.5881071661947288, 'IoU-171': 0.002877392506910238, 'IoU-172': 0.005845624367485176, 'IoU-173': 0.07119592333264194, 'IoU-174': 0.0, 'IoU-175': 0.5528563169430412, 'IoU-176': 0.0, 'IoU-177': 0.0007381163271331562, 'IoU-178': 0.024861910396904018, 'IoU-179': 2.38022996646025, 'IoU-180': 1.374245717294167, 'IoU-181': 0.027077809852555437, 'IoU-182': 0.0, 'IoU-183': 0.004694593236968983, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.15300755474801567, 'IoU-189': 0.07192171245087262, 'IoU-190': 0.0, 'IoU-191': 0.7000302155449054, 'IoU-192': 0.0, 'mACC': 20.550097456316983, 'pACC': 43.071811833312765, 'ACC-0': nan, 'ACC-1': 98.65849684191843, 'ACC-2': 54.041566083283044, 'ACC-3': 63.91527691443809, 'ACC-4': 56.49739787619495, 'ACC-5': 58.36835568293187, 'ACC-6': 58.517134987936274, 'ACC-7': 46.65580070811045, 'ACC-8': 24.381695087650336, 'ACC-9': 22.63770565426054, 'ACC-10': 38.10529767552626, 'ACC-11': 46.63901589641975, 'ACC-12': 46.8172140337953, 'ACC-13': 48.046368333251344, 'ACC-14': 48.05504297241557, 'ACC-15': 48.6248034673933, 'ACC-16': 41.725868324750046, 'ACC-17': 51.24993573561044, 'ACC-18': 36.59847082812061, 'ACC-19': 47.542128295988455, 'ACC-20': 51.084086334004674, 'ACC-21': 43.09974116883361, 'ACC-22': 48.76458882926226, 'ACC-23': 41.40540429167135, 'ACC-24': 44.36463307848041, 'ACC-25': 42.21824200543264, 'ACC-26': 39.021193228080556, 'ACC-27': 43.61853270052812, 'ACC-28': 46.29151705775724, 'ACC-29': 45.46157389333567, 'ACC-30': 42.05139138068169, 'ACC-31': 44.20912830769666, 'ACC-32': 49.00748013679938, 'ACC-33': 46.903768172790706, 'ACC-34': 46.71365108041287, 'ACC-35': 44.6125156930578, 'ACC-36': 48.17749922560118, 'ACC-37': 40.98631896525718, 'ACC-38': 42.373415602690955, 'ACC-39': 40.08060073649292, 'ACC-40': 45.35873822544588, 'ACC-41': 37.53269632975921, 'ACC-42': 36.53514851871912, 'ACC-43': 35.90276908303448, 'ACC-44': 33.042241741777055, 'ACC-45': 37.243681756455494, 'ACC-46': 31.71368371670017, 'ACC-47': 38.616154755800245, 'ACC-48': 40.423636464342785, 'ACC-49': 31.744978908877002, 'ACC-50': 40.4273186851214, 'ACC-51': 33.52703672375353, 'ACC-52': 33.46234690101951, 'ACC-53': 32.79486344391197, 'ACC-54': 34.71839816014813, 'ACC-55': 29.31408586104786, 'ACC-56': 35.90282290656501, 'ACC-57': 36.118058407218854, 'ACC-58': 32.39731917865871, 'ACC-59': 36.187254405457395, 'ACC-60': 28.198566686464165, 'ACC-61': 27.79373918223001, 'ACC-62': 36.863364628540864, 'ACC-63': 23.730312970824905, 'ACC-64': 30.599083748561373, 'ACC-65': 25.350852940841897, 'ACC-66': 29.039564502657573, 'ACC-67': 26.72696124186186, 'ACC-68': 25.107469773569967, 'ACC-69': 29.534842510448268, 'ACC-70': 28.15284842071642, 'ACC-71': 25.189273761003182, 'ACC-72': 25.018163441124614, 'ACC-73': 27.43288712963008, 'ACC-74': 26.512177669390947, 'ACC-75': 23.224597838467073, 'ACC-76': 29.63179484181501, 'ACC-77': 25.747875866829943, 'ACC-78': 22.092594281034117, 'ACC-79': 27.110658752771872, 'ACC-80': 19.1957056056624, 'ACC-81': 29.32897662869508, 'ACC-82': 19.194073162647342, 'ACC-83': 27.896237751498905, 'ACC-84': 16.604534891805194, 'ACC-85': 24.922775963963815, 'ACC-86': 11.202813729739407, 'ACC-87': 17.773718323286243, 'ACC-88': 17.589649951749813, 'ACC-89': 10.466099148620428, 'ACC-90': 13.520999685273072, 'ACC-91': 15.504078079665229, 'ACC-92': 13.87055825472929, 'ACC-93': 8.150593017498315, 'ACC-94': 15.369808125998963, 'ACC-95': 11.142840503794831, 'ACC-96': 12.07909781212546, 'ACC-97': 14.156534971319996, 'ACC-98': 9.768849250586593, 'ACC-99': 11.794232058296506, 'ACC-100': 5.132133476381973, 'ACC-101': 13.503402851930375, 'ACC-102': 11.923674671499773, 'ACC-103': 12.159157457258903, 'ACC-104': 10.642581343301934, 'ACC-105': 8.292779228261873, 'ACC-106': 15.384484272736831, 'ACC-107': 9.455379249724771, 'ACC-108': 8.421615248836027, 'ACC-109': 12.899843086226031, 'ACC-110': 19.279898132254033, 'ACC-111': 9.262426270362322, 'ACC-112': 19.722342895313368, 'ACC-113': 9.739241704681998, 'ACC-114': 17.111607629308633, 'ACC-115': 7.648429630297837, 'ACC-116': 15.664975608835844, 'ACC-117': 10.512148333999022, 'ACC-118': 14.39515605889414, 'ACC-119': 11.35191077816908, 'ACC-120': 13.849678645849806, 'ACC-121': 4.855727150875239, 'ACC-122': 13.108966193967184, 'ACC-123': 10.381284428295395, 'ACC-124': 10.49836956029537, 'ACC-125': 10.797584849509931, 'ACC-126': 6.646349238153353, 'ACC-127': 9.957573662028429, 'ACC-128': 2.086252928742967, 'ACC-129': 6.265723452975385, 'ACC-130': 5.67248731435883, 'ACC-131': 9.263361185820818, 'ACC-132': 6.880196238099547, 'ACC-133': 8.21191151755156, 'ACC-134': 7.360275743214132, 'ACC-135': 5.286400433270623, 'ACC-136': 11.471388138278046, 'ACC-137': 5.497409971020067, 'ACC-138': 6.5960764779044085, 'ACC-139': 8.539105868155273, 'ACC-140': 5.964846021199728, 'ACC-141': 3.1897417944285764, 'ACC-142': 4.470067533520048, 'ACC-143': 4.609773258462708, 'ACC-144': 6.617870036101083, 'ACC-145': 1.1272166193340638, 'ACC-146': 10.06410637179868, 'ACC-147': 4.081772878494832, 'ACC-148': 2.4175634070971843, 'ACC-149': 2.167901029238319, 'ACC-150': 1.1526887907034435, 'ACC-151': 4.999664280393016, 'ACC-152': 0.883088036954616, 'ACC-153': 3.297513695743784, 'ACC-154': 0.41612508175143575, 'ACC-155': 4.823461839014157, 'ACC-156': 10.76913132566723, 'ACC-157': 2.995646037404064, 'ACC-158': 4.284800952930699, 'ACC-159': 8.627905196392268, 'ACC-160': 6.639794371804732, 'ACC-161': 3.619722700427155, 'ACC-162': 1.679405892871488, 'ACC-163': 3.3639728081667224, 'ACC-164': 0.06373688399570013, 'ACC-165': 1.098381015605396, 'ACC-166': 0.9199956350572059, 'ACC-167': 0.7888240944851799, 'ACC-168': 10.19797454110697, 'ACC-169': 2.8650992379271196, 'ACC-170': 0.8816389113676051, 'ACC-171': 0.0029389668429434484, 'ACC-172': 0.005926584435307627, 'ACC-173': 0.07168310423588821, 'ACC-174': 0.0, 'ACC-175': 0.6347075778501292, 'ACC-176': 0.0, 'ACC-177': 0.0007381857976743457, 'ACC-178': 0.02491737668313016, 'ACC-179': 13.528823387389654, 'ACC-180': 2.3701276711029835, 'ACC-181': 0.027239501540808328, 'ACC-182': 0.0, 'ACC-183': 0.004708641062646114, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.16141398652193212, 'ACC-189': 0.0723966101955992, 'ACC-190': 0.0, 'ACC-191': 0.8284502446982055, 'ACC-192': 0.0})])
[01/18 21:50:31] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/18 21:50:31] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/18 21:50:31] d2.evaluation.testing INFO: copypaste: 2.8108,0.2501,0.1145,12.6262,30.3674,20.5501,43.0718
[01/18 21:50:31] d2.utils.events INFO:  eta: 12:20:57  iter: 7999  total_loss: 43.57  loss_ce: 0.37  loss_mask: 0.4757  loss_dice: 3.436  loss_ce_0: 0.6142  loss_mask_0: 0.4485  loss_dice_0: 3.59  loss_ce_1: 0.3667  loss_mask_1: 0.4768  loss_dice_1: 3.474  loss_ce_2: 0.3721  loss_mask_2: 0.476  loss_dice_2: 3.456  loss_ce_3: 0.3773  loss_mask_3: 0.4746  loss_dice_3: 3.436  loss_ce_4: 0.376  loss_mask_4: 0.4755  loss_dice_4: 3.445  loss_ce_5: 0.3698  loss_mask_5: 0.4757  loss_dice_5: 3.443  loss_ce_6: 0.3779  loss_mask_6: 0.4761  loss_dice_6: 3.433  loss_ce_7: 0.3644  loss_mask_7: 0.4755  loss_dice_7: 3.431  loss_ce_8: 0.3728  loss_mask_8: 0.4739  loss_dice_8: 3.438  time: 1.4176  data_time: 0.0593  lr: 8.1808e-06  max_mem: 21588M
[01/18 21:50:59] d2.utils.events INFO:  eta: 12:20:59  iter: 8019  total_loss: 43.96  loss_ce: 0.3747  loss_mask: 0.4768  loss_dice: 3.476  loss_ce_0: 0.6084  loss_mask_0: 0.4469  loss_dice_0: 3.626  loss_ce_1: 0.3591  loss_mask_1: 0.4782  loss_dice_1: 3.524  loss_ce_2: 0.3734  loss_mask_2: 0.4753  loss_dice_2: 3.502  loss_ce_3: 0.3493  loss_mask_3: 0.475  loss_dice_3: 3.494  loss_ce_4: 0.3589  loss_mask_4: 0.4753  loss_dice_4: 3.473  loss_ce_5: 0.3588  loss_mask_5: 0.4755  loss_dice_5: 3.488  loss_ce_6: 0.3639  loss_mask_6: 0.4748  loss_dice_6: 3.48  loss_ce_7: 0.3648  loss_mask_7: 0.475  loss_dice_7: 3.482  loss_ce_8: 0.3728  loss_mask_8: 0.4762  loss_dice_8: 3.48  time: 1.4176  data_time: 0.0598  lr: 8.1761e-06  max_mem: 21588M
[01/18 21:51:27] d2.utils.events INFO:  eta: 12:20:31  iter: 8039  total_loss: 43.78  loss_ce: 0.342  loss_mask: 0.4815  loss_dice: 3.491  loss_ce_0: 0.6454  loss_mask_0: 0.4589  loss_dice_0: 3.641  loss_ce_1: 0.357  loss_mask_1: 0.4843  loss_dice_1: 3.524  loss_ce_2: 0.358  loss_mask_2: 0.4847  loss_dice_2: 3.504  loss_ce_3: 0.3411  loss_mask_3: 0.4858  loss_dice_3: 3.49  loss_ce_4: 0.3642  loss_mask_4: 0.482  loss_dice_4: 3.496  loss_ce_5: 0.3462  loss_mask_5: 0.4804  loss_dice_5: 3.496  loss_ce_6: 0.3545  loss_mask_6: 0.4791  loss_dice_6: 3.485  loss_ce_7: 0.3473  loss_mask_7: 0.4811  loss_dice_7: 3.491  loss_ce_8: 0.3446  loss_mask_8: 0.4817  loss_dice_8: 3.495  time: 1.4175  data_time: 0.0694  lr: 8.1715e-06  max_mem: 21588M
[01/18 21:51:55] d2.utils.events INFO:  eta: 12:20:30  iter: 8059  total_loss: 44.04  loss_ce: 0.3676  loss_mask: 0.4669  loss_dice: 3.507  loss_ce_0: 0.5873  loss_mask_0: 0.4435  loss_dice_0: 3.654  loss_ce_1: 0.3798  loss_mask_1: 0.4643  loss_dice_1: 3.55  loss_ce_2: 0.3557  loss_mask_2: 0.4668  loss_dice_2: 3.532  loss_ce_3: 0.3635  loss_mask_3: 0.4664  loss_dice_3: 3.52  loss_ce_4: 0.3687  loss_mask_4: 0.468  loss_dice_4: 3.52  loss_ce_5: 0.3536  loss_mask_5: 0.4658  loss_dice_5: 3.517  loss_ce_6: 0.359  loss_mask_6: 0.4669  loss_dice_6: 3.507  loss_ce_7: 0.346  loss_mask_7: 0.4656  loss_dice_7: 3.513  loss_ce_8: 0.3603  loss_mask_8: 0.4679  loss_dice_8: 3.499  time: 1.4175  data_time: 0.0651  lr: 8.1669e-06  max_mem: 21588M
[01/18 21:52:23] d2.utils.events INFO:  eta: 12:20:14  iter: 8079  total_loss: 43.92  loss_ce: 0.3611  loss_mask: 0.4794  loss_dice: 3.516  loss_ce_0: 0.5971  loss_mask_0: 0.4555  loss_dice_0: 3.653  loss_ce_1: 0.3591  loss_mask_1: 0.4831  loss_dice_1: 3.546  loss_ce_2: 0.3301  loss_mask_2: 0.4821  loss_dice_2: 3.529  loss_ce_3: 0.3335  loss_mask_3: 0.4821  loss_dice_3: 3.526  loss_ce_4: 0.3559  loss_mask_4: 0.4813  loss_dice_4: 3.52  loss_ce_5: 0.3569  loss_mask_5: 0.48  loss_dice_5: 3.523  loss_ce_6: 0.3458  loss_mask_6: 0.4779  loss_dice_6: 3.517  loss_ce_7: 0.3618  loss_mask_7: 0.4783  loss_dice_7: 3.519  loss_ce_8: 0.3485  loss_mask_8: 0.4798  loss_dice_8: 3.512  time: 1.4174  data_time: 0.0607  lr: 8.1623e-06  max_mem: 21588M
[01/18 21:52:51] d2.utils.events INFO:  eta: 12:19:27  iter: 8099  total_loss: 43.52  loss_ce: 0.3763  loss_mask: 0.4681  loss_dice: 3.494  loss_ce_0: 0.6291  loss_mask_0: 0.4404  loss_dice_0: 3.636  loss_ce_1: 0.3817  loss_mask_1: 0.4678  loss_dice_1: 3.524  loss_ce_2: 0.3588  loss_mask_2: 0.4632  loss_dice_2: 3.508  loss_ce_3: 0.3583  loss_mask_3: 0.4644  loss_dice_3: 3.488  loss_ce_4: 0.3604  loss_mask_4: 0.465  loss_dice_4: 3.494  loss_ce_5: 0.3818  loss_mask_5: 0.4678  loss_dice_5: 3.494  loss_ce_6: 0.3555  loss_mask_6: 0.4706  loss_dice_6: 3.491  loss_ce_7: 0.3599  loss_mask_7: 0.4695  loss_dice_7: 3.488  loss_ce_8: 0.3651  loss_mask_8: 0.4695  loss_dice_8: 3.489  time: 1.4174  data_time: 0.0651  lr: 8.1577e-06  max_mem: 21588M
[01/18 21:53:19] d2.utils.events INFO:  eta: 12:19:18  iter: 8119  total_loss: 43.95  loss_ce: 0.3948  loss_mask: 0.4706  loss_dice: 3.499  loss_ce_0: 0.6291  loss_mask_0: 0.4434  loss_dice_0: 3.643  loss_ce_1: 0.3885  loss_mask_1: 0.4694  loss_dice_1: 3.533  loss_ce_2: 0.3876  loss_mask_2: 0.468  loss_dice_2: 3.505  loss_ce_3: 0.3913  loss_mask_3: 0.4698  loss_dice_3: 3.494  loss_ce_4: 0.3963  loss_mask_4: 0.472  loss_dice_4: 3.497  loss_ce_5: 0.3908  loss_mask_5: 0.4703  loss_dice_5: 3.5  loss_ce_6: 0.3826  loss_mask_6: 0.4721  loss_dice_6: 3.499  loss_ce_7: 0.3923  loss_mask_7: 0.4717  loss_dice_7: 3.505  loss_ce_8: 0.3946  loss_mask_8: 0.4724  loss_dice_8: 3.494  time: 1.4173  data_time: 0.0595  lr: 8.1531e-06  max_mem: 21588M
[01/18 21:53:47] d2.utils.events INFO:  eta: 12:18:50  iter: 8139  total_loss: 43.59  loss_ce: 0.3771  loss_mask: 0.4699  loss_dice: 3.492  loss_ce_0: 0.6105  loss_mask_0: 0.4444  loss_dice_0: 3.648  loss_ce_1: 0.3795  loss_mask_1: 0.4713  loss_dice_1: 3.538  loss_ce_2: 0.3718  loss_mask_2: 0.4676  loss_dice_2: 3.513  loss_ce_3: 0.3542  loss_mask_3: 0.4696  loss_dice_3: 3.509  loss_ce_4: 0.3619  loss_mask_4: 0.4671  loss_dice_4: 3.501  loss_ce_5: 0.3608  loss_mask_5: 0.4669  loss_dice_5: 3.504  loss_ce_6: 0.3661  loss_mask_6: 0.4707  loss_dice_6: 3.502  loss_ce_7: 0.3661  loss_mask_7: 0.47  loss_dice_7: 3.5  loss_ce_8: 0.3531  loss_mask_8: 0.4679  loss_dice_8: 3.499  time: 1.4173  data_time: 0.0629  lr: 8.1485e-06  max_mem: 21588M
[01/18 21:54:15] d2.utils.events INFO:  eta: 12:18:10  iter: 8159  total_loss: 43.54  loss_ce: 0.3689  loss_mask: 0.4722  loss_dice: 3.454  loss_ce_0: 0.6372  loss_mask_0: 0.4436  loss_dice_0: 3.605  loss_ce_1: 0.3584  loss_mask_1: 0.4704  loss_dice_1: 3.488  loss_ce_2: 0.361  loss_mask_2: 0.4711  loss_dice_2: 3.469  loss_ce_3: 0.3528  loss_mask_3: 0.4712  loss_dice_3: 3.454  loss_ce_4: 0.3699  loss_mask_4: 0.4725  loss_dice_4: 3.459  loss_ce_5: 0.3826  loss_mask_5: 0.4718  loss_dice_5: 3.458  loss_ce_6: 0.3629  loss_mask_6: 0.4701  loss_dice_6: 3.457  loss_ce_7: 0.362  loss_mask_7: 0.4695  loss_dice_7: 3.46  loss_ce_8: 0.3673  loss_mask_8: 0.4697  loss_dice_8: 3.454  time: 1.4172  data_time: 0.0580  lr: 8.1439e-06  max_mem: 21588M
[01/18 21:54:43] d2.utils.events INFO:  eta: 12:17:22  iter: 8179  total_loss: 43.59  loss_ce: 0.3656  loss_mask: 0.4775  loss_dice: 3.48  loss_ce_0: 0.6272  loss_mask_0: 0.4514  loss_dice_0: 3.617  loss_ce_1: 0.3632  loss_mask_1: 0.4806  loss_dice_1: 3.513  loss_ce_2: 0.387  loss_mask_2: 0.479  loss_dice_2: 3.48  loss_ce_3: 0.3795  loss_mask_3: 0.48  loss_dice_3: 3.48  loss_ce_4: 0.3824  loss_mask_4: 0.4729  loss_dice_4: 3.479  loss_ce_5: 0.3658  loss_mask_5: 0.4743  loss_dice_5: 3.477  loss_ce_6: 0.3628  loss_mask_6: 0.4752  loss_dice_6: 3.477  loss_ce_7: 0.3569  loss_mask_7: 0.4789  loss_dice_7: 3.469  loss_ce_8: 0.3776  loss_mask_8: 0.4778  loss_dice_8: 3.474  time: 1.4171  data_time: 0.0569  lr: 8.1393e-06  max_mem: 21588M
[01/18 21:55:11] d2.utils.events INFO:  eta: 12:16:56  iter: 8199  total_loss: 43.63  loss_ce: 0.3926  loss_mask: 0.4693  loss_dice: 3.476  loss_ce_0: 0.6127  loss_mask_0: 0.4449  loss_dice_0: 3.636  loss_ce_1: 0.3732  loss_mask_1: 0.4729  loss_dice_1: 3.52  loss_ce_2: 0.3756  loss_mask_2: 0.4718  loss_dice_2: 3.486  loss_ce_3: 0.359  loss_mask_3: 0.471  loss_dice_3: 3.483  loss_ce_4: 0.3918  loss_mask_4: 0.467  loss_dice_4: 3.481  loss_ce_5: 0.3646  loss_mask_5: 0.47  loss_dice_5: 3.482  loss_ce_6: 0.3704  loss_mask_6: 0.4686  loss_dice_6: 3.485  loss_ce_7: 0.3771  loss_mask_7: 0.4685  loss_dice_7: 3.471  loss_ce_8: 0.3714  loss_mask_8: 0.4697  loss_dice_8: 3.466  time: 1.4171  data_time: 0.0563  lr: 8.1347e-06  max_mem: 21588M
[01/18 21:55:38] d2.utils.events INFO:  eta: 12:16:27  iter: 8219  total_loss: 43  loss_ce: 0.3464  loss_mask: 0.4813  loss_dice: 3.434  loss_ce_0: 0.6189  loss_mask_0: 0.4457  loss_dice_0: 3.585  loss_ce_1: 0.3825  loss_mask_1: 0.4777  loss_dice_1: 3.471  loss_ce_2: 0.3511  loss_mask_2: 0.4825  loss_dice_2: 3.447  loss_ce_3: 0.3547  loss_mask_3: 0.4797  loss_dice_3: 3.43  loss_ce_4: 0.3531  loss_mask_4: 0.484  loss_dice_4: 3.429  loss_ce_5: 0.3563  loss_mask_5: 0.4848  loss_dice_5: 3.437  loss_ce_6: 0.3582  loss_mask_6: 0.4813  loss_dice_6: 3.426  loss_ce_7: 0.3366  loss_mask_7: 0.4838  loss_dice_7: 3.438  loss_ce_8: 0.34  loss_mask_8: 0.4828  loss_dice_8: 3.436  time: 1.4170  data_time: 0.0614  lr: 8.1301e-06  max_mem: 21588M
[01/18 21:56:06] d2.utils.events INFO:  eta: 12:15:59  iter: 8239  total_loss: 43.45  loss_ce: 0.3719  loss_mask: 0.4798  loss_dice: 3.456  loss_ce_0: 0.6181  loss_mask_0: 0.4508  loss_dice_0: 3.611  loss_ce_1: 0.3976  loss_mask_1: 0.4855  loss_dice_1: 3.497  loss_ce_2: 0.3913  loss_mask_2: 0.4796  loss_dice_2: 3.47  loss_ce_3: 0.3781  loss_mask_3: 0.4805  loss_dice_3: 3.459  loss_ce_4: 0.3901  loss_mask_4: 0.4808  loss_dice_4: 3.451  loss_ce_5: 0.371  loss_mask_5: 0.4783  loss_dice_5: 3.455  loss_ce_6: 0.3831  loss_mask_6: 0.4787  loss_dice_6: 3.457  loss_ce_7: 0.3785  loss_mask_7: 0.4794  loss_dice_7: 3.456  loss_ce_8: 0.3868  loss_mask_8: 0.4781  loss_dice_8: 3.455  time: 1.4169  data_time: 0.0604  lr: 8.1255e-06  max_mem: 21588M
[01/18 21:56:34] d2.utils.events INFO:  eta: 12:15:32  iter: 8259  total_loss: 44.1  loss_ce: 0.3925  loss_mask: 0.4626  loss_dice: 3.492  loss_ce_0: 0.6327  loss_mask_0: 0.4444  loss_dice_0: 3.623  loss_ce_1: 0.3916  loss_mask_1: 0.4673  loss_dice_1: 3.514  loss_ce_2: 0.3907  loss_mask_2: 0.4648  loss_dice_2: 3.496  loss_ce_3: 0.3759  loss_mask_3: 0.4653  loss_dice_3: 3.493  loss_ce_4: 0.3801  loss_mask_4: 0.4633  loss_dice_4: 3.497  loss_ce_5: 0.3667  loss_mask_5: 0.4638  loss_dice_5: 3.493  loss_ce_6: 0.3948  loss_mask_6: 0.4638  loss_dice_6: 3.487  loss_ce_7: 0.3808  loss_mask_7: 0.4628  loss_dice_7: 3.491  loss_ce_8: 0.3838  loss_mask_8: 0.4637  loss_dice_8: 3.487  time: 1.4168  data_time: 0.0596  lr: 8.1209e-06  max_mem: 21588M
[01/18 21:57:02] d2.utils.events INFO:  eta: 12:15:06  iter: 8279  total_loss: 43.31  loss_ce: 0.3723  loss_mask: 0.4722  loss_dice: 3.425  loss_ce_0: 0.6324  loss_mask_0: 0.4432  loss_dice_0: 3.587  loss_ce_1: 0.3991  loss_mask_1: 0.4737  loss_dice_1: 3.476  loss_ce_2: 0.3738  loss_mask_2: 0.4756  loss_dice_2: 3.45  loss_ce_3: 0.3549  loss_mask_3: 0.4729  loss_dice_3: 3.444  loss_ce_4: 0.3629  loss_mask_4: 0.4732  loss_dice_4: 3.435  loss_ce_5: 0.3603  loss_mask_5: 0.473  loss_dice_5: 3.442  loss_ce_6: 0.3733  loss_mask_6: 0.4728  loss_dice_6: 3.44  loss_ce_7: 0.3641  loss_mask_7: 0.4732  loss_dice_7: 3.434  loss_ce_8: 0.3621  loss_mask_8: 0.4744  loss_dice_8: 3.435  time: 1.4168  data_time: 0.0561  lr: 8.1163e-06  max_mem: 21588M
[01/18 21:57:30] d2.utils.events INFO:  eta: 12:15:00  iter: 8299  total_loss: 43.55  loss_ce: 0.3818  loss_mask: 0.4674  loss_dice: 3.473  loss_ce_0: 0.6372  loss_mask_0: 0.437  loss_dice_0: 3.623  loss_ce_1: 0.3806  loss_mask_1: 0.4671  loss_dice_1: 3.515  loss_ce_2: 0.388  loss_mask_2: 0.47  loss_dice_2: 3.482  loss_ce_3: 0.3753  loss_mask_3: 0.4705  loss_dice_3: 3.479  loss_ce_4: 0.3881  loss_mask_4: 0.4712  loss_dice_4: 3.467  loss_ce_5: 0.3814  loss_mask_5: 0.4717  loss_dice_5: 3.478  loss_ce_6: 0.383  loss_mask_6: 0.4669  loss_dice_6: 3.473  loss_ce_7: 0.3872  loss_mask_7: 0.4652  loss_dice_7: 3.473  loss_ce_8: 0.3857  loss_mask_8: 0.4668  loss_dice_8: 3.466  time: 1.4168  data_time: 0.0607  lr: 8.1117e-06  max_mem: 21588M
[01/18 21:57:58] d2.utils.events INFO:  eta: 12:14:36  iter: 8319  total_loss: 43.06  loss_ce: 0.3742  loss_mask: 0.4714  loss_dice: 3.423  loss_ce_0: 0.6178  loss_mask_0: 0.4367  loss_dice_0: 3.591  loss_ce_1: 0.3613  loss_mask_1: 0.4695  loss_dice_1: 3.467  loss_ce_2: 0.3584  loss_mask_2: 0.472  loss_dice_2: 3.439  loss_ce_3: 0.3622  loss_mask_3: 0.4687  loss_dice_3: 3.432  loss_ce_4: 0.3646  loss_mask_4: 0.4673  loss_dice_4: 3.428  loss_ce_5: 0.3694  loss_mask_5: 0.469  loss_dice_5: 3.42  loss_ce_6: 0.366  loss_mask_6: 0.4712  loss_dice_6: 3.415  loss_ce_7: 0.3857  loss_mask_7: 0.4709  loss_dice_7: 3.418  loss_ce_8: 0.3533  loss_mask_8: 0.4736  loss_dice_8: 3.417  time: 1.4167  data_time: 0.0630  lr: 8.1071e-06  max_mem: 21588M
[01/18 21:58:26] d2.utils.events INFO:  eta: 12:13:54  iter: 8339  total_loss: 44.51  loss_ce: 0.3743  loss_mask: 0.4683  loss_dice: 3.541  loss_ce_0: 0.6358  loss_mask_0: 0.45  loss_dice_0: 3.673  loss_ce_1: 0.3704  loss_mask_1: 0.4733  loss_dice_1: 3.576  loss_ce_2: 0.3713  loss_mask_2: 0.4735  loss_dice_2: 3.553  loss_ce_3: 0.3411  loss_mask_3: 0.4728  loss_dice_3: 3.546  loss_ce_4: 0.3498  loss_mask_4: 0.4698  loss_dice_4: 3.545  loss_ce_5: 0.3546  loss_mask_5: 0.4685  loss_dice_5: 3.548  loss_ce_6: 0.3467  loss_mask_6: 0.4696  loss_dice_6: 3.541  loss_ce_7: 0.3549  loss_mask_7: 0.4687  loss_dice_7: 3.539  loss_ce_8: 0.3598  loss_mask_8: 0.4673  loss_dice_8: 3.542  time: 1.4166  data_time: 0.0583  lr: 8.1025e-06  max_mem: 21588M
[01/18 21:58:54] d2.utils.events INFO:  eta: 12:13:44  iter: 8359  total_loss: 43.64  loss_ce: 0.3635  loss_mask: 0.4735  loss_dice: 3.458  loss_ce_0: 0.607  loss_mask_0: 0.4457  loss_dice_0: 3.611  loss_ce_1: 0.3615  loss_mask_1: 0.4694  loss_dice_1: 3.501  loss_ce_2: 0.3592  loss_mask_2: 0.4688  loss_dice_2: 3.464  loss_ce_3: 0.3523  loss_mask_3: 0.4668  loss_dice_3: 3.458  loss_ce_4: 0.3576  loss_mask_4: 0.4692  loss_dice_4: 3.466  loss_ce_5: 0.3435  loss_mask_5: 0.4707  loss_dice_5: 3.465  loss_ce_6: 0.3478  loss_mask_6: 0.4721  loss_dice_6: 3.459  loss_ce_7: 0.3501  loss_mask_7: 0.4734  loss_dice_7: 3.446  loss_ce_8: 0.372  loss_mask_8: 0.4714  loss_dice_8: 3.463  time: 1.4166  data_time: 0.0615  lr: 8.0979e-06  max_mem: 21588M
[01/18 21:59:21] d2.utils.events INFO:  eta: 12:13:16  iter: 8379  total_loss: 43.6  loss_ce: 0.3654  loss_mask: 0.4592  loss_dice: 3.449  loss_ce_0: 0.6172  loss_mask_0: 0.4438  loss_dice_0: 3.607  loss_ce_1: 0.3498  loss_mask_1: 0.4619  loss_dice_1: 3.495  loss_ce_2: 0.3415  loss_mask_2: 0.4603  loss_dice_2: 3.469  loss_ce_3: 0.3627  loss_mask_3: 0.4587  loss_dice_3: 3.454  loss_ce_4: 0.3629  loss_mask_4: 0.4606  loss_dice_4: 3.462  loss_ce_5: 0.3595  loss_mask_5: 0.4584  loss_dice_5: 3.457  loss_ce_6: 0.3531  loss_mask_6: 0.4605  loss_dice_6: 3.459  loss_ce_7: 0.3586  loss_mask_7: 0.4588  loss_dice_7: 3.452  loss_ce_8: 0.3657  loss_mask_8: 0.4579  loss_dice_8: 3.448  time: 1.4165  data_time: 0.0653  lr: 8.0933e-06  max_mem: 21588M
[01/18 21:59:49] d2.utils.events INFO:  eta: 12:12:50  iter: 8399  total_loss: 43.2  loss_ce: 0.3682  loss_mask: 0.4641  loss_dice: 3.435  loss_ce_0: 0.6065  loss_mask_0: 0.4328  loss_dice_0: 3.599  loss_ce_1: 0.3592  loss_mask_1: 0.4595  loss_dice_1: 3.476  loss_ce_2: 0.356  loss_mask_2: 0.4605  loss_dice_2: 3.455  loss_ce_3: 0.3573  loss_mask_3: 0.4587  loss_dice_3: 3.452  loss_ce_4: 0.3494  loss_mask_4: 0.4593  loss_dice_4: 3.448  loss_ce_5: 0.3491  loss_mask_5: 0.4596  loss_dice_5: 3.435  loss_ce_6: 0.3627  loss_mask_6: 0.4615  loss_dice_6: 3.43  loss_ce_7: 0.3512  loss_mask_7: 0.4597  loss_dice_7: 3.437  loss_ce_8: 0.3572  loss_mask_8: 0.462  loss_dice_8: 3.431  time: 1.4165  data_time: 0.0620  lr: 8.0887e-06  max_mem: 21588M
[01/18 22:00:17] d2.utils.events INFO:  eta: 12:12:08  iter: 8419  total_loss: 43.13  loss_ce: 0.3741  loss_mask: 0.4778  loss_dice: 3.416  loss_ce_0: 0.6039  loss_mask_0: 0.4441  loss_dice_0: 3.576  loss_ce_1: 0.374  loss_mask_1: 0.4743  loss_dice_1: 3.466  loss_ce_2: 0.3743  loss_mask_2: 0.4744  loss_dice_2: 3.446  loss_ce_3: 0.3618  loss_mask_3: 0.4741  loss_dice_3: 3.425  loss_ce_4: 0.3718  loss_mask_4: 0.4748  loss_dice_4: 3.425  loss_ce_5: 0.3806  loss_mask_5: 0.477  loss_dice_5: 3.427  loss_ce_6: 0.3797  loss_mask_6: 0.475  loss_dice_6: 3.415  loss_ce_7: 0.3736  loss_mask_7: 0.4758  loss_dice_7: 3.423  loss_ce_8: 0.3828  loss_mask_8: 0.4775  loss_dice_8: 3.417  time: 1.4164  data_time: 0.0574  lr: 8.0841e-06  max_mem: 21588M
[01/18 22:00:45] d2.utils.events INFO:  eta: 12:12:01  iter: 8439  total_loss: 43.47  loss_ce: 0.3455  loss_mask: 0.4463  loss_dice: 3.475  loss_ce_0: 0.6445  loss_mask_0: 0.4264  loss_dice_0: 3.619  loss_ce_1: 0.3704  loss_mask_1: 0.4449  loss_dice_1: 3.506  loss_ce_2: 0.3602  loss_mask_2: 0.4465  loss_dice_2: 3.481  loss_ce_3: 0.3577  loss_mask_3: 0.4476  loss_dice_3: 3.478  loss_ce_4: 0.3622  loss_mask_4: 0.4457  loss_dice_4: 3.471  loss_ce_5: 0.3558  loss_mask_5: 0.4445  loss_dice_5: 3.475  loss_ce_6: 0.3563  loss_mask_6: 0.4452  loss_dice_6: 3.465  loss_ce_7: 0.3676  loss_mask_7: 0.4468  loss_dice_7: 3.47  loss_ce_8: 0.3644  loss_mask_8: 0.4476  loss_dice_8: 3.466  time: 1.4163  data_time: 0.0612  lr: 8.0794e-06  max_mem: 21588M
[01/18 22:01:13] d2.utils.events INFO:  eta: 12:11:25  iter: 8459  total_loss: 42.49  loss_ce: 0.356  loss_mask: 0.4607  loss_dice: 3.38  loss_ce_0: 0.6384  loss_mask_0: 0.4378  loss_dice_0: 3.545  loss_ce_1: 0.3724  loss_mask_1: 0.4643  loss_dice_1: 3.428  loss_ce_2: 0.3741  loss_mask_2: 0.46  loss_dice_2: 3.401  loss_ce_3: 0.3556  loss_mask_3: 0.4635  loss_dice_3: 3.385  loss_ce_4: 0.3546  loss_mask_4: 0.4614  loss_dice_4: 3.379  loss_ce_5: 0.3464  loss_mask_5: 0.4618  loss_dice_5: 3.38  loss_ce_6: 0.3628  loss_mask_6: 0.4607  loss_dice_6: 3.382  loss_ce_7: 0.3605  loss_mask_7: 0.4597  loss_dice_7: 3.38  loss_ce_8: 0.3629  loss_mask_8: 0.4599  loss_dice_8: 3.381  time: 1.4162  data_time: 0.0598  lr: 8.0748e-06  max_mem: 21588M
[01/18 22:01:41] d2.utils.events INFO:  eta: 12:10:58  iter: 8479  total_loss: 42.78  loss_ce: 0.3541  loss_mask: 0.4553  loss_dice: 3.415  loss_ce_0: 0.6151  loss_mask_0: 0.4285  loss_dice_0: 3.573  loss_ce_1: 0.364  loss_mask_1: 0.4478  loss_dice_1: 3.459  loss_ce_2: 0.3723  loss_mask_2: 0.4486  loss_dice_2: 3.433  loss_ce_3: 0.3681  loss_mask_3: 0.4521  loss_dice_3: 3.418  loss_ce_4: 0.3557  loss_mask_4: 0.4528  loss_dice_4: 3.411  loss_ce_5: 0.3627  loss_mask_5: 0.4539  loss_dice_5: 3.412  loss_ce_6: 0.3546  loss_mask_6: 0.4553  loss_dice_6: 3.407  loss_ce_7: 0.3472  loss_mask_7: 0.4552  loss_dice_7: 3.408  loss_ce_8: 0.3561  loss_mask_8: 0.4562  loss_dice_8: 3.415  time: 1.4162  data_time: 0.0629  lr: 8.0702e-06  max_mem: 21588M
[01/18 22:02:10] d2.utils.events INFO:  eta: 12:10:40  iter: 8499  total_loss: 43.18  loss_ce: 0.3534  loss_mask: 0.4661  loss_dice: 3.447  loss_ce_0: 0.6169  loss_mask_0: 0.4396  loss_dice_0: 3.584  loss_ce_1: 0.3682  loss_mask_1: 0.4645  loss_dice_1: 3.467  loss_ce_2: 0.3762  loss_mask_2: 0.4621  loss_dice_2: 3.448  loss_ce_3: 0.3688  loss_mask_3: 0.4653  loss_dice_3: 3.438  loss_ce_4: 0.3577  loss_mask_4: 0.4613  loss_dice_4: 3.436  loss_ce_5: 0.3616  loss_mask_5: 0.4597  loss_dice_5: 3.434  loss_ce_6: 0.3513  loss_mask_6: 0.46  loss_dice_6: 3.433  loss_ce_7: 0.359  loss_mask_7: 0.4633  loss_dice_7: 3.44  loss_ce_8: 0.361  loss_mask_8: 0.4627  loss_dice_8: 3.441  time: 1.4163  data_time: 0.0605  lr: 8.0656e-06  max_mem: 21588M
[01/18 22:02:37] d2.utils.events INFO:  eta: 12:10:17  iter: 8519  total_loss: 42.3  loss_ce: 0.3282  loss_mask: 0.4645  loss_dice: 3.372  loss_ce_0: 0.619  loss_mask_0: 0.436  loss_dice_0: 3.544  loss_ce_1: 0.3809  loss_mask_1: 0.4635  loss_dice_1: 3.415  loss_ce_2: 0.3512  loss_mask_2: 0.4657  loss_dice_2: 3.389  loss_ce_3: 0.3309  loss_mask_3: 0.4635  loss_dice_3: 3.381  loss_ce_4: 0.3317  loss_mask_4: 0.4639  loss_dice_4: 3.377  loss_ce_5: 0.332  loss_mask_5: 0.4659  loss_dice_5: 3.375  loss_ce_6: 0.3218  loss_mask_6: 0.4651  loss_dice_6: 3.371  loss_ce_7: 0.3318  loss_mask_7: 0.4658  loss_dice_7: 3.379  loss_ce_8: 0.3394  loss_mask_8: 0.4669  loss_dice_8: 3.367  time: 1.4162  data_time: 0.0585  lr: 8.061e-06  max_mem: 21588M
[01/18 22:03:05] d2.utils.events INFO:  eta: 12:09:38  iter: 8539  total_loss: 42.43  loss_ce: 0.3503  loss_mask: 0.4587  loss_dice: 3.394  loss_ce_0: 0.6084  loss_mask_0: 0.4261  loss_dice_0: 3.551  loss_ce_1: 0.3504  loss_mask_1: 0.4568  loss_dice_1: 3.437  loss_ce_2: 0.3372  loss_mask_2: 0.4595  loss_dice_2: 3.409  loss_ce_3: 0.3354  loss_mask_3: 0.4604  loss_dice_3: 3.4  loss_ce_4: 0.3511  loss_mask_4: 0.4624  loss_dice_4: 3.394  loss_ce_5: 0.354  loss_mask_5: 0.4606  loss_dice_5: 3.4  loss_ce_6: 0.3456  loss_mask_6: 0.4597  loss_dice_6: 3.387  loss_ce_7: 0.333  loss_mask_7: 0.4586  loss_dice_7: 3.39  loss_ce_8: 0.3427  loss_mask_8: 0.4601  loss_dice_8: 3.392  time: 1.4161  data_time: 0.0562  lr: 8.0564e-06  max_mem: 21588M
[01/18 22:03:34] d2.utils.events INFO:  eta: 12:09:30  iter: 8559  total_loss: 43.04  loss_ce: 0.3404  loss_mask: 0.4559  loss_dice: 3.411  loss_ce_0: 0.606  loss_mask_0: 0.4388  loss_dice_0: 3.562  loss_ce_1: 0.3539  loss_mask_1: 0.4627  loss_dice_1: 3.443  loss_ce_2: 0.3439  loss_mask_2: 0.461  loss_dice_2: 3.423  loss_ce_3: 0.3414  loss_mask_3: 0.4565  loss_dice_3: 3.425  loss_ce_4: 0.339  loss_mask_4: 0.4586  loss_dice_4: 3.416  loss_ce_5: 0.3221  loss_mask_5: 0.4568  loss_dice_5: 3.421  loss_ce_6: 0.3307  loss_mask_6: 0.4584  loss_dice_6: 3.418  loss_ce_7: 0.3417  loss_mask_7: 0.4595  loss_dice_7: 3.413  loss_ce_8: 0.3366  loss_mask_8: 0.4577  loss_dice_8: 3.416  time: 1.4162  data_time: 0.0590  lr: 8.0518e-06  max_mem: 21588M
[01/18 22:04:03] d2.utils.events INFO:  eta: 12:09:22  iter: 8579  total_loss: 42.75  loss_ce: 0.347  loss_mask: 0.4519  loss_dice: 3.389  loss_ce_0: 0.642  loss_mask_0: 0.4303  loss_dice_0: 3.555  loss_ce_1: 0.366  loss_mask_1: 0.4467  loss_dice_1: 3.456  loss_ce_2: 0.3702  loss_mask_2: 0.4504  loss_dice_2: 3.418  loss_ce_3: 0.3506  loss_mask_3: 0.4478  loss_dice_3: 3.407  loss_ce_4: 0.3564  loss_mask_4: 0.4465  loss_dice_4: 3.403  loss_ce_5: 0.3423  loss_mask_5: 0.4479  loss_dice_5: 3.403  loss_ce_6: 0.3589  loss_mask_6: 0.447  loss_dice_6: 3.397  loss_ce_7: 0.3538  loss_mask_7: 0.4488  loss_dice_7: 3.395  loss_ce_8: 0.3454  loss_mask_8: 0.4507  loss_dice_8: 3.393  time: 1.4162  data_time: 0.0724  lr: 8.0472e-06  max_mem: 21588M
[01/18 22:04:32] d2.utils.events INFO:  eta: 12:09:03  iter: 8599  total_loss: 43.25  loss_ce: 0.3789  loss_mask: 0.4657  loss_dice: 3.419  loss_ce_0: 0.6424  loss_mask_0: 0.4462  loss_dice_0: 3.569  loss_ce_1: 0.3997  loss_mask_1: 0.4741  loss_dice_1: 3.462  loss_ce_2: 0.3794  loss_mask_2: 0.4722  loss_dice_2: 3.433  loss_ce_3: 0.3771  loss_mask_3: 0.47  loss_dice_3: 3.419  loss_ce_4: 0.3695  loss_mask_4: 0.4675  loss_dice_4: 3.424  loss_ce_5: 0.3776  loss_mask_5: 0.4672  loss_dice_5: 3.435  loss_ce_6: 0.3715  loss_mask_6: 0.4652  loss_dice_6: 3.423  loss_ce_7: 0.3688  loss_mask_7: 0.4657  loss_dice_7: 3.419  loss_ce_8: 0.3757  loss_mask_8: 0.4652  loss_dice_8: 3.424  time: 1.4163  data_time: 0.0651  lr: 8.0426e-06  max_mem: 21588M
[01/18 22:05:01] d2.utils.events INFO:  eta: 12:09:00  iter: 8619  total_loss: 42.44  loss_ce: 0.3664  loss_mask: 0.4605  loss_dice: 3.382  loss_ce_0: 0.6011  loss_mask_0: 0.4315  loss_dice_0: 3.532  loss_ce_1: 0.3675  loss_mask_1: 0.4589  loss_dice_1: 3.419  loss_ce_2: 0.3659  loss_mask_2: 0.4618  loss_dice_2: 3.392  loss_ce_3: 0.3645  loss_mask_3: 0.46  loss_dice_3: 3.388  loss_ce_4: 0.3657  loss_mask_4: 0.4596  loss_dice_4: 3.383  loss_ce_5: 0.3548  loss_mask_5: 0.4628  loss_dice_5: 3.384  loss_ce_6: 0.3583  loss_mask_6: 0.4601  loss_dice_6: 3.386  loss_ce_7: 0.3657  loss_mask_7: 0.4604  loss_dice_7: 3.386  loss_ce_8: 0.366  loss_mask_8: 0.4603  loss_dice_8: 3.381  time: 1.4164  data_time: 0.0723  lr: 8.038e-06  max_mem: 21588M
[01/18 22:05:30] d2.utils.events INFO:  eta: 12:08:39  iter: 8639  total_loss: 42.07  loss_ce: 0.3378  loss_mask: 0.4622  loss_dice: 3.353  loss_ce_0: 0.5818  loss_mask_0: 0.4346  loss_dice_0: 3.518  loss_ce_1: 0.3557  loss_mask_1: 0.4593  loss_dice_1: 3.386  loss_ce_2: 0.3481  loss_mask_2: 0.4607  loss_dice_2: 3.366  loss_ce_3: 0.3359  loss_mask_3: 0.4606  loss_dice_3: 3.357  loss_ce_4: 0.3375  loss_mask_4: 0.4624  loss_dice_4: 3.352  loss_ce_5: 0.3475  loss_mask_5: 0.462  loss_dice_5: 3.354  loss_ce_6: 0.3484  loss_mask_6: 0.4632  loss_dice_6: 3.351  loss_ce_7: 0.3382  loss_mask_7: 0.4621  loss_dice_7: 3.342  loss_ce_8: 0.3329  loss_mask_8: 0.4626  loss_dice_8: 3.351  time: 1.4165  data_time: 0.0684  lr: 8.0334e-06  max_mem: 21588M
[01/18 22:05:59] d2.utils.events INFO:  eta: 12:08:15  iter: 8659  total_loss: 42.66  loss_ce: 0.3558  loss_mask: 0.4638  loss_dice: 3.378  loss_ce_0: 0.6277  loss_mask_0: 0.4326  loss_dice_0: 3.539  loss_ce_1: 0.3641  loss_mask_1: 0.4631  loss_dice_1: 3.418  loss_ce_2: 0.36  loss_mask_2: 0.4607  loss_dice_2: 3.406  loss_ce_3: 0.3645  loss_mask_3: 0.4627  loss_dice_3: 3.385  loss_ce_4: 0.3537  loss_mask_4: 0.4618  loss_dice_4: 3.387  loss_ce_5: 0.3526  loss_mask_5: 0.4611  loss_dice_5: 3.386  loss_ce_6: 0.3446  loss_mask_6: 0.4621  loss_dice_6: 3.385  loss_ce_7: 0.346  loss_mask_7: 0.4634  loss_dice_7: 3.387  loss_ce_8: 0.3474  loss_mask_8: 0.4626  loss_dice_8: 3.393  time: 1.4165  data_time: 0.0681  lr: 8.0287e-06  max_mem: 21588M
[01/18 22:06:29] d2.utils.events INFO:  eta: 12:07:58  iter: 8679  total_loss: 42.04  loss_ce: 0.3423  loss_mask: 0.4616  loss_dice: 3.357  loss_ce_0: 0.6117  loss_mask_0: 0.4316  loss_dice_0: 3.518  loss_ce_1: 0.3525  loss_mask_1: 0.4591  loss_dice_1: 3.398  loss_ce_2: 0.3351  loss_mask_2: 0.4605  loss_dice_2: 3.372  loss_ce_3: 0.3262  loss_mask_3: 0.4609  loss_dice_3: 3.362  loss_ce_4: 0.3534  loss_mask_4: 0.4626  loss_dice_4: 3.359  loss_ce_5: 0.3487  loss_mask_5: 0.4631  loss_dice_5: 3.366  loss_ce_6: 0.3583  loss_mask_6: 0.4612  loss_dice_6: 3.359  loss_ce_7: 0.3459  loss_mask_7: 0.4617  loss_dice_7: 3.354  loss_ce_8: 0.3626  loss_mask_8: 0.4605  loss_dice_8: 3.353  time: 1.4167  data_time: 0.0802  lr: 8.0241e-06  max_mem: 21588M
[01/18 22:06:57] d2.utils.events INFO:  eta: 12:07:26  iter: 8699  total_loss: 42.75  loss_ce: 0.3659  loss_mask: 0.4499  loss_dice: 3.379  loss_ce_0: 0.6517  loss_mask_0: 0.4306  loss_dice_0: 3.558  loss_ce_1: 0.387  loss_mask_1: 0.4529  loss_dice_1: 3.43  loss_ce_2: 0.3852  loss_mask_2: 0.4515  loss_dice_2: 3.403  loss_ce_3: 0.382  loss_mask_3: 0.4529  loss_dice_3: 3.395  loss_ce_4: 0.3724  loss_mask_4: 0.4524  loss_dice_4: 3.398  loss_ce_5: 0.3792  loss_mask_5: 0.4516  loss_dice_5: 3.396  loss_ce_6: 0.3778  loss_mask_6: 0.4508  loss_dice_6: 3.389  loss_ce_7: 0.3776  loss_mask_7: 0.4492  loss_dice_7: 3.392  loss_ce_8: 0.3773  loss_mask_8: 0.4508  loss_dice_8: 3.389  time: 1.4167  data_time: 0.0528  lr: 8.0195e-06  max_mem: 21588M
[01/18 22:07:25] d2.utils.events INFO:  eta: 12:06:51  iter: 8719  total_loss: 41.83  loss_ce: 0.355  loss_mask: 0.4543  loss_dice: 3.327  loss_ce_0: 0.6166  loss_mask_0: 0.4294  loss_dice_0: 3.495  loss_ce_1: 0.3712  loss_mask_1: 0.4532  loss_dice_1: 3.36  loss_ce_2: 0.3751  loss_mask_2: 0.4539  loss_dice_2: 3.338  loss_ce_3: 0.3529  loss_mask_3: 0.4522  loss_dice_3: 3.33  loss_ce_4: 0.347  loss_mask_4: 0.4518  loss_dice_4: 3.326  loss_ce_5: 0.3483  loss_mask_5: 0.4518  loss_dice_5: 3.322  loss_ce_6: 0.3481  loss_mask_6: 0.4529  loss_dice_6: 3.323  loss_ce_7: 0.3521  loss_mask_7: 0.4537  loss_dice_7: 3.323  loss_ce_8: 0.3492  loss_mask_8: 0.454  loss_dice_8: 3.326  time: 1.4166  data_time: 0.0516  lr: 8.0149e-06  max_mem: 21588M
[01/18 22:07:53] d2.utils.events INFO:  eta: 12:06:34  iter: 8739  total_loss: 42.52  loss_ce: 0.3632  loss_mask: 0.4532  loss_dice: 3.393  loss_ce_0: 0.6253  loss_mask_0: 0.4295  loss_dice_0: 3.546  loss_ce_1: 0.3774  loss_mask_1: 0.4511  loss_dice_1: 3.438  loss_ce_2: 0.3626  loss_mask_2: 0.453  loss_dice_2: 3.409  loss_ce_3: 0.3517  loss_mask_3: 0.4539  loss_dice_3: 3.402  loss_ce_4: 0.3601  loss_mask_4: 0.4533  loss_dice_4: 3.398  loss_ce_5: 0.3677  loss_mask_5: 0.4515  loss_dice_5: 3.393  loss_ce_6: 0.3678  loss_mask_6: 0.451  loss_dice_6: 3.389  loss_ce_7: 0.3764  loss_mask_7: 0.4511  loss_dice_7: 3.39  loss_ce_8: 0.3485  loss_mask_8: 0.4526  loss_dice_8: 3.395  time: 1.4166  data_time: 0.0566  lr: 8.0103e-06  max_mem: 21588M
[01/18 22:08:22] d2.utils.events INFO:  eta: 12:06:17  iter: 8759  total_loss: 42.2  loss_ce: 0.3608  loss_mask: 0.4704  loss_dice: 3.341  loss_ce_0: 0.6065  loss_mask_0: 0.4397  loss_dice_0: 3.5  loss_ce_1: 0.3549  loss_mask_1: 0.4746  loss_dice_1: 3.38  loss_ce_2: 0.3707  loss_mask_2: 0.4705  loss_dice_2: 3.359  loss_ce_3: 0.3406  loss_mask_3: 0.4704  loss_dice_3: 3.342  loss_ce_4: 0.3587  loss_mask_4: 0.4694  loss_dice_4: 3.339  loss_ce_5: 0.3648  loss_mask_5: 0.4725  loss_dice_5: 3.338  loss_ce_6: 0.352  loss_mask_6: 0.4734  loss_dice_6: 3.335  loss_ce_7: 0.3547  loss_mask_7: 0.4721  loss_dice_7: 3.342  loss_ce_8: 0.3459  loss_mask_8: 0.4728  loss_dice_8: 3.337  time: 1.4166  data_time: 0.0688  lr: 8.0057e-06  max_mem: 21588M
[01/18 22:08:51] d2.utils.events INFO:  eta: 12:06:31  iter: 8779  total_loss: 42.22  loss_ce: 0.3385  loss_mask: 0.461  loss_dice: 3.382  loss_ce_0: 0.5888  loss_mask_0: 0.4358  loss_dice_0: 3.535  loss_ce_1: 0.3544  loss_mask_1: 0.4574  loss_dice_1: 3.419  loss_ce_2: 0.3434  loss_mask_2: 0.458  loss_dice_2: 3.392  loss_ce_3: 0.3416  loss_mask_3: 0.4595  loss_dice_3: 3.384  loss_ce_4: 0.3497  loss_mask_4: 0.4575  loss_dice_4: 3.378  loss_ce_5: 0.3375  loss_mask_5: 0.4561  loss_dice_5: 3.381  loss_ce_6: 0.3311  loss_mask_6: 0.4548  loss_dice_6: 3.378  loss_ce_7: 0.339  loss_mask_7: 0.4571  loss_dice_7: 3.378  loss_ce_8: 0.3364  loss_mask_8: 0.4599  loss_dice_8: 3.381  time: 1.4167  data_time: 0.0622  lr: 8.0011e-06  max_mem: 21588M
[01/18 22:09:20] d2.utils.events INFO:  eta: 12:06:35  iter: 8799  total_loss: 42.31  loss_ce: 0.3309  loss_mask: 0.4611  loss_dice: 3.387  loss_ce_0: 0.6005  loss_mask_0: 0.4348  loss_dice_0: 3.536  loss_ce_1: 0.3638  loss_mask_1: 0.4637  loss_dice_1: 3.41  loss_ce_2: 0.3371  loss_mask_2: 0.4647  loss_dice_2: 3.393  loss_ce_3: 0.3273  loss_mask_3: 0.4637  loss_dice_3: 3.38  loss_ce_4: 0.3237  loss_mask_4: 0.4618  loss_dice_4: 3.385  loss_ce_5: 0.3232  loss_mask_5: 0.464  loss_dice_5: 3.382  loss_ce_6: 0.3204  loss_mask_6: 0.4643  loss_dice_6: 3.389  loss_ce_7: 0.339  loss_mask_7: 0.4606  loss_dice_7: 3.39  loss_ce_8: 0.3411  loss_mask_8: 0.4601  loss_dice_8: 3.387  time: 1.4168  data_time: 0.0667  lr: 7.9965e-06  max_mem: 21588M
[01/18 22:09:49] d2.utils.events INFO:  eta: 12:06:24  iter: 8819  total_loss: 42.87  loss_ce: 0.3628  loss_mask: 0.4683  loss_dice: 3.409  loss_ce_0: 0.637  loss_mask_0: 0.4445  loss_dice_0: 3.571  loss_ce_1: 0.3714  loss_mask_1: 0.4726  loss_dice_1: 3.453  loss_ce_2: 0.3849  loss_mask_2: 0.4693  loss_dice_2: 3.425  loss_ce_3: 0.359  loss_mask_3: 0.4697  loss_dice_3: 3.416  loss_ce_4: 0.3678  loss_mask_4: 0.4698  loss_dice_4: 3.411  loss_ce_5: 0.3594  loss_mask_5: 0.4685  loss_dice_5: 3.408  loss_ce_6: 0.3712  loss_mask_6: 0.4714  loss_dice_6: 3.409  loss_ce_7: 0.3574  loss_mask_7: 0.468  loss_dice_7: 3.405  loss_ce_8: 0.353  loss_mask_8: 0.4691  loss_dice_8: 3.397  time: 1.4169  data_time: 0.0598  lr: 7.9918e-06  max_mem: 21588M
[01/18 22:10:19] d2.utils.events INFO:  eta: 12:06:44  iter: 8839  total_loss: 41.73  loss_ce: 0.3481  loss_mask: 0.4436  loss_dice: 3.353  loss_ce_0: 0.5857  loss_mask_0: 0.4228  loss_dice_0: 3.508  loss_ce_1: 0.3406  loss_mask_1: 0.4468  loss_dice_1: 3.39  loss_ce_2: 0.3396  loss_mask_2: 0.4457  loss_dice_2: 3.364  loss_ce_3: 0.3443  loss_mask_3: 0.4462  loss_dice_3: 3.354  loss_ce_4: 0.3381  loss_mask_4: 0.4451  loss_dice_4: 3.349  loss_ce_5: 0.3496  loss_mask_5: 0.4425  loss_dice_5: 3.344  loss_ce_6: 0.328  loss_mask_6: 0.4444  loss_dice_6: 3.338  loss_ce_7: 0.3428  loss_mask_7: 0.4439  loss_dice_7: 3.353  loss_ce_8: 0.3334  loss_mask_8: 0.4439  loss_dice_8: 3.344  time: 1.4170  data_time: 0.0616  lr: 7.9872e-06  max_mem: 21588M
[01/18 22:10:48] d2.utils.events INFO:  eta: 12:06:54  iter: 8859  total_loss: 42.32  loss_ce: 0.3709  loss_mask: 0.4412  loss_dice: 3.351  loss_ce_0: 0.6569  loss_mask_0: 0.4216  loss_dice_0: 3.519  loss_ce_1: 0.3761  loss_mask_1: 0.4407  loss_dice_1: 3.39  loss_ce_2: 0.3815  loss_mask_2: 0.4396  loss_dice_2: 3.369  loss_ce_3: 0.3654  loss_mask_3: 0.4418  loss_dice_3: 3.366  loss_ce_4: 0.3636  loss_mask_4: 0.44  loss_dice_4: 3.357  loss_ce_5: 0.3627  loss_mask_5: 0.4404  loss_dice_5: 3.355  loss_ce_6: 0.3565  loss_mask_6: 0.4401  loss_dice_6: 3.349  loss_ce_7: 0.3559  loss_mask_7: 0.4413  loss_dice_7: 3.355  loss_ce_8: 0.3525  loss_mask_8: 0.4414  loss_dice_8: 3.345  time: 1.4171  data_time: 0.0614  lr: 7.9826e-06  max_mem: 21588M
[01/18 22:11:17] d2.utils.events INFO:  eta: 12:07:43  iter: 8879  total_loss: 42.75  loss_ce: 0.38  loss_mask: 0.4477  loss_dice: 3.416  loss_ce_0: 0.6373  loss_mask_0: 0.4271  loss_dice_0: 3.574  loss_ce_1: 0.3823  loss_mask_1: 0.4512  loss_dice_1: 3.463  loss_ce_2: 0.4022  loss_mask_2: 0.4495  loss_dice_2: 3.421  loss_ce_3: 0.3931  loss_mask_3: 0.4478  loss_dice_3: 3.418  loss_ce_4: 0.3918  loss_mask_4: 0.4467  loss_dice_4: 3.421  loss_ce_5: 0.3812  loss_mask_5: 0.4487  loss_dice_5: 3.419  loss_ce_6: 0.3834  loss_mask_6: 0.4486  loss_dice_6: 3.42  loss_ce_7: 0.3749  loss_mask_7: 0.4494  loss_dice_7: 3.404  loss_ce_8: 0.3899  loss_mask_8: 0.4499  loss_dice_8: 3.407  time: 1.4172  data_time: 0.0644  lr: 7.978e-06  max_mem: 21588M
[01/18 22:11:46] d2.utils.events INFO:  eta: 12:07:11  iter: 8899  total_loss: 43.16  loss_ce: 0.3697  loss_mask: 0.4502  loss_dice: 3.451  loss_ce_0: 0.6506  loss_mask_0: 0.427  loss_dice_0: 3.609  loss_ce_1: 0.3645  loss_mask_1: 0.4485  loss_dice_1: 3.486  loss_ce_2: 0.3591  loss_mask_2: 0.45  loss_dice_2: 3.458  loss_ce_3: 0.3589  loss_mask_3: 0.4473  loss_dice_3: 3.447  loss_ce_4: 0.3502  loss_mask_4: 0.4471  loss_dice_4: 3.453  loss_ce_5: 0.3425  loss_mask_5: 0.4469  loss_dice_5: 3.452  loss_ce_6: 0.3555  loss_mask_6: 0.4469  loss_dice_6: 3.452  loss_ce_7: 0.3427  loss_mask_7: 0.4484  loss_dice_7: 3.446  loss_ce_8: 0.3562  loss_mask_8: 0.4502  loss_dice_8: 3.457  time: 1.4172  data_time: 0.0625  lr: 7.9734e-06  max_mem: 21588M
[01/18 22:12:13] d2.utils.events INFO:  eta: 12:06:12  iter: 8919  total_loss: 42.23  loss_ce: 0.3595  loss_mask: 0.4624  loss_dice: 3.361  loss_ce_0: 0.5752  loss_mask_0: 0.435  loss_dice_0: 3.532  loss_ce_1: 0.3382  loss_mask_1: 0.4648  loss_dice_1: 3.414  loss_ce_2: 0.352  loss_mask_2: 0.4631  loss_dice_2: 3.386  loss_ce_3: 0.3588  loss_mask_3: 0.4597  loss_dice_3: 3.386  loss_ce_4: 0.3394  loss_mask_4: 0.4614  loss_dice_4: 3.378  loss_ce_5: 0.3361  loss_mask_5: 0.4591  loss_dice_5: 3.376  loss_ce_6: 0.3416  loss_mask_6: 0.4596  loss_dice_6: 3.371  loss_ce_7: 0.337  loss_mask_7: 0.4596  loss_dice_7: 3.372  loss_ce_8: 0.3363  loss_mask_8: 0.4602  loss_dice_8: 3.373  time: 1.4171  data_time: 0.0584  lr: 7.9688e-06  max_mem: 21588M
[01/18 22:12:42] d2.utils.events INFO:  eta: 12:07:18  iter: 8939  total_loss: 42.1  loss_ce: 0.3483  loss_mask: 0.4531  loss_dice: 3.354  loss_ce_0: 0.5975  loss_mask_0: 0.4296  loss_dice_0: 3.525  loss_ce_1: 0.3642  loss_mask_1: 0.4555  loss_dice_1: 3.409  loss_ce_2: 0.3573  loss_mask_2: 0.4555  loss_dice_2: 3.379  loss_ce_3: 0.3489  loss_mask_3: 0.4537  loss_dice_3: 3.368  loss_ce_4: 0.3465  loss_mask_4: 0.4511  loss_dice_4: 3.358  loss_ce_5: 0.3395  loss_mask_5: 0.4521  loss_dice_5: 3.354  loss_ce_6: 0.3429  loss_mask_6: 0.4514  loss_dice_6: 3.35  loss_ce_7: 0.3465  loss_mask_7: 0.4536  loss_dice_7: 3.36  loss_ce_8: 0.3508  loss_mask_8: 0.452  loss_dice_8: 3.357  time: 1.4172  data_time: 0.0634  lr: 7.9642e-06  max_mem: 21588M
[01/18 22:13:12] d2.utils.events INFO:  eta: 12:08:09  iter: 8959  total_loss: 42.9  loss_ce: 0.3637  loss_mask: 0.4604  loss_dice: 3.395  loss_ce_0: 0.6305  loss_mask_0: 0.4303  loss_dice_0: 3.562  loss_ce_1: 0.3764  loss_mask_1: 0.4594  loss_dice_1: 3.446  loss_ce_2: 0.3666  loss_mask_2: 0.461  loss_dice_2: 3.411  loss_ce_3: 0.3587  loss_mask_3: 0.4585  loss_dice_3: 3.409  loss_ce_4: 0.3696  loss_mask_4: 0.4588  loss_dice_4: 3.413  loss_ce_5: 0.3797  loss_mask_5: 0.4575  loss_dice_5: 3.407  loss_ce_6: 0.368  loss_mask_6: 0.4606  loss_dice_6: 3.397  loss_ce_7: 0.3799  loss_mask_7: 0.4595  loss_dice_7: 3.402  loss_ce_8: 0.3646  loss_mask_8: 0.4583  loss_dice_8: 3.405  time: 1.4173  data_time: 0.0629  lr: 7.9595e-06  max_mem: 21588M
[01/18 22:13:41] d2.utils.events INFO:  eta: 12:08:36  iter: 8979  total_loss: 42.57  loss_ce: 0.349  loss_mask: 0.4374  loss_dice: 3.389  loss_ce_0: 0.6065  loss_mask_0: 0.4125  loss_dice_0: 3.555  loss_ce_1: 0.3573  loss_mask_1: 0.4417  loss_dice_1: 3.434  loss_ce_2: 0.337  loss_mask_2: 0.4382  loss_dice_2: 3.402  loss_ce_3: 0.3393  loss_mask_3: 0.4369  loss_dice_3: 3.403  loss_ce_4: 0.351  loss_mask_4: 0.4344  loss_dice_4: 3.393  loss_ce_5: 0.3456  loss_mask_5: 0.4356  loss_dice_5: 3.394  loss_ce_6: 0.3467  loss_mask_6: 0.4384  loss_dice_6: 3.396  loss_ce_7: 0.341  loss_mask_7: 0.4384  loss_dice_7: 3.396  loss_ce_8: 0.3437  loss_mask_8: 0.4382  loss_dice_8: 3.39  time: 1.4174  data_time: 0.0610  lr: 7.9549e-06  max_mem: 21588M
[01/18 22:14:11] d2.utils.events INFO:  eta: 12:08:51  iter: 8999  total_loss: 41.89  loss_ce: 0.3447  loss_mask: 0.4531  loss_dice: 3.336  loss_ce_0: 0.5947  loss_mask_0: 0.4278  loss_dice_0: 3.496  loss_ce_1: 0.3514  loss_mask_1: 0.4561  loss_dice_1: 3.376  loss_ce_2: 0.3404  loss_mask_2: 0.455  loss_dice_2: 3.357  loss_ce_3: 0.335  loss_mask_3: 0.4539  loss_dice_3: 3.345  loss_ce_4: 0.3513  loss_mask_4: 0.4519  loss_dice_4: 3.351  loss_ce_5: 0.3556  loss_mask_5: 0.4516  loss_dice_5: 3.341  loss_ce_6: 0.3454  loss_mask_6: 0.4515  loss_dice_6: 3.342  loss_ce_7: 0.3384  loss_mask_7: 0.4523  loss_dice_7: 3.337  loss_ce_8: 0.3526  loss_mask_8: 0.4521  loss_dice_8: 3.335  time: 1.4175  data_time: 0.0618  lr: 7.9503e-06  max_mem: 21588M
[01/18 22:14:39] d2.utils.events INFO:  eta: 12:08:14  iter: 9019  total_loss: 41.82  loss_ce: 0.3301  loss_mask: 0.4432  loss_dice: 3.365  loss_ce_0: 0.5988  loss_mask_0: 0.4212  loss_dice_0: 3.521  loss_ce_1: 0.3412  loss_mask_1: 0.4444  loss_dice_1: 3.399  loss_ce_2: 0.3282  loss_mask_2: 0.4423  loss_dice_2: 3.371  loss_ce_3: 0.3202  loss_mask_3: 0.442  loss_dice_3: 3.356  loss_ce_4: 0.3263  loss_mask_4: 0.4442  loss_dice_4: 3.364  loss_ce_5: 0.3258  loss_mask_5: 0.4439  loss_dice_5: 3.356  loss_ce_6: 0.3195  loss_mask_6: 0.4423  loss_dice_6: 3.364  loss_ce_7: 0.331  loss_mask_7: 0.4444  loss_dice_7: 3.361  loss_ce_8: 0.3375  loss_mask_8: 0.444  loss_dice_8: 3.358  time: 1.4175  data_time: 0.0592  lr: 7.9457e-06  max_mem: 21588M
[01/18 22:15:08] d2.utils.events INFO:  eta: 12:08:17  iter: 9039  total_loss: 42.18  loss_ce: 0.3646  loss_mask: 0.4533  loss_dice: 3.364  loss_ce_0: 0.5922  loss_mask_0: 0.4278  loss_dice_0: 3.513  loss_ce_1: 0.3607  loss_mask_1: 0.4546  loss_dice_1: 3.407  loss_ce_2: 0.3517  loss_mask_2: 0.4535  loss_dice_2: 3.383  loss_ce_3: 0.3519  loss_mask_3: 0.4494  loss_dice_3: 3.369  loss_ce_4: 0.357  loss_mask_4: 0.4488  loss_dice_4: 3.371  loss_ce_5: 0.369  loss_mask_5: 0.4461  loss_dice_5: 3.371  loss_ce_6: 0.3556  loss_mask_6: 0.4483  loss_dice_6: 3.358  loss_ce_7: 0.352  loss_mask_7: 0.45  loss_dice_7: 3.365  loss_ce_8: 0.3658  loss_mask_8: 0.4501  loss_dice_8: 3.36  time: 1.4176  data_time: 0.0654  lr: 7.9411e-06  max_mem: 21588M
[01/18 22:15:37] d2.utils.events INFO:  eta: 12:08:08  iter: 9059  total_loss: 42.21  loss_ce: 0.3754  loss_mask: 0.4452  loss_dice: 3.385  loss_ce_0: 0.6254  loss_mask_0: 0.4149  loss_dice_0: 3.544  loss_ce_1: 0.3612  loss_mask_1: 0.4473  loss_dice_1: 3.427  loss_ce_2: 0.3671  loss_mask_2: 0.4478  loss_dice_2: 3.401  loss_ce_3: 0.347  loss_mask_3: 0.4432  loss_dice_3: 3.395  loss_ce_4: 0.3662  loss_mask_4: 0.4413  loss_dice_4: 3.406  loss_ce_5: 0.3433  loss_mask_5: 0.4421  loss_dice_5: 3.4  loss_ce_6: 0.3467  loss_mask_6: 0.4425  loss_dice_6: 3.397  loss_ce_7: 0.3606  loss_mask_7: 0.4436  loss_dice_7: 3.389  loss_ce_8: 0.3556  loss_mask_8: 0.4456  loss_dice_8: 3.397  time: 1.4176  data_time: 0.0654  lr: 7.9365e-06  max_mem: 21588M
[01/18 22:16:06] d2.utils.events INFO:  eta: 12:08:02  iter: 9079  total_loss: 41.61  loss_ce: 0.3353  loss_mask: 0.4575  loss_dice: 3.301  loss_ce_0: 0.5935  loss_mask_0: 0.4263  loss_dice_0: 3.461  loss_ce_1: 0.3384  loss_mask_1: 0.4584  loss_dice_1: 3.34  loss_ce_2: 0.3348  loss_mask_2: 0.4567  loss_dice_2: 3.316  loss_ce_3: 0.343  loss_mask_3: 0.4578  loss_dice_3: 3.308  loss_ce_4: 0.353  loss_mask_4: 0.4551  loss_dice_4: 3.308  loss_ce_5: 0.3428  loss_mask_5: 0.4567  loss_dice_5: 3.31  loss_ce_6: 0.3345  loss_mask_6: 0.4577  loss_dice_6: 3.306  loss_ce_7: 0.3379  loss_mask_7: 0.459  loss_dice_7: 3.309  loss_ce_8: 0.3312  loss_mask_8: 0.4599  loss_dice_8: 3.3  time: 1.4177  data_time: 0.0593  lr: 7.9318e-06  max_mem: 21588M
[01/18 22:16:35] d2.utils.events INFO:  eta: 12:08:29  iter: 9099  total_loss: 42.12  loss_ce: 0.3478  loss_mask: 0.4461  loss_dice: 3.334  loss_ce_0: 0.5997  loss_mask_0: 0.4242  loss_dice_0: 3.486  loss_ce_1: 0.3489  loss_mask_1: 0.4501  loss_dice_1: 3.365  loss_ce_2: 0.3471  loss_mask_2: 0.4479  loss_dice_2: 3.343  loss_ce_3: 0.3561  loss_mask_3: 0.4475  loss_dice_3: 3.328  loss_ce_4: 0.3505  loss_mask_4: 0.4454  loss_dice_4: 3.33  loss_ce_5: 0.3479  loss_mask_5: 0.4471  loss_dice_5: 3.332  loss_ce_6: 0.3553  loss_mask_6: 0.4474  loss_dice_6: 3.326  loss_ce_7: 0.3604  loss_mask_7: 0.4455  loss_dice_7: 3.329  loss_ce_8: 0.3557  loss_mask_8: 0.4441  loss_dice_8: 3.332  time: 1.4177  data_time: 0.0614  lr: 7.9272e-06  max_mem: 21588M
[01/18 22:17:04] d2.utils.events INFO:  eta: 12:08:44  iter: 9119  total_loss: 42.23  loss_ce: 0.3403  loss_mask: 0.4616  loss_dice: 3.371  loss_ce_0: 0.633  loss_mask_0: 0.4299  loss_dice_0: 3.525  loss_ce_1: 0.353  loss_mask_1: 0.4656  loss_dice_1: 3.412  loss_ce_2: 0.3343  loss_mask_2: 0.4643  loss_dice_2: 3.382  loss_ce_3: 0.3509  loss_mask_3: 0.462  loss_dice_3: 3.379  loss_ce_4: 0.3433  loss_mask_4: 0.4607  loss_dice_4: 3.385  loss_ce_5: 0.3356  loss_mask_5: 0.4623  loss_dice_5: 3.377  loss_ce_6: 0.3231  loss_mask_6: 0.4649  loss_dice_6: 3.381  loss_ce_7: 0.351  loss_mask_7: 0.4621  loss_dice_7: 3.373  loss_ce_8: 0.3307  loss_mask_8: 0.463  loss_dice_8: 3.376  time: 1.4178  data_time: 0.0593  lr: 7.9226e-06  max_mem: 21588M
[01/18 22:17:33] d2.utils.events INFO:  eta: 12:09:20  iter: 9139  total_loss: 41.58  loss_ce: 0.3265  loss_mask: 0.4368  loss_dice: 3.34  loss_ce_0: 0.5926  loss_mask_0: 0.4179  loss_dice_0: 3.497  loss_ce_1: 0.3504  loss_mask_1: 0.4412  loss_dice_1: 3.379  loss_ce_2: 0.3536  loss_mask_2: 0.439  loss_dice_2: 3.348  loss_ce_3: 0.3364  loss_mask_3: 0.438  loss_dice_3: 3.343  loss_ce_4: 0.3257  loss_mask_4: 0.4387  loss_dice_4: 3.344  loss_ce_5: 0.3323  loss_mask_5: 0.436  loss_dice_5: 3.342  loss_ce_6: 0.3356  loss_mask_6: 0.4343  loss_dice_6: 3.339  loss_ce_7: 0.3308  loss_mask_7: 0.4358  loss_dice_7: 3.336  loss_ce_8: 0.3245  loss_mask_8: 0.4358  loss_dice_8: 3.332  time: 1.4179  data_time: 0.0592  lr: 7.918e-06  max_mem: 21588M
[01/18 22:18:03] d2.utils.events INFO:  eta: 12:10:30  iter: 9159  total_loss: 42.35  loss_ce: 0.3453  loss_mask: 0.4336  loss_dice: 3.37  loss_ce_0: 0.6276  loss_mask_0: 0.4112  loss_dice_0: 3.524  loss_ce_1: 0.3712  loss_mask_1: 0.4325  loss_dice_1: 3.416  loss_ce_2: 0.3529  loss_mask_2: 0.4327  loss_dice_2: 3.386  loss_ce_3: 0.3522  loss_mask_3: 0.435  loss_dice_3: 3.372  loss_ce_4: 0.3373  loss_mask_4: 0.4352  loss_dice_4: 3.369  loss_ce_5: 0.3403  loss_mask_5: 0.4382  loss_dice_5: 3.374  loss_ce_6: 0.3404  loss_mask_6: 0.44  loss_dice_6: 3.369  loss_ce_7: 0.3409  loss_mask_7: 0.4388  loss_dice_7: 3.374  loss_ce_8: 0.3471  loss_mask_8: 0.4355  loss_dice_8: 3.364  time: 1.4181  data_time: 0.0793  lr: 7.9134e-06  max_mem: 21588M
[01/18 22:18:32] d2.utils.events INFO:  eta: 12:10:39  iter: 9179  total_loss: 42.82  loss_ce: 0.384  loss_mask: 0.4548  loss_dice: 3.351  loss_ce_0: 0.6365  loss_mask_0: 0.4294  loss_dice_0: 3.494  loss_ce_1: 0.3609  loss_mask_1: 0.464  loss_dice_1: 3.371  loss_ce_2: 0.3769  loss_mask_2: 0.4599  loss_dice_2: 3.361  loss_ce_3: 0.3744  loss_mask_3: 0.4569  loss_dice_3: 3.359  loss_ce_4: 0.3613  loss_mask_4: 0.455  loss_dice_4: 3.349  loss_ce_5: 0.3959  loss_mask_5: 0.4556  loss_dice_5: 3.355  loss_ce_6: 0.3709  loss_mask_6: 0.4541  loss_dice_6: 3.356  loss_ce_7: 0.3778  loss_mask_7: 0.4525  loss_dice_7: 3.352  loss_ce_8: 0.3695  loss_mask_8: 0.4543  loss_dice_8: 3.356  time: 1.4182  data_time: 0.0726  lr: 7.9088e-06  max_mem: 21588M
[01/18 22:19:02] d2.utils.events INFO:  eta: 12:10:57  iter: 9199  total_loss: 42.36  loss_ce: 0.3563  loss_mask: 0.4477  loss_dice: 3.368  loss_ce_0: 0.6138  loss_mask_0: 0.4219  loss_dice_0: 3.525  loss_ce_1: 0.3567  loss_mask_1: 0.4483  loss_dice_1: 3.419  loss_ce_2: 0.3625  loss_mask_2: 0.4476  loss_dice_2: 3.392  loss_ce_3: 0.3517  loss_mask_3: 0.4476  loss_dice_3: 3.376  loss_ce_4: 0.346  loss_mask_4: 0.4481  loss_dice_4: 3.371  loss_ce_5: 0.3564  loss_mask_5: 0.448  loss_dice_5: 3.374  loss_ce_6: 0.3387  loss_mask_6: 0.4474  loss_dice_6: 3.372  loss_ce_7: 0.3566  loss_mask_7: 0.4472  loss_dice_7: 3.369  loss_ce_8: 0.3515  loss_mask_8: 0.448  loss_dice_8: 3.372  time: 1.4183  data_time: 0.0706  lr: 7.9041e-06  max_mem: 21588M
[01/18 22:19:31] d2.utils.events INFO:  eta: 12:11:19  iter: 9219  total_loss: 41.49  loss_ce: 0.3213  loss_mask: 0.4623  loss_dice: 3.318  loss_ce_0: 0.5817  loss_mask_0: 0.4344  loss_dice_0: 3.482  loss_ce_1: 0.3375  loss_mask_1: 0.4667  loss_dice_1: 3.364  loss_ce_2: 0.3466  loss_mask_2: 0.4664  loss_dice_2: 3.33  loss_ce_3: 0.3308  loss_mask_3: 0.4636  loss_dice_3: 3.317  loss_ce_4: 0.3383  loss_mask_4: 0.4624  loss_dice_4: 3.317  loss_ce_5: 0.3276  loss_mask_5: 0.4635  loss_dice_5: 3.318  loss_ce_6: 0.3356  loss_mask_6: 0.4622  loss_dice_6: 3.323  loss_ce_7: 0.3291  loss_mask_7: 0.4612  loss_dice_7: 3.318  loss_ce_8: 0.3291  loss_mask_8: 0.4614  loss_dice_8: 3.33  time: 1.4184  data_time: 0.0609  lr: 7.8995e-06  max_mem: 21588M
[01/18 22:20:01] d2.utils.events INFO:  eta: 12:12:13  iter: 9239  total_loss: 41.65  loss_ce: 0.3428  loss_mask: 0.4424  loss_dice: 3.299  loss_ce_0: 0.5981  loss_mask_0: 0.4185  loss_dice_0: 3.46  loss_ce_1: 0.3606  loss_mask_1: 0.4406  loss_dice_1: 3.343  loss_ce_2: 0.353  loss_mask_2: 0.4428  loss_dice_2: 3.316  loss_ce_3: 0.3482  loss_mask_3: 0.4476  loss_dice_3: 3.297  loss_ce_4: 0.3529  loss_mask_4: 0.4453  loss_dice_4: 3.301  loss_ce_5: 0.3525  loss_mask_5: 0.4449  loss_dice_5: 3.3  loss_ce_6: 0.3544  loss_mask_6: 0.4446  loss_dice_6: 3.298  loss_ce_7: 0.3531  loss_mask_7: 0.444  loss_dice_7: 3.293  loss_ce_8: 0.3549  loss_mask_8: 0.4432  loss_dice_8: 3.29  time: 1.4185  data_time: 0.0648  lr: 7.8949e-06  max_mem: 21588M
[01/18 22:20:30] d2.utils.events INFO:  eta: 12:12:38  iter: 9259  total_loss: 41.89  loss_ce: 0.392  loss_mask: 0.4587  loss_dice: 3.291  loss_ce_0: 0.6226  loss_mask_0: 0.4268  loss_dice_0: 3.457  loss_ce_1: 0.3993  loss_mask_1: 0.4586  loss_dice_1: 3.333  loss_ce_2: 0.3769  loss_mask_2: 0.4577  loss_dice_2: 3.304  loss_ce_3: 0.3893  loss_mask_3: 0.4574  loss_dice_3: 3.296  loss_ce_4: 0.3904  loss_mask_4: 0.4587  loss_dice_4: 3.299  loss_ce_5: 0.3773  loss_mask_5: 0.4604  loss_dice_5: 3.289  loss_ce_6: 0.38  loss_mask_6: 0.4597  loss_dice_6: 3.276  loss_ce_7: 0.3824  loss_mask_7: 0.4603  loss_dice_7: 3.283  loss_ce_8: 0.3794  loss_mask_8: 0.4586  loss_dice_8: 3.288  time: 1.4186  data_time: 0.0688  lr: 7.8903e-06  max_mem: 21588M
[01/18 22:20:59] d2.utils.events INFO:  eta: 12:12:51  iter: 9279  total_loss: 42.11  loss_ce: 0.3303  loss_mask: 0.4455  loss_dice: 3.373  loss_ce_0: 0.6034  loss_mask_0: 0.4233  loss_dice_0: 3.497  loss_ce_1: 0.3441  loss_mask_1: 0.4511  loss_dice_1: 3.392  loss_ce_2: 0.332  loss_mask_2: 0.4516  loss_dice_2: 3.373  loss_ce_3: 0.3216  loss_mask_3: 0.4459  loss_dice_3: 3.377  loss_ce_4: 0.3335  loss_mask_4: 0.4464  loss_dice_4: 3.369  loss_ce_5: 0.3316  loss_mask_5: 0.4469  loss_dice_5: 3.37  loss_ce_6: 0.3293  loss_mask_6: 0.4452  loss_dice_6: 3.377  loss_ce_7: 0.3267  loss_mask_7: 0.4467  loss_dice_7: 3.375  loss_ce_8: 0.3272  loss_mask_8: 0.4455  loss_dice_8: 3.377  time: 1.4187  data_time: 0.0616  lr: 7.8857e-06  max_mem: 21588M
[01/18 22:21:28] d2.utils.events INFO:  eta: 12:12:37  iter: 9299  total_loss: 42.07  loss_ce: 0.3589  loss_mask: 0.4452  loss_dice: 3.319  loss_ce_0: 0.6034  loss_mask_0: 0.4161  loss_dice_0: 3.498  loss_ce_1: 0.3469  loss_mask_1: 0.4393  loss_dice_1: 3.371  loss_ce_2: 0.3531  loss_mask_2: 0.4422  loss_dice_2: 3.332  loss_ce_3: 0.3583  loss_mask_3: 0.4442  loss_dice_3: 3.319  loss_ce_4: 0.3417  loss_mask_4: 0.4423  loss_dice_4: 3.314  loss_ce_5: 0.3528  loss_mask_5: 0.4421  loss_dice_5: 3.322  loss_ce_6: 0.3481  loss_mask_6: 0.4454  loss_dice_6: 3.313  loss_ce_7: 0.3529  loss_mask_7: 0.4459  loss_dice_7: 3.32  loss_ce_8: 0.3554  loss_mask_8: 0.4456  loss_dice_8: 3.325  time: 1.4187  data_time: 0.0697  lr: 7.881e-06  max_mem: 21588M
[01/18 22:21:57] d2.utils.events INFO:  eta: 12:13:31  iter: 9319  total_loss: 41.55  loss_ce: 0.3639  loss_mask: 0.4416  loss_dice: 3.323  loss_ce_0: 0.5922  loss_mask_0: 0.4152  loss_dice_0: 3.486  loss_ce_1: 0.3741  loss_mask_1: 0.4403  loss_dice_1: 3.362  loss_ce_2: 0.372  loss_mask_2: 0.4409  loss_dice_2: 3.332  loss_ce_3: 0.3532  loss_mask_3: 0.4425  loss_dice_3: 3.322  loss_ce_4: 0.3682  loss_mask_4: 0.444  loss_dice_4: 3.323  loss_ce_5: 0.3663  loss_mask_5: 0.4414  loss_dice_5: 3.32  loss_ce_6: 0.3516  loss_mask_6: 0.4398  loss_dice_6: 3.322  loss_ce_7: 0.3499  loss_mask_7: 0.4385  loss_dice_7: 3.322  loss_ce_8: 0.3517  loss_mask_8: 0.4392  loss_dice_8: 3.316  time: 1.4188  data_time: 0.0668  lr: 7.8764e-06  max_mem: 21588M
[01/18 22:22:26] d2.utils.events INFO:  eta: 12:13:38  iter: 9339  total_loss: 42.15  loss_ce: 0.3527  loss_mask: 0.4527  loss_dice: 3.353  loss_ce_0: 0.6339  loss_mask_0: 0.4299  loss_dice_0: 3.499  loss_ce_1: 0.384  loss_mask_1: 0.4586  loss_dice_1: 3.392  loss_ce_2: 0.3727  loss_mask_2: 0.4539  loss_dice_2: 3.37  loss_ce_3: 0.3608  loss_mask_3: 0.4552  loss_dice_3: 3.36  loss_ce_4: 0.3612  loss_mask_4: 0.4547  loss_dice_4: 3.352  loss_ce_5: 0.3668  loss_mask_5: 0.4506  loss_dice_5: 3.348  loss_ce_6: 0.3714  loss_mask_6: 0.4512  loss_dice_6: 3.354  loss_ce_7: 0.3614  loss_mask_7: 0.4526  loss_dice_7: 3.354  loss_ce_8: 0.3716  loss_mask_8: 0.4519  loss_dice_8: 3.352  time: 1.4189  data_time: 0.0593  lr: 7.8718e-06  max_mem: 21588M
[01/18 22:22:55] d2.utils.events INFO:  eta: 12:13:15  iter: 9359  total_loss: 41.74  loss_ce: 0.397  loss_mask: 0.4493  loss_dice: 3.302  loss_ce_0: 0.6498  loss_mask_0: 0.4218  loss_dice_0: 3.475  loss_ce_1: 0.3954  loss_mask_1: 0.4471  loss_dice_1: 3.348  loss_ce_2: 0.3877  loss_mask_2: 0.4497  loss_dice_2: 3.317  loss_ce_3: 0.3796  loss_mask_3: 0.446  loss_dice_3: 3.309  loss_ce_4: 0.4092  loss_mask_4: 0.4458  loss_dice_4: 3.301  loss_ce_5: 0.3875  loss_mask_5: 0.4467  loss_dice_5: 3.299  loss_ce_6: 0.3779  loss_mask_6: 0.4496  loss_dice_6: 3.3  loss_ce_7: 0.3711  loss_mask_7: 0.4505  loss_dice_7: 3.308  loss_ce_8: 0.3924  loss_mask_8: 0.45  loss_dice_8: 3.306  time: 1.4189  data_time: 0.0549  lr: 7.8672e-06  max_mem: 21588M
[01/18 22:23:24] d2.utils.events INFO:  eta: 12:13:38  iter: 9379  total_loss: 42.34  loss_ce: 0.3771  loss_mask: 0.4346  loss_dice: 3.376  loss_ce_0: 0.6226  loss_mask_0: 0.4093  loss_dice_0: 3.535  loss_ce_1: 0.3934  loss_mask_1: 0.4386  loss_dice_1: 3.427  loss_ce_2: 0.3767  loss_mask_2: 0.4352  loss_dice_2: 3.384  loss_ce_3: 0.3595  loss_mask_3: 0.4366  loss_dice_3: 3.386  loss_ce_4: 0.3717  loss_mask_4: 0.436  loss_dice_4: 3.38  loss_ce_5: 0.3707  loss_mask_5: 0.4361  loss_dice_5: 3.373  loss_ce_6: 0.3656  loss_mask_6: 0.4361  loss_dice_6: 3.383  loss_ce_7: 0.3714  loss_mask_7: 0.436  loss_dice_7: 3.374  loss_ce_8: 0.3648  loss_mask_8: 0.4365  loss_dice_8: 3.371  time: 1.4190  data_time: 0.0683  lr: 7.8626e-06  max_mem: 21588M
[01/18 22:23:54] d2.utils.events INFO:  eta: 12:14:32  iter: 9399  total_loss: 42.03  loss_ce: 0.3525  loss_mask: 0.4393  loss_dice: 3.346  loss_ce_0: 0.5975  loss_mask_0: 0.416  loss_dice_0: 3.501  loss_ce_1: 0.3532  loss_mask_1: 0.4436  loss_dice_1: 3.382  loss_ce_2: 0.3787  loss_mask_2: 0.4405  loss_dice_2: 3.35  loss_ce_3: 0.3653  loss_mask_3: 0.4412  loss_dice_3: 3.347  loss_ce_4: 0.354  loss_mask_4: 0.4403  loss_dice_4: 3.347  loss_ce_5: 0.37  loss_mask_5: 0.4394  loss_dice_5: 3.347  loss_ce_6: 0.3496  loss_mask_6: 0.4377  loss_dice_6: 3.344  loss_ce_7: 0.3561  loss_mask_7: 0.436  loss_dice_7: 3.351  loss_ce_8: 0.3614  loss_mask_8: 0.4351  loss_dice_8: 3.346  time: 1.4191  data_time: 0.0629  lr: 7.8579e-06  max_mem: 21588M
[01/18 22:24:22] d2.utils.events INFO:  eta: 12:14:42  iter: 9419  total_loss: 41.13  loss_ce: 0.3533  loss_mask: 0.4526  loss_dice: 3.278  loss_ce_0: 0.601  loss_mask_0: 0.421  loss_dice_0: 3.446  loss_ce_1: 0.339  loss_mask_1: 0.45  loss_dice_1: 3.315  loss_ce_2: 0.3413  loss_mask_2: 0.4534  loss_dice_2: 3.295  loss_ce_3: 0.3563  loss_mask_3: 0.4524  loss_dice_3: 3.287  loss_ce_4: 0.332  loss_mask_4: 0.4518  loss_dice_4: 3.285  loss_ce_5: 0.3574  loss_mask_5: 0.454  loss_dice_5: 3.289  loss_ce_6: 0.3337  loss_mask_6: 0.4558  loss_dice_6: 3.284  loss_ce_7: 0.3424  loss_mask_7: 0.4555  loss_dice_7: 3.278  loss_ce_8: 0.3535  loss_mask_8: 0.4532  loss_dice_8: 3.281  time: 1.4192  data_time: 0.0585  lr: 7.8533e-06  max_mem: 21588M
[01/18 22:24:52] d2.utils.events INFO:  eta: 12:14:44  iter: 9439  total_loss: 42.32  loss_ce: 0.3402  loss_mask: 0.4587  loss_dice: 3.358  loss_ce_0: 0.6025  loss_mask_0: 0.4343  loss_dice_0: 3.514  loss_ce_1: 0.3689  loss_mask_1: 0.4632  loss_dice_1: 3.396  loss_ce_2: 0.3491  loss_mask_2: 0.4622  loss_dice_2: 3.364  loss_ce_3: 0.3523  loss_mask_3: 0.4599  loss_dice_3: 3.356  loss_ce_4: 0.3451  loss_mask_4: 0.4585  loss_dice_4: 3.361  loss_ce_5: 0.3446  loss_mask_5: 0.4571  loss_dice_5: 3.363  loss_ce_6: 0.3498  loss_mask_6: 0.4571  loss_dice_6: 3.361  loss_ce_7: 0.3462  loss_mask_7: 0.4536  loss_dice_7: 3.367  loss_ce_8: 0.3451  loss_mask_8: 0.4572  loss_dice_8: 3.366  time: 1.4193  data_time: 0.0659  lr: 7.8487e-06  max_mem: 21588M
[01/18 22:25:21] d2.utils.events INFO:  eta: 12:15:18  iter: 9459  total_loss: 41.47  loss_ce: 0.3463  loss_mask: 0.4396  loss_dice: 3.313  loss_ce_0: 0.6291  loss_mask_0: 0.4201  loss_dice_0: 3.477  loss_ce_1: 0.3478  loss_mask_1: 0.4449  loss_dice_1: 3.359  loss_ce_2: 0.3546  loss_mask_2: 0.44  loss_dice_2: 3.33  loss_ce_3: 0.336  loss_mask_3: 0.4389  loss_dice_3: 3.323  loss_ce_4: 0.3374  loss_mask_4: 0.4388  loss_dice_4: 3.31  loss_ce_5: 0.3385  loss_mask_5: 0.4391  loss_dice_5: 3.319  loss_ce_6: 0.3353  loss_mask_6: 0.4388  loss_dice_6: 3.314  loss_ce_7: 0.328  loss_mask_7: 0.4411  loss_dice_7: 3.32  loss_ce_8: 0.3453  loss_mask_8: 0.4408  loss_dice_8: 3.314  time: 1.4194  data_time: 0.0602  lr: 7.8441e-06  max_mem: 21588M
[01/18 22:25:50] d2.utils.events INFO:  eta: 12:15:06  iter: 9479  total_loss: 41.37  loss_ce: 0.3202  loss_mask: 0.4426  loss_dice: 3.282  loss_ce_0: 0.5554  loss_mask_0: 0.4183  loss_dice_0: 3.459  loss_ce_1: 0.3236  loss_mask_1: 0.4507  loss_dice_1: 3.34  loss_ce_2: 0.3035  loss_mask_2: 0.4471  loss_dice_2: 3.304  loss_ce_3: 0.3209  loss_mask_3: 0.4449  loss_dice_3: 3.304  loss_ce_4: 0.3102  loss_mask_4: 0.4449  loss_dice_4: 3.299  loss_ce_5: 0.3265  loss_mask_5: 0.4439  loss_dice_5: 3.299  loss_ce_6: 0.3061  loss_mask_6: 0.4422  loss_dice_6: 3.291  loss_ce_7: 0.3094  loss_mask_7: 0.441  loss_dice_7: 3.292  loss_ce_8: 0.3066  loss_mask_8: 0.4431  loss_dice_8: 3.294  time: 1.4194  data_time: 0.0677  lr: 7.8394e-06  max_mem: 21588M
[01/18 22:26:20] d2.utils.events INFO:  eta: 12:15:35  iter: 9499  total_loss: 41.75  loss_ce: 0.3429  loss_mask: 0.4446  loss_dice: 3.327  loss_ce_0: 0.6022  loss_mask_0: 0.4202  loss_dice_0: 3.466  loss_ce_1: 0.341  loss_mask_1: 0.4399  loss_dice_1: 3.363  loss_ce_2: 0.3518  loss_mask_2: 0.4374  loss_dice_2: 3.342  loss_ce_3: 0.3488  loss_mask_3: 0.4418  loss_dice_3: 3.327  loss_ce_4: 0.3386  loss_mask_4: 0.4422  loss_dice_4: 3.33  loss_ce_5: 0.3516  loss_mask_5: 0.4448  loss_dice_5: 3.33  loss_ce_6: 0.3352  loss_mask_6: 0.445  loss_dice_6: 3.327  loss_ce_7: 0.342  loss_mask_7: 0.4444  loss_dice_7: 3.325  loss_ce_8: 0.3505  loss_mask_8: 0.4436  loss_dice_8: 3.326  time: 1.4195  data_time: 0.0587  lr: 7.8348e-06  max_mem: 21588M
[01/18 22:26:49] d2.utils.events INFO:  eta: 12:15:47  iter: 9519  total_loss: 41.24  loss_ce: 0.3135  loss_mask: 0.4559  loss_dice: 3.31  loss_ce_0: 0.6034  loss_mask_0: 0.4304  loss_dice_0: 3.457  loss_ce_1: 0.335  loss_mask_1: 0.4594  loss_dice_1: 3.345  loss_ce_2: 0.3215  loss_mask_2: 0.4558  loss_dice_2: 3.326  loss_ce_3: 0.3285  loss_mask_3: 0.4559  loss_dice_3: 3.322  loss_ce_4: 0.3434  loss_mask_4: 0.4545  loss_dice_4: 3.312  loss_ce_5: 0.3317  loss_mask_5: 0.4539  loss_dice_5: 3.306  loss_ce_6: 0.3204  loss_mask_6: 0.4567  loss_dice_6: 3.317  loss_ce_7: 0.3224  loss_mask_7: 0.4573  loss_dice_7: 3.316  loss_ce_8: 0.3443  loss_mask_8: 0.4553  loss_dice_8: 3.306  time: 1.4196  data_time: 0.0644  lr: 7.8302e-06  max_mem: 21588M
[01/18 22:27:18] d2.utils.events INFO:  eta: 12:15:35  iter: 9539  total_loss: 40.93  loss_ce: 0.3432  loss_mask: 0.4394  loss_dice: 3.268  loss_ce_0: 0.6232  loss_mask_0: 0.4096  loss_dice_0: 3.442  loss_ce_1: 0.3829  loss_mask_1: 0.4364  loss_dice_1: 3.331  loss_ce_2: 0.3528  loss_mask_2: 0.4343  loss_dice_2: 3.293  loss_ce_3: 0.3513  loss_mask_3: 0.4374  loss_dice_3: 3.275  loss_ce_4: 0.3456  loss_mask_4: 0.435  loss_dice_4: 3.274  loss_ce_5: 0.3508  loss_mask_5: 0.436  loss_dice_5: 3.271  loss_ce_6: 0.3278  loss_mask_6: 0.4376  loss_dice_6: 3.278  loss_ce_7: 0.3281  loss_mask_7: 0.4378  loss_dice_7: 3.277  loss_ce_8: 0.344  loss_mask_8: 0.44  loss_dice_8: 3.273  time: 1.4197  data_time: 0.0693  lr: 7.8256e-06  max_mem: 21588M
[01/18 22:27:47] d2.utils.events INFO:  eta: 12:15:16  iter: 9559  total_loss: 41.37  loss_ce: 0.3302  loss_mask: 0.4364  loss_dice: 3.293  loss_ce_0: 0.5851  loss_mask_0: 0.412  loss_dice_0: 3.458  loss_ce_1: 0.3322  loss_mask_1: 0.4406  loss_dice_1: 3.339  loss_ce_2: 0.3208  loss_mask_2: 0.4378  loss_dice_2: 3.32  loss_ce_3: 0.3265  loss_mask_3: 0.4357  loss_dice_3: 3.312  loss_ce_4: 0.3315  loss_mask_4: 0.4356  loss_dice_4: 3.312  loss_ce_5: 0.329  loss_mask_5: 0.4358  loss_dice_5: 3.298  loss_ce_6: 0.3173  loss_mask_6: 0.4349  loss_dice_6: 3.313  loss_ce_7: 0.3361  loss_mask_7: 0.4352  loss_dice_7: 3.299  loss_ce_8: 0.3233  loss_mask_8: 0.4346  loss_dice_8: 3.296  time: 1.4198  data_time: 0.0669  lr: 7.8209e-06  max_mem: 21588M
[01/18 22:28:17] d2.utils.events INFO:  eta: 12:15:14  iter: 9579  total_loss: 41.21  loss_ce: 0.3501  loss_mask: 0.4457  loss_dice: 3.281  loss_ce_0: 0.5707  loss_mask_0: 0.4189  loss_dice_0: 3.446  loss_ce_1: 0.3546  loss_mask_1: 0.4466  loss_dice_1: 3.325  loss_ce_2: 0.3413  loss_mask_2: 0.4456  loss_dice_2: 3.297  loss_ce_3: 0.3296  loss_mask_3: 0.4461  loss_dice_3: 3.284  loss_ce_4: 0.3406  loss_mask_4: 0.4452  loss_dice_4: 3.289  loss_ce_5: 0.3336  loss_mask_5: 0.4459  loss_dice_5: 3.278  loss_ce_6: 0.3445  loss_mask_6: 0.4445  loss_dice_6: 3.281  loss_ce_7: 0.3244  loss_mask_7: 0.4441  loss_dice_7: 3.282  loss_ce_8: 0.3317  loss_mask_8: 0.4447  loss_dice_8: 3.273  time: 1.4199  data_time: 0.0616  lr: 7.8163e-06  max_mem: 21588M
[01/18 22:28:46] d2.utils.events INFO:  eta: 12:14:50  iter: 9599  total_loss: 41.63  loss_ce: 0.3427  loss_mask: 0.4565  loss_dice: 3.297  loss_ce_0: 0.619  loss_mask_0: 0.4288  loss_dice_0: 3.451  loss_ce_1: 0.3453  loss_mask_1: 0.4619  loss_dice_1: 3.349  loss_ce_2: 0.3337  loss_mask_2: 0.4597  loss_dice_2: 3.317  loss_ce_3: 0.3111  loss_mask_3: 0.459  loss_dice_3: 3.305  loss_ce_4: 0.354  loss_mask_4: 0.4601  loss_dice_4: 3.302  loss_ce_5: 0.3386  loss_mask_5: 0.4587  loss_dice_5: 3.296  loss_ce_6: 0.3315  loss_mask_6: 0.4585  loss_dice_6: 3.303  loss_ce_7: 0.3533  loss_mask_7: 0.4573  loss_dice_7: 3.303  loss_ce_8: 0.3515  loss_mask_8: 0.4563  loss_dice_8: 3.302  time: 1.4200  data_time: 0.0653  lr: 7.8117e-06  max_mem: 21588M
[01/18 22:29:16] d2.utils.events INFO:  eta: 12:14:29  iter: 9619  total_loss: 41.59  loss_ce: 0.339  loss_mask: 0.4451  loss_dice: 3.34  loss_ce_0: 0.6038  loss_mask_0: 0.4264  loss_dice_0: 3.49  loss_ce_1: 0.3469  loss_mask_1: 0.4491  loss_dice_1: 3.38  loss_ce_2: 0.3384  loss_mask_2: 0.4463  loss_dice_2: 3.364  loss_ce_3: 0.344  loss_mask_3: 0.4454  loss_dice_3: 3.347  loss_ce_4: 0.3319  loss_mask_4: 0.4468  loss_dice_4: 3.346  loss_ce_5: 0.343  loss_mask_5: 0.446  loss_dice_5: 3.35  loss_ce_6: 0.3379  loss_mask_6: 0.4468  loss_dice_6: 3.346  loss_ce_7: 0.341  loss_mask_7: 0.447  loss_dice_7: 3.341  loss_ce_8: 0.3504  loss_mask_8: 0.4445  loss_dice_8: 3.34  time: 1.4201  data_time: 0.0623  lr: 7.8071e-06  max_mem: 21588M
[01/18 22:29:45] d2.utils.events INFO:  eta: 12:14:03  iter: 9639  total_loss: 41.57  loss_ce: 0.3519  loss_mask: 0.4388  loss_dice: 3.321  loss_ce_0: 0.6205  loss_mask_0: 0.4201  loss_dice_0: 3.489  loss_ce_1: 0.361  loss_mask_1: 0.4402  loss_dice_1: 3.378  loss_ce_2: 0.35  loss_mask_2: 0.4399  loss_dice_2: 3.352  loss_ce_3: 0.3303  loss_mask_3: 0.4394  loss_dice_3: 3.335  loss_ce_4: 0.3377  loss_mask_4: 0.4359  loss_dice_4: 3.338  loss_ce_5: 0.3602  loss_mask_5: 0.4366  loss_dice_5: 3.339  loss_ce_6: 0.352  loss_mask_6: 0.4384  loss_dice_6: 3.336  loss_ce_7: 0.3446  loss_mask_7: 0.437  loss_dice_7: 3.332  loss_ce_8: 0.3492  loss_mask_8: 0.4362  loss_dice_8: 3.324  time: 1.4201  data_time: 0.0596  lr: 7.8024e-06  max_mem: 21588M
[01/18 22:30:14] d2.utils.events INFO:  eta: 12:13:45  iter: 9659  total_loss: 40.86  loss_ce: 0.3273  loss_mask: 0.4546  loss_dice: 3.265  loss_ce_0: 0.5943  loss_mask_0: 0.4282  loss_dice_0: 3.428  loss_ce_1: 0.3603  loss_mask_1: 0.4609  loss_dice_1: 3.304  loss_ce_2: 0.3518  loss_mask_2: 0.4593  loss_dice_2: 3.275  loss_ce_3: 0.3425  loss_mask_3: 0.4524  loss_dice_3: 3.276  loss_ce_4: 0.3554  loss_mask_4: 0.4525  loss_dice_4: 3.272  loss_ce_5: 0.34  loss_mask_5: 0.4549  loss_dice_5: 3.262  loss_ce_6: 0.3505  loss_mask_6: 0.4569  loss_dice_6: 3.267  loss_ce_7: 0.348  loss_mask_7: 0.4531  loss_dice_7: 3.268  loss_ce_8: 0.3362  loss_mask_8: 0.4543  loss_dice_8: 3.259  time: 1.4202  data_time: 0.0600  lr: 7.7978e-06  max_mem: 21588M
[01/18 22:30:42] d2.utils.events INFO:  eta: 12:12:49  iter: 9679  total_loss: 41.28  loss_ce: 0.3293  loss_mask: 0.4384  loss_dice: 3.322  loss_ce_0: 0.6265  loss_mask_0: 0.4159  loss_dice_0: 3.472  loss_ce_1: 0.3485  loss_mask_1: 0.4465  loss_dice_1: 3.351  loss_ce_2: 0.3462  loss_mask_2: 0.4445  loss_dice_2: 3.319  loss_ce_3: 0.3267  loss_mask_3: 0.4416  loss_dice_3: 3.319  loss_ce_4: 0.338  loss_mask_4: 0.4401  loss_dice_4: 3.318  loss_ce_5: 0.3304  loss_mask_5: 0.4407  loss_dice_5: 3.315  loss_ce_6: 0.334  loss_mask_6: 0.4392  loss_dice_6: 3.316  loss_ce_7: 0.3287  loss_mask_7: 0.4381  loss_dice_7: 3.309  loss_ce_8: 0.331  loss_mask_8: 0.4384  loss_dice_8: 3.305  time: 1.4202  data_time: 0.0615  lr: 7.7932e-06  max_mem: 21588M
[01/18 22:31:10] d2.utils.events INFO:  eta: 12:12:23  iter: 9699  total_loss: 41.49  loss_ce: 0.3303  loss_mask: 0.4452  loss_dice: 3.315  loss_ce_0: 0.6072  loss_mask_0: 0.4211  loss_dice_0: 3.477  loss_ce_1: 0.3641  loss_mask_1: 0.4431  loss_dice_1: 3.362  loss_ce_2: 0.3577  loss_mask_2: 0.4427  loss_dice_2: 3.326  loss_ce_3: 0.3353  loss_mask_3: 0.4432  loss_dice_3: 3.321  loss_ce_4: 0.3319  loss_mask_4: 0.4429  loss_dice_4: 3.31  loss_ce_5: 0.3415  loss_mask_5: 0.4444  loss_dice_5: 3.316  loss_ce_6: 0.3267  loss_mask_6: 0.4425  loss_dice_6: 3.31  loss_ce_7: 0.3335  loss_mask_7: 0.445  loss_dice_7: 3.32  loss_ce_8: 0.3389  loss_mask_8: 0.4446  loss_dice_8: 3.312  time: 1.4202  data_time: 0.0546  lr: 7.7886e-06  max_mem: 21588M
[01/18 22:31:38] d2.utils.events INFO:  eta: 12:11:53  iter: 9719  total_loss: 41.43  loss_ce: 0.3465  loss_mask: 0.4194  loss_dice: 3.313  loss_ce_0: 0.6229  loss_mask_0: 0.4066  loss_dice_0: 3.48  loss_ce_1: 0.3514  loss_mask_1: 0.424  loss_dice_1: 3.352  loss_ce_2: 0.3468  loss_mask_2: 0.4211  loss_dice_2: 3.321  loss_ce_3: 0.3297  loss_mask_3: 0.4205  loss_dice_3: 3.311  loss_ce_4: 0.3452  loss_mask_4: 0.4203  loss_dice_4: 3.309  loss_ce_5: 0.3354  loss_mask_5: 0.4182  loss_dice_5: 3.314  loss_ce_6: 0.3376  loss_mask_6: 0.4189  loss_dice_6: 3.319  loss_ce_7: 0.3394  loss_mask_7: 0.4207  loss_dice_7: 3.31  loss_ce_8: 0.3359  loss_mask_8: 0.422  loss_dice_8: 3.308  time: 1.4201  data_time: 0.0602  lr: 7.7839e-06  max_mem: 21588M
[01/18 22:32:07] d2.utils.events INFO:  eta: 12:11:13  iter: 9739  total_loss: 41.2  loss_ce: 0.3352  loss_mask: 0.4355  loss_dice: 3.279  loss_ce_0: 0.6018  loss_mask_0: 0.4147  loss_dice_0: 3.449  loss_ce_1: 0.345  loss_mask_1: 0.4401  loss_dice_1: 3.328  loss_ce_2: 0.3476  loss_mask_2: 0.438  loss_dice_2: 3.307  loss_ce_3: 0.3334  loss_mask_3: 0.4366  loss_dice_3: 3.302  loss_ce_4: 0.3458  loss_mask_4: 0.4356  loss_dice_4: 3.287  loss_ce_5: 0.3429  loss_mask_5: 0.4341  loss_dice_5: 3.291  loss_ce_6: 0.338  loss_mask_6: 0.4358  loss_dice_6: 3.278  loss_ce_7: 0.3307  loss_mask_7: 0.4366  loss_dice_7: 3.287  loss_ce_8: 0.3235  loss_mask_8: 0.4353  loss_dice_8: 3.283  time: 1.4201  data_time: 0.0554  lr: 7.7793e-06  max_mem: 21588M
[01/18 22:32:36] d2.utils.events INFO:  eta: 12:10:48  iter: 9759  total_loss: 41.77  loss_ce: 0.3731  loss_mask: 0.4412  loss_dice: 3.291  loss_ce_0: 0.6295  loss_mask_0: 0.4177  loss_dice_0: 3.45  loss_ce_1: 0.3694  loss_mask_1: 0.4469  loss_dice_1: 3.333  loss_ce_2: 0.3872  loss_mask_2: 0.4484  loss_dice_2: 3.305  loss_ce_3: 0.3601  loss_mask_3: 0.4458  loss_dice_3: 3.295  loss_ce_4: 0.3556  loss_mask_4: 0.4454  loss_dice_4: 3.292  loss_ce_5: 0.3621  loss_mask_5: 0.445  loss_dice_5: 3.295  loss_ce_6: 0.356  loss_mask_6: 0.4427  loss_dice_6: 3.3  loss_ce_7: 0.3493  loss_mask_7: 0.4409  loss_dice_7: 3.301  loss_ce_8: 0.3545  loss_mask_8: 0.4419  loss_dice_8: 3.295  time: 1.4202  data_time: 0.0667  lr: 7.7747e-06  max_mem: 21588M
[01/18 22:33:05] d2.utils.events INFO:  eta: 12:10:23  iter: 9779  total_loss: 41.25  loss_ce: 0.3579  loss_mask: 0.4477  loss_dice: 3.281  loss_ce_0: 0.6208  loss_mask_0: 0.4205  loss_dice_0: 3.456  loss_ce_1: 0.3587  loss_mask_1: 0.4499  loss_dice_1: 3.332  loss_ce_2: 0.3548  loss_mask_2: 0.4477  loss_dice_2: 3.297  loss_ce_3: 0.3246  loss_mask_3: 0.4477  loss_dice_3: 3.293  loss_ce_4: 0.3411  loss_mask_4: 0.4484  loss_dice_4: 3.29  loss_ce_5: 0.34  loss_mask_5: 0.4488  loss_dice_5: 3.281  loss_ce_6: 0.3379  loss_mask_6: 0.4491  loss_dice_6: 3.285  loss_ce_7: 0.3432  loss_mask_7: 0.4472  loss_dice_7: 3.285  loss_ce_8: 0.348  loss_mask_8: 0.4502  loss_dice_8: 3.288  time: 1.4203  data_time: 0.0613  lr: 7.7701e-06  max_mem: 21588M
[01/18 22:33:34] d2.utils.events INFO:  eta: 12:09:53  iter: 9799  total_loss: 41  loss_ce: 0.3256  loss_mask: 0.4335  loss_dice: 3.243  loss_ce_0: 0.6229  loss_mask_0: 0.409  loss_dice_0: 3.41  loss_ce_1: 0.3681  loss_mask_1: 0.4347  loss_dice_1: 3.294  loss_ce_2: 0.3525  loss_mask_2: 0.4374  loss_dice_2: 3.267  loss_ce_3: 0.3294  loss_mask_3: 0.4365  loss_dice_3: 3.248  loss_ce_4: 0.3321  loss_mask_4: 0.4356  loss_dice_4: 3.252  loss_ce_5: 0.3255  loss_mask_5: 0.4349  loss_dice_5: 3.255  loss_ce_6: 0.3367  loss_mask_6: 0.4344  loss_dice_6: 3.243  loss_ce_7: 0.3212  loss_mask_7: 0.4335  loss_dice_7: 3.248  loss_ce_8: 0.3408  loss_mask_8: 0.4316  loss_dice_8: 3.244  time: 1.4203  data_time: 0.0656  lr: 7.7654e-06  max_mem: 21588M
[01/18 22:34:03] d2.utils.events INFO:  eta: 12:09:25  iter: 9819  total_loss: 40.77  loss_ce: 0.3235  loss_mask: 0.4268  loss_dice: 3.267  loss_ce_0: 0.5767  loss_mask_0: 0.3984  loss_dice_0: 3.463  loss_ce_1: 0.3238  loss_mask_1: 0.4285  loss_dice_1: 3.316  loss_ce_2: 0.3173  loss_mask_2: 0.4294  loss_dice_2: 3.29  loss_ce_3: 0.3211  loss_mask_3: 0.4264  loss_dice_3: 3.273  loss_ce_4: 0.3089  loss_mask_4: 0.4287  loss_dice_4: 3.279  loss_ce_5: 0.3119  loss_mask_5: 0.4281  loss_dice_5: 3.269  loss_ce_6: 0.3121  loss_mask_6: 0.428  loss_dice_6: 3.265  loss_ce_7: 0.3201  loss_mask_7: 0.4285  loss_dice_7: 3.267  loss_ce_8: 0.3213  loss_mask_8: 0.4277  loss_dice_8: 3.263  time: 1.4204  data_time: 0.0589  lr: 7.7608e-06  max_mem: 21588M
[01/18 22:34:33] d2.utils.events INFO:  eta: 12:08:55  iter: 9839  total_loss: 40.25  loss_ce: 0.3214  loss_mask: 0.4357  loss_dice: 3.221  loss_ce_0: 0.6338  loss_mask_0: 0.4077  loss_dice_0: 3.407  loss_ce_1: 0.3521  loss_mask_1: 0.4298  loss_dice_1: 3.26  loss_ce_2: 0.3328  loss_mask_2: 0.4302  loss_dice_2: 3.247  loss_ce_3: 0.3347  loss_mask_3: 0.4334  loss_dice_3: 3.235  loss_ce_4: 0.3212  loss_mask_4: 0.4336  loss_dice_4: 3.232  loss_ce_5: 0.3266  loss_mask_5: 0.432  loss_dice_5: 3.227  loss_ce_6: 0.3156  loss_mask_6: 0.4329  loss_dice_6: 3.226  loss_ce_7: 0.3183  loss_mask_7: 0.4353  loss_dice_7: 3.226  loss_ce_8: 0.3154  loss_mask_8: 0.4333  loss_dice_8: 3.225  time: 1.4205  data_time: 0.0735  lr: 7.7562e-06  max_mem: 21588M
[01/18 22:35:01] d2.utils.events INFO:  eta: 12:08:20  iter: 9859  total_loss: 40.17  loss_ce: 0.3154  loss_mask: 0.4471  loss_dice: 3.22  loss_ce_0: 0.5759  loss_mask_0: 0.4143  loss_dice_0: 3.398  loss_ce_1: 0.3379  loss_mask_1: 0.4428  loss_dice_1: 3.266  loss_ce_2: 0.3265  loss_mask_2: 0.4463  loss_dice_2: 3.234  loss_ce_3: 0.305  loss_mask_3: 0.447  loss_dice_3: 3.237  loss_ce_4: 0.3157  loss_mask_4: 0.4473  loss_dice_4: 3.231  loss_ce_5: 0.3257  loss_mask_5: 0.4453  loss_dice_5: 3.216  loss_ce_6: 0.3104  loss_mask_6: 0.447  loss_dice_6: 3.223  loss_ce_7: 0.3137  loss_mask_7: 0.4452  loss_dice_7: 3.227  loss_ce_8: 0.3053  loss_mask_8: 0.4456  loss_dice_8: 3.23  time: 1.4205  data_time: 0.0609  lr: 7.7515e-06  max_mem: 21588M
[01/18 22:35:30] d2.utils.events INFO:  eta: 12:07:35  iter: 9879  total_loss: 40.64  loss_ce: 0.3067  loss_mask: 0.4518  loss_dice: 3.266  loss_ce_0: 0.586  loss_mask_0: 0.4129  loss_dice_0: 3.425  loss_ce_1: 0.3155  loss_mask_1: 0.4454  loss_dice_1: 3.316  loss_ce_2: 0.3326  loss_mask_2: 0.4496  loss_dice_2: 3.283  loss_ce_3: 0.3184  loss_mask_3: 0.4484  loss_dice_3: 3.268  loss_ce_4: 0.3117  loss_mask_4: 0.4499  loss_dice_4: 3.266  loss_ce_5: 0.3187  loss_mask_5: 0.4487  loss_dice_5: 3.273  loss_ce_6: 0.3064  loss_mask_6: 0.4492  loss_dice_6: 3.275  loss_ce_7: 0.3161  loss_mask_7: 0.45  loss_dice_7: 3.268  loss_ce_8: 0.3113  loss_mask_8: 0.4485  loss_dice_8: 3.262  time: 1.4206  data_time: 0.0613  lr: 7.7469e-06  max_mem: 21588M
[01/18 22:36:00] d2.utils.events INFO:  eta: 12:07:28  iter: 9899  total_loss: 40.71  loss_ce: 0.3078  loss_mask: 0.4319  loss_dice: 3.238  loss_ce_0: 0.576  loss_mask_0: 0.402  loss_dice_0: 3.394  loss_ce_1: 0.3391  loss_mask_1: 0.4321  loss_dice_1: 3.276  loss_ce_2: 0.32  loss_mask_2: 0.4328  loss_dice_2: 3.244  loss_ce_3: 0.3263  loss_mask_3: 0.4339  loss_dice_3: 3.241  loss_ce_4: 0.334  loss_mask_4: 0.4319  loss_dice_4: 3.239  loss_ce_5: 0.3179  loss_mask_5: 0.4333  loss_dice_5: 3.236  loss_ce_6: 0.3168  loss_mask_6: 0.4329  loss_dice_6: 3.235  loss_ce_7: 0.3269  loss_mask_7: 0.4334  loss_dice_7: 3.231  loss_ce_8: 0.3235  loss_mask_8: 0.4321  loss_dice_8: 3.233  time: 1.4206  data_time: 0.0603  lr: 7.7423e-06  max_mem: 21588M
[01/18 22:36:29] d2.utils.events INFO:  eta: 12:07:43  iter: 9919  total_loss: 40.4  loss_ce: 0.3169  loss_mask: 0.424  loss_dice: 3.218  loss_ce_0: 0.5898  loss_mask_0: 0.3953  loss_dice_0: 3.391  loss_ce_1: 0.344  loss_mask_1: 0.4187  loss_dice_1: 3.258  loss_ce_2: 0.3345  loss_mask_2: 0.4207  loss_dice_2: 3.244  loss_ce_3: 0.3344  loss_mask_3: 0.4224  loss_dice_3: 3.221  loss_ce_4: 0.33  loss_mask_4: 0.4212  loss_dice_4: 3.22  loss_ce_5: 0.3278  loss_mask_5: 0.4208  loss_dice_5: 3.223  loss_ce_6: 0.3201  loss_mask_6: 0.4215  loss_dice_6: 3.229  loss_ce_7: 0.311  loss_mask_7: 0.4218  loss_dice_7: 3.234  loss_ce_8: 0.3185  loss_mask_8: 0.424  loss_dice_8: 3.225  time: 1.4207  data_time: 0.0614  lr: 7.7376e-06  max_mem: 21588M
[01/18 22:36:58] d2.utils.events INFO:  eta: 12:07:41  iter: 9939  total_loss: 40.98  loss_ce: 0.3354  loss_mask: 0.4279  loss_dice: 3.261  loss_ce_0: 0.604  loss_mask_0: 0.4117  loss_dice_0: 3.42  loss_ce_1: 0.3524  loss_mask_1: 0.4363  loss_dice_1: 3.311  loss_ce_2: 0.3475  loss_mask_2: 0.4342  loss_dice_2: 3.277  loss_ce_3: 0.3326  loss_mask_3: 0.4292  loss_dice_3: 3.266  loss_ce_4: 0.3486  loss_mask_4: 0.4293  loss_dice_4: 3.266  loss_ce_5: 0.35  loss_mask_5: 0.4294  loss_dice_5: 3.26  loss_ce_6: 0.3467  loss_mask_6: 0.4262  loss_dice_6: 3.261  loss_ce_7: 0.3415  loss_mask_7: 0.4273  loss_dice_7: 3.262  loss_ce_8: 0.3482  loss_mask_8: 0.4263  loss_dice_8: 3.267  time: 1.4208  data_time: 0.0617  lr: 7.733e-06  max_mem: 21588M
[01/18 22:37:27] d2.utils.events INFO:  eta: 12:06:33  iter: 9959  total_loss: 40.61  loss_ce: 0.3355  loss_mask: 0.4339  loss_dice: 3.22  loss_ce_0: 0.5817  loss_mask_0: 0.4135  loss_dice_0: 3.403  loss_ce_1: 0.3386  loss_mask_1: 0.4409  loss_dice_1: 3.27  loss_ce_2: 0.3397  loss_mask_2: 0.4385  loss_dice_2: 3.241  loss_ce_3: 0.3244  loss_mask_3: 0.4358  loss_dice_3: 3.228  loss_ce_4: 0.3328  loss_mask_4: 0.4359  loss_dice_4: 3.222  loss_ce_5: 0.3219  loss_mask_5: 0.4336  loss_dice_5: 3.228  loss_ce_6: 0.326  loss_mask_6: 0.4332  loss_dice_6: 3.231  loss_ce_7: 0.3267  loss_mask_7: 0.4335  loss_dice_7: 3.234  loss_ce_8: 0.3352  loss_mask_8: 0.4339  loss_dice_8: 3.23  time: 1.4208  data_time: 0.0686  lr: 7.7284e-06  max_mem: 21588M
[01/18 22:37:56] d2.utils.events INFO:  eta: 12:05:59  iter: 9979  total_loss: 41.24  loss_ce: 0.3444  loss_mask: 0.4248  loss_dice: 3.281  loss_ce_0: 0.6491  loss_mask_0: 0.4031  loss_dice_0: 3.452  loss_ce_1: 0.3775  loss_mask_1: 0.4245  loss_dice_1: 3.315  loss_ce_2: 0.3659  loss_mask_2: 0.4241  loss_dice_2: 3.296  loss_ce_3: 0.3634  loss_mask_3: 0.4252  loss_dice_3: 3.279  loss_ce_4: 0.3656  loss_mask_4: 0.4235  loss_dice_4: 3.279  loss_ce_5: 0.361  loss_mask_5: 0.4233  loss_dice_5: 3.277  loss_ce_6: 0.3638  loss_mask_6: 0.4248  loss_dice_6: 3.276  loss_ce_7: 0.3601  loss_mask_7: 0.4272  loss_dice_7: 3.283  loss_ce_8: 0.3587  loss_mask_8: 0.4258  loss_dice_8: 3.283  time: 1.4209  data_time: 0.0648  lr: 7.7238e-06  max_mem: 21588M
[01/18 22:38:25] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/sceneflow_testing/model_0009999.pth
[01/18 22:38:26] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: None
[01/18 22:38:27] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/18 22:38:27] d2.data.common INFO: Serialized dataset takes 1.50 MiB
[01/18 22:44:59] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 2.5733612357959452, 'error_1pix': 0.19538599656047417, 'error_3pix': 0.09622274961135227, 'mIoU': 15.996329688399328, 'fwIoU': 36.44315291342571, 'IoU-0': nan, 'IoU-1': 94.49980428894666, 'IoU-2': 45.480006394783416, 'IoU-3': 54.89306707107829, 'IoU-4': 48.82379336567041, 'IoU-5': 41.05110685609516, 'IoU-6': 37.76975222416902, 'IoU-7': 29.971461336787424, 'IoU-8': 18.46589481457852, 'IoU-9': 31.80120420640986, 'IoU-10': 31.810788333399167, 'IoU-11': 43.36399981867711, 'IoU-12': 42.599757915535065, 'IoU-13': 39.57307508987614, 'IoU-14': 40.07503839456687, 'IoU-15': 38.81093055892693, 'IoU-16': 30.581761868143438, 'IoU-17': 28.405622417158742, 'IoU-18': 31.26073384790409, 'IoU-19': 34.629650661727766, 'IoU-20': 37.49855011375086, 'IoU-21': 35.62537199265966, 'IoU-22': 41.28123194392069, 'IoU-23': 37.43270522399344, 'IoU-24': 39.46001096660015, 'IoU-25': 38.24553697218575, 'IoU-26': 37.702098536296916, 'IoU-27': 39.5918308447166, 'IoU-28': 38.36790204344113, 'IoU-29': 38.359213561482605, 'IoU-30': 36.54114739590158, 'IoU-31': 40.41628065859169, 'IoU-32': 38.89923509582698, 'IoU-33': 36.528497394405626, 'IoU-34': 37.81374454774839, 'IoU-35': 37.40578658074534, 'IoU-36': 37.910209354961296, 'IoU-37': 35.333716845472345, 'IoU-38': 35.67975565650001, 'IoU-39': 35.369962688711425, 'IoU-40': 35.97150832565087, 'IoU-41': 32.97061844984286, 'IoU-42': 33.22129126091497, 'IoU-43': 31.993448842035527, 'IoU-44': 32.39739523720472, 'IoU-45': 30.970083389404877, 'IoU-46': 31.087616342161695, 'IoU-47': 29.48310496504399, 'IoU-48': 28.542888397434492, 'IoU-49': 29.23921168520251, 'IoU-50': 28.18849479892315, 'IoU-51': 28.405167331952235, 'IoU-52': 25.96868162567368, 'IoU-53': 27.91118463800833, 'IoU-54': 27.409131771787408, 'IoU-55': 26.042498940491367, 'IoU-56': 21.95682131541784, 'IoU-57': 19.85635934383104, 'IoU-58': 19.841427068263908, 'IoU-59': 19.32770936277859, 'IoU-60': 19.58770772951636, 'IoU-61': 19.121685891382516, 'IoU-62': 18.73582982409437, 'IoU-63': 19.096459346867732, 'IoU-64': 18.648451907466313, 'IoU-65': 19.705062779203057, 'IoU-66': 17.814467789132955, 'IoU-67': 18.449927645400326, 'IoU-68': 17.76990708083195, 'IoU-69': 18.771066689844183, 'IoU-70': 15.963348518136463, 'IoU-71': 15.794777308921704, 'IoU-72': 16.242933435930183, 'IoU-73': 15.594103462527434, 'IoU-74': 16.073328254533358, 'IoU-75': 16.114515164327567, 'IoU-76': 14.892643029391284, 'IoU-77': 14.361402082461463, 'IoU-78': 16.388386439053782, 'IoU-79': 12.596070387203168, 'IoU-80': 15.048445850346162, 'IoU-81': 15.297012512188745, 'IoU-82': 14.2276213222826, 'IoU-83': 14.554236838260767, 'IoU-84': 15.083104799062616, 'IoU-85': 14.042756379180807, 'IoU-86': 15.627132082454231, 'IoU-87': 11.140528763473652, 'IoU-88': 17.541389546526673, 'IoU-89': 12.227385879708654, 'IoU-90': 13.32492808498745, 'IoU-91': 14.674114598791121, 'IoU-92': 12.062422898410464, 'IoU-93': 10.628088696070078, 'IoU-94': 11.949708580948569, 'IoU-95': 12.800971548406025, 'IoU-96': 8.547946813961433, 'IoU-97': 15.04323614477153, 'IoU-98': 9.51239994200801, 'IoU-99': 12.753217106493764, 'IoU-100': 10.571876074945271, 'IoU-101': 11.591285846045823, 'IoU-102': 10.675540547426582, 'IoU-103': 11.260951496602805, 'IoU-104': 11.371842599288659, 'IoU-105': 9.041374009887265, 'IoU-106': 12.535164525283227, 'IoU-107': 7.584891396995941, 'IoU-108': 12.894056771952789, 'IoU-109': 8.93703334620354, 'IoU-110': 10.008094328498837, 'IoU-111': 9.917940749587869, 'IoU-112': 7.303278807918081, 'IoU-113': 10.031094940658692, 'IoU-114': 6.974153744719203, 'IoU-115': 7.800940470375009, 'IoU-116': 10.183635202149963, 'IoU-117': 9.751076798277685, 'IoU-118': 5.536748111814311, 'IoU-119': 6.483929844648125, 'IoU-120': 10.09082103033364, 'IoU-121': 8.399818863685146, 'IoU-122': 6.9273400893095, 'IoU-123': 2.872404053934916, 'IoU-124': 10.084640603311424, 'IoU-125': 4.106743260954845, 'IoU-126': 7.758662469104098, 'IoU-127': 6.634360399040283, 'IoU-128': 6.524939086166909, 'IoU-129': 4.000525235139554, 'IoU-130': 4.576327778840649, 'IoU-131': 6.303091405116014, 'IoU-132': 5.368782395002215, 'IoU-133': 5.481742815190555, 'IoU-134': 7.079784695442716, 'IoU-135': 3.6468966527284596, 'IoU-136': 5.02981342926649, 'IoU-137': 4.200255820493514, 'IoU-138': 1.9528070466917322, 'IoU-139': 3.682362231732269, 'IoU-140': 4.369346512110496, 'IoU-141': 4.0476390623237375, 'IoU-142': 4.984533019903646, 'IoU-143': 3.556174832502438, 'IoU-144': 3.631837305565803, 'IoU-145': 1.5901089753869886, 'IoU-146': 2.2885600771810113, 'IoU-147': 2.67192717101129, 'IoU-148': 2.1427275715723493, 'IoU-149': 1.1186118300021828, 'IoU-150': 2.345512843031434, 'IoU-151': 1.9870303829841403, 'IoU-152': 2.1660294741750343, 'IoU-153': 1.5869374407475625, 'IoU-154': 2.3344416315390775, 'IoU-155': 1.4451321372385857, 'IoU-156': 1.9005853521062395, 'IoU-157': 1.4871426124119773, 'IoU-158': 0.7705328389146697, 'IoU-159': 1.7293526152449463, 'IoU-160': 1.5920338772668925, 'IoU-161': 1.4044507830245494, 'IoU-162': 1.051359476659555, 'IoU-163': 1.5687940047378506, 'IoU-164': 3.3580161315667123, 'IoU-165': 0.8670859739137534, 'IoU-166': 1.539024008078135, 'IoU-167': 1.2130529776387236, 'IoU-168': 0.8023131821630953, 'IoU-169': 1.9327484672532411, 'IoU-170': 0.0, 'IoU-171': 0.31619561052311673, 'IoU-172': 1.8694551341718486, 'IoU-173': 1.122565864833906, 'IoU-174': 0.8472966396985538, 'IoU-175': 1.6394154121251927, 'IoU-176': 1.1401620646489448, 'IoU-177': 0.41979087274929133, 'IoU-178': 0.2834501067928219, 'IoU-179': 0.5558457909202119, 'IoU-180': 1.4934720600268963, 'IoU-181': 0.42619002119839833, 'IoU-182': 0.0, 'IoU-183': 0.4319995651125102, 'IoU-184': 0.013633393351605214, 'IoU-185': 0.0, 'IoU-186': 0.11171175798353856, 'IoU-187': 0.010958393079891349, 'IoU-188': 1.6029821235839903, 'IoU-189': 0.40379456260198576, 'IoU-190': 0.864331788585797, 'IoU-191': 1.0155534360156007, 'IoU-192': 0.14281990271607403, 'mACC': 25.0360199128761, 'pACC': 50.27718430782181, 'ACC-0': nan, 'ACC-1': 98.46243343447381, 'ACC-2': 61.96226717905026, 'ACC-3': 68.753740603719, 'ACC-4': 65.9488532820552, 'ACC-5': 57.384205301723526, 'ACC-6': 56.47207749764158, 'ACC-7': 43.788719093093555, 'ACC-8': 23.461885678689093, 'ACC-9': 47.50198758707855, 'ACC-10': 44.93672314411787, 'ACC-11': 59.96675641628031, 'ACC-12': 59.076196037272844, 'ACC-13': 54.611364086487946, 'ACC-14': 56.57914394298006, 'ACC-15': 55.17936422419852, 'ACC-16': 51.86006722404848, 'ACC-17': 42.85184811883091, 'ACC-18': 48.178253452486146, 'ACC-19': 52.152637446878344, 'ACC-20': 54.56120785725265, 'ACC-21': 56.41553255179945, 'ACC-22': 59.477816893044846, 'ACC-23': 54.51887095981729, 'ACC-24': 57.90116776818013, 'ACC-25': 56.9735050247216, 'ACC-26': 56.9369357589064, 'ACC-27': 53.91733890238013, 'ACC-28': 55.87500141574354, 'ACC-29': 57.105984032679416, 'ACC-30': 49.37598867669323, 'ACC-31': 60.74236256226692, 'ACC-32': 55.91675242388081, 'ACC-33': 54.35121918529898, 'ACC-34': 54.002501412199, 'ACC-35': 50.94776601249157, 'ACC-36': 54.19480827244282, 'ACC-37': 49.83404413004235, 'ACC-38': 54.950380048454704, 'ACC-39': 50.299295158853376, 'ACC-40': 52.13476413687669, 'ACC-41': 49.35132520172775, 'ACC-42': 48.38335581846718, 'ACC-43': 48.13738483634261, 'ACC-44': 51.85414220428458, 'ACC-45': 47.1845269608651, 'ACC-46': 46.976919800576546, 'ACC-47': 46.68506372635201, 'ACC-48': 41.462551953295254, 'ACC-49': 44.84834899823352, 'ACC-50': 43.682048510503066, 'ACC-51': 45.87284124316078, 'ACC-52': 41.47295904608804, 'ACC-53': 46.92553511914528, 'ACC-54': 48.78438518940759, 'ACC-55': 44.18011133979965, 'ACC-56': 38.09066227310242, 'ACC-57': 31.775853282090427, 'ACC-58': 32.751428475643394, 'ACC-59': 29.93977745220041, 'ACC-60': 30.965432685825718, 'ACC-61': 33.47934540471815, 'ACC-62': 29.756153598645096, 'ACC-63': 31.60320629453699, 'ACC-64': 30.394911273742025, 'ACC-65': 31.568163799460603, 'ACC-66': 29.947208355086257, 'ACC-67': 30.348857311961314, 'ACC-68': 29.144208249998034, 'ACC-69': 30.698951672586038, 'ACC-70': 25.071314832002418, 'ACC-71': 26.36936733801678, 'ACC-72': 29.845596273142515, 'ACC-73': 24.559913973894275, 'ACC-74': 25.43932450042139, 'ACC-75': 31.418832221844873, 'ACC-76': 23.504739767148376, 'ACC-77': 23.517855337781768, 'ACC-78': 29.22826859293935, 'ACC-79': 20.600730686435586, 'ACC-80': 25.54519507463649, 'ACC-81': 29.290572919956077, 'ACC-82': 24.34671867999673, 'ACC-83': 28.151872676912472, 'ACC-84': 25.0500594702537, 'ACC-85': 23.412284002994067, 'ACC-86': 27.98131374189413, 'ACC-87': 18.178954163155325, 'ACC-88': 36.008690312232375, 'ACC-89': 22.005356566047297, 'ACC-90': 23.991519047231964, 'ACC-91': 27.927980642287004, 'ACC-92': 20.325240362499343, 'ACC-93': 17.925190828223883, 'ACC-94': 23.25493065337391, 'ACC-95': 26.69105263654936, 'ACC-96': 11.735310129163517, 'ACC-97': 28.169254741065007, 'ACC-98': 16.53562184712988, 'ACC-99': 22.548609348761616, 'ACC-100': 15.483433848519276, 'ACC-101': 19.486464249420965, 'ACC-102': 19.792115994562756, 'ACC-103': 20.366699726079155, 'ACC-104': 18.528294926342195, 'ACC-105': 15.283468405851435, 'ACC-106': 21.879084954466155, 'ACC-107': 11.619023841537974, 'ACC-108': 25.579955046764795, 'ACC-109': 14.06216733783805, 'ACC-110': 17.679979549369516, 'ACC-111': 16.082862381893904, 'ACC-112': 12.547020798257503, 'ACC-113': 19.83763942566941, 'ACC-114': 12.921479141558828, 'ACC-115': 16.776382060649798, 'ACC-116': 19.742183115308972, 'ACC-117': 22.334723910997674, 'ACC-118': 7.749390455628907, 'ACC-119': 9.676792605049801, 'ACC-120': 24.590093366645934, 'ACC-121': 17.170574307091982, 'ACC-122': 11.249115457556115, 'ACC-123': 4.469140602641962, 'ACC-124': 28.397512973462803, 'ACC-125': 5.642221842732414, 'ACC-126': 17.67866738312735, 'ACC-127': 13.992456241998335, 'ACC-128': 11.880847576080235, 'ACC-129': 5.314958529932057, 'ACC-130': 8.114424870305925, 'ACC-131': 11.234833486518692, 'ACC-132': 10.824796506854595, 'ACC-133': 10.041573958779862, 'ACC-134': 13.672382593709608, 'ACC-135': 7.665754517986431, 'ACC-136': 9.760674850913157, 'ACC-137': 7.774437364192344, 'ACC-138': 3.3283784298296824, 'ACC-139': 6.055488283283583, 'ACC-140': 6.853634416510543, 'ACC-141': 7.820644663959107, 'ACC-142': 13.481115853216554, 'ACC-143': 8.785976225071956, 'ACC-144': 7.241696750902527, 'ACC-145': 2.7937118450770364, 'ACC-146': 5.378264147494917, 'ACC-147': 4.181031641167967, 'ACC-148': 4.423739913749428, 'ACC-149': 1.8918554381082864, 'ACC-150': 5.080315068964332, 'ACC-151': 5.856015722335372, 'ACC-152': 3.7591037831276557, 'ACC-153': 3.049707763059052, 'ACC-154': 4.0634426366173635, 'ACC-155': 2.8554489810507735, 'ACC-156': 3.8709302100098895, 'ACC-157': 3.591780959886108, 'ACC-158': 1.5161929063680666, 'ACC-159': 3.478296619949133, 'ACC-160': 5.78470682712754, 'ACC-161': 4.447071841202886, 'ACC-162': 1.8921395651902255, 'ACC-163': 4.3591315367482615, 'ACC-164': 6.573143623616259, 'ACC-165': 1.3832993993526603, 'ACC-166': 2.819753044967305, 'ACC-167': 2.9715095706371915, 'ACC-168': 1.1284197200928336, 'ACC-169': 4.764929556951919, 'ACC-170': 0.0, 'ACC-171': 0.43955922844772954, 'ACC-172': 6.0073341482386935, 'ACC-173': 2.6090015917035743, 'ACC-174': 1.2138360911197228, 'ACC-175': 3.1426622220496636, 'ACC-176': 1.5430911887624796, 'ACC-177': 0.5143309545296003, 'ACC-178': 0.3565695919151805, 'ACC-179': 0.6950967880685196, 'ACC-180': 4.214500999017915, 'ACC-181': 0.45430751265452496, 'ACC-182': 0.0, 'ACC-183': 0.5987037111154535, 'ACC-184': 0.01367869684470198, 'ACC-185': 0.0, 'ACC-186': 0.12322568004286931, 'ACC-187': 0.01135553703233912, 'ACC-188': 4.457548121544732, 'ACC-189': 0.4872651281959124, 'ACC-190': 1.6409549660961882, 'ACC-191': 1.403458401305057, 'ACC-192': 0.14573918063451727})])
[01/18 22:44:59] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/18 22:44:59] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/18 22:44:59] d2.evaluation.testing INFO: copypaste: 2.5734,0.1954,0.0962,15.9963,36.4432,25.0360,50.2772
[01/18 22:44:59] d2.utils.events INFO:  eta: 12:05:30  iter: 9999  total_loss: 40.71  loss_ce: 0.3495  loss_mask: 0.4298  loss_dice: 3.255  loss_ce_0: 0.5798  loss_mask_0: 0.4065  loss_dice_0: 3.419  loss_ce_1: 0.3358  loss_mask_1: 0.4345  loss_dice_1: 3.292  loss_ce_2: 0.3551  loss_mask_2: 0.4307  loss_dice_2: 3.256  loss_ce_3: 0.3234  loss_mask_3: 0.4299  loss_dice_3: 3.264  loss_ce_4: 0.3386  loss_mask_4: 0.4292  loss_dice_4: 3.254  loss_ce_5: 0.3198  loss_mask_5: 0.4303  loss_dice_5: 3.254  loss_ce_6: 0.3288  loss_mask_6: 0.4308  loss_dice_6: 3.247  loss_ce_7: 0.3318  loss_mask_7: 0.4301  loss_dice_7: 3.254  loss_ce_8: 0.3316  loss_mask_8: 0.4301  loss_dice_8: 3.25  time: 1.4209  data_time: 0.0605  lr: 7.7191e-06  max_mem: 21588M
[01/18 22:45:28] d2.utils.events INFO:  eta: 12:05:27  iter: 10019  total_loss: 40.99  loss_ce: 0.317  loss_mask: 0.434  loss_dice: 3.256  loss_ce_0: 0.5967  loss_mask_0: 0.4055  loss_dice_0: 3.42  loss_ce_1: 0.3644  loss_mask_1: 0.4376  loss_dice_1: 3.302  loss_ce_2: 0.3566  loss_mask_2: 0.4323  loss_dice_2: 3.274  loss_ce_3: 0.3395  loss_mask_3: 0.4327  loss_dice_3: 3.261  loss_ce_4: 0.34  loss_mask_4: 0.4317  loss_dice_4: 3.262  loss_ce_5: 0.3239  loss_mask_5: 0.4312  loss_dice_5: 3.267  loss_ce_6: 0.3124  loss_mask_6: 0.4315  loss_dice_6: 3.259  loss_ce_7: 0.3302  loss_mask_7: 0.4321  loss_dice_7: 3.259  loss_ce_8: 0.3292  loss_mask_8: 0.4353  loss_dice_8: 3.257  time: 1.4210  data_time: 0.0647  lr: 7.7145e-06  max_mem: 21588M
[01/18 22:45:58] d2.utils.events INFO:  eta: 12:05:23  iter: 10039  total_loss: 40.89  loss_ce: 0.3271  loss_mask: 0.4289  loss_dice: 3.274  loss_ce_0: 0.5874  loss_mask_0: 0.4041  loss_dice_0: 3.444  loss_ce_1: 0.3419  loss_mask_1: 0.4319  loss_dice_1: 3.327  loss_ce_2: 0.3395  loss_mask_2: 0.4293  loss_dice_2: 3.292  loss_ce_3: 0.31  loss_mask_3: 0.4288  loss_dice_3: 3.287  loss_ce_4: 0.3205  loss_mask_4: 0.4314  loss_dice_4: 3.286  loss_ce_5: 0.3257  loss_mask_5: 0.4305  loss_dice_5: 3.278  loss_ce_6: 0.3196  loss_mask_6: 0.4304  loss_dice_6: 3.285  loss_ce_7: 0.3207  loss_mask_7: 0.4311  loss_dice_7: 3.279  loss_ce_8: 0.3177  loss_mask_8: 0.4298  loss_dice_8: 3.277  time: 1.4211  data_time: 0.0777  lr: 7.7099e-06  max_mem: 21588M
[01/18 22:46:28] d2.utils.events INFO:  eta: 12:05:11  iter: 10059  total_loss: 40.82  loss_ce: 0.333  loss_mask: 0.4415  loss_dice: 3.254  loss_ce_0: 0.5852  loss_mask_0: 0.4137  loss_dice_0: 3.422  loss_ce_1: 0.3614  loss_mask_1: 0.44  loss_dice_1: 3.302  loss_ce_2: 0.3499  loss_mask_2: 0.4397  loss_dice_2: 3.273  loss_ce_3: 0.3424  loss_mask_3: 0.4407  loss_dice_3: 3.272  loss_ce_4: 0.3446  loss_mask_4: 0.4406  loss_dice_4: 3.261  loss_ce_5: 0.348  loss_mask_5: 0.4425  loss_dice_5: 3.261  loss_ce_6: 0.3343  loss_mask_6: 0.4405  loss_dice_6: 3.266  loss_ce_7: 0.3374  loss_mask_7: 0.4406  loss_dice_7: 3.258  loss_ce_8: 0.3454  loss_mask_8: 0.4411  loss_dice_8: 3.259  time: 1.4213  data_time: 0.0781  lr: 7.7052e-06  max_mem: 21588M
[01/18 22:46:57] d2.utils.events INFO:  eta: 12:04:46  iter: 10079  total_loss: 40  loss_ce: 0.3494  loss_mask: 0.4215  loss_dice: 3.182  loss_ce_0: 0.6156  loss_mask_0: 0.3959  loss_dice_0: 3.357  loss_ce_1: 0.362  loss_mask_1: 0.4226  loss_dice_1: 3.226  loss_ce_2: 0.3411  loss_mask_2: 0.4231  loss_dice_2: 3.206  loss_ce_3: 0.3391  loss_mask_3: 0.4222  loss_dice_3: 3.202  loss_ce_4: 0.344  loss_mask_4: 0.4231  loss_dice_4: 3.191  loss_ce_5: 0.3398  loss_mask_5: 0.4239  loss_dice_5: 3.192  loss_ce_6: 0.334  loss_mask_6: 0.4222  loss_dice_6: 3.185  loss_ce_7: 0.3307  loss_mask_7: 0.4211  loss_dice_7: 3.185  loss_ce_8: 0.3365  loss_mask_8: 0.4218  loss_dice_8: 3.184  time: 1.4214  data_time: 0.0613  lr: 7.7006e-06  max_mem: 21588M
[01/18 22:47:27] d2.utils.events INFO:  eta: 12:04:52  iter: 10099  total_loss: 41.08  loss_ce: 0.3573  loss_mask: 0.4334  loss_dice: 3.252  loss_ce_0: 0.6122  loss_mask_0: 0.4101  loss_dice_0: 3.411  loss_ce_1: 0.3639  loss_mask_1: 0.4354  loss_dice_1: 3.3  loss_ce_2: 0.3631  loss_mask_2: 0.4334  loss_dice_2: 3.272  loss_ce_3: 0.3734  loss_mask_3: 0.4332  loss_dice_3: 3.261  loss_ce_4: 0.3432  loss_mask_4: 0.4332  loss_dice_4: 3.262  loss_ce_5: 0.34  loss_mask_5: 0.4344  loss_dice_5: 3.26  loss_ce_6: 0.353  loss_mask_6: 0.4323  loss_dice_6: 3.258  loss_ce_7: 0.3491  loss_mask_7: 0.4338  loss_dice_7: 3.262  loss_ce_8: 0.3425  loss_mask_8: 0.4327  loss_dice_8: 3.263  time: 1.4215  data_time: 0.0600  lr: 7.696e-06  max_mem: 21588M
[01/18 22:47:56] d2.utils.events INFO:  eta: 12:04:31  iter: 10119  total_loss: 41.73  loss_ce: 0.3811  loss_mask: 0.4334  loss_dice: 3.293  loss_ce_0: 0.6419  loss_mask_0: 0.4228  loss_dice_0: 3.441  loss_ce_1: 0.3669  loss_mask_1: 0.4433  loss_dice_1: 3.336  loss_ce_2: 0.373  loss_mask_2: 0.4374  loss_dice_2: 3.311  loss_ce_3: 0.3541  loss_mask_3: 0.4342  loss_dice_3: 3.307  loss_ce_4: 0.3561  loss_mask_4: 0.4363  loss_dice_4: 3.3  loss_ce_5: 0.3612  loss_mask_5: 0.4346  loss_dice_5: 3.3  loss_ce_6: 0.3609  loss_mask_6: 0.4374  loss_dice_6: 3.292  loss_ce_7: 0.352  loss_mask_7: 0.4351  loss_dice_7: 3.306  loss_ce_8: 0.354  loss_mask_8: 0.4341  loss_dice_8: 3.3  time: 1.4216  data_time: 0.0781  lr: 7.6913e-06  max_mem: 21588M
[01/18 22:48:25] d2.utils.events INFO:  eta: 12:03:59  iter: 10139  total_loss: 40.4  loss_ce: 0.3343  loss_mask: 0.4269  loss_dice: 3.25  loss_ce_0: 0.6046  loss_mask_0: 0.4077  loss_dice_0: 3.4  loss_ce_1: 0.3626  loss_mask_1: 0.4311  loss_dice_1: 3.277  loss_ce_2: 0.349  loss_mask_2: 0.4268  loss_dice_2: 3.249  loss_ce_3: 0.3343  loss_mask_3: 0.4277  loss_dice_3: 3.246  loss_ce_4: 0.3384  loss_mask_4: 0.4279  loss_dice_4: 3.243  loss_ce_5: 0.3201  loss_mask_5: 0.4274  loss_dice_5: 3.234  loss_ce_6: 0.3215  loss_mask_6: 0.4266  loss_dice_6: 3.243  loss_ce_7: 0.3224  loss_mask_7: 0.4274  loss_dice_7: 3.25  loss_ce_8: 0.3467  loss_mask_8: 0.4262  loss_dice_8: 3.239  time: 1.4216  data_time: 0.0659  lr: 7.6867e-06  max_mem: 21588M
[01/18 22:48:55] d2.utils.events INFO:  eta: 12:03:32  iter: 10159  total_loss: 40.5  loss_ce: 0.3041  loss_mask: 0.442  loss_dice: 3.236  loss_ce_0: 0.591  loss_mask_0: 0.4127  loss_dice_0: 3.409  loss_ce_1: 0.3403  loss_mask_1: 0.4433  loss_dice_1: 3.277  loss_ce_2: 0.3372  loss_mask_2: 0.443  loss_dice_2: 3.255  loss_ce_3: 0.3201  loss_mask_3: 0.4389  loss_dice_3: 3.246  loss_ce_4: 0.3094  loss_mask_4: 0.439  loss_dice_4: 3.244  loss_ce_5: 0.3092  loss_mask_5: 0.4415  loss_dice_5: 3.234  loss_ce_6: 0.3055  loss_mask_6: 0.4432  loss_dice_6: 3.239  loss_ce_7: 0.31  loss_mask_7: 0.441  loss_dice_7: 3.234  loss_ce_8: 0.3058  loss_mask_8: 0.4413  loss_dice_8: 3.234  time: 1.4217  data_time: 0.0669  lr: 7.6821e-06  max_mem: 21588M
[01/18 22:49:25] d2.utils.events INFO:  eta: 12:03:01  iter: 10179  total_loss: 41.85  loss_ce: 0.3398  loss_mask: 0.4257  loss_dice: 3.262  loss_ce_0: 0.6288  loss_mask_0: 0.409  loss_dice_0: 3.434  loss_ce_1: 0.3671  loss_mask_1: 0.434  loss_dice_1: 3.311  loss_ce_2: 0.3617  loss_mask_2: 0.4302  loss_dice_2: 3.277  loss_ce_3: 0.3617  loss_mask_3: 0.43  loss_dice_3: 3.259  loss_ce_4: 0.355  loss_mask_4: 0.4274  loss_dice_4: 3.267  loss_ce_5: 0.3437  loss_mask_5: 0.4279  loss_dice_5: 3.275  loss_ce_6: 0.341  loss_mask_6: 0.4274  loss_dice_6: 3.267  loss_ce_7: 0.34  loss_mask_7: 0.4269  loss_dice_7: 3.264  loss_ce_8: 0.36  loss_mask_8: 0.4273  loss_dice_8: 3.265  time: 1.4218  data_time: 0.0639  lr: 7.6774e-06  max_mem: 21588M
[01/18 22:49:54] d2.utils.events INFO:  eta: 12:02:32  iter: 10199  total_loss: 40.24  loss_ce: 0.368  loss_mask: 0.4307  loss_dice: 3.211  loss_ce_0: 0.6252  loss_mask_0: 0.4079  loss_dice_0: 3.365  loss_ce_1: 0.3699  loss_mask_1: 0.4339  loss_dice_1: 3.25  loss_ce_2: 0.376  loss_mask_2: 0.4273  loss_dice_2: 3.224  loss_ce_3: 0.3642  loss_mask_3: 0.43  loss_dice_3: 3.211  loss_ce_4: 0.379  loss_mask_4: 0.4294  loss_dice_4: 3.213  loss_ce_5: 0.3522  loss_mask_5: 0.43  loss_dice_5: 3.218  loss_ce_6: 0.3542  loss_mask_6: 0.4309  loss_dice_6: 3.212  loss_ce_7: 0.3496  loss_mask_7: 0.4289  loss_dice_7: 3.208  loss_ce_8: 0.359  loss_mask_8: 0.4311  loss_dice_8: 3.214  time: 1.4219  data_time: 0.0581  lr: 7.6728e-06  max_mem: 21588M
[01/18 22:50:24] d2.utils.events INFO:  eta: 12:02:09  iter: 10219  total_loss: 40.62  loss_ce: 0.3377  loss_mask: 0.4291  loss_dice: 3.245  loss_ce_0: 0.5852  loss_mask_0: 0.4045  loss_dice_0: 3.396  loss_ce_1: 0.346  loss_mask_1: 0.4367  loss_dice_1: 3.287  loss_ce_2: 0.3423  loss_mask_2: 0.4335  loss_dice_2: 3.262  loss_ce_3: 0.3317  loss_mask_3: 0.4357  loss_dice_3: 3.255  loss_ce_4: 0.3391  loss_mask_4: 0.4315  loss_dice_4: 3.25  loss_ce_5: 0.3388  loss_mask_5: 0.429  loss_dice_5: 3.241  loss_ce_6: 0.3327  loss_mask_6: 0.429  loss_dice_6: 3.244  loss_ce_7: 0.345  loss_mask_7: 0.4267  loss_dice_7: 3.254  loss_ce_8: 0.3293  loss_mask_8: 0.4276  loss_dice_8: 3.245  time: 1.4220  data_time: 0.0691  lr: 7.6682e-06  max_mem: 21588M
[01/18 22:50:53] d2.utils.events INFO:  eta: 12:01:41  iter: 10239  total_loss: 41.2  loss_ce: 0.3541  loss_mask: 0.4173  loss_dice: 3.284  loss_ce_0: 0.5972  loss_mask_0: 0.4063  loss_dice_0: 3.436  loss_ce_1: 0.3575  loss_mask_1: 0.4275  loss_dice_1: 3.328  loss_ce_2: 0.3415  loss_mask_2: 0.422  loss_dice_2: 3.299  loss_ce_3: 0.3592  loss_mask_3: 0.4199  loss_dice_3: 3.289  loss_ce_4: 0.3582  loss_mask_4: 0.4202  loss_dice_4: 3.283  loss_ce_5: 0.3395  loss_mask_5: 0.4209  loss_dice_5: 3.285  loss_ce_6: 0.3549  loss_mask_6: 0.4169  loss_dice_6: 3.292  loss_ce_7: 0.3415  loss_mask_7: 0.418  loss_dice_7: 3.282  loss_ce_8: 0.3526  loss_mask_8: 0.4185  loss_dice_8: 3.285  time: 1.4221  data_time: 0.0632  lr: 7.6635e-06  max_mem: 21588M
[01/18 22:51:22] d2.utils.events INFO:  eta: 12:01:14  iter: 10259  total_loss: 40.47  loss_ce: 0.3733  loss_mask: 0.4358  loss_dice: 3.178  loss_ce_0: 0.6111  loss_mask_0: 0.4152  loss_dice_0: 3.358  loss_ce_1: 0.3665  loss_mask_1: 0.4437  loss_dice_1: 3.234  loss_ce_2: 0.3669  loss_mask_2: 0.4402  loss_dice_2: 3.203  loss_ce_3: 0.3658  loss_mask_3: 0.4393  loss_dice_3: 3.194  loss_ce_4: 0.37  loss_mask_4: 0.4392  loss_dice_4: 3.194  loss_ce_5: 0.3598  loss_mask_5: 0.4413  loss_dice_5: 3.187  loss_ce_6: 0.36  loss_mask_6: 0.442  loss_dice_6: 3.181  loss_ce_7: 0.3561  loss_mask_7: 0.4382  loss_dice_7: 3.186  loss_ce_8: 0.3644  loss_mask_8: 0.4381  loss_dice_8: 3.186  time: 1.4222  data_time: 0.0665  lr: 7.6589e-06  max_mem: 21588M
[01/18 22:51:52] d2.utils.events INFO:  eta: 12:01:01  iter: 10279  total_loss: 40.39  loss_ce: 0.3624  loss_mask: 0.4315  loss_dice: 3.213  loss_ce_0: 0.5696  loss_mask_0: 0.4048  loss_dice_0: 3.394  loss_ce_1: 0.3519  loss_mask_1: 0.4338  loss_dice_1: 3.276  loss_ce_2: 0.376  loss_mask_2: 0.4329  loss_dice_2: 3.24  loss_ce_3: 0.3502  loss_mask_3: 0.4306  loss_dice_3: 3.228  loss_ce_4: 0.3507  loss_mask_4: 0.4294  loss_dice_4: 3.217  loss_ce_5: 0.3597  loss_mask_5: 0.4301  loss_dice_5: 3.21  loss_ce_6: 0.344  loss_mask_6: 0.4306  loss_dice_6: 3.226  loss_ce_7: 0.3443  loss_mask_7: 0.4307  loss_dice_7: 3.219  loss_ce_8: 0.3536  loss_mask_8: 0.4302  loss_dice_8: 3.223  time: 1.4223  data_time: 0.0730  lr: 7.6543e-06  max_mem: 21588M
[01/18 22:52:21] d2.utils.events INFO:  eta: 12:00:48  iter: 10299  total_loss: 40.49  loss_ce: 0.3332  loss_mask: 0.4287  loss_dice: 3.279  loss_ce_0: 0.6107  loss_mask_0: 0.4033  loss_dice_0: 3.431  loss_ce_1: 0.3343  loss_mask_1: 0.4284  loss_dice_1: 3.312  loss_ce_2: 0.3249  loss_mask_2: 0.4264  loss_dice_2: 3.288  loss_ce_3: 0.3101  loss_mask_3: 0.4259  loss_dice_3: 3.285  loss_ce_4: 0.3122  loss_mask_4: 0.4274  loss_dice_4: 3.288  loss_ce_5: 0.3166  loss_mask_5: 0.4271  loss_dice_5: 3.277  loss_ce_6: 0.3146  loss_mask_6: 0.4273  loss_dice_6: 3.275  loss_ce_7: 0.3293  loss_mask_7: 0.4283  loss_dice_7: 3.275  loss_ce_8: 0.3383  loss_mask_8: 0.4279  loss_dice_8: 3.263  time: 1.4224  data_time: 0.0694  lr: 7.6496e-06  max_mem: 21588M
[01/18 22:52:51] d2.utils.events INFO:  eta: 12:00:19  iter: 10319  total_loss: 40.8  loss_ce: 0.3107  loss_mask: 0.4226  loss_dice: 3.265  loss_ce_0: 0.5921  loss_mask_0: 0.4001  loss_dice_0: 3.425  loss_ce_1: 0.329  loss_mask_1: 0.4235  loss_dice_1: 3.312  loss_ce_2: 0.3222  loss_mask_2: 0.4206  loss_dice_2: 3.272  loss_ce_3: 0.3301  loss_mask_3: 0.42  loss_dice_3: 3.272  loss_ce_4: 0.3327  loss_mask_4: 0.4205  loss_dice_4: 3.278  loss_ce_5: 0.3081  loss_mask_5: 0.421  loss_dice_5: 3.273  loss_ce_6: 0.332  loss_mask_6: 0.4216  loss_dice_6: 3.27  loss_ce_7: 0.3241  loss_mask_7: 0.4215  loss_dice_7: 3.268  loss_ce_8: 0.3194  loss_mask_8: 0.4232  loss_dice_8: 3.26  time: 1.4225  data_time: 0.0693  lr: 7.645e-06  max_mem: 21588M
[01/18 22:53:20] d2.utils.events INFO:  eta: 12:00:01  iter: 10339  total_loss: 39.72  loss_ce: 0.334  loss_mask: 0.423  loss_dice: 3.174  loss_ce_0: 0.5985  loss_mask_0: 0.402  loss_dice_0: 3.349  loss_ce_1: 0.3481  loss_mask_1: 0.4273  loss_dice_1: 3.217  loss_ce_2: 0.3558  loss_mask_2: 0.421  loss_dice_2: 3.193  loss_ce_3: 0.3439  loss_mask_3: 0.4241  loss_dice_3: 3.182  loss_ce_4: 0.3476  loss_mask_4: 0.4242  loss_dice_4: 3.182  loss_ce_5: 0.3465  loss_mask_5: 0.4221  loss_dice_5: 3.171  loss_ce_6: 0.3169  loss_mask_6: 0.4234  loss_dice_6: 3.182  loss_ce_7: 0.3357  loss_mask_7: 0.4212  loss_dice_7: 3.168  loss_ce_8: 0.3352  loss_mask_8: 0.4223  loss_dice_8: 3.172  time: 1.4226  data_time: 0.0656  lr: 7.6403e-06  max_mem: 21588M
[01/18 22:53:48] d2.utils.events INFO:  eta: 11:59:27  iter: 10359  total_loss: 40.68  loss_ce: 0.3227  loss_mask: 0.4256  loss_dice: 3.245  loss_ce_0: 0.5897  loss_mask_0: 0.3997  loss_dice_0: 3.394  loss_ce_1: 0.3276  loss_mask_1: 0.4286  loss_dice_1: 3.269  loss_ce_2: 0.3415  loss_mask_2: 0.4276  loss_dice_2: 3.252  loss_ce_3: 0.3161  loss_mask_3: 0.4283  loss_dice_3: 3.246  loss_ce_4: 0.3243  loss_mask_4: 0.426  loss_dice_4: 3.245  loss_ce_5: 0.3124  loss_mask_5: 0.4262  loss_dice_5: 3.237  loss_ce_6: 0.3183  loss_mask_6: 0.4281  loss_dice_6: 3.252  loss_ce_7: 0.3088  loss_mask_7: 0.4289  loss_dice_7: 3.237  loss_ce_8: 0.3009  loss_mask_8: 0.4271  loss_dice_8: 3.238  time: 1.4225  data_time: 0.0539  lr: 7.6357e-06  max_mem: 21588M
[01/18 22:54:16] d2.utils.events INFO:  eta: 11:58:18  iter: 10379  total_loss: 40.64  loss_ce: 0.3329  loss_mask: 0.4153  loss_dice: 3.264  loss_ce_0: 0.6056  loss_mask_0: 0.3906  loss_dice_0: 3.411  loss_ce_1: 0.3391  loss_mask_1: 0.4146  loss_dice_1: 3.298  loss_ce_2: 0.3456  loss_mask_2: 0.4122  loss_dice_2: 3.281  loss_ce_3: 0.3288  loss_mask_3: 0.4141  loss_dice_3: 3.262  loss_ce_4: 0.3368  loss_mask_4: 0.4121  loss_dice_4: 3.271  loss_ce_5: 0.3333  loss_mask_5: 0.4149  loss_dice_5: 3.269  loss_ce_6: 0.3172  loss_mask_6: 0.4145  loss_dice_6: 3.259  loss_ce_7: 0.315  loss_mask_7: 0.4132  loss_dice_7: 3.267  loss_ce_8: 0.3263  loss_mask_8: 0.4146  loss_dice_8: 3.269  time: 1.4225  data_time: 0.0554  lr: 7.6311e-06  max_mem: 21588M
[01/18 22:54:44] d2.utils.events INFO:  eta: 11:57:30  iter: 10399  total_loss: 40.09  loss_ce: 0.3397  loss_mask: 0.4237  loss_dice: 3.194  loss_ce_0: 0.6144  loss_mask_0: 0.3944  loss_dice_0: 3.361  loss_ce_1: 0.3748  loss_mask_1: 0.423  loss_dice_1: 3.239  loss_ce_2: 0.3662  loss_mask_2: 0.4261  loss_dice_2: 3.204  loss_ce_3: 0.3504  loss_mask_3: 0.4257  loss_dice_3: 3.197  loss_ce_4: 0.3616  loss_mask_4: 0.4244  loss_dice_4: 3.194  loss_ce_5: 0.3483  loss_mask_5: 0.4252  loss_dice_5: 3.193  loss_ce_6: 0.3415  loss_mask_6: 0.4244  loss_dice_6: 3.189  loss_ce_7: 0.3525  loss_mask_7: 0.4236  loss_dice_7: 3.195  loss_ce_8: 0.3421  loss_mask_8: 0.4237  loss_dice_8: 3.193  time: 1.4225  data_time: 0.0546  lr: 7.6264e-06  max_mem: 21588M
[01/18 22:55:12] d2.utils.events INFO:  eta: 11:56:32  iter: 10419  total_loss: 39.94  loss_ce: 0.313  loss_mask: 0.4364  loss_dice: 3.196  loss_ce_0: 0.5781  loss_mask_0: 0.4181  loss_dice_0: 3.363  loss_ce_1: 0.328  loss_mask_1: 0.4431  loss_dice_1: 3.248  loss_ce_2: 0.3348  loss_mask_2: 0.4387  loss_dice_2: 3.202  loss_ce_3: 0.3148  loss_mask_3: 0.4345  loss_dice_3: 3.196  loss_ce_4: 0.3118  loss_mask_4: 0.436  loss_dice_4: 3.193  loss_ce_5: 0.3316  loss_mask_5: 0.4352  loss_dice_5: 3.199  loss_ce_6: 0.3257  loss_mask_6: 0.4361  loss_dice_6: 3.195  loss_ce_7: 0.3274  loss_mask_7: 0.437  loss_dice_7: 3.196  loss_ce_8: 0.3061  loss_mask_8: 0.4375  loss_dice_8: 3.2  time: 1.4224  data_time: 0.0555  lr: 7.6218e-06  max_mem: 21588M
[01/18 22:55:40] d2.utils.events INFO:  eta: 11:55:07  iter: 10439  total_loss: 40.45  loss_ce: 0.3292  loss_mask: 0.426  loss_dice: 3.183  loss_ce_0: 0.5971  loss_mask_0: 0.3979  loss_dice_0: 3.351  loss_ce_1: 0.3444  loss_mask_1: 0.4193  loss_dice_1: 3.228  loss_ce_2: 0.3562  loss_mask_2: 0.4188  loss_dice_2: 3.2  loss_ce_3: 0.3298  loss_mask_3: 0.4211  loss_dice_3: 3.187  loss_ce_4: 0.3366  loss_mask_4: 0.4195  loss_dice_4: 3.188  loss_ce_5: 0.3532  loss_mask_5: 0.4194  loss_dice_5: 3.189  loss_ce_6: 0.3348  loss_mask_6: 0.4218  loss_dice_6: 3.183  loss_ce_7: 0.3345  loss_mask_7: 0.4207  loss_dice_7: 3.184  loss_ce_8: 0.3344  loss_mask_8: 0.4243  loss_dice_8: 3.185  time: 1.4223  data_time: 0.0597  lr: 7.6172e-06  max_mem: 21588M
[01/18 22:56:07] d2.utils.events INFO:  eta: 11:53:54  iter: 10459  total_loss: 39.81  loss_ce: 0.3273  loss_mask: 0.42  loss_dice: 3.179  loss_ce_0: 0.5855  loss_mask_0: 0.3909  loss_dice_0: 3.347  loss_ce_1: 0.335  loss_mask_1: 0.4219  loss_dice_1: 3.228  loss_ce_2: 0.3298  loss_mask_2: 0.4182  loss_dice_2: 3.198  loss_ce_3: 0.3095  loss_mask_3: 0.417  loss_dice_3: 3.182  loss_ce_4: 0.3166  loss_mask_4: 0.4172  loss_dice_4: 3.178  loss_ce_5: 0.3095  loss_mask_5: 0.4187  loss_dice_5: 3.185  loss_ce_6: 0.326  loss_mask_6: 0.4183  loss_dice_6: 3.178  loss_ce_7: 0.3107  loss_mask_7: 0.4184  loss_dice_7: 3.183  loss_ce_8: 0.3106  loss_mask_8: 0.4197  loss_dice_8: 3.183  time: 1.4222  data_time: 0.0581  lr: 7.6125e-06  max_mem: 21588M
[01/18 22:56:35] d2.utils.events INFO:  eta: 11:52:46  iter: 10479  total_loss: 40.08  loss_ce: 0.3324  loss_mask: 0.4201  loss_dice: 3.184  loss_ce_0: 0.5849  loss_mask_0: 0.4037  loss_dice_0: 3.342  loss_ce_1: 0.3414  loss_mask_1: 0.4289  loss_dice_1: 3.223  loss_ce_2: 0.3478  loss_mask_2: 0.425  loss_dice_2: 3.192  loss_ce_3: 0.3444  loss_mask_3: 0.4211  loss_dice_3: 3.186  loss_ce_4: 0.3339  loss_mask_4: 0.4192  loss_dice_4: 3.181  loss_ce_5: 0.344  loss_mask_5: 0.4182  loss_dice_5: 3.181  loss_ce_6: 0.3373  loss_mask_6: 0.4211  loss_dice_6: 3.189  loss_ce_7: 0.3279  loss_mask_7: 0.4227  loss_dice_7: 3.184  loss_ce_8: 0.3335  loss_mask_8: 0.4214  loss_dice_8: 3.179  time: 1.4221  data_time: 0.0530  lr: 7.6079e-06  max_mem: 21588M
[01/18 22:57:03] d2.utils.events INFO:  eta: 11:51:05  iter: 10499  total_loss: 39.89  loss_ce: 0.3322  loss_mask: 0.425  loss_dice: 3.162  loss_ce_0: 0.6029  loss_mask_0: 0.4031  loss_dice_0: 3.332  loss_ce_1: 0.3387  loss_mask_1: 0.4248  loss_dice_1: 3.203  loss_ce_2: 0.3456  loss_mask_2: 0.4236  loss_dice_2: 3.175  loss_ce_3: 0.3444  loss_mask_3: 0.4247  loss_dice_3: 3.174  loss_ce_4: 0.3374  loss_mask_4: 0.4222  loss_dice_4: 3.166  loss_ce_5: 0.3272  loss_mask_5: 0.4232  loss_dice_5: 3.163  loss_ce_6: 0.323  loss_mask_6: 0.4233  loss_dice_6: 3.162  loss_ce_7: 0.3293  loss_mask_7: 0.423  loss_dice_7: 3.163  loss_ce_8: 0.3256  loss_mask_8: 0.4247  loss_dice_8: 3.162  time: 1.4221  data_time: 0.0542  lr: 7.6032e-06  max_mem: 21588M
[01/18 22:57:30] d2.utils.events INFO:  eta: 11:49:43  iter: 10519  total_loss: 40.06  loss_ce: 0.3577  loss_mask: 0.4185  loss_dice: 3.165  loss_ce_0: 0.5978  loss_mask_0: 0.3915  loss_dice_0: 3.352  loss_ce_1: 0.3442  loss_mask_1: 0.4181  loss_dice_1: 3.21  loss_ce_2: 0.3489  loss_mask_2: 0.4173  loss_dice_2: 3.184  loss_ce_3: 0.3316  loss_mask_3: 0.4162  loss_dice_3: 3.18  loss_ce_4: 0.3429  loss_mask_4: 0.4131  loss_dice_4: 3.175  loss_ce_5: 0.3433  loss_mask_5: 0.414  loss_dice_5: 3.175  loss_ce_6: 0.338  loss_mask_6: 0.4145  loss_dice_6: 3.169  loss_ce_7: 0.3455  loss_mask_7: 0.4152  loss_dice_7: 3.175  loss_ce_8: 0.358  loss_mask_8: 0.4169  loss_dice_8: 3.171  time: 1.4220  data_time: 0.0554  lr: 7.5986e-06  max_mem: 21588M
[01/18 22:57:58] d2.utils.events INFO:  eta: 11:48:55  iter: 10539  total_loss: 40.57  loss_ce: 0.3188  loss_mask: 0.4131  loss_dice: 3.235  loss_ce_0: 0.6164  loss_mask_0: 0.3976  loss_dice_0: 3.386  loss_ce_1: 0.3406  loss_mask_1: 0.4219  loss_dice_1: 3.268  loss_ce_2: 0.328  loss_mask_2: 0.4186  loss_dice_2: 3.236  loss_ce_3: 0.324  loss_mask_3: 0.414  loss_dice_3: 3.242  loss_ce_4: 0.326  loss_mask_4: 0.4114  loss_dice_4: 3.232  loss_ce_5: 0.3232  loss_mask_5: 0.4108  loss_dice_5: 3.24  loss_ce_6: 0.3261  loss_mask_6: 0.4114  loss_dice_6: 3.23  loss_ce_7: 0.3224  loss_mask_7: 0.4087  loss_dice_7: 3.238  loss_ce_8: 0.3201  loss_mask_8: 0.4113  loss_dice_8: 3.229  time: 1.4219  data_time: 0.0580  lr: 7.594e-06  max_mem: 21588M
[01/18 22:58:26] d2.utils.events INFO:  eta: 11:47:33  iter: 10559  total_loss: 39.77  loss_ce: 0.3426  loss_mask: 0.4324  loss_dice: 3.165  loss_ce_0: 0.584  loss_mask_0: 0.4007  loss_dice_0: 3.324  loss_ce_1: 0.3424  loss_mask_1: 0.4288  loss_dice_1: 3.195  loss_ce_2: 0.3356  loss_mask_2: 0.429  loss_dice_2: 3.176  loss_ce_3: 0.3254  loss_mask_3: 0.4305  loss_dice_3: 3.173  loss_ce_4: 0.325  loss_mask_4: 0.4313  loss_dice_4: 3.158  loss_ce_5: 0.3285  loss_mask_5: 0.4304  loss_dice_5: 3.166  loss_ce_6: 0.333  loss_mask_6: 0.4307  loss_dice_6: 3.158  loss_ce_7: 0.3199  loss_mask_7: 0.4334  loss_dice_7: 3.166  loss_ce_8: 0.3208  loss_mask_8: 0.4335  loss_dice_8: 3.164  time: 1.4219  data_time: 0.0548  lr: 7.5893e-06  max_mem: 21588M
[01/18 22:58:54] d2.utils.events INFO:  eta: 11:45:43  iter: 10579  total_loss: 39.63  loss_ce: 0.328  loss_mask: 0.4198  loss_dice: 3.145  loss_ce_0: 0.595  loss_mask_0: 0.3972  loss_dice_0: 3.333  loss_ce_1: 0.3503  loss_mask_1: 0.4199  loss_dice_1: 3.195  loss_ce_2: 0.3356  loss_mask_2: 0.4189  loss_dice_2: 3.18  loss_ce_3: 0.3198  loss_mask_3: 0.4198  loss_dice_3: 3.163  loss_ce_4: 0.3194  loss_mask_4: 0.4179  loss_dice_4: 3.161  loss_ce_5: 0.3243  loss_mask_5: 0.4183  loss_dice_5: 3.155  loss_ce_6: 0.3307  loss_mask_6: 0.4186  loss_dice_6: 3.156  loss_ce_7: 0.3309  loss_mask_7: 0.4188  loss_dice_7: 3.161  loss_ce_8: 0.3203  loss_mask_8: 0.4205  loss_dice_8: 3.153  time: 1.4218  data_time: 0.0556  lr: 7.5847e-06  max_mem: 21588M
[01/18 22:59:22] d2.utils.events INFO:  eta: 11:43:59  iter: 10599  total_loss: 40.04  loss_ce: 0.3283  loss_mask: 0.4239  loss_dice: 3.182  loss_ce_0: 0.5676  loss_mask_0: 0.399  loss_dice_0: 3.357  loss_ce_1: 0.3407  loss_mask_1: 0.4235  loss_dice_1: 3.22  loss_ce_2: 0.3472  loss_mask_2: 0.4239  loss_dice_2: 3.196  loss_ce_3: 0.3333  loss_mask_3: 0.4256  loss_dice_3: 3.173  loss_ce_4: 0.3109  loss_mask_4: 0.4266  loss_dice_4: 3.182  loss_ce_5: 0.3245  loss_mask_5: 0.4247  loss_dice_5: 3.18  loss_ce_6: 0.3094  loss_mask_6: 0.4247  loss_dice_6: 3.181  loss_ce_7: 0.316  loss_mask_7: 0.425  loss_dice_7: 3.178  loss_ce_8: 0.3292  loss_mask_8: 0.4267  loss_dice_8: 3.172  time: 1.4217  data_time: 0.0556  lr: 7.58e-06  max_mem: 21588M
[01/18 22:59:49] d2.utils.events INFO:  eta: 11:42:11  iter: 10619  total_loss: 40.13  loss_ce: 0.3424  loss_mask: 0.4327  loss_dice: 3.152  loss_ce_0: 0.6279  loss_mask_0: 0.4098  loss_dice_0: 3.325  loss_ce_1: 0.3621  loss_mask_1: 0.4333  loss_dice_1: 3.207  loss_ce_2: 0.375  loss_mask_2: 0.4304  loss_dice_2: 3.177  loss_ce_3: 0.3446  loss_mask_3: 0.4299  loss_dice_3: 3.168  loss_ce_4: 0.365  loss_mask_4: 0.4299  loss_dice_4: 3.159  loss_ce_5: 0.3381  loss_mask_5: 0.4324  loss_dice_5: 3.162  loss_ce_6: 0.3514  loss_mask_6: 0.4318  loss_dice_6: 3.166  loss_ce_7: 0.3455  loss_mask_7: 0.432  loss_dice_7: 3.166  loss_ce_8: 0.3473  loss_mask_8: 0.4316  loss_dice_8: 3.155  time: 1.4216  data_time: 0.0545  lr: 7.5754e-06  max_mem: 21588M
[01/18 23:00:17] d2.utils.events INFO:  eta: 11:41:07  iter: 10639  total_loss: 40.94  loss_ce: 0.342  loss_mask: 0.4155  loss_dice: 3.26  loss_ce_0: 0.6315  loss_mask_0: 0.4011  loss_dice_0: 3.425  loss_ce_1: 0.3754  loss_mask_1: 0.4209  loss_dice_1: 3.293  loss_ce_2: 0.3934  loss_mask_2: 0.4192  loss_dice_2: 3.272  loss_ce_3: 0.341  loss_mask_3: 0.4169  loss_dice_3: 3.27  loss_ce_4: 0.3392  loss_mask_4: 0.4177  loss_dice_4: 3.264  loss_ce_5: 0.3505  loss_mask_5: 0.4157  loss_dice_5: 3.26  loss_ce_6: 0.3494  loss_mask_6: 0.4183  loss_dice_6: 3.262  loss_ce_7: 0.3548  loss_mask_7: 0.4161  loss_dice_7: 3.257  loss_ce_8: 0.3522  loss_mask_8: 0.415  loss_dice_8: 3.268  time: 1.4216  data_time: 0.0664  lr: 7.5708e-06  max_mem: 21588M
[01/18 23:00:45] d2.utils.events INFO:  eta: 11:40:06  iter: 10659  total_loss: 39.95  loss_ce: 0.3293  loss_mask: 0.425  loss_dice: 3.179  loss_ce_0: 0.5864  loss_mask_0: 0.4002  loss_dice_0: 3.329  loss_ce_1: 0.3528  loss_mask_1: 0.4265  loss_dice_1: 3.201  loss_ce_2: 0.3404  loss_mask_2: 0.4269  loss_dice_2: 3.182  loss_ce_3: 0.3291  loss_mask_3: 0.4297  loss_dice_3: 3.179  loss_ce_4: 0.3269  loss_mask_4: 0.4273  loss_dice_4: 3.178  loss_ce_5: 0.3271  loss_mask_5: 0.4277  loss_dice_5: 3.18  loss_ce_6: 0.3402  loss_mask_6: 0.4266  loss_dice_6: 3.181  loss_ce_7: 0.3333  loss_mask_7: 0.4272  loss_dice_7: 3.179  loss_ce_8: 0.3195  loss_mask_8: 0.4257  loss_dice_8: 3.177  time: 1.4215  data_time: 0.0606  lr: 7.5661e-06  max_mem: 21588M
[01/18 23:01:13] d2.utils.events INFO:  eta: 11:39:13  iter: 10679  total_loss: 39.88  loss_ce: 0.3191  loss_mask: 0.4292  loss_dice: 3.188  loss_ce_0: 0.5684  loss_mask_0: 0.4072  loss_dice_0: 3.36  loss_ce_1: 0.3284  loss_mask_1: 0.4297  loss_dice_1: 3.22  loss_ce_2: 0.3354  loss_mask_2: 0.4286  loss_dice_2: 3.196  loss_ce_3: 0.3118  loss_mask_3: 0.4289  loss_dice_3: 3.191  loss_ce_4: 0.3261  loss_mask_4: 0.4281  loss_dice_4: 3.192  loss_ce_5: 0.3135  loss_mask_5: 0.4272  loss_dice_5: 3.196  loss_ce_6: 0.317  loss_mask_6: 0.4289  loss_dice_6: 3.19  loss_ce_7: 0.3302  loss_mask_7: 0.4293  loss_dice_7: 3.186  loss_ce_8: 0.3263  loss_mask_8: 0.4288  loss_dice_8: 3.191  time: 1.4215  data_time: 0.0588  lr: 7.5615e-06  max_mem: 21588M
[01/18 23:01:41] d2.utils.events INFO:  eta: 11:38:45  iter: 10699  total_loss: 40.54  loss_ce: 0.3152  loss_mask: 0.4248  loss_dice: 3.219  loss_ce_0: 0.6036  loss_mask_0: 0.4062  loss_dice_0: 3.376  loss_ce_1: 0.3339  loss_mask_1: 0.4308  loss_dice_1: 3.252  loss_ce_2: 0.3168  loss_mask_2: 0.4247  loss_dice_2: 3.237  loss_ce_3: 0.3184  loss_mask_3: 0.4222  loss_dice_3: 3.227  loss_ce_4: 0.326  loss_mask_4: 0.4214  loss_dice_4: 3.214  loss_ce_5: 0.3288  loss_mask_5: 0.425  loss_dice_5: 3.214  loss_ce_6: 0.3204  loss_mask_6: 0.4242  loss_dice_6: 3.214  loss_ce_7: 0.3183  loss_mask_7: 0.4255  loss_dice_7: 3.218  loss_ce_8: 0.323  loss_mask_8: 0.4269  loss_dice_8: 3.211  time: 1.4214  data_time: 0.0570  lr: 7.5568e-06  max_mem: 21588M
[01/18 23:02:09] d2.utils.events INFO:  eta: 11:38:13  iter: 10719  total_loss: 39.81  loss_ce: 0.3299  loss_mask: 0.4258  loss_dice: 3.169  loss_ce_0: 0.5979  loss_mask_0: 0.394  loss_dice_0: 3.33  loss_ce_1: 0.3458  loss_mask_1: 0.426  loss_dice_1: 3.204  loss_ce_2: 0.3341  loss_mask_2: 0.4224  loss_dice_2: 3.178  loss_ce_3: 0.3206  loss_mask_3: 0.4224  loss_dice_3: 3.168  loss_ce_4: 0.3199  loss_mask_4: 0.4222  loss_dice_4: 3.166  loss_ce_5: 0.3208  loss_mask_5: 0.4224  loss_dice_5: 3.167  loss_ce_6: 0.3176  loss_mask_6: 0.4247  loss_dice_6: 3.166  loss_ce_7: 0.3255  loss_mask_7: 0.4254  loss_dice_7: 3.165  loss_ce_8: 0.3347  loss_mask_8: 0.4248  loss_dice_8: 3.177  time: 1.4214  data_time: 0.0549  lr: 7.5522e-06  max_mem: 21588M
[01/18 23:02:36] d2.utils.events INFO:  eta: 11:37:13  iter: 10739  total_loss: 40.94  loss_ce: 0.3221  loss_mask: 0.4223  loss_dice: 3.275  loss_ce_0: 0.5728  loss_mask_0: 0.3949  loss_dice_0: 3.426  loss_ce_1: 0.3604  loss_mask_1: 0.4267  loss_dice_1: 3.304  loss_ce_2: 0.3365  loss_mask_2: 0.4242  loss_dice_2: 3.295  loss_ce_3: 0.3467  loss_mask_3: 0.4223  loss_dice_3: 3.275  loss_ce_4: 0.3439  loss_mask_4: 0.4207  loss_dice_4: 3.276  loss_ce_5: 0.3436  loss_mask_5: 0.4198  loss_dice_5: 3.28  loss_ce_6: 0.3284  loss_mask_6: 0.4218  loss_dice_6: 3.267  loss_ce_7: 0.3241  loss_mask_7: 0.4213  loss_dice_7: 3.275  loss_ce_8: 0.336  loss_mask_8: 0.4197  loss_dice_8: 3.276  time: 1.4213  data_time: 0.0571  lr: 7.5476e-06  max_mem: 21588M
[01/18 23:03:04] d2.utils.events INFO:  eta: 11:36:11  iter: 10759  total_loss: 39.56  loss_ce: 0.322  loss_mask: 0.4254  loss_dice: 3.168  loss_ce_0: 0.5733  loss_mask_0: 0.3983  loss_dice_0: 3.345  loss_ce_1: 0.3372  loss_mask_1: 0.4223  loss_dice_1: 3.216  loss_ce_2: 0.3414  loss_mask_2: 0.4243  loss_dice_2: 3.187  loss_ce_3: 0.3271  loss_mask_3: 0.4234  loss_dice_3: 3.172  loss_ce_4: 0.3362  loss_mask_4: 0.4269  loss_dice_4: 3.173  loss_ce_5: 0.3261  loss_mask_5: 0.4267  loss_dice_5: 3.167  loss_ce_6: 0.3224  loss_mask_6: 0.4262  loss_dice_6: 3.175  loss_ce_7: 0.3355  loss_mask_7: 0.4264  loss_dice_7: 3.174  loss_ce_8: 0.3118  loss_mask_8: 0.427  loss_dice_8: 3.173  time: 1.4212  data_time: 0.0553  lr: 7.5429e-06  max_mem: 21588M
[01/18 23:03:32] d2.utils.events INFO:  eta: 11:34:55  iter: 10779  total_loss: 39.11  loss_ce: 0.3176  loss_mask: 0.4173  loss_dice: 3.111  loss_ce_0: 0.6292  loss_mask_0: 0.3902  loss_dice_0: 3.296  loss_ce_1: 0.3583  loss_mask_1: 0.4185  loss_dice_1: 3.17  loss_ce_2: 0.3358  loss_mask_2: 0.4169  loss_dice_2: 3.126  loss_ce_3: 0.337  loss_mask_3: 0.4177  loss_dice_3: 3.131  loss_ce_4: 0.3298  loss_mask_4: 0.4172  loss_dice_4: 3.123  loss_ce_5: 0.3259  loss_mask_5: 0.4158  loss_dice_5: 3.115  loss_ce_6: 0.3186  loss_mask_6: 0.4151  loss_dice_6: 3.117  loss_ce_7: 0.317  loss_mask_7: 0.4146  loss_dice_7: 3.122  loss_ce_8: 0.3276  loss_mask_8: 0.4166  loss_dice_8: 3.116  time: 1.4212  data_time: 0.0584  lr: 7.5383e-06  max_mem: 21588M
[01/18 23:04:00] d2.utils.events INFO:  eta: 11:34:05  iter: 10799  total_loss: 40.15  loss_ce: 0.3328  loss_mask: 0.4177  loss_dice: 3.202  loss_ce_0: 0.6097  loss_mask_0: 0.3953  loss_dice_0: 3.368  loss_ce_1: 0.3449  loss_mask_1: 0.4201  loss_dice_1: 3.245  loss_ce_2: 0.3592  loss_mask_2: 0.4185  loss_dice_2: 3.217  loss_ce_3: 0.3347  loss_mask_3: 0.4186  loss_dice_3: 3.208  loss_ce_4: 0.331  loss_mask_4: 0.4172  loss_dice_4: 3.204  loss_ce_5: 0.3393  loss_mask_5: 0.4174  loss_dice_5: 3.203  loss_ce_6: 0.3482  loss_mask_6: 0.4167  loss_dice_6: 3.199  loss_ce_7: 0.3573  loss_mask_7: 0.4186  loss_dice_7: 3.203  loss_ce_8: 0.3489  loss_mask_8: 0.4179  loss_dice_8: 3.202  time: 1.4211  data_time: 0.0561  lr: 7.5336e-06  max_mem: 21588M
[01/18 23:04:28] d2.utils.events INFO:  eta: 11:32:23  iter: 10819  total_loss: 40.8  loss_ce: 0.325  loss_mask: 0.4234  loss_dice: 3.306  loss_ce_0: 0.6104  loss_mask_0: 0.4055  loss_dice_0: 3.465  loss_ce_1: 0.3389  loss_mask_1: 0.4269  loss_dice_1: 3.347  loss_ce_2: 0.3274  loss_mask_2: 0.4259  loss_dice_2: 3.33  loss_ce_3: 0.333  loss_mask_3: 0.4237  loss_dice_3: 3.316  loss_ce_4: 0.3375  loss_mask_4: 0.4237  loss_dice_4: 3.312  loss_ce_5: 0.3334  loss_mask_5: 0.4225  loss_dice_5: 3.32  loss_ce_6: 0.3221  loss_mask_6: 0.4234  loss_dice_6: 3.319  loss_ce_7: 0.3176  loss_mask_7: 0.4216  loss_dice_7: 3.309  loss_ce_8: 0.3176  loss_mask_8: 0.4229  loss_dice_8: 3.308  time: 1.4210  data_time: 0.0594  lr: 7.529e-06  max_mem: 21588M
[01/18 23:04:55] d2.utils.events INFO:  eta: 11:30:44  iter: 10839  total_loss: 40.09  loss_ce: 0.3572  loss_mask: 0.4354  loss_dice: 3.195  loss_ce_0: 0.6041  loss_mask_0: 0.4034  loss_dice_0: 3.35  loss_ce_1: 0.3656  loss_mask_1: 0.4329  loss_dice_1: 3.237  loss_ce_2: 0.3559  loss_mask_2: 0.431  loss_dice_2: 3.201  loss_ce_3: 0.3476  loss_mask_3: 0.4297  loss_dice_3: 3.196  loss_ce_4: 0.3327  loss_mask_4: 0.4287  loss_dice_4: 3.192  loss_ce_5: 0.3364  loss_mask_5: 0.4304  loss_dice_5: 3.192  loss_ce_6: 0.3621  loss_mask_6: 0.4296  loss_dice_6: 3.19  loss_ce_7: 0.3392  loss_mask_7: 0.4319  loss_dice_7: 3.201  loss_ce_8: 0.3479  loss_mask_8: 0.4332  loss_dice_8: 3.202  time: 1.4210  data_time: 0.0551  lr: 7.5243e-06  max_mem: 21588M
[01/18 23:05:23] d2.utils.events INFO:  eta: 11:29:18  iter: 10859  total_loss: 39.45  loss_ce: 0.3071  loss_mask: 0.4172  loss_dice: 3.16  loss_ce_0: 0.559  loss_mask_0: 0.3962  loss_dice_0: 3.335  loss_ce_1: 0.33  loss_mask_1: 0.4258  loss_dice_1: 3.203  loss_ce_2: 0.3249  loss_mask_2: 0.4192  loss_dice_2: 3.174  loss_ce_3: 0.3121  loss_mask_3: 0.4214  loss_dice_3: 3.174  loss_ce_4: 0.3108  loss_mask_4: 0.42  loss_dice_4: 3.168  loss_ce_5: 0.3204  loss_mask_5: 0.4183  loss_dice_5: 3.173  loss_ce_6: 0.3106  loss_mask_6: 0.4179  loss_dice_6: 3.175  loss_ce_7: 0.302  loss_mask_7: 0.4179  loss_dice_7: 3.165  loss_ce_8: 0.3149  loss_mask_8: 0.4178  loss_dice_8: 3.166  time: 1.4209  data_time: 0.0611  lr: 7.5197e-06  max_mem: 21588M
[01/18 23:05:51] d2.utils.events INFO:  eta: 11:28:10  iter: 10879  total_loss: 40.35  loss_ce: 0.334  loss_mask: 0.4181  loss_dice: 3.201  loss_ce_0: 0.5926  loss_mask_0: 0.3958  loss_dice_0: 3.359  loss_ce_1: 0.3466  loss_mask_1: 0.4229  loss_dice_1: 3.24  loss_ce_2: 0.352  loss_mask_2: 0.4235  loss_dice_2: 3.208  loss_ce_3: 0.3573  loss_mask_3: 0.4174  loss_dice_3: 3.202  loss_ce_4: 0.3491  loss_mask_4: 0.4179  loss_dice_4: 3.203  loss_ce_5: 0.336  loss_mask_5: 0.4212  loss_dice_5: 3.201  loss_ce_6: 0.3309  loss_mask_6: 0.4189  loss_dice_6: 3.203  loss_ce_7: 0.3414  loss_mask_7: 0.4185  loss_dice_7: 3.194  loss_ce_8: 0.3368  loss_mask_8: 0.4193  loss_dice_8: 3.195  time: 1.4209  data_time: 0.0627  lr: 7.515e-06  max_mem: 21588M
[01/18 23:06:19] d2.utils.events INFO:  eta: 11:26:52  iter: 10899  total_loss: 40.04  loss_ce: 0.3195  loss_mask: 0.4114  loss_dice: 3.186  loss_ce_0: 0.5921  loss_mask_0: 0.3906  loss_dice_0: 3.36  loss_ce_1: 0.3309  loss_mask_1: 0.4151  loss_dice_1: 3.24  loss_ce_2: 0.3374  loss_mask_2: 0.4116  loss_dice_2: 3.211  loss_ce_3: 0.3169  loss_mask_3: 0.4111  loss_dice_3: 3.199  loss_ce_4: 0.3216  loss_mask_4: 0.4096  loss_dice_4: 3.192  loss_ce_5: 0.3135  loss_mask_5: 0.4099  loss_dice_5: 3.191  loss_ce_6: 0.3188  loss_mask_6: 0.41  loss_dice_6: 3.188  loss_ce_7: 0.3205  loss_mask_7: 0.4117  loss_dice_7: 3.2  loss_ce_8: 0.3295  loss_mask_8: 0.4108  loss_dice_8: 3.192  time: 1.4208  data_time: 0.0572  lr: 7.5104e-06  max_mem: 21588M
[01/18 23:06:46] d2.utils.events INFO:  eta: 11:25:13  iter: 10919  total_loss: 39.51  loss_ce: 0.3367  loss_mask: 0.4221  loss_dice: 3.134  loss_ce_0: 0.6157  loss_mask_0: 0.4067  loss_dice_0: 3.316  loss_ce_1: 0.3499  loss_mask_1: 0.429  loss_dice_1: 3.172  loss_ce_2: 0.3433  loss_mask_2: 0.4287  loss_dice_2: 3.147  loss_ce_3: 0.3457  loss_mask_3: 0.4247  loss_dice_3: 3.137  loss_ce_4: 0.3372  loss_mask_4: 0.4249  loss_dice_4: 3.136  loss_ce_5: 0.3245  loss_mask_5: 0.4267  loss_dice_5: 3.139  loss_ce_6: 0.3234  loss_mask_6: 0.4273  loss_dice_6: 3.133  loss_ce_7: 0.3324  loss_mask_7: 0.4254  loss_dice_7: 3.14  loss_ce_8: 0.3201  loss_mask_8: 0.4229  loss_dice_8: 3.141  time: 1.4207  data_time: 0.0603  lr: 7.5058e-06  max_mem: 21588M
[01/18 23:07:14] d2.utils.events INFO:  eta: 11:24:18  iter: 10939  total_loss: 40.29  loss_ce: 0.3295  loss_mask: 0.4212  loss_dice: 3.204  loss_ce_0: 0.5983  loss_mask_0: 0.39  loss_dice_0: 3.363  loss_ce_1: 0.3615  loss_mask_1: 0.414  loss_dice_1: 3.236  loss_ce_2: 0.3572  loss_mask_2: 0.4165  loss_dice_2: 3.205  loss_ce_3: 0.3458  loss_mask_3: 0.4161  loss_dice_3: 3.204  loss_ce_4: 0.3356  loss_mask_4: 0.4163  loss_dice_4: 3.204  loss_ce_5: 0.3438  loss_mask_5: 0.418  loss_dice_5: 3.203  loss_ce_6: 0.3323  loss_mask_6: 0.42  loss_dice_6: 3.205  loss_ce_7: 0.3226  loss_mask_7: 0.4172  loss_dice_7: 3.195  loss_ce_8: 0.3377  loss_mask_8: 0.4193  loss_dice_8: 3.199  time: 1.4207  data_time: 0.0634  lr: 7.5011e-06  max_mem: 21588M
[01/18 23:07:42] d2.utils.events INFO:  eta: 11:23:25  iter: 10959  total_loss: 39.57  loss_ce: 0.3146  loss_mask: 0.4155  loss_dice: 3.15  loss_ce_0: 0.5871  loss_mask_0: 0.3977  loss_dice_0: 3.328  loss_ce_1: 0.3261  loss_mask_1: 0.4258  loss_dice_1: 3.196  loss_ce_2: 0.3386  loss_mask_2: 0.4195  loss_dice_2: 3.172  loss_ce_3: 0.3279  loss_mask_3: 0.4163  loss_dice_3: 3.161  loss_ce_4: 0.3264  loss_mask_4: 0.4174  loss_dice_4: 3.15  loss_ce_5: 0.3263  loss_mask_5: 0.4158  loss_dice_5: 3.154  loss_ce_6: 0.3133  loss_mask_6: 0.4161  loss_dice_6: 3.157  loss_ce_7: 0.3186  loss_mask_7: 0.416  loss_dice_7: 3.154  loss_ce_8: 0.3195  loss_mask_8: 0.4181  loss_dice_8: 3.165  time: 1.4206  data_time: 0.0594  lr: 7.4965e-06  max_mem: 21588M
[01/18 23:08:10] d2.utils.events INFO:  eta: 11:21:32  iter: 10979  total_loss: 39.51  loss_ce: 0.3364  loss_mask: 0.4231  loss_dice: 3.158  loss_ce_0: 0.5916  loss_mask_0: 0.4013  loss_dice_0: 3.331  loss_ce_1: 0.3488  loss_mask_1: 0.4257  loss_dice_1: 3.207  loss_ce_2: 0.3437  loss_mask_2: 0.4239  loss_dice_2: 3.163  loss_ce_3: 0.336  loss_mask_3: 0.4226  loss_dice_3: 3.154  loss_ce_4: 0.354  loss_mask_4: 0.421  loss_dice_4: 3.165  loss_ce_5: 0.34  loss_mask_5: 0.4228  loss_dice_5: 3.155  loss_ce_6: 0.3404  loss_mask_6: 0.421  loss_dice_6: 3.16  loss_ce_7: 0.3251  loss_mask_7: 0.4224  loss_dice_7: 3.157  loss_ce_8: 0.3261  loss_mask_8: 0.4207  loss_dice_8: 3.158  time: 1.4206  data_time: 0.0534  lr: 7.4918e-06  max_mem: 21588M
[01/18 23:08:38] d2.utils.events INFO:  eta: 11:20:09  iter: 10999  total_loss: 39.55  loss_ce: 0.3307  loss_mask: 0.4209  loss_dice: 3.113  loss_ce_0: 0.5976  loss_mask_0: 0.3997  loss_dice_0: 3.286  loss_ce_1: 0.3505  loss_mask_1: 0.427  loss_dice_1: 3.164  loss_ce_2: 0.3571  loss_mask_2: 0.4224  loss_dice_2: 3.13  loss_ce_3: 0.334  loss_mask_3: 0.4219  loss_dice_3: 3.118  loss_ce_4: 0.3321  loss_mask_4: 0.4218  loss_dice_4: 3.123  loss_ce_5: 0.3267  loss_mask_5: 0.4222  loss_dice_5: 3.12  loss_ce_6: 0.3319  loss_mask_6: 0.4234  loss_dice_6: 3.122  loss_ce_7: 0.3275  loss_mask_7: 0.4212  loss_dice_7: 3.114  loss_ce_8: 0.3226  loss_mask_8: 0.4212  loss_dice_8: 3.119  time: 1.4205  data_time: 0.0583  lr: 7.4872e-06  max_mem: 21588M
[01/18 23:09:05] d2.utils.events INFO:  eta: 11:19:27  iter: 11019  total_loss: 39.4  loss_ce: 0.3081  loss_mask: 0.4253  loss_dice: 3.126  loss_ce_0: 0.5748  loss_mask_0: 0.3979  loss_dice_0: 3.289  loss_ce_1: 0.3153  loss_mask_1: 0.4257  loss_dice_1: 3.174  loss_ce_2: 0.3154  loss_mask_2: 0.4251  loss_dice_2: 3.15  loss_ce_3: 0.3088  loss_mask_3: 0.4246  loss_dice_3: 3.134  loss_ce_4: 0.3141  loss_mask_4: 0.4248  loss_dice_4: 3.136  loss_ce_5: 0.3121  loss_mask_5: 0.4238  loss_dice_5: 3.137  loss_ce_6: 0.3113  loss_mask_6: 0.4238  loss_dice_6: 3.138  loss_ce_7: 0.315  loss_mask_7: 0.4241  loss_dice_7: 3.128  loss_ce_8: 0.3053  loss_mask_8: 0.4241  loss_dice_8: 3.13  time: 1.4204  data_time: 0.0571  lr: 7.4825e-06  max_mem: 21588M
[01/18 23:09:33] d2.utils.events INFO:  eta: 11:17:52  iter: 11039  total_loss: 39.26  loss_ce: 0.3081  loss_mask: 0.42  loss_dice: 3.141  loss_ce_0: 0.5938  loss_mask_0: 0.3974  loss_dice_0: 3.305  loss_ce_1: 0.3286  loss_mask_1: 0.4234  loss_dice_1: 3.183  loss_ce_2: 0.3249  loss_mask_2: 0.4201  loss_dice_2: 3.16  loss_ce_3: 0.3186  loss_mask_3: 0.4183  loss_dice_3: 3.146  loss_ce_4: 0.3273  loss_mask_4: 0.4197  loss_dice_4: 3.146  loss_ce_5: 0.3269  loss_mask_5: 0.4217  loss_dice_5: 3.149  loss_ce_6: 0.31  loss_mask_6: 0.4214  loss_dice_6: 3.145  loss_ce_7: 0.3117  loss_mask_7: 0.4206  loss_dice_7: 3.146  loss_ce_8: 0.2997  loss_mask_8: 0.4202  loss_dice_8: 3.148  time: 1.4204  data_time: 0.0566  lr: 7.4779e-06  max_mem: 21588M
[01/18 23:10:02] d2.utils.events INFO:  eta: 11:16:54  iter: 11059  total_loss: 40.36  loss_ce: 0.3335  loss_mask: 0.4076  loss_dice: 3.227  loss_ce_0: 0.616  loss_mask_0: 0.3867  loss_dice_0: 3.391  loss_ce_1: 0.3601  loss_mask_1: 0.4088  loss_dice_1: 3.279  loss_ce_2: 0.3583  loss_mask_2: 0.4098  loss_dice_2: 3.245  loss_ce_3: 0.3332  loss_mask_3: 0.407  loss_dice_3: 3.235  loss_ce_4: 0.3415  loss_mask_4: 0.4073  loss_dice_4: 3.229  loss_ce_5: 0.3374  loss_mask_5: 0.4074  loss_dice_5: 3.225  loss_ce_6: 0.3194  loss_mask_6: 0.4063  loss_dice_6: 3.242  loss_ce_7: 0.3454  loss_mask_7: 0.4066  loss_dice_7: 3.227  loss_ce_8: 0.3446  loss_mask_8: 0.4056  loss_dice_8: 3.221  time: 1.4204  data_time: 0.0587  lr: 7.4732e-06  max_mem: 21588M
[01/18 23:10:29] d2.utils.events INFO:  eta: 11:15:48  iter: 11079  total_loss: 39.31  loss_ce: 0.329  loss_mask: 0.4319  loss_dice: 3.124  loss_ce_0: 0.5653  loss_mask_0: 0.4013  loss_dice_0: 3.294  loss_ce_1: 0.3468  loss_mask_1: 0.4323  loss_dice_1: 3.164  loss_ce_2: 0.3386  loss_mask_2: 0.4314  loss_dice_2: 3.141  loss_ce_3: 0.3135  loss_mask_3: 0.4314  loss_dice_3: 3.137  loss_ce_4: 0.3255  loss_mask_4: 0.4299  loss_dice_4: 3.126  loss_ce_5: 0.3138  loss_mask_5: 0.4309  loss_dice_5: 3.124  loss_ce_6: 0.3105  loss_mask_6: 0.4302  loss_dice_6: 3.118  loss_ce_7: 0.312  loss_mask_7: 0.4317  loss_dice_7: 3.109  loss_ce_8: 0.3204  loss_mask_8: 0.4333  loss_dice_8: 3.124  time: 1.4203  data_time: 0.0539  lr: 7.4686e-06  max_mem: 21588M
[01/18 23:10:57] d2.utils.events INFO:  eta: 11:14:12  iter: 11099  total_loss: 39.88  loss_ce: 0.3352  loss_mask: 0.422  loss_dice: 3.2  loss_ce_0: 0.5956  loss_mask_0: 0.3979  loss_dice_0: 3.352  loss_ce_1: 0.354  loss_mask_1: 0.4274  loss_dice_1: 3.242  loss_ce_2: 0.3384  loss_mask_2: 0.425  loss_dice_2: 3.211  loss_ce_3: 0.3428  loss_mask_3: 0.4234  loss_dice_3: 3.206  loss_ce_4: 0.3482  loss_mask_4: 0.4219  loss_dice_4: 3.201  loss_ce_5: 0.3536  loss_mask_5: 0.4232  loss_dice_5: 3.204  loss_ce_6: 0.3525  loss_mask_6: 0.4237  loss_dice_6: 3.197  loss_ce_7: 0.3436  loss_mask_7: 0.4214  loss_dice_7: 3.203  loss_ce_8: 0.3458  loss_mask_8: 0.421  loss_dice_8: 3.196  time: 1.4202  data_time: 0.0579  lr: 7.4639e-06  max_mem: 21588M
[01/18 23:11:24] d2.utils.events INFO:  eta: 11:13:09  iter: 11119  total_loss: 39.68  loss_ce: 0.3306  loss_mask: 0.4178  loss_dice: 3.169  loss_ce_0: 0.576  loss_mask_0: 0.3943  loss_dice_0: 3.346  loss_ce_1: 0.3261  loss_mask_1: 0.4196  loss_dice_1: 3.212  loss_ce_2: 0.3284  loss_mask_2: 0.4186  loss_dice_2: 3.184  loss_ce_3: 0.334  loss_mask_3: 0.4175  loss_dice_3: 3.178  loss_ce_4: 0.3331  loss_mask_4: 0.42  loss_dice_4: 3.171  loss_ce_5: 0.3166  loss_mask_5: 0.4192  loss_dice_5: 3.174  loss_ce_6: 0.3319  loss_mask_6: 0.4173  loss_dice_6: 3.164  loss_ce_7: 0.3088  loss_mask_7: 0.4188  loss_dice_7: 3.171  loss_ce_8: 0.3122  loss_mask_8: 0.4215  loss_dice_8: 3.165  time: 1.4201  data_time: 0.0577  lr: 7.4593e-06  max_mem: 21588M
[01/18 23:11:52] d2.utils.events INFO:  eta: 11:12:18  iter: 11139  total_loss: 39.59  loss_ce: 0.3237  loss_mask: 0.4142  loss_dice: 3.154  loss_ce_0: 0.5757  loss_mask_0: 0.3952  loss_dice_0: 3.321  loss_ce_1: 0.3273  loss_mask_1: 0.419  loss_dice_1: 3.196  loss_ce_2: 0.3078  loss_mask_2: 0.4152  loss_dice_2: 3.172  loss_ce_3: 0.3059  loss_mask_3: 0.4159  loss_dice_3: 3.162  loss_ce_4: 0.3076  loss_mask_4: 0.4149  loss_dice_4: 3.162  loss_ce_5: 0.3068  loss_mask_5: 0.4151  loss_dice_5: 3.165  loss_ce_6: 0.3108  loss_mask_6: 0.4155  loss_dice_6: 3.152  loss_ce_7: 0.3041  loss_mask_7: 0.4131  loss_dice_7: 3.157  loss_ce_8: 0.313  loss_mask_8: 0.4147  loss_dice_8: 3.15  time: 1.4201  data_time: 0.0571  lr: 7.4546e-06  max_mem: 21588M
[01/18 23:12:21] d2.utils.events INFO:  eta: 11:11:20  iter: 11159  total_loss: 39.26  loss_ce: 0.3325  loss_mask: 0.4097  loss_dice: 3.132  loss_ce_0: 0.5948  loss_mask_0: 0.3859  loss_dice_0: 3.316  loss_ce_1: 0.3553  loss_mask_1: 0.4122  loss_dice_1: 3.18  loss_ce_2: 0.3547  loss_mask_2: 0.4096  loss_dice_2: 3.151  loss_ce_3: 0.3317  loss_mask_3: 0.4085  loss_dice_3: 3.141  loss_ce_4: 0.3216  loss_mask_4: 0.409  loss_dice_4: 3.148  loss_ce_5: 0.3237  loss_mask_5: 0.4082  loss_dice_5: 3.141  loss_ce_6: 0.3393  loss_mask_6: 0.4085  loss_dice_6: 3.136  loss_ce_7: 0.3259  loss_mask_7: 0.4093  loss_dice_7: 3.14  loss_ce_8: 0.3364  loss_mask_8: 0.4077  loss_dice_8: 3.139  time: 1.4201  data_time: 0.0626  lr: 7.45e-06  max_mem: 21588M
[01/18 23:12:48] d2.utils.events INFO:  eta: 11:10:27  iter: 11179  total_loss: 39.73  loss_ce: 0.3273  loss_mask: 0.4152  loss_dice: 3.201  loss_ce_0: 0.6115  loss_mask_0: 0.3893  loss_dice_0: 3.362  loss_ce_1: 0.332  loss_mask_1: 0.4184  loss_dice_1: 3.243  loss_ce_2: 0.344  loss_mask_2: 0.4122  loss_dice_2: 3.217  loss_ce_3: 0.3379  loss_mask_3: 0.411  loss_dice_3: 3.213  loss_ce_4: 0.3263  loss_mask_4: 0.4123  loss_dice_4: 3.208  loss_ce_5: 0.3274  loss_mask_5: 0.4099  loss_dice_5: 3.205  loss_ce_6: 0.3294  loss_mask_6: 0.412  loss_dice_6: 3.199  loss_ce_7: 0.3216  loss_mask_7: 0.4123  loss_dice_7: 3.207  loss_ce_8: 0.3321  loss_mask_8: 0.4136  loss_dice_8: 3.2  time: 1.4200  data_time: 0.0626  lr: 7.4453e-06  max_mem: 21588M
[01/18 23:13:16] d2.utils.events INFO:  eta: 11:09:13  iter: 11199  total_loss: 39.94  loss_ce: 0.3252  loss_mask: 0.4193  loss_dice: 3.166  loss_ce_0: 0.5689  loss_mask_0: 0.4019  loss_dice_0: 3.331  loss_ce_1: 0.3304  loss_mask_1: 0.4254  loss_dice_1: 3.212  loss_ce_2: 0.3413  loss_mask_2: 0.4216  loss_dice_2: 3.188  loss_ce_3: 0.3204  loss_mask_3: 0.4228  loss_dice_3: 3.181  loss_ce_4: 0.3204  loss_mask_4: 0.4223  loss_dice_4: 3.174  loss_ce_5: 0.3224  loss_mask_5: 0.4217  loss_dice_5: 3.176  loss_ce_6: 0.3182  loss_mask_6: 0.4209  loss_dice_6: 3.173  loss_ce_7: 0.3221  loss_mask_7: 0.4202  loss_dice_7: 3.172  loss_ce_8: 0.3255  loss_mask_8: 0.4191  loss_dice_8: 3.166  time: 1.4200  data_time: 0.0559  lr: 7.4407e-06  max_mem: 21588M
[01/18 23:13:44] d2.utils.events INFO:  eta: 11:08:11  iter: 11219  total_loss: 39.01  loss_ce: 0.3273  loss_mask: 0.4144  loss_dice: 3.086  loss_ce_0: 0.5802  loss_mask_0: 0.3928  loss_dice_0: 3.268  loss_ce_1: 0.3502  loss_mask_1: 0.4199  loss_dice_1: 3.13  loss_ce_2: 0.3405  loss_mask_2: 0.4169  loss_dice_2: 3.108  loss_ce_3: 0.3318  loss_mask_3: 0.4105  loss_dice_3: 3.094  loss_ce_4: 0.3166  loss_mask_4: 0.4105  loss_dice_4: 3.095  loss_ce_5: 0.3227  loss_mask_5: 0.4115  loss_dice_5: 3.089  loss_ce_6: 0.3143  loss_mask_6: 0.4124  loss_dice_6: 3.085  loss_ce_7: 0.3258  loss_mask_7: 0.4125  loss_dice_7: 3.093  loss_ce_8: 0.3145  loss_mask_8: 0.4143  loss_dice_8: 3.092  time: 1.4199  data_time: 0.0547  lr: 7.436e-06  max_mem: 21588M
[01/18 23:14:12] d2.utils.events INFO:  eta: 11:07:25  iter: 11239  total_loss: 39.04  loss_ce: 0.3024  loss_mask: 0.4034  loss_dice: 3.12  loss_ce_0: 0.5821  loss_mask_0: 0.3842  loss_dice_0: 3.29  loss_ce_1: 0.3416  loss_mask_1: 0.4062  loss_dice_1: 3.161  loss_ce_2: 0.3395  loss_mask_2: 0.4067  loss_dice_2: 3.122  loss_ce_3: 0.3027  loss_mask_3: 0.4056  loss_dice_3: 3.124  loss_ce_4: 0.3149  loss_mask_4: 0.4075  loss_dice_4: 3.119  loss_ce_5: 0.3012  loss_mask_5: 0.4051  loss_dice_5: 3.114  loss_ce_6: 0.302  loss_mask_6: 0.404  loss_dice_6: 3.122  loss_ce_7: 0.3015  loss_mask_7: 0.4028  loss_dice_7: 3.117  loss_ce_8: 0.3011  loss_mask_8: 0.4039  loss_dice_8: 3.117  time: 1.4198  data_time: 0.0558  lr: 7.4314e-06  max_mem: 21588M
[01/18 23:14:40] d2.utils.events INFO:  eta: 11:06:24  iter: 11259  total_loss: 39.15  loss_ce: 0.3331  loss_mask: 0.4061  loss_dice: 3.166  loss_ce_0: 0.6306  loss_mask_0: 0.3855  loss_dice_0: 3.334  loss_ce_1: 0.3428  loss_mask_1: 0.4088  loss_dice_1: 3.195  loss_ce_2: 0.3479  loss_mask_2: 0.4084  loss_dice_2: 3.171  loss_ce_3: 0.34  loss_mask_3: 0.4083  loss_dice_3: 3.167  loss_ce_4: 0.3294  loss_mask_4: 0.4068  loss_dice_4: 3.161  loss_ce_5: 0.3288  loss_mask_5: 0.4052  loss_dice_5: 3.174  loss_ce_6: 0.3259  loss_mask_6: 0.4062  loss_dice_6: 3.167  loss_ce_7: 0.3232  loss_mask_7: 0.4054  loss_dice_7: 3.157  loss_ce_8: 0.3221  loss_mask_8: 0.4058  loss_dice_8: 3.161  time: 1.4198  data_time: 0.0566  lr: 7.4267e-06  max_mem: 21588M
[01/18 23:15:07] d2.utils.events INFO:  eta: 11:05:24  iter: 11279  total_loss: 38.67  loss_ce: 0.314  loss_mask: 0.4026  loss_dice: 3.071  loss_ce_0: 0.5905  loss_mask_0: 0.3836  loss_dice_0: 3.25  loss_ce_1: 0.3274  loss_mask_1: 0.4023  loss_dice_1: 3.115  loss_ce_2: 0.3461  loss_mask_2: 0.405  loss_dice_2: 3.087  loss_ce_3: 0.3117  loss_mask_3: 0.4022  loss_dice_3: 3.074  loss_ce_4: 0.3066  loss_mask_4: 0.4027  loss_dice_4: 3.08  loss_ce_5: 0.3114  loss_mask_5: 0.4028  loss_dice_5: 3.077  loss_ce_6: 0.3047  loss_mask_6: 0.4038  loss_dice_6: 3.078  loss_ce_7: 0.3061  loss_mask_7: 0.4019  loss_dice_7: 3.069  loss_ce_8: 0.3097  loss_mask_8: 0.4041  loss_dice_8: 3.069  time: 1.4197  data_time: 0.0580  lr: 7.4221e-06  max_mem: 21588M
[01/18 23:15:35] d2.utils.events INFO:  eta: 11:04:11  iter: 11299  total_loss: 39.84  loss_ce: 0.2932  loss_mask: 0.4307  loss_dice: 3.167  loss_ce_0: 0.5936  loss_mask_0: 0.4083  loss_dice_0: 3.326  loss_ce_1: 0.3099  loss_mask_1: 0.4376  loss_dice_1: 3.208  loss_ce_2: 0.3177  loss_mask_2: 0.4317  loss_dice_2: 3.185  loss_ce_3: 0.31  loss_mask_3: 0.4311  loss_dice_3: 3.17  loss_ce_4: 0.3165  loss_mask_4: 0.4309  loss_dice_4: 3.166  loss_ce_5: 0.3011  loss_mask_5: 0.4308  loss_dice_5: 3.168  loss_ce_6: 0.2856  loss_mask_6: 0.4315  loss_dice_6: 3.165  loss_ce_7: 0.2978  loss_mask_7: 0.4305  loss_dice_7: 3.17  loss_ce_8: 0.3003  loss_mask_8: 0.4314  loss_dice_8: 3.168  time: 1.4196  data_time: 0.0587  lr: 7.4174e-06  max_mem: 21588M
[01/18 23:16:03] d2.utils.events INFO:  eta: 11:03:13  iter: 11319  total_loss: 38.34  loss_ce: 0.3053  loss_mask: 0.4067  loss_dice: 3.054  loss_ce_0: 0.5728  loss_mask_0: 0.3878  loss_dice_0: 3.239  loss_ce_1: 0.3377  loss_mask_1: 0.4141  loss_dice_1: 3.103  loss_ce_2: 0.3344  loss_mask_2: 0.4091  loss_dice_2: 3.079  loss_ce_3: 0.3256  loss_mask_3: 0.4095  loss_dice_3: 3.057  loss_ce_4: 0.3251  loss_mask_4: 0.408  loss_dice_4: 3.056  loss_ce_5: 0.3077  loss_mask_5: 0.4076  loss_dice_5: 3.056  loss_ce_6: 0.3033  loss_mask_6: 0.4065  loss_dice_6: 3.047  loss_ce_7: 0.3096  loss_mask_7: 0.4071  loss_dice_7: 3.053  loss_ce_8: 0.3059  loss_mask_8: 0.4077  loss_dice_8: 3.054  time: 1.4196  data_time: 0.0614  lr: 7.4128e-06  max_mem: 21588M
[01/18 23:16:31] d2.utils.events INFO:  eta: 11:01:57  iter: 11339  total_loss: 38.55  loss_ce: 0.3058  loss_mask: 0.4049  loss_dice: 3.091  loss_ce_0: 0.5923  loss_mask_0: 0.3814  loss_dice_0: 3.277  loss_ce_1: 0.3351  loss_mask_1: 0.4038  loss_dice_1: 3.141  loss_ce_2: 0.3298  loss_mask_2: 0.4021  loss_dice_2: 3.123  loss_ce_3: 0.3124  loss_mask_3: 0.4005  loss_dice_3: 3.107  loss_ce_4: 0.3036  loss_mask_4: 0.4007  loss_dice_4: 3.102  loss_ce_5: 0.3158  loss_mask_5: 0.4015  loss_dice_5: 3.091  loss_ce_6: 0.3055  loss_mask_6: 0.4029  loss_dice_6: 3.099  loss_ce_7: 0.3119  loss_mask_7: 0.4031  loss_dice_7: 3.094  loss_ce_8: 0.2972  loss_mask_8: 0.4049  loss_dice_8: 3.096  time: 1.4195  data_time: 0.0564  lr: 7.4081e-06  max_mem: 21588M
[01/18 23:16:59] d2.utils.events INFO:  eta: 11:01:32  iter: 11359  total_loss: 39.24  loss_ce: 0.3339  loss_mask: 0.4105  loss_dice: 3.126  loss_ce_0: 0.5868  loss_mask_0: 0.3923  loss_dice_0: 3.291  loss_ce_1: 0.3592  loss_mask_1: 0.4183  loss_dice_1: 3.17  loss_ce_2: 0.3345  loss_mask_2: 0.4155  loss_dice_2: 3.132  loss_ce_3: 0.3508  loss_mask_3: 0.413  loss_dice_3: 3.124  loss_ce_4: 0.3449  loss_mask_4: 0.4136  loss_dice_4: 3.12  loss_ce_5: 0.3306  loss_mask_5: 0.4136  loss_dice_5: 3.134  loss_ce_6: 0.3356  loss_mask_6: 0.4133  loss_dice_6: 3.119  loss_ce_7: 0.3226  loss_mask_7: 0.4136  loss_dice_7: 3.125  loss_ce_8: 0.3478  loss_mask_8: 0.4143  loss_dice_8: 3.121  time: 1.4195  data_time: 0.0625  lr: 7.4035e-06  max_mem: 21588M
[01/18 23:17:27] d2.utils.events INFO:  eta: 11:01:07  iter: 11379  total_loss: 39.19  loss_ce: 0.2865  loss_mask: 0.4214  loss_dice: 3.14  loss_ce_0: 0.605  loss_mask_0: 0.4032  loss_dice_0: 3.301  loss_ce_1: 0.3074  loss_mask_1: 0.43  loss_dice_1: 3.173  loss_ce_2: 0.3145  loss_mask_2: 0.4251  loss_dice_2: 3.151  loss_ce_3: 0.3121  loss_mask_3: 0.423  loss_dice_3: 3.142  loss_ce_4: 0.3086  loss_mask_4: 0.4212  loss_dice_4: 3.135  loss_ce_5: 0.3095  loss_mask_5: 0.4182  loss_dice_5: 3.137  loss_ce_6: 0.3063  loss_mask_6: 0.4207  loss_dice_6: 3.144  loss_ce_7: 0.2983  loss_mask_7: 0.4203  loss_dice_7: 3.145  loss_ce_8: 0.3093  loss_mask_8: 0.4204  loss_dice_8: 3.143  time: 1.4195  data_time: 0.0564  lr: 7.3988e-06  max_mem: 21588M
[01/18 23:17:55] d2.utils.events INFO:  eta: 11:00:36  iter: 11399  total_loss: 38.52  loss_ce: 0.3094  loss_mask: 0.4206  loss_dice: 3.049  loss_ce_0: 0.5821  loss_mask_0: 0.391  loss_dice_0: 3.234  loss_ce_1: 0.3284  loss_mask_1: 0.4176  loss_dice_1: 3.103  loss_ce_2: 0.3262  loss_mask_2: 0.4177  loss_dice_2: 3.081  loss_ce_3: 0.3132  loss_mask_3: 0.4168  loss_dice_3: 3.07  loss_ce_4: 0.2965  loss_mask_4: 0.4176  loss_dice_4: 3.061  loss_ce_5: 0.3129  loss_mask_5: 0.4193  loss_dice_5: 3.06  loss_ce_6: 0.3007  loss_mask_6: 0.4185  loss_dice_6: 3.064  loss_ce_7: 0.3036  loss_mask_7: 0.4197  loss_dice_7: 3.062  loss_ce_8: 0.3073  loss_mask_8: 0.4209  loss_dice_8: 3.048  time: 1.4194  data_time: 0.0576  lr: 7.3942e-06  max_mem: 21588M
[01/18 23:18:23] d2.utils.events INFO:  eta: 11:00:28  iter: 11419  total_loss: 39.27  loss_ce: 0.3238  loss_mask: 0.408  loss_dice: 3.111  loss_ce_0: 0.6064  loss_mask_0: 0.3845  loss_dice_0: 3.287  loss_ce_1: 0.347  loss_mask_1: 0.4118  loss_dice_1: 3.15  loss_ce_2: 0.3519  loss_mask_2: 0.4114  loss_dice_2: 3.126  loss_ce_3: 0.3355  loss_mask_3: 0.406  loss_dice_3: 3.121  loss_ce_4: 0.3328  loss_mask_4: 0.4074  loss_dice_4: 3.129  loss_ce_5: 0.3404  loss_mask_5: 0.4069  loss_dice_5: 3.115  loss_ce_6: 0.3337  loss_mask_6: 0.4065  loss_dice_6: 3.116  loss_ce_7: 0.3321  loss_mask_7: 0.4064  loss_dice_7: 3.113  loss_ce_8: 0.3228  loss_mask_8: 0.4064  loss_dice_8: 3.119  time: 1.4194  data_time: 0.0571  lr: 7.3895e-06  max_mem: 21588M
[01/18 23:18:51] d2.utils.events INFO:  eta: 11:00:18  iter: 11439  total_loss: 38.88  loss_ce: 0.3155  loss_mask: 0.4016  loss_dice: 3.077  loss_ce_0: 0.6071  loss_mask_0: 0.3887  loss_dice_0: 3.236  loss_ce_1: 0.3505  loss_mask_1: 0.4147  loss_dice_1: 3.111  loss_ce_2: 0.3491  loss_mask_2: 0.4086  loss_dice_2: 3.084  loss_ce_3: 0.3236  loss_mask_3: 0.4073  loss_dice_3: 3.088  loss_ce_4: 0.3384  loss_mask_4: 0.4076  loss_dice_4: 3.087  loss_ce_5: 0.3099  loss_mask_5: 0.4036  loss_dice_5: 3.077  loss_ce_6: 0.3208  loss_mask_6: 0.4049  loss_dice_6: 3.082  loss_ce_7: 0.3188  loss_mask_7: 0.4046  loss_dice_7: 3.077  loss_ce_8: 0.3112  loss_mask_8: 0.4046  loss_dice_8: 3.075  time: 1.4194  data_time: 0.0635  lr: 7.3849e-06  max_mem: 21588M
[01/18 23:19:19] d2.utils.events INFO:  eta: 10:59:31  iter: 11459  total_loss: 38.99  loss_ce: 0.334  loss_mask: 0.4066  loss_dice: 3.098  loss_ce_0: 0.5816  loss_mask_0: 0.3846  loss_dice_0: 3.264  loss_ce_1: 0.3589  loss_mask_1: 0.4087  loss_dice_1: 3.134  loss_ce_2: 0.3494  loss_mask_2: 0.407  loss_dice_2: 3.109  loss_ce_3: 0.3415  loss_mask_3: 0.4064  loss_dice_3: 3.1  loss_ce_4: 0.36  loss_mask_4: 0.4045  loss_dice_4: 3.101  loss_ce_5: 0.3376  loss_mask_5: 0.4065  loss_dice_5: 3.097  loss_ce_6: 0.3389  loss_mask_6: 0.4062  loss_dice_6: 3.095  loss_ce_7: 0.3287  loss_mask_7: 0.4077  loss_dice_7: 3.107  loss_ce_8: 0.3305  loss_mask_8: 0.4069  loss_dice_8: 3.1  time: 1.4193  data_time: 0.0533  lr: 7.3802e-06  max_mem: 21588M
[01/18 23:19:46] d2.utils.events INFO:  eta: 10:58:53  iter: 11479  total_loss: 38.75  loss_ce: 0.3055  loss_mask: 0.4121  loss_dice: 3.107  loss_ce_0: 0.5529  loss_mask_0: 0.3869  loss_dice_0: 3.295  loss_ce_1: 0.3026  loss_mask_1: 0.4152  loss_dice_1: 3.155  loss_ce_2: 0.3065  loss_mask_2: 0.4121  loss_dice_2: 3.126  loss_ce_3: 0.31  loss_mask_3: 0.4107  loss_dice_3: 3.118  loss_ce_4: 0.3152  loss_mask_4: 0.4097  loss_dice_4: 3.106  loss_ce_5: 0.3101  loss_mask_5: 0.4104  loss_dice_5: 3.106  loss_ce_6: 0.2918  loss_mask_6: 0.4111  loss_dice_6: 3.108  loss_ce_7: 0.2917  loss_mask_7: 0.4112  loss_dice_7: 3.109  loss_ce_8: 0.2925  loss_mask_8: 0.4111  loss_dice_8: 3.105  time: 1.4192  data_time: 0.0562  lr: 7.3755e-06  max_mem: 21588M
[01/18 23:20:14] d2.utils.events INFO:  eta: 10:58:25  iter: 11499  total_loss: 39.2  loss_ce: 0.3155  loss_mask: 0.4169  loss_dice: 3.115  loss_ce_0: 0.5612  loss_mask_0: 0.3918  loss_dice_0: 3.278  loss_ce_1: 0.328  loss_mask_1: 0.4177  loss_dice_1: 3.142  loss_ce_2: 0.3385  loss_mask_2: 0.4131  loss_dice_2: 3.124  loss_ce_3: 0.3348  loss_mask_3: 0.4114  loss_dice_3: 3.113  loss_ce_4: 0.3232  loss_mask_4: 0.4105  loss_dice_4: 3.107  loss_ce_5: 0.3186  loss_mask_5: 0.4115  loss_dice_5: 3.118  loss_ce_6: 0.318  loss_mask_6: 0.4156  loss_dice_6: 3.099  loss_ce_7: 0.3166  loss_mask_7: 0.416  loss_dice_7: 3.113  loss_ce_8: 0.3175  loss_mask_8: 0.4175  loss_dice_8: 3.118  time: 1.4192  data_time: 0.0624  lr: 7.3709e-06  max_mem: 21588M
[01/18 23:20:42] d2.utils.events INFO:  eta: 10:58:12  iter: 11519  total_loss: 38.86  loss_ce: 0.2878  loss_mask: 0.4071  loss_dice: 3.13  loss_ce_0: 0.5753  loss_mask_0: 0.386  loss_dice_0: 3.3  loss_ce_1: 0.3103  loss_mask_1: 0.4117  loss_dice_1: 3.173  loss_ce_2: 0.305  loss_mask_2: 0.4099  loss_dice_2: 3.151  loss_ce_3: 0.3022  loss_mask_3: 0.4066  loss_dice_3: 3.139  loss_ce_4: 0.2786  loss_mask_4: 0.406  loss_dice_4: 3.134  loss_ce_5: 0.2971  loss_mask_5: 0.41  loss_dice_5: 3.142  loss_ce_6: 0.2974  loss_mask_6: 0.409  loss_dice_6: 3.138  loss_ce_7: 0.3002  loss_mask_7: 0.4069  loss_dice_7: 3.132  loss_ce_8: 0.2917  loss_mask_8: 0.4068  loss_dice_8: 3.145  time: 1.4192  data_time: 0.0593  lr: 7.3662e-06  max_mem: 21588M
[01/18 23:21:10] d2.utils.events INFO:  eta: 10:57:49  iter: 11539  total_loss: 38.46  loss_ce: 0.3079  loss_mask: 0.4007  loss_dice: 3.067  loss_ce_0: 0.5753  loss_mask_0: 0.3813  loss_dice_0: 3.236  loss_ce_1: 0.3412  loss_mask_1: 0.4085  loss_dice_1: 3.101  loss_ce_2: 0.3294  loss_mask_2: 0.4042  loss_dice_2: 3.081  loss_ce_3: 0.3157  loss_mask_3: 0.401  loss_dice_3: 3.072  loss_ce_4: 0.3186  loss_mask_4: 0.4018  loss_dice_4: 3.071  loss_ce_5: 0.3297  loss_mask_5: 0.4045  loss_dice_5: 3.075  loss_ce_6: 0.319  loss_mask_6: 0.3993  loss_dice_6: 3.056  loss_ce_7: 0.325  loss_mask_7: 0.4019  loss_dice_7: 3.068  loss_ce_8: 0.3123  loss_mask_8: 0.4011  loss_dice_8: 3.07  time: 1.4191  data_time: 0.0563  lr: 7.3616e-06  max_mem: 21588M
[01/18 23:21:38] d2.utils.events INFO:  eta: 10:57:49  iter: 11559  total_loss: 39.28  loss_ce: 0.3225  loss_mask: 0.4007  loss_dice: 3.133  loss_ce_0: 0.6145  loss_mask_0: 0.3818  loss_dice_0: 3.282  loss_ce_1: 0.3633  loss_mask_1: 0.3999  loss_dice_1: 3.171  loss_ce_2: 0.3686  loss_mask_2: 0.3982  loss_dice_2: 3.148  loss_ce_3: 0.34  loss_mask_3: 0.4008  loss_dice_3: 3.122  loss_ce_4: 0.3485  loss_mask_4: 0.4018  loss_dice_4: 3.127  loss_ce_5: 0.3384  loss_mask_5: 0.4002  loss_dice_5: 3.131  loss_ce_6: 0.333  loss_mask_6: 0.4006  loss_dice_6: 3.128  loss_ce_7: 0.3301  loss_mask_7: 0.4028  loss_dice_7: 3.127  loss_ce_8: 0.3366  loss_mask_8: 0.4033  loss_dice_8: 3.13  time: 1.4191  data_time: 0.0537  lr: 7.3569e-06  max_mem: 21588M
[01/18 23:22:06] d2.utils.events INFO:  eta: 10:57:26  iter: 11579  total_loss: 39.26  loss_ce: 0.3175  loss_mask: 0.4159  loss_dice: 3.132  loss_ce_0: 0.5515  loss_mask_0: 0.395  loss_dice_0: 3.294  loss_ce_1: 0.3225  loss_mask_1: 0.4209  loss_dice_1: 3.165  loss_ce_2: 0.3312  loss_mask_2: 0.4183  loss_dice_2: 3.148  loss_ce_3: 0.3133  loss_mask_3: 0.4192  loss_dice_3: 3.132  loss_ce_4: 0.309  loss_mask_4: 0.4164  loss_dice_4: 3.134  loss_ce_5: 0.317  loss_mask_5: 0.4166  loss_dice_5: 3.132  loss_ce_6: 0.315  loss_mask_6: 0.4167  loss_dice_6: 3.136  loss_ce_7: 0.3051  loss_mask_7: 0.4165  loss_dice_7: 3.131  loss_ce_8: 0.2965  loss_mask_8: 0.4154  loss_dice_8: 3.131  time: 1.4190  data_time: 0.0606  lr: 7.3523e-06  max_mem: 21588M
[01/18 23:22:34] d2.utils.events INFO:  eta: 10:56:52  iter: 11599  total_loss: 38.09  loss_ce: 0.3149  loss_mask: 0.4018  loss_dice: 3.066  loss_ce_0: 0.57  loss_mask_0: 0.3819  loss_dice_0: 3.243  loss_ce_1: 0.3321  loss_mask_1: 0.4043  loss_dice_1: 3.117  loss_ce_2: 0.3244  loss_mask_2: 0.4012  loss_dice_2: 3.083  loss_ce_3: 0.3181  loss_mask_3: 0.3999  loss_dice_3: 3.079  loss_ce_4: 0.3059  loss_mask_4: 0.3985  loss_dice_4: 3.075  loss_ce_5: 0.3011  loss_mask_5: 0.3983  loss_dice_5: 3.081  loss_ce_6: 0.3075  loss_mask_6: 0.3986  loss_dice_6: 3.074  loss_ce_7: 0.3068  loss_mask_7: 0.4008  loss_dice_7: 3.066  loss_ce_8: 0.3122  loss_mask_8: 0.4007  loss_dice_8: 3.068  time: 1.4189  data_time: 0.0572  lr: 7.3476e-06  max_mem: 21588M
[01/18 23:23:02] d2.utils.events INFO:  eta: 10:56:40  iter: 11619  total_loss: 38.99  loss_ce: 0.3113  loss_mask: 0.4136  loss_dice: 3.116  loss_ce_0: 0.5816  loss_mask_0: 0.3859  loss_dice_0: 3.28  loss_ce_1: 0.3188  loss_mask_1: 0.4131  loss_dice_1: 3.151  loss_ce_2: 0.3353  loss_mask_2: 0.4154  loss_dice_2: 3.117  loss_ce_3: 0.3333  loss_mask_3: 0.4153  loss_dice_3: 3.117  loss_ce_4: 0.3353  loss_mask_4: 0.4151  loss_dice_4: 3.111  loss_ce_5: 0.3244  loss_mask_5: 0.4149  loss_dice_5: 3.11  loss_ce_6: 0.3214  loss_mask_6: 0.4146  loss_dice_6: 3.111  loss_ce_7: 0.3144  loss_mask_7: 0.4131  loss_dice_7: 3.112  loss_ce_8: 0.3377  loss_mask_8: 0.4138  loss_dice_8: 3.115  time: 1.4189  data_time: 0.0554  lr: 7.343e-06  max_mem: 21588M
[01/18 23:23:04] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 391, in run_step
    data = next(self._data_loader_iter)
  File "/home/nstarli/detectron2/detectron2/data/common.py", line 234, in __iter__
    for d in self.dataset:
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/_utils.py", line 425, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 28, in fetch
    data.append(next(self.dataset_iter))
  File "/home/nstarli/detectron2/detectron2/data/common.py", line 201, in __iter__
    yield self.dataset[idx]
  File "/home/nstarli/detectron2/detectron2/data/common.py", line 90, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/nstarli/Mask2Former/mask2former/data/dataset_mappers/mask_former_sceneflow_dataset_mapper.py", line 115, in __call__
    image_left = utils.read_image(dataset_dict["file_name"], format=self.img_format)
  File "/home/nstarli/detectron2/detectron2/data/detection_utils.py", line 180, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/iopath/common/file_io.py", line 1012, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/iopath/common/file_io.py", line 604, in _open
    return open(  # type: ignore
FileNotFoundError: [Errno 2] No such file or directory: '/home/Datasets/sceneflow/flyingthings3d__frames_finalpass/frames_finalpass/TRAIN/A/0175/left/0014.png'

[01/18 23:23:04] d2.engine.hooks INFO: Overall training speed: 11620 iterations in 4:34:47 (1.4189 s / it)
[01/18 23:23:04] d2.engine.hooks INFO: Total training time: 5:06:19 (0:31:31 on hooks)
[01/18 23:23:04] d2.utils.events INFO:  eta: 10:56:35  iter: 11622  total_loss: 38.91  loss_ce: 0.3321  loss_mask: 0.4127  loss_dice: 3.116  loss_ce_0: 0.5899  loss_mask_0: 0.3834  loss_dice_0: 3.278  loss_ce_1: 0.3325  loss_mask_1: 0.4118  loss_dice_1: 3.151  loss_ce_2: 0.3396  loss_mask_2: 0.4154  loss_dice_2: 3.117  loss_ce_3: 0.3428  loss_mask_3: 0.4153  loss_dice_3: 3.117  loss_ce_4: 0.3389  loss_mask_4: 0.4151  loss_dice_4: 3.111  loss_ce_5: 0.3376  loss_mask_5: 0.4149  loss_dice_5: 3.11  loss_ce_6: 0.3258  loss_mask_6: 0.4146  loss_dice_6: 3.111  loss_ce_7: 0.3272  loss_mask_7: 0.4124  loss_dice_7: 3.112  loss_ce_8: 0.3394  loss_mask_8: 0.4129  loss_dice_8: 3.115  time: 1.4189  data_time: 0.0556  lr: 7.3425e-06  max_mem: 21588M
[01/19 00:22:18] detectron2 INFO: Rank of current process: 0. World size: 4
[01/19 00:22:21] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/19 00:22:21] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/19 00:22:21] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/19 00:22:21] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m192[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_testing[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/19 00:22:21] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_testing/config.yaml
[01/19 00:22:21] d2.utils.env INFO: Using a generated random seed 21951441
[01/19 00:22:22] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/19 00:22:23] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 00:22:27] d2.data.build INFO: Using training sampler TrainingSampler
[01/19 00:22:27] d2.data.common INFO: Serializing 26790 elements to byte tensors and concatenating them all ...
[01/19 00:22:27] d2.data.common INFO: Serialized dataset takes 7.95 MiB
[01/19 00:22:28] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/19 00:22:28] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/19 00:22:28] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/19 00:22:28] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/19 00:22:28] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/19 00:22:28] d2.engine.train_loop INFO: Starting training from iteration 0
[01/19 00:22:35] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 391, in run_step
    data = next(self._data_loader_iter)
  File "/home/nstarli/detectron2/detectron2/data/common.py", line 234, in __iter__
    for d in self.dataset:
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/_utils.py", line 425, in reraise
    raise self.exc_type(msg)
AttributeError: Caught AttributeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/data/transforms/augmentation.py", line 68, in _get_aug_input_args
    args.append(getattr(aug_input, f))
AttributeError: 'AugStereoInput' object has no attribute 'image'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 28, in fetch
    data.append(next(self.dataset_iter))
  File "/home/nstarli/detectron2/detectron2/data/common.py", line 201, in __iter__
    yield self.dataset[idx]
  File "/home/nstarli/detectron2/detectron2/data/common.py", line 90, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/nstarli/Mask2Former/mask2former/data/dataset_mappers/mask_former_sceneflow_dataset_mapper.py", line 140, in __call__
    aug_input, transforms = T.apply_transform_gens(self.tfm_gens, aug_input)
  File "/home/nstarli/detectron2/detectron2/data/transforms/augmentation.py", line 360, in apply_augmentations
    tfms = inputs.apply_augmentations(augmentations)
  File "/home/nstarli/Mask2Former/mask2former/data/dataset_mappers/mask_former_sceneflow_dataset_mapper.py", line 285, in apply_augmentations
    return AugmentationList(augmentations)(self)
  File "/home/nstarli/detectron2/detectron2/data/transforms/augmentation.py", line 264, in __call__
    tfm = x(aug_input)
  File "/home/nstarli/detectron2/detectron2/data/transforms/augmentation.py", line 164, in __call__
    args = _get_aug_input_args(self, aug_input)
  File "/home/nstarli/detectron2/detectron2/data/transforms/augmentation.py", line 70, in _get_aug_input_args
    raise AttributeError(
AttributeError: <class 'detectron2.data.transforms.augmentation_impl.RandomCrop_CategoryAreaConstraint'>.get_transform needs input attribute 'image', but it is not an attribute of <class 'mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper.AugStereoInput'>!

[01/19 00:22:35] d2.engine.hooks INFO: Total training time: 0:00:06 (0:00:00 on hooks)
[01/19 00:22:35] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 494M
[01/19 00:26:26] detectron2 INFO: Rank of current process: 0. World size: 4
[01/19 00:26:29] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/19 00:26:29] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/19 00:26:29] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/19 00:26:29] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m192[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_testing[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/19 00:26:29] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_testing/config.yaml
[01/19 00:26:29] d2.utils.env INFO: Using a generated random seed 29668599
[01/19 00:26:30] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/19 00:26:30] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 00:26:34] d2.data.build INFO: Using training sampler TrainingSampler
[01/19 00:26:35] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/19 00:26:36] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/19 00:26:36] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/19 00:26:36] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/19 00:26:36] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/19 00:26:36] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/19 00:26:36] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/19 00:26:36] d2.engine.train_loop INFO: Starting training from iteration 0
[01/19 00:26:44] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/nstarli/detectron2/detectron2/engine/train_loop.py", line 391, in run_step
    data = next(self._data_loader_iter)
  File "/home/nstarli/detectron2/detectron2/data/common.py", line 234, in __iter__
    for d in self.dataset:
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/_utils.py", line 425, in reraise
    raise self.exc_type(msg)
AttributeError: Caught AttributeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/nstarli/detectron2/detectron2/data/transforms/augmentation.py", line 68, in _get_aug_input_args
    args.append(getattr(aug_input, f))
AttributeError: 'AugStereoInput' object has no attribute 'image'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 28, in fetch
    data.append(next(self.dataset_iter))
  File "/home/nstarli/detectron2/detectron2/data/common.py", line 201, in __iter__
    yield self.dataset[idx]
  File "/home/nstarli/detectron2/detectron2/data/common.py", line 90, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/nstarli/Mask2Former/mask2former/data/dataset_mappers/mask_former_sceneflow_dataset_mapper.py", line 140, in __call__
    aug_input, transforms = T.apply_transform_gens(self.tfm_gens, aug_input)
  File "/home/nstarli/detectron2/detectron2/data/transforms/augmentation.py", line 360, in apply_augmentations
    tfms = inputs.apply_augmentations(augmentations)
  File "/home/nstarli/Mask2Former/mask2former/data/dataset_mappers/mask_former_sceneflow_dataset_mapper.py", line 285, in apply_augmentations
    return AugmentationList(augmentations)(self)
  File "/home/nstarli/detectron2/detectron2/data/transforms/augmentation.py", line 264, in __call__
    tfm = x(aug_input)
  File "/home/nstarli/detectron2/detectron2/data/transforms/augmentation.py", line 164, in __call__
    args = _get_aug_input_args(self, aug_input)
  File "/home/nstarli/detectron2/detectron2/data/transforms/augmentation.py", line 70, in _get_aug_input_args
    raise AttributeError(
AttributeError: <class 'detectron2.data.transforms.augmentation_impl.RandomCrop_CategoryAreaConstraint'>.get_transform needs input attribute 'image', but it is not an attribute of <class 'mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper.AugStereoInput'>!

[01/19 00:26:44] d2.engine.hooks INFO: Total training time: 0:00:07 (0:00:00 on hooks)
[01/19 00:26:44] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 494M
[01/19 00:32:31] detectron2 INFO: Rank of current process: 0. World size: 4
[01/19 00:32:33] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/19 00:32:33] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml', dist_url='tcp://127.0.0.1:61200', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/19 00:32:33] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R101_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmaskformer2stereo_R50_bs16_90k.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcheckpoints/R-101.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbasic[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;242m# not used[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSyncBN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m[38;5;15m  [39m[38;5;242m# not used[39m

[01/19 00:32:33] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m192[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m614[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m716[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m819[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m921[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1126[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1228[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1331[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1433[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1638[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1740[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1843[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1945[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m101[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcheckpoints/R-101.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/sceneflow_testing[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1280[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1536[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1792[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/19 00:32:33] detectron2 INFO: Full config saved to ./work_dirs/sceneflow_testing/config.yaml
[01/19 00:32:33] d2.utils.env INFO: Using a generated random seed 33779582
[01/19 00:32:34] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_mask: 5.0
          cost_dice: 5.0
      losses: ['labels', 'masks']
      weight_dict: {'loss_ce': 2.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_ce_0': 2.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_ce_1': 2.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_ce_2': 2.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_ce_3': 2.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_ce_4': 2.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_ce_5': 2.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_ce_6': 2.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_ce_7': 2.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_ce_8': 2.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
)
[01/19 00:32:34] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 00:32:39] d2.data.build INFO: Using training sampler TrainingSampler
[01/19 00:32:40] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/19 00:32:40] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/19 00:32:40] fvcore.common.checkpoint INFO: [Checkpointer] Loading from checkpoints/R-101.pkl ...
[01/19 00:32:40] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[01/19 00:32:41] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
[01/19 00:32:41] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.pixel_decoder.adapter_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.adapter_1.weight[0m
[34msem_seg_head.pixel_decoder.input_proj.0.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.0.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.1.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.0.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.input_proj.2.1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.norm.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.layer_1.weight[0m
[34msem_seg_head.pixel_decoder.mask_features.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.0.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.1.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.2.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.3.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.4.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm1.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.norm2.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.attention_weights.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.output_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.sampling_offsets.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.encoder.layers.5.self_attn.value_proj.{bias, weight}[0m
[34msem_seg_head.pixel_decoder.transformer.level_embed[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[34msem_seg_head.predictor.decoder_norm.{bias, weight}[0m
[34msem_seg_head.predictor.level_embed.weight[0m
[34msem_seg_head.predictor.mask_embed.layers.0.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.1.{bias, weight}[0m
[34msem_seg_head.predictor.mask_embed.layers.2.{bias, weight}[0m
[34msem_seg_head.predictor.query_embed.weight[0m
[34msem_seg_head.predictor.query_feat.weight[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_cross_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear1.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.linear2.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_ffn_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.3.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.4.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.5.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.6.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.7.self_attn.{in_proj_bias, in_proj_weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.norm.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.out_proj.{bias, weight}[0m
[34msem_seg_head.predictor.transformer_self_attention_layers.8.self_attn.{in_proj_bias, in_proj_weight}[0m
[01/19 00:32:41] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
[01/19 00:32:41] d2.engine.train_loop INFO: Starting training from iteration 0
[01/19 00:33:45] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[192, 384], single_category_max_area=1.0, ignored_category=0)]
[01/19 00:33:46] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/19 00:33:46] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/19 00:36:49] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 24.2004102045382, 'error_1pix': 0.9517523794466253, 'error_3pix': 0.8907622516199543, 'mIoU': 0.008179204405485663, 'fwIoU': 0.024661789178283825, 'IoU-0': nan, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 0.0, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 1.5704072458532474, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5208333333333333, 'pACC': 1.5704072458532474, 'ACC-0': nan, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 0.0, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 100.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/19 00:36:49] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/19 00:36:49] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/19 00:36:49] d2.evaluation.testing INFO: copypaste: 24.2004,0.9518,0.8908,0.0082,0.0247,0.5208,1.5704
[01/19 00:36:49] d2.utils.events INFO:  eta: 18:17:28  iter: 19  total_loss: 143.7  loss_ce: 9.024  loss_mask: 0.5379  loss_dice: 4.92  loss_ce_0: 9.957  loss_mask_0: 0.5626  loss_dice_0: 4.797  loss_ce_1: 8.885  loss_mask_1: 0.5731  loss_dice_1: 4.827  loss_ce_2: 8.88  loss_mask_2: 0.5302  loss_dice_2: 4.86  loss_ce_3: 8.777  loss_mask_3: 0.527  loss_dice_3: 4.899  loss_ce_4: 8.72  loss_mask_4: 0.5286  loss_dice_4: 4.912  loss_ce_5: 8.969  loss_mask_5: 0.5365  loss_dice_5: 4.918  loss_ce_6: 8.861  loss_mask_6: 0.5322  loss_dice_6: 4.921  loss_ce_7: 8.84  loss_mask_7: 0.5364  loss_dice_7: 4.922  loss_ce_8: 8.905  loss_mask_8: 0.5386  loss_dice_8: 4.919  time: 2.2359  data_time: 0.7214  lr: 9.9943e-06  max_mem: 15485M
[01/19 00:37:02] d2.engine.hooks INFO: Overall training speed: 24 iterations in 0:00:54 (2.2539 s / it)
[01/19 00:37:02] d2.engine.hooks INFO: Total training time: 0:03:57 (0:03:03 on hooks)
[01/19 00:37:02] d2.utils.events INFO:  eta: 17:52:15  iter: 26  total_loss: 139.7  loss_ce: 8.517  loss_mask: 0.4825  loss_dice: 4.927  loss_ce_0: 9.953  loss_mask_0: 0.5513  loss_dice_0: 4.804  loss_ce_1: 8.237  loss_mask_1: 0.5353  loss_dice_1: 4.829  loss_ce_2: 8.362  loss_mask_2: 0.4656  loss_dice_2: 4.86  loss_ce_3: 8.412  loss_mask_3: 0.4635  loss_dice_3: 4.9  loss_ce_4: 8.522  loss_mask_4: 0.4692  loss_dice_4: 4.916  loss_ce_5: 8.48  loss_mask_5: 0.4834  loss_dice_5: 4.923  loss_ce_6: 8.506  loss_mask_6: 0.4807  loss_dice_6: 4.927  loss_ce_7: 8.504  loss_mask_7: 0.474  loss_dice_7: 4.927  loss_ce_8: 8.532  loss_mask_8: 0.4723  loss_dice_8: 4.926  time: 2.1685  data_time: 0.3537  lr: 9.9925e-06  max_mem: 15702M
