[01/28 20:50:15] detectron2 INFO: Rank of current process: 0. World size: 4
[01/28 20:50:19] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/28 20:50:19] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/28 20:50:19] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/28 20:50:19] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_nopretrain_instancenorm[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/28 20:50:19] detectron2 INFO: Full config saved to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_nopretrain_instancenorm/config.yaml
[01/28 20:50:19] d2.utils.env INFO: Using a generated random seed 19260903
[01/28 20:50:20] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 1.0
          cost_dice: 0.1
      losses: ['masks']
      weight_dict: {'loss_mask': 1.0, 'loss_mask_0': 1.0, 'loss_mask_1': 1.0, 'loss_mask_2': 1.0, 'loss_mask_3': 1.0, 'loss_mask_4': 1.0, 'loss_mask_5': 1.0, 'loss_mask_6': 1.0, 'loss_mask_7': 1.0, 'loss_mask_8': 1.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (upsampler): UpsampleMasks(
    (conv2d): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
[01/28 20:50:20] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/28 20:50:25] d2.data.build INFO: Using training sampler TrainingSampler
[01/28 20:50:26] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/28 20:50:26] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/28 20:50:26] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[01/28 20:50:26] d2.engine.train_loop INFO: Starting training from iteration 0
[01/28 20:51:30] d2.utils.events INFO:  eta: 1 day, 19:53:39  iter: 19  total_loss: 1.456e+05  loss_mask: 1.478e+04  loss_mask_0: 1.437e+04  loss_mask_1: 1.458e+04  loss_mask_2: 1.452e+04  loss_mask_3: 1.48e+04  loss_mask_4: 1.473e+04  loss_mask_5: 1.452e+04  loss_mask_6: 1.444e+04  loss_mask_7: 1.457e+04  loss_mask_8: 1.43e+04  time: 2.6634  data_time: 0.4543  lr: 9.9971e-05  max_mem: 27536M
[01/28 20:52:23] d2.utils.events INFO:  eta: 1 day, 19:48:00  iter: 39  total_loss: 5572  loss_mask: 236.9  loss_mask_0: 1926  loss_mask_1: 922.1  loss_mask_2: 221.5  loss_mask_3: 160.8  loss_mask_4: 96.44  loss_mask_5: 228.6  loss_mask_6: 607.8  loss_mask_7: 514  loss_mask_8: 658.2  time: 2.6490  data_time: 0.0586  lr: 9.9941e-05  max_mem: 27551M
[01/28 20:53:15] d2.utils.events INFO:  eta: 1 day, 19:45:30  iter: 59  total_loss: 483.6  loss_mask: 27.44  loss_mask_0: 245.6  loss_mask_1: 32.01  loss_mask_2: 29.28  loss_mask_3: 27.65  loss_mask_4: 26.78  loss_mask_5: 27.13  loss_mask_6: 27.03  loss_mask_7: 26.73  loss_mask_8: 26.93  time: 2.6433  data_time: 0.0538  lr: 9.9911e-05  max_mem: 27563M
[01/28 20:54:07] d2.utils.events INFO:  eta: 1 day, 19:37:11  iter: 79  total_loss: 368.2  loss_mask: 26.89  loss_mask_0: 117.5  loss_mask_1: 28.02  loss_mask_2: 26.62  loss_mask_3: 27.21  loss_mask_4: 26.8  loss_mask_5: 26.78  loss_mask_6: 26.84  loss_mask_7: 26.69  loss_mask_8: 26.4  time: 2.6335  data_time: 0.0614  lr: 9.9881e-05  max_mem: 27563M
[01/28 20:55:00] d2.utils.events INFO:  eta: 1 day, 19:34:16  iter: 99  total_loss: 341.9  loss_mask: 27.68  loss_mask_0: 83.07  loss_mask_1: 27.64  loss_mask_2: 27.98  loss_mask_3: 28.23  loss_mask_4: 28.36  loss_mask_5: 28.59  loss_mask_6: 28.5  loss_mask_7: 28.25  loss_mask_8: 28.19  time: 2.6280  data_time: 0.0530  lr: 9.9851e-05  max_mem: 27564M
[01/28 20:55:52] d2.utils.events INFO:  eta: 1 day, 19:27:46  iter: 119  total_loss: 302.5  loss_mask: 26.5  loss_mask_0: 61.65  loss_mask_1: 26.39  loss_mask_2: 26.34  loss_mask_3: 26.35  loss_mask_4: 26.46  loss_mask_5: 26.37  loss_mask_6: 26.66  loss_mask_7: 26.15  loss_mask_8: 26.36  time: 2.6235  data_time: 0.0533  lr: 9.9821e-05  max_mem: 27579M
[01/28 20:56:44] d2.utils.events INFO:  eta: 1 day, 19:26:54  iter: 139  total_loss: 286.7  loss_mask: 26.92  loss_mask_0: 47.07  loss_mask_1: 26.56  loss_mask_2: 26.46  loss_mask_3: 26.49  loss_mask_4: 26.45  loss_mask_5: 26.64  loss_mask_6: 27.04  loss_mask_7: 26.4  loss_mask_8: 26.76  time: 2.6217  data_time: 0.0662  lr: 9.9791e-05  max_mem: 27579M
[01/28 20:57:36] d2.utils.events INFO:  eta: 1 day, 19:22:29  iter: 159  total_loss: 276  loss_mask: 26.2  loss_mask_0: 36.43  loss_mask_1: 26.23  loss_mask_2: 26.15  loss_mask_3: 26.22  loss_mask_4: 26.22  loss_mask_5: 26.25  loss_mask_6: 26.42  loss_mask_7: 26.2  loss_mask_8: 26.3  time: 2.6191  data_time: 0.0509  lr: 9.9761e-05  max_mem: 27579M
[01/28 20:58:28] d2.utils.events INFO:  eta: 1 day, 19:20:17  iter: 179  total_loss: 274.8  loss_mask: 26.91  loss_mask_0: 32.71  loss_mask_1: 26.87  loss_mask_2: 26.77  loss_mask_3: 26.98  loss_mask_4: 26.71  loss_mask_5: 26.73  loss_mask_6: 26.87  loss_mask_7: 26.95  loss_mask_8: 26.94  time: 2.6156  data_time: 0.0531  lr: 9.9731e-05  max_mem: 27579M
[01/28 20:59:20] d2.utils.events INFO:  eta: 1 day, 19:18:23  iter: 199  total_loss: 268.3  loss_mask: 26.43  loss_mask_0: 30.52  loss_mask_1: 26.29  loss_mask_2: 26.5  loss_mask_3: 26.43  loss_mask_4: 26.62  loss_mask_5: 26.74  loss_mask_6: 26.22  loss_mask_7: 26.37  loss_mask_8: 26.5  time: 2.6147  data_time: 0.0586  lr: 9.9701e-05  max_mem: 27579M
[01/28 21:00:12] d2.utils.events INFO:  eta: 1 day, 19:17:09  iter: 219  total_loss: 260.2  loss_mask: 25.75  loss_mask_0: 28.98  loss_mask_1: 25.64  loss_mask_2: 25.59  loss_mask_3: 25.83  loss_mask_4: 25.78  loss_mask_5: 25.65  loss_mask_6: 25.63  loss_mask_7: 25.68  loss_mask_8: 25.7  time: 2.6139  data_time: 0.0597  lr: 9.9671e-05  max_mem: 27579M
[01/28 21:01:04] d2.utils.events INFO:  eta: 1 day, 19:16:07  iter: 239  total_loss: 250.5  loss_mask: 24.93  loss_mask_0: 28.35  loss_mask_1: 24.41  loss_mask_2: 24.55  loss_mask_3: 24.59  loss_mask_4: 24.87  loss_mask_5: 24.52  loss_mask_6: 24.57  loss_mask_7: 24.76  loss_mask_8: 24.94  time: 2.6123  data_time: 0.0519  lr: 9.9641e-05  max_mem: 27579M
[01/28 21:01:56] d2.utils.events INFO:  eta: 1 day, 19:15:16  iter: 259  total_loss: 246.9  loss_mask: 24.32  loss_mask_0: 25.85  loss_mask_1: 24.66  loss_mask_2: 24.61  loss_mask_3: 24.61  loss_mask_4: 24.65  loss_mask_5: 24.45  loss_mask_6: 24.37  loss_mask_7: 24.38  loss_mask_8: 24.3  time: 2.6124  data_time: 0.0644  lr: 9.9611e-05  max_mem: 27639M
[01/28 21:02:49] d2.utils.events INFO:  eta: 1 day, 19:14:23  iter: 279  total_loss: 261.1  loss_mask: 25.86  loss_mask_0: 27.99  loss_mask_1: 25.79  loss_mask_2: 25.92  loss_mask_3: 26  loss_mask_4: 25.93  loss_mask_5: 26.05  loss_mask_6: 25.99  loss_mask_7: 25.85  loss_mask_8: 25.86  time: 2.6122  data_time: 0.0553  lr: 9.9581e-05  max_mem: 27639M
[01/28 21:03:41] d2.utils.events INFO:  eta: 1 day, 19:13:31  iter: 299  total_loss: 250.4  loss_mask: 24.86  loss_mask_0: 27.41  loss_mask_1: 24.65  loss_mask_2: 24.75  loss_mask_3: 24.76  loss_mask_4: 24.76  loss_mask_5: 24.74  loss_mask_6: 24.7  loss_mask_7: 24.81  loss_mask_8: 24.78  time: 2.6115  data_time: 0.0576  lr: 9.9551e-05  max_mem: 27639M
[01/28 21:04:33] d2.utils.events INFO:  eta: 1 day, 19:12:39  iter: 319  total_loss: 242.6  loss_mask: 23.85  loss_mask_0: 25.95  loss_mask_1: 23.92  loss_mask_2: 23.88  loss_mask_3: 23.86  loss_mask_4: 23.92  loss_mask_5: 23.93  loss_mask_6: 24.05  loss_mask_7: 24.01  loss_mask_8: 23.85  time: 2.6106  data_time: 0.0579  lr: 9.9521e-05  max_mem: 27639M
[01/28 21:05:25] d2.utils.events INFO:  eta: 1 day, 19:11:47  iter: 339  total_loss: 252.8  loss_mask: 25.05  loss_mask_0: 26.9  loss_mask_1: 24.97  loss_mask_2: 25.2  loss_mask_3: 25.23  loss_mask_4: 25.15  loss_mask_5: 25.13  loss_mask_6: 25.07  loss_mask_7: 25.02  loss_mask_8: 25.04  time: 2.6111  data_time: 0.0582  lr: 9.9491e-05  max_mem: 27639M
[01/28 21:06:17] d2.utils.events INFO:  eta: 1 day, 19:11:19  iter: 359  total_loss: 249.2  loss_mask: 24.74  loss_mask_0: 27.4  loss_mask_1: 24.91  loss_mask_2: 25.01  loss_mask_3: 24.92  loss_mask_4: 24.87  loss_mask_5: 24.65  loss_mask_6: 24.66  loss_mask_7: 24.67  loss_mask_8: 24.64  time: 2.6113  data_time: 0.0614  lr: 9.9461e-05  max_mem: 27639M
[01/28 21:07:10] d2.utils.events INFO:  eta: 1 day, 19:10:27  iter: 379  total_loss: 243.9  loss_mask: 24.26  loss_mask_0: 26.17  loss_mask_1: 24.24  loss_mask_2: 24.19  loss_mask_3: 24.17  loss_mask_4: 24.2  loss_mask_5: 24.18  loss_mask_6: 24.12  loss_mask_7: 24.25  loss_mask_8: 24.23  time: 2.6116  data_time: 0.0595  lr: 9.9431e-05  max_mem: 27639M
[01/28 21:08:02] d2.utils.events INFO:  eta: 1 day, 19:09:10  iter: 399  total_loss: 244.7  loss_mask: 24.28  loss_mask_0: 26.28  loss_mask_1: 24.16  loss_mask_2: 24.23  loss_mask_3: 24.13  loss_mask_4: 24.2  loss_mask_5: 24.22  loss_mask_6: 24.15  loss_mask_7: 24.29  loss_mask_8: 24.26  time: 2.6118  data_time: 0.0569  lr: 9.9401e-05  max_mem: 27639M
[01/28 21:08:54] d2.utils.events INFO:  eta: 1 day, 19:08:14  iter: 419  total_loss: 234.9  loss_mask: 23.3  loss_mask_0: 25.59  loss_mask_1: 23.18  loss_mask_2: 23.19  loss_mask_3: 23.24  loss_mask_4: 23.25  loss_mask_5: 23.19  loss_mask_6: 23.2  loss_mask_7: 23.39  loss_mask_8: 23.27  time: 2.6116  data_time: 0.0622  lr: 9.9371e-05  max_mem: 27639M
[01/28 21:09:46] d2.utils.events INFO:  eta: 1 day, 19:07:12  iter: 439  total_loss: 238  loss_mask: 23.57  loss_mask_0: 25.43  loss_mask_1: 23.48  loss_mask_2: 23.49  loss_mask_3: 23.43  loss_mask_4: 23.44  loss_mask_5: 23.48  loss_mask_6: 23.53  loss_mask_7: 23.55  loss_mask_8: 23.59  time: 2.6111  data_time: 0.0630  lr: 9.9341e-05  max_mem: 27639M
[01/28 21:10:38] d2.utils.events INFO:  eta: 1 day, 19:06:07  iter: 459  total_loss: 244.1  loss_mask: 23.83  loss_mask_0: 27.82  loss_mask_1: 24.03  loss_mask_2: 23.99  loss_mask_3: 23.69  loss_mask_4: 23.84  loss_mask_5: 23.99  loss_mask_6: 23.75  loss_mask_7: 23.95  loss_mask_8: 24.08  time: 2.6106  data_time: 0.0619  lr: 9.9311e-05  max_mem: 27639M
[01/28 21:11:31] d2.utils.events INFO:  eta: 1 day, 19:05:08  iter: 479  total_loss: 240.4  loss_mask: 23.68  loss_mask_0: 26.68  loss_mask_1: 23.62  loss_mask_2: 23.79  loss_mask_3: 23.66  loss_mask_4: 23.71  loss_mask_5: 23.68  loss_mask_6: 23.61  loss_mask_7: 23.72  loss_mask_8: 23.72  time: 2.6104  data_time: 0.0592  lr: 9.9281e-05  max_mem: 27639M
[01/28 21:12:23] d2.utils.events INFO:  eta: 1 day, 19:04:20  iter: 499  total_loss: 239.3  loss_mask: 23.53  loss_mask_0: 27.37  loss_mask_1: 23.36  loss_mask_2: 23.41  loss_mask_3: 23.34  loss_mask_4: 23.35  loss_mask_5: 23.4  loss_mask_6: 23.27  loss_mask_7: 23.49  loss_mask_8: 23.51  time: 2.6104  data_time: 0.0583  lr: 9.9251e-05  max_mem: 27639M
[01/28 21:13:15] d2.utils.events INFO:  eta: 1 day, 19:03:18  iter: 519  total_loss: 239.3  loss_mask: 23.71  loss_mask_0: 27.38  loss_mask_1: 23.58  loss_mask_2: 23.68  loss_mask_3: 23.62  loss_mask_4: 23.56  loss_mask_5: 23.62  loss_mask_6: 23.56  loss_mask_7: 23.7  loss_mask_8: 23.81  time: 2.6101  data_time: 0.0549  lr: 9.9221e-05  max_mem: 27639M
[01/28 21:14:07] d2.utils.events INFO:  eta: 1 day, 19:02:38  iter: 539  total_loss: 233.5  loss_mask: 23.16  loss_mask_0: 26.92  loss_mask_1: 23.08  loss_mask_2: 22.91  loss_mask_3: 23.04  loss_mask_4: 23.05  loss_mask_5: 22.98  loss_mask_6: 23.08  loss_mask_7: 23.18  loss_mask_8: 23.07  time: 2.6102  data_time: 0.0579  lr: 9.9191e-05  max_mem: 27639M
[01/28 21:14:59] d2.utils.events INFO:  eta: 1 day, 19:01:46  iter: 559  total_loss: 235.3  loss_mask: 23.03  loss_mask_0: 27.16  loss_mask_1: 23.16  loss_mask_2: 23.11  loss_mask_3: 23.02  loss_mask_4: 23.08  loss_mask_5: 23.16  loss_mask_6: 22.99  loss_mask_7: 23.03  loss_mask_8: 23.05  time: 2.6102  data_time: 0.0572  lr: 9.9161e-05  max_mem: 27639M
[01/28 21:15:51] d2.utils.events INFO:  eta: 1 day, 19:00:30  iter: 579  total_loss: 236.6  loss_mask: 23.13  loss_mask_0: 26.6  loss_mask_1: 23.14  loss_mask_2: 23.12  loss_mask_3: 23.1  loss_mask_4: 23.19  loss_mask_5: 23.15  loss_mask_6: 23.22  loss_mask_7: 23.22  loss_mask_8: 23.17  time: 2.6098  data_time: 0.0634  lr: 9.9131e-05  max_mem: 27639M
[01/28 21:16:44] d2.utils.events INFO:  eta: 1 day, 18:59:19  iter: 599  total_loss: 231.5  loss_mask: 22.85  loss_mask_0: 26.23  loss_mask_1: 22.78  loss_mask_2: 22.8  loss_mask_3: 22.84  loss_mask_4: 22.81  loss_mask_5: 22.76  loss_mask_6: 22.85  loss_mask_7: 22.88  loss_mask_8: 22.81  time: 2.6095  data_time: 0.0546  lr: 9.9101e-05  max_mem: 27639M
[01/28 21:17:35] d2.utils.events INFO:  eta: 1 day, 18:58:20  iter: 619  total_loss: 223.7  loss_mask: 22.07  loss_mask_0: 25.83  loss_mask_1: 21.97  loss_mask_2: 22.02  loss_mask_3: 22.07  loss_mask_4: 22.01  loss_mask_5: 22.1  loss_mask_6: 22.02  loss_mask_7: 22.08  loss_mask_8: 22.08  time: 2.6089  data_time: 0.0584  lr: 9.9071e-05  max_mem: 27639M
[01/28 21:18:27] d2.utils.events INFO:  eta: 1 day, 18:57:02  iter: 639  total_loss: 228.1  loss_mask: 22.39  loss_mask_0: 26.61  loss_mask_1: 22.3  loss_mask_2: 22.34  loss_mask_3: 22.39  loss_mask_4: 22.42  loss_mask_5: 22.37  loss_mask_6: 22.43  loss_mask_7: 22.42  loss_mask_8: 22.39  time: 2.6086  data_time: 0.0693  lr: 9.9041e-05  max_mem: 27639M
[01/28 21:19:20] d2.utils.events INFO:  eta: 1 day, 18:56:05  iter: 659  total_loss: 217.2  loss_mask: 21.32  loss_mask_0: 25.64  loss_mask_1: 21.35  loss_mask_2: 21.39  loss_mask_3: 21.39  loss_mask_4: 21.4  loss_mask_5: 21.36  loss_mask_6: 21.3  loss_mask_7: 21.33  loss_mask_8: 21.34  time: 2.6085  data_time: 0.0555  lr: 9.9011e-05  max_mem: 27639M
[01/28 21:20:12] d2.utils.events INFO:  eta: 1 day, 18:55:07  iter: 679  total_loss: 233.5  loss_mask: 22.89  loss_mask_0: 26.94  loss_mask_1: 22.9  loss_mask_2: 22.86  loss_mask_3: 22.9  loss_mask_4: 22.9  loss_mask_5: 22.97  loss_mask_6: 22.92  loss_mask_7: 22.9  loss_mask_8: 22.91  time: 2.6086  data_time: 0.0704  lr: 9.8981e-05  max_mem: 27639M
[01/28 21:21:04] d2.utils.events INFO:  eta: 1 day, 18:54:15  iter: 699  total_loss: 229.6  loss_mask: 22.59  loss_mask_0: 27.26  loss_mask_1: 22.55  loss_mask_2: 22.57  loss_mask_3: 22.58  loss_mask_4: 22.57  loss_mask_5: 22.61  loss_mask_6: 22.57  loss_mask_7: 22.53  loss_mask_8: 22.56  time: 2.6085  data_time: 0.0613  lr: 9.8951e-05  max_mem: 27639M
[01/28 21:21:56] d2.utils.events INFO:  eta: 1 day, 18:53:33  iter: 719  total_loss: 229.9  loss_mask: 22.6  loss_mask_0: 26.23  loss_mask_1: 22.36  loss_mask_2: 22.5  loss_mask_3: 22.51  loss_mask_4: 22.48  loss_mask_5: 22.57  loss_mask_6: 22.48  loss_mask_7: 22.49  loss_mask_8: 22.53  time: 2.6088  data_time: 0.0632  lr: 9.8921e-05  max_mem: 27639M
[01/28 21:22:49] d2.utils.events INFO:  eta: 1 day, 18:52:51  iter: 739  total_loss: 217.5  loss_mask: 21.13  loss_mask_0: 26  loss_mask_1: 21  loss_mask_2: 21.07  loss_mask_3: 21.12  loss_mask_4: 21.12  loss_mask_5: 21  loss_mask_6: 21.11  loss_mask_7: 21.23  loss_mask_8: 21.14  time: 2.6088  data_time: 0.0628  lr: 9.8891e-05  max_mem: 27639M
[01/28 21:23:41] d2.utils.events INFO:  eta: 1 day, 18:51:59  iter: 759  total_loss: 235.7  loss_mask: 23.19  loss_mask_0: 27.25  loss_mask_1: 23.18  loss_mask_2: 23.12  loss_mask_3: 23.15  loss_mask_4: 23.22  loss_mask_5: 23.21  loss_mask_6: 23.18  loss_mask_7: 23.22  loss_mask_8: 23.2  time: 2.6087  data_time: 0.0588  lr: 9.8861e-05  max_mem: 27639M
[01/28 21:24:33] d2.utils.events INFO:  eta: 1 day, 18:51:16  iter: 779  total_loss: 226.8  loss_mask: 22.11  loss_mask_0: 26.93  loss_mask_1: 22.24  loss_mask_2: 22.19  loss_mask_3: 22.16  loss_mask_4: 22.22  loss_mask_5: 22.21  loss_mask_6: 22.09  loss_mask_7: 22.18  loss_mask_8: 22.21  time: 2.6086  data_time: 0.0588  lr: 9.8831e-05  max_mem: 27639M
[01/28 21:25:25] d2.utils.events INFO:  eta: 1 day, 18:50:24  iter: 799  total_loss: 226.3  loss_mask: 21.94  loss_mask_0: 27.23  loss_mask_1: 21.7  loss_mask_2: 21.73  loss_mask_3: 21.86  loss_mask_4: 21.79  loss_mask_5: 21.69  loss_mask_6: 21.69  loss_mask_7: 21.98  loss_mask_8: 21.81  time: 2.6087  data_time: 0.0541  lr: 9.8801e-05  max_mem: 27639M
[01/28 21:26:18] d2.utils.events INFO:  eta: 1 day, 18:49:40  iter: 819  total_loss: 230.3  loss_mask: 22.55  loss_mask_0: 27.06  loss_mask_1: 22.56  loss_mask_2: 22.51  loss_mask_3: 22.5  loss_mask_4: 22.52  loss_mask_5: 22.51  loss_mask_6: 22.49  loss_mask_7: 22.55  loss_mask_8: 22.6  time: 2.6091  data_time: 0.0605  lr: 9.8771e-05  max_mem: 27639M
[01/28 21:27:10] d2.utils.events INFO:  eta: 1 day, 18:48:40  iter: 839  total_loss: 223.2  loss_mask: 21.98  loss_mask_0: 27.32  loss_mask_1: 21.9  loss_mask_2: 21.87  loss_mask_3: 21.89  loss_mask_4: 21.9  loss_mask_5: 21.89  loss_mask_6: 21.91  loss_mask_7: 22.13  loss_mask_8: 21.98  time: 2.6087  data_time: 0.0562  lr: 9.8741e-05  max_mem: 27639M
[01/28 21:28:02] d2.utils.events INFO:  eta: 1 day, 18:47:55  iter: 859  total_loss: 225.6  loss_mask: 21.95  loss_mask_0: 27.26  loss_mask_1: 21.93  loss_mask_2: 22.04  loss_mask_3: 21.92  loss_mask_4: 21.97  loss_mask_5: 21.93  loss_mask_6: 21.91  loss_mask_7: 22  loss_mask_8: 21.98  time: 2.6089  data_time: 0.0600  lr: 9.8711e-05  max_mem: 27639M
[01/28 21:28:54] d2.utils.events INFO:  eta: 1 day, 18:47:09  iter: 879  total_loss: 220.2  loss_mask: 21.44  loss_mask_0: 26.44  loss_mask_1: 21.42  loss_mask_2: 21.57  loss_mask_3: 21.64  loss_mask_4: 21.54  loss_mask_5: 21.59  loss_mask_6: 21.45  loss_mask_7: 21.47  loss_mask_8: 21.49  time: 2.6088  data_time: 0.0518  lr: 9.8681e-05  max_mem: 27639M
[01/28 21:29:46] d2.utils.events INFO:  eta: 1 day, 18:46:11  iter: 899  total_loss: 219.9  loss_mask: 21.49  loss_mask_0: 27.04  loss_mask_1: 21.48  loss_mask_2: 21.49  loss_mask_3: 21.49  loss_mask_4: 21.5  loss_mask_5: 21.52  loss_mask_6: 21.49  loss_mask_7: 21.48  loss_mask_8: 21.49  time: 2.6089  data_time: 0.0590  lr: 9.865e-05  max_mem: 27639M
[01/28 21:30:38] d2.utils.events INFO:  eta: 1 day, 18:45:16  iter: 919  total_loss: 224.7  loss_mask: 22.15  loss_mask_0: 27.62  loss_mask_1: 21.9  loss_mask_2: 22.03  loss_mask_3: 22.06  loss_mask_4: 22.08  loss_mask_5: 22.06  loss_mask_6: 22.04  loss_mask_7: 22.12  loss_mask_8: 22.23  time: 2.6088  data_time: 0.0613  lr: 9.862e-05  max_mem: 27639M
[01/28 21:31:31] d2.utils.events INFO:  eta: 1 day, 18:44:16  iter: 939  total_loss: 214.7  loss_mask: 20.88  loss_mask_0: 26.55  loss_mask_1: 20.93  loss_mask_2: 20.95  loss_mask_3: 20.9  loss_mask_4: 20.88  loss_mask_5: 20.9  loss_mask_6: 20.9  loss_mask_7: 20.89  loss_mask_8: 20.88  time: 2.6087  data_time: 0.0632  lr: 9.859e-05  max_mem: 27639M
[01/28 21:32:23] d2.utils.events INFO:  eta: 1 day, 18:43:32  iter: 959  total_loss: 225.7  loss_mask: 22.08  loss_mask_0: 26.53  loss_mask_1: 22.11  loss_mask_2: 22.13  loss_mask_3: 22.06  loss_mask_4: 22.22  loss_mask_5: 22.08  loss_mask_6: 22.04  loss_mask_7: 22.22  loss_mask_8: 22.11  time: 2.6087  data_time: 0.0614  lr: 9.856e-05  max_mem: 27639M
[01/28 21:33:15] d2.utils.events INFO:  eta: 1 day, 18:42:40  iter: 979  total_loss: 228.9  loss_mask: 22.37  loss_mask_0: 27.41  loss_mask_1: 22.28  loss_mask_2: 22.33  loss_mask_3: 22.39  loss_mask_4: 22.29  loss_mask_5: 22.32  loss_mask_6: 22.35  loss_mask_7: 22.42  loss_mask_8: 22.33  time: 2.6088  data_time: 0.0635  lr: 9.853e-05  max_mem: 27639M
[01/28 21:34:07] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/28 21:34:08] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/28 21:34:08] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/28 21:44:22] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 23.4529427951654, 'error_1pix': 0.9476792069641655, 'error_3pix': 0.8789837536682151, 'mIoU': 0.22603012255576252, 'fwIoU': 0.6128657518558576, 'IoU-0': 0.0, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.7812076668316383, 'IoU-10': 1.015582274733678, 'IoU-11': 0.3240044284152024, 'IoU-12': 0.6753494746691601, 'IoU-13': 1.0391822840492493, 'IoU-14': 1.0703188942300206, 'IoU-15': 1.0839523574436754, 'IoU-16': 0.9798881477222733, 'IoU-17': 0.8822337897568764, 'IoU-18': 1.148310402648572, 'IoU-19': 1.3324885207021597, 'IoU-20': 1.0482403042093509, 'IoU-21': 1.1020376963696141, 'IoU-22': 1.2695255844731927, 'IoU-23': 1.2973627890569712, 'IoU-24': 0.9175772456043662, 'IoU-25': 1.1666496619749323, 'IoU-26': 1.3316832135190986, 'IoU-27': 1.221602141861073, 'IoU-28': 1.3460959912065158, 'IoU-29': 1.3635080076730512, 'IoU-30': 1.4342255981831495, 'IoU-31': 1.2370541939281205, 'IoU-32': 1.3386220163601237, 'IoU-33': 1.1256922681694148, 'IoU-34': 1.2449757587494048, 'IoU-35': 1.1750201533075308, 'IoU-36': 0.9415020574775708, 'IoU-37': 0.9360070798177944, 'IoU-38': 0.7840865529791026, 'IoU-39': 0.8913885850504732, 'IoU-40': 0.8713810061316628, 'IoU-41': 0.7432337388654925, 'IoU-42': 0.6918878530061198, 'IoU-43': 0.6719780516276211, 'IoU-44': 0.6911339186287658, 'IoU-45': 0.46454141010266226, 'IoU-46': 0.3874884019178795, 'IoU-47': 0.5654130194684865, 'IoU-48': 0.49686738598232977, 'IoU-49': 0.3841197403373004, 'IoU-50': 0.35185764895915544, 'IoU-51': 0.3833256529818025, 'IoU-52': 0.35966631161672674, 'IoU-53': 0.2443449835348796, 'IoU-54': 0.22079432584311529, 'IoU-55': 0.06642836140298598, 'IoU-56': 0.20028491975461155, 'IoU-57': 0.18655896720182152, 'IoU-58': 0.12137828630155345, 'IoU-59': 0.16539032583159763, 'IoU-60': 0.07073304277122558, 'IoU-61': 0.08807632603060689, 'IoU-62': 0.058488331492542386, 'IoU-63': 0.06565492394297127, 'IoU-64': 0.1470313537805355, 'IoU-65': 0.030909521130196665, 'IoU-66': 0.050482017626940164, 'IoU-67': 0.11638879910775907, 'IoU-68': 0.054776878004155025, 'IoU-69': 0.14094425661308688, 'IoU-70': 0.028769369689264083, 'IoU-71': 0.06498221462613818, 'IoU-72': 0.044928570126176064, 'IoU-73': 0.0465961409905201, 'IoU-74': 0.05616281687269672, 'IoU-75': 0.0, 'IoU-76': 0.2054778873043138, 'IoU-77': 0.06849346226025738, 'IoU-78': 0.0, 'IoU-79': 0.011460171063229475, 'IoU-80': 0.05670857588913746, 'IoU-81': 0.03548148851605199, 'IoU-82': 0.05534201006233301, 'IoU-83': 0.012091767358605513, 'IoU-84': 0.0, 'IoU-85': 0.01635729396634241, 'IoU-86': 0.029732384945559884, 'IoU-87': 8.05346858865379e-05, 'IoU-88': 0.025915048690817344, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 5.2537509154660967e-05, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.007619487449875333, 'IoU-98': 0.0, 'IoU-99': 0.07653078679859718, 'IoU-100': 0.0823543002038906, 'IoU-101': 0.0263895105827036, 'IoU-102': 0.0165507654362035, 'IoU-103': 0.0, 'IoU-104': 0.04255269005013362, 'IoU-105': 0.0, 'IoU-106': 0.016248937014336183, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.594480725366871, 'pACC': 1.675221505353561, 'ACC-0': 0.0, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 1.3336755627790267, 'ACC-10': 1.3952702576334333, 'ACC-11': 0.3682539764993073, 'ACC-12': 0.8340483615683433, 'ACC-13': 1.4280333047029292, 'ACC-14': 1.6819157028569276, 'ACC-15': 2.173078456633113, 'ACC-16': 2.209321321953077, 'ACC-17': 2.333888858937907, 'ACC-18': 2.6986407941438206, 'ACC-19': 4.2829489392964435, 'ACC-20': 3.1237837279925587, 'ACC-21': 3.3563765983294442, 'ACC-22': 4.565219758213796, 'ACC-23': 5.166168247064619, 'ACC-24': 3.9661905766663943, 'ACC-25': 5.351425987414774, 'ACC-26': 5.872031735484915, 'ACC-27': 5.017036738171626, 'ACC-28': 5.614390767294385, 'ACC-29': 4.981976828679948, 'ACC-30': 5.922826290545603, 'ACC-31': 3.7107284279741575, 'ACC-32': 3.9159480591981657, 'ACC-33': 3.124192768329699, 'ACC-34': 3.597697908286775, 'ACC-35': 3.38136375448224, 'ACC-36': 1.9927013595878464, 'ACC-37': 1.9797847078810196, 'ACC-38': 1.5544816579313903, 'ACC-39': 1.7954381206304406, 'ACC-40': 1.7681431400767045, 'ACC-41': 1.4629521958826115, 'ACC-42': 1.3671265398852268, 'ACC-43': 1.1588115195386248, 'ACC-44': 1.209414434387661, 'ACC-45': 0.7163683699939535, 'ACC-46': 0.6412620550163477, 'ACC-47': 0.8602268352517574, 'ACC-48': 0.7552040890541462, 'ACC-49': 0.5717828937591916, 'ACC-50': 0.5560635962505938, 'ACC-51': 0.6406334780113192, 'ACC-52': 0.49430667249204063, 'ACC-53': 0.34001550348365833, 'ACC-54': 0.2970780879450626, 'ACC-55': 0.0745298994784268, 'ACC-56': 0.2591725677213654, 'ACC-57': 0.22999181960472612, 'ACC-58': 0.14734986355955376, 'ACC-59': 0.20335514774500116, 'ACC-60': 0.08225275941430983, 'ACC-61': 0.1184612590281636, 'ACC-62': 0.06907529706846646, 'ACC-63': 0.08757066523823648, 'ACC-64': 0.20471450039173233, 'ACC-65': 0.032484505810661035, 'ACC-66': 0.06115008354350374, 'ACC-67': 0.12900616897702646, 'ACC-68': 0.05780838790107873, 'ACC-69': 0.17938703568537318, 'ACC-70': 0.031919053111864104, 'ACC-71': 0.08349931942486577, 'ACC-72': 0.05268622928298619, 'ACC-73': 0.051910019097760114, 'ACC-74': 0.05930097828096224, 'ACC-75': 0.0, 'ACC-76': 0.2838628477407258, 'ACC-77': 0.07231997456956789, 'ACC-78': 0.0, 'ACC-79': 0.013443775003110336, 'ACC-80': 0.06317432342489095, 'ACC-81': 0.037506218719425784, 'ACC-82': 0.06821574040799831, 'ACC-83': 0.012787867530157496, 'ACC-84': 0.0, 'ACC-85': 0.01733577191401272, 'ACC-86': 0.03885954297050789, 'ACC-87': 8.564249982137421e-05, 'ACC-88': 0.029284431767651033, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 6.081970363774812e-05, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.008971329241106014, 'ACC-98': 0.0, 'ACC-99': 0.0841171021137652, 'ACC-100': 0.09958261261633852, 'ACC-101': 0.032261753079159725, 'ACC-102': 0.020434979610330768, 'ACC-103': 0.0, 'ACC-104': 0.04795750227490716, 'ACC-105': 0.0, 'ACC-106': 0.0206632320598961, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/28 21:44:22] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/28 21:44:22] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/28 21:44:22] d2.evaluation.testing INFO: copypaste: 23.4529,0.9477,0.8790,0.2260,0.6129,0.5945,1.6752
[01/28 21:44:22] d2.utils.events INFO:  eta: 1 day, 18:41:50  iter: 999  total_loss: 209.2  loss_mask: 20.23  loss_mask_0: 25.54  loss_mask_1: 20.15  loss_mask_2: 20.19  loss_mask_3: 20.25  loss_mask_4: 20.24  loss_mask_5: 20.18  loss_mask_6: 20.22  loss_mask_7: 20.21  loss_mask_8: 20.25  time: 2.6087  data_time: 0.0619  lr: 9.85e-05  max_mem: 27639M
[01/28 21:45:14] d2.utils.events INFO:  eta: 1 day, 18:40:31  iter: 1019  total_loss: 220.9  loss_mask: 21.62  loss_mask_0: 26.37  loss_mask_1: 21.58  loss_mask_2: 21.55  loss_mask_3: 21.62  loss_mask_4: 21.62  loss_mask_5: 21.59  loss_mask_6: 21.62  loss_mask_7: 21.61  loss_mask_8: 21.6  time: 2.6087  data_time: 0.0596  lr: 9.847e-05  max_mem: 27639M
[01/28 21:46:06] d2.utils.events INFO:  eta: 1 day, 18:38:54  iter: 1039  total_loss: 218.3  loss_mask: 21.32  loss_mask_0: 26.41  loss_mask_1: 21.32  loss_mask_2: 21.33  loss_mask_3: 21.32  loss_mask_4: 21.37  loss_mask_5: 21.36  loss_mask_6: 21.37  loss_mask_7: 21.39  loss_mask_8: 21.38  time: 2.6086  data_time: 0.0562  lr: 9.844e-05  max_mem: 27639M
[01/28 21:46:58] d2.utils.events INFO:  eta: 1 day, 18:37:26  iter: 1059  total_loss: 221.8  loss_mask: 21.59  loss_mask_0: 25.79  loss_mask_1: 21.45  loss_mask_2: 21.51  loss_mask_3: 21.5  loss_mask_4: 21.47  loss_mask_5: 21.49  loss_mask_6: 21.43  loss_mask_7: 21.51  loss_mask_8: 21.57  time: 2.6085  data_time: 0.0579  lr: 9.841e-05  max_mem: 27639M
[01/28 21:47:50] d2.utils.events INFO:  eta: 1 day, 18:36:40  iter: 1079  total_loss: 219.4  loss_mask: 21.56  loss_mask_0: 25.77  loss_mask_1: 21.41  loss_mask_2: 21.46  loss_mask_3: 21.5  loss_mask_4: 21.52  loss_mask_5: 21.49  loss_mask_6: 21.45  loss_mask_7: 21.56  loss_mask_8: 21.54  time: 2.6087  data_time: 0.0568  lr: 9.838e-05  max_mem: 27639M
[01/28 21:48:43] d2.utils.events INFO:  eta: 1 day, 18:35:38  iter: 1099  total_loss: 229.7  loss_mask: 22.52  loss_mask_0: 27.27  loss_mask_1: 22.41  loss_mask_2: 22.49  loss_mask_3: 22.56  loss_mask_4: 22.43  loss_mask_5: 22.4  loss_mask_6: 22.38  loss_mask_7: 22.56  loss_mask_8: 22.56  time: 2.6086  data_time: 0.0665  lr: 9.835e-05  max_mem: 27639M
[01/28 21:49:35] d2.utils.events INFO:  eta: 1 day, 18:34:46  iter: 1119  total_loss: 205.3  loss_mask: 20.16  loss_mask_0: 24.99  loss_mask_1: 20.12  loss_mask_2: 20.21  loss_mask_3: 20.2  loss_mask_4: 20.27  loss_mask_5: 20.16  loss_mask_6: 20.11  loss_mask_7: 20.19  loss_mask_8: 20.21  time: 2.6084  data_time: 0.0662  lr: 9.832e-05  max_mem: 27639M
[01/28 21:50:27] d2.utils.events INFO:  eta: 1 day, 18:33:58  iter: 1139  total_loss: 223.7  loss_mask: 21.97  loss_mask_0: 26.25  loss_mask_1: 21.92  loss_mask_2: 22  loss_mask_3: 21.84  loss_mask_4: 21.97  loss_mask_5: 21.98  loss_mask_6: 21.91  loss_mask_7: 22.07  loss_mask_8: 22.07  time: 2.6083  data_time: 0.0642  lr: 9.829e-05  max_mem: 27639M
[01/28 21:51:19] d2.utils.events INFO:  eta: 1 day, 18:33:15  iter: 1159  total_loss: 213.4  loss_mask: 20.89  loss_mask_0: 26.06  loss_mask_1: 20.86  loss_mask_2: 20.89  loss_mask_3: 20.92  loss_mask_4: 20.88  loss_mask_5: 20.88  loss_mask_6: 20.97  loss_mask_7: 20.95  loss_mask_8: 20.85  time: 2.6082  data_time: 0.0623  lr: 9.826e-05  max_mem: 27639M
[01/28 21:52:11] d2.utils.events INFO:  eta: 1 day, 18:32:58  iter: 1179  total_loss: 218.8  loss_mask: 21.35  loss_mask_0: 26.58  loss_mask_1: 21.26  loss_mask_2: 21.39  loss_mask_3: 21.3  loss_mask_4: 21.34  loss_mask_5: 21.4  loss_mask_6: 21.38  loss_mask_7: 21.4  loss_mask_8: 21.39  time: 2.6082  data_time: 0.0602  lr: 9.823e-05  max_mem: 27639M
[01/28 21:53:03] d2.utils.events INFO:  eta: 1 day, 18:31:51  iter: 1199  total_loss: 214.3  loss_mask: 20.81  loss_mask_0: 26.47  loss_mask_1: 20.69  loss_mask_2: 20.76  loss_mask_3: 20.75  loss_mask_4: 20.68  loss_mask_5: 20.72  loss_mask_6: 20.74  loss_mask_7: 20.81  loss_mask_8: 20.82  time: 2.6083  data_time: 0.0564  lr: 9.82e-05  max_mem: 27639M
[01/28 21:53:56] d2.utils.events INFO:  eta: 1 day, 18:31:19  iter: 1219  total_loss: 238.9  loss_mask: 23.12  loss_mask_0: 28.69  loss_mask_1: 23.1  loss_mask_2: 23.13  loss_mask_3: 23.07  loss_mask_4: 23.1  loss_mask_5: 23.2  loss_mask_6: 23.15  loss_mask_7: 23.13  loss_mask_8: 23.14  time: 2.6084  data_time: 0.0603  lr: 9.817e-05  max_mem: 27639M
[01/28 21:54:48] d2.utils.events INFO:  eta: 1 day, 18:30:38  iter: 1239  total_loss: 219.8  loss_mask: 21.41  loss_mask_0: 25.62  loss_mask_1: 21.51  loss_mask_2: 21.56  loss_mask_3: 21.43  loss_mask_4: 21.47  loss_mask_5: 21.54  loss_mask_6: 21.42  loss_mask_7: 21.4  loss_mask_8: 21.41  time: 2.6083  data_time: 0.0614  lr: 9.814e-05  max_mem: 27639M
[01/28 21:55:40] d2.utils.events INFO:  eta: 1 day, 18:29:35  iter: 1259  total_loss: 222.5  loss_mask: 21.8  loss_mask_0: 27.12  loss_mask_1: 21.63  loss_mask_2: 21.75  loss_mask_3: 21.92  loss_mask_4: 21.86  loss_mask_5: 21.68  loss_mask_6: 21.76  loss_mask_7: 21.87  loss_mask_8: 21.76  time: 2.6084  data_time: 0.0620  lr: 9.811e-05  max_mem: 27639M
[01/28 21:56:32] d2.utils.events INFO:  eta: 1 day, 18:28:29  iter: 1279  total_loss: 232.9  loss_mask: 22.76  loss_mask_0: 28.3  loss_mask_1: 22.66  loss_mask_2: 22.65  loss_mask_3: 22.69  loss_mask_4: 22.66  loss_mask_5: 22.7  loss_mask_6: 22.63  loss_mask_7: 22.7  loss_mask_8: 22.75  time: 2.6084  data_time: 0.0672  lr: 9.8079e-05  max_mem: 27639M
[01/28 21:57:25] d2.utils.events INFO:  eta: 1 day, 18:27:37  iter: 1299  total_loss: 222.3  loss_mask: 21.63  loss_mask_0: 27.03  loss_mask_1: 21.79  loss_mask_2: 21.64  loss_mask_3: 21.59  loss_mask_4: 21.75  loss_mask_5: 21.89  loss_mask_6: 21.69  loss_mask_7: 21.63  loss_mask_8: 21.65  time: 2.6084  data_time: 0.0546  lr: 9.8049e-05  max_mem: 27639M
[01/28 21:58:17] d2.utils.events INFO:  eta: 1 day, 18:26:59  iter: 1319  total_loss: 212.8  loss_mask: 20.87  loss_mask_0: 25.81  loss_mask_1: 20.68  loss_mask_2: 20.74  loss_mask_3: 20.88  loss_mask_4: 20.8  loss_mask_5: 20.68  loss_mask_6: 20.68  loss_mask_7: 20.84  loss_mask_8: 20.84  time: 2.6084  data_time: 0.0550  lr: 9.8019e-05  max_mem: 27639M
[01/28 21:59:09] d2.utils.events INFO:  eta: 1 day, 18:26:40  iter: 1339  total_loss: 219.6  loss_mask: 21.66  loss_mask_0: 26.5  loss_mask_1: 21.66  loss_mask_2: 21.64  loss_mask_3: 21.66  loss_mask_4: 21.62  loss_mask_5: 21.66  loss_mask_6: 21.69  loss_mask_7: 21.69  loss_mask_8: 21.66  time: 2.6085  data_time: 0.0556  lr: 9.7989e-05  max_mem: 27639M
[01/28 22:00:01] d2.utils.events INFO:  eta: 1 day, 18:25:09  iter: 1359  total_loss: 212.7  loss_mask: 20.79  loss_mask_0: 26.35  loss_mask_1: 20.82  loss_mask_2: 20.76  loss_mask_3: 20.76  loss_mask_4: 20.8  loss_mask_5: 20.75  loss_mask_6: 20.83  loss_mask_7: 20.79  loss_mask_8: 20.75  time: 2.6083  data_time: 0.0572  lr: 9.7959e-05  max_mem: 27639M
[01/28 22:00:53] d2.utils.events INFO:  eta: 1 day, 18:24:08  iter: 1379  total_loss: 205.4  loss_mask: 19.84  loss_mask_0: 25.53  loss_mask_1: 19.74  loss_mask_2: 19.84  loss_mask_3: 19.72  loss_mask_4: 19.76  loss_mask_5: 19.75  loss_mask_6: 19.74  loss_mask_7: 19.88  loss_mask_8: 19.89  time: 2.6083  data_time: 0.0538  lr: 9.7929e-05  max_mem: 27639M
[01/28 22:01:45] d2.utils.events INFO:  eta: 1 day, 18:22:56  iter: 1399  total_loss: 218.8  loss_mask: 21.27  loss_mask_0: 27.26  loss_mask_1: 21.28  loss_mask_2: 21.32  loss_mask_3: 21.19  loss_mask_4: 21.29  loss_mask_5: 21.29  loss_mask_6: 21.17  loss_mask_7: 21.25  loss_mask_8: 21.27  time: 2.6081  data_time: 0.0593  lr: 9.7899e-05  max_mem: 27639M
[01/28 22:02:37] d2.utils.events INFO:  eta: 1 day, 18:22:04  iter: 1419  total_loss: 227  loss_mask: 22.1  loss_mask_0: 26.37  loss_mask_1: 22.02  loss_mask_2: 22.15  loss_mask_3: 22.1  loss_mask_4: 22.14  loss_mask_5: 22.12  loss_mask_6: 22.18  loss_mask_7: 22.16  loss_mask_8: 22.08  time: 2.6081  data_time: 0.0643  lr: 9.7869e-05  max_mem: 27639M
[01/28 22:03:29] d2.utils.events INFO:  eta: 1 day, 18:21:32  iter: 1439  total_loss: 207  loss_mask: 20.08  loss_mask_0: 26.15  loss_mask_1: 20.04  loss_mask_2: 20  loss_mask_3: 19.99  loss_mask_4: 19.96  loss_mask_5: 20.02  loss_mask_6: 19.97  loss_mask_7: 20.08  loss_mask_8: 20.12  time: 2.6081  data_time: 0.0591  lr: 9.7839e-05  max_mem: 27639M
[01/28 22:04:21] d2.utils.events INFO:  eta: 1 day, 18:20:29  iter: 1459  total_loss: 202.9  loss_mask: 19.79  loss_mask_0: 24.68  loss_mask_1: 19.5  loss_mask_2: 19.69  loss_mask_3: 19.7  loss_mask_4: 19.72  loss_mask_5: 19.62  loss_mask_6: 19.66  loss_mask_7: 19.81  loss_mask_8: 19.77  time: 2.6078  data_time: 0.0541  lr: 9.7809e-05  max_mem: 27639M
[01/28 22:05:13] d2.utils.events INFO:  eta: 1 day, 18:19:37  iter: 1479  total_loss: 217.8  loss_mask: 21.24  loss_mask_0: 26.4  loss_mask_1: 21.25  loss_mask_2: 21.25  loss_mask_3: 21.21  loss_mask_4: 21.23  loss_mask_5: 21.23  loss_mask_6: 21.24  loss_mask_7: 21.31  loss_mask_8: 21.25  time: 2.6077  data_time: 0.0620  lr: 9.7779e-05  max_mem: 27639M
[01/28 22:06:05] d2.utils.events INFO:  eta: 1 day, 18:18:39  iter: 1499  total_loss: 222.8  loss_mask: 21.73  loss_mask_0: 26.69  loss_mask_1: 21.67  loss_mask_2: 21.69  loss_mask_3: 21.72  loss_mask_4: 21.71  loss_mask_5: 21.66  loss_mask_6: 21.65  loss_mask_7: 21.77  loss_mask_8: 21.74  time: 2.6076  data_time: 0.0599  lr: 9.7749e-05  max_mem: 27639M
[01/28 22:06:58] d2.utils.events INFO:  eta: 1 day, 18:18:10  iter: 1519  total_loss: 214.1  loss_mask: 21.03  loss_mask_0: 25.96  loss_mask_1: 20.84  loss_mask_2: 20.83  loss_mask_3: 20.82  loss_mask_4: 20.73  loss_mask_5: 20.84  loss_mask_6: 20.86  loss_mask_7: 21.01  loss_mask_8: 21.04  time: 2.6076  data_time: 0.0611  lr: 9.7719e-05  max_mem: 27639M
[01/28 22:07:50] d2.utils.events INFO:  eta: 1 day, 18:16:46  iter: 1539  total_loss: 218.2  loss_mask: 21.29  loss_mask_0: 26.76  loss_mask_1: 21.41  loss_mask_2: 21.62  loss_mask_3: 21.63  loss_mask_4: 21.57  loss_mask_5: 21.49  loss_mask_6: 21.41  loss_mask_7: 21.27  loss_mask_8: 21.33  time: 2.6075  data_time: 0.0600  lr: 9.7689e-05  max_mem: 27639M
[01/28 22:08:42] d2.utils.events INFO:  eta: 1 day, 18:15:48  iter: 1559  total_loss: 225.3  loss_mask: 21.87  loss_mask_0: 27.97  loss_mask_1: 21.76  loss_mask_2: 21.75  loss_mask_3: 21.77  loss_mask_4: 21.78  loss_mask_5: 21.79  loss_mask_6: 21.85  loss_mask_7: 21.94  loss_mask_8: 21.91  time: 2.6075  data_time: 0.0662  lr: 9.7658e-05  max_mem: 27639M
[01/28 22:09:34] d2.utils.events INFO:  eta: 1 day, 18:14:53  iter: 1579  total_loss: 217.6  loss_mask: 21.09  loss_mask_0: 26.69  loss_mask_1: 21.15  loss_mask_2: 20.97  loss_mask_3: 21.02  loss_mask_4: 21.05  loss_mask_5: 21  loss_mask_6: 21.04  loss_mask_7: 21.21  loss_mask_8: 21.14  time: 2.6073  data_time: 0.0576  lr: 9.7628e-05  max_mem: 27639M
[01/28 22:10:26] d2.utils.events INFO:  eta: 1 day, 18:14:00  iter: 1599  total_loss: 215.7  loss_mask: 21.14  loss_mask_0: 25.82  loss_mask_1: 21.08  loss_mask_2: 21.07  loss_mask_3: 21.13  loss_mask_4: 21.09  loss_mask_5: 21.03  loss_mask_6: 21.07  loss_mask_7: 21.16  loss_mask_8: 21.13  time: 2.6072  data_time: 0.0565  lr: 9.7598e-05  max_mem: 27639M
[01/28 22:11:18] d2.utils.events INFO:  eta: 1 day, 18:13:18  iter: 1619  total_loss: 210.5  loss_mask: 20.17  loss_mask_0: 25.98  loss_mask_1: 20.14  loss_mask_2: 20.24  loss_mask_3: 20.22  loss_mask_4: 20.21  loss_mask_5: 20.18  loss_mask_6: 20.14  loss_mask_7: 20.15  loss_mask_8: 20.16  time: 2.6073  data_time: 0.0612  lr: 9.7568e-05  max_mem: 27639M
[01/28 22:12:10] d2.utils.events INFO:  eta: 1 day, 18:12:32  iter: 1639  total_loss: 204.8  loss_mask: 20.11  loss_mask_0: 25.91  loss_mask_1: 19.94  loss_mask_2: 20.09  loss_mask_3: 20.03  loss_mask_4: 20.05  loss_mask_5: 20.08  loss_mask_6: 20.03  loss_mask_7: 20.08  loss_mask_8: 20.04  time: 2.6072  data_time: 0.0610  lr: 9.7538e-05  max_mem: 27639M
[01/28 22:13:03] d2.utils.events INFO:  eta: 1 day, 18:11:34  iter: 1659  total_loss: 219.8  loss_mask: 21.2  loss_mask_0: 28.37  loss_mask_1: 21.17  loss_mask_2: 21.14  loss_mask_3: 21.11  loss_mask_4: 21.26  loss_mask_5: 21.2  loss_mask_6: 21.18  loss_mask_7: 21.26  loss_mask_8: 21.23  time: 2.6073  data_time: 0.0585  lr: 9.7508e-05  max_mem: 27639M
[01/28 22:13:55] d2.utils.events INFO:  eta: 1 day, 18:10:42  iter: 1679  total_loss: 215.5  loss_mask: 21.03  loss_mask_0: 26.98  loss_mask_1: 20.96  loss_mask_2: 20.93  loss_mask_3: 20.96  loss_mask_4: 20.92  loss_mask_5: 20.96  loss_mask_6: 20.94  loss_mask_7: 20.97  loss_mask_8: 20.98  time: 2.6074  data_time: 0.0548  lr: 9.7478e-05  max_mem: 27639M
[01/28 22:14:47] d2.utils.events INFO:  eta: 1 day, 18:09:43  iter: 1699  total_loss: 196.4  loss_mask: 19.29  loss_mask_0: 24.56  loss_mask_1: 19.29  loss_mask_2: 19.2  loss_mask_3: 19.22  loss_mask_4: 19.2  loss_mask_5: 19.24  loss_mask_6: 19.23  loss_mask_7: 19.26  loss_mask_8: 19.25  time: 2.6074  data_time: 0.0573  lr: 9.7448e-05  max_mem: 27639M
[01/28 22:15:39] d2.utils.events INFO:  eta: 1 day, 18:08:34  iter: 1719  total_loss: 208.7  loss_mask: 20.18  loss_mask_0: 27.24  loss_mask_1: 20.17  loss_mask_2: 20.19  loss_mask_3: 20.15  loss_mask_4: 20.16  loss_mask_5: 20.25  loss_mask_6: 20.14  loss_mask_7: 20.19  loss_mask_8: 20.23  time: 2.6073  data_time: 0.0610  lr: 9.7418e-05  max_mem: 27639M
[01/28 22:16:31] d2.utils.events INFO:  eta: 1 day, 18:07:14  iter: 1739  total_loss: 210.3  loss_mask: 20.37  loss_mask_0: 27.45  loss_mask_1: 20.41  loss_mask_2: 20.4  loss_mask_3: 20.42  loss_mask_4: 20.39  loss_mask_5: 20.39  loss_mask_6: 20.38  loss_mask_7: 20.34  loss_mask_8: 20.37  time: 2.6072  data_time: 0.0598  lr: 9.7388e-05  max_mem: 27639M
[01/28 22:17:23] d2.utils.events INFO:  eta: 1 day, 18:06:15  iter: 1759  total_loss: 217.1  loss_mask: 21.26  loss_mask_0: 26.36  loss_mask_1: 21.31  loss_mask_2: 21.27  loss_mask_3: 21.27  loss_mask_4: 21.34  loss_mask_5: 21.33  loss_mask_6: 21.29  loss_mask_7: 21.27  loss_mask_8: 21.32  time: 2.6071  data_time: 0.0603  lr: 9.7358e-05  max_mem: 27639M
[01/28 22:18:15] d2.utils.events INFO:  eta: 1 day, 18:05:09  iter: 1779  total_loss: 212.9  loss_mask: 20.8  loss_mask_0: 26.81  loss_mask_1: 20.69  loss_mask_2: 20.68  loss_mask_3: 20.69  loss_mask_4: 20.68  loss_mask_5: 20.64  loss_mask_6: 20.68  loss_mask_7: 20.83  loss_mask_8: 20.82  time: 2.6070  data_time: 0.0620  lr: 9.7328e-05  max_mem: 27639M
[01/28 22:19:07] d2.utils.events INFO:  eta: 1 day, 18:04:28  iter: 1799  total_loss: 211.1  loss_mask: 20.58  loss_mask_0: 26.5  loss_mask_1: 20.52  loss_mask_2: 20.55  loss_mask_3: 20.61  loss_mask_4: 20.52  loss_mask_5: 20.57  loss_mask_6: 20.62  loss_mask_7: 20.61  loss_mask_8: 20.57  time: 2.6069  data_time: 0.0605  lr: 9.7297e-05  max_mem: 27639M
[01/28 22:19:59] d2.utils.events INFO:  eta: 1 day, 18:03:03  iter: 1819  total_loss: 221.9  loss_mask: 21.61  loss_mask_0: 27.75  loss_mask_1: 21.51  loss_mask_2: 21.49  loss_mask_3: 21.49  loss_mask_4: 21.56  loss_mask_5: 21.49  loss_mask_6: 21.59  loss_mask_7: 21.67  loss_mask_8: 21.69  time: 2.6068  data_time: 0.0566  lr: 9.7267e-05  max_mem: 27639M
[01/28 22:20:51] d2.utils.events INFO:  eta: 1 day, 18:02:11  iter: 1839  total_loss: 215.8  loss_mask: 21.03  loss_mask_0: 26.26  loss_mask_1: 21.02  loss_mask_2: 20.98  loss_mask_3: 20.97  loss_mask_4: 20.98  loss_mask_5: 20.99  loss_mask_6: 20.99  loss_mask_7: 21.06  loss_mask_8: 21.04  time: 2.6067  data_time: 0.0594  lr: 9.7237e-05  max_mem: 27639M
[01/28 22:21:43] d2.utils.events INFO:  eta: 1 day, 18:00:38  iter: 1859  total_loss: 205.6  loss_mask: 20.1  loss_mask_0: 27.11  loss_mask_1: 19.98  loss_mask_2: 19.87  loss_mask_3: 19.96  loss_mask_4: 19.91  loss_mask_5: 19.84  loss_mask_6: 19.87  loss_mask_7: 20.02  loss_mask_8: 20  time: 2.6066  data_time: 0.0641  lr: 9.7207e-05  max_mem: 27639M
[01/28 22:22:35] d2.utils.events INFO:  eta: 1 day, 17:59:04  iter: 1879  total_loss: 205.9  loss_mask: 19.9  loss_mask_0: 26.66  loss_mask_1: 19.9  loss_mask_2: 19.91  loss_mask_3: 19.94  loss_mask_4: 19.87  loss_mask_5: 19.9  loss_mask_6: 19.93  loss_mask_7: 19.98  loss_mask_8: 19.89  time: 2.6065  data_time: 0.0588  lr: 9.7177e-05  max_mem: 27639M
[01/28 22:23:27] d2.utils.events INFO:  eta: 1 day, 17:58:04  iter: 1899  total_loss: 211.3  loss_mask: 20.56  loss_mask_0: 26.71  loss_mask_1: 20.53  loss_mask_2: 20.49  loss_mask_3: 20.51  loss_mask_4: 20.47  loss_mask_5: 20.51  loss_mask_6: 20.48  loss_mask_7: 20.56  loss_mask_8: 20.53  time: 2.6065  data_time: 0.0630  lr: 9.7147e-05  max_mem: 27639M
[01/28 22:24:19] d2.utils.events INFO:  eta: 1 day, 17:56:45  iter: 1919  total_loss: 215.9  loss_mask: 21.06  loss_mask_0: 25.46  loss_mask_1: 21  loss_mask_2: 21.11  loss_mask_3: 21.08  loss_mask_4: 21.05  loss_mask_5: 21.08  loss_mask_6: 21.05  loss_mask_7: 21.06  loss_mask_8: 21.11  time: 2.6063  data_time: 0.0561  lr: 9.7117e-05  max_mem: 27639M
[01/28 22:25:11] d2.utils.events INFO:  eta: 1 day, 17:55:40  iter: 1939  total_loss: 213  loss_mask: 20.95  loss_mask_0: 26.88  loss_mask_1: 20.74  loss_mask_2: 20.84  loss_mask_3: 20.87  loss_mask_4: 20.81  loss_mask_5: 20.83  loss_mask_6: 20.87  loss_mask_7: 20.93  loss_mask_8: 20.87  time: 2.6063  data_time: 0.0613  lr: 9.7087e-05  max_mem: 27639M
[01/28 22:26:03] d2.utils.events INFO:  eta: 1 day, 17:54:36  iter: 1959  total_loss: 205  loss_mask: 19.84  loss_mask_0: 26.52  loss_mask_1: 19.82  loss_mask_2: 19.87  loss_mask_3: 19.84  loss_mask_4: 19.88  loss_mask_5: 19.83  loss_mask_6: 19.83  loss_mask_7: 19.88  loss_mask_8: 19.82  time: 2.6062  data_time: 0.0539  lr: 9.7057e-05  max_mem: 27639M
[01/28 22:26:55] d2.utils.events INFO:  eta: 1 day, 17:53:17  iter: 1979  total_loss: 201.6  loss_mask: 19.53  loss_mask_0: 25.69  loss_mask_1: 19.62  loss_mask_2: 19.55  loss_mask_3: 19.58  loss_mask_4: 19.62  loss_mask_5: 19.53  loss_mask_6: 19.5  loss_mask_7: 19.58  loss_mask_8: 19.58  time: 2.6062  data_time: 0.0565  lr: 9.7027e-05  max_mem: 27639M
[01/28 22:27:47] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/28 22:27:48] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/28 22:27:48] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/28 22:38:01] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 22.788634765304565, 'error_1pix': 0.9445306442590691, 'error_3pix': 0.8735462863486331, 'mIoU': 0.26694120726013487, 'fwIoU': 0.7001769315125664, 'IoU-0': 0.0, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.15207240899592783, 'IoU-8': 7.047387691948818e-05, 'IoU-9': 0.7190304713346758, 'IoU-10': 0.5590898846260669, 'IoU-11': 0.16066329691435394, 'IoU-12': 0.7989245019699159, 'IoU-13': 1.1087639743156092, 'IoU-14': 1.530424568834352, 'IoU-15': 1.212320155091935, 'IoU-16': 0.9433109554311425, 'IoU-17': 1.295978384940992, 'IoU-18': 1.2082832859347108, 'IoU-19': 1.5185247438265352, 'IoU-20': 1.270227609997159, 'IoU-21': 1.0945966428811535, 'IoU-22': 1.338379740605677, 'IoU-23': 1.6113941276438397, 'IoU-24': 1.3654874135595296, 'IoU-25': 1.1393243352152858, 'IoU-26': 0.9926305814670824, 'IoU-27': 1.4632100613646897, 'IoU-28': 1.5762597696205447, 'IoU-29': 1.485455658043396, 'IoU-30': 1.4916774965490132, 'IoU-31': 1.069848754265488, 'IoU-32': 1.2569134430124853, 'IoU-33': 1.285157041721637, 'IoU-34': 1.2637237022468677, 'IoU-35': 1.2289071030434802, 'IoU-36': 1.2245868944075917, 'IoU-37': 1.158420024440531, 'IoU-38': 1.271559692129196, 'IoU-39': 1.250421230473053, 'IoU-40': 1.0077829397489875, 'IoU-41': 0.648854841307183, 'IoU-42': 0.8581118101804669, 'IoU-43': 0.8207713135923291, 'IoU-44': 0.6907961006008096, 'IoU-45': 0.6306141731117914, 'IoU-46': 0.6065100927781273, 'IoU-47': 0.45961258768260504, 'IoU-48': 0.7012728334709543, 'IoU-49': 0.3597214036644836, 'IoU-50': 0.5222804477206396, 'IoU-51': 0.39812821571135043, 'IoU-52': 0.4305710985757717, 'IoU-53': 0.24461164241178585, 'IoU-54': 0.4574510777020843, 'IoU-55': 0.3917772968608801, 'IoU-56': 0.49627627124593404, 'IoU-57': 0.35842614006630374, 'IoU-58': 0.18782965143538677, 'IoU-59': 0.14807941403032426, 'IoU-60': 0.14276305730761973, 'IoU-61': 0.19937914334782267, 'IoU-62': 0.12215897062148827, 'IoU-63': 0.10567319125854473, 'IoU-64': 0.21403196692472834, 'IoU-65': 0.1545460843422088, 'IoU-66': 0.059196663497349214, 'IoU-67': 0.13048063646686148, 'IoU-68': 0.11260077060044685, 'IoU-69': 0.12785378511262455, 'IoU-70': 0.01131868069992202, 'IoU-71': 0.11348099608840503, 'IoU-72': 0.04530597045802474, 'IoU-73': 0.14326115196244985, 'IoU-74': 0.2980272892822738, 'IoU-75': 0.04428991769906763, 'IoU-76': 0.12234157662585791, 'IoU-77': 0.06015889562750507, 'IoU-78': 0.23070394428742957, 'IoU-79': 0.052651121208618215, 'IoU-80': 0.12718036815797346, 'IoU-81': 0.12513519539629347, 'IoU-82': 0.021006194082770328, 'IoU-83': 0.039549139806209214, 'IoU-84': 0.13681338816727065, 'IoU-85': 0.005611978626440936, 'IoU-86': 0.02635821677850716, 'IoU-87': 0.17421536366198526, 'IoU-88': 0.10219518949051204, 'IoU-89': 0.004603541220356927, 'IoU-90': 0.11278248617593034, 'IoU-91': 0.03837810341306244, 'IoU-92': 0.03643572113966076, 'IoU-93': 0.2238692986530185, 'IoU-94': 0.009116078016288881, 'IoU-95': 0.07971359938618851, 'IoU-96': 0.09349914802178204, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.058239604416270074, 'IoU-101': 0.0036033413696634517, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.026782349179623924, 'IoU-106': 0.056380696506013635, 'IoU-107': 0.0008104280156384004, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.007495277705431272, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0004057566590754104, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.054130943061768966, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.6624278208045186, 'pACC': 1.8183672874819898, 'ACC-0': 0.0, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.2953498802192152, 'ACC-8': 0.00011104115518334561, 'ACC-9': 1.514056425852037, 'ACC-10': 0.8255042510825641, 'ACC-11': 0.1784034990363949, 'ACC-12': 1.0292843533160612, 'ACC-13': 1.476549515730037, 'ACC-14': 2.444224067592892, 'ACC-15': 2.0630514885726896, 'ACC-16': 1.9993120449676518, 'ACC-17': 2.8754817875891985, 'ACC-18': 2.745542999583181, 'ACC-19': 4.543727818798393, 'ACC-20': 3.536755801648267, 'ACC-21': 3.4179595953283246, 'ACC-22': 3.9325866318792237, 'ACC-23': 5.394519973095217, 'ACC-24': 5.135851421979305, 'ACC-25': 3.630676554163222, 'ACC-26': 3.6943893481164656, 'ACC-27': 5.868524030611712, 'ACC-28': 5.748048485779782, 'ACC-29': 4.911062156566284, 'ACC-30': 5.677496543553063, 'ACC-31': 3.2575976246241987, 'ACC-32': 3.7669798065919253, 'ACC-33': 4.218772847610971, 'ACC-34': 3.781609183486349, 'ACC-35': 3.429864843760592, 'ACC-36': 3.3751402741536256, 'ACC-37': 2.8161618046772894, 'ACC-38': 3.369176749902513, 'ACC-39': 3.0233611855683478, 'ACC-40': 2.2004021408143926, 'ACC-41': 1.3915399477373407, 'ACC-42': 1.6304117082624852, 'ACC-43': 1.6591481585592542, 'ACC-44': 1.310829949470064, 'ACC-45': 1.0446226736702222, 'ACC-46': 1.220174444085506, 'ACC-47': 0.7606189322068577, 'ACC-48': 1.1914905514769183, 'ACC-49': 0.5693402308443581, 'ACC-50': 0.8620480979587439, 'ACC-51': 0.5929253389997873, 'ACC-52': 0.7887929142269429, 'ACC-53': 0.34726932718200376, 'ACC-54': 0.693389466382013, 'ACC-55': 0.6177016766061564, 'ACC-56': 0.7379491780948544, 'ACC-57': 0.5850608851801896, 'ACC-58': 0.26152817178668136, 'ACC-59': 0.2106367109015424, 'ACC-60': 0.17756176298133258, 'ACC-61': 0.31952487285781445, 'ACC-62': 0.16634852715308482, 'ACC-63': 0.15603164976308423, 'ACC-64': 0.28727355336465227, 'ACC-65': 0.22552199999307576, 'ACC-66': 0.08423850719798727, 'ACC-67': 0.18034201182755813, 'ACC-68': 0.14392228239899094, 'ACC-69': 0.16975885810873145, 'ACC-70': 0.01256005208715024, 'ACC-71': 0.1392684409950455, 'ACC-72': 0.06097169844099543, 'ACC-73': 0.18402753683976047, 'ACC-74': 0.36425876445910677, 'ACC-75': 0.04928260126520767, 'ACC-76': 0.14231798485019861, 'ACC-77': 0.06692736061675784, 'ACC-78': 0.2698782747046047, 'ACC-79': 0.06173889382124324, 'ACC-80': 0.14886272395341887, 'ACC-81': 0.16087231597853557, 'ACC-82': 0.027126529791140348, 'ACC-83': 0.044095327375530034, 'ACC-84': 0.18482449782029356, 'ACC-85': 0.005948322272231334, 'ACC-86': 0.031210960359590104, 'ACC-87': 0.21803356990238712, 'ACC-88': 0.13534937583941373, 'ACC-89': 0.005214855239078049, 'ACC-90': 0.12787084107123875, 'ACC-91': 0.043775842647549905, 'ACC-92': 0.04179228169505172, 'ACC-93': 0.25748717094257717, 'ACC-94': 0.010552218581149297, 'ACC-95': 0.11214503146356743, 'ACC-96': 0.11760456389639808, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.08267465273807584, 'ACC-101': 0.004406168808279642, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.033864965620419706, 'ACC-106': 0.06400881910939896, 'ACC-107': 0.0009246809306859175, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.00871232741051766, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0005637995579811466, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.065877397502705, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/28 22:38:01] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/28 22:38:01] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/28 22:38:01] d2.evaluation.testing INFO: copypaste: 22.7886,0.9445,0.8735,0.2669,0.7002,0.6624,1.8184
[01/28 22:38:01] d2.utils.events INFO:  eta: 1 day, 17:52:12  iter: 1999  total_loss: 218.5  loss_mask: 21.44  loss_mask_0: 27.01  loss_mask_1: 21.45  loss_mask_2: 21.4  loss_mask_3: 21.45  loss_mask_4: 21.44  loss_mask_5: 21.43  loss_mask_6: 21.44  loss_mask_7: 21.44  loss_mask_8: 21.42  time: 2.6062  data_time: 0.0630  lr: 9.6996e-05  max_mem: 27639M
[01/28 22:38:54] d2.utils.events INFO:  eta: 1 day, 17:51:25  iter: 2019  total_loss: 210.2  loss_mask: 20.46  loss_mask_0: 27.44  loss_mask_1: 20.28  loss_mask_2: 20.42  loss_mask_3: 20.45  loss_mask_4: 20.4  loss_mask_5: 20.33  loss_mask_6: 20.38  loss_mask_7: 20.47  loss_mask_8: 20.44  time: 2.6064  data_time: 0.0692  lr: 9.6966e-05  max_mem: 27639M
[01/28 22:39:46] d2.utils.events INFO:  eta: 1 day, 17:50:29  iter: 2039  total_loss: 214  loss_mask: 20.75  loss_mask_0: 26.69  loss_mask_1: 20.79  loss_mask_2: 20.83  loss_mask_3: 20.85  loss_mask_4: 20.7  loss_mask_5: 20.64  loss_mask_6: 20.74  loss_mask_7: 20.74  loss_mask_8: 20.74  time: 2.6065  data_time: 0.0566  lr: 9.6936e-05  max_mem: 27639M
[01/28 22:40:38] d2.utils.events INFO:  eta: 1 day, 17:49:37  iter: 2059  total_loss: 209.7  loss_mask: 20.64  loss_mask_0: 26.03  loss_mask_1: 20.59  loss_mask_2: 20.64  loss_mask_3: 20.68  loss_mask_4: 20.58  loss_mask_5: 20.58  loss_mask_6: 20.58  loss_mask_7: 20.67  loss_mask_8: 20.67  time: 2.6064  data_time: 0.0621  lr: 9.6906e-05  max_mem: 27639M
[01/28 22:41:31] d2.utils.events INFO:  eta: 1 day, 17:48:30  iter: 2079  total_loss: 217  loss_mask: 21.11  loss_mask_0: 26.49  loss_mask_1: 21.22  loss_mask_2: 21.26  loss_mask_3: 21.2  loss_mask_4: 21.24  loss_mask_5: 21.15  loss_mask_6: 21.19  loss_mask_7: 21.19  loss_mask_8: 21.11  time: 2.6065  data_time: 0.0672  lr: 9.6876e-05  max_mem: 27639M
[01/28 22:42:23] d2.utils.events INFO:  eta: 1 day, 17:48:05  iter: 2099  total_loss: 211  loss_mask: 20.65  loss_mask_0: 26.03  loss_mask_1: 20.61  loss_mask_2: 20.62  loss_mask_3: 20.63  loss_mask_4: 20.61  loss_mask_5: 20.61  loss_mask_6: 20.62  loss_mask_7: 20.66  loss_mask_8: 20.64  time: 2.6066  data_time: 0.0741  lr: 9.6846e-05  max_mem: 27639M
[01/28 22:43:15] d2.utils.events INFO:  eta: 1 day, 17:47:32  iter: 2119  total_loss: 201.5  loss_mask: 19.57  loss_mask_0: 25.17  loss_mask_1: 19.58  loss_mask_2: 19.5  loss_mask_3: 19.53  loss_mask_4: 19.5  loss_mask_5: 19.52  loss_mask_6: 19.52  loss_mask_7: 19.54  loss_mask_8: 19.51  time: 2.6065  data_time: 0.0630  lr: 9.6816e-05  max_mem: 27639M
[01/28 22:44:07] d2.utils.events INFO:  eta: 1 day, 17:46:09  iter: 2139  total_loss: 217.5  loss_mask: 21.34  loss_mask_0: 27.57  loss_mask_1: 21.23  loss_mask_2: 21.27  loss_mask_3: 21.3  loss_mask_4: 21.28  loss_mask_5: 21.25  loss_mask_6: 21.24  loss_mask_7: 21.32  loss_mask_8: 21.3  time: 2.6065  data_time: 0.0595  lr: 9.6786e-05  max_mem: 27639M
[01/28 22:44:59] d2.utils.events INFO:  eta: 1 day, 17:45:02  iter: 2159  total_loss: 203.7  loss_mask: 19.7  loss_mask_0: 25.2  loss_mask_1: 19.72  loss_mask_2: 19.74  loss_mask_3: 19.71  loss_mask_4: 19.73  loss_mask_5: 19.71  loss_mask_6: 19.73  loss_mask_7: 19.7  loss_mask_8: 19.67  time: 2.6065  data_time: 0.0565  lr: 9.6756e-05  max_mem: 27639M
[01/28 22:45:51] d2.utils.events INFO:  eta: 1 day, 17:43:43  iter: 2179  total_loss: 207.8  loss_mask: 20.44  loss_mask_0: 25.59  loss_mask_1: 20.21  loss_mask_2: 20.22  loss_mask_3: 20.26  loss_mask_4: 20.25  loss_mask_5: 20.23  loss_mask_6: 20.2  loss_mask_7: 20.38  loss_mask_8: 20.45  time: 2.6064  data_time: 0.0610  lr: 9.6725e-05  max_mem: 27639M
[01/28 22:46:44] d2.utils.events INFO:  eta: 1 day, 17:42:42  iter: 2199  total_loss: 209.4  loss_mask: 20.55  loss_mask_0: 26.12  loss_mask_1: 20.49  loss_mask_2: 20.54  loss_mask_3: 20.62  loss_mask_4: 20.56  loss_mask_5: 20.49  loss_mask_6: 20.5  loss_mask_7: 20.62  loss_mask_8: 20.54  time: 2.6065  data_time: 0.0617  lr: 9.6695e-05  max_mem: 27639M
[01/28 22:47:36] d2.utils.events INFO:  eta: 1 day, 17:41:32  iter: 2219  total_loss: 209.2  loss_mask: 20.47  loss_mask_0: 25.84  loss_mask_1: 20.22  loss_mask_2: 20.4  loss_mask_3: 20.43  loss_mask_4: 20.37  loss_mask_5: 20.31  loss_mask_6: 20.4  loss_mask_7: 20.61  loss_mask_8: 20.47  time: 2.6065  data_time: 0.0660  lr: 9.6665e-05  max_mem: 27639M
[01/28 22:48:28] d2.utils.events INFO:  eta: 1 day, 17:40:40  iter: 2239  total_loss: 214.9  loss_mask: 20.84  loss_mask_0: 27.32  loss_mask_1: 20.76  loss_mask_2: 20.78  loss_mask_3: 20.8  loss_mask_4: 20.79  loss_mask_5: 20.79  loss_mask_6: 20.76  loss_mask_7: 20.88  loss_mask_8: 20.86  time: 2.6065  data_time: 0.0666  lr: 9.6635e-05  max_mem: 27639M
[01/28 22:49:20] d2.utils.events INFO:  eta: 1 day, 17:39:41  iter: 2259  total_loss: 207.4  loss_mask: 19.88  loss_mask_0: 26.69  loss_mask_1: 19.97  loss_mask_2: 19.94  loss_mask_3: 19.99  loss_mask_4: 19.98  loss_mask_5: 19.97  loss_mask_6: 19.87  loss_mask_7: 19.9  loss_mask_8: 19.9  time: 2.6065  data_time: 0.0629  lr: 9.6605e-05  max_mem: 27639M
[01/28 22:50:12] d2.utils.events INFO:  eta: 1 day, 17:38:57  iter: 2279  total_loss: 208.5  loss_mask: 20.01  loss_mask_0: 26.92  loss_mask_1: 19.88  loss_mask_2: 19.86  loss_mask_3: 19.9  loss_mask_4: 19.86  loss_mask_5: 19.87  loss_mask_6: 19.87  loss_mask_7: 19.94  loss_mask_8: 19.92  time: 2.6065  data_time: 0.0615  lr: 9.6575e-05  max_mem: 27639M
[01/28 22:51:05] d2.utils.events INFO:  eta: 1 day, 17:38:00  iter: 2299  total_loss: 209  loss_mask: 20.31  loss_mask_0: 26.94  loss_mask_1: 20.3  loss_mask_2: 20.23  loss_mask_3: 20.23  loss_mask_4: 20.29  loss_mask_5: 20.31  loss_mask_6: 20.32  loss_mask_7: 20.39  loss_mask_8: 20.29  time: 2.6066  data_time: 0.0654  lr: 9.6545e-05  max_mem: 27639M
[01/28 22:51:57] d2.utils.events INFO:  eta: 1 day, 17:36:57  iter: 2319  total_loss: 204.4  loss_mask: 20.29  loss_mask_0: 25.45  loss_mask_1: 20.02  loss_mask_2: 20  loss_mask_3: 20.18  loss_mask_4: 20.02  loss_mask_5: 19.92  loss_mask_6: 20.02  loss_mask_7: 20.01  loss_mask_8: 20.13  time: 2.6067  data_time: 0.0633  lr: 9.6515e-05  max_mem: 27639M
[01/28 22:52:49] d2.utils.events INFO:  eta: 1 day, 17:35:07  iter: 2339  total_loss: 212.8  loss_mask: 20.63  loss_mask_0: 26.39  loss_mask_1: 20.72  loss_mask_2: 20.68  loss_mask_3: 20.61  loss_mask_4: 20.63  loss_mask_5: 20.63  loss_mask_6: 20.64  loss_mask_7: 20.68  loss_mask_8: 20.64  time: 2.6067  data_time: 0.0649  lr: 9.6485e-05  max_mem: 27639M
[01/28 22:53:42] d2.utils.events INFO:  eta: 1 day, 17:34:13  iter: 2359  total_loss: 207.6  loss_mask: 20.09  loss_mask_0: 26.13  loss_mask_1: 20.02  loss_mask_2: 20  loss_mask_3: 19.98  loss_mask_4: 20  loss_mask_5: 20.05  loss_mask_6: 19.97  loss_mask_7: 20.09  loss_mask_8: 20.11  time: 2.6067  data_time: 0.0689  lr: 9.6454e-05  max_mem: 27639M
[01/28 22:54:34] d2.utils.events INFO:  eta: 1 day, 17:33:23  iter: 2379  total_loss: 214.6  loss_mask: 20.76  loss_mask_0: 26.78  loss_mask_1: 20.79  loss_mask_2: 20.72  loss_mask_3: 20.75  loss_mask_4: 20.73  loss_mask_5: 20.73  loss_mask_6: 20.73  loss_mask_7: 20.72  loss_mask_8: 20.74  time: 2.6067  data_time: 0.0597  lr: 9.6424e-05  max_mem: 27639M
[01/28 22:55:26] d2.utils.events INFO:  eta: 1 day, 17:33:30  iter: 2399  total_loss: 213.9  loss_mask: 21.04  loss_mask_0: 27.27  loss_mask_1: 20.92  loss_mask_2: 21.03  loss_mask_3: 21.03  loss_mask_4: 21.02  loss_mask_5: 20.98  loss_mask_6: 20.94  loss_mask_7: 21.03  loss_mask_8: 21.01  time: 2.6068  data_time: 0.0632  lr: 9.6394e-05  max_mem: 27639M
[01/28 22:56:18] d2.utils.events INFO:  eta: 1 day, 17:31:53  iter: 2419  total_loss: 211.7  loss_mask: 20.58  loss_mask_0: 26.47  loss_mask_1: 20.61  loss_mask_2: 20.6  loss_mask_3: 20.63  loss_mask_4: 20.64  loss_mask_5: 20.58  loss_mask_6: 20.63  loss_mask_7: 20.6  loss_mask_8: 20.58  time: 2.6068  data_time: 0.0673  lr: 9.6364e-05  max_mem: 27639M
[01/28 22:57:11] d2.utils.events INFO:  eta: 1 day, 17:31:19  iter: 2439  total_loss: 204.5  loss_mask: 19.84  loss_mask_0: 27.3  loss_mask_1: 19.93  loss_mask_2: 19.85  loss_mask_3: 19.84  loss_mask_4: 19.82  loss_mask_5: 19.86  loss_mask_6: 19.9  loss_mask_7: 19.84  loss_mask_8: 19.84  time: 2.6069  data_time: 0.0631  lr: 9.6334e-05  max_mem: 27639M
[01/28 22:58:03] d2.utils.events INFO:  eta: 1 day, 17:30:27  iter: 2459  total_loss: 213.8  loss_mask: 20.88  loss_mask_0: 27.19  loss_mask_1: 20.85  loss_mask_2: 20.85  loss_mask_3: 20.89  loss_mask_4: 20.88  loss_mask_5: 20.83  loss_mask_6: 20.88  loss_mask_7: 20.88  loss_mask_8: 20.86  time: 2.6068  data_time: 0.0651  lr: 9.6304e-05  max_mem: 27639M
[01/28 22:58:55] d2.utils.events INFO:  eta: 1 day, 17:29:48  iter: 2479  total_loss: 207.7  loss_mask: 20.08  loss_mask_0: 26.5  loss_mask_1: 20.04  loss_mask_2: 20.01  loss_mask_3: 20  loss_mask_4: 20  loss_mask_5: 19.99  loss_mask_6: 19.99  loss_mask_7: 20.08  loss_mask_8: 20.08  time: 2.6069  data_time: 0.0700  lr: 9.6274e-05  max_mem: 27639M
[01/28 22:59:47] d2.utils.events INFO:  eta: 1 day, 17:28:03  iter: 2499  total_loss: 211.3  loss_mask: 20.64  loss_mask_0: 26.13  loss_mask_1: 20.61  loss_mask_2: 20.52  loss_mask_3: 20.57  loss_mask_4: 20.59  loss_mask_5: 20.57  loss_mask_6: 20.57  loss_mask_7: 20.6  loss_mask_8: 20.62  time: 2.6069  data_time: 0.0579  lr: 9.6244e-05  max_mem: 27639M
[01/28 23:00:39] d2.utils.events INFO:  eta: 1 day, 17:27:03  iter: 2519  total_loss: 201.5  loss_mask: 19.6  loss_mask_0: 26.18  loss_mask_1: 19.64  loss_mask_2: 19.61  loss_mask_3: 19.59  loss_mask_4: 19.6  loss_mask_5: 19.66  loss_mask_6: 19.63  loss_mask_7: 19.6  loss_mask_8: 19.65  time: 2.6068  data_time: 0.0618  lr: 9.6213e-05  max_mem: 27639M
[01/28 23:01:32] d2.utils.events INFO:  eta: 1 day, 17:26:41  iter: 2539  total_loss: 209.4  loss_mask: 20.42  loss_mask_0: 26.72  loss_mask_1: 20.43  loss_mask_2: 20.4  loss_mask_3: 20.43  loss_mask_4: 20.4  loss_mask_5: 20.41  loss_mask_6: 20.46  loss_mask_7: 20.43  loss_mask_8: 20.39  time: 2.6070  data_time: 0.0657  lr: 9.6183e-05  max_mem: 27639M
[01/28 23:02:24] d2.utils.events INFO:  eta: 1 day, 17:25:37  iter: 2559  total_loss: 222.6  loss_mask: 21.8  loss_mask_0: 27.49  loss_mask_1: 21.84  loss_mask_2: 21.73  loss_mask_3: 21.76  loss_mask_4: 21.79  loss_mask_5: 21.77  loss_mask_6: 21.77  loss_mask_7: 21.76  loss_mask_8: 21.77  time: 2.6070  data_time: 0.0661  lr: 9.6153e-05  max_mem: 27639M
[01/28 23:03:16] d2.utils.events INFO:  eta: 1 day, 17:25:57  iter: 2579  total_loss: 206.9  loss_mask: 20.16  loss_mask_0: 26.51  loss_mask_1: 20.08  loss_mask_2: 20.21  loss_mask_3: 20.14  loss_mask_4: 20.1  loss_mask_5: 20.26  loss_mask_6: 20.17  loss_mask_7: 20.17  loss_mask_8: 20.15  time: 2.6071  data_time: 0.0692  lr: 9.6123e-05  max_mem: 27639M
[01/28 23:04:09] d2.utils.events INFO:  eta: 1 day, 17:25:12  iter: 2599  total_loss: 211.9  loss_mask: 20.54  loss_mask_0: 27.08  loss_mask_1: 20.64  loss_mask_2: 20.6  loss_mask_3: 20.6  loss_mask_4: 20.54  loss_mask_5: 20.59  loss_mask_6: 20.65  loss_mask_7: 20.57  loss_mask_8: 20.55  time: 2.6071  data_time: 0.0674  lr: 9.6093e-05  max_mem: 27639M
[01/28 23:05:01] d2.utils.events INFO:  eta: 1 day, 17:24:25  iter: 2619  total_loss: 205.8  loss_mask: 20.09  loss_mask_0: 25.95  loss_mask_1: 19.88  loss_mask_2: 19.94  loss_mask_3: 19.96  loss_mask_4: 19.92  loss_mask_5: 20  loss_mask_6: 19.92  loss_mask_7: 20.08  loss_mask_8: 20.08  time: 2.6071  data_time: 0.0658  lr: 9.6063e-05  max_mem: 27639M
[01/28 23:05:53] d2.utils.events INFO:  eta: 1 day, 17:24:20  iter: 2639  total_loss: 212.2  loss_mask: 20.5  loss_mask_0: 27.7  loss_mask_1: 20.48  loss_mask_2: 20.47  loss_mask_3: 20.51  loss_mask_4: 20.47  loss_mask_5: 20.41  loss_mask_6: 20.47  loss_mask_7: 20.46  loss_mask_8: 20.52  time: 2.6071  data_time: 0.0624  lr: 9.6033e-05  max_mem: 27639M
[01/28 23:06:45] d2.utils.events INFO:  eta: 1 day, 17:23:58  iter: 2659  total_loss: 218  loss_mask: 21.08  loss_mask_0: 28.59  loss_mask_1: 21.04  loss_mask_2: 21.1  loss_mask_3: 21.03  loss_mask_4: 21.01  loss_mask_5: 21.04  loss_mask_6: 21.02  loss_mask_7: 21.13  loss_mask_8: 21.1  time: 2.6072  data_time: 0.0616  lr: 9.6003e-05  max_mem: 27639M
[01/28 23:07:38] d2.utils.events INFO:  eta: 1 day, 17:23:11  iter: 2679  total_loss: 205.9  loss_mask: 19.83  loss_mask_0: 27.46  loss_mask_1: 19.74  loss_mask_2: 19.75  loss_mask_3: 19.81  loss_mask_4: 19.77  loss_mask_5: 19.81  loss_mask_6: 19.77  loss_mask_7: 19.82  loss_mask_8: 19.84  time: 2.6072  data_time: 0.0589  lr: 9.5972e-05  max_mem: 27639M
[01/28 23:08:30] d2.utils.events INFO:  eta: 1 day, 17:22:40  iter: 2699  total_loss: 206.2  loss_mask: 19.94  loss_mask_0: 26.01  loss_mask_1: 19.98  loss_mask_2: 20.02  loss_mask_3: 19.92  loss_mask_4: 19.91  loss_mask_5: 19.89  loss_mask_6: 19.93  loss_mask_7: 19.95  loss_mask_8: 19.96  time: 2.6072  data_time: 0.0666  lr: 9.5942e-05  max_mem: 27639M
[01/28 23:09:22] d2.utils.events INFO:  eta: 1 day, 17:22:25  iter: 2719  total_loss: 209.7  loss_mask: 20.55  loss_mask_0: 26.76  loss_mask_1: 20.36  loss_mask_2: 20.6  loss_mask_3: 20.61  loss_mask_4: 20.55  loss_mask_5: 20.5  loss_mask_6: 20.41  loss_mask_7: 20.59  loss_mask_8: 20.6  time: 2.6073  data_time: 0.0728  lr: 9.5912e-05  max_mem: 27639M
[01/28 23:10:15] d2.utils.events INFO:  eta: 1 day, 17:21:57  iter: 2739  total_loss: 196  loss_mask: 18.91  loss_mask_0: 25.19  loss_mask_1: 18.94  loss_mask_2: 18.93  loss_mask_3: 18.91  loss_mask_4: 18.92  loss_mask_5: 18.91  loss_mask_6: 18.92  loss_mask_7: 18.92  loss_mask_8: 18.92  time: 2.6073  data_time: 0.0676  lr: 9.5882e-05  max_mem: 27639M
[01/28 23:11:07] d2.utils.events INFO:  eta: 1 day, 17:21:16  iter: 2759  total_loss: 204.9  loss_mask: 19.84  loss_mask_0: 25.46  loss_mask_1: 19.88  loss_mask_2: 19.8  loss_mask_3: 19.81  loss_mask_4: 19.78  loss_mask_5: 19.74  loss_mask_6: 19.74  loss_mask_7: 19.82  loss_mask_8: 19.82  time: 2.6073  data_time: 0.0634  lr: 9.5852e-05  max_mem: 27639M
[01/28 23:11:59] d2.utils.events INFO:  eta: 1 day, 17:20:26  iter: 2779  total_loss: 206.5  loss_mask: 19.92  loss_mask_0: 25.78  loss_mask_1: 19.89  loss_mask_2: 19.94  loss_mask_3: 19.9  loss_mask_4: 19.89  loss_mask_5: 19.95  loss_mask_6: 19.92  loss_mask_7: 19.94  loss_mask_8: 19.93  time: 2.6072  data_time: 0.0581  lr: 9.5822e-05  max_mem: 27639M
[01/28 23:12:51] d2.utils.events INFO:  eta: 1 day, 17:19:05  iter: 2799  total_loss: 202.7  loss_mask: 19.63  loss_mask_0: 26.19  loss_mask_1: 19.65  loss_mask_2: 19.6  loss_mask_3: 19.59  loss_mask_4: 19.56  loss_mask_5: 19.54  loss_mask_6: 19.58  loss_mask_7: 19.65  loss_mask_8: 19.63  time: 2.6072  data_time: 0.0631  lr: 9.5792e-05  max_mem: 27639M
[01/28 23:13:43] d2.utils.events INFO:  eta: 1 day, 17:19:17  iter: 2819  total_loss: 206.6  loss_mask: 19.99  loss_mask_0: 26.61  loss_mask_1: 19.97  loss_mask_2: 19.96  loss_mask_3: 19.99  loss_mask_4: 19.96  loss_mask_5: 19.98  loss_mask_6: 19.93  loss_mask_7: 19.96  loss_mask_8: 19.99  time: 2.6073  data_time: 0.0673  lr: 9.5761e-05  max_mem: 27639M
[01/28 23:14:35] d2.utils.events INFO:  eta: 1 day, 17:18:34  iter: 2839  total_loss: 208.6  loss_mask: 20.4  loss_mask_0: 27.27  loss_mask_1: 20.43  loss_mask_2: 20.37  loss_mask_3: 20.37  loss_mask_4: 20.5  loss_mask_5: 20.38  loss_mask_6: 20.44  loss_mask_7: 20.4  loss_mask_8: 20.41  time: 2.6073  data_time: 0.0668  lr: 9.5731e-05  max_mem: 27639M
[01/28 23:15:28] d2.utils.events INFO:  eta: 1 day, 17:18:14  iter: 2859  total_loss: 208.7  loss_mask: 20.43  loss_mask_0: 25.82  loss_mask_1: 20.5  loss_mask_2: 20.39  loss_mask_3: 20.42  loss_mask_4: 20.51  loss_mask_5: 20.44  loss_mask_6: 20.48  loss_mask_7: 20.48  loss_mask_8: 20.42  time: 2.6073  data_time: 0.0547  lr: 9.5701e-05  max_mem: 27639M
[01/28 23:16:20] d2.utils.events INFO:  eta: 1 day, 17:17:42  iter: 2879  total_loss: 220.1  loss_mask: 21.47  loss_mask_0: 27.99  loss_mask_1: 21.47  loss_mask_2: 21.44  loss_mask_3: 21.41  loss_mask_4: 21.41  loss_mask_5: 21.48  loss_mask_6: 21.45  loss_mask_7: 21.49  loss_mask_8: 21.51  time: 2.6073  data_time: 0.0618  lr: 9.5671e-05  max_mem: 27639M
[01/28 23:17:12] d2.utils.events INFO:  eta: 1 day, 17:16:54  iter: 2899  total_loss: 207.1  loss_mask: 20.12  loss_mask_0: 26.46  loss_mask_1: 20.14  loss_mask_2: 20.11  loss_mask_3: 20.11  loss_mask_4: 20.13  loss_mask_5: 20.19  loss_mask_6: 20.15  loss_mask_7: 20.1  loss_mask_8: 20.13  time: 2.6073  data_time: 0.0535  lr: 9.5641e-05  max_mem: 27639M
[01/28 23:18:04] d2.utils.events INFO:  eta: 1 day, 17:16:30  iter: 2919  total_loss: 209.1  loss_mask: 20.29  loss_mask_0: 27.16  loss_mask_1: 20.29  loss_mask_2: 20.27  loss_mask_3: 20.25  loss_mask_4: 20.22  loss_mask_5: 20.28  loss_mask_6: 20.26  loss_mask_7: 20.28  loss_mask_8: 20.28  time: 2.6073  data_time: 0.0667  lr: 9.5611e-05  max_mem: 27639M
[01/28 23:18:56] d2.utils.events INFO:  eta: 1 day, 17:15:33  iter: 2939  total_loss: 206.5  loss_mask: 20.08  loss_mask_0: 26.71  loss_mask_1: 19.91  loss_mask_2: 19.91  loss_mask_3: 19.99  loss_mask_4: 19.98  loss_mask_5: 19.96  loss_mask_6: 19.93  loss_mask_7: 20.05  loss_mask_8: 20.06  time: 2.6073  data_time: 0.0612  lr: 9.5581e-05  max_mem: 27639M
[01/28 23:19:49] d2.utils.events INFO:  eta: 1 day, 17:14:41  iter: 2959  total_loss: 205.6  loss_mask: 19.97  loss_mask_0: 26.26  loss_mask_1: 19.89  loss_mask_2: 19.91  loss_mask_3: 19.94  loss_mask_4: 19.85  loss_mask_5: 19.9  loss_mask_6: 19.91  loss_mask_7: 19.87  loss_mask_8: 19.93  time: 2.6073  data_time: 0.0604  lr: 9.555e-05  max_mem: 27639M
[01/28 23:20:41] d2.utils.events INFO:  eta: 1 day, 17:14:05  iter: 2979  total_loss: 208.7  loss_mask: 20.32  loss_mask_0: 26.26  loss_mask_1: 20.25  loss_mask_2: 20.26  loss_mask_3: 20.32  loss_mask_4: 20.28  loss_mask_5: 20.21  loss_mask_6: 20.25  loss_mask_7: 20.34  loss_mask_8: 20.27  time: 2.6074  data_time: 0.0668  lr: 9.552e-05  max_mem: 27639M
[01/28 23:21:33] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/28 23:21:34] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/28 23:21:34] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/28 23:31:49] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 22.774060710817125, 'error_1pix': 0.9446802300965316, 'error_3pix': 0.8727402520837617, 'mIoU': 0.29347042162121006, 'fwIoU': 0.7360700820093695, 'IoU-0': 0.0, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.1574997036050743, 'IoU-7': 0.0, 'IoU-8': 6.82884257264352e-05, 'IoU-9': 0.3133896387199584, 'IoU-10': 0.4879527309384132, 'IoU-11': 0.8679254982270556, 'IoU-12': 0.919966083261173, 'IoU-13': 1.7079273972555837, 'IoU-14': 1.4431988594382141, 'IoU-15': 1.5397182922148265, 'IoU-16': 0.9416947266616442, 'IoU-17': 1.5287842360696702, 'IoU-18': 1.2312770828574422, 'IoU-19': 1.5065771634070368, 'IoU-20': 1.1958667564495773, 'IoU-21': 1.3540381987038843, 'IoU-22': 1.1828289746752456, 'IoU-23': 1.3517869179979047, 'IoU-24': 1.0108616931107994, 'IoU-25': 0.9151662119498555, 'IoU-26': 0.9612591467721057, 'IoU-27': 1.490646853279224, 'IoU-28': 1.4374833188439482, 'IoU-29': 1.449038554555845, 'IoU-30': 1.4097403978200074, 'IoU-31': 1.113587961589889, 'IoU-32': 1.0589499232439403, 'IoU-33': 1.0870908081737396, 'IoU-34': 1.1199661822050375, 'IoU-35': 1.3578687264522378, 'IoU-36': 1.021809175655069, 'IoU-37': 1.188867572401301, 'IoU-38': 1.0123191964525018, 'IoU-39': 1.3154105430789744, 'IoU-40': 0.9991310621856566, 'IoU-41': 1.0491213315418662, 'IoU-42': 1.0976496731730283, 'IoU-43': 0.6759449616836491, 'IoU-44': 1.0158758736865119, 'IoU-45': 0.5576828871293787, 'IoU-46': 0.7093904116470702, 'IoU-47': 0.6443147224588485, 'IoU-48': 0.44308658650848737, 'IoU-49': 0.5572785834270831, 'IoU-50': 0.7697102724673845, 'IoU-51': 0.5371819638959237, 'IoU-52': 0.37857612991637146, 'IoU-53': 0.32718257144363083, 'IoU-54': 0.3402591008127875, 'IoU-55': 0.4006249351121603, 'IoU-56': 0.4271610824713717, 'IoU-57': 0.46622010149851223, 'IoU-58': 0.46734648081644076, 'IoU-59': 0.3633356700778517, 'IoU-60': 0.35417461155927976, 'IoU-61': 0.2794503722032178, 'IoU-62': 0.2755532867519595, 'IoU-63': 0.1778545095319446, 'IoU-64': 0.2536170944498825, 'IoU-65': 0.21690891067014267, 'IoU-66': 0.14362738714518253, 'IoU-67': 0.2895402799499035, 'IoU-68': 0.1727584676124755, 'IoU-69': 0.03875160222970757, 'IoU-70': 0.13615437214840664, 'IoU-71': 0.3852957837595348, 'IoU-72': 0.20184404618873333, 'IoU-73': 0.28842934422327793, 'IoU-74': 0.3281912218949788, 'IoU-75': 0.057065293988455286, 'IoU-76': 0.24240209928815568, 'IoU-77': 0.12011818618379046, 'IoU-78': 0.1802677148609573, 'IoU-79': 0.1267597712658691, 'IoU-80': 0.2803283697390653, 'IoU-81': 0.08676049774067404, 'IoU-82': 0.19097410407905396, 'IoU-83': 0.0963921220739158, 'IoU-84': 0.04373437321334476, 'IoU-85': 0.040169501652159406, 'IoU-86': 0.11545512362900294, 'IoU-87': 0.09943448611878208, 'IoU-88': 0.10391049897342582, 'IoU-89': 0.0604649213656691, 'IoU-90': 0.04009771612315006, 'IoU-91': 0.09637537314120762, 'IoU-92': 0.06939227400055024, 'IoU-93': 0.05948562444734437, 'IoU-94': 0.09300680900557694, 'IoU-95': 0.10235955584719313, 'IoU-96': 0.2758622519156364, 'IoU-97': 0.02568871258883177, 'IoU-98': 0.245771471334062, 'IoU-99': 0.09505905271323686, 'IoU-100': 0.0009134928025331155, 'IoU-101': 0.0, 'IoU-102': 0.02631866616321489, 'IoU-103': 0.06316200546822445, 'IoU-104': 0.1905497925625516, 'IoU-105': 0.2466321116843109, 'IoU-106': 0.18520871856280274, 'IoU-107': 0.07876777965526569, 'IoU-108': 0.0011603227631152733, 'IoU-109': 0.034416331522680664, 'IoU-110': 0.08211609545252105, 'IoU-111': 0.0360849415581664, 'IoU-112': 0.0, 'IoU-113': 0.12380974936927854, 'IoU-114': 0.010054968181237123, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0508495252635177, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.11261845982947134, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.6751641369275073, 'pACC': 1.7859305255388875, 'ACC-0': 0.0, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.29784232465330773, 'ACC-7': 0.0, 'ACC-8': 0.00016656173277501842, 'ACC-9': 0.5375133509637094, 'ACC-10': 0.6895930456553425, 'ACC-11': 1.0414802406782002, 'ACC-12': 1.26446492020558, 'ACC-13': 2.454999264915099, 'ACC-14': 2.417427726847745, 'ACC-15': 2.74626891796702, 'ACC-16': 1.957496624378009, 'ACC-17': 4.042935644194835, 'ACC-18': 2.9100738111295286, 'ACC-19': 3.973442394290506, 'ACC-20': 3.9357823160085292, 'ACC-21': 3.699041454291378, 'ACC-22': 3.4808717099158106, 'ACC-23': 4.220904265520023, 'ACC-24': 2.7801162395754915, 'ACC-25': 3.0981326627179033, 'ACC-26': 3.3235835006496255, 'ACC-27': 4.967972060031347, 'ACC-28': 5.079780066797735, 'ACC-29': 4.553507471028323, 'ACC-30': 4.680405478796809, 'ACC-31': 3.404267022330439, 'ACC-32': 2.827007835382529, 'ACC-33': 3.0659856786621873, 'ACC-34': 3.4553923655554297, 'ACC-35': 3.804227601577885, 'ACC-36': 2.7931710628917075, 'ACC-37': 3.287608572459369, 'ACC-38': 2.241293052689535, 'ACC-39': 3.098450572636813, 'ACC-40': 2.2601489858930686, 'ACC-41': 2.714877643120862, 'ACC-42': 2.1601813290561203, 'ACC-43': 1.2923239422338872, 'ACC-44': 1.9775595228193512, 'ACC-45': 1.0006331837715905, 'ACC-46': 1.3054746800932508, 'ACC-47': 1.1067416982018563, 'ACC-48': 0.6940555007273949, 'ACC-49': 0.9194174130901216, 'ACC-50': 1.416505785369012, 'ACC-51': 0.8546137073643387, 'ACC-52': 0.5917214189105854, 'ACC-53': 0.5837069759962648, 'ACC-54': 0.5458979316006747, 'ACC-55': 0.6315957777554494, 'ACC-56': 0.6496320267031599, 'ACC-57': 0.7290244389470784, 'ACC-58': 0.749127177346536, 'ACC-59': 0.5855850959357114, 'ACC-60': 0.5984401340420016, 'ACC-61': 0.39925584426684896, 'ACC-62': 0.4994837096913264, 'ACC-63': 0.29637528461619056, 'ACC-64': 0.3652111251414378, 'ACC-65': 0.31632826166843153, 'ACC-66': 0.2118125240440534, 'ACC-67': 0.415384416799644, 'ACC-68': 0.28818975390282126, 'ACC-69': 0.0514985691723125, 'ACC-70': 0.19568688234937784, 'ACC-71': 0.712892116299237, 'ACC-72': 0.28284186246655746, 'ACC-73': 0.40291588897399366, 'ACC-74': 0.43794927108488, 'ACC-75': 0.0731758721644486, 'ACC-76': 0.3613021322491834, 'ACC-77': 0.17428840965701448, 'ACC-78': 0.23167759334820096, 'ACC-79': 0.17045860202783808, 'ACC-80': 0.3917184024161276, 'ACC-81': 0.10660187010327782, 'ACC-82': 0.24619772911229076, 'ACC-83': 0.10741140951570932, 'ACC-84': 0.04628551642149104, 'ACC-85': 0.044971167995896816, 'ACC-86': 0.15785725847525212, 'ACC-87': 0.13083727044139654, 'ACC-88': 0.16467151288401882, 'ACC-89': 0.07246983103740896, 'ACC-90': 0.05090864373537093, 'ACC-91': 0.11665847031937994, 'ACC-92': 0.08467949557469649, 'ACC-93': 0.07307108181000016, 'ACC-94': 0.12221719446005484, 'ACC-95': 0.13562859454337692, 'ACC-96': 0.34635226846747197, 'ACC-97': 0.041637925027423334, 'ACC-98': 0.45167180308921917, 'ACC-99': 0.1329443608372988, 'ACC-100': 0.0012974933239913813, 'ACC-101': 0.0, 'ACC-102': 0.038672405980969646, 'ACC-103': 0.09403041465948805, 'ACC-104': 0.26293008042104227, 'ACC-105': 0.4740329011165989, 'ACC-106': 0.2602570789269909, 'ACC-107': 0.11199517860484141, 'ACC-108': 0.0013265432741906911, 'ACC-109': 0.05462923982576475, 'ACC-110': 0.1204696298201025, 'ACC-111': 0.05951334443371596, 'ACC-112': 0.0, 'ACC-113': 0.19034540634357536, 'ACC-114': 0.011953365838227956, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.07396943533736036, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.14126579680225157, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/28 23:31:49] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/28 23:31:49] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/28 23:31:49] d2.evaluation.testing INFO: copypaste: 22.7741,0.9447,0.8727,0.2935,0.7361,0.6752,1.7859
[01/28 23:31:49] d2.utils.events INFO:  eta: 1 day, 17:13:29  iter: 2999  total_loss: 206.6  loss_mask: 19.92  loss_mask_0: 26.15  loss_mask_1: 19.84  loss_mask_2: 19.85  loss_mask_3: 19.84  loss_mask_4: 19.86  loss_mask_5: 19.86  loss_mask_6: 19.86  loss_mask_7: 19.9  loss_mask_8: 19.91  time: 2.6074  data_time: 0.0601  lr: 9.549e-05  max_mem: 27639M
[01/28 23:32:42] d2.utils.events INFO:  eta: 1 day, 17:12:17  iter: 3019  total_loss: 196.2  loss_mask: 19.05  loss_mask_0: 24.86  loss_mask_1: 18.96  loss_mask_2: 18.91  loss_mask_3: 18.95  loss_mask_4: 18.93  loss_mask_5: 19.03  loss_mask_6: 18.95  loss_mask_7: 19.04  loss_mask_8: 19.07  time: 2.6074  data_time: 0.0562  lr: 9.546e-05  max_mem: 27639M
[01/28 23:33:34] d2.utils.events INFO:  eta: 1 day, 17:11:37  iter: 3039  total_loss: 200  loss_mask: 19.51  loss_mask_0: 25.77  loss_mask_1: 19.35  loss_mask_2: 19.39  loss_mask_3: 19.43  loss_mask_4: 19.35  loss_mask_5: 19.36  loss_mask_6: 19.37  loss_mask_7: 19.52  loss_mask_8: 19.46  time: 2.6074  data_time: 0.0590  lr: 9.543e-05  max_mem: 27639M
[01/28 23:34:26] d2.utils.events INFO:  eta: 1 day, 17:10:37  iter: 3059  total_loss: 197.5  loss_mask: 19.22  loss_mask_0: 26.38  loss_mask_1: 19.14  loss_mask_2: 19.14  loss_mask_3: 19.11  loss_mask_4: 19.14  loss_mask_5: 19.15  loss_mask_6: 19.1  loss_mask_7: 19.2  loss_mask_8: 19.21  time: 2.6074  data_time: 0.0613  lr: 9.54e-05  max_mem: 27639M
[01/28 23:35:18] d2.utils.events INFO:  eta: 1 day, 17:09:53  iter: 3079  total_loss: 193  loss_mask: 18.71  loss_mask_0: 25.72  loss_mask_1: 18.66  loss_mask_2: 18.65  loss_mask_3: 18.64  loss_mask_4: 18.67  loss_mask_5: 18.63  loss_mask_6: 18.66  loss_mask_7: 18.72  loss_mask_8: 18.73  time: 2.6074  data_time: 0.0632  lr: 9.5369e-05  max_mem: 27639M
[01/28 23:36:10] d2.utils.events INFO:  eta: 1 day, 17:08:53  iter: 3099  total_loss: 222.9  loss_mask: 21.85  loss_mask_0: 27.37  loss_mask_1: 21.74  loss_mask_2: 21.78  loss_mask_3: 21.83  loss_mask_4: 21.79  loss_mask_5: 21.76  loss_mask_6: 21.82  loss_mask_7: 21.86  loss_mask_8: 21.84  time: 2.6074  data_time: 0.0614  lr: 9.5339e-05  max_mem: 27639M
[01/28 23:37:02] d2.utils.events INFO:  eta: 1 day, 17:08:09  iter: 3119  total_loss: 215  loss_mask: 20.93  loss_mask_0: 26.4  loss_mask_1: 20.9  loss_mask_2: 20.96  loss_mask_3: 20.93  loss_mask_4: 20.99  loss_mask_5: 20.92  loss_mask_6: 21.04  loss_mask_7: 20.98  loss_mask_8: 20.93  time: 2.6074  data_time: 0.0564  lr: 9.5309e-05  max_mem: 27639M
[01/28 23:37:54] d2.utils.events INFO:  eta: 1 day, 17:07:00  iter: 3139  total_loss: 206.8  loss_mask: 20.28  loss_mask_0: 27.26  loss_mask_1: 20.27  loss_mask_2: 20.21  loss_mask_3: 20.28  loss_mask_4: 20.29  loss_mask_5: 20.26  loss_mask_6: 20.23  loss_mask_7: 20.27  loss_mask_8: 20.28  time: 2.6073  data_time: 0.0629  lr: 9.5279e-05  max_mem: 27639M
[01/28 23:38:47] d2.utils.events INFO:  eta: 1 day, 17:06:01  iter: 3159  total_loss: 200.4  loss_mask: 19.63  loss_mask_0: 25.24  loss_mask_1: 19.51  loss_mask_2: 19.56  loss_mask_3: 19.58  loss_mask_4: 19.62  loss_mask_5: 19.58  loss_mask_6: 19.59  loss_mask_7: 19.65  loss_mask_8: 19.63  time: 2.6073  data_time: 0.0549  lr: 9.5249e-05  max_mem: 27639M
[01/28 23:39:39] d2.utils.events INFO:  eta: 1 day, 17:05:25  iter: 3179  total_loss: 207.7  loss_mask: 20.09  loss_mask_0: 26.62  loss_mask_1: 20.11  loss_mask_2: 20.11  loss_mask_3: 20.11  loss_mask_4: 20.13  loss_mask_5: 20.13  loss_mask_6: 20.07  loss_mask_7: 20.07  loss_mask_8: 20.11  time: 2.6073  data_time: 0.0618  lr: 9.5219e-05  max_mem: 27639M
[01/28 23:40:31] d2.utils.events INFO:  eta: 1 day, 17:04:24  iter: 3199  total_loss: 204.6  loss_mask: 19.78  loss_mask_0: 26.7  loss_mask_1: 19.73  loss_mask_2: 19.85  loss_mask_3: 19.79  loss_mask_4: 19.77  loss_mask_5: 19.72  loss_mask_6: 19.75  loss_mask_7: 19.73  loss_mask_8: 19.75  time: 2.6074  data_time: 0.0570  lr: 9.5188e-05  max_mem: 27639M
[01/28 23:41:23] d2.utils.events INFO:  eta: 1 day, 17:03:32  iter: 3219  total_loss: 204.6  loss_mask: 19.88  loss_mask_0: 26.14  loss_mask_1: 19.81  loss_mask_2: 19.86  loss_mask_3: 19.9  loss_mask_4: 19.78  loss_mask_5: 19.85  loss_mask_6: 19.75  loss_mask_7: 19.88  loss_mask_8: 19.92  time: 2.6073  data_time: 0.0672  lr: 9.5158e-05  max_mem: 27639M
[01/28 23:42:16] d2.utils.events INFO:  eta: 1 day, 17:02:32  iter: 3239  total_loss: 206.9  loss_mask: 20.13  loss_mask_0: 27.85  loss_mask_1: 20.09  loss_mask_2: 20.1  loss_mask_3: 20.11  loss_mask_4: 20.1  loss_mask_5: 20.12  loss_mask_6: 20.14  loss_mask_7: 20.13  loss_mask_8: 20.13  time: 2.6074  data_time: 0.0639  lr: 9.5128e-05  max_mem: 27639M
[01/28 23:43:08] d2.utils.events INFO:  eta: 1 day, 17:01:38  iter: 3259  total_loss: 208.5  loss_mask: 20.33  loss_mask_0: 25.86  loss_mask_1: 20.37  loss_mask_2: 20.19  loss_mask_3: 20.3  loss_mask_4: 20.36  loss_mask_5: 20.25  loss_mask_6: 20.32  loss_mask_7: 20.39  loss_mask_8: 20.24  time: 2.6075  data_time: 0.0639  lr: 9.5098e-05  max_mem: 27639M
[01/28 23:44:00] d2.utils.events INFO:  eta: 1 day, 17:01:04  iter: 3279  total_loss: 201.3  loss_mask: 19.47  loss_mask_0: 25.96  loss_mask_1: 19.53  loss_mask_2: 19.48  loss_mask_3: 19.52  loss_mask_4: 19.5  loss_mask_5: 19.5  loss_mask_6: 19.51  loss_mask_7: 19.47  loss_mask_8: 19.45  time: 2.6075  data_time: 0.0582  lr: 9.5068e-05  max_mem: 27639M
[01/28 23:44:52] d2.utils.events INFO:  eta: 1 day, 17:00:04  iter: 3299  total_loss: 206  loss_mask: 20.17  loss_mask_0: 26.03  loss_mask_1: 20.12  loss_mask_2: 20.15  loss_mask_3: 20.16  loss_mask_4: 20.17  loss_mask_5: 20.18  loss_mask_6: 20.17  loss_mask_7: 20.16  loss_mask_8: 20.17  time: 2.6075  data_time: 0.0691  lr: 9.5038e-05  max_mem: 27639M
[01/28 23:45:45] d2.utils.events INFO:  eta: 1 day, 16:59:12  iter: 3319  total_loss: 211.7  loss_mask: 20.59  loss_mask_0: 26.56  loss_mask_1: 20.55  loss_mask_2: 20.54  loss_mask_3: 20.55  loss_mask_4: 20.55  loss_mask_5: 20.58  loss_mask_6: 20.6  loss_mask_7: 20.62  loss_mask_8: 20.59  time: 2.6074  data_time: 0.0601  lr: 9.5007e-05  max_mem: 27639M
[01/28 23:46:37] d2.utils.events INFO:  eta: 1 day, 16:58:10  iter: 3339  total_loss: 206.2  loss_mask: 19.85  loss_mask_0: 27.36  loss_mask_1: 19.9  loss_mask_2: 19.79  loss_mask_3: 19.81  loss_mask_4: 19.86  loss_mask_5: 19.82  loss_mask_6: 19.83  loss_mask_7: 19.78  loss_mask_8: 19.77  time: 2.6074  data_time: 0.0611  lr: 9.4977e-05  max_mem: 27639M
[01/28 23:47:29] d2.utils.events INFO:  eta: 1 day, 16:57:41  iter: 3359  total_loss: 210.7  loss_mask: 20.55  loss_mask_0: 26.91  loss_mask_1: 20.53  loss_mask_2: 20.49  loss_mask_3: 20.5  loss_mask_4: 20.46  loss_mask_5: 20.48  loss_mask_6: 20.5  loss_mask_7: 20.49  loss_mask_8: 20.47  time: 2.6074  data_time: 0.0649  lr: 9.4947e-05  max_mem: 27639M
[01/28 23:48:21] d2.utils.events INFO:  eta: 1 day, 16:56:44  iter: 3379  total_loss: 208.1  loss_mask: 20.25  loss_mask_0: 27.47  loss_mask_1: 20.12  loss_mask_2: 20.15  loss_mask_3: 20.2  loss_mask_4: 20.2  loss_mask_5: 20.11  loss_mask_6: 20.13  loss_mask_7: 20.26  loss_mask_8: 20.24  time: 2.6074  data_time: 0.0607  lr: 9.4917e-05  max_mem: 27639M
[01/28 23:49:13] d2.utils.events INFO:  eta: 1 day, 16:55:13  iter: 3399  total_loss: 202.5  loss_mask: 19.61  loss_mask_0: 25.97  loss_mask_1: 19.54  loss_mask_2: 19.65  loss_mask_3: 19.64  loss_mask_4: 19.65  loss_mask_5: 19.58  loss_mask_6: 19.59  loss_mask_7: 19.57  loss_mask_8: 19.62  time: 2.6074  data_time: 0.0643  lr: 9.4887e-05  max_mem: 27639M
[01/28 23:50:05] d2.utils.events INFO:  eta: 1 day, 16:54:13  iter: 3419  total_loss: 205.3  loss_mask: 19.74  loss_mask_0: 27.04  loss_mask_1: 19.67  loss_mask_2: 19.69  loss_mask_3: 19.71  loss_mask_4: 19.69  loss_mask_5: 19.64  loss_mask_6: 19.67  loss_mask_7: 19.75  loss_mask_8: 19.74  time: 2.6073  data_time: 0.0610  lr: 9.4857e-05  max_mem: 27639M
[01/28 23:50:58] d2.utils.events INFO:  eta: 1 day, 16:53:27  iter: 3439  total_loss: 217.1  loss_mask: 20.97  loss_mask_0: 26.7  loss_mask_1: 20.92  loss_mask_2: 20.94  loss_mask_3: 20.95  loss_mask_4: 20.96  loss_mask_5: 20.91  loss_mask_6: 20.97  loss_mask_7: 20.98  loss_mask_8: 20.98  time: 2.6074  data_time: 0.0587  lr: 9.4826e-05  max_mem: 27639M
[01/28 23:51:50] d2.utils.events INFO:  eta: 1 day, 16:52:37  iter: 3459  total_loss: 208.7  loss_mask: 20.25  loss_mask_0: 26.5  loss_mask_1: 20.15  loss_mask_2: 20.09  loss_mask_3: 20.16  loss_mask_4: 20.12  loss_mask_5: 20.16  loss_mask_6: 20.11  loss_mask_7: 20.14  loss_mask_8: 20.2  time: 2.6075  data_time: 0.0634  lr: 9.4796e-05  max_mem: 27639M
[01/28 23:52:42] d2.utils.events INFO:  eta: 1 day, 16:52:08  iter: 3479  total_loss: 205.5  loss_mask: 19.88  loss_mask_0: 27.13  loss_mask_1: 19.87  loss_mask_2: 19.88  loss_mask_3: 19.87  loss_mask_4: 19.88  loss_mask_5: 19.88  loss_mask_6: 19.85  loss_mask_7: 19.85  loss_mask_8: 19.91  time: 2.6075  data_time: 0.0585  lr: 9.4766e-05  max_mem: 27639M
[01/28 23:53:35] d2.utils.events INFO:  eta: 1 day, 16:51:31  iter: 3499  total_loss: 213.1  loss_mask: 20.6  loss_mask_0: 26.45  loss_mask_1: 20.42  loss_mask_2: 20.49  loss_mask_3: 20.5  loss_mask_4: 20.42  loss_mask_5: 20.43  loss_mask_6: 20.47  loss_mask_7: 20.59  loss_mask_8: 20.58  time: 2.6075  data_time: 0.0652  lr: 9.4736e-05  max_mem: 27639M
[01/28 23:54:27] d2.utils.events INFO:  eta: 1 day, 16:50:41  iter: 3519  total_loss: 212.5  loss_mask: 20.44  loss_mask_0: 27.13  loss_mask_1: 20.53  loss_mask_2: 20.47  loss_mask_3: 20.5  loss_mask_4: 20.6  loss_mask_5: 20.52  loss_mask_6: 20.73  loss_mask_7: 20.46  loss_mask_8: 20.49  time: 2.6076  data_time: 0.0652  lr: 9.4706e-05  max_mem: 27639M
[01/28 23:55:19] d2.utils.events INFO:  eta: 1 day, 16:49:23  iter: 3539  total_loss: 217.2  loss_mask: 21.02  loss_mask_0: 27.21  loss_mask_1: 21.03  loss_mask_2: 21.11  loss_mask_3: 21.06  loss_mask_4: 21.1  loss_mask_5: 21.07  loss_mask_6: 21.03  loss_mask_7: 21.06  loss_mask_8: 21.09  time: 2.6076  data_time: 0.0598  lr: 9.4675e-05  max_mem: 27639M
[01/28 23:56:12] d2.utils.events INFO:  eta: 1 day, 16:48:47  iter: 3559  total_loss: 200.7  loss_mask: 19.43  loss_mask_0: 25.46  loss_mask_1: 19.25  loss_mask_2: 19.28  loss_mask_3: 19.34  loss_mask_4: 19.24  loss_mask_5: 19.27  loss_mask_6: 19.26  loss_mask_7: 19.39  loss_mask_8: 19.39  time: 2.6076  data_time: 0.0611  lr: 9.4645e-05  max_mem: 27639M
[01/28 23:57:03] d2.utils.events INFO:  eta: 1 day, 16:47:16  iter: 3579  total_loss: 197  loss_mask: 18.83  loss_mask_0: 25.63  loss_mask_1: 18.78  loss_mask_2: 18.67  loss_mask_3: 18.73  loss_mask_4: 18.73  loss_mask_5: 18.7  loss_mask_6: 18.7  loss_mask_7: 18.75  loss_mask_8: 18.77  time: 2.6076  data_time: 0.0645  lr: 9.4615e-05  max_mem: 27639M
[01/28 23:57:55] d2.utils.events INFO:  eta: 1 day, 16:45:35  iter: 3599  total_loss: 210  loss_mask: 20.36  loss_mask_0: 26.52  loss_mask_1: 20.23  loss_mask_2: 20.28  loss_mask_3: 20.26  loss_mask_4: 20.33  loss_mask_5: 20.23  loss_mask_6: 20.14  loss_mask_7: 20.38  loss_mask_8: 20.38  time: 2.6075  data_time: 0.0629  lr: 9.4585e-05  max_mem: 27639M
[01/28 23:58:48] d2.utils.events INFO:  eta: 1 day, 16:44:42  iter: 3619  total_loss: 208.8  loss_mask: 20.19  loss_mask_0: 27.23  loss_mask_1: 20.1  loss_mask_2: 20.16  loss_mask_3: 20.17  loss_mask_4: 20.16  loss_mask_5: 20.1  loss_mask_6: 20.13  loss_mask_7: 20.26  loss_mask_8: 20.2  time: 2.6075  data_time: 0.0657  lr: 9.4555e-05  max_mem: 27639M
[01/28 23:59:40] d2.utils.events INFO:  eta: 1 day, 16:43:37  iter: 3639  total_loss: 205.1  loss_mask: 19.86  loss_mask_0: 25.78  loss_mask_1: 19.93  loss_mask_2: 19.89  loss_mask_3: 19.84  loss_mask_4: 19.85  loss_mask_5: 19.94  loss_mask_6: 19.87  loss_mask_7: 19.82  loss_mask_8: 19.81  time: 2.6075  data_time: 0.0634  lr: 9.4525e-05  max_mem: 27639M
[01/29 00:00:32] d2.utils.events INFO:  eta: 1 day, 16:42:12  iter: 3659  total_loss: 199.3  loss_mask: 19.28  loss_mask_0: 26.39  loss_mask_1: 19.22  loss_mask_2: 19.26  loss_mask_3: 19.28  loss_mask_4: 19.25  loss_mask_5: 19.24  loss_mask_6: 19.26  loss_mask_7: 19.31  loss_mask_8: 19.28  time: 2.6075  data_time: 0.0651  lr: 9.4494e-05  max_mem: 27639M
[01/29 00:01:24] d2.utils.events INFO:  eta: 1 day, 16:41:10  iter: 3679  total_loss: 208.1  loss_mask: 20.04  loss_mask_0: 26.97  loss_mask_1: 20.02  loss_mask_2: 19.99  loss_mask_3: 20.04  loss_mask_4: 20.02  loss_mask_5: 20.02  loss_mask_6: 20  loss_mask_7: 20.03  loss_mask_8: 20.02  time: 2.6074  data_time: 0.0639  lr: 9.4464e-05  max_mem: 27639M
[01/29 00:02:16] d2.utils.events INFO:  eta: 1 day, 16:40:11  iter: 3699  total_loss: 190.4  loss_mask: 18.21  loss_mask_0: 25.73  loss_mask_1: 18.14  loss_mask_2: 18.15  loss_mask_3: 18.18  loss_mask_4: 18.11  loss_mask_5: 18.12  loss_mask_6: 18.14  loss_mask_7: 18.16  loss_mask_8: 18.17  time: 2.6075  data_time: 0.0683  lr: 9.4434e-05  max_mem: 27639M
[01/29 00:03:08] d2.utils.events INFO:  eta: 1 day, 16:39:01  iter: 3719  total_loss: 213.4  loss_mask: 20.61  loss_mask_0: 27.14  loss_mask_1: 20.48  loss_mask_2: 20.55  loss_mask_3: 20.65  loss_mask_4: 20.69  loss_mask_5: 20.6  loss_mask_6: 20.59  loss_mask_7: 20.66  loss_mask_8: 20.6  time: 2.6075  data_time: 0.0554  lr: 9.4404e-05  max_mem: 27639M
[01/29 00:04:00] d2.utils.events INFO:  eta: 1 day, 16:38:03  iter: 3739  total_loss: 193.2  loss_mask: 18.75  loss_mask_0: 25.62  loss_mask_1: 18.87  loss_mask_2: 18.73  loss_mask_3: 18.74  loss_mask_4: 18.79  loss_mask_5: 18.66  loss_mask_6: 18.76  loss_mask_7: 18.74  loss_mask_8: 18.76  time: 2.6074  data_time: 0.0621  lr: 9.4374e-05  max_mem: 27639M
[01/29 00:04:52] d2.utils.events INFO:  eta: 1 day, 16:37:10  iter: 3759  total_loss: 196.7  loss_mask: 18.99  loss_mask_0: 26.89  loss_mask_1: 18.95  loss_mask_2: 18.97  loss_mask_3: 18.98  loss_mask_4: 18.97  loss_mask_5: 18.98  loss_mask_6: 18.95  loss_mask_7: 19.02  loss_mask_8: 19.02  time: 2.6074  data_time: 0.0613  lr: 9.4343e-05  max_mem: 27639M
[01/29 00:05:45] d2.utils.events INFO:  eta: 1 day, 16:36:18  iter: 3779  total_loss: 210.7  loss_mask: 20.44  loss_mask_0: 26.85  loss_mask_1: 20.5  loss_mask_2: 20.41  loss_mask_3: 20.45  loss_mask_4: 20.46  loss_mask_5: 20.46  loss_mask_6: 20.44  loss_mask_7: 20.44  loss_mask_8: 20.43  time: 2.6074  data_time: 0.0674  lr: 9.4313e-05  max_mem: 27639M
[01/29 00:06:37] d2.utils.events INFO:  eta: 1 day, 16:35:30  iter: 3799  total_loss: 208.5  loss_mask: 20.06  loss_mask_0: 26.68  loss_mask_1: 19.92  loss_mask_2: 20.02  loss_mask_3: 20.01  loss_mask_4: 19.99  loss_mask_5: 19.99  loss_mask_6: 20.03  loss_mask_7: 20.05  loss_mask_8: 20.07  time: 2.6074  data_time: 0.0687  lr: 9.4283e-05  max_mem: 27639M
[01/29 00:07:29] d2.utils.events INFO:  eta: 1 day, 16:34:10  iter: 3819  total_loss: 203  loss_mask: 19.67  loss_mask_0: 24.74  loss_mask_1: 19.71  loss_mask_2: 19.65  loss_mask_3: 19.65  loss_mask_4: 19.71  loss_mask_5: 19.65  loss_mask_6: 19.63  loss_mask_7: 19.69  loss_mask_8: 19.68  time: 2.6075  data_time: 0.0716  lr: 9.4253e-05  max_mem: 27639M
[01/29 00:08:21] d2.utils.events INFO:  eta: 1 day, 16:33:10  iter: 3839  total_loss: 195.5  loss_mask: 18.78  loss_mask_0: 26.84  loss_mask_1: 18.65  loss_mask_2: 18.73  loss_mask_3: 18.73  loss_mask_4: 18.68  loss_mask_5: 18.71  loss_mask_6: 18.68  loss_mask_7: 18.77  loss_mask_8: 18.75  time: 2.6074  data_time: 0.0614  lr: 9.4223e-05  max_mem: 27639M
[01/29 00:09:13] d2.utils.events INFO:  eta: 1 day, 16:32:30  iter: 3859  total_loss: 206.9  loss_mask: 19.94  loss_mask_0: 26.82  loss_mask_1: 19.9  loss_mask_2: 19.9  loss_mask_3: 19.93  loss_mask_4: 19.98  loss_mask_5: 19.85  loss_mask_6: 19.84  loss_mask_7: 19.97  loss_mask_8: 19.92  time: 2.6074  data_time: 0.0673  lr: 9.4192e-05  max_mem: 27639M
[01/29 00:10:06] d2.utils.events INFO:  eta: 1 day, 16:31:55  iter: 3879  total_loss: 209.8  loss_mask: 20.36  loss_mask_0: 26.92  loss_mask_1: 20.41  loss_mask_2: 20.43  loss_mask_3: 20.44  loss_mask_4: 20.41  loss_mask_5: 20.33  loss_mask_6: 20.34  loss_mask_7: 20.4  loss_mask_8: 20.35  time: 2.6075  data_time: 0.0531  lr: 9.4162e-05  max_mem: 27639M
[01/29 00:10:58] d2.utils.events INFO:  eta: 1 day, 16:31:03  iter: 3899  total_loss: 199.7  loss_mask: 19.42  loss_mask_0: 25.39  loss_mask_1: 19.35  loss_mask_2: 19.32  loss_mask_3: 19.35  loss_mask_4: 19.3  loss_mask_5: 19.3  loss_mask_6: 19.33  loss_mask_7: 19.52  loss_mask_8: 19.44  time: 2.6075  data_time: 0.0640  lr: 9.4132e-05  max_mem: 27639M
[01/29 00:11:50] d2.utils.events INFO:  eta: 1 day, 16:30:11  iter: 3919  total_loss: 213.7  loss_mask: 20.71  loss_mask_0: 27.38  loss_mask_1: 20.69  loss_mask_2: 20.7  loss_mask_3: 20.73  loss_mask_4: 20.76  loss_mask_5: 20.71  loss_mask_6: 20.76  loss_mask_7: 20.74  loss_mask_8: 20.76  time: 2.6075  data_time: 0.0728  lr: 9.4102e-05  max_mem: 27639M
[01/29 00:12:42] d2.utils.events INFO:  eta: 1 day, 16:29:24  iter: 3939  total_loss: 203.9  loss_mask: 19.7  loss_mask_0: 26.88  loss_mask_1: 19.66  loss_mask_2: 19.66  loss_mask_3: 19.68  loss_mask_4: 19.68  loss_mask_5: 19.71  loss_mask_6: 19.68  loss_mask_7: 19.67  loss_mask_8: 19.7  time: 2.6075  data_time: 0.0576  lr: 9.4072e-05  max_mem: 27639M
[01/29 00:13:35] d2.utils.events INFO:  eta: 1 day, 16:28:37  iter: 3959  total_loss: 205.3  loss_mask: 19.73  loss_mask_0: 27.26  loss_mask_1: 19.85  loss_mask_2: 19.69  loss_mask_3: 19.7  loss_mask_4: 19.74  loss_mask_5: 19.73  loss_mask_6: 19.71  loss_mask_7: 19.73  loss_mask_8: 19.74  time: 2.6074  data_time: 0.0655  lr: 9.4041e-05  max_mem: 27639M
[01/29 00:14:27] d2.utils.events INFO:  eta: 1 day, 16:27:39  iter: 3979  total_loss: 199.1  loss_mask: 19.32  loss_mask_0: 25.11  loss_mask_1: 19.24  loss_mask_2: 19.24  loss_mask_3: 19.23  loss_mask_4: 19.25  loss_mask_5: 19.24  loss_mask_6: 19.23  loss_mask_7: 19.34  loss_mask_8: 19.35  time: 2.6074  data_time: 0.0613  lr: 9.4011e-05  max_mem: 27639M
[01/29 00:15:19] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 00:15:20] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 00:15:20] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 00:25:28] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 22.47080460194458, 'error_1pix': 0.9428623978020956, 'error_3pix': 0.8684241646152233, 'mIoU': 0.28129683419208823, 'fwIoU': 0.7467350605180657, 'IoU-0': 0.0, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.15474721867955415, 'IoU-6': 0.024748845621032065, 'IoU-7': 0.0025171279112872593, 'IoU-8': 0.0019121111756069244, 'IoU-9': 0.006584613776004674, 'IoU-10': 0.5570135434894802, 'IoU-11': 0.6270488343627334, 'IoU-12': 0.8796851070717121, 'IoU-13': 1.5058869606283372, 'IoU-14': 1.674393761932047, 'IoU-15': 1.3655456312361658, 'IoU-16': 1.1795982168695993, 'IoU-17': 1.2296900185322972, 'IoU-18': 1.0078074372921895, 'IoU-19': 1.6858519881695913, 'IoU-20': 1.0768308733854481, 'IoU-21': 1.1496864777727331, 'IoU-22': 1.4437870069471324, 'IoU-23': 1.3546481510496968, 'IoU-24': 0.9467210787251702, 'IoU-25': 0.9520007597552718, 'IoU-26': 1.1688311056008707, 'IoU-27': 1.4457668299906479, 'IoU-28': 1.2739204765228007, 'IoU-29': 1.6338888502997702, 'IoU-30': 1.6390652349885042, 'IoU-31': 1.4887595325208824, 'IoU-32': 1.2502663737938582, 'IoU-33': 1.1379615638353202, 'IoU-34': 1.1611099903941204, 'IoU-35': 1.272241002197236, 'IoU-36': 1.381545760120098, 'IoU-37': 1.4430380726622913, 'IoU-38': 1.4642914297702507, 'IoU-39': 1.1060898218929673, 'IoU-40': 1.215957911305407, 'IoU-41': 0.8396172719025781, 'IoU-42': 0.9708978796521593, 'IoU-43': 0.9665048281182602, 'IoU-44': 0.9085227343045935, 'IoU-45': 0.6721976117853619, 'IoU-46': 0.7519114060694524, 'IoU-47': 0.7677362395039105, 'IoU-48': 0.6021301397377573, 'IoU-49': 0.5881052232302022, 'IoU-50': 0.6543192875959355, 'IoU-51': 0.37735064075416097, 'IoU-52': 0.4245358635558379, 'IoU-53': 0.3791488331320446, 'IoU-54': 0.657883460731029, 'IoU-55': 0.5127038936531398, 'IoU-56': 0.3146598625721787, 'IoU-57': 0.14616400418893105, 'IoU-58': 0.1319541939650551, 'IoU-59': 0.21193912314039684, 'IoU-60': 0.12242872083624641, 'IoU-61': 0.35719347332135526, 'IoU-62': 0.2133525755018613, 'IoU-63': 0.10859608811843006, 'IoU-64': 0.09270304443530228, 'IoU-65': 0.0913742497605419, 'IoU-66': 0.2024015425599249, 'IoU-67': 0.035986418441451395, 'IoU-68': 0.028988472157091702, 'IoU-69': 0.10440771055448622, 'IoU-70': 0.30190857322896225, 'IoU-71': 0.14921522204402576, 'IoU-72': 0.3128717216394017, 'IoU-73': 0.10988464330723609, 'IoU-74': 0.005609321289653081, 'IoU-75': 0.139216893058094, 'IoU-76': 0.032890237394201396, 'IoU-77': 0.0491300426644753, 'IoU-78': 0.21779243171299797, 'IoU-79': 0.14818831065325855, 'IoU-80': 0.10526010521613342, 'IoU-81': 0.10103207484274279, 'IoU-82': 0.05641968578771594, 'IoU-83': 0.036378184495289415, 'IoU-84': 0.11114116056659502, 'IoU-85': 0.12236624959238837, 'IoU-86': 0.0, 'IoU-87': 0.02770328628525287, 'IoU-88': 0.034537830436938595, 'IoU-89': 0.08961735325009396, 'IoU-90': 0.09114970713264077, 'IoU-91': 0.07216373661847199, 'IoU-92': 0.05796120468666827, 'IoU-93': 0.0, 'IoU-94': 0.1610837164069763, 'IoU-95': 0.03640410888294409, 'IoU-96': 0.058271599030044, 'IoU-97': 0.04975117864469934, 'IoU-98': 0.03791717145827856, 'IoU-99': 0.039253905689412116, 'IoU-100': 0.061540623595466304, 'IoU-101': 0.0038318553738256158, 'IoU-102': 0.029081522768560967, 'IoU-103': 0.004544513509828773, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0014540139485226622, 'IoU-108': 0.022945556649774643, 'IoU-109': 0.0, 'IoU-110': 0.0005469393793227744, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.1089334099708362, 'IoU-126': 0.0, 'IoU-127': 0.017308167437238838, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.13982822686626104, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.6802965021799292, 'pACC': 1.88291910331384, 'ACC-0': 0.0, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.28091527879263245, 'ACC-6': 0.06898490437829942, 'ACC-7': 0.01203277289781988, 'ACC-8': 0.004663728517700515, 'ACC-9': 0.009219809525221506, 'ACC-10': 0.6971426291502448, 'ACC-11': 0.7717173543795406, 'ACC-12': 1.1034896905360074, 'ACC-13': 2.153315723025518, 'ACC-14': 2.7252024123557765, 'ACC-15': 2.2690706118058763, 'ACC-16': 2.1901773273082052, 'ACC-17': 2.5727414290056245, 'ACC-18': 2.1401720493717793, 'ACC-19': 3.9966572748898868, 'ACC-20': 2.391803521387666, 'ACC-21': 2.988402103357909, 'ACC-22': 3.6215496690796054, 'ACC-23': 4.229718910363596, 'ACC-24': 2.7569614922458254, 'ACC-25': 3.1305085222404196, 'ACC-26': 3.796209896356395, 'ACC-27': 4.46641105215568, 'ACC-28': 4.6593942934684645, 'ACC-29': 5.976414036518838, 'ACC-30': 5.90944914169583, 'ACC-31': 5.032311481000503, 'ACC-32': 3.9379059482329772, 'ACC-33': 4.1908733214401614, 'ACC-34': 3.8892951168784737, 'ACC-35': 3.675677812703454, 'ACC-36': 4.2664415338204575, 'ACC-37': 4.420780506220775, 'ACC-38': 4.151957886763348, 'ACC-39': 2.947855757887662, 'ACC-40': 3.2782623948161964, 'ACC-41': 1.8118597764129576, 'ACC-42': 2.3360111517496778, 'ACC-43': 2.2761625387049316, 'ACC-44': 1.736995238403899, 'ACC-45': 1.1523392172792077, 'ACC-46': 1.3831411869522903, 'ACC-47': 1.6368123409173565, 'ACC-48': 1.1475911561675312, 'ACC-49': 1.16263490321039, 'ACC-50': 1.062697224207762, 'ACC-51': 0.6502816937098259, 'ACC-52': 0.62889476071719, 'ACC-53': 0.6121345641434189, 'ACC-54': 1.0901097655192689, 'ACC-55': 0.7604475888823048, 'ACC-56': 0.4790754086829771, 'ACC-57': 0.20477552116814957, 'ACC-58': 0.1885632179608768, 'ACC-59': 0.35025956762405575, 'ACC-60': 0.15230179847789768, 'ACC-61': 0.5869391453694602, 'ACC-62': 0.3096076964759769, 'ACC-63': 0.1240376910783615, 'ACC-64': 0.13827357628187384, 'ACC-65': 0.1287411215364657, 'ACC-66': 0.2662067651636468, 'ACC-67': 0.03991964861398514, 'ACC-68': 0.032221245504855785, 'ACC-69': 0.1386605859799965, 'ACC-70': 0.4166739033464808, 'ACC-71': 0.2171224875365716, 'ACC-72': 0.4379382723638621, 'ACC-73': 0.1286259115191625, 'ACC-74': 0.005925740665841928, 'ACC-75': 0.1626336761893946, 'ACC-76': 0.034684581067450544, 'ACC-77': 0.051884805906287725, 'ACC-78': 0.2922951089152005, 'ACC-79': 0.1650565880456438, 'ACC-80': 0.1111770781925177, 'ACC-81': 0.12411954567060786, 'ACC-82': 0.06954337645750248, 'ACC-83': 0.0468554589225092, 'ACC-84': 0.13059978475703735, 'ACC-85': 0.13688084792986813, 'ACC-86': 0.0, 'ACC-87': 0.03472191635615143, 'ACC-88': 0.039024961647449126, 'ACC-89': 0.12522059029854982, 'ACC-90': 0.1095161125596887, 'ACC-91': 0.08228552082366622, 'ACC-92': 0.06219783604428589, 'ACC-93': 0.0, 'ACC-94': 0.21153092925208797, 'ACC-95': 0.045298722884511866, 'ACC-96': 0.0632653268539247, 'ACC-97': 0.058553332069814064, 'ACC-98': 0.04145003636807416, 'ACC-99': 0.05100635834271182, 'ACC-100': 0.08735779270435723, 'ACC-101': 0.0046855843912437176, 'ACC-102': 0.032487539646579064, 'ACC-103': 0.005100595069424766, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0016589863756423814, 'ACC-108': 0.026226865983478453, 'ACC-109': 0.0, 'ACC-110': 0.0006323074796856168, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.1701721735593014, 'ACC-126': 0.0, 'ACC-127': 0.022544832677625245, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.188885940381174, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 00:25:28] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 00:25:28] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 00:25:28] d2.evaluation.testing INFO: copypaste: 22.4708,0.9429,0.8684,0.2813,0.7467,0.6803,1.8829
[01/29 00:25:28] d2.utils.events INFO:  eta: 1 day, 16:26:53  iter: 3999  total_loss: 198.7  loss_mask: 19.15  loss_mask_0: 25.89  loss_mask_1: 19.16  loss_mask_2: 19.1  loss_mask_3: 19.13  loss_mask_4: 19.08  loss_mask_5: 19.1  loss_mask_6: 19.1  loss_mask_7: 19.14  loss_mask_8: 19.16  time: 2.6074  data_time: 0.0626  lr: 9.3981e-05  max_mem: 27639M
[01/29 00:26:20] d2.utils.events INFO:  eta: 1 day, 16:26:18  iter: 4019  total_loss: 190.8  loss_mask: 18.39  loss_mask_0: 26.57  loss_mask_1: 18.4  loss_mask_2: 18.35  loss_mask_3: 18.38  loss_mask_4: 18.35  loss_mask_5: 18.35  loss_mask_6: 18.34  loss_mask_7: 18.33  loss_mask_8: 18.37  time: 2.6075  data_time: 0.0529  lr: 9.3951e-05  max_mem: 27639M
[01/29 00:27:13] d2.utils.events INFO:  eta: 1 day, 16:25:28  iter: 4039  total_loss: 202.3  loss_mask: 19.58  loss_mask_0: 27.24  loss_mask_1: 19.6  loss_mask_2: 19.59  loss_mask_3: 19.55  loss_mask_4: 19.55  loss_mask_5: 19.53  loss_mask_6: 19.52  loss_mask_7: 19.57  loss_mask_8: 19.61  time: 2.6075  data_time: 0.0590  lr: 9.3921e-05  max_mem: 27639M
[01/29 00:28:05] d2.utils.events INFO:  eta: 1 day, 16:24:29  iter: 4059  total_loss: 207.2  loss_mask: 20.18  loss_mask_0: 26.94  loss_mask_1: 20.13  loss_mask_2: 20.08  loss_mask_3: 20.08  loss_mask_4: 20.14  loss_mask_5: 20.15  loss_mask_6: 20.14  loss_mask_7: 20.14  loss_mask_8: 20.23  time: 2.6075  data_time: 0.0602  lr: 9.389e-05  max_mem: 27639M
[01/29 00:28:57] d2.utils.events INFO:  eta: 1 day, 16:23:41  iter: 4079  total_loss: 202.9  loss_mask: 19.64  loss_mask_0: 26.32  loss_mask_1: 19.69  loss_mask_2: 19.59  loss_mask_3: 19.64  loss_mask_4: 19.63  loss_mask_5: 19.63  loss_mask_6: 19.65  loss_mask_7: 19.63  loss_mask_8: 19.62  time: 2.6076  data_time: 0.0591  lr: 9.386e-05  max_mem: 27639M
[01/29 00:29:50] d2.utils.events INFO:  eta: 1 day, 16:22:47  iter: 4099  total_loss: 206.1  loss_mask: 20.13  loss_mask_0: 26.21  loss_mask_1: 20.01  loss_mask_2: 20.13  loss_mask_3: 20.1  loss_mask_4: 20.1  loss_mask_5: 20.11  loss_mask_6: 20.09  loss_mask_7: 20.12  loss_mask_8: 20.16  time: 2.6076  data_time: 0.0648  lr: 9.383e-05  max_mem: 27639M
[01/29 00:30:42] d2.utils.events INFO:  eta: 1 day, 16:21:35  iter: 4119  total_loss: 215.1  loss_mask: 20.82  loss_mask_0: 27.23  loss_mask_1: 20.73  loss_mask_2: 20.79  loss_mask_3: 20.8  loss_mask_4: 20.82  loss_mask_5: 20.75  loss_mask_6: 20.78  loss_mask_7: 20.86  loss_mask_8: 20.83  time: 2.6076  data_time: 0.0555  lr: 9.38e-05  max_mem: 27639M
[01/29 00:31:34] d2.utils.events INFO:  eta: 1 day, 16:21:03  iter: 4139  total_loss: 218.3  loss_mask: 21  loss_mask_0: 27.41  loss_mask_1: 20.99  loss_mask_2: 20.97  loss_mask_3: 21  loss_mask_4: 20.98  loss_mask_5: 21.07  loss_mask_6: 21.02  loss_mask_7: 20.98  loss_mask_8: 21.01  time: 2.6077  data_time: 0.0639  lr: 9.377e-05  max_mem: 27639M
[01/29 00:32:26] d2.utils.events INFO:  eta: 1 day, 16:20:07  iter: 4159  total_loss: 206.9  loss_mask: 19.97  loss_mask_0: 26.16  loss_mask_1: 19.96  loss_mask_2: 19.94  loss_mask_3: 19.98  loss_mask_4: 19.91  loss_mask_5: 19.98  loss_mask_6: 19.97  loss_mask_7: 19.92  loss_mask_8: 19.96  time: 2.6076  data_time: 0.0530  lr: 9.3739e-05  max_mem: 27639M
[01/29 00:33:18] d2.utils.events INFO:  eta: 1 day, 16:19:15  iter: 4179  total_loss: 202.7  loss_mask: 19.8  loss_mask_0: 25.93  loss_mask_1: 19.84  loss_mask_2: 19.77  loss_mask_3: 19.78  loss_mask_4: 19.79  loss_mask_5: 19.86  loss_mask_6: 19.74  loss_mask_7: 19.77  loss_mask_8: 19.84  time: 2.6076  data_time: 0.0611  lr: 9.3709e-05  max_mem: 27639M
[01/29 00:34:11] d2.utils.events INFO:  eta: 1 day, 16:18:27  iter: 4199  total_loss: 196  loss_mask: 18.88  loss_mask_0: 25.24  loss_mask_1: 18.88  loss_mask_2: 18.95  loss_mask_3: 18.96  loss_mask_4: 18.91  loss_mask_5: 18.89  loss_mask_6: 18.88  loss_mask_7: 18.9  loss_mask_8: 18.95  time: 2.6076  data_time: 0.0582  lr: 9.3679e-05  max_mem: 27639M
[01/29 00:35:03] d2.utils.events INFO:  eta: 1 day, 16:17:35  iter: 4219  total_loss: 205.2  loss_mask: 19.87  loss_mask_0: 26.83  loss_mask_1: 19.85  loss_mask_2: 19.86  loss_mask_3: 19.88  loss_mask_4: 19.83  loss_mask_5: 19.85  loss_mask_6: 19.87  loss_mask_7: 19.86  loss_mask_8: 19.89  time: 2.6076  data_time: 0.0627  lr: 9.3649e-05  max_mem: 27639M
[01/29 00:35:55] d2.utils.events INFO:  eta: 1 day, 16:16:45  iter: 4239  total_loss: 210.6  loss_mask: 20.46  loss_mask_0: 26.88  loss_mask_1: 20.63  loss_mask_2: 20.48  loss_mask_3: 20.49  loss_mask_4: 20.51  loss_mask_5: 20.5  loss_mask_6: 20.5  loss_mask_7: 20.49  loss_mask_8: 20.46  time: 2.6076  data_time: 0.0628  lr: 9.3618e-05  max_mem: 27639M
[01/29 00:36:47] d2.utils.events INFO:  eta: 1 day, 16:15:49  iter: 4259  total_loss: 202.5  loss_mask: 19.53  loss_mask_0: 26.49  loss_mask_1: 19.5  loss_mask_2: 19.53  loss_mask_3: 19.51  loss_mask_4: 19.49  loss_mask_5: 19.55  loss_mask_6: 19.54  loss_mask_7: 19.58  loss_mask_8: 19.61  time: 2.6076  data_time: 0.0660  lr: 9.3588e-05  max_mem: 27639M
[01/29 00:37:40] d2.utils.events INFO:  eta: 1 day, 16:14:55  iter: 4279  total_loss: 218.4  loss_mask: 20.93  loss_mask_0: 27.47  loss_mask_1: 20.94  loss_mask_2: 20.92  loss_mask_3: 20.92  loss_mask_4: 20.93  loss_mask_5: 20.95  loss_mask_6: 20.96  loss_mask_7: 20.94  loss_mask_8: 20.93  time: 2.6077  data_time: 0.0644  lr: 9.3558e-05  max_mem: 27639M
[01/29 00:38:32] d2.utils.events INFO:  eta: 1 day, 16:14:03  iter: 4299  total_loss: 206.7  loss_mask: 19.85  loss_mask_0: 26.77  loss_mask_1: 19.8  loss_mask_2: 19.73  loss_mask_3: 19.79  loss_mask_4: 19.74  loss_mask_5: 19.79  loss_mask_6: 19.77  loss_mask_7: 19.78  loss_mask_8: 19.86  time: 2.6077  data_time: 0.0627  lr: 9.3528e-05  max_mem: 27639M
[01/29 00:39:24] d2.utils.events INFO:  eta: 1 day, 16:13:01  iter: 4319  total_loss: 209.1  loss_mask: 20.26  loss_mask_0: 26.66  loss_mask_1: 20.34  loss_mask_2: 20.23  loss_mask_3: 20.25  loss_mask_4: 20.28  loss_mask_5: 20.16  loss_mask_6: 20.15  loss_mask_7: 20.31  loss_mask_8: 20.23  time: 2.6077  data_time: 0.0645  lr: 9.3498e-05  max_mem: 27639M
[01/29 00:40:16] d2.utils.events INFO:  eta: 1 day, 16:12:04  iter: 4339  total_loss: 195.4  loss_mask: 18.86  loss_mask_0: 26.71  loss_mask_1: 18.81  loss_mask_2: 18.87  loss_mask_3: 18.82  loss_mask_4: 18.79  loss_mask_5: 18.81  loss_mask_6: 18.77  loss_mask_7: 18.8  loss_mask_8: 18.89  time: 2.6077  data_time: 0.0648  lr: 9.3467e-05  max_mem: 27639M
[01/29 00:41:08] d2.utils.events INFO:  eta: 1 day, 16:10:38  iter: 4359  total_loss: 200.2  loss_mask: 19.2  loss_mask_0: 26.57  loss_mask_1: 19.2  loss_mask_2: 19.24  loss_mask_3: 19.22  loss_mask_4: 19.19  loss_mask_5: 19.26  loss_mask_6: 19.19  loss_mask_7: 19.16  loss_mask_8: 19.27  time: 2.6077  data_time: 0.0663  lr: 9.3437e-05  max_mem: 27639M
[01/29 00:42:01] d2.utils.events INFO:  eta: 1 day, 16:09:46  iter: 4379  total_loss: 215.3  loss_mask: 21.01  loss_mask_0: 26.79  loss_mask_1: 20.72  loss_mask_2: 20.84  loss_mask_3: 20.95  loss_mask_4: 20.96  loss_mask_5: 20.99  loss_mask_6: 21  loss_mask_7: 20.96  loss_mask_8: 20.96  time: 2.6077  data_time: 0.0540  lr: 9.3407e-05  max_mem: 27639M
[01/29 00:42:53] d2.utils.events INFO:  eta: 1 day, 16:09:02  iter: 4399  total_loss: 212.8  loss_mask: 20.71  loss_mask_0: 27.24  loss_mask_1: 20.74  loss_mask_2: 20.66  loss_mask_3: 20.67  loss_mask_4: 20.66  loss_mask_5: 20.66  loss_mask_6: 20.68  loss_mask_7: 20.66  loss_mask_8: 20.72  time: 2.6076  data_time: 0.0632  lr: 9.3377e-05  max_mem: 27639M
[01/29 00:43:45] d2.utils.events INFO:  eta: 1 day, 16:08:25  iter: 4419  total_loss: 200.7  loss_mask: 19.44  loss_mask_0: 26.1  loss_mask_1: 19.35  loss_mask_2: 19.39  loss_mask_3: 19.43  loss_mask_4: 19.42  loss_mask_5: 19.38  loss_mask_6: 19.38  loss_mask_7: 19.41  loss_mask_8: 19.42  time: 2.6077  data_time: 0.0580  lr: 9.3346e-05  max_mem: 27639M
[01/29 00:44:37] d2.utils.events INFO:  eta: 1 day, 16:07:33  iter: 4439  total_loss: 197.9  loss_mask: 19.42  loss_mask_0: 26.63  loss_mask_1: 19.43  loss_mask_2: 19.44  loss_mask_3: 19.41  loss_mask_4: 19.42  loss_mask_5: 19.45  loss_mask_6: 19.41  loss_mask_7: 19.44  loss_mask_8: 19.47  time: 2.6077  data_time: 0.0617  lr: 9.3316e-05  max_mem: 27639M
[01/29 00:45:29] d2.utils.events INFO:  eta: 1 day, 16:06:41  iter: 4459  total_loss: 215.6  loss_mask: 20.68  loss_mask_0: 27.7  loss_mask_1: 20.74  loss_mask_2: 20.67  loss_mask_3: 20.7  loss_mask_4: 20.68  loss_mask_5: 20.66  loss_mask_6: 20.7  loss_mask_7: 20.65  loss_mask_8: 20.67  time: 2.6076  data_time: 0.0595  lr: 9.3286e-05  max_mem: 27639M
[01/29 00:46:21] d2.utils.events INFO:  eta: 1 day, 16:05:26  iter: 4479  total_loss: 206.4  loss_mask: 19.92  loss_mask_0: 26.42  loss_mask_1: 19.96  loss_mask_2: 19.89  loss_mask_3: 19.92  loss_mask_4: 19.91  loss_mask_5: 19.91  loss_mask_6: 19.88  loss_mask_7: 19.94  loss_mask_8: 19.91  time: 2.6076  data_time: 0.0583  lr: 9.3256e-05  max_mem: 27639M
[01/29 00:47:14] d2.utils.events INFO:  eta: 1 day, 16:04:57  iter: 4499  total_loss: 208.8  loss_mask: 20.2  loss_mask_0: 26.34  loss_mask_1: 20.24  loss_mask_2: 20.16  loss_mask_3: 20.16  loss_mask_4: 20.2  loss_mask_5: 20.18  loss_mask_6: 20.22  loss_mask_7: 20.22  loss_mask_8: 20.19  time: 2.6077  data_time: 0.0659  lr: 9.3225e-05  max_mem: 27639M
[01/29 00:48:06] d2.utils.events INFO:  eta: 1 day, 16:04:05  iter: 4519  total_loss: 202.4  loss_mask: 19.57  loss_mask_0: 25.19  loss_mask_1: 19.5  loss_mask_2: 19.46  loss_mask_3: 19.52  loss_mask_4: 19.53  loss_mask_5: 19.48  loss_mask_6: 19.51  loss_mask_7: 19.58  loss_mask_8: 19.5  time: 2.6076  data_time: 0.0626  lr: 9.3195e-05  max_mem: 27639M
[01/29 00:48:58] d2.utils.events INFO:  eta: 1 day, 16:02:53  iter: 4539  total_loss: 197.9  loss_mask: 19.09  loss_mask_0: 27.47  loss_mask_1: 19.1  loss_mask_2: 19.08  loss_mask_3: 19.06  loss_mask_4: 19.05  loss_mask_5: 19.1  loss_mask_6: 19.08  loss_mask_7: 19.11  loss_mask_8: 19.13  time: 2.6076  data_time: 0.0630  lr: 9.3165e-05  max_mem: 27639M
[01/29 00:49:50] d2.utils.events INFO:  eta: 1 day, 16:01:10  iter: 4559  total_loss: 203.3  loss_mask: 19.7  loss_mask_0: 26.63  loss_mask_1: 19.78  loss_mask_2: 19.71  loss_mask_3: 19.7  loss_mask_4: 19.69  loss_mask_5: 19.72  loss_mask_6: 19.73  loss_mask_7: 19.67  loss_mask_8: 19.69  time: 2.6076  data_time: 0.0695  lr: 9.3135e-05  max_mem: 27639M
[01/29 00:50:42] d2.utils.events INFO:  eta: 1 day, 16:00:15  iter: 4579  total_loss: 219  loss_mask: 21.17  loss_mask_0: 28.61  loss_mask_1: 21.06  loss_mask_2: 21.12  loss_mask_3: 21.14  loss_mask_4: 21.12  loss_mask_5: 21.05  loss_mask_6: 21.08  loss_mask_7: 21.19  loss_mask_8: 21.17  time: 2.6076  data_time: 0.0604  lr: 9.3105e-05  max_mem: 27639M
[01/29 00:51:34] d2.utils.events INFO:  eta: 1 day, 16:00:14  iter: 4599  total_loss: 215.1  loss_mask: 20.95  loss_mask_0: 27.41  loss_mask_1: 20.92  loss_mask_2: 20.97  loss_mask_3: 20.98  loss_mask_4: 20.93  loss_mask_5: 20.81  loss_mask_6: 20.89  loss_mask_7: 20.96  loss_mask_8: 21.01  time: 2.6076  data_time: 0.0685  lr: 9.3074e-05  max_mem: 27639M
[01/29 00:52:27] d2.utils.events INFO:  eta: 1 day, 15:58:34  iter: 4619  total_loss: 208.4  loss_mask: 20.02  loss_mask_0: 27.93  loss_mask_1: 20.05  loss_mask_2: 19.96  loss_mask_3: 20.02  loss_mask_4: 19.98  loss_mask_5: 19.96  loss_mask_6: 19.95  loss_mask_7: 19.96  loss_mask_8: 19.95  time: 2.6076  data_time: 0.0604  lr: 9.3044e-05  max_mem: 27639M
[01/29 00:53:19] d2.utils.events INFO:  eta: 1 day, 15:57:39  iter: 4639  total_loss: 218.5  loss_mask: 21.18  loss_mask_0: 26.99  loss_mask_1: 21.2  loss_mask_2: 21.08  loss_mask_3: 21.16  loss_mask_4: 21.18  loss_mask_5: 21.09  loss_mask_6: 21.19  loss_mask_7: 21.17  loss_mask_8: 21.11  time: 2.6076  data_time: 0.0583  lr: 9.3014e-05  max_mem: 27639M
[01/29 00:54:11] d2.utils.events INFO:  eta: 1 day, 15:57:15  iter: 4659  total_loss: 202.8  loss_mask: 19.96  loss_mask_0: 25.93  loss_mask_1: 19.81  loss_mask_2: 19.98  loss_mask_3: 19.91  loss_mask_4: 19.92  loss_mask_5: 19.92  loss_mask_6: 19.93  loss_mask_7: 19.97  loss_mask_8: 19.98  time: 2.6077  data_time: 0.0609  lr: 9.2984e-05  max_mem: 27639M
[01/29 00:55:03] d2.utils.events INFO:  eta: 1 day, 15:56:03  iter: 4679  total_loss: 202.6  loss_mask: 19.77  loss_mask_0: 26.7  loss_mask_1: 19.78  loss_mask_2: 19.82  loss_mask_3: 19.71  loss_mask_4: 19.75  loss_mask_5: 19.68  loss_mask_6: 19.72  loss_mask_7: 19.79  loss_mask_8: 19.81  time: 2.6076  data_time: 0.0608  lr: 9.2953e-05  max_mem: 27639M
[01/29 00:55:55] d2.utils.events INFO:  eta: 1 day, 15:55:07  iter: 4699  total_loss: 207.6  loss_mask: 20.01  loss_mask_0: 27.41  loss_mask_1: 19.94  loss_mask_2: 19.97  loss_mask_3: 19.96  loss_mask_4: 19.91  loss_mask_5: 19.99  loss_mask_6: 19.98  loss_mask_7: 19.97  loss_mask_8: 20.03  time: 2.6076  data_time: 0.0637  lr: 9.2923e-05  max_mem: 27639M
[01/29 00:56:47] d2.utils.events INFO:  eta: 1 day, 15:54:15  iter: 4719  total_loss: 202.9  loss_mask: 19.68  loss_mask_0: 26.41  loss_mask_1: 19.67  loss_mask_2: 19.61  loss_mask_3: 19.65  loss_mask_4: 19.58  loss_mask_5: 19.6  loss_mask_6: 19.58  loss_mask_7: 19.67  loss_mask_8: 19.7  time: 2.6076  data_time: 0.0613  lr: 9.2893e-05  max_mem: 27639M
[01/29 00:57:40] d2.utils.events INFO:  eta: 1 day, 15:53:23  iter: 4739  total_loss: 214.4  loss_mask: 20.65  loss_mask_0: 27.38  loss_mask_1: 20.52  loss_mask_2: 20.48  loss_mask_3: 20.53  loss_mask_4: 20.46  loss_mask_5: 20.44  loss_mask_6: 20.49  loss_mask_7: 20.59  loss_mask_8: 20.59  time: 2.6076  data_time: 0.0616  lr: 9.2863e-05  max_mem: 27639M
[01/29 00:58:32] d2.utils.events INFO:  eta: 1 day, 15:52:36  iter: 4759  total_loss: 212.9  loss_mask: 20.58  loss_mask_0: 27.69  loss_mask_1: 20.56  loss_mask_2: 20.49  loss_mask_3: 20.56  loss_mask_4: 20.46  loss_mask_5: 20.51  loss_mask_6: 20.53  loss_mask_7: 20.49  loss_mask_8: 20.54  time: 2.6077  data_time: 0.0651  lr: 9.2832e-05  max_mem: 27639M
[01/29 00:59:24] d2.utils.events INFO:  eta: 1 day, 15:51:39  iter: 4779  total_loss: 204.3  loss_mask: 19.71  loss_mask_0: 26.3  loss_mask_1: 19.57  loss_mask_2: 19.67  loss_mask_3: 19.65  loss_mask_4: 19.66  loss_mask_5: 19.63  loss_mask_6: 19.63  loss_mask_7: 19.73  loss_mask_8: 19.74  time: 2.6076  data_time: 0.0618  lr: 9.2802e-05  max_mem: 27639M
[01/29 01:00:16] d2.utils.events INFO:  eta: 1 day, 15:50:47  iter: 4799  total_loss: 205.2  loss_mask: 20.07  loss_mask_0: 26.3  loss_mask_1: 19.99  loss_mask_2: 20.07  loss_mask_3: 20.05  loss_mask_4: 20.03  loss_mask_5: 20.01  loss_mask_6: 20.01  loss_mask_7: 20.1  loss_mask_8: 20.07  time: 2.6076  data_time: 0.0587  lr: 9.2772e-05  max_mem: 27639M
[01/29 01:01:09] d2.utils.events INFO:  eta: 1 day, 15:49:52  iter: 4819  total_loss: 208.2  loss_mask: 19.95  loss_mask_0: 27.48  loss_mask_1: 19.95  loss_mask_2: 20.09  loss_mask_3: 20.08  loss_mask_4: 20.09  loss_mask_5: 20.12  loss_mask_6: 20.1  loss_mask_7: 20.06  loss_mask_8: 19.96  time: 2.6076  data_time: 0.0645  lr: 9.2742e-05  max_mem: 27639M
[01/29 01:02:01] d2.utils.events INFO:  eta: 1 day, 15:49:03  iter: 4839  total_loss: 208.9  loss_mask: 20.23  loss_mask_0: 27.65  loss_mask_1: 20.16  loss_mask_2: 20.17  loss_mask_3: 20.18  loss_mask_4: 20.17  loss_mask_5: 20.21  loss_mask_6: 20.15  loss_mask_7: 20.2  loss_mask_8: 20.24  time: 2.6076  data_time: 0.0603  lr: 9.2711e-05  max_mem: 27639M
[01/29 01:02:53] d2.utils.events INFO:  eta: 1 day, 15:48:01  iter: 4859  total_loss: 203.8  loss_mask: 19.64  loss_mask_0: 27.22  loss_mask_1: 19.61  loss_mask_2: 19.63  loss_mask_3: 19.65  loss_mask_4: 19.62  loss_mask_5: 19.6  loss_mask_6: 19.61  loss_mask_7: 19.66  loss_mask_8: 19.67  time: 2.6076  data_time: 0.0526  lr: 9.2681e-05  max_mem: 27639M
[01/29 01:03:45] d2.utils.events INFO:  eta: 1 day, 15:46:52  iter: 4879  total_loss: 202.7  loss_mask: 19.62  loss_mask_0: 26.69  loss_mask_1: 19.7  loss_mask_2: 19.56  loss_mask_3: 19.6  loss_mask_4: 19.58  loss_mask_5: 19.58  loss_mask_6: 19.59  loss_mask_7: 19.6  loss_mask_8: 19.56  time: 2.6076  data_time: 0.0679  lr: 9.2651e-05  max_mem: 27639M
[01/29 01:04:37] d2.utils.events INFO:  eta: 1 day, 15:46:01  iter: 4899  total_loss: 202.4  loss_mask: 19.46  loss_mask_0: 26.82  loss_mask_1: 19.46  loss_mask_2: 19.51  loss_mask_3: 19.48  loss_mask_4: 19.5  loss_mask_5: 19.51  loss_mask_6: 19.45  loss_mask_7: 19.46  loss_mask_8: 19.45  time: 2.6076  data_time: 0.0618  lr: 9.2621e-05  max_mem: 27639M
[01/29 01:05:29] d2.utils.events INFO:  eta: 1 day, 15:44:58  iter: 4919  total_loss: 202.1  loss_mask: 19.62  loss_mask_0: 25.93  loss_mask_1: 19.66  loss_mask_2: 19.71  loss_mask_3: 19.61  loss_mask_4: 19.61  loss_mask_5: 19.72  loss_mask_6: 19.61  loss_mask_7: 19.61  loss_mask_8: 19.69  time: 2.6076  data_time: 0.0667  lr: 9.259e-05  max_mem: 27639M
[01/29 01:06:21] d2.utils.events INFO:  eta: 1 day, 15:43:54  iter: 4939  total_loss: 195.5  loss_mask: 19.06  loss_mask_0: 24.91  loss_mask_1: 19  loss_mask_2: 19.12  loss_mask_3: 19.07  loss_mask_4: 19.09  loss_mask_5: 19.03  loss_mask_6: 19.03  loss_mask_7: 19.11  loss_mask_8: 19.07  time: 2.6075  data_time: 0.0630  lr: 9.256e-05  max_mem: 27639M
[01/29 01:07:13] d2.utils.events INFO:  eta: 1 day, 15:42:58  iter: 4959  total_loss: 208.2  loss_mask: 20.21  loss_mask_0: 26.19  loss_mask_1: 20.23  loss_mask_2: 20.25  loss_mask_3: 20.28  loss_mask_4: 20.23  loss_mask_5: 20.22  loss_mask_6: 20.23  loss_mask_7: 20.19  loss_mask_8: 20.2  time: 2.6075  data_time: 0.0697  lr: 9.253e-05  max_mem: 27639M
[01/29 01:08:05] d2.utils.events INFO:  eta: 1 day, 15:42:03  iter: 4979  total_loss: 201.2  loss_mask: 19.42  loss_mask_0: 25.56  loss_mask_1: 19.29  loss_mask_2: 19.32  loss_mask_3: 19.35  loss_mask_4: 19.32  loss_mask_5: 19.3  loss_mask_6: 19.35  loss_mask_7: 19.4  loss_mask_8: 19.44  time: 2.6075  data_time: 0.0667  lr: 9.25e-05  max_mem: 27639M
[01/29 01:08:58] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_nopretrain_instancenorm/model_0004999.pth
[01/29 01:08:59] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 01:08:59] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 01:08:59] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 01:19:13] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 22.473835949932575, 'error_1pix': 0.9424476215433295, 'error_3pix': 0.8701377570109606, 'mIoU': 0.3077746528912973, 'fwIoU': 0.7730257020596806, 'IoU-0': 0.0, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.050978758222304334, 'IoU-7': 0.15207240899592783, 'IoU-8': 3.523691362692495e-05, 'IoU-9': 0.4456335871351498, 'IoU-10': 0.7883343555237895, 'IoU-11': 0.7610948935282166, 'IoU-12': 0.6972057781592471, 'IoU-13': 1.1585977855409215, 'IoU-14': 1.5881533257099278, 'IoU-15': 1.4008040949095046, 'IoU-16': 0.8304725117195907, 'IoU-17': 0.7672157294257521, 'IoU-18': 1.0797375526371464, 'IoU-19': 1.5965922343458911, 'IoU-20': 1.1174502297800828, 'IoU-21': 1.021237515841253, 'IoU-22': 1.149974725609927, 'IoU-23': 1.1648223111674345, 'IoU-24': 1.0674449012164309, 'IoU-25': 1.195077042783577, 'IoU-26': 1.3783494391160307, 'IoU-27': 1.4636796484914771, 'IoU-28': 1.3610942292617758, 'IoU-29': 1.7734176799471444, 'IoU-30': 1.4322619818431925, 'IoU-31': 1.6334518654234373, 'IoU-32': 1.6301773791490966, 'IoU-33': 1.4299005880421638, 'IoU-34': 1.2518312860148773, 'IoU-35': 1.1416961525528717, 'IoU-36': 1.146568519103664, 'IoU-37': 1.466511290679634, 'IoU-38': 1.4539549238288014, 'IoU-39': 1.349264269120586, 'IoU-40': 1.3775415358504637, 'IoU-41': 1.1295223397470662, 'IoU-42': 1.0675417000850551, 'IoU-43': 1.2708119634757757, 'IoU-44': 0.8538320892746065, 'IoU-45': 0.8830078656380755, 'IoU-46': 0.8133560331655677, 'IoU-47': 0.9164425824652912, 'IoU-48': 0.9759350670246083, 'IoU-49': 0.644109947625694, 'IoU-50': 0.7916480577753114, 'IoU-51': 0.849253561343628, 'IoU-52': 0.448385967445153, 'IoU-53': 0.390148055533676, 'IoU-54': 0.44620951980887363, 'IoU-55': 0.2336071767250055, 'IoU-56': 0.4205412375014812, 'IoU-57': 0.41331897046528965, 'IoU-58': 0.3176457499401877, 'IoU-59': 0.2664414052570527, 'IoU-60': 0.3035132723357415, 'IoU-61': 0.23020014108633824, 'IoU-62': 0.20775098174078366, 'IoU-63': 0.1959996535115014, 'IoU-64': 0.14346343921751772, 'IoU-65': 0.36066618038754905, 'IoU-66': 0.08329284700527545, 'IoU-67': 0.007399277102069309, 'IoU-68': 0.24612882645766912, 'IoU-69': 0.1828454987729177, 'IoU-70': 0.25134185540755205, 'IoU-71': 0.3116067442236244, 'IoU-72': 0.2261798825286636, 'IoU-73': 0.019390002713913095, 'IoU-74': 0.02566985533917521, 'IoU-75': 0.1513291824856053, 'IoU-76': 0.36776461401586563, 'IoU-77': 0.3589846954884738, 'IoU-78': 0.30547750970621707, 'IoU-79': 0.16010473925021645, 'IoU-80': 0.07589618392886265, 'IoU-81': 0.16562249494531966, 'IoU-82': 0.1502272116468077, 'IoU-83': 0.10157084043375755, 'IoU-84': 0.15510351232120928, 'IoU-85': 0.16435252826940264, 'IoU-86': 0.05291718818517367, 'IoU-87': 0.1151110907024981, 'IoU-88': 0.03856601178604907, 'IoU-89': 0.1388239541199979, 'IoU-90': 0.056175620699269346, 'IoU-91': 0.07381372267937342, 'IoU-92': 0.11069786157105431, 'IoU-93': 0.05395207342322976, 'IoU-94': 0.10380884794090293, 'IoU-95': 0.007903003087042918, 'IoU-96': 0.0064867983131848515, 'IoU-97': 0.047922821881830995, 'IoU-98': 0.08116606743041299, 'IoU-99': 0.005384040386410168, 'IoU-100': 0.018829759700002956, 'IoU-101': 0.02199341905342258, 'IoU-102': 0.007583089062570014, 'IoU-103': 0.09085962632034857, 'IoU-104': 0.05110827720800206, 'IoU-105': 0.061766360306597136, 'IoU-106': 0.04311996219456383, 'IoU-107': 0.0445905130050564, 'IoU-108': 0.14126087232556664, 'IoU-109': 0.011320656340942457, 'IoU-110': 0.07133339476159235, 'IoU-111': 0.030049143362806733, 'IoU-112': 0.11532994172684936, 'IoU-113': 0.007383587455163871, 'IoU-114': 0.0030653248309396725, 'IoU-115': 0.01003488010453356, 'IoU-116': 0.1875113899664159, 'IoU-117': 0.0, 'IoU-118': 0.0006509146810215051, 'IoU-119': 0.11034261071544202, 'IoU-120': 0.07175049731257868, 'IoU-121': 0.0016176571691808367, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.7258165295679571, 'pACC': 1.9096726505777324, 'ACC-0': 0.0, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.23316897679865203, 'ACC-7': 0.2953498802192152, 'ACC-8': 5.5520577591672804e-05, 'ACC-9': 0.692288779877897, 'ACC-10': 1.0602270984538005, 'ACC-11': 0.8612856994015889, 'ACC-12': 0.7613002481931704, 'ACC-13': 1.5060784807383958, 'ACC-14': 2.1879610438240924, 'ACC-15': 2.116760744650355, 'ACC-16': 1.230689531518724, 'ACC-17': 1.402821695032851, 'ACC-18': 2.3078189295498373, 'ACC-19': 3.295735990629872, 'ACC-20': 2.3399071962904134, 'ACC-21': 1.983418475006851, 'ACC-22': 2.2364760293751837, 'ACC-23': 2.515877028511292, 'ACC-24': 2.8145864431480017, 'ACC-25': 3.5779597428762, 'ACC-26': 3.9316117937649624, 'ACC-27': 3.9516604934042374, 'ACC-28': 3.990938549640551, 'ACC-29': 5.263689187758577, 'ACC-30': 4.433913809004114, 'ACC-31': 5.535363208182222, 'ACC-32': 5.1828251411982675, 'ACC-33': 5.083860971065189, 'ACC-34': 4.060224758497844, 'ACC-35': 3.8705998479094115, 'ACC-36': 3.613430958371432, 'ACC-37': 4.939015692345337, 'ACC-38': 4.891626347612366, 'ACC-39': 4.6948132603197905, 'ACC-40': 4.462292009278629, 'ACC-41': 3.449963293291796, 'ACC-42': 3.301700014695496, 'ACC-43': 3.7179670942411223, 'ACC-44': 1.9480038983022652, 'ACC-45': 1.83679297584907, 'ACC-46': 1.7362186497558645, 'ACC-47': 1.7303710085536617, 'ACC-48': 2.1191246346435997, 'ACC-49': 1.0466946798029868, 'ACC-50': 1.3031597033486073, 'ACC-51': 1.588345679429461, 'ACC-52': 0.8212836587808106, 'ACC-53': 0.6517503454817194, 'ACC-54': 0.7409250973791432, 'ACC-55': 0.4189473881042588, 'ACC-56': 0.6534083287422231, 'ACC-57': 0.6466438545120652, 'ACC-58': 0.4758168348310059, 'ACC-59': 0.40932361723636834, 'ACC-60': 0.463567711071474, 'ACC-61': 0.2893002238343519, 'ACC-62': 0.31091331860755134, 'ACC-63': 0.31720040964072327, 'ACC-64': 0.20681603813729965, 'ACC-65': 0.5620788896708867, 'ACC-66': 0.12731850086936755, 'ACC-67': 0.008210349145097395, 'ACC-68': 0.3690934503495633, 'ACC-69': 0.252662868991432, 'ACC-70': 0.3745881976176991, 'ACC-71': 0.48819481924927793, 'ACC-72': 0.34292265024540136, 'ACC-73': 0.024938465965015873, 'ACC-74': 0.027112442127353968, 'ACC-75': 0.21097714523461378, 'ACC-76': 0.4871197881518742, 'ACC-77': 0.5601222966247695, 'ACC-78': 0.4271288727271759, 'ACC-79': 0.2521459639771431, 'ACC-80': 0.09757574477529105, 'ACC-81': 0.22233376213412048, 'ACC-82': 0.21999379386402623, 'ACC-83': 0.12488482293811773, 'ACC-84': 0.2186001086762603, 'ACC-85': 0.2526763978441614, 'ACC-86': 0.06914555845621957, 'ACC-87': 0.14414856184220443, 'ACC-88': 0.043574731733238684, 'ACC-89': 0.18467250260646664, 'ACC-90': 0.0637269921068154, 'ACC-91': 0.11018122409611798, 'ACC-92': 0.14318015800866818, 'ACC-93': 0.08275005373523607, 'ACC-94': 0.12822314019428244, 'ACC-95': 0.009191957666627842, 'ACC-96': 0.008726251979851685, 'ACC-97': 0.06490517013937576, 'ACC-98': 0.1114601587702482, 'ACC-99': 0.0064601625878292854, 'ACC-100': 0.026740526474134878, 'ACC-101': 0.029338636211227866, 'ACC-102': 0.008473040326234709, 'ACC-103': 0.1352129970718806, 'ACC-104': 0.06411549150291435, 'ACC-105': 0.07807330309323005, 'ACC-106': 0.0606785773941619, 'ACC-107': 0.0634222332458694, 'ACC-108': 0.20168985031340964, 'ACC-109': 0.017973501842000444, 'ACC-110': 0.1046619428279621, 'ACC-111': 0.03980092018473895, 'ACC-112': 0.27460079450718333, 'ACC-113': 0.012692005596966403, 'ACC-114': 0.0036443188531182797, 'ACC-115': 0.015899147535068332, 'ACC-116': 0.3396919623135683, 'ACC-117': 0.0, 'ACC-118': 0.0012176192017708382, 'ACC-119': 0.18374145467131767, 'ACC-120': 0.08802538504517231, 'ACC-121': 0.00199852200213751, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 01:19:13] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 01:19:13] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 01:19:13] d2.evaluation.testing INFO: copypaste: 22.4738,0.9424,0.8701,0.3078,0.7730,0.7258,1.9097
[01/29 01:19:13] d2.utils.events INFO:  eta: 1 day, 15:41:07  iter: 4999  total_loss: 207.2  loss_mask: 20.1  loss_mask_0: 25.73  loss_mask_1: 19.98  loss_mask_2: 20.13  loss_mask_3: 20.1  loss_mask_4: 20.09  loss_mask_5: 20.12  loss_mask_6: 20.13  loss_mask_7: 20.08  loss_mask_8: 20.11  time: 2.6075  data_time: 0.0637  lr: 9.2469e-05  max_mem: 27639M
[01/29 01:20:05] d2.utils.events INFO:  eta: 1 day, 15:39:49  iter: 5019  total_loss: 202.4  loss_mask: 19.57  loss_mask_0: 25.7  loss_mask_1: 19.44  loss_mask_2: 19.53  loss_mask_3: 19.5  loss_mask_4: 19.52  loss_mask_5: 19.48  loss_mask_6: 19.47  loss_mask_7: 19.57  loss_mask_8: 19.61  time: 2.6073  data_time: 0.0583  lr: 9.2439e-05  max_mem: 27639M
[01/29 01:20:56] d2.utils.events INFO:  eta: 1 day, 15:38:16  iter: 5039  total_loss: 205.8  loss_mask: 19.97  loss_mask_0: 26.39  loss_mask_1: 19.95  loss_mask_2: 19.98  loss_mask_3: 19.95  loss_mask_4: 19.98  loss_mask_5: 20.05  loss_mask_6: 19.96  loss_mask_7: 19.95  loss_mask_8: 19.99  time: 2.6073  data_time: 0.0587  lr: 9.2409e-05  max_mem: 27639M
[01/29 01:21:48] d2.utils.events INFO:  eta: 1 day, 15:37:24  iter: 5059  total_loss: 198.8  loss_mask: 19.21  loss_mask_0: 25.64  loss_mask_1: 19.28  loss_mask_2: 19.24  loss_mask_3: 19.24  loss_mask_4: 19.26  loss_mask_5: 19.25  loss_mask_6: 19.24  loss_mask_7: 19.24  loss_mask_8: 19.24  time: 2.6072  data_time: 0.0586  lr: 9.2378e-05  max_mem: 27639M
[01/29 01:22:39] d2.utils.events INFO:  eta: 1 day, 15:36:13  iter: 5079  total_loss: 199.2  loss_mask: 19.26  loss_mask_0: 25.96  loss_mask_1: 19.3  loss_mask_2: 19.3  loss_mask_3: 19.28  loss_mask_4: 19.34  loss_mask_5: 19.33  loss_mask_6: 19.26  loss_mask_7: 19.28  loss_mask_8: 19.28  time: 2.6070  data_time: 0.0571  lr: 9.2348e-05  max_mem: 27639M
[01/29 01:23:31] d2.utils.events INFO:  eta: 1 day, 15:34:44  iter: 5099  total_loss: 197.3  loss_mask: 18.89  loss_mask_0: 27.09  loss_mask_1: 19.01  loss_mask_2: 19.05  loss_mask_3: 18.99  loss_mask_4: 18.96  loss_mask_5: 18.97  loss_mask_6: 18.92  loss_mask_7: 18.96  loss_mask_8: 18.94  time: 2.6069  data_time: 0.0567  lr: 9.2318e-05  max_mem: 27639M
[01/29 01:24:23] d2.utils.events INFO:  eta: 1 day, 15:33:52  iter: 5119  total_loss: 206.8  loss_mask: 20  loss_mask_0: 26.96  loss_mask_1: 20.06  loss_mask_2: 20.11  loss_mask_3: 20.07  loss_mask_4: 20.06  loss_mask_5: 20.05  loss_mask_6: 19.99  loss_mask_7: 19.98  loss_mask_8: 20.03  time: 2.6069  data_time: 0.0691  lr: 9.2288e-05  max_mem: 27639M
[01/29 01:25:15] d2.utils.events INFO:  eta: 1 day, 15:32:28  iter: 5139  total_loss: 197.3  loss_mask: 19.22  loss_mask_0: 24.93  loss_mask_1: 19.17  loss_mask_2: 19.14  loss_mask_3: 19.15  loss_mask_4: 19.13  loss_mask_5: 19.09  loss_mask_6: 19.15  loss_mask_7: 19.2  loss_mask_8: 19.21  time: 2.6068  data_time: 0.0481  lr: 9.2257e-05  max_mem: 27639M
[01/29 01:26:06] d2.utils.events INFO:  eta: 1 day, 15:31:28  iter: 5159  total_loss: 213.1  loss_mask: 20.51  loss_mask_0: 27.44  loss_mask_1: 20.48  loss_mask_2: 20.5  loss_mask_3: 20.5  loss_mask_4: 20.5  loss_mask_5: 20.51  loss_mask_6: 20.49  loss_mask_7: 20.54  loss_mask_8: 20.56  time: 2.6066  data_time: 0.0479  lr: 9.2227e-05  max_mem: 27639M
[01/29 01:26:58] d2.utils.events INFO:  eta: 1 day, 15:30:01  iter: 5179  total_loss: 211.2  loss_mask: 20.14  loss_mask_0: 27.95  loss_mask_1: 20.15  loss_mask_2: 20.03  loss_mask_3: 20.05  loss_mask_4: 20.09  loss_mask_5: 20.08  loss_mask_6: 20.08  loss_mask_7: 20.08  loss_mask_8: 20.09  time: 2.6065  data_time: 0.0583  lr: 9.2197e-05  max_mem: 27639M
[01/29 01:27:50] d2.utils.events INFO:  eta: 1 day, 15:29:03  iter: 5199  total_loss: 212.8  loss_mask: 20.56  loss_mask_0: 27.73  loss_mask_1: 20.58  loss_mask_2: 20.59  loss_mask_3: 20.59  loss_mask_4: 20.55  loss_mask_5: 20.54  loss_mask_6: 20.57  loss_mask_7: 20.54  loss_mask_8: 20.51  time: 2.6064  data_time: 0.0586  lr: 9.2167e-05  max_mem: 27639M
[01/29 01:28:41] d2.utils.events INFO:  eta: 1 day, 15:27:30  iter: 5219  total_loss: 204.4  loss_mask: 19.96  loss_mask_0: 26.18  loss_mask_1: 19.92  loss_mask_2: 19.95  loss_mask_3: 19.96  loss_mask_4: 19.85  loss_mask_5: 19.95  loss_mask_6: 19.91  loss_mask_7: 19.89  loss_mask_8: 19.98  time: 2.6063  data_time: 0.0578  lr: 9.2136e-05  max_mem: 27639M
[01/29 01:29:32] d2.utils.events INFO:  eta: 1 day, 15:25:32  iter: 5239  total_loss: 209.8  loss_mask: 20.27  loss_mask_0: 27.93  loss_mask_1: 20.12  loss_mask_2: 20.23  loss_mask_3: 20.22  loss_mask_4: 20.18  loss_mask_5: 20.23  loss_mask_6: 20.2  loss_mask_7: 20.22  loss_mask_8: 20.27  time: 2.6061  data_time: 0.0507  lr: 9.2106e-05  max_mem: 27639M
[01/29 01:30:24] d2.utils.events INFO:  eta: 1 day, 15:24:23  iter: 5259  total_loss: 192.2  loss_mask: 18.65  loss_mask_0: 25.51  loss_mask_1: 18.74  loss_mask_2: 18.71  loss_mask_3: 18.67  loss_mask_4: 18.67  loss_mask_5: 18.71  loss_mask_6: 18.69  loss_mask_7: 18.69  loss_mask_8: 18.68  time: 2.6060  data_time: 0.0546  lr: 9.2076e-05  max_mem: 27639M
[01/29 01:31:15] d2.utils.events INFO:  eta: 1 day, 15:22:48  iter: 5279  total_loss: 193.4  loss_mask: 18.71  loss_mask_0: 25.31  loss_mask_1: 18.72  loss_mask_2: 18.72  loss_mask_3: 18.71  loss_mask_4: 18.7  loss_mask_5: 18.7  loss_mask_6: 18.69  loss_mask_7: 18.74  loss_mask_8: 18.74  time: 2.6059  data_time: 0.0453  lr: 9.2045e-05  max_mem: 27639M
[01/29 01:32:07] d2.utils.events INFO:  eta: 1 day, 15:21:23  iter: 5299  total_loss: 207.6  loss_mask: 20.16  loss_mask_0: 26.13  loss_mask_1: 20.22  loss_mask_2: 20.26  loss_mask_3: 20.21  loss_mask_4: 20.2  loss_mask_5: 20.2  loss_mask_6: 20.19  loss_mask_7: 20.24  loss_mask_8: 20.25  time: 2.6058  data_time: 0.0546  lr: 9.2015e-05  max_mem: 27639M
[01/29 01:32:58] d2.utils.events INFO:  eta: 1 day, 15:19:45  iter: 5319  total_loss: 201.2  loss_mask: 19.44  loss_mask_0: 25.77  loss_mask_1: 19.42  loss_mask_2: 19.33  loss_mask_3: 19.35  loss_mask_4: 19.39  loss_mask_5: 19.35  loss_mask_6: 19.33  loss_mask_7: 19.44  loss_mask_8: 19.44  time: 2.6056  data_time: 0.0535  lr: 9.1985e-05  max_mem: 27639M
[01/29 01:33:50] d2.utils.events INFO:  eta: 1 day, 15:18:15  iter: 5339  total_loss: 200.1  loss_mask: 19.23  loss_mask_0: 26.9  loss_mask_1: 19.28  loss_mask_2: 19.2  loss_mask_3: 19.23  loss_mask_4: 19.22  loss_mask_5: 19.28  loss_mask_6: 19.28  loss_mask_7: 19.19  loss_mask_8: 19.2  time: 2.6055  data_time: 0.0637  lr: 9.1955e-05  max_mem: 27639M
[01/29 01:34:41] d2.utils.events INFO:  eta: 1 day, 15:16:54  iter: 5359  total_loss: 191.7  loss_mask: 18.52  loss_mask_0: 25.76  loss_mask_1: 18.56  loss_mask_2: 18.51  loss_mask_3: 18.52  loss_mask_4: 18.52  loss_mask_5: 18.48  loss_mask_6: 18.49  loss_mask_7: 18.53  loss_mask_8: 18.52  time: 2.6054  data_time: 0.0537  lr: 9.1924e-05  max_mem: 27639M
[01/29 01:35:33] d2.utils.events INFO:  eta: 1 day, 15:15:39  iter: 5379  total_loss: 201.7  loss_mask: 19.67  loss_mask_0: 26.06  loss_mask_1: 19.61  loss_mask_2: 19.64  loss_mask_3: 19.67  loss_mask_4: 19.64  loss_mask_5: 19.64  loss_mask_6: 19.65  loss_mask_7: 19.67  loss_mask_8: 19.66  time: 2.6053  data_time: 0.0595  lr: 9.1894e-05  max_mem: 27639M
[01/29 01:36:24] d2.utils.events INFO:  eta: 1 day, 15:14:19  iter: 5399  total_loss: 208  loss_mask: 20.24  loss_mask_0: 26.37  loss_mask_1: 20.16  loss_mask_2: 20.25  loss_mask_3: 20.24  loss_mask_4: 20.19  loss_mask_5: 20.27  loss_mask_6: 20.26  loss_mask_7: 20.31  loss_mask_8: 20.27  time: 2.6052  data_time: 0.0552  lr: 9.1864e-05  max_mem: 27639M
[01/29 01:37:16] d2.utils.events INFO:  eta: 1 day, 15:12:46  iter: 5419  total_loss: 212.1  loss_mask: 20.41  loss_mask_0: 27.68  loss_mask_1: 20.46  loss_mask_2: 20.41  loss_mask_3: 20.4  loss_mask_4: 20.4  loss_mask_5: 20.42  loss_mask_6: 20.38  loss_mask_7: 20.37  loss_mask_8: 20.41  time: 2.6050  data_time: 0.0562  lr: 9.1834e-05  max_mem: 27639M
[01/29 01:38:07] d2.utils.events INFO:  eta: 1 day, 15:11:08  iter: 5439  total_loss: 190.2  loss_mask: 18.62  loss_mask_0: 25.22  loss_mask_1: 18.36  loss_mask_2: 18.37  loss_mask_3: 18.48  loss_mask_4: 18.33  loss_mask_5: 18.33  loss_mask_6: 18.36  loss_mask_7: 18.64  loss_mask_8: 18.54  time: 2.6049  data_time: 0.0553  lr: 9.1803e-05  max_mem: 27639M
[01/29 01:38:59] d2.utils.events INFO:  eta: 1 day, 15:09:58  iter: 5459  total_loss: 200  loss_mask: 19.45  loss_mask_0: 26.9  loss_mask_1: 19.36  loss_mask_2: 19.42  loss_mask_3: 19.41  loss_mask_4: 19.42  loss_mask_5: 19.47  loss_mask_6: 19.39  loss_mask_7: 19.44  loss_mask_8: 19.48  time: 2.6048  data_time: 0.0511  lr: 9.1773e-05  max_mem: 27639M
[01/29 01:39:50] d2.utils.events INFO:  eta: 1 day, 15:08:38  iter: 5479  total_loss: 198.6  loss_mask: 19.32  loss_mask_0: 25.29  loss_mask_1: 19.29  loss_mask_2: 19.25  loss_mask_3: 19.28  loss_mask_4: 19.32  loss_mask_5: 19.26  loss_mask_6: 19.23  loss_mask_7: 19.33  loss_mask_8: 19.33  time: 2.6047  data_time: 0.0501  lr: 9.1743e-05  max_mem: 27639M
[01/29 01:40:42] d2.utils.events INFO:  eta: 1 day, 15:06:40  iter: 5499  total_loss: 206.3  loss_mask: 19.84  loss_mask_0: 26.53  loss_mask_1: 19.7  loss_mask_2: 19.79  loss_mask_3: 19.82  loss_mask_4: 19.82  loss_mask_5: 19.83  loss_mask_6: 19.84  loss_mask_7: 19.84  loss_mask_8: 19.82  time: 2.6046  data_time: 0.0523  lr: 9.1712e-05  max_mem: 27639M
[01/29 01:41:33] d2.utils.events INFO:  eta: 1 day, 15:05:22  iter: 5519  total_loss: 203.5  loss_mask: 19.56  loss_mask_0: 27.06  loss_mask_1: 19.66  loss_mask_2: 19.55  loss_mask_3: 19.52  loss_mask_4: 19.54  loss_mask_5: 19.51  loss_mask_6: 19.49  loss_mask_7: 19.59  loss_mask_8: 19.57  time: 2.6045  data_time: 0.0523  lr: 9.1682e-05  max_mem: 27639M
[01/29 01:42:25] d2.utils.events INFO:  eta: 1 day, 15:03:51  iter: 5539  total_loss: 199.6  loss_mask: 19.12  loss_mask_0: 26.97  loss_mask_1: 19.1  loss_mask_2: 19.07  loss_mask_3: 19.11  loss_mask_4: 19.07  loss_mask_5: 19.08  loss_mask_6: 19.09  loss_mask_7: 19.13  loss_mask_8: 19.1  time: 2.6044  data_time: 0.0585  lr: 9.1652e-05  max_mem: 27639M
[01/29 01:43:16] d2.utils.events INFO:  eta: 1 day, 15:02:22  iter: 5559  total_loss: 204.4  loss_mask: 19.68  loss_mask_0: 27.09  loss_mask_1: 19.76  loss_mask_2: 19.64  loss_mask_3: 19.64  loss_mask_4: 19.71  loss_mask_5: 19.7  loss_mask_6: 19.67  loss_mask_7: 19.68  loss_mask_8: 19.63  time: 2.6042  data_time: 0.0536  lr: 9.1621e-05  max_mem: 27639M
[01/29 01:44:08] d2.utils.events INFO:  eta: 1 day, 15:00:59  iter: 5579  total_loss: 204.8  loss_mask: 19.78  loss_mask_0: 26.31  loss_mask_1: 19.77  loss_mask_2: 19.81  loss_mask_3: 19.81  loss_mask_4: 19.76  loss_mask_5: 19.77  loss_mask_6: 19.78  loss_mask_7: 19.77  loss_mask_8: 19.78  time: 2.6042  data_time: 0.0550  lr: 9.1591e-05  max_mem: 27639M
[01/29 01:44:59] d2.utils.events INFO:  eta: 1 day, 14:59:29  iter: 5599  total_loss: 202.1  loss_mask: 19.62  loss_mask_0: 26.12  loss_mask_1: 19.59  loss_mask_2: 19.55  loss_mask_3: 19.63  loss_mask_4: 19.58  loss_mask_5: 19.51  loss_mask_6: 19.54  loss_mask_7: 19.59  loss_mask_8: 19.57  time: 2.6040  data_time: 0.0630  lr: 9.1561e-05  max_mem: 27639M
[01/29 01:45:51] d2.utils.events INFO:  eta: 1 day, 14:57:31  iter: 5619  total_loss: 188.1  loss_mask: 18.14  loss_mask_0: 25.75  loss_mask_1: 18.26  loss_mask_2: 17.84  loss_mask_3: 18.02  loss_mask_4: 17.94  loss_mask_5: 18  loss_mask_6: 18.18  loss_mask_7: 18.06  loss_mask_8: 17.94  time: 2.6039  data_time: 0.0489  lr: 9.1531e-05  max_mem: 27639M
[01/29 01:46:42] d2.utils.events INFO:  eta: 1 day, 14:55:52  iter: 5639  total_loss: 203.4  loss_mask: 19.63  loss_mask_0: 26.49  loss_mask_1: 19.6  loss_mask_2: 19.54  loss_mask_3: 19.59  loss_mask_4: 19.6  loss_mask_5: 19.59  loss_mask_6: 19.56  loss_mask_7: 19.64  loss_mask_8: 19.62  time: 2.6037  data_time: 0.0587  lr: 9.15e-05  max_mem: 27639M
[01/29 01:47:33] d2.utils.events INFO:  eta: 1 day, 14:54:11  iter: 5659  total_loss: 195.8  loss_mask: 18.84  loss_mask_0: 26.58  loss_mask_1: 18.71  loss_mask_2: 18.75  loss_mask_3: 18.78  loss_mask_4: 18.75  loss_mask_5: 18.78  loss_mask_6: 18.76  loss_mask_7: 18.84  loss_mask_8: 18.8  time: 2.6036  data_time: 0.0470  lr: 9.147e-05  max_mem: 27639M
[01/29 01:48:25] d2.utils.events INFO:  eta: 1 day, 14:52:30  iter: 5679  total_loss: 209.3  loss_mask: 20.14  loss_mask_0: 27.2  loss_mask_1: 20.15  loss_mask_2: 20.17  loss_mask_3: 20.11  loss_mask_4: 20.13  loss_mask_5: 20.18  loss_mask_6: 20.12  loss_mask_7: 20.13  loss_mask_8: 20.18  time: 2.6035  data_time: 0.0528  lr: 9.144e-05  max_mem: 27639M
[01/29 01:49:16] d2.utils.events INFO:  eta: 1 day, 14:51:19  iter: 5699  total_loss: 200  loss_mask: 19.12  loss_mask_0: 26.05  loss_mask_1: 19.28  loss_mask_2: 19.11  loss_mask_3: 19.07  loss_mask_4: 19.05  loss_mask_5: 18.98  loss_mask_6: 19.02  loss_mask_7: 19.11  loss_mask_8: 19  time: 2.6034  data_time: 0.0528  lr: 9.1409e-05  max_mem: 27639M
[01/29 01:50:08] d2.utils.events INFO:  eta: 1 day, 14:50:04  iter: 5719  total_loss: 199.1  loss_mask: 19.17  loss_mask_0: 26.37  loss_mask_1: 19.15  loss_mask_2: 19.11  loss_mask_3: 19.18  loss_mask_4: 19.16  loss_mask_5: 19.08  loss_mask_6: 19.11  loss_mask_7: 19.17  loss_mask_8: 19.18  time: 2.6033  data_time: 0.0565  lr: 9.1379e-05  max_mem: 27639M
[01/29 01:50:59] d2.utils.events INFO:  eta: 1 day, 14:48:58  iter: 5739  total_loss: 204.4  loss_mask: 19.79  loss_mask_0: 26.95  loss_mask_1: 19.77  loss_mask_2: 19.78  loss_mask_3: 19.77  loss_mask_4: 19.77  loss_mask_5: 19.8  loss_mask_6: 19.77  loss_mask_7: 19.76  loss_mask_8: 19.79  time: 2.6032  data_time: 0.0559  lr: 9.1349e-05  max_mem: 27639M
[01/29 01:51:51] d2.utils.events INFO:  eta: 1 day, 14:47:40  iter: 5759  total_loss: 214.2  loss_mask: 20.63  loss_mask_0: 26.26  loss_mask_1: 20.6  loss_mask_2: 20.61  loss_mask_3: 20.6  loss_mask_4: 20.58  loss_mask_5: 20.61  loss_mask_6: 20.56  loss_mask_7: 20.66  loss_mask_8: 20.65  time: 2.6031  data_time: 0.0507  lr: 9.1319e-05  max_mem: 27639M
[01/29 01:52:42] d2.utils.events INFO:  eta: 1 day, 14:46:09  iter: 5779  total_loss: 200  loss_mask: 19.54  loss_mask_0: 26.04  loss_mask_1: 19.41  loss_mask_2: 19.37  loss_mask_3: 19.52  loss_mask_4: 19.4  loss_mask_5: 19.4  loss_mask_6: 19.56  loss_mask_7: 19.48  loss_mask_8: 19.33  time: 2.6030  data_time: 0.0563  lr: 9.1288e-05  max_mem: 27639M
[01/29 01:53:34] d2.utils.events INFO:  eta: 1 day, 14:44:42  iter: 5799  total_loss: 207.8  loss_mask: 20.08  loss_mask_0: 26.26  loss_mask_1: 20.05  loss_mask_2: 20.08  loss_mask_3: 20.09  loss_mask_4: 20  loss_mask_5: 19.96  loss_mask_6: 20  loss_mask_7: 20.05  loss_mask_8: 20.05  time: 2.6029  data_time: 0.0586  lr: 9.1258e-05  max_mem: 27639M
[01/29 01:54:25] d2.utils.events INFO:  eta: 1 day, 14:43:18  iter: 5819  total_loss: 199.4  loss_mask: 19.13  loss_mask_0: 25.87  loss_mask_1: 19.16  loss_mask_2: 19.12  loss_mask_3: 19.15  loss_mask_4: 19.11  loss_mask_5: 19.17  loss_mask_6: 19.11  loss_mask_7: 19.09  loss_mask_8: 19.09  time: 2.6028  data_time: 0.0548  lr: 9.1228e-05  max_mem: 27639M
[01/29 01:55:17] d2.utils.events INFO:  eta: 1 day, 14:41:53  iter: 5839  total_loss: 204.5  loss_mask: 19.74  loss_mask_0: 27.68  loss_mask_1: 19.76  loss_mask_2: 19.74  loss_mask_3: 19.73  loss_mask_4: 19.7  loss_mask_5: 19.74  loss_mask_6: 19.74  loss_mask_7: 19.71  loss_mask_8: 19.73  time: 2.6027  data_time: 0.0567  lr: 9.1197e-05  max_mem: 27639M
[01/29 01:56:08] d2.utils.events INFO:  eta: 1 day, 14:40:10  iter: 5859  total_loss: 202.2  loss_mask: 19.42  loss_mask_0: 25.66  loss_mask_1: 19.39  loss_mask_2: 19.43  loss_mask_3: 19.39  loss_mask_4: 19.37  loss_mask_5: 19.41  loss_mask_6: 19.38  loss_mask_7: 19.42  loss_mask_8: 19.47  time: 2.6026  data_time: 0.0522  lr: 9.1167e-05  max_mem: 27639M
[01/29 01:57:00] d2.utils.events INFO:  eta: 1 day, 14:38:55  iter: 5879  total_loss: 204.7  loss_mask: 19.72  loss_mask_0: 27.24  loss_mask_1: 19.69  loss_mask_2: 19.58  loss_mask_3: 19.61  loss_mask_4: 19.65  loss_mask_5: 19.65  loss_mask_6: 19.62  loss_mask_7: 19.73  loss_mask_8: 19.69  time: 2.6025  data_time: 0.0597  lr: 9.1137e-05  max_mem: 27639M
[01/29 01:57:51] d2.utils.events INFO:  eta: 1 day, 14:37:24  iter: 5899  total_loss: 214  loss_mask: 20.66  loss_mask_0: 27.54  loss_mask_1: 20.62  loss_mask_2: 20.64  loss_mask_3: 20.72  loss_mask_4: 20.6  loss_mask_5: 20.56  loss_mask_6: 20.61  loss_mask_7: 20.72  loss_mask_8: 20.64  time: 2.6024  data_time: 0.0548  lr: 9.1106e-05  max_mem: 27639M
[01/29 01:58:43] d2.utils.events INFO:  eta: 1 day, 14:35:55  iter: 5919  total_loss: 194.9  loss_mask: 18.68  loss_mask_0: 26.65  loss_mask_1: 18.76  loss_mask_2: 18.76  loss_mask_3: 18.75  loss_mask_4: 18.71  loss_mask_5: 18.67  loss_mask_6: 18.64  loss_mask_7: 18.69  loss_mask_8: 18.72  time: 2.6023  data_time: 0.0518  lr: 9.1076e-05  max_mem: 27639M
[01/29 01:59:34] d2.utils.events INFO:  eta: 1 day, 14:34:47  iter: 5939  total_loss: 199.1  loss_mask: 19.37  loss_mask_0: 25.37  loss_mask_1: 19.35  loss_mask_2: 19.33  loss_mask_3: 19.3  loss_mask_4: 19.31  loss_mask_5: 19.31  loss_mask_6: 19.32  loss_mask_7: 19.35  loss_mask_8: 19.37  time: 2.6021  data_time: 0.0534  lr: 9.1046e-05  max_mem: 27639M
[01/29 02:00:26] d2.utils.events INFO:  eta: 1 day, 14:33:38  iter: 5959  total_loss: 202.2  loss_mask: 19.45  loss_mask_0: 26.32  loss_mask_1: 19.26  loss_mask_2: 19.41  loss_mask_3: 19.41  loss_mask_4: 19.38  loss_mask_5: 19.37  loss_mask_6: 19.38  loss_mask_7: 19.43  loss_mask_8: 19.45  time: 2.6021  data_time: 0.0549  lr: 9.1015e-05  max_mem: 27639M
[01/29 02:01:17] d2.utils.events INFO:  eta: 1 day, 14:32:10  iter: 5979  total_loss: 201  loss_mask: 19.33  loss_mask_0: 26.28  loss_mask_1: 19.3  loss_mask_2: 19.27  loss_mask_3: 19.3  loss_mask_4: 19.29  loss_mask_5: 19.3  loss_mask_6: 19.3  loss_mask_7: 19.32  loss_mask_8: 19.3  time: 2.6020  data_time: 0.0558  lr: 9.0985e-05  max_mem: 27639M
[01/29 02:02:09] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 02:02:09] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 02:02:09] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 02:12:19] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 22.53963100075829, 'error_1pix': 0.9405341657275776, 'error_3pix': 0.8644647455539888, 'mIoU': 0.3135278498243818, 'fwIoU': 0.7929423719746346, 'IoU-0': 0.0, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.09658873808020732, 'IoU-5': 0.016769660713665584, 'IoU-6': 0.02156944177717064, 'IoU-7': 0.006644815446640215, 'IoU-8': 0.02754014551881305, 'IoU-9': 0.5331458544401192, 'IoU-10': 0.6700706695760972, 'IoU-11': 1.043364761038709, 'IoU-12': 1.0201018555600156, 'IoU-13': 1.7685726335244747, 'IoU-14': 1.8574670760698655, 'IoU-15': 1.7273515023144055, 'IoU-16': 1.3836270601637393, 'IoU-17': 1.346629289085541, 'IoU-18': 1.2823382360136528, 'IoU-19': 0.851460236437796, 'IoU-20': 1.2958613970737582, 'IoU-21': 1.3343148705128771, 'IoU-22': 1.640467887850447, 'IoU-23': 1.4917575054440033, 'IoU-24': 1.2232818710503524, 'IoU-25': 1.2152718875434474, 'IoU-26': 1.0850050942723903, 'IoU-27': 1.3551996975850928, 'IoU-28': 1.5511779496361384, 'IoU-29': 1.194774289796068, 'IoU-30': 1.6328589413692889, 'IoU-31': 1.486080058770293, 'IoU-32': 1.2005819852713173, 'IoU-33': 1.1069153700505117, 'IoU-34': 1.481015907230132, 'IoU-35': 1.5482757879203353, 'IoU-36': 1.4373988114379412, 'IoU-37': 1.4760444246942064, 'IoU-38': 1.3928232481146094, 'IoU-39': 1.0982312489918202, 'IoU-40': 0.9834713776907086, 'IoU-41': 1.0122803894860013, 'IoU-42': 0.8245968846469389, 'IoU-43': 0.9139941147163226, 'IoU-44': 0.8938206173957133, 'IoU-45': 0.8674627446240443, 'IoU-46': 0.7037272684318608, 'IoU-47': 0.5425791969932499, 'IoU-48': 0.6218599861481646, 'IoU-49': 0.5007047643105267, 'IoU-50': 0.6607011003742067, 'IoU-51': 0.6759311192406147, 'IoU-52': 0.4265306279487641, 'IoU-53': 0.4179776871568376, 'IoU-54': 0.26252545338330024, 'IoU-55': 0.19885330934319032, 'IoU-56': 0.279855235805742, 'IoU-57': 0.2697466016641336, 'IoU-58': 0.10341415691340729, 'IoU-59': 0.28324291960562176, 'IoU-60': 0.09814545485766517, 'IoU-61': 0.19804106401454324, 'IoU-62': 0.13422765233795972, 'IoU-63': 0.26262626768160435, 'IoU-64': 0.07971648082696858, 'IoU-65': 0.14935945231478343, 'IoU-66': 0.1158059741252954, 'IoU-67': 0.249253473507564, 'IoU-68': 0.16119195873217437, 'IoU-69': 0.03934801665666097, 'IoU-70': 0.24538676784450655, 'IoU-71': 0.1429626361982789, 'IoU-72': 0.15929137412894326, 'IoU-73': 0.29881615801604106, 'IoU-74': 0.2396380112222327, 'IoU-75': 0.13944147996497552, 'IoU-76': 0.3260831861793607, 'IoU-77': 0.25635003703130005, 'IoU-78': 0.06585882758146994, 'IoU-79': 0.2329675002020663, 'IoU-80': 0.05239038542579166, 'IoU-81': 0.0678301860654732, 'IoU-82': 0.1453855569838804, 'IoU-83': 0.08768514123349824, 'IoU-84': 0.03696290913526726, 'IoU-85': 0.04093252967141561, 'IoU-86': 0.18335429091566452, 'IoU-87': 0.10330641081975175, 'IoU-88': 0.06479054118182709, 'IoU-89': 0.030166331012649, 'IoU-90': 0.20887752065706938, 'IoU-91': 0.09719678447945197, 'IoU-92': 0.037692333578079565, 'IoU-93': 0.014263677353975603, 'IoU-94': 0.11168364573238472, 'IoU-95': 0.07169030831820142, 'IoU-96': 0.08334511829136823, 'IoU-97': 0.0463310196431886, 'IoU-98': 0.0367937819169131, 'IoU-99': 0.07226371818197609, 'IoU-100': 0.024480862450227694, 'IoU-101': 0.06585029189408233, 'IoU-102': 0.0, 'IoU-103': 0.05367474622170024, 'IoU-104': 0.020137111256121585, 'IoU-105': 0.08435685086918639, 'IoU-106': 0.06878475858489079, 'IoU-107': 0.011220369002956481, 'IoU-108': 0.07813512347863759, 'IoU-109': 0.03545660015710686, 'IoU-110': 0.12450440794369616, 'IoU-111': 0.04262172063591101, 'IoU-112': 0.021175177732639328, 'IoU-113': 0.0, 'IoU-114': 0.02968024139112027, 'IoU-115': 1.1805221797487453, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.014139457120716821, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.05187306885586053, 'IoU-122': 0.0, 'IoU-123': 0.0013359308019278268, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.45966441907642996, 'IoU-129': 0.008858891170993328, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.06271602185304939, 'IoU-139': 0.0, 'IoU-140': 0.15289537243813228, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.06490021132441211, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.18774095634608037, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.13484051547356077, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.729530194304022, 'pACC': 1.9486650528293359, 'ACC-0': 0.0, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.49896947583397366, 'ACC-5': 0.05791904905443602, 'ACC-6': 0.11796418648689201, 'ACC-7': 0.05688219915333034, 'ACC-8': 0.08300326349955084, 'ACC-9': 0.9973455596964907, 'ACC-10': 1.031300535764827, 'ACC-11': 1.4525812503471498, 'ACC-12': 1.4230462916704145, 'ACC-13': 2.7231153811497744, 'ACC-14': 3.2808496726568777, 'ACC-15': 3.26892574104961, 'ACC-16': 2.6762451786144763, 'ACC-17': 3.2447039501699, 'ACC-18': 2.3827478442341765, 'ACC-19': 1.7441305325750007, 'ACC-20': 3.1579655901561163, 'ACC-21': 3.502852841689405, 'ACC-22': 4.68939896622863, 'ACC-23': 4.256723666004695, 'ACC-24': 3.8846874874595345, 'ACC-25': 3.831109195579992, 'ACC-26': 3.729926036188975, 'ACC-27': 4.620309821929785, 'ACC-28': 5.794902752611805, 'ACC-29': 3.763940248118284, 'ACC-30': 5.272636163067363, 'ACC-31': 4.566076402403664, 'ACC-32': 3.333804143100689, 'ACC-33': 3.413100117251137, 'ACC-34': 5.184875394747633, 'ACC-35': 5.162238694282141, 'ACC-36': 4.1345361488055845, 'ACC-37': 4.1773903156901815, 'ACC-38': 3.6860720165312673, 'ACC-39': 2.6761158602972475, 'ACC-40': 2.0242639868211825, 'ACC-41': 2.374225304931823, 'ACC-42': 1.8820026980746567, 'ACC-43': 2.0168268904329825, 'ACC-44': 1.6762061591569664, 'ACC-45': 1.4673304532484053, 'ACC-46': 1.384573282771023, 'ACC-47': 1.0163567491425953, 'ACC-48': 1.057398979187537, 'ACC-49': 0.8148187732538217, 'ACC-50': 1.0890181171948004, 'ACC-51': 1.1963636634219703, 'ACC-52': 0.6778634395767267, 'ACC-53': 0.7332728757329667, 'ACC-54': 0.4063047281539997, 'ACC-55': 0.2958650610577103, 'ACC-56': 0.42623260977945254, 'ACC-57': 0.404555727306854, 'ACC-58': 0.1404024695319022, 'ACC-59': 0.43506223056168847, 'ACC-60': 0.11008608280153213, 'ACC-61': 0.3088323085388265, 'ACC-62': 0.18276081072650074, 'ACC-63': 0.3871739364614184, 'ACC-64': 0.09928577195234473, 'ACC-65': 0.2179647032697673, 'ACC-66': 0.15857321513913766, 'ACC-67': 0.344094039815538, 'ACC-68': 0.19693038431089627, 'ACC-69': 0.047971415010572456, 'ACC-70': 0.36573473763046677, 'ACC-71': 0.20803712648994685, 'ACC-72': 0.269210929335639, 'ACC-73': 0.4173905856572772, 'ACC-74': 0.37406237953127175, 'ACC-75': 0.2180752375949916, 'ACC-76': 0.4320904497621114, 'ACC-77': 0.3569823106979636, 'ACC-78': 0.07338435187397413, 'ACC-79': 0.2995277525962246, 'ACC-80': 0.07037307794083775, 'ACC-81': 0.09114509754386899, 'ACC-82': 0.18751171526302157, 'ACC-83': 0.09771756041321396, 'ACC-84': 0.045639038980661586, 'ACC-85': 0.05073432848533495, 'ACC-86': 0.27302475354073047, 'ACC-87': 0.12938134794443318, 'ACC-88': 0.07318594256782487, 'ACC-89': 0.038169665251138844, 'ACC-90': 0.30697599529785463, 'ACC-91': 0.11765182950908189, 'ACC-92': 0.04045561123593812, 'ACC-93': 0.01535082000927826, 'ACC-94': 0.13793908785041273, 'ACC-95': 0.09502028841341145, 'ACC-96': 0.09765408704169899, 'ACC-97': 0.05452993059718064, 'ACC-98': 0.0402224220505528, 'ACC-99': 0.10108708144895855, 'ACC-100': 0.02961933978674075, 'ACC-101': 0.08047168789365357, 'ACC-102': 0.0, 'ACC-103': 0.06678001322376499, 'ACC-104': 0.02269988441012272, 'ACC-105': 0.12892182990337758, 'ACC-106': 0.08742540061890051, 'ACC-107': 0.015964344303312752, 'ACC-108': 0.12281579813548815, 'ACC-109': 0.04065299943443003, 'ACC-110': 0.22139794752992092, 'ACC-111': 0.06336807922326154, 'ACC-112': 0.02849442023197261, 'ACC-113': 0.0, 'ACC-114': 0.035277006498184944, 'ACC-115': 1.3940883737013818, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.01721461630089806, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.07626178276338363, 'ACC-122': 0.0, 'ACC-123': 0.0016776238530480452, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.7468675714210792, 'ACC-129': 0.014621360112804108, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.11422189506815239, 'ACC-139': 0.0, 'ACC-140': 0.2837563174293964, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.09507095726030301, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.36778667815555116, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.21459718939518865, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 02:12:19] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 02:12:19] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 02:12:19] d2.evaluation.testing INFO: copypaste: 22.5396,0.9405,0.8645,0.3135,0.7929,0.7295,1.9487
[01/29 02:12:19] d2.utils.events INFO:  eta: 1 day, 14:30:43  iter: 5999  total_loss: 209.2  loss_mask: 20.23  loss_mask_0: 27.2  loss_mask_1: 20.22  loss_mask_2: 20.21  loss_mask_3: 20.22  loss_mask_4: 20.19  loss_mask_5: 20.17  loss_mask_6: 20.2  loss_mask_7: 20.25  loss_mask_8: 20.22  time: 2.6019  data_time: 0.0555  lr: 9.0955e-05  max_mem: 27639M
[01/29 02:13:11] d2.utils.events INFO:  eta: 1 day, 14:30:17  iter: 6019  total_loss: 196.8  loss_mask: 18.94  loss_mask_0: 26.29  loss_mask_1: 18.85  loss_mask_2: 18.83  loss_mask_3: 18.86  loss_mask_4: 18.86  loss_mask_5: 18.81  loss_mask_6: 18.82  loss_mask_7: 18.94  loss_mask_8: 18.92  time: 2.6018  data_time: 0.0528  lr: 9.0924e-05  max_mem: 27639M
[01/29 02:14:03] d2.utils.events INFO:  eta: 1 day, 14:29:06  iter: 6039  total_loss: 213.3  loss_mask: 20.75  loss_mask_0: 27.63  loss_mask_1: 20.71  loss_mask_2: 20.66  loss_mask_3: 20.69  loss_mask_4: 20.68  loss_mask_5: 20.68  loss_mask_6: 20.68  loss_mask_7: 20.72  loss_mask_8: 20.77  time: 2.6017  data_time: 0.0556  lr: 9.0894e-05  max_mem: 27639M
[01/29 02:14:54] d2.utils.events INFO:  eta: 1 day, 14:28:00  iter: 6059  total_loss: 203.2  loss_mask: 19.65  loss_mask_0: 26.41  loss_mask_1: 19.66  loss_mask_2: 19.64  loss_mask_3: 19.66  loss_mask_4: 19.66  loss_mask_5: 19.6  loss_mask_6: 19.64  loss_mask_7: 19.61  loss_mask_8: 19.63  time: 2.6016  data_time: 0.0586  lr: 9.0864e-05  max_mem: 27639M
[01/29 02:15:45] d2.utils.events INFO:  eta: 1 day, 14:27:09  iter: 6079  total_loss: 199  loss_mask: 19.1  loss_mask_0: 25.87  loss_mask_1: 19.11  loss_mask_2: 19.12  loss_mask_3: 19.14  loss_mask_4: 19.15  loss_mask_5: 19.14  loss_mask_6: 19.14  loss_mask_7: 19.11  loss_mask_8: 19.11  time: 2.6015  data_time: 0.0557  lr: 9.0833e-05  max_mem: 27639M
[01/29 02:16:37] d2.utils.events INFO:  eta: 1 day, 14:25:56  iter: 6099  total_loss: 195  loss_mask: 18.92  loss_mask_0: 27.43  loss_mask_1: 19.02  loss_mask_2: 18.96  loss_mask_3: 18.92  loss_mask_4: 18.97  loss_mask_5: 18.94  loss_mask_6: 18.92  loss_mask_7: 18.95  loss_mask_8: 18.91  time: 2.6014  data_time: 0.0483  lr: 9.0803e-05  max_mem: 27639M
[01/29 02:17:28] d2.utils.events INFO:  eta: 1 day, 14:24:54  iter: 6119  total_loss: 195.3  loss_mask: 18.82  loss_mask_0: 25.56  loss_mask_1: 18.93  loss_mask_2: 18.83  loss_mask_3: 18.82  loss_mask_4: 18.85  loss_mask_5: 18.8  loss_mask_6: 18.87  loss_mask_7: 18.82  loss_mask_8: 18.79  time: 2.6013  data_time: 0.0565  lr: 9.0773e-05  max_mem: 27639M
[01/29 02:18:19] d2.utils.events INFO:  eta: 1 day, 14:24:03  iter: 6139  total_loss: 197.4  loss_mask: 19.21  loss_mask_0: 25.93  loss_mask_1: 19.22  loss_mask_2: 19.18  loss_mask_3: 19.18  loss_mask_4: 19.16  loss_mask_5: 19.18  loss_mask_6: 19.17  loss_mask_7: 19.15  loss_mask_8: 19.15  time: 2.6011  data_time: 0.0575  lr: 9.0743e-05  max_mem: 27639M
[01/29 02:19:11] d2.utils.events INFO:  eta: 1 day, 14:23:13  iter: 6159  total_loss: 205.2  loss_mask: 19.77  loss_mask_0: 26.78  loss_mask_1: 19.71  loss_mask_2: 19.75  loss_mask_3: 19.71  loss_mask_4: 19.72  loss_mask_5: 19.81  loss_mask_6: 19.74  loss_mask_7: 19.76  loss_mask_8: 19.79  time: 2.6011  data_time: 0.0552  lr: 9.0712e-05  max_mem: 27639M
[01/29 02:20:02] d2.utils.events INFO:  eta: 1 day, 14:22:21  iter: 6179  total_loss: 197.4  loss_mask: 19.14  loss_mask_0: 25.98  loss_mask_1: 19.19  loss_mask_2: 19.13  loss_mask_3: 19.13  loss_mask_4: 19.18  loss_mask_5: 19.18  loss_mask_6: 19.2  loss_mask_7: 19.19  loss_mask_8: 19.16  time: 2.6010  data_time: 0.0609  lr: 9.0682e-05  max_mem: 27639M
[01/29 02:20:54] d2.utils.events INFO:  eta: 1 day, 14:21:16  iter: 6199  total_loss: 210.5  loss_mask: 20.34  loss_mask_0: 27.49  loss_mask_1: 20.39  loss_mask_2: 20.32  loss_mask_3: 20.34  loss_mask_4: 20.34  loss_mask_5: 20.29  loss_mask_6: 20.31  loss_mask_7: 20.39  loss_mask_8: 20.37  time: 2.6009  data_time: 0.0546  lr: 9.0652e-05  max_mem: 27639M
[01/29 02:21:45] d2.utils.events INFO:  eta: 1 day, 14:20:35  iter: 6219  total_loss: 206.4  loss_mask: 19.91  loss_mask_0: 27.38  loss_mask_1: 19.81  loss_mask_2: 19.81  loss_mask_3: 19.82  loss_mask_4: 19.78  loss_mask_5: 19.81  loss_mask_6: 19.86  loss_mask_7: 19.94  loss_mask_8: 19.89  time: 2.6008  data_time: 0.0533  lr: 9.0621e-05  max_mem: 27639M
[01/29 02:22:37] d2.utils.events INFO:  eta: 1 day, 14:19:57  iter: 6239  total_loss: 205  loss_mask: 19.61  loss_mask_0: 27.95  loss_mask_1: 19.54  loss_mask_2: 19.57  loss_mask_3: 19.57  loss_mask_4: 19.58  loss_mask_5: 19.52  loss_mask_6: 19.55  loss_mask_7: 19.62  loss_mask_8: 19.6  time: 2.6007  data_time: 0.0578  lr: 9.0591e-05  max_mem: 27639M
[01/29 02:23:29] d2.utils.events INFO:  eta: 1 day, 14:19:08  iter: 6259  total_loss: 219.7  loss_mask: 21.34  loss_mask_0: 27.29  loss_mask_1: 20.89  loss_mask_2: 21.25  loss_mask_3: 21.38  loss_mask_4: 21.27  loss_mask_5: 21.17  loss_mask_6: 21.28  loss_mask_7: 21.24  loss_mask_8: 21.23  time: 2.6006  data_time: 0.0543  lr: 9.0561e-05  max_mem: 27639M
[01/29 02:24:20] d2.utils.events INFO:  eta: 1 day, 14:18:17  iter: 6279  total_loss: 218.4  loss_mask: 21.16  loss_mask_0: 28.12  loss_mask_1: 20.83  loss_mask_2: 20.99  loss_mask_3: 21.14  loss_mask_4: 21.06  loss_mask_5: 21.05  loss_mask_6: 20.98  loss_mask_7: 21.14  loss_mask_8: 21.08  time: 2.6006  data_time: 0.0587  lr: 9.053e-05  max_mem: 27639M
[01/29 02:25:12] d2.utils.events INFO:  eta: 1 day, 14:17:25  iter: 6299  total_loss: 204.7  loss_mask: 19.88  loss_mask_0: 27.35  loss_mask_1: 19.86  loss_mask_2: 19.87  loss_mask_3: 19.88  loss_mask_4: 19.89  loss_mask_5: 19.91  loss_mask_6: 19.85  loss_mask_7: 19.88  loss_mask_8: 19.93  time: 2.6005  data_time: 0.0576  lr: 9.05e-05  max_mem: 27639M
[01/29 02:26:03] d2.utils.events INFO:  eta: 1 day, 14:16:46  iter: 6319  total_loss: 201.1  loss_mask: 19.48  loss_mask_0: 26.85  loss_mask_1: 19.57  loss_mask_2: 19.52  loss_mask_3: 19.49  loss_mask_4: 19.49  loss_mask_5: 19.53  loss_mask_6: 19.5  loss_mask_7: 19.53  loss_mask_8: 19.54  time: 2.6004  data_time: 0.0542  lr: 9.047e-05  max_mem: 27639M
[01/29 02:26:55] d2.utils.events INFO:  eta: 1 day, 14:16:09  iter: 6339  total_loss: 206.7  loss_mask: 20.25  loss_mask_0: 24.39  loss_mask_1: 20.18  loss_mask_2: 20.35  loss_mask_3: 20.32  loss_mask_4: 20.24  loss_mask_5: 20.08  loss_mask_6: 20.1  loss_mask_7: 20.37  loss_mask_8: 20.35  time: 2.6004  data_time: 0.0608  lr: 9.0439e-05  max_mem: 27639M
[01/29 02:27:46] d2.utils.events INFO:  eta: 1 day, 14:15:13  iter: 6359  total_loss: 193.7  loss_mask: 19.05  loss_mask_0: 22.17  loss_mask_1: 19.12  loss_mask_2: 19.07  loss_mask_3: 19.05  loss_mask_4: 19.06  loss_mask_5: 19.06  loss_mask_6: 18.96  loss_mask_7: 19.06  loss_mask_8: 19.1  time: 2.6002  data_time: 0.0560  lr: 9.0409e-05  max_mem: 27639M
[01/29 02:28:38] d2.utils.events INFO:  eta: 1 day, 14:14:11  iter: 6379  total_loss: 201.9  loss_mask: 20.11  loss_mask_0: 20.84  loss_mask_1: 19.98  loss_mask_2: 20.05  loss_mask_3: 19.99  loss_mask_4: 20.04  loss_mask_5: 20.02  loss_mask_6: 19.99  loss_mask_7: 20.14  loss_mask_8: 20.09  time: 2.6001  data_time: 0.0533  lr: 9.0379e-05  max_mem: 27639M
[01/29 02:29:29] d2.utils.events INFO:  eta: 1 day, 14:13:27  iter: 6399  total_loss: 203  loss_mask: 20.57  loss_mask_0: 19.63  loss_mask_1: 20.5  loss_mask_2: 20.42  loss_mask_3: 20.47  loss_mask_4: 20.46  loss_mask_5: 20.39  loss_mask_6: 20.47  loss_mask_7: 20.54  loss_mask_8: 20.47  time: 2.6001  data_time: 0.0535  lr: 9.0348e-05  max_mem: 27639M
[01/29 02:30:21] d2.utils.events INFO:  eta: 1 day, 14:12:35  iter: 6419  total_loss: 235  loss_mask: 20.87  loss_mask_0: 46.58  loss_mask_1: 20.91  loss_mask_2: 20.67  loss_mask_3: 20.74  loss_mask_4: 20.66  loss_mask_5: 20.64  loss_mask_6: 20.68  loss_mask_7: 20.84  loss_mask_8: 20.78  time: 2.6000  data_time: 0.0531  lr: 9.0318e-05  max_mem: 27639M
[01/29 02:31:12] d2.utils.events INFO:  eta: 1 day, 14:11:48  iter: 6439  total_loss: 208  loss_mask: 20.02  loss_mask_0: 27.17  loss_mask_1: 20.15  loss_mask_2: 20.08  loss_mask_3: 20.06  loss_mask_4: 20.05  loss_mask_5: 20.1  loss_mask_6: 20.05  loss_mask_7: 20.06  loss_mask_8: 20.05  time: 2.5999  data_time: 0.0577  lr: 9.0288e-05  max_mem: 27639M
[01/29 02:32:04] d2.utils.events INFO:  eta: 1 day, 14:11:01  iter: 6459  total_loss: 205  loss_mask: 20.45  loss_mask_0: 20.82  loss_mask_1: 20.55  loss_mask_2: 20.43  loss_mask_3: 20.45  loss_mask_4: 20.54  loss_mask_5: 20.43  loss_mask_6: 20.43  loss_mask_7: 20.45  loss_mask_8: 20.45  time: 2.5998  data_time: 0.0572  lr: 9.0257e-05  max_mem: 27639M
[01/29 02:32:56] d2.utils.events INFO:  eta: 1 day, 14:10:08  iter: 6479  total_loss: 201.7  loss_mask: 20.2  loss_mask_0: 19.74  loss_mask_1: 20.2  loss_mask_2: 20.18  loss_mask_3: 20.18  loss_mask_4: 20.18  loss_mask_5: 20.16  loss_mask_6: 20.14  loss_mask_7: 20.18  loss_mask_8: 20.2  time: 2.5998  data_time: 0.0567  lr: 9.0227e-05  max_mem: 27639M
[01/29 02:33:47] d2.utils.events INFO:  eta: 1 day, 14:09:37  iter: 6499  total_loss: 190.6  loss_mask: 19.07  loss_mask_0: 18.93  loss_mask_1: 18.99  loss_mask_2: 18.97  loss_mask_3: 18.96  loss_mask_4: 18.98  loss_mask_5: 18.97  loss_mask_6: 18.93  loss_mask_7: 19.08  loss_mask_8: 19.07  time: 2.5997  data_time: 0.0635  lr: 9.0196e-05  max_mem: 27639M
[01/29 02:34:39] d2.utils.events INFO:  eta: 1 day, 14:08:49  iter: 6519  total_loss: 197.8  loss_mask: 20  loss_mask_0: 16.95  loss_mask_1: 20.08  loss_mask_2: 20  loss_mask_3: 20.04  loss_mask_4: 19.99  loss_mask_5: 20.01  loss_mask_6: 20.02  loss_mask_7: 19.99  loss_mask_8: 20  time: 2.5997  data_time: 0.0514  lr: 9.0166e-05  max_mem: 27639M
[01/29 02:35:31] d2.utils.events INFO:  eta: 1 day, 14:08:17  iter: 6539  total_loss: 202.3  loss_mask: 19.96  loss_mask_0: 21.41  loss_mask_1: 19.8  loss_mask_2: 19.83  loss_mask_3: 19.84  loss_mask_4: 19.84  loss_mask_5: 19.84  loss_mask_6: 19.83  loss_mask_7: 19.92  loss_mask_8: 19.96  time: 2.5996  data_time: 0.0481  lr: 9.0136e-05  max_mem: 27639M
[01/29 02:36:22] d2.utils.events INFO:  eta: 1 day, 14:07:27  iter: 6559  total_loss: 197.4  loss_mask: 19.9  loss_mask_0: 19.06  loss_mask_1: 19.57  loss_mask_2: 19.69  loss_mask_3: 19.76  loss_mask_4: 19.75  loss_mask_5: 19.7  loss_mask_6: 19.64  loss_mask_7: 19.92  loss_mask_8: 19.93  time: 2.5995  data_time: 0.0530  lr: 9.0105e-05  max_mem: 27639M
[01/29 02:37:14] d2.utils.events INFO:  eta: 1 day, 14:06:46  iter: 6579  total_loss: 201.3  loss_mask: 20.58  loss_mask_0: 19.68  loss_mask_1: 18.2  loss_mask_2: 20.28  loss_mask_3: 20.34  loss_mask_4: 20.38  loss_mask_5: 20.38  loss_mask_6: 20.38  loss_mask_7: 20.54  loss_mask_8: 20.57  time: 2.5995  data_time: 0.0593  lr: 9.0075e-05  max_mem: 27639M
[01/29 02:38:06] d2.utils.events INFO:  eta: 1 day, 14:06:14  iter: 6599  total_loss: 183.8  loss_mask: 18.7  loss_mask_0: 17.5  loss_mask_1: 15.04  loss_mask_2: 17.69  loss_mask_3: 18.57  loss_mask_4: 18.72  loss_mask_5: 18.76  loss_mask_6: 18.66  loss_mask_7: 19.02  loss_mask_8: 18.79  time: 2.5995  data_time: 0.0538  lr: 9.0045e-05  max_mem: 27639M
[01/29 02:38:57] d2.utils.events INFO:  eta: 1 day, 14:05:47  iter: 6619  total_loss: 188.1  loss_mask: 19.43  loss_mask_0: 18.22  loss_mask_1: 15.92  loss_mask_2: 18.88  loss_mask_3: 19.21  loss_mask_4: 19.39  loss_mask_5: 19.39  loss_mask_6: 19.34  loss_mask_7: 19.35  loss_mask_8: 19.46  time: 2.5994  data_time: 0.0523  lr: 9.0014e-05  max_mem: 27639M
[01/29 02:39:49] d2.utils.events INFO:  eta: 1 day, 14:05:09  iter: 6639  total_loss: 181.7  loss_mask: 19.14  loss_mask_0: 16.65  loss_mask_1: 14.21  loss_mask_2: 17.54  loss_mask_3: 18.79  loss_mask_4: 18.96  loss_mask_5: 19.07  loss_mask_6: 19.01  loss_mask_7: 19.13  loss_mask_8: 19.17  time: 2.5993  data_time: 0.0528  lr: 8.9984e-05  max_mem: 27639M
[01/29 02:40:41] d2.utils.events INFO:  eta: 1 day, 14:04:27  iter: 6659  total_loss: 174.1  loss_mask: 19.62  loss_mask_0: 15.81  loss_mask_1: 13.36  loss_mask_2: 13.94  loss_mask_3: 15.88  loss_mask_4: 18.58  loss_mask_5: 19.34  loss_mask_6: 19.54  loss_mask_7: 19.72  loss_mask_8: 19.71  time: 2.5993  data_time: 0.0557  lr: 8.9954e-05  max_mem: 27639M
[01/29 02:41:33] d2.utils.events INFO:  eta: 1 day, 14:03:59  iter: 6679  total_loss: 166.3  loss_mask: 19.81  loss_mask_0: 15.44  loss_mask_1: 13.23  loss_mask_2: 13.79  loss_mask_3: 14.08  loss_mask_4: 15.55  loss_mask_5: 18.04  loss_mask_6: 18.96  loss_mask_7: 19.82  loss_mask_8: 19.9  time: 2.5993  data_time: 0.0554  lr: 8.9923e-05  max_mem: 27639M
[01/29 02:42:25] d2.utils.events INFO:  eta: 1 day, 14:04:01  iter: 6699  total_loss: 158.4  loss_mask: 19.44  loss_mask_0: 14.84  loss_mask_1: 12.3  loss_mask_2: 12.83  loss_mask_3: 12.84  loss_mask_4: 13.23  loss_mask_5: 14.86  loss_mask_6: 17.47  loss_mask_7: 19.26  loss_mask_8: 19.44  time: 2.5993  data_time: 0.0530  lr: 8.9893e-05  max_mem: 27639M
[01/29 02:43:17] d2.utils.events INFO:  eta: 1 day, 14:03:43  iter: 6719  total_loss: 148  loss_mask: 19.02  loss_mask_0: 14.61  loss_mask_1: 12.14  loss_mask_2: 12.37  loss_mask_3: 12.56  loss_mask_4: 12.98  loss_mask_5: 13.25  loss_mask_6: 14.42  loss_mask_7: 18.05  loss_mask_8: 18.82  time: 2.5993  data_time: 0.0611  lr: 8.9863e-05  max_mem: 27639M
[01/29 02:44:09] d2.utils.events INFO:  eta: 1 day, 14:03:19  iter: 6739  total_loss: 146.5  loss_mask: 19.69  loss_mask_0: 14.74  loss_mask_1: 12.24  loss_mask_2: 12.72  loss_mask_3: 12.84  loss_mask_4: 13.27  loss_mask_5: 12.86  loss_mask_6: 13.05  loss_mask_7: 16.17  loss_mask_8: 19.06  time: 2.5993  data_time: 0.0527  lr: 8.9832e-05  max_mem: 27639M
[01/29 02:45:01] d2.utils.events INFO:  eta: 1 day, 14:03:09  iter: 6759  total_loss: 127.3  loss_mask: 18.01  loss_mask_0: 13.2  loss_mask_1: 11.3  loss_mask_2: 11.35  loss_mask_3: 11.32  loss_mask_4: 11.26  loss_mask_5: 11.64  loss_mask_6: 11.96  loss_mask_7: 13.05  loss_mask_8: 14.77  time: 2.5993  data_time: 0.0558  lr: 8.9802e-05  max_mem: 27639M
[01/29 02:45:53] d2.utils.events INFO:  eta: 1 day, 14:02:29  iter: 6779  total_loss: 129.4  loss_mask: 15.57  loss_mask_0: 14.19  loss_mask_1: 11.88  loss_mask_2: 12.12  loss_mask_3: 12.11  loss_mask_4: 12.24  loss_mask_5: 12.17  loss_mask_6: 12.37  loss_mask_7: 12.94  loss_mask_8: 13.44  time: 2.5993  data_time: 0.0552  lr: 8.9772e-05  max_mem: 27639M
[01/29 02:46:45] d2.utils.events INFO:  eta: 1 day, 14:02:11  iter: 6799  total_loss: 118.5  loss_mask: 12.5  loss_mask_0: 13.4  loss_mask_1: 11.05  loss_mask_2: 11.19  loss_mask_3: 11.17  loss_mask_4: 11.41  loss_mask_5: 11.36  loss_mask_6: 11.42  loss_mask_7: 11.82  loss_mask_8: 12.39  time: 2.5993  data_time: 0.0530  lr: 8.9741e-05  max_mem: 27639M
[01/29 02:47:37] d2.utils.events INFO:  eta: 1 day, 14:01:28  iter: 6819  total_loss: 109.5  loss_mask: 11.11  loss_mask_0: 12.94  loss_mask_1: 10.45  loss_mask_2: 10.43  loss_mask_3: 10.51  loss_mask_4: 10.67  loss_mask_5: 10.76  loss_mask_6: 10.79  loss_mask_7: 11.01  loss_mask_8: 11.19  time: 2.5993  data_time: 0.0610  lr: 8.9711e-05  max_mem: 27639M
[01/29 02:48:29] d2.utils.events INFO:  eta: 1 day, 14:00:41  iter: 6839  total_loss: 105.2  loss_mask: 10.72  loss_mask_0: 12.78  loss_mask_1: 10.09  loss_mask_2: 10.1  loss_mask_3: 10.08  loss_mask_4: 10.16  loss_mask_5: 10.13  loss_mask_6: 10.14  loss_mask_7: 10.39  loss_mask_8: 10.57  time: 2.5993  data_time: 0.0576  lr: 8.968e-05  max_mem: 27639M
[01/29 02:49:21] d2.utils.events INFO:  eta: 1 day, 14:01:02  iter: 6859  total_loss: 111.8  loss_mask: 11.28  loss_mask_0: 12.7  loss_mask_1: 10.8  loss_mask_2: 10.8  loss_mask_3: 10.79  loss_mask_4: 10.84  loss_mask_5: 10.91  loss_mask_6: 10.97  loss_mask_7: 11.14  loss_mask_8: 11.26  time: 2.5993  data_time: 0.0543  lr: 8.965e-05  max_mem: 27639M
[01/29 02:50:13] d2.utils.events INFO:  eta: 1 day, 14:01:02  iter: 6879  total_loss: 106  loss_mask: 10.66  loss_mask_0: 12.31  loss_mask_1: 10.4  loss_mask_2: 10.41  loss_mask_3: 10.26  loss_mask_4: 10.2  loss_mask_5: 10.28  loss_mask_6: 10.39  loss_mask_7: 10.52  loss_mask_8: 10.52  time: 2.5993  data_time: 0.0518  lr: 8.962e-05  max_mem: 27639M
[01/29 02:51:05] d2.utils.events INFO:  eta: 1 day, 14:00:50  iter: 6899  total_loss: 104.3  loss_mask: 10.76  loss_mask_0: 12.3  loss_mask_1: 10.06  loss_mask_2: 9.923  loss_mask_3: 9.918  loss_mask_4: 10.05  loss_mask_5: 10.12  loss_mask_6: 10.18  loss_mask_7: 10.6  loss_mask_8: 10.69  time: 2.5994  data_time: 0.0535  lr: 8.9589e-05  max_mem: 27639M
[01/29 02:51:58] d2.utils.events INFO:  eta: 1 day, 14:00:55  iter: 6919  total_loss: 108  loss_mask: 10.93  loss_mask_0: 12.65  loss_mask_1: 10.48  loss_mask_2: 10.5  loss_mask_3: 10.54  loss_mask_4: 10.59  loss_mask_5: 10.58  loss_mask_6: 10.61  loss_mask_7: 10.79  loss_mask_8: 10.92  time: 2.5994  data_time: 0.0515  lr: 8.9559e-05  max_mem: 27639M
[01/29 02:52:50] d2.utils.events INFO:  eta: 1 day, 14:01:05  iter: 6939  total_loss: 110.8  loss_mask: 11.14  loss_mask_0: 12.56  loss_mask_1: 10.84  loss_mask_2: 10.8  loss_mask_3: 10.75  loss_mask_4: 10.85  loss_mask_5: 10.88  loss_mask_6: 10.83  loss_mask_7: 10.88  loss_mask_8: 11.01  time: 2.5994  data_time: 0.0542  lr: 8.9529e-05  max_mem: 27639M
[01/29 02:53:42] d2.utils.events INFO:  eta: 1 day, 14:01:12  iter: 6959  total_loss: 109.2  loss_mask: 10.81  loss_mask_0: 12.63  loss_mask_1: 10.75  loss_mask_2: 10.59  loss_mask_3: 10.56  loss_mask_4: 10.66  loss_mask_5: 10.55  loss_mask_6: 10.61  loss_mask_7: 10.88  loss_mask_8: 10.85  time: 2.5994  data_time: 0.0588  lr: 8.9498e-05  max_mem: 27639M
[01/29 02:54:34] d2.utils.events INFO:  eta: 1 day, 14:00:58  iter: 6979  total_loss: 97.29  loss_mask: 9.714  loss_mask_0: 11.26  loss_mask_1: 9.556  loss_mask_2: 9.465  loss_mask_3: 9.449  loss_mask_4: 9.496  loss_mask_5: 9.432  loss_mask_6: 9.457  loss_mask_7: 9.601  loss_mask_8: 9.609  time: 2.5994  data_time: 0.0502  lr: 8.9468e-05  max_mem: 27639M
[01/29 02:55:26] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 02:55:27] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 02:55:27] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 03:09:04] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 9.746970173270403, 'error_1pix': 0.8166414163335864, 'error_3pix': 0.6164829819677656, 'mIoU': 1.4470998471433731, 'fwIoU': 3.173003044929159, 'IoU-0': 0.6728743374456442, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.004367946683615422, 'IoU-7': 0.016236023864846506, 'IoU-8': 0.3245646315762745, 'IoU-9': 2.0067914596795693, 'IoU-10': 3.479549631782474, 'IoU-11': 5.982332162861887, 'IoU-12': 6.346814100491967, 'IoU-13': 5.8892514079217975, 'IoU-14': 5.674463885757737, 'IoU-15': 4.950594509302243, 'IoU-16': 5.1398040355810055, 'IoU-17': 4.055183029413497, 'IoU-18': 3.554253266464885, 'IoU-19': 3.6828472800054044, 'IoU-20': 3.6235617764921955, 'IoU-21': 3.7657052843062493, 'IoU-22': 4.0334893198916735, 'IoU-23': 3.977936773301187, 'IoU-24': 3.877327377396938, 'IoU-25': 4.005967719117965, 'IoU-26': 4.3575753334824086, 'IoU-27': 4.4268104880855415, 'IoU-28': 4.62349537213521, 'IoU-29': 4.780909002875523, 'IoU-30': 5.073923679661316, 'IoU-31': 5.319746094225686, 'IoU-32': 5.172724240783701, 'IoU-33': 4.900203608781662, 'IoU-34': 4.721453279947885, 'IoU-35': 5.0331205516208, 'IoU-36': 4.88843761985042, 'IoU-37': 4.886385959243973, 'IoU-38': 4.798100226979118, 'IoU-39': 4.694318214346352, 'IoU-40': 4.562484627126828, 'IoU-41': 4.309236527878163, 'IoU-42': 4.192398231475123, 'IoU-43': 4.0692956072437205, 'IoU-44': 4.130005802514144, 'IoU-45': 3.9653989542228616, 'IoU-46': 3.7585131749351306, 'IoU-47': 3.7081737534721473, 'IoU-48': 3.6877245057482586, 'IoU-49': 3.6650856405565797, 'IoU-50': 3.682870667830441, 'IoU-51': 3.458795843471676, 'IoU-52': 3.402452559424584, 'IoU-53': 3.262488190865795, 'IoU-54': 3.03624971241689, 'IoU-55': 2.9269438373838175, 'IoU-56': 2.7270286774288706, 'IoU-57': 2.6685183911709256, 'IoU-58': 2.4255998088828723, 'IoU-59': 2.282730896827069, 'IoU-60': 2.157930013417851, 'IoU-61': 2.0972727135488523, 'IoU-62': 1.9845853621118328, 'IoU-63': 1.7812428581070918, 'IoU-64': 1.7389559481565908, 'IoU-65': 1.665811785677104, 'IoU-66': 1.6598962070485697, 'IoU-67': 1.5260428807367348, 'IoU-68': 1.5070387102340879, 'IoU-69': 1.5068328948273533, 'IoU-70': 1.4724295235732976, 'IoU-71': 1.4197989449891748, 'IoU-72': 1.3730814447851114, 'IoU-73': 1.3735268252422153, 'IoU-74': 1.4087133469744635, 'IoU-75': 1.2616149944766604, 'IoU-76': 1.269317671892064, 'IoU-77': 1.1874892923457, 'IoU-78': 1.2355613100315677, 'IoU-79': 1.2418848457835168, 'IoU-80': 1.1934179579618744, 'IoU-81': 1.1194040080084604, 'IoU-82': 1.0344599150506066, 'IoU-83': 1.0476629804557178, 'IoU-84': 0.9639268612280399, 'IoU-85': 0.8825660852470943, 'IoU-86': 0.8433403470987335, 'IoU-87': 0.7855487759473322, 'IoU-88': 0.7868514376647829, 'IoU-89': 0.8129640595222212, 'IoU-90': 0.7442146507878171, 'IoU-91': 0.7528881453998233, 'IoU-92': 0.6709001788856851, 'IoU-93': 0.6125738991157745, 'IoU-94': 0.5935282570615854, 'IoU-95': 0.626247441926465, 'IoU-96': 0.6351746220257707, 'IoU-97': 0.6433141488782333, 'IoU-98': 0.5795806141709984, 'IoU-99': 0.5536656343659326, 'IoU-100': 0.5029425785194533, 'IoU-101': 0.4758777434720477, 'IoU-102': 0.5401654573018494, 'IoU-103': 0.6095189743562903, 'IoU-104': 0.5447778156301913, 'IoU-105': 0.5087517540139165, 'IoU-106': 0.5244350188841191, 'IoU-107': 0.5049747945308356, 'IoU-108': 0.4119843274570086, 'IoU-109': 0.40600895116508573, 'IoU-110': 0.44614919499839073, 'IoU-111': 0.47827591814948106, 'IoU-112': 0.42061583654287815, 'IoU-113': 0.4961607027862349, 'IoU-114': 0.4607698392570318, 'IoU-115': 0.5158621930300505, 'IoU-116': 0.4543477982205911, 'IoU-117': 0.39873773122509676, 'IoU-118': 0.4008002953179461, 'IoU-119': 0.5599282381586339, 'IoU-120': 0.6888872875702289, 'IoU-121': 0.4739854366724746, 'IoU-122': 0.5213581535296812, 'IoU-123': 0.4894883781459121, 'IoU-124': 0.46690693972696984, 'IoU-125': 0.444691052039549, 'IoU-126': 0.5085180542084324, 'IoU-127': 0.4732025747498678, 'IoU-128': 0.39499499097295665, 'IoU-129': 0.4368017559044037, 'IoU-130': 0.47142813772783276, 'IoU-131': 0.4539643877921784, 'IoU-132': 0.3285695920466232, 'IoU-133': 0.33668780149942923, 'IoU-134': 0.32180336827309053, 'IoU-135': 0.25948210939140515, 'IoU-136': 0.1842246344696411, 'IoU-137': 0.18772434908483848, 'IoU-138': 0.15746765990515707, 'IoU-139': 0.15053090757431373, 'IoU-140': 0.12894750588631337, 'IoU-141': 0.16583447034574852, 'IoU-142': 0.25252552182031657, 'IoU-143': 0.18382972590017285, 'IoU-144': 0.1689371467487093, 'IoU-145': 0.11335598047510888, 'IoU-146': 0.11394546467721797, 'IoU-147': 0.08053248978515883, 'IoU-148': 0.1069099883282394, 'IoU-149': 0.12304422182388361, 'IoU-150': 0.056261983432326454, 'IoU-151': 0.06295137006662353, 'IoU-152': 0.04047159124046311, 'IoU-153': 0.06476493797066896, 'IoU-154': 0.06097302545647893, 'IoU-155': 0.1322441309375971, 'IoU-156': 0.07196172852297145, 'IoU-157': 0.14194281898905428, 'IoU-158': 0.06009735521660037, 'IoU-159': 0.008674396805750478, 'IoU-160': 0.009879870903020201, 'IoU-161': 0.04702908454947607, 'IoU-162': 0.01682120880596801, 'IoU-163': 0.014096804772199949, 'IoU-164': 0.009587016087631512, 'IoU-165': 0.0037476108980524915, 'IoU-166': 0.006777710919057601, 'IoU-167': 0.006511097137002052, 'IoU-168': 0.0036415532438436077, 'IoU-169': 0.00294528866427694, 'IoU-170': 0.007365862384645335, 'IoU-171': 0.009433585742223641, 'IoU-172': 0.009325731338480163, 'IoU-173': 0.0059392672800197485, 'IoU-174': 0.008271815534837211, 'IoU-175': 0.0074758993415738415, 'IoU-176': 0.0014324749227358838, 'IoU-177': 0.0032797997135641586, 'IoU-178': 0.003628717286636198, 'IoU-179': 0.0034096629848992042, 'IoU-180': 0.003345621522383254, 'IoU-181': 0.004441556134256554, 'IoU-182': 0.00584621644564071, 'IoU-183': 0.007907620387705977, 'IoU-184': 0.008618621346694525, 'IoU-185': 0.009813833854075136, 'IoU-186': 0.007463730932499884, 'IoU-187': 0.02243570618772003, 'IoU-188': 0.016931216931216932, 'IoU-189': 0.01647408879280412, 'IoU-190': 0.0160298258178443, 'IoU-191': 0.012875779628456503, 'IoU-192': 0.013105392450736272, 'mACC': 3.0331323591792096, 'pACC': 6.238023000581529, 'ACC-0': 0.6788271198152259, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.06260380072330672, 'ACC-7': 2.161888197308305, 'ACC-8': 9.481082473597189, 'ACC-9': 16.716394952548097, 'ACC-10': 13.71772412787037, 'ACC-11': 13.08810139961842, 'ACC-12': 12.103502833286935, 'ACC-13': 10.854666457303518, 'ACC-14': 10.465626028333126, 'ACC-15': 9.42257880409313, 'ACC-16': 9.874056137374277, 'ACC-17': 8.256029328001539, 'ACC-18': 6.888777710627752, 'ACC-19': 6.9987970465142615, 'ACC-20': 6.808422875371198, 'ACC-21': 6.823509805210362, 'ACC-22': 6.945239099483961, 'ACC-23': 7.059107131340281, 'ACC-24': 6.922549178659704, 'ACC-25': 7.171338337364909, 'ACC-26': 7.745222077692031, 'ACC-27': 7.653844480589629, 'ACC-28': 8.187914205997862, 'ACC-29': 8.332370473796251, 'ACC-30': 9.016378764523933, 'ACC-31': 9.365512627827583, 'ACC-32': 9.336067170362822, 'ACC-33': 9.119622981908329, 'ACC-34': 8.825988496220985, 'ACC-35': 9.226195979819389, 'ACC-36': 8.981023966330254, 'ACC-37': 9.157388522740703, 'ACC-38': 9.010543539262478, 'ACC-39': 8.894074603986542, 'ACC-40': 8.718290963647648, 'ACC-41': 8.62434783839459, 'ACC-42': 8.529793235398477, 'ACC-43': 8.354338154360413, 'ACC-44': 8.355931459631979, 'ACC-45': 8.196757476992929, 'ACC-46': 8.073391459967487, 'ACC-47': 8.051898690983798, 'ACC-48': 8.112854227817468, 'ACC-49': 8.106013204999396, 'ACC-50': 8.214337517801571, 'ACC-51': 7.879048467632923, 'ACC-52': 7.743093051103705, 'ACC-53': 7.410519068552341, 'ACC-54': 6.825637874351538, 'ACC-55': 6.57794639006593, 'ACC-56': 6.195171290942532, 'ACC-57': 5.943492678072314, 'ACC-58': 5.451854905719084, 'ACC-59': 5.192677755390404, 'ACC-60': 4.94234136366087, 'ACC-61': 4.835643753776516, 'ACC-62': 4.597607782706432, 'ACC-63': 4.162000688022415, 'ACC-64': 4.042150951459328, 'ACC-65': 3.893541418837098, 'ACC-66': 3.8948402534554956, 'ACC-67': 3.6094641625666055, 'ACC-68': 3.57413114014559, 'ACC-69': 3.5058539114025384, 'ACC-70': 3.410541293765851, 'ACC-71': 3.353402351939763, 'ACC-72': 3.2524367801371445, 'ACC-73': 3.23338205376278, 'ACC-74': 3.2685252650597962, 'ACC-75': 2.918113130488054, 'ACC-76': 2.8768185840726708, 'ACC-77': 2.718597902906313, 'ACC-78': 2.838851912019527, 'ACC-79': 2.833996778617559, 'ACC-80': 2.6895254583234687, 'ACC-81': 2.4883520199619507, 'ACC-82': 2.266409750339166, 'ACC-83': 2.2304200107756427, 'ACC-84': 2.0248240532252817, 'ACC-85': 1.8148516414360591, 'ACC-86': 1.6939060955645928, 'ACC-87': 1.5359125917965253, 'ACC-88': 1.5074695410488552, 'ACC-89': 1.5123080193326344, 'ACC-90': 1.3550717293597832, 'ACC-91': 1.359963161342488, 'ACC-92': 1.2097578649903113, 'ACC-93': 1.099940762334686, 'ACC-94': 1.056514276817232, 'ACC-95': 1.111424155331493, 'ACC-96': 1.1200910461160767, 'ACC-97': 1.127887839209126, 'ACC-98': 1.042623671761928, 'ACC-99': 1.0013252011135392, 'ACC-100': 0.9218892800290639, 'ACC-101': 0.8727868136478608, 'ACC-102': 0.9793158133212505, 'ACC-103': 1.0999837063939417, 'ACC-104': 0.9926474928285017, 'ACC-105': 0.9257700895736002, 'ACC-106': 0.9561989302844052, 'ACC-107': 0.9362938353154141, 'ACC-108': 0.7772714497211082, 'ACC-109': 0.7390964771652896, 'ACC-110': 0.8255827993095202, 'ACC-111': 0.89859195626537, 'ACC-112': 0.8008133255123824, 'ACC-113': 0.9364688829127806, 'ACC-114': 0.8898697775544214, 'ACC-115': 1.0045404657736081, 'ACC-116': 0.9054915098625824, 'ACC-117': 0.7863688564179673, 'ACC-118': 0.8251259501103624, 'ACC-119': 1.1059752084158083, 'ACC-120': 1.3017566423147338, 'ACC-121': 0.9043328489936742, 'ACC-122': 1.0129625427473306, 'ACC-123': 0.9502362021341582, 'ACC-124': 0.9349603241195791, 'ACC-125': 0.8795936237212363, 'ACC-126': 0.9794847273927842, 'ACC-127': 0.9299318190181307, 'ACC-128': 0.8033424118201654, 'ACC-129': 0.9076857715360435, 'ACC-130': 0.9514282710667645, 'ACC-131': 0.8876111258426026, 'ACC-132': 0.6166621427350685, 'ACC-133': 0.621500487524742, 'ACC-134': 0.5732023918015858, 'ACC-135': 0.46847586430020083, 'ACC-136': 0.331951657356005, 'ACC-137': 0.33711998632286583, 'ACC-138': 0.2688973779729421, 'ACC-139': 0.25447775082332247, 'ACC-140': 0.22080979050401947, 'ACC-141': 0.26921513563006355, 'ACC-142': 0.4136092824542681, 'ACC-143': 0.28423029573250186, 'ACC-144': 0.25433809818641956, 'ACC-145': 0.1686124936043537, 'ACC-146': 0.1668712194667249, 'ACC-147': 0.11346859185663216, 'ACC-148': 0.14610557815317607, 'ACC-149': 0.16672734703729358, 'ACC-150': 0.07129567379102238, 'ACC-151': 0.07673779123057575, 'ACC-152': 0.04826041234202091, 'ACC-153': 0.08336873832637258, 'ACC-154': 0.07432892604682839, 'ACC-155': 0.15370109020540726, 'ACC-156': 0.08260872937690523, 'ACC-157': 0.16550792968090725, 'ACC-158': 0.06788760860605993, 'ACC-159': 0.009498722634463634, 'ACC-160': 0.01102945855256739, 'ACC-161': 0.053942963744428356, 'ACC-162': 0.019192687139858153, 'ACC-163': 0.014981960496544976, 'ACC-164': 0.009830409579258471, 'ACC-165': 0.0038117079786989055, 'ACC-166': 0.0068835257082896124, 'ACC-167': 0.006601600366909999, 'ACC-168': 0.0036928466044275476, 'ACC-169': 0.002983555344951649, 'ACC-170': 0.007454553844952379, 'ACC-171': 0.009552852996289085, 'ACC-172': 0.009446386201608108, 'ACC-173': 0.0060212739133952645, 'ACC-174': 0.008388745658824122, 'ACC-175': 0.0075815151565582885, 'ACC-176': 0.0014512761252378733, 'ACC-177': 0.0033220322716979458, 'ACC-178': 0.0036701217321429263, 'ACC-179': 0.003449234371417615, 'ACC-180': 0.0033866017567996615, 'ACC-181': 0.0045005459872895105, 'ACC-182': 0.005923174063131559, 'ACC-183': 0.008005292911313126, 'ACC-184': 0.008726970821255127, 'ACC-185': 0.009932872263262695, 'ACC-186': 0.007555455865512886, 'ACC-187': 0.02271398263105243, 'ACC-188': 0.017152399065698733, 'ACC-189': 0.01669046127299432, 'ACC-190': 0.016247038846145784, 'ACC-191': 0.013052342503909176, 'ACC-192': 0.01330261467136881})])
[01/29 03:09:04] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 03:09:04] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 03:09:04] d2.evaluation.testing INFO: copypaste: 9.7470,0.8166,0.6165,1.4471,3.1730,3.0331,6.2380
[01/29 03:09:04] d2.utils.events INFO:  eta: 1 day, 14:00:50  iter: 6999  total_loss: 108.9  loss_mask: 10.89  loss_mask_0: 12.44  loss_mask_1: 10.73  loss_mask_2: 10.57  loss_mask_3: 10.56  loss_mask_4: 10.56  loss_mask_5: 10.61  loss_mask_6: 10.61  loss_mask_7: 10.87  loss_mask_8: 10.93  time: 2.5995  data_time: 0.0570  lr: 8.9437e-05  max_mem: 27639M
[01/29 03:09:57] d2.utils.events INFO:  eta: 1 day, 14:00:07  iter: 7019  total_loss: 104.9  loss_mask: 10.52  loss_mask_0: 11.9  loss_mask_1: 10.16  loss_mask_2: 10.2  loss_mask_3: 10.21  loss_mask_4: 10.25  loss_mask_5: 10.26  loss_mask_6: 10.26  loss_mask_7: 10.61  loss_mask_8: 10.64  time: 2.5995  data_time: 0.0529  lr: 8.9407e-05  max_mem: 27639M
[01/29 03:10:49] d2.utils.events INFO:  eta: 1 day, 13:59:50  iter: 7039  total_loss: 106.4  loss_mask: 10.78  loss_mask_0: 11.59  loss_mask_1: 10.26  loss_mask_2: 10.25  loss_mask_3: 10.22  loss_mask_4: 10.36  loss_mask_5: 10.35  loss_mask_6: 10.46  loss_mask_7: 10.77  loss_mask_8: 10.8  time: 2.5995  data_time: 0.0496  lr: 8.9377e-05  max_mem: 27639M
[01/29 03:11:41] d2.utils.events INFO:  eta: 1 day, 13:59:28  iter: 7059  total_loss: 102.4  loss_mask: 10.3  loss_mask_0: 11.73  loss_mask_1: 10  loss_mask_2: 9.936  loss_mask_3: 10.01  loss_mask_4: 10.06  loss_mask_5: 10  loss_mask_6: 10.05  loss_mask_7: 10.29  loss_mask_8: 10.21  time: 2.5996  data_time: 0.0569  lr: 8.9346e-05  max_mem: 27639M
[01/29 03:12:34] d2.utils.events INFO:  eta: 1 day, 13:58:49  iter: 7079  total_loss: 101.9  loss_mask: 10.14  loss_mask_0: 12.14  loss_mask_1: 10.13  loss_mask_2: 9.988  loss_mask_3: 9.977  loss_mask_4: 9.941  loss_mask_5: 9.978  loss_mask_6: 9.967  loss_mask_7: 10.13  loss_mask_8: 10.15  time: 2.5996  data_time: 0.0598  lr: 8.9316e-05  max_mem: 27639M
[01/29 03:13:26] d2.utils.events INFO:  eta: 1 day, 13:58:56  iter: 7099  total_loss: 91.11  loss_mask: 9.034  loss_mask_0: 11.11  loss_mask_1: 8.774  loss_mask_2: 8.835  loss_mask_3: 8.906  loss_mask_4: 8.848  loss_mask_5: 8.863  loss_mask_6: 8.879  loss_mask_7: 9.056  loss_mask_8: 9.029  time: 2.5996  data_time: 0.0548  lr: 8.9286e-05  max_mem: 27639M
[01/29 03:14:18] d2.utils.events INFO:  eta: 1 day, 13:59:07  iter: 7119  total_loss: 107.5  loss_mask: 10.77  loss_mask_0: 12.4  loss_mask_1: 10.52  loss_mask_2: 10.5  loss_mask_3: 10.52  loss_mask_4: 10.52  loss_mask_5: 10.46  loss_mask_6: 10.42  loss_mask_7: 10.75  loss_mask_8: 10.7  time: 2.5997  data_time: 0.0524  lr: 8.9255e-05  max_mem: 27639M
[01/29 03:15:11] d2.utils.events INFO:  eta: 1 day, 13:59:13  iter: 7139  total_loss: 100.6  loss_mask: 10.07  loss_mask_0: 11.58  loss_mask_1: 9.739  loss_mask_2: 9.807  loss_mask_3: 9.818  loss_mask_4: 9.798  loss_mask_5: 9.906  loss_mask_6: 9.82  loss_mask_7: 10.03  loss_mask_8: 10.12  time: 2.5997  data_time: 0.0543  lr: 8.9225e-05  max_mem: 27639M
[01/29 03:16:03] d2.utils.events INFO:  eta: 1 day, 13:59:45  iter: 7159  total_loss: 93.88  loss_mask: 9.356  loss_mask_0: 10.69  loss_mask_1: 9.311  loss_mask_2: 9.269  loss_mask_3: 9.229  loss_mask_4: 9.256  loss_mask_5: 9.227  loss_mask_6: 9.239  loss_mask_7: 9.39  loss_mask_8: 9.325  time: 2.5998  data_time: 0.0591  lr: 8.9194e-05  max_mem: 27639M
[01/29 03:16:56] d2.utils.events INFO:  eta: 1 day, 13:59:48  iter: 7179  total_loss: 95.77  loss_mask: 9.569  loss_mask_0: 10.82  loss_mask_1: 9.381  loss_mask_2: 9.367  loss_mask_3: 9.348  loss_mask_4: 9.304  loss_mask_5: 9.321  loss_mask_6: 9.359  loss_mask_7: 9.545  loss_mask_8: 9.609  time: 2.5999  data_time: 0.0583  lr: 8.9164e-05  max_mem: 27639M
[01/29 03:17:49] d2.utils.events INFO:  eta: 1 day, 13:59:43  iter: 7199  total_loss: 95.6  loss_mask: 9.617  loss_mask_0: 11.09  loss_mask_1: 9.339  loss_mask_2: 9.245  loss_mask_3: 9.276  loss_mask_4: 9.263  loss_mask_5: 9.285  loss_mask_6: 9.324  loss_mask_7: 9.635  loss_mask_8: 9.6  time: 2.6000  data_time: 0.0655  lr: 8.9134e-05  max_mem: 27639M
[01/29 03:18:41] d2.utils.events INFO:  eta: 1 day, 13:59:45  iter: 7219  total_loss: 101.2  loss_mask: 10.03  loss_mask_0: 11.71  loss_mask_1: 9.822  loss_mask_2: 9.906  loss_mask_3: 9.821  loss_mask_4: 9.795  loss_mask_5: 9.794  loss_mask_6: 9.784  loss_mask_7: 9.979  loss_mask_8: 10.09  time: 2.6001  data_time: 0.0585  lr: 8.9103e-05  max_mem: 27639M
[01/29 03:19:34] d2.utils.events INFO:  eta: 1 day, 13:59:30  iter: 7239  total_loss: 104.6  loss_mask: 10.41  loss_mask_0: 11.52  loss_mask_1: 10.22  loss_mask_2: 10.25  loss_mask_3: 10.3  loss_mask_4: 10.27  loss_mask_5: 10.31  loss_mask_6: 10.25  loss_mask_7: 10.34  loss_mask_8: 10.37  time: 2.6001  data_time: 0.0543  lr: 8.9073e-05  max_mem: 27639M
[01/29 03:20:26] d2.utils.events INFO:  eta: 1 day, 13:58:47  iter: 7259  total_loss: 96.03  loss_mask: 9.632  loss_mask_0: 11.03  loss_mask_1: 9.271  loss_mask_2: 9.306  loss_mask_3: 9.372  loss_mask_4: 9.403  loss_mask_5: 9.372  loss_mask_6: 9.38  loss_mask_7: 9.561  loss_mask_8: 9.629  time: 2.6002  data_time: 0.0619  lr: 8.9043e-05  max_mem: 27639M
[01/29 03:21:19] d2.utils.events INFO:  eta: 1 day, 13:58:29  iter: 7279  total_loss: 101.9  loss_mask: 10.24  loss_mask_0: 11.42  loss_mask_1: 9.859  loss_mask_2: 9.959  loss_mask_3: 9.924  loss_mask_4: 9.976  loss_mask_5: 10  loss_mask_6: 10.01  loss_mask_7: 10.17  loss_mask_8: 10.18  time: 2.6002  data_time: 0.0536  lr: 8.9012e-05  max_mem: 27639M
[01/29 03:22:11] d2.utils.events INFO:  eta: 1 day, 13:58:25  iter: 7299  total_loss: 91.19  loss_mask: 9.149  loss_mask_0: 10.31  loss_mask_1: 8.936  loss_mask_2: 8.951  loss_mask_3: 8.91  loss_mask_4: 8.908  loss_mask_5: 8.899  loss_mask_6: 8.977  loss_mask_7: 9.166  loss_mask_8: 9.18  time: 2.6003  data_time: 0.0571  lr: 8.8982e-05  max_mem: 27639M
[01/29 03:23:04] d2.utils.events INFO:  eta: 1 day, 13:58:19  iter: 7319  total_loss: 99.02  loss_mask: 9.861  loss_mask_0: 11.23  loss_mask_1: 9.621  loss_mask_2: 9.626  loss_mask_3: 9.631  loss_mask_4: 9.667  loss_mask_5: 9.705  loss_mask_6: 9.685  loss_mask_7: 9.882  loss_mask_8: 9.872  time: 2.6003  data_time: 0.0612  lr: 8.8951e-05  max_mem: 27639M
[01/29 03:23:56] d2.utils.events INFO:  eta: 1 day, 13:58:08  iter: 7339  total_loss: 95.51  loss_mask: 9.574  loss_mask_0: 10.61  loss_mask_1: 9.343  loss_mask_2: 9.258  loss_mask_3: 9.292  loss_mask_4: 9.328  loss_mask_5: 9.301  loss_mask_6: 9.328  loss_mask_7: 9.563  loss_mask_8: 9.64  time: 2.6004  data_time: 0.0527  lr: 8.8921e-05  max_mem: 27639M
[01/29 03:24:49] d2.utils.events INFO:  eta: 1 day, 13:58:03  iter: 7359  total_loss: 92.65  loss_mask: 9.386  loss_mask_0: 10.9  loss_mask_1: 8.941  loss_mask_2: 8.883  loss_mask_3: 8.905  loss_mask_4: 9.016  loss_mask_5: 9.007  loss_mask_6: 9.272  loss_mask_7: 9.319  loss_mask_8: 9.299  time: 2.6004  data_time: 0.0568  lr: 8.8891e-05  max_mem: 27639M
[01/29 03:25:41] d2.utils.events INFO:  eta: 1 day, 13:58:07  iter: 7379  total_loss: 99.19  loss_mask: 9.981  loss_mask_0: 11.07  loss_mask_1: 9.541  loss_mask_2: 9.712  loss_mask_3: 9.726  loss_mask_4: 9.805  loss_mask_5: 9.892  loss_mask_6: 10.31  loss_mask_7: 9.952  loss_mask_8: 9.88  time: 2.6004  data_time: 0.0613  lr: 8.886e-05  max_mem: 27639M
[01/29 03:26:33] d2.utils.events INFO:  eta: 1 day, 13:57:50  iter: 7399  total_loss: 93.82  loss_mask: 9.289  loss_mask_0: 10.09  loss_mask_1: 9.105  loss_mask_2: 9.123  loss_mask_3: 9.153  loss_mask_4: 9.15  loss_mask_5: 9.232  loss_mask_6: 9.32  loss_mask_7: 9.302  loss_mask_8: 9.272  time: 2.6004  data_time: 0.0549  lr: 8.883e-05  max_mem: 27639M
[01/29 03:27:25] d2.utils.events INFO:  eta: 1 day, 13:57:40  iter: 7419  total_loss: 98.33  loss_mask: 9.853  loss_mask_0: 10.77  loss_mask_1: 9.568  loss_mask_2: 9.553  loss_mask_3: 9.631  loss_mask_4: 9.62  loss_mask_5: 9.644  loss_mask_6: 9.656  loss_mask_7: 9.873  loss_mask_8: 9.805  time: 2.6004  data_time: 0.0502  lr: 8.8799e-05  max_mem: 27639M
[01/29 03:28:17] d2.utils.events INFO:  eta: 1 day, 13:57:22  iter: 7439  total_loss: 87.41  loss_mask: 8.744  loss_mask_0: 9.987  loss_mask_1: 8.537  loss_mask_2: 8.513  loss_mask_3: 8.579  loss_mask_4: 8.547  loss_mask_5: 8.556  loss_mask_6: 8.584  loss_mask_7: 8.801  loss_mask_8: 8.821  time: 2.6005  data_time: 0.0634  lr: 8.8769e-05  max_mem: 27639M
[01/29 03:29:10] d2.utils.events INFO:  eta: 1 day, 13:57:11  iter: 7459  total_loss: 98.54  loss_mask: 9.833  loss_mask_0: 11.08  loss_mask_1: 9.517  loss_mask_2: 9.544  loss_mask_3: 9.535  loss_mask_4: 9.531  loss_mask_5: 9.542  loss_mask_6: 9.629  loss_mask_7: 9.841  loss_mask_8: 9.898  time: 2.6005  data_time: 0.0612  lr: 8.8739e-05  max_mem: 27639M
[01/29 03:30:02] d2.utils.events INFO:  eta: 1 day, 13:57:08  iter: 7479  total_loss: 92.4  loss_mask: 9.303  loss_mask_0: 10.21  loss_mask_1: 9.093  loss_mask_2: 9.005  loss_mask_3: 8.969  loss_mask_4: 8.96  loss_mask_5: 8.976  loss_mask_6: 9.013  loss_mask_7: 9.236  loss_mask_8: 9.248  time: 2.6006  data_time: 0.0554  lr: 8.8708e-05  max_mem: 27639M
[01/29 03:30:54] d2.utils.events INFO:  eta: 1 day, 13:56:32  iter: 7499  total_loss: 93.25  loss_mask: 9.325  loss_mask_0: 10.42  loss_mask_1: 9.158  loss_mask_2: 9.061  loss_mask_3: 9.061  loss_mask_4: 9.143  loss_mask_5: 9.133  loss_mask_6: 9.214  loss_mask_7: 9.334  loss_mask_8: 9.334  time: 2.6006  data_time: 0.0559  lr: 8.8678e-05  max_mem: 27639M
[01/29 03:31:46] d2.utils.events INFO:  eta: 1 day, 13:56:17  iter: 7519  total_loss: 95.91  loss_mask: 9.497  loss_mask_0: 10.92  loss_mask_1: 9.37  loss_mask_2: 9.412  loss_mask_3: 9.453  loss_mask_4: 9.409  loss_mask_5: 9.366  loss_mask_6: 9.39  loss_mask_7: 9.523  loss_mask_8: 9.511  time: 2.6006  data_time: 0.0493  lr: 8.8647e-05  max_mem: 27639M
[01/29 03:32:39] d2.utils.events INFO:  eta: 1 day, 13:56:09  iter: 7539  total_loss: 96.52  loss_mask: 9.735  loss_mask_0: 10.52  loss_mask_1: 9.378  loss_mask_2: 9.439  loss_mask_3: 9.436  loss_mask_4: 9.455  loss_mask_5: 9.462  loss_mask_6: 9.499  loss_mask_7: 9.701  loss_mask_8: 9.69  time: 2.6007  data_time: 0.0608  lr: 8.8617e-05  max_mem: 27639M
[01/29 03:33:31] d2.utils.events INFO:  eta: 1 day, 13:56:00  iter: 7559  total_loss: 90.52  loss_mask: 9.095  loss_mask_0: 10.23  loss_mask_1: 8.833  loss_mask_2: 8.832  loss_mask_3: 8.846  loss_mask_4: 8.877  loss_mask_5: 8.805  loss_mask_6: 8.921  loss_mask_7: 9.112  loss_mask_8: 9.141  time: 2.6007  data_time: 0.0556  lr: 8.8587e-05  max_mem: 27639M
[01/29 03:34:23] d2.utils.events INFO:  eta: 1 day, 13:56:01  iter: 7579  total_loss: 90.56  loss_mask: 9.049  loss_mask_0: 10.13  loss_mask_1: 8.885  loss_mask_2: 8.904  loss_mask_3: 8.929  loss_mask_4: 8.912  loss_mask_5: 8.917  loss_mask_6: 8.893  loss_mask_7: 9.11  loss_mask_8: 9.059  time: 2.6007  data_time: 0.0521  lr: 8.8556e-05  max_mem: 27639M
[01/29 03:35:16] d2.utils.events INFO:  eta: 1 day, 13:55:20  iter: 7599  total_loss: 86.61  loss_mask: 8.72  loss_mask_0: 9.9  loss_mask_1: 8.506  loss_mask_2: 8.483  loss_mask_3: 8.445  loss_mask_4: 8.434  loss_mask_5: 8.476  loss_mask_6: 8.492  loss_mask_7: 8.689  loss_mask_8: 8.707  time: 2.6007  data_time: 0.0610  lr: 8.8526e-05  max_mem: 27639M
[01/29 03:36:08] d2.utils.events INFO:  eta: 1 day, 13:54:36  iter: 7619  total_loss: 88.15  loss_mask: 8.873  loss_mask_0: 9.662  loss_mask_1: 8.743  loss_mask_2: 8.657  loss_mask_3: 8.756  loss_mask_4: 8.705  loss_mask_5: 8.724  loss_mask_6: 8.689  loss_mask_7: 8.821  loss_mask_8: 8.822  time: 2.6007  data_time: 0.0561  lr: 8.8495e-05  max_mem: 27639M
[01/29 03:37:00] d2.utils.events INFO:  eta: 1 day, 13:54:14  iter: 7639  total_loss: 88.1  loss_mask: 8.85  loss_mask_0: 9.946  loss_mask_1: 8.625  loss_mask_2: 8.566  loss_mask_3: 8.642  loss_mask_4: 8.654  loss_mask_5: 8.737  loss_mask_6: 8.755  loss_mask_7: 8.864  loss_mask_8: 8.857  time: 2.6007  data_time: 0.0535  lr: 8.8465e-05  max_mem: 27639M
[01/29 03:37:52] d2.utils.events INFO:  eta: 1 day, 13:53:42  iter: 7659  total_loss: 94.89  loss_mask: 9.513  loss_mask_0: 10.66  loss_mask_1: 9.247  loss_mask_2: 9.219  loss_mask_3: 9.267  loss_mask_4: 9.279  loss_mask_5: 9.305  loss_mask_6: 9.374  loss_mask_7: 9.53  loss_mask_8: 9.544  time: 2.6008  data_time: 0.0577  lr: 8.8434e-05  max_mem: 27639M
[01/29 03:38:45] d2.utils.events INFO:  eta: 1 day, 13:53:12  iter: 7679  total_loss: 88.41  loss_mask: 8.933  loss_mask_0: 10.16  loss_mask_1: 8.569  loss_mask_2: 8.597  loss_mask_3: 8.543  loss_mask_4: 8.534  loss_mask_5: 8.62  loss_mask_6: 8.644  loss_mask_7: 8.934  loss_mask_8: 8.983  time: 2.6008  data_time: 0.0566  lr: 8.8404e-05  max_mem: 27639M
[01/29 03:39:37] d2.utils.events INFO:  eta: 1 day, 13:52:22  iter: 7699  total_loss: 87.09  loss_mask: 8.697  loss_mask_0: 10.03  loss_mask_1: 8.593  loss_mask_2: 8.568  loss_mask_3: 8.551  loss_mask_4: 8.519  loss_mask_5: 8.54  loss_mask_6: 8.529  loss_mask_7: 8.707  loss_mask_8: 8.709  time: 2.6008  data_time: 0.0535  lr: 8.8374e-05  max_mem: 27639M
[01/29 03:40:29] d2.utils.events INFO:  eta: 1 day, 13:51:56  iter: 7719  total_loss: 93.65  loss_mask: 9.427  loss_mask_0: 10.7  loss_mask_1: 9.061  loss_mask_2: 9.105  loss_mask_3: 9.117  loss_mask_4: 9.112  loss_mask_5: 9.093  loss_mask_6: 9.075  loss_mask_7: 9.377  loss_mask_8: 9.344  time: 2.6008  data_time: 0.0567  lr: 8.8343e-05  max_mem: 27639M
[01/29 03:41:22] d2.utils.events INFO:  eta: 1 day, 13:50:52  iter: 7739  total_loss: 85  loss_mask: 8.479  loss_mask_0: 9.693  loss_mask_1: 8.264  loss_mask_2: 8.254  loss_mask_3: 8.291  loss_mask_4: 8.258  loss_mask_5: 8.236  loss_mask_6: 8.235  loss_mask_7: 8.487  loss_mask_8: 8.47  time: 2.6009  data_time: 0.0478  lr: 8.8313e-05  max_mem: 27639M
[01/29 03:42:14] d2.utils.events INFO:  eta: 1 day, 13:50:19  iter: 7759  total_loss: 89.01  loss_mask: 8.895  loss_mask_0: 10.14  loss_mask_1: 8.704  loss_mask_2: 8.682  loss_mask_3: 8.699  loss_mask_4: 8.688  loss_mask_5: 8.73  loss_mask_6: 8.688  loss_mask_7: 8.88  loss_mask_8: 8.897  time: 2.6009  data_time: 0.0565  lr: 8.8282e-05  max_mem: 27639M
[01/29 03:43:07] d2.utils.events INFO:  eta: 1 day, 13:50:01  iter: 7779  total_loss: 87.09  loss_mask: 8.739  loss_mask_0: 9.764  loss_mask_1: 8.566  loss_mask_2: 8.561  loss_mask_3: 8.553  loss_mask_4: 8.56  loss_mask_5: 8.548  loss_mask_6: 8.503  loss_mask_7: 8.716  loss_mask_8: 8.793  time: 2.6010  data_time: 0.0631  lr: 8.8252e-05  max_mem: 27639M
[01/29 03:43:59] d2.utils.events INFO:  eta: 1 day, 13:49:11  iter: 7799  total_loss: 90.43  loss_mask: 9.05  loss_mask_0: 10.17  loss_mask_1: 8.851  loss_mask_2: 8.841  loss_mask_3: 8.845  loss_mask_4: 8.879  loss_mask_5: 8.855  loss_mask_6: 8.842  loss_mask_7: 9.11  loss_mask_8: 9.056  time: 2.6010  data_time: 0.0595  lr: 8.8222e-05  max_mem: 27639M
[01/29 03:44:51] d2.utils.events INFO:  eta: 1 day, 13:48:53  iter: 7819  total_loss: 92.53  loss_mask: 9.231  loss_mask_0: 10.35  loss_mask_1: 8.978  loss_mask_2: 9.07  loss_mask_3: 9.084  loss_mask_4: 9.018  loss_mask_5: 9.028  loss_mask_6: 9.054  loss_mask_7: 9.234  loss_mask_8: 9.318  time: 2.6010  data_time: 0.0577  lr: 8.8191e-05  max_mem: 27639M
[01/29 03:45:43] d2.utils.events INFO:  eta: 1 day, 13:48:00  iter: 7839  total_loss: 85.19  loss_mask: 8.482  loss_mask_0: 9.249  loss_mask_1: 8.199  loss_mask_2: 8.297  loss_mask_3: 8.367  loss_mask_4: 8.33  loss_mask_5: 8.35  loss_mask_6: 8.361  loss_mask_7: 8.479  loss_mask_8: 8.491  time: 2.6010  data_time: 0.0571  lr: 8.8161e-05  max_mem: 27639M
[01/29 03:46:35] d2.utils.events INFO:  eta: 1 day, 13:47:07  iter: 7859  total_loss: 80.89  loss_mask: 8.147  loss_mask_0: 9.391  loss_mask_1: 7.919  loss_mask_2: 7.868  loss_mask_3: 7.879  loss_mask_4: 7.908  loss_mask_5: 7.884  loss_mask_6: 7.889  loss_mask_7: 8.117  loss_mask_8: 8.156  time: 2.6011  data_time: 0.0558  lr: 8.813e-05  max_mem: 27639M
[01/29 03:47:28] d2.utils.events INFO:  eta: 1 day, 13:46:36  iter: 7879  total_loss: 87.07  loss_mask: 8.734  loss_mask_0: 9.804  loss_mask_1: 8.58  loss_mask_2: 8.47  loss_mask_3: 8.487  loss_mask_4: 8.528  loss_mask_5: 8.507  loss_mask_6: 8.538  loss_mask_7: 8.714  loss_mask_8: 8.655  time: 2.6011  data_time: 0.0517  lr: 8.81e-05  max_mem: 27639M
[01/29 03:48:20] d2.utils.events INFO:  eta: 1 day, 13:45:43  iter: 7899  total_loss: 87.73  loss_mask: 8.863  loss_mask_0: 10.34  loss_mask_1: 8.395  loss_mask_2: 8.427  loss_mask_3: 8.393  loss_mask_4: 8.415  loss_mask_5: 8.418  loss_mask_6: 8.46  loss_mask_7: 8.879  loss_mask_8: 8.865  time: 2.6011  data_time: 0.0561  lr: 8.8069e-05  max_mem: 27639M
[01/29 03:49:13] d2.utils.events INFO:  eta: 1 day, 13:45:58  iter: 7919  total_loss: 83.88  loss_mask: 8.44  loss_mask_0: 9.555  loss_mask_1: 8.136  loss_mask_2: 8.173  loss_mask_3: 8.163  loss_mask_4: 8.181  loss_mask_5: 8.154  loss_mask_6: 8.141  loss_mask_7: 8.433  loss_mask_8: 8.445  time: 2.6012  data_time: 0.0603  lr: 8.8039e-05  max_mem: 27639M
[01/29 03:50:05] d2.utils.events INFO:  eta: 1 day, 13:45:10  iter: 7939  total_loss: 80.74  loss_mask: 8.076  loss_mask_0: 9.055  loss_mask_1: 7.856  loss_mask_2: 7.858  loss_mask_3: 7.874  loss_mask_4: 7.86  loss_mask_5: 7.894  loss_mask_6: 7.893  loss_mask_7: 8.141  loss_mask_8: 8.138  time: 2.6012  data_time: 0.0590  lr: 8.8009e-05  max_mem: 27639M
[01/29 03:50:57] d2.utils.events INFO:  eta: 1 day, 13:44:08  iter: 7959  total_loss: 83.43  loss_mask: 8.346  loss_mask_0: 9.436  loss_mask_1: 8.145  loss_mask_2: 8.188  loss_mask_3: 8.148  loss_mask_4: 8.143  loss_mask_5: 8.171  loss_mask_6: 8.151  loss_mask_7: 8.316  loss_mask_8: 8.281  time: 2.6012  data_time: 0.0549  lr: 8.7978e-05  max_mem: 27639M
[01/29 03:51:50] d2.utils.events INFO:  eta: 1 day, 13:43:35  iter: 7979  total_loss: 82.92  loss_mask: 8.277  loss_mask_0: 9.239  loss_mask_1: 8.069  loss_mask_2: 8.068  loss_mask_3: 8.091  loss_mask_4: 8.078  loss_mask_5: 8.099  loss_mask_6: 8.106  loss_mask_7: 8.268  loss_mask_8: 8.298  time: 2.6013  data_time: 0.0567  lr: 8.7948e-05  max_mem: 27639M
[01/29 03:52:42] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 03:52:43] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 03:52:43] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 04:07:02] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 7.200418416428675, 'error_1pix': 0.7197184993148823, 'error_3pix': 0.4814095395037085, 'mIoU': 2.7871339213102857, 'fwIoU': 5.2307399960202545, 'IoU-0': 0.0004575073742046641, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.027780456371620254, 'IoU-7': 0.11423858149321661, 'IoU-8': 0.8706736050976573, 'IoU-9': 3.8881645121633204, 'IoU-10': 5.983052524004426, 'IoU-11': 9.51994972469996, 'IoU-12': 9.355455964126222, 'IoU-13': 8.844922051525353, 'IoU-14': 9.335317069020013, 'IoU-15': 8.692507268279451, 'IoU-16': 8.343446003886735, 'IoU-17': 6.941073242661059, 'IoU-18': 7.15244150662824, 'IoU-19': 7.092897403120835, 'IoU-20': 6.898177533030887, 'IoU-21': 6.80141261598248, 'IoU-22': 7.048722606106933, 'IoU-23': 6.7063402758649495, 'IoU-24': 7.3267925105702805, 'IoU-25': 7.4225296043118325, 'IoU-26': 7.498199494629063, 'IoU-27': 7.746108667527353, 'IoU-28': 7.714498761709529, 'IoU-29': 7.935868255662179, 'IoU-30': 7.972705159950803, 'IoU-31': 8.30389468729688, 'IoU-32': 8.129112519515317, 'IoU-33': 7.531043983828857, 'IoU-34': 7.139040935074725, 'IoU-35': 7.181942372653265, 'IoU-36': 7.1424685819534455, 'IoU-37': 6.793745453425025, 'IoU-38': 6.8892519395575915, 'IoU-39': 7.020622692918731, 'IoU-40': 7.163798171594625, 'IoU-41': 6.719673358176112, 'IoU-42': 6.556927037569459, 'IoU-43': 6.163601285164627, 'IoU-44': 5.892351210158424, 'IoU-45': 5.828153014122854, 'IoU-46': 5.629767204234998, 'IoU-47': 5.6115968348154786, 'IoU-48': 5.511212778648665, 'IoU-49': 5.114856789412951, 'IoU-50': 4.976414253801604, 'IoU-51': 4.872029316120667, 'IoU-52': 4.8105754662944, 'IoU-53': 4.899376555957472, 'IoU-54': 4.849289993981831, 'IoU-55': 4.767500120371534, 'IoU-56': 4.4990969709789805, 'IoU-57': 4.464081732261419, 'IoU-58': 4.153116688457995, 'IoU-59': 3.9060194354401583, 'IoU-60': 3.7935823239577697, 'IoU-61': 3.4976075238401725, 'IoU-62': 3.4046172004695077, 'IoU-63': 3.183406440084844, 'IoU-64': 3.1063930585724404, 'IoU-65': 3.009102508217699, 'IoU-66': 2.915207859016622, 'IoU-67': 2.86130529562125, 'IoU-68': 2.8289201995549353, 'IoU-69': 2.8212163806007178, 'IoU-70': 2.855627259342326, 'IoU-71': 2.7085778663950286, 'IoU-72': 2.6919822673478166, 'IoU-73': 2.5788432712426994, 'IoU-74': 2.6796900964834545, 'IoU-75': 2.6464248085491344, 'IoU-76': 2.582493326596113, 'IoU-77': 2.435445812581823, 'IoU-78': 2.5697986131589774, 'IoU-79': 2.519849412194283, 'IoU-80': 2.502856237645987, 'IoU-81': 2.53892664070909, 'IoU-82': 2.454231802187443, 'IoU-83': 2.4693253136279765, 'IoU-84': 2.5625045471372374, 'IoU-85': 2.5636331130747014, 'IoU-86': 2.4960103462350203, 'IoU-87': 2.44601026952843, 'IoU-88': 2.4993781087164626, 'IoU-89': 2.5391916396166208, 'IoU-90': 2.40564893934247, 'IoU-91': 2.395285447417868, 'IoU-92': 2.447548698248815, 'IoU-93': 2.4745600783773214, 'IoU-94': 2.511270675928024, 'IoU-95': 2.511009326631364, 'IoU-96': 2.319485888572687, 'IoU-97': 2.374914530238829, 'IoU-98': 2.4052384946286836, 'IoU-99': 2.276067607409116, 'IoU-100': 2.024198075761202, 'IoU-101': 2.0601617582565868, 'IoU-102': 2.2547087908363093, 'IoU-103': 2.1157282279641336, 'IoU-104': 2.0008278713681484, 'IoU-105': 1.9057996565472606, 'IoU-106': 1.916744340141291, 'IoU-107': 1.9216011891770024, 'IoU-108': 1.9026954512679204, 'IoU-109': 1.640367713910496, 'IoU-110': 1.787866877201286, 'IoU-111': 1.71782997116434, 'IoU-112': 1.7638610124531267, 'IoU-113': 1.7767509677125048, 'IoU-114': 1.840440417324467, 'IoU-115': 1.6789091667278124, 'IoU-116': 1.7499434041589859, 'IoU-117': 1.6458891235517765, 'IoU-118': 1.7372253343204556, 'IoU-119': 1.805616031367392, 'IoU-120': 1.6228422274858705, 'IoU-121': 1.630812495135857, 'IoU-122': 1.5319010033647924, 'IoU-123': 1.4376936929780906, 'IoU-124': 1.3576663930978536, 'IoU-125': 1.4815516032572082, 'IoU-126': 1.4190823196864693, 'IoU-127': 1.3281859313148967, 'IoU-128': 1.304055353512403, 'IoU-129': 1.2758824269866906, 'IoU-130': 1.195629452202075, 'IoU-131': 1.1973643770022604, 'IoU-132': 1.1460420602963357, 'IoU-133': 1.2761351764543494, 'IoU-134': 1.273547002235672, 'IoU-135': 1.2067172478692803, 'IoU-136': 1.1862103470870322, 'IoU-137': 1.3065384716421047, 'IoU-138': 1.1269095677878311, 'IoU-139': 1.1726502964532028, 'IoU-140': 1.1029608629998455, 'IoU-141': 1.0501671664291259, 'IoU-142': 1.014039233849339, 'IoU-143': 1.0035986359097389, 'IoU-144': 1.1391747146067557, 'IoU-145': 1.1584667796048114, 'IoU-146': 1.1723899113214233, 'IoU-147': 0.9835035596017606, 'IoU-148': 1.0666982451675866, 'IoU-149': 1.0158916475400959, 'IoU-150': 0.9161175465097608, 'IoU-151': 0.849371400851852, 'IoU-152': 0.964469844157297, 'IoU-153': 0.9072837971987799, 'IoU-154': 0.8342313793746324, 'IoU-155': 0.8518511220602891, 'IoU-156': 0.8392175370447683, 'IoU-157': 1.0522462285780327, 'IoU-158': 0.691565056559235, 'IoU-159': 0.6454481294129718, 'IoU-160': 0.5897922249448697, 'IoU-161': 0.8896504389047724, 'IoU-162': 0.528334465270635, 'IoU-163': 0.7976001329462981, 'IoU-164': 0.8634146300057803, 'IoU-165': 0.8038545643751626, 'IoU-166': 0.5743089343750838, 'IoU-167': 0.41404198924686086, 'IoU-168': 0.5950580735137528, 'IoU-169': 0.7671832251819807, 'IoU-170': 0.2882430185426856, 'IoU-171': 0.24566595825713813, 'IoU-172': 0.29081418352394967, 'IoU-173': 0.09894407846455368, 'IoU-174': 0.07748042784657118, 'IoU-175': 0.11141728408947124, 'IoU-176': 0.13490088389255986, 'IoU-177': 0.09489773613808865, 'IoU-178': 0.03926410015365855, 'IoU-179': 0.03700037000370004, 'IoU-180': 0.03117709216073988, 'IoU-181': 0.021624060998655548, 'IoU-182': 0.0011781976874335792, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.00024159783141786522, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 5.56225338313407, 'pACC': 9.890830551606285, 'ACC-0': 0.00045751202170995353, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 7.931194456373084, 'ACC-7': 6.567706225319142, 'ACC-8': 10.022685708003957, 'ACC-9': 15.312528377554443, 'ACC-10': 14.06887015589173, 'ACC-11': 15.36748331429066, 'ACC-12': 14.465184767449262, 'ACC-13': 13.991463617732844, 'ACC-14': 15.59189704004914, 'ACC-15': 15.757124739392763, 'ACC-16': 15.692765924293326, 'ACC-17': 14.091985976689802, 'ACC-18': 13.611142989793235, 'ACC-19': 13.098115010957073, 'ACC-20': 12.602902770168809, 'ACC-21': 12.21170327764614, 'ACC-22': 12.399266770437546, 'ACC-23': 12.75124938142041, 'ACC-24': 14.560266996125524, 'ACC-25': 15.081199892422282, 'ACC-26': 15.189613896590547, 'ACC-27': 15.142016050200366, 'ACC-28': 15.404295577741669, 'ACC-29': 15.368988295302039, 'ACC-30': 15.740950924727878, 'ACC-31': 16.01187373586831, 'ACC-32': 15.80734139498967, 'ACC-33': 14.842653613714193, 'ACC-34': 13.900971099911812, 'ACC-35': 13.476172100185051, 'ACC-36': 13.17205267534242, 'ACC-37': 12.763920897889536, 'ACC-38': 12.963242873247353, 'ACC-39': 13.304868825218099, 'ACC-40': 13.633845767778318, 'ACC-41': 13.293801399930633, 'ACC-42': 12.933757957865536, 'ACC-43': 12.013693324164063, 'ACC-44': 11.11140907336162, 'ACC-45': 11.068171903131399, 'ACC-46': 10.959545350729732, 'ACC-47': 10.912164633264464, 'ACC-48': 10.725693325540007, 'ACC-49': 9.868412659114178, 'ACC-50': 9.57461217301506, 'ACC-51': 9.479480019998302, 'ACC-52': 9.397110377597116, 'ACC-53': 9.598506572111196, 'ACC-54': 9.468329147777892, 'ACC-55': 9.351304063172478, 'ACC-56': 8.897247330109955, 'ACC-57': 8.650518560348914, 'ACC-58': 8.128381746210518, 'ACC-59': 7.74533469950746, 'ACC-60': 7.5548528022931, 'ACC-61': 7.023512289520919, 'ACC-62': 6.845955165111254, 'ACC-63': 6.427207241904948, 'ACC-64': 6.235186417333635, 'ACC-65': 6.065017481194547, 'ACC-66': 5.911760725845257, 'ACC-67': 5.855216841034309, 'ACC-68': 5.768951340309965, 'ACC-69': 5.633585456007544, 'ACC-70': 5.650328997114789, 'ACC-71': 5.4293963251699235, 'ACC-72': 5.396958609181548, 'ACC-73': 5.133755036862964, 'ACC-74': 5.266164336692306, 'ACC-75': 5.1607608718204645, 'ACC-76': 4.907248664405338, 'ACC-77': 4.637615250748907, 'ACC-78': 4.889986696313235, 'ACC-79': 4.808672359832495, 'ACC-80': 4.734712626493783, 'ACC-81': 4.772995965726961, 'ACC-82': 4.621849874065845, 'ACC-83': 4.602975666658023, 'ACC-84': 4.797645188909215, 'ACC-85': 4.824043630601738, 'ACC-86': 4.709997730327309, 'ACC-87': 4.646766286022459, 'ACC-88': 4.775951473811297, 'ACC-89': 4.861013857548862, 'ACC-90': 4.590453769532349, 'ACC-91': 4.599824570045566, 'ACC-92': 4.738752735730723, 'ACC-93': 4.79266743479695, 'ACC-94': 4.887015236552155, 'ACC-95': 4.910897821317157, 'ACC-96': 4.585279046054127, 'ACC-97': 4.661564308765074, 'ACC-98': 4.75473078327751, 'ACC-99': 4.549111505877398, 'ACC-100': 4.067215830716046, 'ACC-101': 4.200304906947068, 'ACC-102': 4.671681014952424, 'ACC-103': 4.40275809955606, 'ACC-104': 4.138117606551733, 'ACC-105': 3.9147491630169036, 'ACC-106': 3.901941950477995, 'ACC-107': 3.8525743117110296, 'ACC-108': 3.7425378486286998, 'ACC-109': 3.222359716676376, 'ACC-110': 3.5623300109088096, 'ACC-111': 3.424414761941921, 'ACC-112': 3.5755492516377623, 'ACC-113': 3.6197530607326343, 'ACC-114': 3.781563901126714, 'ACC-115': 3.4745087426518126, 'ACC-116': 3.61532390805718, 'ACC-117': 3.370094838414661, 'ACC-118': 3.5793385976469723, 'ACC-119': 3.7029650397999263, 'ACC-120': 3.3022696844790684, 'ACC-121': 3.2645856904916224, 'ACC-122': 3.0464113523356637, 'ACC-123': 2.8578322336673447, 'ACC-124': 2.7478542710275047, 'ACC-125': 2.996096210093293, 'ACC-126': 2.8902813322525707, 'ACC-127': 2.7412445930302507, 'ACC-128': 2.758110529326459, 'ACC-129': 2.709595314638492, 'ACC-130': 2.574727261939465, 'ACC-131': 2.586473300888608, 'ACC-132': 2.4179911733067927, 'ACC-133': 2.654677580681377, 'ACC-134': 2.6691253769926755, 'ACC-135': 2.5732569408813637, 'ACC-136': 2.547434075661573, 'ACC-137': 2.847009312197903, 'ACC-138': 2.479011726781227, 'ACC-139': 2.5929020055699805, 'ACC-140': 2.388406574930386, 'ACC-141': 2.2558694177625105, 'ACC-142': 2.2370880128552217, 'ACC-143': 2.297518180748041, 'ACC-144': 2.615072202166065, 'ACC-145': 2.618573760593931, 'ACC-146': 2.623654931347239, 'ACC-147': 2.2121983355354726, 'ACC-148': 2.4145217294598833, 'ACC-149': 2.3592669478505055, 'ACC-150': 2.0993175993087396, 'ACC-151': 1.9706208041710231, 'ACC-152': 2.216729044439949, 'ACC-153': 2.1612021107019186, 'ACC-154': 2.0333088323356807, 'ACC-155': 2.0248334208443954, 'ACC-156': 1.972373583612894, 'ACC-157': 2.515471606692499, 'ACC-158': 1.6522452159407015, 'ACC-159': 1.4715597682931325, 'ACC-160': 1.2652411437361444, 'ACC-161': 1.814635598480104, 'ACC-162': 1.079734960621956, 'ACC-163': 1.570088371929492, 'ACC-164': 1.6127651343389597, 'ACC-165': 1.4525437780114159, 'ACC-166': 1.0074623733537031, 'ACC-167': 0.6859868639334893, 'ACC-168': 0.9167311343976369, 'ACC-169': 1.0903801239881872, 'ACC-170': 0.37746496869542995, 'ACC-171': 0.31042837278590174, 'ACC-172': 0.3359632551765011, 'ACC-173': 0.10780687329964289, 'ACC-174': 0.08220235199382644, 'ACC-175': 0.11721660482289015, 'ACC-176': 0.14257339536908553, 'ACC-177': 0.09854780398952515, 'ACC-178': 0.040176855427062584, 'ACC-179': 0.03753441500078113, 'ACC-180': 0.031536794337769646, 'ACC-181': 0.02179160123264666, 'ACC-182': 0.0011845842938337649, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.00024160717090083232, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 04:07:02] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 04:07:02] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 04:07:02] d2.evaluation.testing INFO: copypaste: 7.2004,0.7197,0.4814,2.7871,5.2307,5.5623,9.8908
[01/29 04:07:03] d2.utils.events INFO:  eta: 1 day, 13:42:37  iter: 7999  total_loss: 82.27  loss_mask: 8.13  loss_mask_0: 9.261  loss_mask_1: 8.137  loss_mask_2: 8.115  loss_mask_3: 8.14  loss_mask_4: 8.118  loss_mask_5: 8.158  loss_mask_6: 8.141  loss_mask_7: 8.136  loss_mask_8: 8.176  time: 2.6013  data_time: 0.0614  lr: 8.7917e-05  max_mem: 27639M
[01/29 04:07:55] d2.utils.events INFO:  eta: 1 day, 13:41:28  iter: 8019  total_loss: 80.78  loss_mask: 8.086  loss_mask_0: 9.361  loss_mask_1: 7.823  loss_mask_2: 7.884  loss_mask_3: 7.831  loss_mask_4: 7.84  loss_mask_5: 7.798  loss_mask_6: 7.825  loss_mask_7: 8.087  loss_mask_8: 8.11  time: 2.6013  data_time: 0.0621  lr: 8.7887e-05  max_mem: 27639M
[01/29 04:08:48] d2.utils.events INFO:  eta: 1 day, 13:40:44  iter: 8039  total_loss: 85.34  loss_mask: 8.52  loss_mask_0: 9.655  loss_mask_1: 8.342  loss_mask_2: 8.298  loss_mask_3: 8.306  loss_mask_4: 8.32  loss_mask_5: 8.34  loss_mask_6: 8.334  loss_mask_7: 8.537  loss_mask_8: 8.494  time: 2.6014  data_time: 0.0616  lr: 8.7856e-05  max_mem: 27639M
[01/29 04:09:41] d2.utils.events INFO:  eta: 1 day, 13:40:40  iter: 8059  total_loss: 81.49  loss_mask: 8.189  loss_mask_0: 9.395  loss_mask_1: 7.902  loss_mask_2: 7.885  loss_mask_3: 7.937  loss_mask_4: 7.969  loss_mask_5: 8.011  loss_mask_6: 7.933  loss_mask_7: 8.198  loss_mask_8: 8.219  time: 2.6015  data_time: 0.0568  lr: 8.7826e-05  max_mem: 27639M
[01/29 04:10:33] d2.utils.events INFO:  eta: 1 day, 13:40:06  iter: 8079  total_loss: 86.21  loss_mask: 8.616  loss_mask_0: 9.749  loss_mask_1: 8.342  loss_mask_2: 8.305  loss_mask_3: 8.317  loss_mask_4: 8.351  loss_mask_5: 8.351  loss_mask_6: 8.312  loss_mask_7: 8.645  loss_mask_8: 8.644  time: 2.6015  data_time: 0.0546  lr: 8.7796e-05  max_mem: 27639M
[01/29 04:11:26] d2.utils.events INFO:  eta: 1 day, 13:39:14  iter: 8099  total_loss: 80.6  loss_mask: 8.033  loss_mask_0: 9.254  loss_mask_1: 7.908  loss_mask_2: 7.916  loss_mask_3: 7.949  loss_mask_4: 7.923  loss_mask_5: 7.906  loss_mask_6: 7.924  loss_mask_7: 8.046  loss_mask_8: 8.101  time: 2.6016  data_time: 0.0568  lr: 8.7765e-05  max_mem: 27639M
[01/29 04:12:19] d2.utils.events INFO:  eta: 1 day, 13:38:34  iter: 8119  total_loss: 79.61  loss_mask: 7.965  loss_mask_0: 9.018  loss_mask_1: 7.874  loss_mask_2: 7.794  loss_mask_3: 7.774  loss_mask_4: 7.782  loss_mask_5: 7.832  loss_mask_6: 7.818  loss_mask_7: 7.98  loss_mask_8: 7.981  time: 2.6017  data_time: 0.0572  lr: 8.7735e-05  max_mem: 27639M
[01/29 04:13:11] d2.utils.events INFO:  eta: 1 day, 13:37:43  iter: 8139  total_loss: 84.44  loss_mask: 8.472  loss_mask_0: 9.431  loss_mask_1: 8.256  loss_mask_2: 8.259  loss_mask_3: 8.262  loss_mask_4: 8.231  loss_mask_5: 8.257  loss_mask_6: 8.258  loss_mask_7: 8.516  loss_mask_8: 8.483  time: 2.6018  data_time: 0.0586  lr: 8.7704e-05  max_mem: 27639M
[01/29 04:14:04] d2.utils.events INFO:  eta: 1 day, 13:37:01  iter: 8159  total_loss: 85.92  loss_mask: 8.619  loss_mask_0: 9.627  loss_mask_1: 8.401  loss_mask_2: 8.339  loss_mask_3: 8.376  loss_mask_4: 8.372  loss_mask_5: 8.426  loss_mask_6: 8.441  loss_mask_7: 8.666  loss_mask_8: 8.649  time: 2.6018  data_time: 0.0580  lr: 8.7674e-05  max_mem: 27639M
[01/29 04:14:56] d2.utils.events INFO:  eta: 1 day, 13:35:59  iter: 8179  total_loss: 78.75  loss_mask: 7.977  loss_mask_0: 9.408  loss_mask_1: 7.642  loss_mask_2: 7.658  loss_mask_3: 7.639  loss_mask_4: 7.633  loss_mask_5: 7.665  loss_mask_6: 7.658  loss_mask_7: 7.982  loss_mask_8: 7.973  time: 2.6019  data_time: 0.0634  lr: 8.7643e-05  max_mem: 27639M
[01/29 04:15:49] d2.utils.events INFO:  eta: 1 day, 13:34:59  iter: 8199  total_loss: 76.19  loss_mask: 7.636  loss_mask_0: 8.854  loss_mask_1: 7.36  loss_mask_2: 7.363  loss_mask_3: 7.427  loss_mask_4: 7.396  loss_mask_5: 7.383  loss_mask_6: 7.438  loss_mask_7: 7.638  loss_mask_8: 7.645  time: 2.6019  data_time: 0.0538  lr: 8.7613e-05  max_mem: 27639M
[01/29 04:16:41] d2.utils.events INFO:  eta: 1 day, 13:34:00  iter: 8219  total_loss: 85.43  loss_mask: 8.555  loss_mask_0: 9.608  loss_mask_1: 8.383  loss_mask_2: 8.325  loss_mask_3: 8.321  loss_mask_4: 8.331  loss_mask_5: 8.366  loss_mask_6: 8.309  loss_mask_7: 8.545  loss_mask_8: 8.581  time: 2.6019  data_time: 0.0596  lr: 8.7582e-05  max_mem: 27639M
[01/29 04:17:34] d2.utils.events INFO:  eta: 1 day, 13:32:55  iter: 8239  total_loss: 77.66  loss_mask: 7.801  loss_mask_0: 8.96  loss_mask_1: 7.566  loss_mask_2: 7.581  loss_mask_3: 7.53  loss_mask_4: 7.557  loss_mask_5: 7.538  loss_mask_6: 7.531  loss_mask_7: 7.83  loss_mask_8: 7.829  time: 2.6020  data_time: 0.0663  lr: 8.7552e-05  max_mem: 27639M
[01/29 04:18:26] d2.utils.events INFO:  eta: 1 day, 13:32:12  iter: 8259  total_loss: 77.61  loss_mask: 7.799  loss_mask_0: 8.822  loss_mask_1: 7.558  loss_mask_2: 7.529  loss_mask_3: 7.534  loss_mask_4: 7.638  loss_mask_5: 7.618  loss_mask_6: 7.639  loss_mask_7: 7.811  loss_mask_8: 7.78  time: 2.6020  data_time: 0.0512  lr: 8.7522e-05  max_mem: 27639M
[01/29 04:19:19] d2.utils.events INFO:  eta: 1 day, 13:31:22  iter: 8279  total_loss: 83.26  loss_mask: 8.389  loss_mask_0: 9.51  loss_mask_1: 8.224  loss_mask_2: 8.193  loss_mask_3: 8.198  loss_mask_4: 8.272  loss_mask_5: 8.195  loss_mask_6: 8.166  loss_mask_7: 8.384  loss_mask_8: 8.373  time: 2.6021  data_time: 0.0587  lr: 8.7491e-05  max_mem: 27639M
[01/29 04:20:12] d2.utils.events INFO:  eta: 1 day, 13:30:42  iter: 8299  total_loss: 86.15  loss_mask: 8.71  loss_mask_0: 9.418  loss_mask_1: 8.379  loss_mask_2: 8.465  loss_mask_3: 8.38  loss_mask_4: 8.393  loss_mask_5: 8.432  loss_mask_6: 8.425  loss_mask_7: 8.696  loss_mask_8: 8.759  time: 2.6021  data_time: 0.0588  lr: 8.7461e-05  max_mem: 27639M
[01/29 04:21:04] d2.utils.events INFO:  eta: 1 day, 13:29:45  iter: 8319  total_loss: 73.72  loss_mask: 7.454  loss_mask_0: 8.663  loss_mask_1: 7.113  loss_mask_2: 7.133  loss_mask_3: 7.073  loss_mask_4: 7.095  loss_mask_5: 7.138  loss_mask_6: 7.173  loss_mask_7: 7.457  loss_mask_8: 7.474  time: 2.6022  data_time: 0.0564  lr: 8.743e-05  max_mem: 27639M
[01/29 04:21:56] d2.utils.events INFO:  eta: 1 day, 13:28:39  iter: 8339  total_loss: 79.69  loss_mask: 8.026  loss_mask_0: 8.906  loss_mask_1: 7.8  loss_mask_2: 7.785  loss_mask_3: 7.811  loss_mask_4: 7.808  loss_mask_5: 7.802  loss_mask_6: 7.781  loss_mask_7: 8.053  loss_mask_8: 8.063  time: 2.6022  data_time: 0.0594  lr: 8.74e-05  max_mem: 27639M
[01/29 04:22:49] d2.utils.events INFO:  eta: 1 day, 13:27:53  iter: 8359  total_loss: 81.95  loss_mask: 8.157  loss_mask_0: 9.562  loss_mask_1: 7.988  loss_mask_2: 7.965  loss_mask_3: 7.994  loss_mask_4: 8.004  loss_mask_5: 7.928  loss_mask_6: 7.932  loss_mask_7: 8.256  loss_mask_8: 8.174  time: 2.6023  data_time: 0.0486  lr: 8.7369e-05  max_mem: 27639M
[01/29 04:23:41] d2.utils.events INFO:  eta: 1 day, 13:27:16  iter: 8379  total_loss: 80.01  loss_mask: 8.01  loss_mask_0: 8.993  loss_mask_1: 7.863  loss_mask_2: 7.827  loss_mask_3: 7.841  loss_mask_4: 7.816  loss_mask_5: 7.81  loss_mask_6: 7.84  loss_mask_7: 8.019  loss_mask_8: 8.011  time: 2.6023  data_time: 0.0562  lr: 8.7339e-05  max_mem: 27639M
[01/29 04:24:34] d2.utils.events INFO:  eta: 1 day, 13:26:28  iter: 8399  total_loss: 85.81  loss_mask: 8.637  loss_mask_0: 9.423  loss_mask_1: 8.398  loss_mask_2: 8.353  loss_mask_3: 8.374  loss_mask_4: 8.394  loss_mask_5: 8.377  loss_mask_6: 8.39  loss_mask_7: 8.571  loss_mask_8: 8.594  time: 2.6024  data_time: 0.0595  lr: 8.7308e-05  max_mem: 27639M
[01/29 04:25:27] d2.utils.events INFO:  eta: 1 day, 13:26:24  iter: 8419  total_loss: 85.28  loss_mask: 8.491  loss_mask_0: 9.457  loss_mask_1: 8.248  loss_mask_2: 8.273  loss_mask_3: 8.324  loss_mask_4: 8.318  loss_mask_5: 8.28  loss_mask_6: 8.281  loss_mask_7: 8.495  loss_mask_8: 8.477  time: 2.6025  data_time: 0.0541  lr: 8.7278e-05  max_mem: 27639M
[01/29 04:26:19] d2.utils.events INFO:  eta: 1 day, 13:25:31  iter: 8439  total_loss: 78.33  loss_mask: 7.844  loss_mask_0: 8.902  loss_mask_1: 7.564  loss_mask_2: 7.637  loss_mask_3: 7.582  loss_mask_4: 7.606  loss_mask_5: 7.591  loss_mask_6: 7.604  loss_mask_7: 7.87  loss_mask_8: 7.826  time: 2.6025  data_time: 0.0594  lr: 8.7248e-05  max_mem: 27639M
[01/29 04:27:12] d2.utils.events INFO:  eta: 1 day, 13:25:19  iter: 8459  total_loss: 75.67  loss_mask: 7.614  loss_mask_0: 9.038  loss_mask_1: 7.289  loss_mask_2: 7.31  loss_mask_3: 7.309  loss_mask_4: 7.288  loss_mask_5: 7.254  loss_mask_6: 7.292  loss_mask_7: 7.592  loss_mask_8: 7.586  time: 2.6026  data_time: 0.0654  lr: 8.7217e-05  max_mem: 27639M
[01/29 04:28:05] d2.utils.events INFO:  eta: 1 day, 13:24:50  iter: 8479  total_loss: 78.07  loss_mask: 7.814  loss_mask_0: 8.73  loss_mask_1: 7.753  loss_mask_2: 7.704  loss_mask_3: 7.674  loss_mask_4: 7.674  loss_mask_5: 7.672  loss_mask_6: 7.697  loss_mask_7: 7.805  loss_mask_8: 7.825  time: 2.6026  data_time: 0.0542  lr: 8.7187e-05  max_mem: 27639M
[01/29 04:28:57] d2.utils.events INFO:  eta: 1 day, 13:23:49  iter: 8499  total_loss: 74.63  loss_mask: 7.513  loss_mask_0: 8.867  loss_mask_1: 7.31  loss_mask_2: 7.264  loss_mask_3: 7.259  loss_mask_4: 7.303  loss_mask_5: 7.263  loss_mask_6: 7.294  loss_mask_7: 7.506  loss_mask_8: 7.475  time: 2.6027  data_time: 0.0599  lr: 8.7156e-05  max_mem: 27639M
[01/29 04:29:49] d2.utils.events INFO:  eta: 1 day, 13:23:05  iter: 8519  total_loss: 81.59  loss_mask: 8.151  loss_mask_0: 8.968  loss_mask_1: 8.018  loss_mask_2: 7.933  loss_mask_3: 7.945  loss_mask_4: 7.911  loss_mask_5: 7.928  loss_mask_6: 7.936  loss_mask_7: 8.181  loss_mask_8: 8.166  time: 2.6027  data_time: 0.0626  lr: 8.7126e-05  max_mem: 27639M
[01/29 04:30:42] d2.utils.events INFO:  eta: 1 day, 13:21:55  iter: 8539  total_loss: 78.97  loss_mask: 7.909  loss_mask_0: 9.111  loss_mask_1: 7.662  loss_mask_2: 7.655  loss_mask_3: 7.669  loss_mask_4: 7.708  loss_mask_5: 7.658  loss_mask_6: 7.715  loss_mask_7: 7.938  loss_mask_8: 7.928  time: 2.6027  data_time: 0.0560  lr: 8.7095e-05  max_mem: 27639M
[01/29 04:31:34] d2.utils.events INFO:  eta: 1 day, 13:21:36  iter: 8559  total_loss: 82.09  loss_mask: 8.185  loss_mask_0: 8.884  loss_mask_1: 8.02  loss_mask_2: 8.029  loss_mask_3: 8.049  loss_mask_4: 8.055  loss_mask_5: 8.041  loss_mask_6: 8.03  loss_mask_7: 8.204  loss_mask_8: 8.205  time: 2.6028  data_time: 0.0619  lr: 8.7065e-05  max_mem: 27639M
[01/29 04:32:27] d2.utils.events INFO:  eta: 1 day, 13:21:16  iter: 8579  total_loss: 77.75  loss_mask: 7.772  loss_mask_0: 8.998  loss_mask_1: 7.684  loss_mask_2: 7.633  loss_mask_3: 7.647  loss_mask_4: 7.658  loss_mask_5: 7.676  loss_mask_6: 7.668  loss_mask_7: 7.751  loss_mask_8: 7.771  time: 2.6029  data_time: 0.0527  lr: 8.7034e-05  max_mem: 27639M
[01/29 04:33:19] d2.utils.events INFO:  eta: 1 day, 13:20:57  iter: 8599  total_loss: 80.96  loss_mask: 8.139  loss_mask_0: 9.089  loss_mask_1: 7.878  loss_mask_2: 7.906  loss_mask_3: 7.973  loss_mask_4: 7.912  loss_mask_5: 7.935  loss_mask_6: 7.924  loss_mask_7: 8.158  loss_mask_8: 8.14  time: 2.6029  data_time: 0.0567  lr: 8.7004e-05  max_mem: 27639M
[01/29 04:34:12] d2.utils.events INFO:  eta: 1 day, 13:20:17  iter: 8619  total_loss: 83.82  loss_mask: 8.36  loss_mask_0: 9.328  loss_mask_1: 8.07  loss_mask_2: 8.115  loss_mask_3: 8.16  loss_mask_4: 8.206  loss_mask_5: 8.207  loss_mask_6: 8.182  loss_mask_7: 8.406  loss_mask_8: 8.41  time: 2.6029  data_time: 0.0578  lr: 8.6973e-05  max_mem: 27639M
[01/29 04:35:05] d2.utils.events INFO:  eta: 1 day, 13:19:55  iter: 8639  total_loss: 75.63  loss_mask: 7.558  loss_mask_0: 8.659  loss_mask_1: 7.392  loss_mask_2: 7.364  loss_mask_3: 7.372  loss_mask_4: 7.367  loss_mask_5: 7.382  loss_mask_6: 7.353  loss_mask_7: 7.536  loss_mask_8: 7.567  time: 2.6030  data_time: 0.0636  lr: 8.6943e-05  max_mem: 27639M
[01/29 04:35:57] d2.utils.events INFO:  eta: 1 day, 13:19:20  iter: 8659  total_loss: 73.22  loss_mask: 7.377  loss_mask_0: 8.402  loss_mask_1: 7.151  loss_mask_2: 7.099  loss_mask_3: 7.085  loss_mask_4: 7.096  loss_mask_5: 7.147  loss_mask_6: 7.131  loss_mask_7: 7.328  loss_mask_8: 7.393  time: 2.6031  data_time: 0.0586  lr: 8.6912e-05  max_mem: 27639M
[01/29 04:36:50] d2.utils.events INFO:  eta: 1 day, 13:18:35  iter: 8679  total_loss: 79.19  loss_mask: 7.965  loss_mask_0: 9.074  loss_mask_1: 7.731  loss_mask_2: 7.761  loss_mask_3: 7.734  loss_mask_4: 7.747  loss_mask_5: 7.75  loss_mask_6: 7.75  loss_mask_7: 7.986  loss_mask_8: 7.992  time: 2.6032  data_time: 0.0565  lr: 8.6882e-05  max_mem: 27639M
[01/29 04:37:42] d2.utils.events INFO:  eta: 1 day, 13:18:13  iter: 8699  total_loss: 74.37  loss_mask: 7.411  loss_mask_0: 8.294  loss_mask_1: 7.281  loss_mask_2: 7.31  loss_mask_3: 7.291  loss_mask_4: 7.32  loss_mask_5: 7.35  loss_mask_6: 7.334  loss_mask_7: 7.481  loss_mask_8: 7.495  time: 2.6032  data_time: 0.0552  lr: 8.6851e-05  max_mem: 27639M
[01/29 04:38:35] d2.utils.events INFO:  eta: 1 day, 13:17:22  iter: 8719  total_loss: 75.88  loss_mask: 7.627  loss_mask_0: 8.538  loss_mask_1: 7.419  loss_mask_2: 7.493  loss_mask_3: 7.5  loss_mask_4: 7.425  loss_mask_5: 7.433  loss_mask_6: 7.408  loss_mask_7: 7.637  loss_mask_8: 7.644  time: 2.6032  data_time: 0.0542  lr: 8.6821e-05  max_mem: 27639M
[01/29 04:39:27] d2.utils.events INFO:  eta: 1 day, 13:16:56  iter: 8739  total_loss: 74.77  loss_mask: 7.516  loss_mask_0: 8.669  loss_mask_1: 7.225  loss_mask_2: 7.255  loss_mask_3: 7.281  loss_mask_4: 7.247  loss_mask_5: 7.255  loss_mask_6: 7.296  loss_mask_7: 7.5  loss_mask_8: 7.503  time: 2.6033  data_time: 0.0612  lr: 8.6791e-05  max_mem: 27639M
[01/29 04:40:20] d2.utils.events INFO:  eta: 1 day, 13:16:00  iter: 8759  total_loss: 73.49  loss_mask: 7.426  loss_mask_0: 8.519  loss_mask_1: 7.135  loss_mask_2: 7.128  loss_mask_3: 7.169  loss_mask_4: 7.153  loss_mask_5: 7.162  loss_mask_6: 7.133  loss_mask_7: 7.461  loss_mask_8: 7.443  time: 2.6033  data_time: 0.0538  lr: 8.676e-05  max_mem: 27639M
[01/29 04:41:12] d2.utils.events INFO:  eta: 1 day, 13:14:43  iter: 8779  total_loss: 73.51  loss_mask: 7.414  loss_mask_0: 8.382  loss_mask_1: 7.149  loss_mask_2: 7.103  loss_mask_3: 7.12  loss_mask_4: 7.136  loss_mask_5: 7.13  loss_mask_6: 7.11  loss_mask_7: 7.441  loss_mask_8: 7.425  time: 2.6033  data_time: 0.0551  lr: 8.673e-05  max_mem: 27639M
[01/29 04:42:04] d2.utils.events INFO:  eta: 1 day, 13:13:51  iter: 8799  total_loss: 75.39  loss_mask: 7.601  loss_mask_0: 8.729  loss_mask_1: 7.329  loss_mask_2: 7.3  loss_mask_3: 7.287  loss_mask_4: 7.293  loss_mask_5: 7.329  loss_mask_6: 7.327  loss_mask_7: 7.625  loss_mask_8: 7.604  time: 2.6033  data_time: 0.0562  lr: 8.6699e-05  max_mem: 27639M
[01/29 04:42:57] d2.utils.events INFO:  eta: 1 day, 13:12:59  iter: 8819  total_loss: 72.73  loss_mask: 7.29  loss_mask_0: 8.351  loss_mask_1: 7.138  loss_mask_2: 7.134  loss_mask_3: 7.097  loss_mask_4: 7.125  loss_mask_5: 7.131  loss_mask_6: 7.107  loss_mask_7: 7.266  loss_mask_8: 7.29  time: 2.6033  data_time: 0.0539  lr: 8.6669e-05  max_mem: 27639M
[01/29 04:43:49] d2.utils.events INFO:  eta: 1 day, 13:12:34  iter: 8839  total_loss: 77.98  loss_mask: 7.806  loss_mask_0: 8.847  loss_mask_1: 7.623  loss_mask_2: 7.618  loss_mask_3: 7.639  loss_mask_4: 7.625  loss_mask_5: 7.63  loss_mask_6: 7.614  loss_mask_7: 7.809  loss_mask_8: 7.798  time: 2.6034  data_time: 0.0586  lr: 8.6638e-05  max_mem: 27639M
[01/29 04:44:42] d2.utils.events INFO:  eta: 1 day, 13:11:51  iter: 8859  total_loss: 80.96  loss_mask: 8.074  loss_mask_0: 9.359  loss_mask_1: 7.939  loss_mask_2: 7.888  loss_mask_3: 7.889  loss_mask_4: 7.897  loss_mask_5: 7.904  loss_mask_6: 7.893  loss_mask_7: 8.084  loss_mask_8: 8.071  time: 2.6035  data_time: 0.0528  lr: 8.6608e-05  max_mem: 27639M
[01/29 04:45:34] d2.utils.events INFO:  eta: 1 day, 13:10:52  iter: 8879  total_loss: 79.47  loss_mask: 7.989  loss_mask_0: 8.888  loss_mask_1: 7.706  loss_mask_2: 7.704  loss_mask_3: 7.764  loss_mask_4: 7.74  loss_mask_5: 7.743  loss_mask_6: 7.766  loss_mask_7: 8.009  loss_mask_8: 7.996  time: 2.6035  data_time: 0.0569  lr: 8.6577e-05  max_mem: 27639M
[01/29 04:46:27] d2.utils.events INFO:  eta: 1 day, 13:10:26  iter: 8899  total_loss: 73.83  loss_mask: 7.385  loss_mask_0: 8.297  loss_mask_1: 7.135  loss_mask_2: 7.168  loss_mask_3: 7.199  loss_mask_4: 7.219  loss_mask_5: 7.216  loss_mask_6: 7.242  loss_mask_7: 7.419  loss_mask_8: 7.422  time: 2.6036  data_time: 0.0561  lr: 8.6547e-05  max_mem: 27639M
[01/29 04:47:20] d2.utils.events INFO:  eta: 1 day, 13:10:02  iter: 8919  total_loss: 75.38  loss_mask: 7.585  loss_mask_0: 8.669  loss_mask_1: 7.26  loss_mask_2: 7.31  loss_mask_3: 7.279  loss_mask_4: 7.352  loss_mask_5: 7.329  loss_mask_6: 7.33  loss_mask_7: 7.592  loss_mask_8: 7.61  time: 2.6036  data_time: 0.0598  lr: 8.6516e-05  max_mem: 27639M
[01/29 04:48:12] d2.utils.events INFO:  eta: 1 day, 13:09:17  iter: 8939  total_loss: 74.58  loss_mask: 7.518  loss_mask_0: 8.534  loss_mask_1: 7.151  loss_mask_2: 7.156  loss_mask_3: 7.173  loss_mask_4: 7.151  loss_mask_5: 7.147  loss_mask_6: 7.157  loss_mask_7: 7.499  loss_mask_8: 7.463  time: 2.6037  data_time: 0.0574  lr: 8.6486e-05  max_mem: 27639M
[01/29 04:49:05] d2.utils.events INFO:  eta: 1 day, 13:08:29  iter: 8959  total_loss: 72.3  loss_mask: 7.283  loss_mask_0: 8.164  loss_mask_1: 7.058  loss_mask_2: 7.041  loss_mask_3: 7.051  loss_mask_4: 7.068  loss_mask_5: 7.053  loss_mask_6: 7.03  loss_mask_7: 7.282  loss_mask_8: 7.267  time: 2.6038  data_time: 0.0593  lr: 8.6455e-05  max_mem: 27639M
[01/29 04:49:58] d2.utils.events INFO:  eta: 1 day, 13:07:34  iter: 8979  total_loss: 75.18  loss_mask: 7.589  loss_mask_0: 8.828  loss_mask_1: 7.248  loss_mask_2: 7.26  loss_mask_3: 7.287  loss_mask_4: 7.259  loss_mask_5: 7.219  loss_mask_6: 7.247  loss_mask_7: 7.595  loss_mask_8: 7.593  time: 2.6038  data_time: 0.0579  lr: 8.6425e-05  max_mem: 27639M
[01/29 04:50:50] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 04:50:51] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 04:50:51] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 05:05:11] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 6.709977565429845, 'error_1pix': 0.7288606547653086, 'error_3pix': 0.4730492388768039, 'mIoU': 2.7321621178339317, 'fwIoU': 4.8753265396691585, 'IoU-0': 1.938609660169481e-05, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.02708016383594656, 'IoU-7': 0.19843915470760148, 'IoU-8': 0.9830129197247416, 'IoU-9': 4.726896741069362, 'IoU-10': 7.796698007044646, 'IoU-11': 12.761628169663222, 'IoU-12': 12.323207943564706, 'IoU-13': 11.208191945133619, 'IoU-14': 10.707677893137792, 'IoU-15': 9.338384943664572, 'IoU-16': 8.167725423694913, 'IoU-17': 6.623403973276811, 'IoU-18': 6.546264213228427, 'IoU-19': 6.512640056484702, 'IoU-20': 7.203771210847279, 'IoU-21': 8.299840377162958, 'IoU-22': 8.464141307822693, 'IoU-23': 7.616507159181932, 'IoU-24': 7.456193164508272, 'IoU-25': 7.10612696820905, 'IoU-26': 6.46468007873422, 'IoU-27': 6.727464312200182, 'IoU-28': 6.724286893454674, 'IoU-29': 6.479522999236329, 'IoU-30': 6.09670771681607, 'IoU-31': 5.663980293092733, 'IoU-32': 5.119334757645648, 'IoU-33': 4.447537180686883, 'IoU-34': 4.252253029163812, 'IoU-35': 4.1905495246441316, 'IoU-36': 4.112483895060086, 'IoU-37': 4.233395449818627, 'IoU-38': 4.243976747384268, 'IoU-39': 4.121342675966914, 'IoU-40': 3.9044806275611097, 'IoU-41': 3.643724674436075, 'IoU-42': 3.5650718557334593, 'IoU-43': 3.811984275087349, 'IoU-44': 3.9513819423994323, 'IoU-45': 4.17884313321051, 'IoU-46': 4.128375114197624, 'IoU-47': 4.301702096269562, 'IoU-48': 4.331151106150257, 'IoU-49': 4.3828809094004235, 'IoU-50': 4.68298206533047, 'IoU-51': 4.837345004562115, 'IoU-52': 5.001210514127479, 'IoU-53': 5.1116959814532725, 'IoU-54': 5.255222161603597, 'IoU-55': 5.326162534448475, 'IoU-56': 5.089869838649374, 'IoU-57': 5.052317397212963, 'IoU-58': 4.807509167352627, 'IoU-59': 4.568240873434281, 'IoU-60': 4.557732976834459, 'IoU-61': 4.438177965087314, 'IoU-62': 4.284551162500532, 'IoU-63': 4.196621144197703, 'IoU-64': 4.406083211327686, 'IoU-65': 4.088895603518592, 'IoU-66': 3.9085758391190746, 'IoU-67': 3.7525069948724497, 'IoU-68': 3.6126099815190056, 'IoU-69': 3.6877780527690724, 'IoU-70': 3.785055888902512, 'IoU-71': 3.5061211073280836, 'IoU-72': 3.42927010476535, 'IoU-73': 3.2770187655787297, 'IoU-74': 3.2665019083119002, 'IoU-75': 3.3835270305894385, 'IoU-76': 3.450784584944939, 'IoU-77': 3.1923507470941423, 'IoU-78': 3.3354086300235926, 'IoU-79': 3.326329260483657, 'IoU-80': 3.216232375374705, 'IoU-81': 3.293252843806349, 'IoU-82': 3.2462802301490545, 'IoU-83': 3.272290986847737, 'IoU-84': 3.246126536445282, 'IoU-85': 3.0849660002919865, 'IoU-86': 3.0787559345160385, 'IoU-87': 3.0216858192610094, 'IoU-88': 3.072278654438829, 'IoU-89': 3.084660662280785, 'IoU-90': 3.0144365537015103, 'IoU-91': 2.87165433652882, 'IoU-92': 2.9887116245596976, 'IoU-93': 2.889044607864876, 'IoU-94': 2.913171453128526, 'IoU-95': 2.9237682207598983, 'IoU-96': 2.769520947410174, 'IoU-97': 2.9216252805161145, 'IoU-98': 2.9004121098286864, 'IoU-99': 2.6905619518601127, 'IoU-100': 2.6762366186939155, 'IoU-101': 2.4937080441554973, 'IoU-102': 2.4531591128990273, 'IoU-103': 2.4187128794196115, 'IoU-104': 2.3141900538397464, 'IoU-105': 2.2087222542364935, 'IoU-106': 2.156922552267179, 'IoU-107': 2.1578229596009395, 'IoU-108': 2.0892774082146075, 'IoU-109': 1.962026129086822, 'IoU-110': 2.0726178302269758, 'IoU-111': 1.9289350266959024, 'IoU-112': 1.7020403650123381, 'IoU-113': 1.6064303245850868, 'IoU-114': 1.6484583499150742, 'IoU-115': 1.6243581524243964, 'IoU-116': 1.639910421348954, 'IoU-117': 1.6375525464576046, 'IoU-118': 1.792682472370421, 'IoU-119': 1.6544387234543414, 'IoU-120': 1.4915150529306005, 'IoU-121': 1.5638071416811634, 'IoU-122': 1.3426747003535697, 'IoU-123': 1.23972930526628, 'IoU-124': 1.0922251680501738, 'IoU-125': 1.23285735502189, 'IoU-126': 1.2360253317750094, 'IoU-127': 1.2692868745213348, 'IoU-128': 1.4675904769585046, 'IoU-129': 1.3010581905365481, 'IoU-130': 1.3256641983168793, 'IoU-131': 1.161523790469024, 'IoU-132': 1.0601740056707705, 'IoU-133': 1.1870392353164017, 'IoU-134': 1.1438284559632383, 'IoU-135': 0.9943911176334542, 'IoU-136': 1.0562484658995794, 'IoU-137': 0.9353522294883984, 'IoU-138': 0.8591070367102207, 'IoU-139': 0.9680128102750543, 'IoU-140': 0.9095348600682753, 'IoU-141': 0.7361409550098899, 'IoU-142': 0.7811390537111244, 'IoU-143': 0.8616149445788625, 'IoU-144': 0.6629619869065008, 'IoU-145': 0.7016521023186639, 'IoU-146': 0.7848286096804546, 'IoU-147': 1.1418812738526667, 'IoU-148': 1.0149978481313746, 'IoU-149': 0.7223888392853358, 'IoU-150': 0.8843218786070743, 'IoU-151': 0.89923053206005, 'IoU-152': 0.8374391051636745, 'IoU-153': 1.006606893470653, 'IoU-154': 0.8532634590109253, 'IoU-155': 0.7411104000916897, 'IoU-156': 0.6383889173739757, 'IoU-157': 0.613920986628991, 'IoU-158': 0.6945467121851083, 'IoU-159': 0.8777413350501793, 'IoU-160': 0.6139379743917398, 'IoU-161': 0.5576538533231029, 'IoU-162': 0.4147429320053123, 'IoU-163': 0.40891755385725437, 'IoU-164': 0.1828268422474508, 'IoU-165': 0.2869516982420208, 'IoU-166': 0.47707681492481135, 'IoU-167': 0.2902041277703974, 'IoU-168': 0.26970089437085537, 'IoU-169': 0.4713083543903033, 'IoU-170': 0.16290310340225422, 'IoU-171': 0.1367406472118514, 'IoU-172': 0.022839989558861917, 'IoU-173': 0.045345577696317814, 'IoU-174': 0.06852717685602425, 'IoU-175': 0.09501712517953817, 'IoU-176': 0.009714177668840213, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 5.4619587238693335, 'pACC': 9.331140571587989, 'ACC-0': 1.9386098104977894e-05, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 8.554990454213856, 'ACC-7': 7.371896547323438, 'ACC-8': 9.008047152516136, 'ACC-9': 17.18178684541669, 'ACC-10': 18.825562852308703, 'ACC-11': 22.69573284727369, 'ACC-12': 21.57997031103771, 'ACC-13': 20.304019125047855, 'ACC-14': 20.166162576028405, 'ACC-15': 18.201145246598827, 'ACC-16': 15.810407876722312, 'ACC-17': 13.454551989305156, 'ACC-18': 12.472291538664845, 'ACC-19': 12.199809793994692, 'ACC-20': 13.60213950559867, 'ACC-21': 15.800266481525579, 'ACC-22': 16.01840497648002, 'ACC-23': 15.468244784759905, 'ACC-24': 15.299098626782548, 'ACC-25': 14.482450025068841, 'ACC-26': 13.056691904121493, 'ACC-27': 13.286194363454737, 'ACC-28': 13.869407665292346, 'ACC-29': 13.247489275429425, 'ACC-30': 12.615017712761256, 'ACC-31': 11.340821690181722, 'ACC-32': 10.269089166082576, 'ACC-33': 9.068534313375007, 'ACC-34': 8.508280139736286, 'ACC-35': 8.069173964679596, 'ACC-36': 7.794595452519651, 'ACC-37': 8.121401501920738, 'ACC-38': 8.059185316115084, 'ACC-39': 7.736052305338981, 'ACC-40': 7.18719851026957, 'ACC-41': 6.836305688982764, 'ACC-42': 6.646666369009521, 'ACC-43': 7.007971389196539, 'ACC-44': 7.026738590611149, 'ACC-45': 7.460125561329542, 'ACC-46': 7.471593679848396, 'ACC-47': 7.653935681547118, 'ACC-48': 7.646785368012572, 'ACC-49': 7.642047999415941, 'ACC-50': 8.122507956783815, 'ACC-51': 8.52914837075373, 'ACC-52': 8.840665221472218, 'ACC-53': 9.061456973751552, 'ACC-54': 9.250620887266052, 'ACC-55': 9.396891863536256, 'ACC-56': 9.046036173413384, 'ACC-57': 8.832520369028735, 'ACC-58': 8.475910759719357, 'ACC-59': 8.190894889221216, 'ACC-60': 8.290438756110937, 'ACC-61': 8.186155458032394, 'ACC-62': 7.988882758988113, 'ACC-63': 7.938818033045729, 'ACC-64': 8.376719944610691, 'ACC-65': 7.817311254288692, 'ACC-66': 7.5109227969719115, 'ACC-67': 7.261577703231005, 'ACC-68': 6.9973175570406125, 'ACC-69': 7.013867859247272, 'ACC-70': 7.1305830278748425, 'ACC-71': 6.704820037631477, 'ACC-72': 6.547647684033188, 'ACC-73': 6.220451177400556, 'ACC-74': 6.155951333547633, 'ACC-75': 6.4024793090607695, 'ACC-76': 6.4454436427981685, 'ACC-77': 6.0645620335088735, 'ACC-78': 6.368377467099608, 'ACC-79': 6.344782372905369, 'ACC-80': 6.076334885175442, 'ACC-81': 6.189933264414964, 'ACC-82': 6.1386628094714, 'ACC-83': 6.130741866599059, 'ACC-84': 6.094308809570769, 'ACC-85': 5.805365803303564, 'ACC-86': 5.839947776189429, 'ACC-87': 5.7555797312097905, 'ACC-88': 5.880552699031703, 'ACC-89': 5.90176827156506, 'ACC-90': 5.75345834870493, 'ACC-91': 5.546550308472047, 'ACC-92': 5.822735598477846, 'ACC-93': 5.652932102380246, 'ACC-94': 5.719393700538376, 'ACC-95': 5.753315558017937, 'ACC-96': 5.490561076353206, 'ACC-97': 5.827169396672972, 'ACC-98': 5.8743692003121755, 'ACC-99': 5.515513260881806, 'ACC-100': 5.514245260297434, 'ACC-101': 5.186963414613177, 'ACC-102': 5.113910285455369, 'ACC-103': 5.06914139982998, 'ACC-104': 4.8922800718132855, 'ACC-105': 4.6565604687565045, 'ACC-106': 4.507836163645456, 'ACC-107': 4.4804598601447285, 'ACC-108': 4.271469342894026, 'ACC-109': 3.9855248106616314, 'ACC-110': 4.27063482767664, 'ACC-111': 3.9846362180225463, 'ACC-112': 3.5489900496416844, 'ACC-113': 3.340043451046484, 'ACC-114': 3.3904920449985916, 'ACC-115': 3.306458887736232, 'ACC-116': 3.370469005220951, 'ACC-117': 3.347391802958547, 'ACC-118': 3.655838673013402, 'ACC-119': 3.382103736719597, 'ACC-120': 3.040829019913767, 'ACC-121': 3.1839634960872116, 'ACC-122': 2.7325521054468944, 'ACC-123': 2.5410573767094493, 'ACC-124': 2.3053101564593486, 'ACC-125': 2.6049558226728724, 'ACC-126': 2.628894616526562, 'ACC-127': 2.7219673111607436, 'ACC-128': 3.1962785297069973, 'ACC-129': 2.8329042100104234, 'ACC-130': 2.86294348150231, 'ACC-131': 2.484659865369675, 'ACC-132': 2.2839487555837046, 'ACC-133': 2.5542468717467184, 'ACC-134': 2.4256441189142612, 'ACC-135': 2.1294395986545807, 'ACC-136': 2.2460573518449496, 'ACC-137': 2.013330616226167, 'ACC-138': 1.8457147752366934, 'ACC-139': 2.0820608762593737, 'ACC-140': 1.9405751656073427, 'ACC-141': 1.610481722290575, 'ACC-142': 1.7677660840776168, 'ACC-143': 1.9772602491074744, 'ACC-144': 1.523465703971119, 'ACC-145': 1.60611820478991, 'ACC-146': 1.8026547257316488, 'ACC-147': 2.644795693153931, 'ACC-148': 2.425547810895099, 'ACC-149': 1.7279723832713534, 'ACC-150': 2.152887871595951, 'ACC-151': 2.293977403406009, 'ACC-152': 2.040975453503271, 'ACC-153': 2.538865680939556, 'ACC-154': 2.1595294874639968, 'ACC-155': 1.9127946103046123, 'ACC-156': 1.7319190469726644, 'ACC-157': 1.5654666389014784, 'ACC-158': 1.7572482432457226, 'ACC-159': 2.129933907402314, 'ACC-160': 1.524962674750034, 'ACC-161': 1.264473695296242, 'ACC-162': 0.8580753999541805, 'ACC-163': 0.8490186756592735, 'ACC-164': 0.36910314910942765, 'ACC-165': 0.512662509886382, 'ACC-166': 0.8214486573603849, 'ACC-167': 0.45043401827792806, 'ACC-168': 0.42654195091075325, 'ACC-169': 0.6896031360272894, 'ACC-170': 0.2209421184888624, 'ACC-171': 0.1846038548223854, 'ACC-172': 0.02722524724969441, 'ACC-173': 0.05380936433455125, 'ACC-174': 0.07996555330011687, 'ACC-175': 0.11130030931132472, 'ACC-176': 0.010157882516833062, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 05:05:11] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 05:05:11] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 05:05:11] d2.evaluation.testing INFO: copypaste: 6.7100,0.7289,0.4730,2.7322,4.8753,5.4620,9.3311
[01/29 05:05:11] d2.utils.events INFO:  eta: 1 day, 13:06:44  iter: 8999  total_loss: 76.98  loss_mask: 7.777  loss_mask_0: 8.713  loss_mask_1: 7.445  loss_mask_2: 7.464  loss_mask_3: 7.428  loss_mask_4: 7.502  loss_mask_5: 7.514  loss_mask_6: 7.473  loss_mask_7: 7.783  loss_mask_8: 7.77  time: 2.6039  data_time: 0.0627  lr: 8.6394e-05  max_mem: 27639M
[01/29 05:06:03] d2.utils.events INFO:  eta: 1 day, 13:06:12  iter: 9019  total_loss: 74.85  loss_mask: 7.57  loss_mask_0: 8.507  loss_mask_1: 7.31  loss_mask_2: 7.316  loss_mask_3: 7.338  loss_mask_4: 7.322  loss_mask_5: 7.33  loss_mask_6: 7.318  loss_mask_7: 7.576  loss_mask_8: 7.56  time: 2.6039  data_time: 0.0563  lr: 8.6364e-05  max_mem: 27639M
[01/29 05:06:56] d2.utils.events INFO:  eta: 1 day, 13:05:32  iter: 9039  total_loss: 68.37  loss_mask: 6.966  loss_mask_0: 7.933  loss_mask_1: 6.6  loss_mask_2: 6.566  loss_mask_3: 6.544  loss_mask_4: 6.569  loss_mask_5: 6.599  loss_mask_6: 6.604  loss_mask_7: 6.909  loss_mask_8: 6.91  time: 2.6039  data_time: 0.0565  lr: 8.6333e-05  max_mem: 27639M
[01/29 05:07:49] d2.utils.events INFO:  eta: 1 day, 13:04:45  iter: 9059  total_loss: 75.68  loss_mask: 7.663  loss_mask_0: 8.826  loss_mask_1: 7.379  loss_mask_2: 7.435  loss_mask_3: 7.452  loss_mask_4: 7.419  loss_mask_5: 7.441  loss_mask_6: 7.449  loss_mask_7: 7.665  loss_mask_8: 7.644  time: 2.6040  data_time: 0.0581  lr: 8.6303e-05  max_mem: 27639M
[01/29 05:08:42] d2.utils.events INFO:  eta: 1 day, 13:03:46  iter: 9079  total_loss: 77.28  loss_mask: 7.789  loss_mask_0: 8.737  loss_mask_1: 7.475  loss_mask_2: 7.523  loss_mask_3: 7.515  loss_mask_4: 7.514  loss_mask_5: 7.517  loss_mask_6: 7.534  loss_mask_7: 7.788  loss_mask_8: 7.789  time: 2.6041  data_time: 0.0699  lr: 8.6272e-05  max_mem: 27639M
[01/29 05:09:34] d2.utils.events INFO:  eta: 1 day, 13:03:13  iter: 9099  total_loss: 72.83  loss_mask: 7.33  loss_mask_0: 8.316  loss_mask_1: 7.07  loss_mask_2: 7.047  loss_mask_3: 7.059  loss_mask_4: 7.053  loss_mask_5: 7.031  loss_mask_6: 7.028  loss_mask_7: 7.363  loss_mask_8: 7.388  time: 2.6041  data_time: 0.0520  lr: 8.6242e-05  max_mem: 27639M
[01/29 05:10:27] d2.utils.events INFO:  eta: 1 day, 13:02:18  iter: 9119  total_loss: 70.98  loss_mask: 7.079  loss_mask_0: 8.086  loss_mask_1: 7  loss_mask_2: 7.005  loss_mask_3: 6.95  loss_mask_4: 6.981  loss_mask_5: 6.997  loss_mask_6: 6.953  loss_mask_7: 7.106  loss_mask_8: 7.134  time: 2.6042  data_time: 0.0565  lr: 8.6211e-05  max_mem: 27639M
[01/29 05:11:20] d2.utils.events INFO:  eta: 1 day, 13:01:34  iter: 9139  total_loss: 72.26  loss_mask: 7.315  loss_mask_0: 8.431  loss_mask_1: 6.99  loss_mask_2: 7.034  loss_mask_3: 7.031  loss_mask_4: 7.1  loss_mask_5: 7.061  loss_mask_6: 7.053  loss_mask_7: 7.316  loss_mask_8: 7.318  time: 2.6043  data_time: 0.0616  lr: 8.6181e-05  max_mem: 27639M
[01/29 05:12:13] d2.utils.events INFO:  eta: 1 day, 13:00:36  iter: 9159  total_loss: 72.09  loss_mask: 7.265  loss_mask_0: 8.434  loss_mask_1: 6.937  loss_mask_2: 6.931  loss_mask_3: 6.956  loss_mask_4: 6.936  loss_mask_5: 6.92  loss_mask_6: 6.94  loss_mask_7: 7.259  loss_mask_8: 7.284  time: 2.6044  data_time: 0.0615  lr: 8.615e-05  max_mem: 27639M
[01/29 05:13:05] d2.utils.events INFO:  eta: 1 day, 12:59:44  iter: 9179  total_loss: 68.38  loss_mask: 6.805  loss_mask_0: 8.032  loss_mask_1: 6.819  loss_mask_2: 6.729  loss_mask_3: 6.717  loss_mask_4: 6.707  loss_mask_5: 6.738  loss_mask_6: 6.78  loss_mask_7: 6.78  loss_mask_8: 6.833  time: 2.6044  data_time: 0.0596  lr: 8.612e-05  max_mem: 27639M
[01/29 05:13:58] d2.utils.events INFO:  eta: 1 day, 12:58:55  iter: 9199  total_loss: 73.55  loss_mask: 7.447  loss_mask_0: 8.516  loss_mask_1: 7.102  loss_mask_2: 7.088  loss_mask_3: 7.11  loss_mask_4: 7.087  loss_mask_5: 7.104  loss_mask_6: 7.077  loss_mask_7: 7.401  loss_mask_8: 7.442  time: 2.6045  data_time: 0.0621  lr: 8.6089e-05  max_mem: 27639M
[01/29 05:14:50] d2.utils.events INFO:  eta: 1 day, 12:57:59  iter: 9219  total_loss: 74.28  loss_mask: 7.512  loss_mask_0: 8.554  loss_mask_1: 7.182  loss_mask_2: 7.168  loss_mask_3: 7.162  loss_mask_4: 7.165  loss_mask_5: 7.164  loss_mask_6: 7.163  loss_mask_7: 7.51  loss_mask_8: 7.493  time: 2.6045  data_time: 0.0561  lr: 8.6059e-05  max_mem: 27639M
[01/29 05:15:43] d2.utils.events INFO:  eta: 1 day, 12:57:21  iter: 9239  total_loss: 69.66  loss_mask: 7.018  loss_mask_0: 7.718  loss_mask_1: 6.825  loss_mask_2: 6.835  loss_mask_3: 6.9  loss_mask_4: 6.86  loss_mask_5: 6.836  loss_mask_6: 6.806  loss_mask_7: 7.055  loss_mask_8: 7.031  time: 2.6046  data_time: 0.0614  lr: 8.6028e-05  max_mem: 27639M
[01/29 05:16:36] d2.utils.events INFO:  eta: 1 day, 12:56:30  iter: 9259  total_loss: 73.45  loss_mask: 7.327  loss_mask_0: 8.17  loss_mask_1: 7.3  loss_mask_2: 7.24  loss_mask_3: 7.191  loss_mask_4: 7.188  loss_mask_5: 7.191  loss_mask_6: 7.216  loss_mask_7: 7.284  loss_mask_8: 7.304  time: 2.6046  data_time: 0.0598  lr: 8.5998e-05  max_mem: 27639M
[01/29 05:17:28] d2.utils.events INFO:  eta: 1 day, 12:55:32  iter: 9279  total_loss: 68.88  loss_mask: 6.961  loss_mask_0: 7.942  loss_mask_1: 6.754  loss_mask_2: 6.743  loss_mask_3: 6.72  loss_mask_4: 6.744  loss_mask_5: 6.741  loss_mask_6: 6.748  loss_mask_7: 6.979  loss_mask_8: 6.979  time: 2.6046  data_time: 0.0552  lr: 8.5967e-05  max_mem: 27639M
[01/29 05:18:20] d2.utils.events INFO:  eta: 1 day, 12:54:28  iter: 9299  total_loss: 72.4  loss_mask: 7.305  loss_mask_0: 8.01  loss_mask_1: 7.035  loss_mask_2: 7.004  loss_mask_3: 7.001  loss_mask_4: 6.99  loss_mask_5: 7.043  loss_mask_6: 7.021  loss_mask_7: 7.342  loss_mask_8: 7.324  time: 2.6047  data_time: 0.0556  lr: 8.5937e-05  max_mem: 27639M
[01/29 05:19:13] d2.utils.events INFO:  eta: 1 day, 12:53:39  iter: 9319  total_loss: 80.25  loss_mask: 8.195  loss_mask_0: 8.258  loss_mask_1: 7.919  loss_mask_2: 7.888  loss_mask_3: 7.926  loss_mask_4: 7.939  loss_mask_5: 7.954  loss_mask_6: 7.937  loss_mask_7: 8.173  loss_mask_8: 8.164  time: 2.6047  data_time: 0.0603  lr: 8.5906e-05  max_mem: 27639M
[01/29 05:20:06] d2.utils.events INFO:  eta: 1 day, 12:52:55  iter: 9339  total_loss: 70.82  loss_mask: 7.205  loss_mask_0: 7.229  loss_mask_1: 7.01  loss_mask_2: 6.98  loss_mask_3: 6.98  loss_mask_4: 6.989  loss_mask_5: 6.997  loss_mask_6: 7.001  loss_mask_7: 7.23  loss_mask_8: 7.245  time: 2.6048  data_time: 0.0583  lr: 8.5876e-05  max_mem: 27639M
[01/29 05:20:58] d2.utils.events INFO:  eta: 1 day, 12:52:17  iter: 9359  total_loss: 66.52  loss_mask: 6.823  loss_mask_0: 6.818  loss_mask_1: 6.531  loss_mask_2: 6.531  loss_mask_3: 6.52  loss_mask_4: 6.546  loss_mask_5: 6.538  loss_mask_6: 6.553  loss_mask_7: 6.861  loss_mask_8: 6.872  time: 2.6048  data_time: 0.0604  lr: 8.5845e-05  max_mem: 27639M
[01/29 05:21:51] d2.utils.events INFO:  eta: 1 day, 12:51:14  iter: 9379  total_loss: 63.65  loss_mask: 6.555  loss_mask_0: 6.59  loss_mask_1: 6.232  loss_mask_2: 6.271  loss_mask_3: 6.268  loss_mask_4: 6.267  loss_mask_5: 6.276  loss_mask_6: 6.289  loss_mask_7: 6.541  loss_mask_8: 6.549  time: 2.6049  data_time: 0.0566  lr: 8.5815e-05  max_mem: 27639M
[01/29 05:22:43] d2.utils.events INFO:  eta: 1 day, 12:50:39  iter: 9399  total_loss: 72.35  loss_mask: 7.394  loss_mask_0: 7.335  loss_mask_1: 7.078  loss_mask_2: 7.143  loss_mask_3: 7.153  loss_mask_4: 7.145  loss_mask_5: 7.146  loss_mask_6: 7.096  loss_mask_7: 7.4  loss_mask_8: 7.416  time: 2.6049  data_time: 0.0615  lr: 8.5784e-05  max_mem: 27639M
[01/29 05:23:36] d2.utils.events INFO:  eta: 1 day, 12:49:43  iter: 9419  total_loss: 70.17  loss_mask: 7.264  loss_mask_0: 7  loss_mask_1: 6.932  loss_mask_2: 6.87  loss_mask_3: 6.901  loss_mask_4: 6.902  loss_mask_5: 6.882  loss_mask_6: 6.894  loss_mask_7: 7.253  loss_mask_8: 7.242  time: 2.6050  data_time: 0.0637  lr: 8.5754e-05  max_mem: 27639M
[01/29 05:24:28] d2.utils.events INFO:  eta: 1 day, 12:48:37  iter: 9439  total_loss: 77.02  loss_mask: 7.808  loss_mask_0: 7.65  loss_mask_1: 7.625  loss_mask_2: 7.587  loss_mask_3: 7.63  loss_mask_4: 7.604  loss_mask_5: 7.598  loss_mask_6: 7.627  loss_mask_7: 7.847  loss_mask_8: 7.801  time: 2.6050  data_time: 0.0575  lr: 8.5723e-05  max_mem: 27639M
[01/29 05:25:21] d2.utils.events INFO:  eta: 1 day, 12:47:41  iter: 9459  total_loss: 78.02  loss_mask: 7.905  loss_mask_0: 7.755  loss_mask_1: 7.726  loss_mask_2: 7.744  loss_mask_3: 7.794  loss_mask_4: 7.775  loss_mask_5: 7.778  loss_mask_6: 7.766  loss_mask_7: 7.896  loss_mask_8: 7.908  time: 2.6050  data_time: 0.0569  lr: 8.5693e-05  max_mem: 27639M
[01/29 05:26:14] d2.utils.events INFO:  eta: 1 day, 12:46:43  iter: 9479  total_loss: 64.82  loss_mask: 6.63  loss_mask_0: 6.648  loss_mask_1: 6.361  loss_mask_2: 6.378  loss_mask_3: 6.37  loss_mask_4: 6.376  loss_mask_5: 6.39  loss_mask_6: 6.396  loss_mask_7: 6.62  loss_mask_8: 6.624  time: 2.6051  data_time: 0.0603  lr: 8.5662e-05  max_mem: 27639M
[01/29 05:27:06] d2.utils.events INFO:  eta: 1 day, 12:45:47  iter: 9499  total_loss: 76.14  loss_mask: 7.664  loss_mask_0: 7.603  loss_mask_1: 7.499  loss_mask_2: 7.493  loss_mask_3: 7.496  loss_mask_4: 7.505  loss_mask_5: 7.529  loss_mask_6: 7.483  loss_mask_7: 7.661  loss_mask_8: 7.681  time: 2.6051  data_time: 0.0574  lr: 8.5632e-05  max_mem: 27639M
[01/29 05:27:58] d2.utils.events INFO:  eta: 1 day, 12:44:53  iter: 9519  total_loss: 75.58  loss_mask: 7.672  loss_mask_0: 7.712  loss_mask_1: 7.525  loss_mask_2: 7.476  loss_mask_3: 7.478  loss_mask_4: 7.484  loss_mask_5: 7.473  loss_mask_6: 7.491  loss_mask_7: 7.686  loss_mask_8: 7.644  time: 2.6051  data_time: 0.0604  lr: 8.5601e-05  max_mem: 27639M
[01/29 05:28:51] d2.utils.events INFO:  eta: 1 day, 12:44:25  iter: 9539  total_loss: 74.67  loss_mask: 7.681  loss_mask_0: 7.473  loss_mask_1: 7.388  loss_mask_2: 7.365  loss_mask_3: 7.386  loss_mask_4: 7.385  loss_mask_5: 7.379  loss_mask_6: 7.364  loss_mask_7: 7.657  loss_mask_8: 7.674  time: 2.6052  data_time: 0.0523  lr: 8.5571e-05  max_mem: 27639M
[01/29 05:29:44] d2.utils.events INFO:  eta: 1 day, 12:43:43  iter: 9559  total_loss: 73.74  loss_mask: 7.508  loss_mask_0: 7.343  loss_mask_1: 7.257  loss_mask_2: 7.263  loss_mask_3: 7.258  loss_mask_4: 7.248  loss_mask_5: 7.228  loss_mask_6: 7.229  loss_mask_7: 7.485  loss_mask_8: 7.518  time: 2.6053  data_time: 0.0618  lr: 8.554e-05  max_mem: 27639M
[01/29 05:30:36] d2.utils.events INFO:  eta: 1 day, 12:42:57  iter: 9579  total_loss: 68.49  loss_mask: 6.978  loss_mask_0: 6.947  loss_mask_1: 6.774  loss_mask_2: 6.775  loss_mask_3: 6.793  loss_mask_4: 6.803  loss_mask_5: 6.758  loss_mask_6: 6.757  loss_mask_7: 6.999  loss_mask_8: 6.977  time: 2.6053  data_time: 0.0513  lr: 8.5509e-05  max_mem: 27639M
[01/29 05:31:29] d2.utils.events INFO:  eta: 1 day, 12:42:09  iter: 9599  total_loss: 69.26  loss_mask: 6.99  loss_mask_0: 6.982  loss_mask_1: 6.901  loss_mask_2: 6.89  loss_mask_3: 6.871  loss_mask_4: 6.888  loss_mask_5: 6.873  loss_mask_6: 6.845  loss_mask_7: 7.01  loss_mask_8: 7.007  time: 2.6053  data_time: 0.0570  lr: 8.5479e-05  max_mem: 27639M
[01/29 05:32:21] d2.utils.events INFO:  eta: 1 day, 12:41:16  iter: 9619  total_loss: 70.77  loss_mask: 7.209  loss_mask_0: 7.101  loss_mask_1: 6.943  loss_mask_2: 6.988  loss_mask_3: 7.059  loss_mask_4: 7.034  loss_mask_5: 7.001  loss_mask_6: 7.044  loss_mask_7: 7.184  loss_mask_8: 7.205  time: 2.6054  data_time: 0.0625  lr: 8.5448e-05  max_mem: 27639M
[01/29 05:33:14] d2.utils.events INFO:  eta: 1 day, 12:40:28  iter: 9639  total_loss: 71.37  loss_mask: 7.328  loss_mask_0: 7.108  loss_mask_1: 7.048  loss_mask_2: 7.032  loss_mask_3: 7.031  loss_mask_4: 7.047  loss_mask_5: 7.039  loss_mask_6: 7.043  loss_mask_7: 7.347  loss_mask_8: 7.345  time: 2.6054  data_time: 0.0682  lr: 8.5418e-05  max_mem: 27639M
[01/29 05:34:07] d2.utils.events INFO:  eta: 1 day, 12:39:32  iter: 9659  total_loss: 68.02  loss_mask: 6.937  loss_mask_0: 6.795  loss_mask_1: 6.756  loss_mask_2: 6.734  loss_mask_3: 6.707  loss_mask_4: 6.748  loss_mask_5: 6.788  loss_mask_6: 6.769  loss_mask_7: 6.937  loss_mask_8: 6.956  time: 2.6055  data_time: 0.0547  lr: 8.5387e-05  max_mem: 27639M
[01/29 05:34:59] d2.utils.events INFO:  eta: 1 day, 12:38:39  iter: 9679  total_loss: 68.91  loss_mask: 7.128  loss_mask_0: 7.094  loss_mask_1: 6.801  loss_mask_2: 6.833  loss_mask_3: 6.825  loss_mask_4: 6.828  loss_mask_5: 6.811  loss_mask_6: 6.833  loss_mask_7: 7.114  loss_mask_8: 7.129  time: 2.6055  data_time: 0.0498  lr: 8.5357e-05  max_mem: 27639M
[01/29 05:35:52] d2.utils.events INFO:  eta: 1 day, 12:37:50  iter: 9699  total_loss: 64.54  loss_mask: 6.623  loss_mask_0: 6.419  loss_mask_1: 6.392  loss_mask_2: 6.367  loss_mask_3: 6.363  loss_mask_4: 6.362  loss_mask_5: 6.365  loss_mask_6: 6.381  loss_mask_7: 6.635  loss_mask_8: 6.607  time: 2.6056  data_time: 0.0557  lr: 8.5326e-05  max_mem: 27639M
[01/29 05:36:45] d2.utils.events INFO:  eta: 1 day, 12:37:11  iter: 9719  total_loss: 71.49  loss_mask: 7.376  loss_mask_0: 7.251  loss_mask_1: 7.014  loss_mask_2: 6.995  loss_mask_3: 7.089  loss_mask_4: 7.057  loss_mask_5: 7.039  loss_mask_6: 7.01  loss_mask_7: 7.411  loss_mask_8: 7.402  time: 2.6056  data_time: 0.0660  lr: 8.5296e-05  max_mem: 27639M
[01/29 05:37:37] d2.utils.events INFO:  eta: 1 day, 12:36:09  iter: 9739  total_loss: 68.21  loss_mask: 6.925  loss_mask_0: 6.861  loss_mask_1: 6.714  loss_mask_2: 6.74  loss_mask_3: 6.757  loss_mask_4: 6.762  loss_mask_5: 6.776  loss_mask_6: 6.801  loss_mask_7: 6.944  loss_mask_8: 6.912  time: 2.6056  data_time: 0.0563  lr: 8.5265e-05  max_mem: 27639M
[01/29 05:38:30] d2.utils.events INFO:  eta: 1 day, 12:35:29  iter: 9759  total_loss: 65.75  loss_mask: 6.794  loss_mask_0: 6.712  loss_mask_1: 6.402  loss_mask_2: 6.433  loss_mask_3: 6.448  loss_mask_4: 6.453  loss_mask_5: 6.462  loss_mask_6: 6.462  loss_mask_7: 6.784  loss_mask_8: 6.793  time: 2.6057  data_time: 0.0605  lr: 8.5235e-05  max_mem: 27639M
[01/29 05:39:22] d2.utils.events INFO:  eta: 1 day, 12:34:48  iter: 9779  total_loss: 67.74  loss_mask: 6.965  loss_mask_0: 6.828  loss_mask_1: 6.754  loss_mask_2: 6.687  loss_mask_3: 6.69  loss_mask_4: 6.713  loss_mask_5: 6.717  loss_mask_6: 6.686  loss_mask_7: 6.921  loss_mask_8: 6.926  time: 2.6057  data_time: 0.0656  lr: 8.5204e-05  max_mem: 27639M
[01/29 05:40:15] d2.utils.events INFO:  eta: 1 day, 12:34:23  iter: 9799  total_loss: 60.66  loss_mask: 6.149  loss_mask_0: 6.1  loss_mask_1: 6.011  loss_mask_2: 6.035  loss_mask_3: 6.001  loss_mask_4: 5.986  loss_mask_5: 6.008  loss_mask_6: 6.026  loss_mask_7: 6.17  loss_mask_8: 6.173  time: 2.6058  data_time: 0.0657  lr: 8.5174e-05  max_mem: 27639M
[01/29 05:41:08] d2.utils.events INFO:  eta: 1 day, 12:33:27  iter: 9819  total_loss: 67.17  loss_mask: 6.763  loss_mask_0: 6.912  loss_mask_1: 6.647  loss_mask_2: 6.608  loss_mask_3: 6.646  loss_mask_4: 6.664  loss_mask_5: 6.628  loss_mask_6: 6.651  loss_mask_7: 6.779  loss_mask_8: 6.781  time: 2.6058  data_time: 0.0561  lr: 8.5143e-05  max_mem: 27639M
[01/29 05:42:00] d2.utils.events INFO:  eta: 1 day, 12:32:38  iter: 9839  total_loss: 75.38  loss_mask: 7.699  loss_mask_0: 7.555  loss_mask_1: 7.387  loss_mask_2: 7.36  loss_mask_3: 7.399  loss_mask_4: 7.412  loss_mask_5: 7.468  loss_mask_6: 7.412  loss_mask_7: 7.731  loss_mask_8: 7.744  time: 2.6059  data_time: 0.0592  lr: 8.5113e-05  max_mem: 27639M
[01/29 05:42:53] d2.utils.events INFO:  eta: 1 day, 12:32:12  iter: 9859  total_loss: 67.16  loss_mask: 6.857  loss_mask_0: 6.739  loss_mask_1: 6.707  loss_mask_2: 6.627  loss_mask_3: 6.597  loss_mask_4: 6.592  loss_mask_5: 6.659  loss_mask_6: 6.684  loss_mask_7: 6.877  loss_mask_8: 6.842  time: 2.6059  data_time: 0.0502  lr: 8.5082e-05  max_mem: 27639M
[01/29 05:43:45] d2.utils.events INFO:  eta: 1 day, 12:31:41  iter: 9879  total_loss: 64.53  loss_mask: 6.582  loss_mask_0: 6.575  loss_mask_1: 6.43  loss_mask_2: 6.376  loss_mask_3: 6.393  loss_mask_4: 6.388  loss_mask_5: 6.385  loss_mask_6: 6.363  loss_mask_7: 6.566  loss_mask_8: 6.571  time: 2.6060  data_time: 0.0583  lr: 8.5051e-05  max_mem: 27639M
[01/29 05:44:38] d2.utils.events INFO:  eta: 1 day, 12:30:48  iter: 9899  total_loss: 64.86  loss_mask: 6.732  loss_mask_0: 6.574  loss_mask_1: 6.422  loss_mask_2: 6.395  loss_mask_3: 6.376  loss_mask_4: 6.391  loss_mask_5: 6.362  loss_mask_6: 6.385  loss_mask_7: 6.734  loss_mask_8: 6.745  time: 2.6061  data_time: 0.0645  lr: 8.5021e-05  max_mem: 27639M
[01/29 05:45:31] d2.utils.events INFO:  eta: 1 day, 12:29:54  iter: 9919  total_loss: 59.63  loss_mask: 6.087  loss_mask_0: 5.935  loss_mask_1: 5.87  loss_mask_2: 5.861  loss_mask_3: 5.886  loss_mask_4: 5.862  loss_mask_5: 5.89  loss_mask_6: 5.867  loss_mask_7: 6.076  loss_mask_8: 6.095  time: 2.6061  data_time: 0.0624  lr: 8.499e-05  max_mem: 27639M
[01/29 05:46:23] d2.utils.events INFO:  eta: 1 day, 12:29:01  iter: 9939  total_loss: 68.52  loss_mask: 7.185  loss_mask_0: 6.756  loss_mask_1: 6.671  loss_mask_2: 6.683  loss_mask_3: 6.634  loss_mask_4: 6.668  loss_mask_5: 6.687  loss_mask_6: 6.704  loss_mask_7: 7.163  loss_mask_8: 7.184  time: 2.6062  data_time: 0.0711  lr: 8.496e-05  max_mem: 27639M
[01/29 05:47:16] d2.utils.events INFO:  eta: 1 day, 12:27:24  iter: 9959  total_loss: 73.42  loss_mask: 7.564  loss_mask_0: 7.489  loss_mask_1: 7.238  loss_mask_2: 7.175  loss_mask_3: 7.137  loss_mask_4: 7.181  loss_mask_5: 7.216  loss_mask_6: 7.195  loss_mask_7: 7.559  loss_mask_8: 7.588  time: 2.6062  data_time: 0.0521  lr: 8.4929e-05  max_mem: 27639M
[01/29 05:48:08] d2.utils.events INFO:  eta: 1 day, 12:26:53  iter: 9979  total_loss: 66.79  loss_mask: 6.844  loss_mask_0: 6.85  loss_mask_1: 6.609  loss_mask_2: 6.604  loss_mask_3: 6.572  loss_mask_4: 6.583  loss_mask_5: 6.598  loss_mask_6: 6.603  loss_mask_7: 6.842  loss_mask_8: 6.84  time: 2.6062  data_time: 0.0582  lr: 8.4899e-05  max_mem: 27639M
[01/29 05:49:00] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_nopretrain_instancenorm/model_0009999.pth
[01/29 05:49:01] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 05:49:02] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 05:49:02] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 06:03:15] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 5.848581044854848, 'error_1pix': 0.6366053915892484, 'error_3pix': 0.3993791436865015, 'mIoU': 3.894633355465375, 'fwIoU': 7.305249775773241, 'IoU-0': 0.10624514876161996, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.027962565822048494, 'IoU-7': 0.16271704148806798, 'IoU-8': 1.3121024326930555, 'IoU-9': 5.740339188454477, 'IoU-10': 9.008360531761534, 'IoU-11': 13.63505657529998, 'IoU-12': 13.42623766990225, 'IoU-13': 13.175287546833566, 'IoU-14': 12.864007526753857, 'IoU-15': 12.03058871535644, 'IoU-16': 11.659482803441216, 'IoU-17': 10.078481464744964, 'IoU-18': 9.87068402447603, 'IoU-19': 9.508768531145792, 'IoU-20': 9.941895625163813, 'IoU-21': 10.607600273153036, 'IoU-22': 11.057490385431928, 'IoU-23': 10.561792025791243, 'IoU-24': 11.051147797838086, 'IoU-25': 11.087538886448078, 'IoU-26': 10.637928081599867, 'IoU-27': 10.75167184247724, 'IoU-28': 10.566584916081402, 'IoU-29': 10.664499057453964, 'IoU-30': 10.996443388550617, 'IoU-31': 11.325329977680006, 'IoU-32': 10.977290970612534, 'IoU-33': 9.704637788615605, 'IoU-34': 9.165766296288405, 'IoU-35': 9.417722080581232, 'IoU-36': 8.859882666525717, 'IoU-37': 8.799634824727871, 'IoU-38': 8.858166742721531, 'IoU-39': 9.376816540195247, 'IoU-40': 9.381705611586005, 'IoU-41': 9.021833857326696, 'IoU-42': 8.790856656613276, 'IoU-43': 8.542000677365722, 'IoU-44': 8.827460890212887, 'IoU-45': 8.632594572598457, 'IoU-46': 8.140979466152427, 'IoU-47': 8.09377535979245, 'IoU-48': 8.061753759077657, 'IoU-49': 7.864918371844409, 'IoU-50': 7.737328759653886, 'IoU-51': 7.116978902428631, 'IoU-52': 7.166759722564417, 'IoU-53': 6.933551434528927, 'IoU-54': 6.631496244751098, 'IoU-55': 6.229927885856953, 'IoU-56': 6.0468863006694376, 'IoU-57': 5.804237958226671, 'IoU-58': 5.364004773638199, 'IoU-59': 4.935675279641382, 'IoU-60': 4.521434986095862, 'IoU-61': 4.36608271941427, 'IoU-62': 4.325975270244005, 'IoU-63': 4.0926403036974515, 'IoU-64': 4.122971910777132, 'IoU-65': 3.939289200140979, 'IoU-66': 3.8532025480195706, 'IoU-67': 3.799188541414908, 'IoU-68': 3.7543325124732476, 'IoU-69': 3.7908384830176973, 'IoU-70': 3.759431730299577, 'IoU-71': 3.6207940768076896, 'IoU-72': 3.5515438840195688, 'IoU-73': 3.6283947404201227, 'IoU-74': 3.722614233021505, 'IoU-75': 3.7195805468652225, 'IoU-76': 3.6908384411250745, 'IoU-77': 3.6718469094600663, 'IoU-78': 3.698583679578001, 'IoU-79': 3.767185096097096, 'IoU-80': 3.8061688597047074, 'IoU-81': 3.7486829157370143, 'IoU-82': 3.9127049798887135, 'IoU-83': 3.886975906744936, 'IoU-84': 3.8433551982699057, 'IoU-85': 3.7840051302347764, 'IoU-86': 3.6295643128144066, 'IoU-87': 3.623602864141926, 'IoU-88': 3.629361193437666, 'IoU-89': 3.538910579237991, 'IoU-90': 3.4303726204674043, 'IoU-91': 3.320658842513888, 'IoU-92': 3.2130877233077677, 'IoU-93': 3.1374765444524146, 'IoU-94': 3.2091534987654073, 'IoU-95': 3.1246243620535608, 'IoU-96': 3.06128252918323, 'IoU-97': 3.192908779513287, 'IoU-98': 3.0823288380759455, 'IoU-99': 2.8941948676439617, 'IoU-100': 2.787856664738939, 'IoU-101': 2.678662757660161, 'IoU-102': 2.650350363652017, 'IoU-103': 2.573018943982053, 'IoU-104': 2.5437416361579355, 'IoU-105': 2.5723990739506317, 'IoU-106': 2.5321914745086063, 'IoU-107': 2.4686336604771024, 'IoU-108': 2.418385566905291, 'IoU-109': 2.4999900239233708, 'IoU-110': 2.455771304951718, 'IoU-111': 2.63955707263694, 'IoU-112': 2.245178258967813, 'IoU-113': 2.3262322710737733, 'IoU-114': 2.2841502888357805, 'IoU-115': 2.2267171339444083, 'IoU-116': 2.24825706195834, 'IoU-117': 2.3018417007384393, 'IoU-118': 2.2620272529380703, 'IoU-119': 2.0761650390247075, 'IoU-120': 2.0012641062615115, 'IoU-121': 2.0810267292012252, 'IoU-122': 1.944586706627007, 'IoU-123': 2.0282223299389326, 'IoU-124': 2.0349000887973308, 'IoU-125': 1.91986591108628, 'IoU-126': 1.8484091596960257, 'IoU-127': 1.831234600714024, 'IoU-128': 1.9097589724548212, 'IoU-129': 1.8303469251632078, 'IoU-130': 1.8789983724013655, 'IoU-131': 1.9271087588875178, 'IoU-132': 1.739242581062241, 'IoU-133': 1.5971293384808638, 'IoU-134': 1.4823157375254854, 'IoU-135': 1.4876109119356093, 'IoU-136': 1.6462761357304863, 'IoU-137': 1.6043328851823722, 'IoU-138': 1.4235098416951548, 'IoU-139': 1.5268445032276816, 'IoU-140': 1.5998677967925243, 'IoU-141': 1.502245678898521, 'IoU-142': 1.6856956357431605, 'IoU-143': 1.5298090873087737, 'IoU-144': 1.3255294268413802, 'IoU-145': 1.1428508181842778, 'IoU-146': 1.2911056183815222, 'IoU-147': 1.4275210167460965, 'IoU-148': 1.477525100360641, 'IoU-149': 1.2936663201342764, 'IoU-150': 1.4093593046452777, 'IoU-151': 1.3563475892212837, 'IoU-152': 1.2773795775790489, 'IoU-153': 1.2918451158259978, 'IoU-154': 1.5251100824264259, 'IoU-155': 1.2424947525986134, 'IoU-156': 1.250380702211454, 'IoU-157': 1.3537383388720696, 'IoU-158': 1.1714704168824444, 'IoU-159': 1.1499128846304705, 'IoU-160': 1.084234963790159, 'IoU-161': 0.9960305997894168, 'IoU-162': 1.1059947720202892, 'IoU-163': 1.0223031717899267, 'IoU-164': 1.379289776832107, 'IoU-165': 1.3835605071999155, 'IoU-166': 1.0828716965158798, 'IoU-167': 1.3229334836893472, 'IoU-168': 1.0608536740494314, 'IoU-169': 0.8310017045973821, 'IoU-170': 0.5940659381637884, 'IoU-171': 0.6080524385880944, 'IoU-172': 0.5788329664157909, 'IoU-173': 0.5135473835344722, 'IoU-174': 0.7968202098324431, 'IoU-175': 0.7503347341349277, 'IoU-176': 0.7765453073713986, 'IoU-177': 0.5157486971664514, 'IoU-178': 0.29311265841438255, 'IoU-179': 0.12088678382941093, 'IoU-180': 0.12053107583934684, 'IoU-181': 0.030855313040320742, 'IoU-182': 0.015593831323349232, 'IoU-183': 0.020390145463718153, 'IoU-184': 0.005434333685478156, 'IoU-185': 0.0023931199975633687, 'IoU-186': 0.001626473410645036, 'IoU-187': 0.0009619431251127277, 'IoU-188': 0.0007533675529617389, 'IoU-189': 0.0010225157978690771, 'IoU-190': 0.0020876826722338207, 'IoU-191': 0.0005201452245466934, 'IoU-192': 0.0, 'mACC': 7.62497246666171, 'pACC': 13.465210187929621, 'ACC-0': 0.10627867750396404, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 8.960621691958258, 'ACC-7': 4.470722075762714, 'ACC-8': 8.909053962670184, 'ACC-9': 16.02024528090922, 'ACC-10': 18.167776557265242, 'ACC-11': 21.456177403437323, 'ACC-12': 21.440682753962754, 'ACC-13': 22.136683184592474, 'ACC-14': 22.845886571149574, 'ACC-15': 22.591435669194595, 'ACC-16': 21.973558618612355, 'ACC-17': 19.82255996512143, 'ACC-18': 17.929608188694075, 'ACC-19': 16.749339821163783, 'ACC-20': 17.57689487172918, 'ACC-21': 18.83079045690124, 'ACC-22': 19.528703722912287, 'ACC-23': 20.223068486608884, 'ACC-24': 21.478804795709046, 'ACC-25': 21.451643551077744, 'ACC-26': 20.167086299234857, 'ACC-27': 19.524251377388914, 'ACC-28': 19.740119342065572, 'ACC-29': 19.739231650455586, 'ACC-30': 21.210616387469376, 'ACC-31': 21.73505004664944, 'ACC-32': 21.301041738341546, 'ACC-33': 19.179394581710348, 'ACC-34': 18.001249439036773, 'ACC-35': 17.726122327931407, 'ACC-36': 16.131793472601625, 'ACC-37': 15.968623327273528, 'ACC-38': 15.933511707492434, 'ACC-39': 16.996435809792295, 'ACC-40': 17.02338696750831, 'ACC-41': 16.769183932047778, 'ACC-42': 16.174441792986244, 'ACC-43': 15.500711450972975, 'ACC-44': 15.613898715269631, 'ACC-45': 15.356566317779244, 'ACC-46': 14.818771977835437, 'ACC-47': 14.600196020787386, 'ACC-48': 14.505412238459497, 'ACC-49': 13.982070400178559, 'ACC-50': 13.632611949035518, 'ACC-51': 12.746665508277456, 'ACC-52': 12.822738608641481, 'ACC-53': 12.455207094489896, 'ACC-54': 11.857081431011828, 'ACC-55': 11.277382711122582, 'ACC-56': 11.209973100519832, 'ACC-57': 10.67902463979632, 'ACC-58': 10.000534734615089, 'ACC-59': 9.298526369458772, 'ACC-60': 8.598720835397545, 'ACC-61': 8.379439626159238, 'ACC-62': 8.382216760613042, 'ACC-63': 8.064543499978603, 'ACC-64': 8.197138314180654, 'ACC-65': 7.898374142570777, 'ACC-66': 7.797305900590171, 'ACC-67': 7.771964698876917, 'ACC-68': 7.678116769060182, 'ACC-69': 7.62202207003086, 'ACC-70': 7.512076077061533, 'ACC-71': 7.3900040079232285, 'ACC-72': 7.276959098843765, 'ACC-73': 7.386427484247717, 'ACC-74': 7.513512377118493, 'ACC-75': 7.5002921138009855, 'ACC-76': 7.272017694963109, 'ACC-77': 7.322951423464508, 'ACC-78': 7.443077484500382, 'ACC-79': 7.607004707994412, 'ACC-80': 7.671584157430475, 'ACC-81': 7.540317272904957, 'ACC-82': 7.91904525416242, 'ACC-83': 7.796960694164258, 'ACC-84': 7.698468857877379, 'ACC-85': 7.570258481219734, 'ACC-86': 7.264529759156184, 'ACC-87': 7.22804346528151, 'ACC-88': 7.2016333928029415, 'ACC-89': 6.958707176834249, 'ACC-90': 6.637325154601786, 'ACC-91': 6.415834853082175, 'ACC-92': 6.1814636149613875, 'ACC-93': 6.005163888491123, 'ACC-94': 6.135172399531932, 'ACC-95': 5.973466092064381, 'ACC-96': 5.8796952939356375, 'ACC-97': 6.044005054761918, 'ACC-98': 5.841169454283913, 'ACC-99': 5.560310149513232, 'ACC-100': 5.3634319347166235, 'ACC-101': 5.1895426353789995, 'ACC-102': 5.133076574535568, 'ACC-103': 4.992089354869179, 'ACC-104': 4.911413885541427, 'ACC-105': 4.962341187740883, 'ACC-106': 4.869940949832138, 'ACC-107': 4.767110948657363, 'ACC-108': 4.658294888911674, 'ACC-109': 4.795413748096338, 'ACC-110': 4.774271368162171, 'ACC-111': 5.161657903132496, 'ACC-112': 4.4512021375486395, 'ACC-113': 4.631819135452482, 'ACC-114': 4.6113024176046835, 'ACC-115': 4.484085817810053, 'ACC-116': 4.567192430013945, 'ACC-117': 4.637326040502216, 'ACC-118': 4.550662825707888, 'ACC-119': 4.118785161891061, 'ACC-120': 3.9484480474528865, 'ACC-121': 4.132898079465777, 'ACC-122': 3.8224970987007842, 'ACC-123': 4.030096571923682, 'ACC-124': 4.197216878580321, 'ACC-125': 3.9245651608776946, 'ACC-126': 3.7857243690743996, 'ACC-127': 3.7223504565036585, 'ACC-128': 4.0273646131010095, 'ACC-129': 3.9795828080416227, 'ACC-130': 4.064440818537699, 'ACC-131': 4.12165107957657, 'ACC-132': 3.5701599531386767, 'ACC-133': 3.2044608653643336, 'ACC-134': 2.9650667815596723, 'ACC-135': 3.0408756627330256, 'ACC-136': 3.3188565737979876, 'ACC-137': 3.2614469675229123, 'ACC-138': 2.919486856915319, 'ACC-139': 3.221635855783917, 'ACC-140': 3.42387977865995, 'ACC-141': 3.2634646635422553, 'ACC-142': 3.728020764013701, 'ACC-143': 3.4537417857377135, 'ACC-144': 2.9872797604327808, 'ACC-145': 2.493709597637868, 'ACC-146': 2.795828828820596, 'ACC-147': 3.1708979351558337, 'ACC-148': 3.270002889601995, 'ACC-149': 2.93661289079455, 'ACC-150': 3.153816568324875, 'ACC-151': 2.9527338766662083, 'ACC-152': 2.8204957994969724, 'ACC-153': 2.9750521607490077, 'ACC-154': 3.521450897417532, 'ACC-155': 2.930145132961514, 'ACC-156': 3.0836355174620413, 'ACC-157': 3.588252026932306, 'ACC-158': 3.2692071565772967, 'ACC-159': 3.2626848320739468, 'ACC-160': 3.1621838664434696, 'ACC-161': 3.002023441591905, 'ACC-162': 3.4977581143763334, 'ACC-163': 3.0605521865345486, 'ACC-164': 4.252944272858149, 'ACC-165': 4.3695495773068656, 'ACC-166': 3.9469288327264365, 'ACC-167': 4.532307740412426, 'ACC-168': 3.8416974500623287, 'ACC-169': 3.478202887564661, 'ACC-170': 2.205162059712935, 'ACC-171': 2.328951815550102, 'ACC-172': 2.00041486244717, 'ACC-173': 1.62989693437139, 'ACC-174': 2.5380256486728303, 'ACC-175': 1.8836075484814478, 'ACC-176': 1.5835413280705826, 'ACC-177': 0.8837994703477804, 'ACC-178': 0.4917811129783083, 'ACC-179': 0.19801980198019803, 'ACC-180': 0.17948495437737982, 'ACC-181': 0.03884598986214411, 'ACC-182': 0.018242684565030434, 'ACC-183': 0.022837231750815194, 'ACC-184': 0.005896073450924622, 'ACC-185': 0.002540568255830604, 'ACC-186': 0.001652471152575022, 'ACC-187': 0.0009664380235375981, 'ACC-188': 0.0007566318784143014, 'ACC-189': 0.001026912817669062, 'ACC-190': 0.002096090006104862, 'ACC-191': 0.0005220296512841929, 'ACC-192': 0.0})])
[01/29 06:03:15] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 06:03:15] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 06:03:15] d2.evaluation.testing INFO: copypaste: 5.8486,0.6366,0.3994,3.8946,7.3052,7.6250,13.4652
[01/29 06:03:15] d2.utils.events INFO:  eta: 1 day, 12:25:39  iter: 9999  total_loss: 70.72  loss_mask: 7.214  loss_mask_0: 7.108  loss_mask_1: 7.015  loss_mask_2: 6.999  loss_mask_3: 7.011  loss_mask_4: 6.995  loss_mask_5: 6.999  loss_mask_6: 6.964  loss_mask_7: 7.202  loss_mask_8: 7.217  time: 2.6062  data_time: 0.0551  lr: 8.4868e-05  max_mem: 27639M
[01/29 06:04:07] d2.utils.events INFO:  eta: 1 day, 12:25:18  iter: 10019  total_loss: 70.68  loss_mask: 7.221  loss_mask_0: 6.949  loss_mask_1: 6.968  loss_mask_2: 6.965  loss_mask_3: 6.988  loss_mask_4: 6.954  loss_mask_5: 6.977  loss_mask_6: 6.977  loss_mask_7: 7.245  loss_mask_8: 7.24  time: 2.6062  data_time: 0.0654  lr: 8.4838e-05  max_mem: 27639M
[01/29 06:04:59] d2.utils.events INFO:  eta: 1 day, 12:23:44  iter: 10039  total_loss: 66.08  loss_mask: 6.771  loss_mask_0: 6.648  loss_mask_1: 6.547  loss_mask_2: 6.512  loss_mask_3: 6.503  loss_mask_4: 6.518  loss_mask_5: 6.529  loss_mask_6: 6.519  loss_mask_7: 6.757  loss_mask_8: 6.773  time: 2.6062  data_time: 0.0503  lr: 8.4807e-05  max_mem: 27639M
[01/29 06:05:51] d2.utils.events INFO:  eta: 1 day, 12:22:28  iter: 10059  total_loss: 64.15  loss_mask: 6.586  loss_mask_0: 6.518  loss_mask_1: 6.305  loss_mask_2: 6.278  loss_mask_3: 6.287  loss_mask_4: 6.295  loss_mask_5: 6.275  loss_mask_6: 6.312  loss_mask_7: 6.572  loss_mask_8: 6.587  time: 2.6062  data_time: 0.0540  lr: 8.4776e-05  max_mem: 27639M
[01/29 06:06:44] d2.utils.events INFO:  eta: 1 day, 12:21:34  iter: 10079  total_loss: 68.35  loss_mask: 6.91  loss_mask_0: 6.865  loss_mask_1: 6.697  loss_mask_2: 6.728  loss_mask_3: 6.812  loss_mask_4: 6.787  loss_mask_5: 6.798  loss_mask_6: 6.816  loss_mask_7: 6.918  loss_mask_8: 6.924  time: 2.6062  data_time: 0.0546  lr: 8.4746e-05  max_mem: 27639M
[01/29 06:07:37] d2.utils.events INFO:  eta: 1 day, 12:20:33  iter: 10099  total_loss: 69.95  loss_mask: 7.099  loss_mask_0: 7.07  loss_mask_1: 6.942  loss_mask_2: 6.919  loss_mask_3: 6.925  loss_mask_4: 6.91  loss_mask_5: 6.937  loss_mask_6: 6.948  loss_mask_7: 7.075  loss_mask_8: 7.127  time: 2.6063  data_time: 0.0568  lr: 8.4715e-05  max_mem: 27639M
[01/29 06:08:29] d2.utils.events INFO:  eta: 1 day, 12:19:38  iter: 10119  total_loss: 67.42  loss_mask: 6.858  loss_mask_0: 6.789  loss_mask_1: 6.698  loss_mask_2: 6.647  loss_mask_3: 6.662  loss_mask_4: 6.649  loss_mask_5: 6.721  loss_mask_6: 6.686  loss_mask_7: 6.884  loss_mask_8: 6.895  time: 2.6063  data_time: 0.0628  lr: 8.4685e-05  max_mem: 27639M
[01/29 06:09:21] d2.utils.events INFO:  eta: 1 day, 12:18:38  iter: 10139  total_loss: 62.5  loss_mask: 6.417  loss_mask_0: 6.318  loss_mask_1: 6.159  loss_mask_2: 6.184  loss_mask_3: 6.133  loss_mask_4: 6.124  loss_mask_5: 6.131  loss_mask_6: 6.142  loss_mask_7: 6.402  loss_mask_8: 6.409  time: 2.6063  data_time: 0.0621  lr: 8.4654e-05  max_mem: 27639M
[01/29 06:10:14] d2.utils.events INFO:  eta: 1 day, 12:17:41  iter: 10159  total_loss: 66.41  loss_mask: 6.9  loss_mask_0: 6.783  loss_mask_1: 6.518  loss_mask_2: 6.517  loss_mask_3: 6.531  loss_mask_4: 6.522  loss_mask_5: 6.521  loss_mask_6: 6.535  loss_mask_7: 6.851  loss_mask_8: 6.861  time: 2.6063  data_time: 0.0557  lr: 8.4624e-05  max_mem: 27639M
[01/29 06:11:06] d2.utils.events INFO:  eta: 1 day, 12:16:45  iter: 10179  total_loss: 62.96  loss_mask: 6.556  loss_mask_0: 6.327  loss_mask_1: 6.214  loss_mask_2: 6.156  loss_mask_3: 6.149  loss_mask_4: 6.134  loss_mask_5: 6.156  loss_mask_6: 6.172  loss_mask_7: 6.551  loss_mask_8: 6.545  time: 2.6063  data_time: 0.0501  lr: 8.4593e-05  max_mem: 27639M
[01/29 06:11:59] d2.utils.events INFO:  eta: 1 day, 12:15:33  iter: 10199  total_loss: 68.26  loss_mask: 6.926  loss_mask_0: 6.877  loss_mask_1: 6.751  loss_mask_2: 6.759  loss_mask_3: 6.776  loss_mask_4: 6.77  loss_mask_5: 6.786  loss_mask_6: 6.781  loss_mask_7: 6.938  loss_mask_8: 6.937  time: 2.6064  data_time: 0.0546  lr: 8.4563e-05  max_mem: 27639M
[01/29 06:12:51] d2.utils.events INFO:  eta: 1 day, 12:14:53  iter: 10219  total_loss: 64.75  loss_mask: 6.749  loss_mask_0: 6.474  loss_mask_1: 6.375  loss_mask_2: 6.395  loss_mask_3: 6.388  loss_mask_4: 6.384  loss_mask_5: 6.383  loss_mask_6: 6.372  loss_mask_7: 6.765  loss_mask_8: 6.759  time: 2.6064  data_time: 0.0566  lr: 8.4532e-05  max_mem: 27639M
[01/29 06:13:44] d2.utils.events INFO:  eta: 1 day, 12:13:46  iter: 10239  total_loss: 64.82  loss_mask: 6.778  loss_mask_0: 6.514  loss_mask_1: 6.3  loss_mask_2: 6.32  loss_mask_3: 6.334  loss_mask_4: 6.324  loss_mask_5: 6.337  loss_mask_6: 6.378  loss_mask_7: 6.788  loss_mask_8: 6.78  time: 2.6064  data_time: 0.0558  lr: 8.4501e-05  max_mem: 27639M
[01/29 06:14:36] d2.utils.events INFO:  eta: 1 day, 12:12:32  iter: 10259  total_loss: 71.15  loss_mask: 7.301  loss_mask_0: 7.152  loss_mask_1: 7.062  loss_mask_2: 6.983  loss_mask_3: 6.994  loss_mask_4: 7.002  loss_mask_5: 7.047  loss_mask_6: 7.042  loss_mask_7: 7.334  loss_mask_8: 7.265  time: 2.6065  data_time: 0.0590  lr: 8.4471e-05  max_mem: 27639M
[01/29 06:15:28] d2.utils.events INFO:  eta: 1 day, 12:11:39  iter: 10279  total_loss: 63.43  loss_mask: 6.465  loss_mask_0: 6.353  loss_mask_1: 6.254  loss_mask_2: 6.262  loss_mask_3: 6.274  loss_mask_4: 6.295  loss_mask_5: 6.273  loss_mask_6: 6.281  loss_mask_7: 6.451  loss_mask_8: 6.465  time: 2.6065  data_time: 0.0541  lr: 8.444e-05  max_mem: 27639M
[01/29 06:16:21] d2.utils.events INFO:  eta: 1 day, 12:10:52  iter: 10299  total_loss: 63.95  loss_mask: 6.628  loss_mask_0: 6.386  loss_mask_1: 6.273  loss_mask_2: 6.323  loss_mask_3: 6.332  loss_mask_4: 6.33  loss_mask_5: 6.295  loss_mask_6: 6.276  loss_mask_7: 6.634  loss_mask_8: 6.624  time: 2.6065  data_time: 0.0579  lr: 8.441e-05  max_mem: 27639M
[01/29 06:17:13] d2.utils.events INFO:  eta: 1 day, 12:09:50  iter: 10319  total_loss: 66.12  loss_mask: 6.868  loss_mask_0: 6.714  loss_mask_1: 6.461  loss_mask_2: 6.473  loss_mask_3: 6.482  loss_mask_4: 6.497  loss_mask_5: 6.48  loss_mask_6: 6.548  loss_mask_7: 6.887  loss_mask_8: 6.875  time: 2.6065  data_time: 0.0535  lr: 8.4379e-05  max_mem: 27639M
[01/29 06:18:06] d2.utils.events INFO:  eta: 1 day, 12:08:53  iter: 10339  total_loss: 61.85  loss_mask: 6.323  loss_mask_0: 6.173  loss_mask_1: 6.144  loss_mask_2: 6.108  loss_mask_3: 6.1  loss_mask_4: 6.116  loss_mask_5: 6.127  loss_mask_6: 6.129  loss_mask_7: 6.309  loss_mask_8: 6.318  time: 2.6066  data_time: 0.0521  lr: 8.4349e-05  max_mem: 27639M
[01/29 06:18:58] d2.utils.events INFO:  eta: 1 day, 12:07:25  iter: 10359  total_loss: 66.83  loss_mask: 6.913  loss_mask_0: 6.561  loss_mask_1: 6.597  loss_mask_2: 6.603  loss_mask_3: 6.588  loss_mask_4: 6.578  loss_mask_5: 6.593  loss_mask_6: 6.599  loss_mask_7: 6.889  loss_mask_8: 6.909  time: 2.6066  data_time: 0.0580  lr: 8.4318e-05  max_mem: 27639M
[01/29 06:19:50] d2.utils.events INFO:  eta: 1 day, 12:06:03  iter: 10379  total_loss: 65.73  loss_mask: 6.588  loss_mask_0: 6.757  loss_mask_1: 6.496  loss_mask_2: 6.49  loss_mask_3: 6.457  loss_mask_4: 6.464  loss_mask_5: 6.466  loss_mask_6: 6.48  loss_mask_7: 6.672  loss_mask_8: 6.619  time: 2.6066  data_time: 0.0575  lr: 8.4287e-05  max_mem: 27639M
[01/29 06:20:43] d2.utils.events INFO:  eta: 1 day, 12:04:15  iter: 10399  total_loss: 65.18  loss_mask: 6.735  loss_mask_0: 6.441  loss_mask_1: 6.322  loss_mask_2: 6.345  loss_mask_3: 6.369  loss_mask_4: 6.373  loss_mask_5: 6.376  loss_mask_6: 6.335  loss_mask_7: 6.765  loss_mask_8: 6.728  time: 2.6066  data_time: 0.0517  lr: 8.4257e-05  max_mem: 27639M
[01/29 06:21:35] d2.utils.events INFO:  eta: 1 day, 12:03:20  iter: 10419  total_loss: 67.08  loss_mask: 6.881  loss_mask_0: 6.717  loss_mask_1: 6.61  loss_mask_2: 6.637  loss_mask_3: 6.634  loss_mask_4: 6.643  loss_mask_5: 6.625  loss_mask_6: 6.633  loss_mask_7: 6.909  loss_mask_8: 6.897  time: 2.6066  data_time: 0.0570  lr: 8.4226e-05  max_mem: 27639M
[01/29 06:22:27] d2.utils.events INFO:  eta: 1 day, 12:02:41  iter: 10439  total_loss: 68.52  loss_mask: 7.026  loss_mask_0: 6.727  loss_mask_1: 6.703  loss_mask_2: 6.751  loss_mask_3: 6.74  loss_mask_4: 6.77  loss_mask_5: 6.751  loss_mask_6: 6.7  loss_mask_7: 7.033  loss_mask_8: 6.99  time: 2.6067  data_time: 0.0632  lr: 8.4196e-05  max_mem: 27639M
[01/29 06:23:20] d2.utils.events INFO:  eta: 1 day, 12:01:57  iter: 10459  total_loss: 63.79  loss_mask: 6.617  loss_mask_0: 6.322  loss_mask_1: 6.241  loss_mask_2: 6.264  loss_mask_3: 6.263  loss_mask_4: 6.264  loss_mask_5: 6.3  loss_mask_6: 6.257  loss_mask_7: 6.634  loss_mask_8: 6.597  time: 2.6067  data_time: 0.0559  lr: 8.4165e-05  max_mem: 27639M
[01/29 06:24:12] d2.utils.events INFO:  eta: 1 day, 12:00:45  iter: 10479  total_loss: 66.55  loss_mask: 6.804  loss_mask_0: 6.749  loss_mask_1: 6.589  loss_mask_2: 6.566  loss_mask_3: 6.54  loss_mask_4: 6.543  loss_mask_5: 6.537  loss_mask_6: 6.558  loss_mask_7: 6.856  loss_mask_8: 6.812  time: 2.6067  data_time: 0.0521  lr: 8.4135e-05  max_mem: 27639M
[01/29 06:25:04] d2.utils.events INFO:  eta: 1 day, 11:59:46  iter: 10499  total_loss: 60.84  loss_mask: 6.326  loss_mask_0: 6.12  loss_mask_1: 5.975  loss_mask_2: 5.985  loss_mask_3: 5.985  loss_mask_4: 5.989  loss_mask_5: 6.028  loss_mask_6: 6.054  loss_mask_7: 6.297  loss_mask_8: 6.343  time: 2.6067  data_time: 0.0493  lr: 8.4104e-05  max_mem: 27639M
[01/29 06:25:57] d2.utils.events INFO:  eta: 1 day, 11:58:50  iter: 10519  total_loss: 63.43  loss_mask: 6.476  loss_mask_0: 6.332  loss_mask_1: 6.265  loss_mask_2: 6.266  loss_mask_3: 6.28  loss_mask_4: 6.26  loss_mask_5: 6.255  loss_mask_6: 6.259  loss_mask_7: 6.498  loss_mask_8: 6.5  time: 2.6067  data_time: 0.0582  lr: 8.4073e-05  max_mem: 27639M
[01/29 06:26:49] d2.utils.events INFO:  eta: 1 day, 11:57:09  iter: 10539  total_loss: 64.62  loss_mask: 6.644  loss_mask_0: 6.593  loss_mask_1: 6.361  loss_mask_2: 6.377  loss_mask_3: 6.381  loss_mask_4: 6.371  loss_mask_5: 6.38  loss_mask_6: 6.373  loss_mask_7: 6.619  loss_mask_8: 6.604  time: 2.6067  data_time: 0.0490  lr: 8.4043e-05  max_mem: 27639M
[01/29 06:27:41] d2.utils.events INFO:  eta: 1 day, 11:55:38  iter: 10559  total_loss: 63.84  loss_mask: 6.452  loss_mask_0: 6.4  loss_mask_1: 6.297  loss_mask_2: 6.308  loss_mask_3: 6.326  loss_mask_4: 6.332  loss_mask_5: 6.35  loss_mask_6: 6.328  loss_mask_7: 6.464  loss_mask_8: 6.479  time: 2.6067  data_time: 0.0539  lr: 8.4012e-05  max_mem: 27639M
[01/29 06:28:34] d2.utils.events INFO:  eta: 1 day, 11:54:41  iter: 10579  total_loss: 60.77  loss_mask: 6.2  loss_mask_0: 6.076  loss_mask_1: 6.028  loss_mask_2: 6.026  loss_mask_3: 6.013  loss_mask_4: 5.997  loss_mask_5: 5.971  loss_mask_6: 5.994  loss_mask_7: 6.209  loss_mask_8: 6.23  time: 2.6068  data_time: 0.0566  lr: 8.3982e-05  max_mem: 27639M
[01/29 06:29:26] d2.utils.events INFO:  eta: 1 day, 11:53:24  iter: 10599  total_loss: 60.25  loss_mask: 6.277  loss_mask_0: 6.072  loss_mask_1: 5.931  loss_mask_2: 5.896  loss_mask_3: 5.875  loss_mask_4: 5.875  loss_mask_5: 5.892  loss_mask_6: 5.894  loss_mask_7: 6.285  loss_mask_8: 6.281  time: 2.6068  data_time: 0.0565  lr: 8.3951e-05  max_mem: 27639M
[01/29 06:30:18] d2.utils.events INFO:  eta: 1 day, 11:52:32  iter: 10619  total_loss: 60.75  loss_mask: 6.239  loss_mask_0: 5.994  loss_mask_1: 6.023  loss_mask_2: 6.01  loss_mask_3: 5.969  loss_mask_4: 5.992  loss_mask_5: 5.984  loss_mask_6: 5.991  loss_mask_7: 6.275  loss_mask_8: 6.251  time: 2.6068  data_time: 0.0547  lr: 8.392e-05  max_mem: 27639M
[01/29 06:31:11] d2.utils.events INFO:  eta: 1 day, 11:50:58  iter: 10639  total_loss: 65.21  loss_mask: 6.678  loss_mask_0: 6.601  loss_mask_1: 6.407  loss_mask_2: 6.384  loss_mask_3: 6.387  loss_mask_4: 6.391  loss_mask_5: 6.421  loss_mask_6: 6.419  loss_mask_7: 6.69  loss_mask_8: 6.678  time: 2.6068  data_time: 0.0578  lr: 8.389e-05  max_mem: 27639M
[01/29 06:32:03] d2.utils.events INFO:  eta: 1 day, 11:49:51  iter: 10659  total_loss: 61.13  loss_mask: 6.248  loss_mask_0: 6.114  loss_mask_1: 6.03  loss_mask_2: 6.034  loss_mask_3: 6.03  loss_mask_4: 6.011  loss_mask_5: 6.007  loss_mask_6: 6.019  loss_mask_7: 6.257  loss_mask_8: 6.257  time: 2.6068  data_time: 0.0591  lr: 8.3859e-05  max_mem: 27639M
[01/29 06:32:55] d2.utils.events INFO:  eta: 1 day, 11:48:33  iter: 10679  total_loss: 68.81  loss_mask: 7.049  loss_mask_0: 6.795  loss_mask_1: 6.756  loss_mask_2: 6.784  loss_mask_3: 6.805  loss_mask_4: 6.831  loss_mask_5: 6.817  loss_mask_6: 6.792  loss_mask_7: 7.048  loss_mask_8: 7.062  time: 2.6068  data_time: 0.0516  lr: 8.3829e-05  max_mem: 27639M
[01/29 06:33:48] d2.utils.events INFO:  eta: 1 day, 11:47:28  iter: 10699  total_loss: 62.02  loss_mask: 6.351  loss_mask_0: 6.189  loss_mask_1: 6.14  loss_mask_2: 6.123  loss_mask_3: 6.12  loss_mask_4: 6.088  loss_mask_5: 6.116  loss_mask_6: 6.094  loss_mask_7: 6.355  loss_mask_8: 6.354  time: 2.6068  data_time: 0.0530  lr: 8.3798e-05  max_mem: 27639M
[01/29 06:34:40] d2.utils.events INFO:  eta: 1 day, 11:46:03  iter: 10719  total_loss: 61.43  loss_mask: 6.365  loss_mask_0: 6.131  loss_mask_1: 6.06  loss_mask_2: 6.056  loss_mask_3: 6.066  loss_mask_4: 6.057  loss_mask_5: 6.047  loss_mask_6: 6.027  loss_mask_7: 6.347  loss_mask_8: 6.346  time: 2.6068  data_time: 0.0526  lr: 8.3767e-05  max_mem: 27639M
[01/29 06:35:32] d2.utils.events INFO:  eta: 1 day, 11:45:11  iter: 10739  total_loss: 61.35  loss_mask: 6.282  loss_mask_0: 6.253  loss_mask_1: 6.051  loss_mask_2: 6.052  loss_mask_3: 6.07  loss_mask_4: 6.052  loss_mask_5: 6.053  loss_mask_6: 6.048  loss_mask_7: 6.303  loss_mask_8: 6.3  time: 2.6068  data_time: 0.0600  lr: 8.3737e-05  max_mem: 27639M
[01/29 06:36:24] d2.utils.events INFO:  eta: 1 day, 11:43:52  iter: 10759  total_loss: 64.36  loss_mask: 6.627  loss_mask_0: 6.336  loss_mask_1: 6.323  loss_mask_2: 6.363  loss_mask_3: 6.446  loss_mask_4: 6.384  loss_mask_5: 6.337  loss_mask_6: 6.318  loss_mask_7: 6.591  loss_mask_8: 6.589  time: 2.6068  data_time: 0.0572  lr: 8.3706e-05  max_mem: 27639M
[01/29 06:37:16] d2.utils.events INFO:  eta: 1 day, 11:42:38  iter: 10779  total_loss: 62.29  loss_mask: 6.351  loss_mask_0: 6.207  loss_mask_1: 6.191  loss_mask_2: 6.188  loss_mask_3: 6.261  loss_mask_4: 6.178  loss_mask_5: 6.18  loss_mask_6: 6.201  loss_mask_7: 6.337  loss_mask_8: 6.345  time: 2.6068  data_time: 0.0525  lr: 8.3676e-05  max_mem: 27639M
[01/29 06:38:09] d2.utils.events INFO:  eta: 1 day, 11:41:34  iter: 10799  total_loss: 60.38  loss_mask: 6.131  loss_mask_0: 6.191  loss_mask_1: 5.978  loss_mask_2: 5.959  loss_mask_3: 5.987  loss_mask_4: 5.968  loss_mask_5: 5.966  loss_mask_6: 5.938  loss_mask_7: 6.134  loss_mask_8: 6.132  time: 2.6068  data_time: 0.0557  lr: 8.3645e-05  max_mem: 27639M
[01/29 06:39:01] d2.utils.events INFO:  eta: 1 day, 11:40:42  iter: 10819  total_loss: 68.82  loss_mask: 7.049  loss_mask_0: 6.794  loss_mask_1: 6.794  loss_mask_2: 6.761  loss_mask_3: 6.79  loss_mask_4: 6.748  loss_mask_5: 6.773  loss_mask_6: 6.758  loss_mask_7: 7.041  loss_mask_8: 7.044  time: 2.6069  data_time: 0.0581  lr: 8.3614e-05  max_mem: 27639M
[01/29 06:39:53] d2.utils.events INFO:  eta: 1 day, 11:39:41  iter: 10839  total_loss: 60.97  loss_mask: 6.368  loss_mask_0: 6.203  loss_mask_1: 6.029  loss_mask_2: 5.987  loss_mask_3: 6.033  loss_mask_4: 5.975  loss_mask_5: 5.969  loss_mask_6: 5.99  loss_mask_7: 6.362  loss_mask_8: 6.367  time: 2.6069  data_time: 0.0555  lr: 8.3584e-05  max_mem: 27639M
[01/29 06:40:45] d2.utils.events INFO:  eta: 1 day, 11:38:05  iter: 10859  total_loss: 58.14  loss_mask: 6.045  loss_mask_0: 5.827  loss_mask_1: 5.715  loss_mask_2: 5.66  loss_mask_3: 5.702  loss_mask_4: 5.693  loss_mask_5: 5.71  loss_mask_6: 5.712  loss_mask_7: 6.058  loss_mask_8: 6.021  time: 2.6068  data_time: 0.0563  lr: 8.3553e-05  max_mem: 27639M
[01/29 06:41:37] d2.utils.events INFO:  eta: 1 day, 11:36:36  iter: 10879  total_loss: 61.58  loss_mask: 6.325  loss_mask_0: 6.116  loss_mask_1: 6.111  loss_mask_2: 6.115  loss_mask_3: 6.081  loss_mask_4: 6.087  loss_mask_5: 6.074  loss_mask_6: 6.075  loss_mask_7: 6.335  loss_mask_8: 6.349  time: 2.6069  data_time: 0.0603  lr: 8.3523e-05  max_mem: 27639M
[01/29 06:42:30] d2.utils.events INFO:  eta: 1 day, 11:35:36  iter: 10899  total_loss: 61.9  loss_mask: 6.352  loss_mask_0: 6.231  loss_mask_1: 6.094  loss_mask_2: 6.093  loss_mask_3: 6.095  loss_mask_4: 6.052  loss_mask_5: 6.094  loss_mask_6: 6.06  loss_mask_7: 6.371  loss_mask_8: 6.379  time: 2.6069  data_time: 0.0551  lr: 8.3492e-05  max_mem: 27639M
[01/29 06:43:22] d2.utils.events INFO:  eta: 1 day, 11:34:38  iter: 10919  total_loss: 61.57  loss_mask: 6.347  loss_mask_0: 6.127  loss_mask_1: 6.074  loss_mask_2: 6.036  loss_mask_3: 6.041  loss_mask_4: 6.052  loss_mask_5: 6.066  loss_mask_6: 6.046  loss_mask_7: 6.353  loss_mask_8: 6.354  time: 2.6069  data_time: 0.0525  lr: 8.3461e-05  max_mem: 27639M
[01/29 06:44:14] d2.utils.events INFO:  eta: 1 day, 11:33:43  iter: 10939  total_loss: 61.59  loss_mask: 6.319  loss_mask_0: 6.068  loss_mask_1: 6.065  loss_mask_2: 6.085  loss_mask_3: 6.068  loss_mask_4: 6.061  loss_mask_5: 6.1  loss_mask_6: 6.081  loss_mask_7: 6.289  loss_mask_8: 6.31  time: 2.6069  data_time: 0.0569  lr: 8.3431e-05  max_mem: 27639M
[01/29 06:45:06] d2.utils.events INFO:  eta: 1 day, 11:32:44  iter: 10959  total_loss: 57.95  loss_mask: 5.944  loss_mask_0: 5.781  loss_mask_1: 5.746  loss_mask_2: 5.738  loss_mask_3: 5.752  loss_mask_4: 5.731  loss_mask_5: 5.713  loss_mask_6: 5.735  loss_mask_7: 5.925  loss_mask_8: 5.944  time: 2.6069  data_time: 0.0566  lr: 8.34e-05  max_mem: 27639M
[01/29 06:45:59] d2.utils.events INFO:  eta: 1 day, 11:31:42  iter: 10979  total_loss: 60.46  loss_mask: 6.241  loss_mask_0: 6.05  loss_mask_1: 5.971  loss_mask_2: 5.931  loss_mask_3: 5.949  loss_mask_4: 5.938  loss_mask_5: 5.942  loss_mask_6: 5.948  loss_mask_7: 6.237  loss_mask_8: 6.225  time: 2.6069  data_time: 0.0600  lr: 8.337e-05  max_mem: 27639M
[01/29 06:46:51] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 06:46:52] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 06:46:52] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 07:01:01] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 5.316087894459342, 'error_1pix': 0.6096809241763181, 'error_3pix': 0.3688348112307327, 'mIoU': 4.339365082946565, 'fwIoU': 8.032094142710875, 'IoU-0': 1.550885924198124e-05, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.08282318233571949, 'IoU-7': 0.3439966627624747, 'IoU-8': 1.8697846681858525, 'IoU-9': 7.170095707512554, 'IoU-10': 10.22962075394881, 'IoU-11': 15.510791413894287, 'IoU-12': 14.772465624832055, 'IoU-13': 13.816381647491937, 'IoU-14': 14.193781172574893, 'IoU-15': 12.523058740548063, 'IoU-16': 12.131564513557171, 'IoU-17': 10.2364437282525, 'IoU-18': 10.076163129168842, 'IoU-19': 11.03359570065143, 'IoU-20': 11.021999036031792, 'IoU-21': 11.636800768242733, 'IoU-22': 12.366990497945409, 'IoU-23': 12.327914091045555, 'IoU-24': 12.65849774917994, 'IoU-25': 12.592311571358827, 'IoU-26': 11.57377886055508, 'IoU-27': 12.147787556202962, 'IoU-28': 11.716235066435248, 'IoU-29': 11.965137527855955, 'IoU-30': 12.142994943217635, 'IoU-31': 12.573348729302596, 'IoU-32': 12.067291308464466, 'IoU-33': 10.66549935558464, 'IoU-34': 9.691072306384505, 'IoU-35': 9.869242336637862, 'IoU-36': 9.587994645135982, 'IoU-37': 9.538186432663965, 'IoU-38': 9.739705135949054, 'IoU-39': 9.829673731290118, 'IoU-40': 9.330450854494497, 'IoU-41': 8.672895833798364, 'IoU-42': 8.279589666870102, 'IoU-43': 8.28914361441134, 'IoU-44': 8.531639265204852, 'IoU-45': 8.256498078453218, 'IoU-46': 7.929781047420372, 'IoU-47': 7.99422011024485, 'IoU-48': 8.135151174713224, 'IoU-49': 8.192731031061061, 'IoU-50': 8.452776281200606, 'IoU-51': 8.136298894050725, 'IoU-52': 8.153077487238896, 'IoU-53': 7.764051650112503, 'IoU-54': 7.593137090885923, 'IoU-55': 7.440455708647187, 'IoU-56': 7.050338486548551, 'IoU-57': 6.988298155328161, 'IoU-58': 6.8345083237921465, 'IoU-59': 6.492555725127809, 'IoU-60': 6.2937499261311665, 'IoU-61': 6.112447323582268, 'IoU-62': 6.083355938081051, 'IoU-63': 5.872088002768899, 'IoU-64': 5.914248672997505, 'IoU-65': 5.546831211668386, 'IoU-66': 5.447370960695167, 'IoU-67': 5.126914588229985, 'IoU-68': 4.944067656620446, 'IoU-69': 4.915964121348024, 'IoU-70': 5.085704335127894, 'IoU-71': 4.866028692747817, 'IoU-72': 4.762582359497385, 'IoU-73': 4.763504957072941, 'IoU-74': 4.869203760330298, 'IoU-75': 4.786476789352007, 'IoU-76': 4.716300823949629, 'IoU-77': 4.525494684545627, 'IoU-78': 4.506340617410108, 'IoU-79': 4.526626208277636, 'IoU-80': 4.562269761274671, 'IoU-81': 4.4986038334751015, 'IoU-82': 4.519679778892771, 'IoU-83': 4.621576534063266, 'IoU-84': 4.452260630306084, 'IoU-85': 4.455797298525544, 'IoU-86': 4.385739178098951, 'IoU-87': 4.328378129036226, 'IoU-88': 4.476405627281264, 'IoU-89': 4.376883003493942, 'IoU-90': 4.422105111247397, 'IoU-91': 4.181585383778904, 'IoU-92': 4.196616330931394, 'IoU-93': 4.183308390866015, 'IoU-94': 4.135005962463115, 'IoU-95': 4.044148070646183, 'IoU-96': 3.878859717706524, 'IoU-97': 4.0236404777429575, 'IoU-98': 3.8014525703562887, 'IoU-99': 3.7115584631508733, 'IoU-100': 3.590478114755444, 'IoU-101': 3.563456157208958, 'IoU-102': 3.4184426709389504, 'IoU-103': 3.6310630536348523, 'IoU-104': 3.5863408526468485, 'IoU-105': 3.5070998990697264, 'IoU-106': 3.542773984691879, 'IoU-107': 3.314104929402916, 'IoU-108': 3.4589981070295437, 'IoU-109': 3.3355359855391176, 'IoU-110': 3.139634822971641, 'IoU-111': 2.9348699625279915, 'IoU-112': 2.750031287150962, 'IoU-113': 2.540098889230656, 'IoU-114': 2.409683595606116, 'IoU-115': 2.3867889197995322, 'IoU-116': 2.428557177785014, 'IoU-117': 2.4281059739306525, 'IoU-118': 2.4543668904833655, 'IoU-119': 2.1936262746954136, 'IoU-120': 2.2799141817507316, 'IoU-121': 2.2163916698813377, 'IoU-122': 2.0392150529696207, 'IoU-123': 2.0086424596938093, 'IoU-124': 1.8789118340966724, 'IoU-125': 1.895892158838039, 'IoU-126': 1.917019857400207, 'IoU-127': 1.6981301207554824, 'IoU-128': 1.6313238889134878, 'IoU-129': 1.4618137435866527, 'IoU-130': 1.6932769888119308, 'IoU-131': 1.683913983376652, 'IoU-132': 1.6109710179518049, 'IoU-133': 1.363946397521424, 'IoU-134': 1.383796211837416, 'IoU-135': 1.5168515159553495, 'IoU-136': 1.496516960294696, 'IoU-137': 1.3614153552864252, 'IoU-138': 1.2780414232283914, 'IoU-139': 1.2140469321652576, 'IoU-140': 1.2666091307652025, 'IoU-141': 1.2305630858469332, 'IoU-142': 1.172446406721506, 'IoU-143': 1.061529887407664, 'IoU-144': 0.9198619759022326, 'IoU-145': 0.9833863794877301, 'IoU-146': 1.0514267397419514, 'IoU-147': 1.1193766568891308, 'IoU-148': 1.1702607075683304, 'IoU-149': 1.150696122959058, 'IoU-150': 1.2617122065943431, 'IoU-151': 1.1447012466567317, 'IoU-152': 1.19764983469275, 'IoU-153': 1.1515629977424136, 'IoU-154': 1.2520060658459176, 'IoU-155': 1.178040435564801, 'IoU-156': 1.1559494851091043, 'IoU-157': 1.0523325605476088, 'IoU-158': 1.0607846227355122, 'IoU-159': 1.0090307436507677, 'IoU-160': 1.0553634506400693, 'IoU-161': 1.056827983697761, 'IoU-162': 1.0953576664799087, 'IoU-163': 1.0117253750245903, 'IoU-164': 0.85670899632369, 'IoU-165': 0.9653488366817814, 'IoU-166': 0.9064815719740684, 'IoU-167': 0.9613578578463934, 'IoU-168': 1.0601759874301064, 'IoU-169': 0.9274952673491419, 'IoU-170': 0.6868707444703243, 'IoU-171': 0.7118991266548848, 'IoU-172': 0.7759424598594735, 'IoU-173': 0.7600190619667645, 'IoU-174': 0.5916628675632551, 'IoU-175': 0.08053709330028902, 'IoU-176': 0.010096590717867601, 'IoU-177': 0.007755307425797039, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 8.476845309746945, 'pACC': 14.640228408551975, 'ACC-0': 1.5508878483982313e-05, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 30.202453448124217, 'ACC-7': 7.741083897597456, 'ACC-8': 13.095916239435823, 'ACC-9': 22.917033451383958, 'ACC-10': 23.334752646718144, 'ACC-11': 26.471525850840433, 'ACC-12': 24.48477642729848, 'ACC-13': 22.950687296787102, 'ACC-14': 24.25059845375094, 'ACC-15': 22.370438092980624, 'ACC-16': 21.213826185398982, 'ACC-17': 18.515935615285628, 'ACC-18': 17.145325949285386, 'ACC-19': 18.481224942638562, 'ACC-20': 18.771061520331386, 'ACC-21': 20.093512770772133, 'ACC-22': 21.19443217132281, 'ACC-23': 22.827357682804212, 'ACC-24': 23.749923490491163, 'ACC-25': 23.387032596639333, 'ACC-26': 21.219547611209897, 'ACC-27': 21.32766165728765, 'ACC-28': 21.097656736211544, 'ACC-29': 21.41287597962333, 'ACC-30': 22.511784015993964, 'ACC-31': 23.211267738442544, 'ACC-32': 22.662836884554505, 'ACC-33': 20.35090616901171, 'ACC-34': 18.50850936290243, 'ACC-35': 18.216179064003278, 'ACC-36': 17.23398550904145, 'ACC-37': 17.226283843236395, 'ACC-38': 17.639121930165107, 'ACC-39': 17.9853851470708, 'ACC-40': 17.032103618554455, 'ACC-41': 16.30074802721548, 'ACC-42': 15.473282460828477, 'ACC-43': 15.35406331653348, 'ACC-44': 15.333683144202192, 'ACC-45': 14.966246154892879, 'ACC-46': 14.6972002115222, 'ACC-47': 14.772624790081945, 'ACC-48': 14.966893405738357, 'ACC-49': 14.923975748988328, 'ACC-50': 15.33954705458894, 'ACC-51': 14.996846607146377, 'ACC-52': 15.055820113009469, 'ACC-53': 14.344961490249919, 'ACC-54': 13.91986789956818, 'ACC-55': 13.70387386239088, 'ACC-56': 13.207889750289803, 'ACC-57': 12.89509151663336, 'ACC-58': 12.737787201667263, 'ACC-59': 12.177103995761506, 'ACC-60': 11.895904002030901, 'ACC-61': 11.733273857857174, 'ACC-62': 11.786911252044305, 'ACC-63': 11.558654545669185, 'ACC-64': 11.650155014559092, 'ACC-65': 10.994313727720689, 'ACC-66': 10.834388443973115, 'ACC-67': 10.218192144600332, 'ACC-68': 9.847209593754494, 'ACC-69': 9.600426393747552, 'ACC-70': 9.872656321815223, 'ACC-71': 9.67701210701541, 'ACC-72': 9.534459088046027, 'ACC-73': 9.5512446250258, 'ACC-74': 9.68782348525705, 'ACC-75': 9.538962520980323, 'ACC-76': 9.254524034349492, 'ACC-77': 9.00788129437581, 'ACC-78': 9.007064020304483, 'ACC-79': 9.003219266188193, 'ACC-80': 8.967149020079217, 'ACC-81': 8.79164602993628, 'ACC-82': 8.890346038210266, 'ACC-83': 8.971662909140809, 'ACC-84': 8.7131662389519, 'ACC-85': 8.77099792479932, 'ACC-86': 8.672022255596659, 'ACC-87': 8.610142127398847, 'ACC-88': 8.901110986125085, 'ACC-89': 8.653315526802242, 'ACC-90': 8.649951397083095, 'ACC-91': 8.168229324997462, 'ACC-92': 8.201980575903045, 'ACC-93': 8.104761538564663, 'ACC-94': 7.943859156163104, 'ACC-95': 7.745908477062604, 'ACC-96': 7.508323662014941, 'ACC-97': 7.6744071774742935, 'ACC-98': 7.294034262721788, 'ACC-99': 7.171956800603514, 'ACC-100': 6.963889949859993, 'ACC-101': 6.9990594441607294, 'ACC-102': 6.792705029451744, 'ACC-103': 7.229597619722301, 'ACC-104': 7.275448218194339, 'ACC-105': 7.1979397024837635, 'ACC-106': 7.216135571780214, 'ACC-107': 6.75648038153423, 'ACC-108': 7.003264125544055, 'ACC-109': 6.76294113394653, 'ACC-110': 6.415722897570103, 'ACC-111': 5.958166412348189, 'ACC-112': 5.66752016464036, 'ACC-113': 5.243428159260396, 'ACC-114': 5.026900539614292, 'ACC-115': 4.9874084765384215, 'ACC-116': 5.0711690622882575, 'ACC-117': 5.019420136346796, 'ACC-118': 5.1006068362180415, 'ACC-119': 4.548158575223125, 'ACC-120': 4.7079085801031, 'ACC-121': 4.5356002628964855, 'ACC-122': 4.169898195061659, 'ACC-123': 4.06947139059228, 'ACC-124': 3.90154818520687, 'ACC-125': 3.9047144599032158, 'ACC-126': 4.001516407253254, 'ACC-127': 3.5295512526983717, 'ACC-128': 3.415149086890818, 'ACC-129': 3.0439412660591794, 'ACC-130': 3.4899379067853666, 'ACC-131': 3.490167227903261, 'ACC-132': 3.288730718835976, 'ACC-133': 2.7471473187858497, 'ACC-134': 2.7399913830245586, 'ACC-135': 3.0154352659483497, 'ACC-136': 2.988725307491614, 'ACC-137': 2.799383613554091, 'ACC-138': 2.661687438129807, 'ACC-139': 2.585851397782994, 'ACC-140': 2.646238862191831, 'ACC-141': 2.5705264256344056, 'ACC-142': 2.4141945276277856, 'ACC-143': 2.1805215962934907, 'ACC-144': 1.8530685920577616, 'ACC-145': 1.900579172163957, 'ACC-146': 1.9903589134358364, 'ACC-147': 2.062242393798231, 'ACC-148': 2.1746094058177787, 'ACC-149': 2.239701278510936, 'ACC-150': 2.518529636474121, 'ACC-151': 2.309431163092585, 'ACC-152': 2.3821565850697954, 'ACC-153': 2.3802653035050114, 'ACC-154': 2.6610165710306966, 'ACC-155': 2.556062544525875, 'ACC-156': 2.500339351160581, 'ACC-157': 2.3445251540355474, 'ACC-158': 2.384443745051521, 'ACC-159': 2.281626484673379, 'ACC-160': 2.4043681853142105, 'ACC-161': 2.401727716196216, 'ACC-162': 2.626293881898596, 'ACC-163': 2.657272531326099, 'ACC-164': 2.3945725347936797, 'ACC-165': 2.7035482979541148, 'ACC-166': 2.195566225415719, 'ACC-167': 2.187201976142457, 'ACC-168': 2.5079119488009, 'ACC-169': 1.8724567594267696, 'ACC-170': 1.3643397646123485, 'ACC-171': 1.5486518408035135, 'ACC-172': 1.5564692373226654, 'ACC-173': 1.3952805800875248, 'ACC-174': 0.7741187479146513, 'ACC-175': 0.08855954843874508, 'ACC-176': 0.010339273276062225, 'ACC-177': 0.007935497324999215, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 07:01:01] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 07:01:01] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 07:01:01] d2.evaluation.testing INFO: copypaste: 5.3161,0.6097,0.3688,4.3394,8.0321,8.4768,14.6402
[01/29 07:01:02] d2.utils.events INFO:  eta: 1 day, 11:31:09  iter: 10999  total_loss: 64  loss_mask: 6.465  loss_mask_0: 6.378  loss_mask_1: 6.236  loss_mask_2: 6.282  loss_mask_3: 6.368  loss_mask_4: 6.332  loss_mask_5: 6.319  loss_mask_6: 6.325  loss_mask_7: 6.494  loss_mask_8: 6.516  time: 2.6069  data_time: 0.0535  lr: 8.3339e-05  max_mem: 27639M
[01/29 07:01:54] d2.utils.events INFO:  eta: 1 day, 11:30:15  iter: 11019  total_loss: 65.25  loss_mask: 6.687  loss_mask_0: 6.545  loss_mask_1: 6.435  loss_mask_2: 6.437  loss_mask_3: 6.449  loss_mask_4: 6.438  loss_mask_5: 6.416  loss_mask_6: 6.431  loss_mask_7: 6.669  loss_mask_8: 6.695  time: 2.6069  data_time: 0.0566  lr: 8.3308e-05  max_mem: 27639M
[01/29 07:02:46] d2.utils.events INFO:  eta: 1 day, 11:29:17  iter: 11039  total_loss: 62.86  loss_mask: 6.368  loss_mask_0: 6.336  loss_mask_1: 6.219  loss_mask_2: 6.204  loss_mask_3: 6.229  loss_mask_4: 6.222  loss_mask_5: 6.22  loss_mask_6: 6.231  loss_mask_7: 6.375  loss_mask_8: 6.395  time: 2.6069  data_time: 0.0585  lr: 8.3278e-05  max_mem: 27639M
[01/29 07:03:38] d2.utils.events INFO:  eta: 1 day, 11:28:13  iter: 11059  total_loss: 60.39  loss_mask: 6.2  loss_mask_0: 6.124  loss_mask_1: 5.941  loss_mask_2: 5.952  loss_mask_3: 5.931  loss_mask_4: 5.958  loss_mask_5: 5.935  loss_mask_6: 5.944  loss_mask_7: 6.226  loss_mask_8: 6.181  time: 2.6069  data_time: 0.0518  lr: 8.3247e-05  max_mem: 27639M
[01/29 07:04:30] d2.utils.events INFO:  eta: 1 day, 11:26:48  iter: 11079  total_loss: 60.16  loss_mask: 6.207  loss_mask_0: 5.974  loss_mask_1: 5.889  loss_mask_2: 5.873  loss_mask_3: 5.874  loss_mask_4: 5.873  loss_mask_5: 5.861  loss_mask_6: 5.879  loss_mask_7: 6.203  loss_mask_8: 6.233  time: 2.6069  data_time: 0.0549  lr: 8.3217e-05  max_mem: 27639M
[01/29 07:05:22] d2.utils.events INFO:  eta: 1 day, 11:25:48  iter: 11099  total_loss: 63.18  loss_mask: 6.518  loss_mask_0: 6.337  loss_mask_1: 6.221  loss_mask_2: 6.202  loss_mask_3: 6.241  loss_mask_4: 6.207  loss_mask_5: 6.221  loss_mask_6: 6.236  loss_mask_7: 6.506  loss_mask_8: 6.518  time: 2.6069  data_time: 0.0512  lr: 8.3186e-05  max_mem: 27639M
[01/29 07:06:15] d2.utils.events INFO:  eta: 1 day, 11:24:45  iter: 11119  total_loss: 58.77  loss_mask: 5.993  loss_mask_0: 5.855  loss_mask_1: 5.826  loss_mask_2: 5.828  loss_mask_3: 5.839  loss_mask_4: 5.816  loss_mask_5: 5.812  loss_mask_6: 5.802  loss_mask_7: 6.011  loss_mask_8: 5.985  time: 2.6069  data_time: 0.0504  lr: 8.3155e-05  max_mem: 27639M
[01/29 07:07:07] d2.utils.events INFO:  eta: 1 day, 11:23:51  iter: 11139  total_loss: 61.05  loss_mask: 6.246  loss_mask_0: 6.076  loss_mask_1: 6.08  loss_mask_2: 6.074  loss_mask_3: 6.086  loss_mask_4: 6.068  loss_mask_5: 6.057  loss_mask_6: 6.053  loss_mask_7: 6.235  loss_mask_8: 6.239  time: 2.6069  data_time: 0.0553  lr: 8.3125e-05  max_mem: 27639M
[01/29 07:07:59] d2.utils.events INFO:  eta: 1 day, 11:22:44  iter: 11159  total_loss: 58.48  loss_mask: 6.097  loss_mask_0: 5.838  loss_mask_1: 5.753  loss_mask_2: 5.719  loss_mask_3: 5.719  loss_mask_4: 5.729  loss_mask_5: 5.733  loss_mask_6: 5.718  loss_mask_7: 6.085  loss_mask_8: 6.086  time: 2.6069  data_time: 0.0557  lr: 8.3094e-05  max_mem: 27639M
[01/29 07:08:51] d2.utils.events INFO:  eta: 1 day, 11:21:46  iter: 11179  total_loss: 60.38  loss_mask: 6.247  loss_mask_0: 6.057  loss_mask_1: 5.914  loss_mask_2: 5.901  loss_mask_3: 5.912  loss_mask_4: 5.93  loss_mask_5: 5.953  loss_mask_6: 5.947  loss_mask_7: 6.252  loss_mask_8: 6.279  time: 2.6069  data_time: 0.0553  lr: 8.3063e-05  max_mem: 27639M
[01/29 07:09:44] d2.utils.events INFO:  eta: 1 day, 11:20:38  iter: 11199  total_loss: 64.29  loss_mask: 6.583  loss_mask_0: 6.443  loss_mask_1: 6.375  loss_mask_2: 6.334  loss_mask_3: 6.283  loss_mask_4: 6.31  loss_mask_5: 6.315  loss_mask_6: 6.316  loss_mask_7: 6.578  loss_mask_8: 6.623  time: 2.6069  data_time: 0.0591  lr: 8.3033e-05  max_mem: 27639M
[01/29 07:10:36] d2.utils.events INFO:  eta: 1 day, 11:19:41  iter: 11219  total_loss: 61.57  loss_mask: 6.339  loss_mask_0: 6.255  loss_mask_1: 6.056  loss_mask_2: 6.075  loss_mask_3: 6.064  loss_mask_4: 6.048  loss_mask_5: 6.066  loss_mask_6: 6.08  loss_mask_7: 6.342  loss_mask_8: 6.34  time: 2.6069  data_time: 0.0528  lr: 8.3002e-05  max_mem: 27639M
[01/29 07:11:28] d2.utils.events INFO:  eta: 1 day, 11:18:49  iter: 11239  total_loss: 59.14  loss_mask: 6.092  loss_mask_0: 5.891  loss_mask_1: 5.806  loss_mask_2: 5.837  loss_mask_3: 5.793  loss_mask_4: 5.808  loss_mask_5: 5.813  loss_mask_6: 5.78  loss_mask_7: 6.094  loss_mask_8: 6.103  time: 2.6070  data_time: 0.0591  lr: 8.2972e-05  max_mem: 27639M
[01/29 07:12:21] d2.utils.events INFO:  eta: 1 day, 11:17:57  iter: 11259  total_loss: 67.1  loss_mask: 6.831  loss_mask_0: 6.623  loss_mask_1: 6.61  loss_mask_2: 6.626  loss_mask_3: 6.626  loss_mask_4: 6.629  loss_mask_5: 6.629  loss_mask_6: 6.639  loss_mask_7: 6.856  loss_mask_8: 6.854  time: 2.6070  data_time: 0.0515  lr: 8.2941e-05  max_mem: 27639M
[01/29 07:13:13] d2.utils.events INFO:  eta: 1 day, 11:16:42  iter: 11279  total_loss: 58.59  loss_mask: 6.119  loss_mask_0: 5.915  loss_mask_1: 5.745  loss_mask_2: 5.713  loss_mask_3: 5.698  loss_mask_4: 5.713  loss_mask_5: 5.716  loss_mask_6: 5.711  loss_mask_7: 6.137  loss_mask_8: 6.122  time: 2.6070  data_time: 0.0564  lr: 8.291e-05  max_mem: 27639M
[01/29 07:14:05] d2.utils.events INFO:  eta: 1 day, 11:15:37  iter: 11299  total_loss: 60.97  loss_mask: 6.32  loss_mask_0: 6.104  loss_mask_1: 6.003  loss_mask_2: 5.997  loss_mask_3: 5.98  loss_mask_4: 5.987  loss_mask_5: 5.996  loss_mask_6: 5.982  loss_mask_7: 6.303  loss_mask_8: 6.311  time: 2.6069  data_time: 0.0539  lr: 8.288e-05  max_mem: 27639M
[01/29 07:14:57] d2.utils.events INFO:  eta: 1 day, 11:14:23  iter: 11319  total_loss: 61.66  loss_mask: 6.305  loss_mask_0: 6.21  loss_mask_1: 6.041  loss_mask_2: 6.069  loss_mask_3: 6.084  loss_mask_4: 6.05  loss_mask_5: 6.054  loss_mask_6: 6.051  loss_mask_7: 6.294  loss_mask_8: 6.306  time: 2.6069  data_time: 0.0515  lr: 8.2849e-05  max_mem: 27639M
[01/29 07:15:49] d2.utils.events INFO:  eta: 1 day, 11:13:25  iter: 11339  total_loss: 59.27  loss_mask: 6.136  loss_mask_0: 5.877  loss_mask_1: 5.857  loss_mask_2: 5.887  loss_mask_3: 5.953  loss_mask_4: 5.894  loss_mask_5: 5.831  loss_mask_6: 5.82  loss_mask_7: 6.121  loss_mask_8: 6.133  time: 2.6069  data_time: 0.0581  lr: 8.2818e-05  max_mem: 27639M
[01/29 07:16:41] d2.utils.events INFO:  eta: 1 day, 11:12:39  iter: 11359  total_loss: 57.49  loss_mask: 5.987  loss_mask_0: 5.751  loss_mask_1: 5.547  loss_mask_2: 5.606  loss_mask_3: 5.681  loss_mask_4: 5.576  loss_mask_5: 5.654  loss_mask_6: 5.675  loss_mask_7: 5.98  loss_mask_8: 6.033  time: 2.6070  data_time: 0.0495  lr: 8.2788e-05  max_mem: 27639M
[01/29 07:17:34] d2.utils.events INFO:  eta: 1 day, 11:11:47  iter: 11379  total_loss: 61.66  loss_mask: 6.34  loss_mask_0: 6.155  loss_mask_1: 6.064  loss_mask_2: 6.086  loss_mask_3: 6.094  loss_mask_4: 6.063  loss_mask_5: 6.064  loss_mask_6: 6.073  loss_mask_7: 6.372  loss_mask_8: 6.351  time: 2.6070  data_time: 0.0523  lr: 8.2757e-05  max_mem: 27639M
[01/29 07:18:26] d2.utils.events INFO:  eta: 1 day, 11:11:05  iter: 11399  total_loss: 57.46  loss_mask: 5.99  loss_mask_0: 5.687  loss_mask_1: 5.632  loss_mask_2: 5.637  loss_mask_3: 5.645  loss_mask_4: 5.614  loss_mask_5: 5.626  loss_mask_6: 5.616  loss_mask_7: 6  loss_mask_8: 6.022  time: 2.6070  data_time: 0.0527  lr: 8.2726e-05  max_mem: 27639M
[01/29 07:19:18] d2.utils.events INFO:  eta: 1 day, 11:09:16  iter: 11419  total_loss: 58.41  loss_mask: 5.956  loss_mask_0: 5.831  loss_mask_1: 5.795  loss_mask_2: 5.783  loss_mask_3: 5.794  loss_mask_4: 5.783  loss_mask_5: 5.779  loss_mask_6: 5.771  loss_mask_7: 5.969  loss_mask_8: 5.952  time: 2.6070  data_time: 0.0517  lr: 8.2696e-05  max_mem: 27639M
[01/29 07:20:10] d2.utils.events INFO:  eta: 1 day, 11:08:43  iter: 11439  total_loss: 63.67  loss_mask: 6.61  loss_mask_0: 6.246  loss_mask_1: 6.249  loss_mask_2: 6.264  loss_mask_3: 6.258  loss_mask_4: 6.255  loss_mask_5: 6.265  loss_mask_6: 6.286  loss_mask_7: 6.666  loss_mask_8: 6.634  time: 2.6070  data_time: 0.0580  lr: 8.2665e-05  max_mem: 27639M
[01/29 07:21:02] d2.utils.events INFO:  eta: 1 day, 11:07:21  iter: 11459  total_loss: 57.64  loss_mask: 5.921  loss_mask_0: 5.787  loss_mask_1: 5.71  loss_mask_2: 5.691  loss_mask_3: 5.701  loss_mask_4: 5.67  loss_mask_5: 5.656  loss_mask_6: 5.669  loss_mask_7: 5.916  loss_mask_8: 5.889  time: 2.6070  data_time: 0.0498  lr: 8.2635e-05  max_mem: 27639M
[01/29 07:21:54] d2.utils.events INFO:  eta: 1 day, 11:06:34  iter: 11479  total_loss: 62.98  loss_mask: 6.449  loss_mask_0: 6.303  loss_mask_1: 6.252  loss_mask_2: 6.175  loss_mask_3: 6.163  loss_mask_4: 6.186  loss_mask_5: 6.219  loss_mask_6: 6.196  loss_mask_7: 6.447  loss_mask_8: 6.447  time: 2.6070  data_time: 0.0591  lr: 8.2604e-05  max_mem: 27639M
[01/29 07:22:47] d2.utils.events INFO:  eta: 1 day, 11:05:42  iter: 11499  total_loss: 61.08  loss_mask: 6.266  loss_mask_0: 6.152  loss_mask_1: 6.039  loss_mask_2: 6.029  loss_mask_3: 6.017  loss_mask_4: 6.021  loss_mask_5: 6.006  loss_mask_6: 6.012  loss_mask_7: 6.276  loss_mask_8: 6.262  time: 2.6070  data_time: 0.0565  lr: 8.2573e-05  max_mem: 27639M
[01/29 07:23:39] d2.utils.events INFO:  eta: 1 day, 11:04:48  iter: 11519  total_loss: 59.07  loss_mask: 6.006  loss_mask_0: 6.015  loss_mask_1: 5.853  loss_mask_2: 5.849  loss_mask_3: 5.842  loss_mask_4: 5.859  loss_mask_5: 5.859  loss_mask_6: 5.852  loss_mask_7: 6.016  loss_mask_8: 6.004  time: 2.6070  data_time: 0.0510  lr: 8.2543e-05  max_mem: 27639M
[01/29 07:24:31] d2.utils.events INFO:  eta: 1 day, 11:04:20  iter: 11539  total_loss: 58.14  loss_mask: 5.985  loss_mask_0: 5.788  loss_mask_1: 5.721  loss_mask_2: 5.766  loss_mask_3: 5.748  loss_mask_4: 5.753  loss_mask_5: 5.749  loss_mask_6: 5.749  loss_mask_7: 5.985  loss_mask_8: 5.992  time: 2.6070  data_time: 0.0502  lr: 8.2512e-05  max_mem: 27639M
[01/29 07:25:23] d2.utils.events INFO:  eta: 1 day, 11:03:06  iter: 11559  total_loss: 57.26  loss_mask: 5.942  loss_mask_0: 5.645  loss_mask_1: 5.627  loss_mask_2: 5.606  loss_mask_3: 5.616  loss_mask_4: 5.635  loss_mask_5: 5.658  loss_mask_6: 5.654  loss_mask_7: 5.927  loss_mask_8: 5.944  time: 2.6070  data_time: 0.0573  lr: 8.2481e-05  max_mem: 27639M
[01/29 07:26:16] d2.utils.events INFO:  eta: 1 day, 11:01:46  iter: 11579  total_loss: 58.99  loss_mask: 6.036  loss_mask_0: 5.853  loss_mask_1: 5.818  loss_mask_2: 5.84  loss_mask_3: 5.856  loss_mask_4: 5.868  loss_mask_5: 5.842  loss_mask_6: 5.847  loss_mask_7: 6.034  loss_mask_8: 6.048  time: 2.6070  data_time: 0.0517  lr: 8.2451e-05  max_mem: 27639M
[01/29 07:27:08] d2.utils.events INFO:  eta: 1 day, 11:00:48  iter: 11599  total_loss: 63.33  loss_mask: 6.479  loss_mask_0: 6.397  loss_mask_1: 6.163  loss_mask_2: 6.241  loss_mask_3: 6.195  loss_mask_4: 6.185  loss_mask_5: 6.171  loss_mask_6: 6.177  loss_mask_7: 6.492  loss_mask_8: 6.49  time: 2.6070  data_time: 0.0536  lr: 8.242e-05  max_mem: 27639M
[01/29 07:28:00] d2.utils.events INFO:  eta: 1 day, 11:00:01  iter: 11619  total_loss: 65.45  loss_mask: 6.718  loss_mask_0: 6.566  loss_mask_1: 6.469  loss_mask_2: 6.467  loss_mask_3: 6.473  loss_mask_4: 6.477  loss_mask_5: 6.482  loss_mask_6: 6.487  loss_mask_7: 6.704  loss_mask_8: 6.686  time: 2.6070  data_time: 0.0561  lr: 8.2389e-05  max_mem: 27639M
[01/29 07:28:53] d2.utils.events INFO:  eta: 1 day, 10:59:16  iter: 11639  total_loss: 60.63  loss_mask: 6.216  loss_mask_0: 6.04  loss_mask_1: 6.017  loss_mask_2: 6.012  loss_mask_3: 5.996  loss_mask_4: 5.991  loss_mask_5: 5.978  loss_mask_6: 5.972  loss_mask_7: 6.222  loss_mask_8: 6.218  time: 2.6070  data_time: 0.0601  lr: 8.2359e-05  max_mem: 27639M
[01/29 07:29:45] d2.utils.events INFO:  eta: 1 day, 10:58:13  iter: 11659  total_loss: 57.89  loss_mask: 6.057  loss_mask_0: 5.676  loss_mask_1: 5.65  loss_mask_2: 5.647  loss_mask_3: 5.636  loss_mask_4: 5.628  loss_mask_5: 5.648  loss_mask_6: 5.648  loss_mask_7: 6.053  loss_mask_8: 6.049  time: 2.6070  data_time: 0.0516  lr: 8.2328e-05  max_mem: 27639M
[01/29 07:30:37] d2.utils.events INFO:  eta: 1 day, 10:57:23  iter: 11679  total_loss: 60.68  loss_mask: 6.303  loss_mask_0: 6.042  loss_mask_1: 5.948  loss_mask_2: 5.959  loss_mask_3: 5.953  loss_mask_4: 5.943  loss_mask_5: 5.966  loss_mask_6: 5.947  loss_mask_7: 6.303  loss_mask_8: 6.316  time: 2.6070  data_time: 0.0512  lr: 8.2297e-05  max_mem: 27639M
[01/29 07:31:29] d2.utils.events INFO:  eta: 1 day, 10:56:29  iter: 11699  total_loss: 59.49  loss_mask: 6.187  loss_mask_0: 6.048  loss_mask_1: 5.867  loss_mask_2: 5.835  loss_mask_3: 5.831  loss_mask_4: 5.851  loss_mask_5: 5.87  loss_mask_6: 5.858  loss_mask_7: 6.18  loss_mask_8: 6.18  time: 2.6070  data_time: 0.0591  lr: 8.2267e-05  max_mem: 27639M
[01/29 07:32:22] d2.utils.events INFO:  eta: 1 day, 10:55:23  iter: 11719  total_loss: 56.41  loss_mask: 5.878  loss_mask_0: 5.766  loss_mask_1: 5.543  loss_mask_2: 5.519  loss_mask_3: 5.529  loss_mask_4: 5.548  loss_mask_5: 5.513  loss_mask_6: 5.531  loss_mask_7: 5.907  loss_mask_8: 5.858  time: 2.6071  data_time: 0.0625  lr: 8.2236e-05  max_mem: 27639M
[01/29 07:33:14] d2.utils.events INFO:  eta: 1 day, 10:54:43  iter: 11739  total_loss: 57.54  loss_mask: 5.932  loss_mask_0: 5.738  loss_mask_1: 5.631  loss_mask_2: 5.632  loss_mask_3: 5.619  loss_mask_4: 5.64  loss_mask_5: 5.651  loss_mask_6: 5.632  loss_mask_7: 5.932  loss_mask_8: 5.939  time: 2.6071  data_time: 0.0502  lr: 8.2205e-05  max_mem: 27639M
[01/29 07:34:06] d2.utils.events INFO:  eta: 1 day, 10:53:55  iter: 11759  total_loss: 55.35  loss_mask: 5.786  loss_mask_0: 5.535  loss_mask_1: 5.474  loss_mask_2: 5.472  loss_mask_3: 5.441  loss_mask_4: 5.469  loss_mask_5: 5.45  loss_mask_6: 5.449  loss_mask_7: 5.796  loss_mask_8: 5.78  time: 2.6071  data_time: 0.0512  lr: 8.2175e-05  max_mem: 27639M
[01/29 07:34:59] d2.utils.events INFO:  eta: 1 day, 10:53:03  iter: 11779  total_loss: 56.89  loss_mask: 5.963  loss_mask_0: 5.749  loss_mask_1: 5.649  loss_mask_2: 5.619  loss_mask_3: 5.608  loss_mask_4: 5.607  loss_mask_5: 5.616  loss_mask_6: 5.613  loss_mask_7: 5.931  loss_mask_8: 5.977  time: 2.6071  data_time: 0.0577  lr: 8.2144e-05  max_mem: 27639M
[01/29 07:35:51] d2.utils.events INFO:  eta: 1 day, 10:52:12  iter: 11799  total_loss: 54.29  loss_mask: 5.56  loss_mask_0: 5.425  loss_mask_1: 5.375  loss_mask_2: 5.366  loss_mask_3: 5.37  loss_mask_4: 5.393  loss_mask_5: 5.38  loss_mask_6: 5.406  loss_mask_7: 5.546  loss_mask_8: 5.539  time: 2.6071  data_time: 0.0543  lr: 8.2113e-05  max_mem: 27639M
[01/29 07:36:44] d2.utils.events INFO:  eta: 1 day, 10:51:37  iter: 11819  total_loss: 57.97  loss_mask: 5.964  loss_mask_0: 5.778  loss_mask_1: 5.733  loss_mask_2: 5.722  loss_mask_3: 5.704  loss_mask_4: 5.724  loss_mask_5: 5.726  loss_mask_6: 5.73  loss_mask_7: 5.974  loss_mask_8: 5.975  time: 2.6072  data_time: 0.0569  lr: 8.2083e-05  max_mem: 27639M
[01/29 07:37:36] d2.utils.events INFO:  eta: 1 day, 10:50:45  iter: 11839  total_loss: 59.28  loss_mask: 6.161  loss_mask_0: 5.841  loss_mask_1: 5.776  loss_mask_2: 5.835  loss_mask_3: 5.837  loss_mask_4: 5.833  loss_mask_5: 5.832  loss_mask_6: 5.777  loss_mask_7: 6.193  loss_mask_8: 6.194  time: 2.6072  data_time: 0.0628  lr: 8.2052e-05  max_mem: 27639M
[01/29 07:38:28] d2.utils.events INFO:  eta: 1 day, 10:50:05  iter: 11859  total_loss: 57.58  loss_mask: 5.916  loss_mask_0: 5.639  loss_mask_1: 5.647  loss_mask_2: 5.684  loss_mask_3: 5.735  loss_mask_4: 5.714  loss_mask_5: 5.704  loss_mask_6: 5.71  loss_mask_7: 5.935  loss_mask_8: 5.922  time: 2.6072  data_time: 0.0493  lr: 8.2021e-05  max_mem: 27639M
[01/29 07:39:21] d2.utils.events INFO:  eta: 1 day, 10:49:19  iter: 11879  total_loss: 58.03  loss_mask: 5.945  loss_mask_0: 5.803  loss_mask_1: 5.713  loss_mask_2: 5.705  loss_mask_3: 5.727  loss_mask_4: 5.726  loss_mask_5: 5.73  loss_mask_6: 5.74  loss_mask_7: 5.94  loss_mask_8: 5.933  time: 2.6072  data_time: 0.0595  lr: 8.1991e-05  max_mem: 27639M
[01/29 07:40:13] d2.utils.events INFO:  eta: 1 day, 10:48:16  iter: 11899  total_loss: 61.77  loss_mask: 6.329  loss_mask_0: 6.206  loss_mask_1: 6.119  loss_mask_2: 6.11  loss_mask_3: 6.095  loss_mask_4: 6.087  loss_mask_5: 6.107  loss_mask_6: 6.091  loss_mask_7: 6.293  loss_mask_8: 6.329  time: 2.6072  data_time: 0.0594  lr: 8.196e-05  max_mem: 27639M
[01/29 07:41:05] d2.utils.events INFO:  eta: 1 day, 10:47:07  iter: 11919  total_loss: 56.14  loss_mask: 5.769  loss_mask_0: 5.633  loss_mask_1: 5.573  loss_mask_2: 5.508  loss_mask_3: 5.524  loss_mask_4: 5.552  loss_mask_5: 5.567  loss_mask_6: 5.557  loss_mask_7: 5.815  loss_mask_8: 5.777  time: 2.6072  data_time: 0.0587  lr: 8.1929e-05  max_mem: 27639M
[01/29 07:41:57] d2.utils.events INFO:  eta: 1 day, 10:46:15  iter: 11939  total_loss: 57.82  loss_mask: 5.999  loss_mask_0: 5.741  loss_mask_1: 5.678  loss_mask_2: 5.698  loss_mask_3: 5.709  loss_mask_4: 5.688  loss_mask_5: 5.677  loss_mask_6: 5.67  loss_mask_7: 6.009  loss_mask_8: 6.043  time: 2.6072  data_time: 0.0571  lr: 8.1899e-05  max_mem: 27639M
[01/29 07:42:50] d2.utils.events INFO:  eta: 1 day, 10:45:23  iter: 11959  total_loss: 55.1  loss_mask: 5.679  loss_mask_0: 5.498  loss_mask_1: 5.431  loss_mask_2: 5.393  loss_mask_3: 5.399  loss_mask_4: 5.406  loss_mask_5: 5.416  loss_mask_6: 5.408  loss_mask_7: 5.669  loss_mask_8: 5.67  time: 2.6072  data_time: 0.0595  lr: 8.1868e-05  max_mem: 27639M
[01/29 07:43:42] d2.utils.events INFO:  eta: 1 day, 10:44:52  iter: 11979  total_loss: 58.04  loss_mask: 6.037  loss_mask_0: 5.832  loss_mask_1: 5.706  loss_mask_2: 5.664  loss_mask_3: 5.685  loss_mask_4: 5.711  loss_mask_5: 5.656  loss_mask_6: 5.705  loss_mask_7: 6.052  loss_mask_8: 6.031  time: 2.6072  data_time: 0.0568  lr: 8.1837e-05  max_mem: 27639M
[01/29 07:44:34] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 07:44:35] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 07:44:35] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 07:58:47] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 5.299438487664979, 'error_1pix': 0.6537664172030091, 'error_3pix': 0.3826369916258801, 'mIoU': 3.4823947105454853, 'fwIoU': 6.544187824004035, 'IoU-0': 0.0567362118135368, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.07910485810826627, 'IoU-7': 0.3995375855310546, 'IoU-8': 2.2290495182140737, 'IoU-9': 7.0904800690808845, 'IoU-10': 9.804599404234073, 'IoU-11': 14.663317420328289, 'IoU-12': 15.536668778649766, 'IoU-13': 14.79196035735931, 'IoU-14': 15.101722463842274, 'IoU-15': 14.274100984860524, 'IoU-16': 13.644888522801605, 'IoU-17': 11.263259437933225, 'IoU-18': 11.063338585384837, 'IoU-19': 11.575585978104435, 'IoU-20': 11.623128505279725, 'IoU-21': 11.727136163894274, 'IoU-22': 11.681755579519358, 'IoU-23': 10.597895293418778, 'IoU-24': 10.258392197024238, 'IoU-25': 9.136505021224425, 'IoU-26': 8.309494341839265, 'IoU-27': 8.048098524606779, 'IoU-28': 7.27223176970416, 'IoU-29': 7.095120994035417, 'IoU-30': 6.91197042179153, 'IoU-31': 6.715323411140213, 'IoU-32': 6.103966057046932, 'IoU-33': 5.781599846975596, 'IoU-34': 5.8140153797120036, 'IoU-35': 5.8374020806510645, 'IoU-36': 5.585344325604721, 'IoU-37': 5.889964354824394, 'IoU-38': 6.050134213945448, 'IoU-39': 6.5093364086727705, 'IoU-40': 6.34484538875679, 'IoU-41': 6.05684544823187, 'IoU-42': 6.141802308808654, 'IoU-43': 6.345673582610932, 'IoU-44': 6.585717819928592, 'IoU-45': 6.604845412798029, 'IoU-46': 6.5984155830450435, 'IoU-47': 7.027592298049901, 'IoU-48': 6.7248392183532975, 'IoU-49': 6.837597863821111, 'IoU-50': 6.980661200388319, 'IoU-51': 7.024289136546082, 'IoU-52': 6.772871105353611, 'IoU-53': 6.2391177251396766, 'IoU-54': 6.015961866432105, 'IoU-55': 5.683633153202297, 'IoU-56': 5.241507474719819, 'IoU-57': 5.230915095247038, 'IoU-58': 5.2164028184488735, 'IoU-59': 5.210744434276538, 'IoU-60': 5.022475631557173, 'IoU-61': 4.895541149770834, 'IoU-62': 4.479592763643985, 'IoU-63': 4.503115507775972, 'IoU-64': 4.362490864945425, 'IoU-65': 4.07222588942219, 'IoU-66': 3.9311709284851233, 'IoU-67': 3.787556703315946, 'IoU-68': 3.606080180996697, 'IoU-69': 3.619873739807385, 'IoU-70': 3.3944838295606177, 'IoU-71': 3.4318986625524315, 'IoU-72': 3.502073995188907, 'IoU-73': 3.456106972654529, 'IoU-74': 3.3986759351134723, 'IoU-75': 3.185887684192538, 'IoU-76': 3.2200503377520415, 'IoU-77': 3.131464005987203, 'IoU-78': 3.115034562977656, 'IoU-79': 3.118939134043821, 'IoU-80': 3.192942599806994, 'IoU-81': 3.2792278322948265, 'IoU-82': 3.365019675424527, 'IoU-83': 3.5562974418599866, 'IoU-84': 3.832834299501145, 'IoU-85': 3.860332343641367, 'IoU-86': 3.7781323644871834, 'IoU-87': 3.8098314614515676, 'IoU-88': 3.765278511641378, 'IoU-89': 3.6617441404059474, 'IoU-90': 3.5548918608350384, 'IoU-91': 3.6361029038719135, 'IoU-92': 3.515974435486692, 'IoU-93': 3.506632719956402, 'IoU-94': 3.386291710100365, 'IoU-95': 3.379040821384221, 'IoU-96': 3.1003874464408754, 'IoU-97': 3.15710177130632, 'IoU-98': 3.004119345359771, 'IoU-99': 2.867531122165149, 'IoU-100': 2.9707913363482605, 'IoU-101': 2.8958007316369923, 'IoU-102': 2.7964061358108085, 'IoU-103': 2.8420025925850516, 'IoU-104': 2.792252216210047, 'IoU-105': 2.5297153303017703, 'IoU-106': 2.6419556568054072, 'IoU-107': 2.4532185459412914, 'IoU-108': 2.3461054168104707, 'IoU-109': 2.281778764426146, 'IoU-110': 2.1388079564857647, 'IoU-111': 2.1661100137276965, 'IoU-112': 2.0170348040783015, 'IoU-113': 1.7365870041554612, 'IoU-114': 1.800185186514402, 'IoU-115': 2.04558494073973, 'IoU-116': 1.8544633917051678, 'IoU-117': 1.8825184550595435, 'IoU-118': 1.5348742677258103, 'IoU-119': 1.4219047685245496, 'IoU-120': 1.310880442469793, 'IoU-121': 1.301701678485799, 'IoU-122': 1.4052190221045089, 'IoU-123': 1.4522740937493885, 'IoU-124': 1.4215117687460634, 'IoU-125': 1.2848897328504465, 'IoU-126': 1.3234129829377363, 'IoU-127': 1.439664078381711, 'IoU-128': 1.2765630953741423, 'IoU-129': 1.1944687779971759, 'IoU-130': 1.1928237635074546, 'IoU-131': 1.200552714490586, 'IoU-132': 1.3837222299397238, 'IoU-133': 1.4033212631833334, 'IoU-134': 1.3766683852803314, 'IoU-135': 1.2688079638917513, 'IoU-136': 1.1999668190095474, 'IoU-137': 1.31808911403702, 'IoU-138': 1.0722393133368004, 'IoU-139': 1.068181517117133, 'IoU-140': 1.0070616016893348, 'IoU-141': 0.9240027986468927, 'IoU-142': 1.0096298310129208, 'IoU-143': 0.9944667922257334, 'IoU-144': 0.9567101406176982, 'IoU-145': 0.8810431897763525, 'IoU-146': 0.8103395796264481, 'IoU-147': 0.8992514398492776, 'IoU-148': 1.1730384161461855, 'IoU-149': 1.1067682323225598, 'IoU-150': 1.0654630816985475, 'IoU-151': 1.065169376632938, 'IoU-152': 1.2227812603101287, 'IoU-153': 1.195118790740125, 'IoU-154': 1.1514681322325797, 'IoU-155': 0.8658854784382561, 'IoU-156': 0.7081542460839199, 'IoU-157': 0.7998867370389637, 'IoU-158': 1.032227319072246, 'IoU-159': 1.0047047604440014, 'IoU-160': 0.88884270112817, 'IoU-161': 0.8124130737134909, 'IoU-162': 1.0467401055456886, 'IoU-163': 1.037509682155251, 'IoU-164': 0.9609933362454344, 'IoU-165': 1.100678611180927, 'IoU-166': 1.1313997294934863, 'IoU-167': 0.9366794062172062, 'IoU-168': 0.692538732470451, 'IoU-169': 0.737210514558046, 'IoU-170': 0.5237786502419287, 'IoU-171': 0.6424289889064505, 'IoU-172': 0.4994875219937061, 'IoU-173': 0.6762350646284419, 'IoU-174': 0.4959005631254924, 'IoU-175': 0.5770455366867703, 'IoU-176': 0.16587760116360603, 'IoU-177': 0.22213819831742132, 'IoU-178': 0.08708282910124635, 'IoU-179': 0.016490979063868264, 'IoU-180': 0.016859044973418266, 'IoU-181': 0.010295237380291056, 'IoU-182': 0.01023316372408778, 'IoU-183': 0.01385428324649151, 'IoU-184': 0.017474236028506163, 'IoU-185': 0.0025614808774779662, 'IoU-186': 0.0016325997518448377, 'IoU-187': 0.001204433278009698, 'IoU-188': 0.00251469208852722, 'IoU-189': 0.0010240970024680738, 'IoU-190': 0.0005226203137289743, 'IoU-191': 0.0013018189013689928, 'IoU-192': 0.0031048362057772535, 'mACC': 6.8553078962292044, 'pACC': 12.101628147998875, 'ACC-0': 0.05674851335645046, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 29.4201646324743, 'ACC-7': 8.626039649809845, 'ACC-8': 14.997440501373024, 'ACC-9': 20.647292402938724, 'ACC-10': 20.358246751060744, 'ACC-11': 23.696519634273503, 'ACC-12': 25.03995524295911, 'ACC-13': 24.3021093422739, 'ACC-14': 25.692102851189745, 'ACC-15': 25.5835252760844, 'ACC-16': 24.290233551703047, 'ACC-17': 21.232573021145132, 'ACC-18': 19.88524271383909, 'ACC-19': 20.929502896175787, 'ACC-20': 21.639994693974877, 'ACC-21': 21.604518572713552, 'ACC-22': 20.800842976192037, 'ACC-23': 20.12583362705323, 'ACC-24': 20.25307022564217, 'ACC-25': 18.11927920442206, 'ACC-26': 16.60141115865994, 'ACC-27': 15.366074884957964, 'ACC-28': 14.308488458238994, 'ACC-29': 13.814277057190846, 'ACC-30': 13.88707439075398, 'ACC-31': 12.986179612649881, 'ACC-32': 11.802300392042516, 'ACC-33': 11.463385992415454, 'ACC-34': 11.518916209832959, 'ACC-35': 11.054516649383729, 'ACC-36': 10.369953829826926, 'ACC-37': 10.992051228882625, 'ACC-38': 11.20334165624746, 'ACC-39': 12.01039709263688, 'ACC-40': 11.68936254356834, 'ACC-41': 11.49158176910656, 'ACC-42': 11.6533479234826, 'ACC-43': 11.907329738075436, 'ACC-44': 11.940056432456865, 'ACC-45': 12.080546969669047, 'ACC-46': 12.46904018716011, 'ACC-47': 13.278501984383514, 'ACC-48': 12.625745688055668, 'ACC-49': 12.714278404458032, 'ACC-50': 12.974518983208222, 'ACC-51': 13.405408873180916, 'ACC-52': 13.019062769798085, 'ACC-53': 12.020380360476402, 'ACC-54': 11.3441156199193, 'ACC-55': 10.614643554172615, 'ACC-56': 9.809974447022869, 'ACC-57': 9.61915614551385, 'ACC-58': 9.731013250058806, 'ACC-59': 9.87287641549344, 'ACC-60': 9.649124884317256, 'ACC-61': 9.531256677635797, 'ACC-62': 8.780720675376422, 'ACC-63': 8.90840375877828, 'ACC-64': 8.645830886690124, 'ACC-65': 8.086238251692603, 'ACC-66': 7.82516656575489, 'ACC-67': 7.620706415901162, 'ACC-68': 7.261117543254622, 'ACC-69': 7.165302463002218, 'ACC-70': 6.662515283075115, 'ACC-71': 6.874674390693679, 'ACC-72': 7.046045381207308, 'ACC-73': 6.915954828338937, 'ACC-74': 6.6703579092897645, 'ACC-75': 6.227550912989599, 'ACC-76': 6.163680367099643, 'ACC-77': 5.98489740111946, 'ACC-78': 5.926686176674419, 'ACC-79': 5.864106637820267, 'ACC-80': 5.921968554142073, 'ACC-81': 6.044706083098712, 'ACC-82': 6.211181382117471, 'ACC-83': 6.540067834714791, 'ACC-84': 7.140706268664909, 'ACC-85': 7.282794813433302, 'ACC-86': 7.166022268640752, 'ACC-87': 7.242113304537878, 'ACC-88': 7.163273652583076, 'ACC-89': 6.931695774826907, 'ACC-90': 6.659561862599811, 'ACC-91': 6.831671339083567, 'ACC-92': 6.645897082915801, 'ACC-93': 6.595666914312813, 'ACC-94': 6.3658463305040005, 'ACC-95': 6.3480226273259275, 'ACC-96': 5.821742322771738, 'ACC-97': 5.855709865842674, 'ACC-98': 5.575517326602637, 'ACC-99': 5.350769472858446, 'ACC-100': 5.538431346789961, 'ACC-101': 5.495911075345916, 'ACC-102': 5.4059130040779335, 'ACC-103': 5.537451591574573, 'ACC-104': 5.4756154546125275, 'ACC-105': 4.989285032936616, 'ACC-106': 5.184347234601368, 'ACC-107': 4.792512477753265, 'ACC-108': 4.520030388895506, 'ACC-109': 4.328864054839025, 'ACC-110': 4.072963465574922, 'ACC-111': 4.16869196939654, 'ACC-112': 3.9529501734689587, 'ACC-113': 3.414010795140279, 'ACC-114': 3.5645811566120518, 'ACC-115': 4.022972952655872, 'ACC-116': 3.66795002601829, 'ACC-117': 3.6572781913435937, 'ACC-118': 2.945672770297817, 'ACC-119': 2.7199225232110833, 'ACC-120': 2.477536835373203, 'ACC-121': 2.4371067396975055, 'ACC-122': 2.610084255616255, 'ACC-123': 2.673244267954029, 'ACC-124': 2.657235812031425, 'ACC-125': 2.3997050131449713, 'ACC-126': 2.500535068625397, 'ACC-127': 2.69977291629676, 'ACC-128': 2.404709894364007, 'ACC-129': 2.2597845451596084, 'ACC-130': 2.2407859809154296, 'ACC-131': 2.2571081661419816, 'ACC-132': 2.5969378009671162, 'ACC-133': 2.655153878081474, 'ACC-134': 2.580611805256355, 'ACC-135': 2.3778575907872983, 'ACC-136': 2.211406308237048, 'ACC-137': 2.4618822683570736, 'ACC-138': 1.9935686727415791, 'ACC-139': 1.9832703834300878, 'ACC-140': 1.836713396180471, 'ACC-141': 1.6959835997973536, 'ACC-142': 1.8486351382153439, 'ACC-143': 1.8338450810664122, 'ACC-144': 1.7276173285198555, 'ACC-145': 1.5288356179699905, 'ACC-146': 1.4500011423088346, 'ACC-147': 1.6029965189794084, 'ACC-148': 2.102084404653387, 'ACC-149': 2.022779338971208, 'ACC-150': 1.9580804432728898, 'ACC-151': 2.0230570094523723, 'ACC-152': 2.311876222267179, 'ACC-153': 2.4291623151761668, 'ACC-154': 2.2829345272271913, 'ACC-155': 1.6872483271109708, 'ACC-156': 1.4336834158121448, 'ACC-157': 1.6532603813645828, 'ACC-158': 2.2132492932759957, 'ACC-159': 2.1358972795876214, 'ACC-160': 2.0557222314907238, 'ACC-161': 1.9685404239544366, 'ACC-162': 2.5724601567695187, 'ACC-163': 2.5840654393476856, 'ACC-164': 2.7869824549164606, 'ACC-165': 2.9211373901774316, 'ACC-166': 3.3507876256398466, 'ACC-167': 3.052985585391529, 'ACC-168': 2.0286308060721785, 'ACC-169': 1.6850649863394451, 'ACC-170': 1.2387021666640048, 'ACC-171': 1.7448439026899143, 'ACC-172': 1.3601536469860485, 'ACC-173': 1.2340452752942594, 'ACC-174': 0.7920160900985873, 'ACC-175': 0.8678514114140765, 'ACC-176': 0.20769430300875583, 'ACC-177': 0.26021289474849774, 'ACC-178': 0.09715939162381737, 'ACC-179': 0.018057280127253102, 'ACC-180': 0.018625875998230543, 'ACC-181': 0.011369611869874792, 'ACC-182': 0.011135197886681592, 'ACC-183': 0.015067757823462383, 'ACC-184': 0.019574779194132284, 'ACC-185': 0.0027715418087081844, 'ACC-186': 0.0016524789545001725, 'ACC-187': 0.0012080504481867163, 'ACC-188': 0.002522125344585375, 'ACC-189': 0.0010269075449464596, 'ACC-190': 0.0005240170095921313, 'ACC-191': 0.001305077534656334, 'ACC-192': 0.0031129726058410686})])
[01/29 07:58:47] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 07:58:47] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 07:58:47] d2.evaluation.testing INFO: copypaste: 5.2994,0.6538,0.3826,3.4824,6.5442,6.8553,12.1016
[01/29 07:58:47] d2.utils.events INFO:  eta: 1 day, 10:43:44  iter: 11999  total_loss: 56.3  loss_mask: 5.794  loss_mask_0: 5.652  loss_mask_1: 5.558  loss_mask_2: 5.522  loss_mask_3: 5.555  loss_mask_4: 5.542  loss_mask_5: 5.536  loss_mask_6: 5.538  loss_mask_7: 5.795  loss_mask_8: 5.791  time: 2.6072  data_time: 0.0627  lr: 8.1807e-05  max_mem: 27639M
[01/29 07:59:39] d2.utils.events INFO:  eta: 1 day, 10:42:28  iter: 12019  total_loss: 56.57  loss_mask: 5.829  loss_mask_0: 5.664  loss_mask_1: 5.558  loss_mask_2: 5.588  loss_mask_3: 5.612  loss_mask_4: 5.558  loss_mask_5: 5.545  loss_mask_6: 5.562  loss_mask_7: 5.85  loss_mask_8: 5.803  time: 2.6072  data_time: 0.0526  lr: 8.1776e-05  max_mem: 27639M
[01/29 08:00:31] d2.utils.events INFO:  eta: 1 day, 10:42:04  iter: 12039  total_loss: 56.39  loss_mask: 5.87  loss_mask_0: 5.807  loss_mask_1: 5.579  loss_mask_2: 5.513  loss_mask_3: 5.503  loss_mask_4: 5.466  loss_mask_5: 5.484  loss_mask_6: 5.496  loss_mask_7: 5.855  loss_mask_8: 5.877  time: 2.6072  data_time: 0.0630  lr: 8.1745e-05  max_mem: 27639M
[01/29 08:01:24] d2.utils.events INFO:  eta: 1 day, 10:41:40  iter: 12059  total_loss: 58  loss_mask: 5.987  loss_mask_0: 5.885  loss_mask_1: 5.683  loss_mask_2: 5.702  loss_mask_3: 5.706  loss_mask_4: 5.688  loss_mask_5: 5.712  loss_mask_6: 5.714  loss_mask_7: 5.967  loss_mask_8: 5.998  time: 2.6072  data_time: 0.0636  lr: 8.1715e-05  max_mem: 27639M
[01/29 08:02:16] d2.utils.events INFO:  eta: 1 day, 10:40:57  iter: 12079  total_loss: 56.9  loss_mask: 5.831  loss_mask_0: 5.724  loss_mask_1: 5.622  loss_mask_2: 5.624  loss_mask_3: 5.614  loss_mask_4: 5.59  loss_mask_5: 5.625  loss_mask_6: 5.608  loss_mask_7: 5.823  loss_mask_8: 5.836  time: 2.6073  data_time: 0.0524  lr: 8.1684e-05  max_mem: 27639M
[01/29 08:03:08] d2.utils.events INFO:  eta: 1 day, 10:40:04  iter: 12099  total_loss: 60.92  loss_mask: 6.305  loss_mask_0: 6.139  loss_mask_1: 5.978  loss_mask_2: 5.983  loss_mask_3: 5.99  loss_mask_4: 5.963  loss_mask_5: 5.967  loss_mask_6: 5.969  loss_mask_7: 6.308  loss_mask_8: 6.296  time: 2.6073  data_time: 0.0560  lr: 8.1653e-05  max_mem: 27639M
[01/29 08:04:01] d2.utils.events INFO:  eta: 1 day, 10:39:24  iter: 12119  total_loss: 62.28  loss_mask: 6.374  loss_mask_0: 6.255  loss_mask_1: 6.178  loss_mask_2: 6.137  loss_mask_3: 6.141  loss_mask_4: 6.162  loss_mask_5: 6.144  loss_mask_6: 6.158  loss_mask_7: 6.366  loss_mask_8: 6.364  time: 2.6073  data_time: 0.0587  lr: 8.1623e-05  max_mem: 27639M
[01/29 08:04:53] d2.utils.events INFO:  eta: 1 day, 10:38:46  iter: 12139  total_loss: 58.93  loss_mask: 6.053  loss_mask_0: 5.987  loss_mask_1: 5.791  loss_mask_2: 5.785  loss_mask_3: 5.779  loss_mask_4: 5.776  loss_mask_5: 5.791  loss_mask_6: 5.776  loss_mask_7: 6.072  loss_mask_8: 6.065  time: 2.6073  data_time: 0.0641  lr: 8.1592e-05  max_mem: 27639M
[01/29 08:05:45] d2.utils.events INFO:  eta: 1 day, 10:38:32  iter: 12159  total_loss: 56.71  loss_mask: 5.869  loss_mask_0: 5.704  loss_mask_1: 5.626  loss_mask_2: 5.595  loss_mask_3: 5.587  loss_mask_4: 5.58  loss_mask_5: 5.577  loss_mask_6: 5.579  loss_mask_7: 5.886  loss_mask_8: 5.895  time: 2.6073  data_time: 0.0525  lr: 8.1561e-05  max_mem: 27639M
[01/29 08:06:38] d2.utils.events INFO:  eta: 1 day, 10:37:42  iter: 12179  total_loss: 58.22  loss_mask: 5.942  loss_mask_0: 5.785  loss_mask_1: 5.729  loss_mask_2: 5.723  loss_mask_3: 5.727  loss_mask_4: 5.731  loss_mask_5: 5.758  loss_mask_6: 5.76  loss_mask_7: 5.952  loss_mask_8: 5.947  time: 2.6073  data_time: 0.0539  lr: 8.1531e-05  max_mem: 27639M
[01/29 08:07:30] d2.utils.events INFO:  eta: 1 day, 10:36:56  iter: 12199  total_loss: 60.03  loss_mask: 6.246  loss_mask_0: 6.001  loss_mask_1: 5.874  loss_mask_2: 5.836  loss_mask_3: 5.851  loss_mask_4: 5.853  loss_mask_5: 5.871  loss_mask_6: 5.891  loss_mask_7: 6.239  loss_mask_8: 6.234  time: 2.6073  data_time: 0.0610  lr: 8.15e-05  max_mem: 27639M
[01/29 08:08:22] d2.utils.events INFO:  eta: 1 day, 10:35:58  iter: 12219  total_loss: 57.78  loss_mask: 5.989  loss_mask_0: 5.824  loss_mask_1: 5.699  loss_mask_2: 5.698  loss_mask_3: 5.672  loss_mask_4: 5.67  loss_mask_5: 5.672  loss_mask_6: 5.645  loss_mask_7: 5.983  loss_mask_8: 5.995  time: 2.6073  data_time: 0.0632  lr: 8.1469e-05  max_mem: 27639M
[01/29 08:09:14] d2.utils.events INFO:  eta: 1 day, 10:35:04  iter: 12239  total_loss: 57.38  loss_mask: 5.958  loss_mask_0: 5.918  loss_mask_1: 5.607  loss_mask_2: 5.57  loss_mask_3: 5.592  loss_mask_4: 5.599  loss_mask_5: 5.616  loss_mask_6: 5.627  loss_mask_7: 5.947  loss_mask_8: 5.956  time: 2.6073  data_time: 0.0560  lr: 8.1439e-05  max_mem: 27639M
[01/29 08:10:07] d2.utils.events INFO:  eta: 1 day, 10:34:20  iter: 12259  total_loss: 58.99  loss_mask: 6.038  loss_mask_0: 5.87  loss_mask_1: 5.834  loss_mask_2: 5.826  loss_mask_3: 5.847  loss_mask_4: 5.855  loss_mask_5: 5.846  loss_mask_6: 5.824  loss_mask_7: 6.01  loss_mask_8: 6.035  time: 2.6074  data_time: 0.0539  lr: 8.1408e-05  max_mem: 27639M
[01/29 08:10:59] d2.utils.events INFO:  eta: 1 day, 10:33:46  iter: 12279  total_loss: 60.51  loss_mask: 6.276  loss_mask_0: 6.057  loss_mask_1: 5.939  loss_mask_2: 5.947  loss_mask_3: 5.922  loss_mask_4: 5.949  loss_mask_5: 5.945  loss_mask_6: 5.917  loss_mask_7: 6.271  loss_mask_8: 6.288  time: 2.6074  data_time: 0.0548  lr: 8.1377e-05  max_mem: 27639M
[01/29 08:11:52] d2.utils.events INFO:  eta: 1 day, 10:32:57  iter: 12299  total_loss: 53.71  loss_mask: 5.646  loss_mask_0: 5.416  loss_mask_1: 5.253  loss_mask_2: 5.245  loss_mask_3: 5.255  loss_mask_4: 5.271  loss_mask_5: 5.272  loss_mask_6: 5.293  loss_mask_7: 5.649  loss_mask_8: 5.643  time: 2.6074  data_time: 0.0586  lr: 8.1346e-05  max_mem: 27639M
[01/29 08:12:44] d2.utils.events INFO:  eta: 1 day, 10:32:07  iter: 12319  total_loss: 57.42  loss_mask: 5.907  loss_mask_0: 5.764  loss_mask_1: 5.688  loss_mask_2: 5.626  loss_mask_3: 5.681  loss_mask_4: 5.666  loss_mask_5: 5.712  loss_mask_6: 5.712  loss_mask_7: 5.922  loss_mask_8: 5.932  time: 2.6074  data_time: 0.0550  lr: 8.1316e-05  max_mem: 27639M
[01/29 08:13:36] d2.utils.events INFO:  eta: 1 day, 10:31:15  iter: 12339  total_loss: 56.72  loss_mask: 5.831  loss_mask_0: 5.715  loss_mask_1: 5.602  loss_mask_2: 5.611  loss_mask_3: 5.609  loss_mask_4: 5.614  loss_mask_5: 5.611  loss_mask_6: 5.642  loss_mask_7: 5.822  loss_mask_8: 5.84  time: 2.6074  data_time: 0.0571  lr: 8.1285e-05  max_mem: 27639M
[01/29 08:14:28] d2.utils.events INFO:  eta: 1 day, 10:30:16  iter: 12359  total_loss: 55.18  loss_mask: 5.769  loss_mask_0: 5.539  loss_mask_1: 5.412  loss_mask_2: 5.404  loss_mask_3: 5.376  loss_mask_4: 5.375  loss_mask_5: 5.387  loss_mask_6: 5.373  loss_mask_7: 5.783  loss_mask_8: 5.765  time: 2.6074  data_time: 0.0518  lr: 8.1254e-05  max_mem: 27639M
[01/29 08:15:20] d2.utils.events INFO:  eta: 1 day, 10:29:22  iter: 12379  total_loss: 67.36  loss_mask: 6.881  loss_mask_0: 6.712  loss_mask_1: 6.647  loss_mask_2: 6.645  loss_mask_3: 6.682  loss_mask_4: 6.675  loss_mask_5: 6.672  loss_mask_6: 6.69  loss_mask_7: 6.886  loss_mask_8: 6.87  time: 2.6074  data_time: 0.0585  lr: 8.1224e-05  max_mem: 27639M
[01/29 08:16:13] d2.utils.events INFO:  eta: 1 day, 10:28:29  iter: 12399  total_loss: 54.2  loss_mask: 5.573  loss_mask_0: 5.416  loss_mask_1: 5.374  loss_mask_2: 5.37  loss_mask_3: 5.343  loss_mask_4: 5.326  loss_mask_5: 5.326  loss_mask_6: 5.308  loss_mask_7: 5.565  loss_mask_8: 5.594  time: 2.6074  data_time: 0.0517  lr: 8.1193e-05  max_mem: 27639M
[01/29 08:17:05] d2.utils.events INFO:  eta: 1 day, 10:28:08  iter: 12419  total_loss: 57.14  loss_mask: 5.903  loss_mask_0: 5.729  loss_mask_1: 5.616  loss_mask_2: 5.613  loss_mask_3: 5.613  loss_mask_4: 5.6  loss_mask_5: 5.565  loss_mask_6: 5.588  loss_mask_7: 5.891  loss_mask_8: 5.875  time: 2.6074  data_time: 0.0574  lr: 8.1162e-05  max_mem: 27639M
[01/29 08:17:57] d2.utils.events INFO:  eta: 1 day, 10:27:33  iter: 12439  total_loss: 60.16  loss_mask: 6.163  loss_mask_0: 5.906  loss_mask_1: 5.955  loss_mask_2: 5.946  loss_mask_3: 5.951  loss_mask_4: 5.903  loss_mask_5: 5.943  loss_mask_6: 5.952  loss_mask_7: 6.172  loss_mask_8: 6.174  time: 2.6074  data_time: 0.0636  lr: 8.1132e-05  max_mem: 27639M
[01/29 08:18:50] d2.utils.events INFO:  eta: 1 day, 10:26:54  iter: 12459  total_loss: 52.24  loss_mask: 5.419  loss_mask_0: 5.251  loss_mask_1: 5.156  loss_mask_2: 5.134  loss_mask_3: 5.139  loss_mask_4: 5.126  loss_mask_5: 5.129  loss_mask_6: 5.122  loss_mask_7: 5.438  loss_mask_8: 5.425  time: 2.6074  data_time: 0.0582  lr: 8.1101e-05  max_mem: 27639M
[01/29 08:19:42] d2.utils.events INFO:  eta: 1 day, 10:26:09  iter: 12479  total_loss: 54.95  loss_mask: 5.663  loss_mask_0: 5.53  loss_mask_1: 5.414  loss_mask_2: 5.469  loss_mask_3: 5.476  loss_mask_4: 5.422  loss_mask_5: 5.412  loss_mask_6: 5.424  loss_mask_7: 5.66  loss_mask_8: 5.666  time: 2.6074  data_time: 0.0638  lr: 8.107e-05  max_mem: 27639M
[01/29 08:20:34] d2.utils.events INFO:  eta: 1 day, 10:25:22  iter: 12499  total_loss: 57.37  loss_mask: 5.815  loss_mask_0: 5.769  loss_mask_1: 5.718  loss_mask_2: 5.717  loss_mask_3: 5.687  loss_mask_4: 5.646  loss_mask_5: 5.656  loss_mask_6: 5.673  loss_mask_7: 5.804  loss_mask_8: 5.792  time: 2.6075  data_time: 0.0621  lr: 8.1039e-05  max_mem: 27639M
[01/29 08:21:27] d2.utils.events INFO:  eta: 1 day, 10:24:42  iter: 12519  total_loss: 55.84  loss_mask: 5.749  loss_mask_0: 5.623  loss_mask_1: 5.493  loss_mask_2: 5.506  loss_mask_3: 5.505  loss_mask_4: 5.487  loss_mask_5: 5.496  loss_mask_6: 5.497  loss_mask_7: 5.766  loss_mask_8: 5.758  time: 2.6075  data_time: 0.0571  lr: 8.1009e-05  max_mem: 27639M
[01/29 08:22:19] d2.utils.events INFO:  eta: 1 day, 10:23:48  iter: 12539  total_loss: 55.41  loss_mask: 5.759  loss_mask_0: 5.593  loss_mask_1: 5.484  loss_mask_2: 5.501  loss_mask_3: 5.45  loss_mask_4: 5.461  loss_mask_5: 5.443  loss_mask_6: 5.438  loss_mask_7: 5.754  loss_mask_8: 5.759  time: 2.6075  data_time: 0.0640  lr: 8.0978e-05  max_mem: 27639M
[01/29 08:23:11] d2.utils.events INFO:  eta: 1 day, 10:22:58  iter: 12559  total_loss: 57.56  loss_mask: 5.943  loss_mask_0: 5.686  loss_mask_1: 5.636  loss_mask_2: 5.649  loss_mask_3: 5.648  loss_mask_4: 5.616  loss_mask_5: 5.634  loss_mask_6: 5.631  loss_mask_7: 5.952  loss_mask_8: 5.959  time: 2.6075  data_time: 0.0477  lr: 8.0947e-05  max_mem: 27639M
[01/29 08:24:04] d2.utils.events INFO:  eta: 1 day, 10:22:37  iter: 12579  total_loss: 54.07  loss_mask: 5.587  loss_mask_0: 5.424  loss_mask_1: 5.318  loss_mask_2: 5.295  loss_mask_3: 5.321  loss_mask_4: 5.345  loss_mask_5: 5.333  loss_mask_6: 5.32  loss_mask_7: 5.61  loss_mask_8: 5.603  time: 2.6075  data_time: 0.0533  lr: 8.0917e-05  max_mem: 27639M
[01/29 08:24:56] d2.utils.events INFO:  eta: 1 day, 10:22:13  iter: 12599  total_loss: 59.09  loss_mask: 6.166  loss_mask_0: 5.798  loss_mask_1: 5.788  loss_mask_2: 5.765  loss_mask_3: 5.771  loss_mask_4: 5.803  loss_mask_5: 5.802  loss_mask_6: 5.777  loss_mask_7: 6.223  loss_mask_8: 6.192  time: 2.6075  data_time: 0.0544  lr: 8.0886e-05  max_mem: 27639M
[01/29 08:25:48] d2.utils.events INFO:  eta: 1 day, 10:21:02  iter: 12619  total_loss: 59.17  loss_mask: 6.217  loss_mask_0: 5.894  loss_mask_1: 5.837  loss_mask_2: 5.811  loss_mask_3: 5.822  loss_mask_4: 5.801  loss_mask_5: 5.808  loss_mask_6: 5.801  loss_mask_7: 6.179  loss_mask_8: 6.189  time: 2.6075  data_time: 0.0512  lr: 8.0855e-05  max_mem: 27639M
[01/29 08:26:40] d2.utils.events INFO:  eta: 1 day, 10:20:09  iter: 12639  total_loss: 59.01  loss_mask: 6.109  loss_mask_0: 5.912  loss_mask_1: 5.807  loss_mask_2: 5.77  loss_mask_3: 5.775  loss_mask_4: 5.786  loss_mask_5: 5.79  loss_mask_6: 5.78  loss_mask_7: 6.114  loss_mask_8: 6.116  time: 2.6075  data_time: 0.0505  lr: 8.0824e-05  max_mem: 27639M
[01/29 08:27:33] d2.utils.events INFO:  eta: 1 day, 10:19:57  iter: 12659  total_loss: 52.58  loss_mask: 5.438  loss_mask_0: 5.273  loss_mask_1: 5.213  loss_mask_2: 5.17  loss_mask_3: 5.184  loss_mask_4: 5.167  loss_mask_5: 5.185  loss_mask_6: 5.205  loss_mask_7: 5.45  loss_mask_8: 5.436  time: 2.6075  data_time: 0.0573  lr: 8.0794e-05  max_mem: 27639M
[01/29 08:28:25] d2.utils.events INFO:  eta: 1 day, 10:18:59  iter: 12679  total_loss: 52.64  loss_mask: 5.398  loss_mask_0: 5.265  loss_mask_1: 5.17  loss_mask_2: 5.162  loss_mask_3: 5.179  loss_mask_4: 5.175  loss_mask_5: 5.17  loss_mask_6: 5.173  loss_mask_7: 5.41  loss_mask_8: 5.416  time: 2.6076  data_time: 0.0610  lr: 8.0763e-05  max_mem: 27639M
[01/29 08:29:18] d2.utils.events INFO:  eta: 1 day, 10:18:03  iter: 12699  total_loss: 57.24  loss_mask: 5.91  loss_mask_0: 5.666  loss_mask_1: 5.657  loss_mask_2: 5.616  loss_mask_3: 5.618  loss_mask_4: 5.655  loss_mask_5: 5.627  loss_mask_6: 5.647  loss_mask_7: 5.933  loss_mask_8: 5.912  time: 2.6076  data_time: 0.0582  lr: 8.0732e-05  max_mem: 27639M
[01/29 08:30:10] d2.utils.events INFO:  eta: 1 day, 10:17:21  iter: 12719  total_loss: 59.39  loss_mask: 6.148  loss_mask_0: 5.868  loss_mask_1: 5.722  loss_mask_2: 5.769  loss_mask_3: 5.802  loss_mask_4: 5.837  loss_mask_5: 5.804  loss_mask_6: 5.846  loss_mask_7: 6.129  loss_mask_8: 6.143  time: 2.6076  data_time: 0.0521  lr: 8.0702e-05  max_mem: 27639M
[01/29 08:31:02] d2.utils.events INFO:  eta: 1 day, 10:15:50  iter: 12739  total_loss: 53.28  loss_mask: 5.56  loss_mask_0: 5.234  loss_mask_1: 5.227  loss_mask_2: 5.251  loss_mask_3: 5.257  loss_mask_4: 5.258  loss_mask_5: 5.256  loss_mask_6: 5.252  loss_mask_7: 5.592  loss_mask_8: 5.572  time: 2.6076  data_time: 0.0579  lr: 8.0671e-05  max_mem: 27639M
[01/29 08:31:54] d2.utils.events INFO:  eta: 1 day, 10:14:55  iter: 12759  total_loss: 55.67  loss_mask: 5.692  loss_mask_0: 5.543  loss_mask_1: 5.455  loss_mask_2: 5.433  loss_mask_3: 5.45  loss_mask_4: 5.449  loss_mask_5: 5.427  loss_mask_6: 5.421  loss_mask_7: 5.703  loss_mask_8: 5.714  time: 2.6076  data_time: 0.0574  lr: 8.064e-05  max_mem: 27639M
[01/29 08:32:47] d2.utils.events INFO:  eta: 1 day, 10:13:44  iter: 12779  total_loss: 52.29  loss_mask: 5.402  loss_mask_0: 5.202  loss_mask_1: 5.147  loss_mask_2: 5.118  loss_mask_3: 5.107  loss_mask_4: 5.124  loss_mask_5: 5.12  loss_mask_6: 5.12  loss_mask_7: 5.384  loss_mask_8: 5.391  time: 2.6076  data_time: 0.0532  lr: 8.0609e-05  max_mem: 27639M
[01/29 08:33:39] d2.utils.events INFO:  eta: 1 day, 10:12:23  iter: 12799  total_loss: 55.35  loss_mask: 5.784  loss_mask_0: 5.625  loss_mask_1: 5.41  loss_mask_2: 5.423  loss_mask_3: 5.418  loss_mask_4: 5.425  loss_mask_5: 5.407  loss_mask_6: 5.423  loss_mask_7: 5.755  loss_mask_8: 5.758  time: 2.6076  data_time: 0.0510  lr: 8.0579e-05  max_mem: 27639M
[01/29 08:34:31] d2.utils.events INFO:  eta: 1 day, 10:11:15  iter: 12819  total_loss: 57.15  loss_mask: 5.903  loss_mask_0: 5.706  loss_mask_1: 5.606  loss_mask_2: 5.583  loss_mask_3: 5.563  loss_mask_4: 5.586  loss_mask_5: 5.625  loss_mask_6: 5.618  loss_mask_7: 5.88  loss_mask_8: 5.908  time: 2.6076  data_time: 0.0668  lr: 8.0548e-05  max_mem: 27639M
[01/29 08:35:23] d2.utils.events INFO:  eta: 1 day, 10:10:10  iter: 12839  total_loss: 53.86  loss_mask: 5.668  loss_mask_0: 5.273  loss_mask_1: 5.238  loss_mask_2: 5.268  loss_mask_3: 5.268  loss_mask_4: 5.276  loss_mask_5: 5.237  loss_mask_6: 5.248  loss_mask_7: 5.679  loss_mask_8: 5.69  time: 2.6076  data_time: 0.0520  lr: 8.0517e-05  max_mem: 27639M
[01/29 08:36:16] d2.utils.events INFO:  eta: 1 day, 10:09:18  iter: 12859  total_loss: 57.48  loss_mask: 5.869  loss_mask_0: 5.741  loss_mask_1: 5.657  loss_mask_2: 5.682  loss_mask_3: 5.667  loss_mask_4: 5.673  loss_mask_5: 5.692  loss_mask_6: 5.699  loss_mask_7: 5.875  loss_mask_8: 5.913  time: 2.6076  data_time: 0.0559  lr: 8.0486e-05  max_mem: 27639M
[01/29 08:37:08] d2.utils.events INFO:  eta: 1 day, 10:07:54  iter: 12879  total_loss: 51.36  loss_mask: 5.311  loss_mask_0: 5.13  loss_mask_1: 5.046  loss_mask_2: 5.048  loss_mask_3: 5.062  loss_mask_4: 5.074  loss_mask_5: 5.063  loss_mask_6: 5.064  loss_mask_7: 5.299  loss_mask_8: 5.302  time: 2.6076  data_time: 0.0535  lr: 8.0456e-05  max_mem: 27639M
[01/29 08:38:00] d2.utils.events INFO:  eta: 1 day, 10:07:08  iter: 12899  total_loss: 53.88  loss_mask: 5.511  loss_mask_0: 5.342  loss_mask_1: 5.338  loss_mask_2: 5.326  loss_mask_3: 5.323  loss_mask_4: 5.313  loss_mask_5: 5.316  loss_mask_6: 5.344  loss_mask_7: 5.546  loss_mask_8: 5.521  time: 2.6076  data_time: 0.0549  lr: 8.0425e-05  max_mem: 27639M
[01/29 08:38:53] d2.utils.events INFO:  eta: 1 day, 10:06:50  iter: 12919  total_loss: 48.92  loss_mask: 5.086  loss_mask_0: 4.913  loss_mask_1: 4.825  loss_mask_2: 4.825  loss_mask_3: 4.825  loss_mask_4: 4.811  loss_mask_5: 4.804  loss_mask_6: 4.797  loss_mask_7: 5.066  loss_mask_8: 5.089  time: 2.6076  data_time: 0.0642  lr: 8.0394e-05  max_mem: 27639M
[01/29 08:39:45] d2.utils.events INFO:  eta: 1 day, 10:05:23  iter: 12939  total_loss: 54.07  loss_mask: 5.508  loss_mask_0: 5.415  loss_mask_1: 5.279  loss_mask_2: 5.289  loss_mask_3: 5.301  loss_mask_4: 5.297  loss_mask_5: 5.297  loss_mask_6: 5.307  loss_mask_7: 5.491  loss_mask_8: 5.494  time: 2.6076  data_time: 0.0631  lr: 8.0364e-05  max_mem: 27639M
[01/29 08:40:37] d2.utils.events INFO:  eta: 1 day, 10:04:21  iter: 12959  total_loss: 58.98  loss_mask: 6.066  loss_mask_0: 5.903  loss_mask_1: 5.844  loss_mask_2: 5.826  loss_mask_3: 5.828  loss_mask_4: 5.833  loss_mask_5: 5.833  loss_mask_6: 5.816  loss_mask_7: 6.044  loss_mask_8: 6.063  time: 2.6077  data_time: 0.0637  lr: 8.0333e-05  max_mem: 27639M
[01/29 08:41:29] d2.utils.events INFO:  eta: 1 day, 10:03:22  iter: 12979  total_loss: 56.25  loss_mask: 5.816  loss_mask_0: 5.593  loss_mask_1: 5.513  loss_mask_2: 5.52  loss_mask_3: 5.537  loss_mask_4: 5.514  loss_mask_5: 5.54  loss_mask_6: 5.554  loss_mask_7: 5.815  loss_mask_8: 5.826  time: 2.6077  data_time: 0.0582  lr: 8.0302e-05  max_mem: 27639M
[01/29 08:42:22] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 08:42:22] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 08:42:22] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 08:56:36] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.899854510117573, 'error_1pix': 0.6000474781070304, 'error_3pix': 0.3504568251823127, 'mIoU': 4.2907853036302965, 'fwIoU': 7.984943925918317, 'IoU-0': 0.024215084233207743, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.10405158304253163, 'IoU-7': 0.4352855414677029, 'IoU-8': 2.385964307511636, 'IoU-9': 7.16482536232001, 'IoU-10': 9.66369231173275, 'IoU-11': 12.351198999915567, 'IoU-12': 12.73480130588884, 'IoU-13': 11.985256793582606, 'IoU-14': 11.174231644186337, 'IoU-15': 10.388515963100744, 'IoU-16': 9.536540674271059, 'IoU-17': 9.010469179643295, 'IoU-18': 9.186426407528629, 'IoU-19': 8.730487948522299, 'IoU-20': 8.02747178274679, 'IoU-21': 7.495507632123447, 'IoU-22': 8.793209258353214, 'IoU-23': 7.750849444918403, 'IoU-24': 8.31777697598995, 'IoU-25': 9.592900210991168, 'IoU-26': 10.290943267677264, 'IoU-27': 11.510875766727006, 'IoU-28': 11.71034025856032, 'IoU-29': 12.021041690559576, 'IoU-30': 12.277693366104655, 'IoU-31': 12.89991473615047, 'IoU-32': 12.708007686076305, 'IoU-33': 12.231665371090225, 'IoU-34': 11.915983276334883, 'IoU-35': 12.94960122086245, 'IoU-36': 13.51669129939845, 'IoU-37': 13.084758870418781, 'IoU-38': 12.922762458692407, 'IoU-39': 13.155156638973581, 'IoU-40': 13.314932166030319, 'IoU-41': 12.29978459556186, 'IoU-42': 12.220270931183236, 'IoU-43': 11.860293885988337, 'IoU-44': 11.721684082497726, 'IoU-45': 10.87604150395856, 'IoU-46': 10.389729610046865, 'IoU-47': 10.350106539064136, 'IoU-48': 10.01928697200329, 'IoU-49': 9.66980202794683, 'IoU-50': 9.179597854415752, 'IoU-51': 8.949289725275264, 'IoU-52': 8.544708945035667, 'IoU-53': 7.8813326471345535, 'IoU-54': 7.455292210523131, 'IoU-55': 6.99345814729327, 'IoU-56': 6.7601408465125665, 'IoU-57': 6.587692663218378, 'IoU-58': 6.385014210731967, 'IoU-59': 6.473776875052953, 'IoU-60': 6.419917904252961, 'IoU-61': 6.071567930504036, 'IoU-62': 5.899271339275307, 'IoU-63': 5.921202277160561, 'IoU-64': 5.988484833798131, 'IoU-65': 5.767359246960398, 'IoU-66': 5.550135595185354, 'IoU-67': 5.375512701996765, 'IoU-68': 5.307186007997675, 'IoU-69': 5.451151507209877, 'IoU-70': 5.3457038011646105, 'IoU-71': 5.33872658863771, 'IoU-72': 5.195004092455919, 'IoU-73': 5.138406030315721, 'IoU-74': 5.15236127213549, 'IoU-75': 5.102416318897754, 'IoU-76': 5.125385488487973, 'IoU-77': 4.979097156786143, 'IoU-78': 4.821560993361334, 'IoU-79': 4.629245310538032, 'IoU-80': 4.664741171302228, 'IoU-81': 4.626776844896453, 'IoU-82': 4.699681571750601, 'IoU-83': 4.683733637870911, 'IoU-84': 4.49957814193363, 'IoU-85': 4.467085481601357, 'IoU-86': 4.324697253575022, 'IoU-87': 4.07313687295152, 'IoU-88': 4.103073816099409, 'IoU-89': 3.832091764455191, 'IoU-90': 3.595365995456727, 'IoU-91': 3.3835772784920186, 'IoU-92': 3.202484459125249, 'IoU-93': 3.1867022008289525, 'IoU-94': 2.9086740145752317, 'IoU-95': 2.9488184723950184, 'IoU-96': 2.5759239349727, 'IoU-97': 2.6529790264024933, 'IoU-98': 2.6655057312733974, 'IoU-99': 2.566806944330716, 'IoU-100': 2.4767095984497485, 'IoU-101': 2.3598323068885834, 'IoU-102': 2.3123004788682713, 'IoU-103': 2.397770220815101, 'IoU-104': 2.2303142025618525, 'IoU-105': 2.1894735685820765, 'IoU-106': 2.046359765554026, 'IoU-107': 2.1100317590910236, 'IoU-108': 2.109672996913424, 'IoU-109': 2.0953635858309, 'IoU-110': 2.060253283938958, 'IoU-111': 1.9341583313561685, 'IoU-112': 1.9727066774611706, 'IoU-113': 1.9830696753027466, 'IoU-114': 1.8153916335585292, 'IoU-115': 1.901683292453516, 'IoU-116': 1.8135217604254712, 'IoU-117': 1.8233478089306703, 'IoU-118': 1.806923887692362, 'IoU-119': 1.8618951088459526, 'IoU-120': 1.658564551420251, 'IoU-121': 1.5852017414622837, 'IoU-122': 1.6196514401175903, 'IoU-123': 1.7230231028555267, 'IoU-124': 1.5163397151286089, 'IoU-125': 1.5088026431948691, 'IoU-126': 1.5688329089539286, 'IoU-127': 1.5456574969361918, 'IoU-128': 1.537053450509988, 'IoU-129': 1.4170781243954373, 'IoU-130': 1.47810850392687, 'IoU-131': 1.5147729659459215, 'IoU-132': 1.5524671728920436, 'IoU-133': 1.458868466548322, 'IoU-134': 1.4730843595676373, 'IoU-135': 1.3796512319091414, 'IoU-136': 1.5163730144081913, 'IoU-137': 1.6534554805654527, 'IoU-138': 1.519827537300732, 'IoU-139': 1.5079784736875916, 'IoU-140': 1.585883496365253, 'IoU-141': 1.4117667287823394, 'IoU-142': 1.281486351120035, 'IoU-143': 1.4742509004521418, 'IoU-144': 1.5027180676481329, 'IoU-145': 1.423755725422536, 'IoU-146': 1.39850040318213, 'IoU-147': 1.4774040789707426, 'IoU-148': 1.6077889952242737, 'IoU-149': 1.510839489783251, 'IoU-150': 1.1294392940151836, 'IoU-151': 1.077286453066705, 'IoU-152': 1.293148214017617, 'IoU-153': 1.1756557104283891, 'IoU-154': 1.2145350838373408, 'IoU-155': 1.1699306173008381, 'IoU-156': 1.1715519929148837, 'IoU-157': 1.4823169643236627, 'IoU-158': 1.0843212337845451, 'IoU-159': 1.0583951906522537, 'IoU-160': 1.4612798642238567, 'IoU-161': 1.171399880026381, 'IoU-162': 1.449070313505644, 'IoU-163': 1.290899474300943, 'IoU-164': 1.1202378076321124, 'IoU-165': 1.7889469152410835, 'IoU-166': 1.7479876067501665, 'IoU-167': 1.258338449795065, 'IoU-168': 1.0784235558605224, 'IoU-169': 1.1086530381440596, 'IoU-170': 0.9395501117841818, 'IoU-171': 0.9887851694885078, 'IoU-172': 0.8569860104072206, 'IoU-173': 1.0426657101094647, 'IoU-174': 1.0716681449616263, 'IoU-175': 0.950171688398169, 'IoU-176': 0.5409728579809229, 'IoU-177': 0.4482194070736922, 'IoU-178': 0.19029420381274628, 'IoU-179': 0.24209897296421848, 'IoU-180': 0.22908577920375525, 'IoU-181': 0.12195567907555036, 'IoU-182': 0.10677283980554046, 'IoU-183': 0.05454039157696629, 'IoU-184': 0.07197936736442437, 'IoU-185': 0.0015512740392073432, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 8.453993020710923, 'pACC': 14.564525591909014, 'ACC-0': 0.02421508517215142, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 39.623721839068565, 'ACC-7': 8.088575793707225, 'ACC-8': 13.680547921476135, 'ACC-9': 17.827544157791248, 'ACC-10': 16.608036347722223, 'ACC-11': 16.638254838742757, 'ACC-12': 17.702779845437835, 'ACC-13': 17.99421406462173, 'ACC-14': 18.102874312187648, 'ACC-15': 18.51988780168186, 'ACC-16': 17.651970651665653, 'ACC-17': 17.762767908278114, 'ACC-18': 16.614498882289464, 'ACC-19': 15.387163313933577, 'ACC-20': 14.454355128270818, 'ACC-21': 13.48986099931889, 'ACC-22': 15.435081535435879, 'ACC-23': 14.838348191638426, 'ACC-24': 16.220901403150872, 'ACC-25': 18.644166495630937, 'ACC-26': 19.81992332212992, 'ACC-27': 20.941978663829136, 'ACC-28': 21.446807193539218, 'ACC-29': 21.206734428679475, 'ACC-30': 22.061925782878294, 'ACC-31': 23.011306399066697, 'ACC-32': 23.260455807014406, 'ACC-33': 23.059939591112975, 'ACC-34': 22.283740037431336, 'ACC-35': 23.682116530534714, 'ACC-36': 24.594153086097144, 'ACC-37': 24.01461631975824, 'ACC-38': 23.57317962235675, 'ACC-39': 24.47666474267695, 'ACC-40': 25.175462758865642, 'ACC-41': 24.20307029325309, 'ACC-42': 23.907443616860956, 'ACC-43': 22.95671691962317, 'ACC-44': 21.879124665939703, 'ACC-45': 20.33005777816106, 'ACC-46': 19.855049680967735, 'ACC-47': 19.957530959411717, 'ACC-48': 19.293870506560886, 'ACC-49': 18.407553585463667, 'ACC-50': 17.296514160583914, 'ACC-51': 17.10151008904715, 'ACC-52': 16.50518848499165, 'ACC-53': 15.18606221038102, 'ACC-54': 14.140360181834152, 'ACC-55': 13.072763313040134, 'ACC-56': 12.549897728331812, 'ACC-57': 11.890715724331693, 'ACC-58': 11.591515673404047, 'ACC-59': 11.924065953391146, 'ACC-60': 11.968700062234237, 'ACC-61': 11.473547213556134, 'ACC-62': 11.153167526916846, 'ACC-63': 11.317634619953457, 'ACC-64': 11.514610584580286, 'ACC-65': 11.21591859485718, 'ACC-66': 10.81324194174154, 'ACC-67': 10.507151997051045, 'ACC-68': 10.357862938566804, 'ACC-69': 10.469377364080373, 'ACC-70': 10.271125562819535, 'ACC-71': 10.505808732200714, 'ACC-72': 10.301366122409343, 'ACC-73': 10.21082671953872, 'ACC-74': 10.198319507875953, 'ACC-75': 10.111407289631652, 'ACC-76': 10.004706512313396, 'ACC-77': 9.848113862314557, 'ACC-78': 9.608369809216214, 'ACC-79': 9.262204068485062, 'ACC-80': 9.260705604003702, 'ACC-81': 9.142032781653974, 'ACC-82': 9.297626524278076, 'ACC-83': 9.123625958102316, 'ACC-84': 8.814606488614682, 'ACC-85': 8.852330237891229, 'ACC-86': 8.645613893620666, 'ACC-87': 8.233474178541611, 'ACC-88': 8.276459112523355, 'ACC-89': 7.70532659664581, 'ACC-90': 7.140132685537777, 'ACC-91': 6.675251285855845, 'ACC-92': 6.30287047137115, 'ACC-93': 6.2045745738269105, 'ACC-94': 5.587004410644908, 'ACC-95': 5.569004215079218, 'ACC-96': 4.879790050374122, 'ACC-97': 4.938288725795601, 'ACC-98': 4.982290760812168, 'ACC-99': 4.8540697481577935, 'ACC-100': 4.70185225281333, 'ACC-101': 4.539858417974761, 'ACC-102': 4.476098776619846, 'ACC-103': 4.633701709643903, 'ACC-104': 4.344261085561103, 'ACC-105': 4.276001002157806, 'ACC-106': 3.942717744707866, 'ACC-107': 4.0259530811328865, 'ACC-108': 3.941464067120879, 'ACC-109': 3.8653234734217548, 'ACC-110': 3.8649644146383397, 'ACC-111': 3.640593303228795, 'ACC-112': 3.7569592783371006, 'ACC-113': 3.771328898066897, 'ACC-114': 3.466148104389327, 'ACC-115': 3.588772119735992, 'ACC-116': 3.416924622420377, 'ACC-117': 3.4257072296912305, 'ACC-118': 3.4161776246096793, 'ACC-119': 3.4997514515103125, 'ACC-120': 3.0828211696658547, 'ACC-121': 2.9346932972751514, 'ACC-122': 3.019143857265514, 'ACC-123': 3.2108240290998658, 'ACC-124': 2.877042844258247, 'ACC-125': 2.852627308255825, 'ACC-126': 2.996498146613357, 'ACC-127': 2.9406405068732537, 'ACC-128': 2.948501691078448, 'ACC-129': 2.711979914141867, 'ACC-130': 2.843144336412627, 'ACC-131': 2.9333168517850248, 'ACC-132': 2.9252076819709596, 'ACC-133': 2.7422482598134277, 'ACC-134': 2.761016803102111, 'ACC-135': 2.621572316287555, 'ACC-136': 2.8767645825568393, 'ACC-137': 3.225648881063213, 'ACC-138': 2.975004441962586, 'ACC-139': 3.00208320864962, 'ACC-140': 3.1786339609764664, 'ACC-141': 2.7638313593283725, 'ACC-142': 2.5092986312519594, 'ACC-143': 2.904157152831506, 'ACC-144': 2.9152527075812276, 'ACC-145': 2.685301549676871, 'ACC-146': 2.6547257316488087, 'ACC-147': 2.8186145928023003, 'ACC-148': 3.0185798977426, 'ACC-149': 2.986910652297152, 'ACC-150': 2.2437771586466253, 'ACC-151': 2.147113397557027, 'ACC-152': 2.5320950502393957, 'ACC-153': 2.4840139980578613, 'ACC-154': 2.6391770492457733, 'ACC-155': 2.6565153834586837, 'ACC-156': 2.6814559134363667, 'ACC-157': 3.7974338977560556, 'ACC-158': 2.642858453378797, 'ACC-159': 2.7113276077655257, 'ACC-160': 3.7979855675700134, 'ACC-161': 2.9778671467126494, 'ACC-162': 3.8852904335303973, 'ACC-163': 3.3765078336265817, 'ACC-164': 3.0436740349886953, 'ACC-165': 5.315776601117439, 'ACC-166': 5.636484206461794, 'ACC-167': 4.215284183390746, 'ACC-168': 4.589809409944441, 'ACC-169': 4.940225621300841, 'ACC-170': 4.205531183894828, 'ACC-171': 4.590666208677667, 'ACC-172': 2.474904619031744, 'ACC-173': 2.849262284903651, 'ACC-174': 2.957047873084042, 'ACC-175': 2.08937673675628, 'ACC-176': 0.9668127466914325, 'ACC-177': 0.7204693385301614, 'ACC-178': 0.2785337765664628, 'ACC-179': 0.3518090573586728, 'ACC-180': 0.31071150394527414, 'ACC-181': 0.1579891089366883, 'ACC-182': 0.12935660488664713, 'ACC-183': 0.06686270308957483, 'ACC-184': 0.07806290785510958, 'ACC-185': 0.0016167103178452485, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 08:56:36] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 08:56:36] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 08:56:36] d2.evaluation.testing INFO: copypaste: 4.8999,0.6000,0.3505,4.2908,7.9849,8.4540,14.5645
[01/29 08:56:36] d2.utils.events INFO:  eta: 1 day, 10:02:30  iter: 12999  total_loss: 53.71  loss_mask: 5.474  loss_mask_0: 5.446  loss_mask_1: 5.336  loss_mask_2: 5.313  loss_mask_3: 5.303  loss_mask_4: 5.302  loss_mask_5: 5.311  loss_mask_6: 5.33  loss_mask_7: 5.467  loss_mask_8: 5.465  time: 2.6077  data_time: 0.0622  lr: 8.0271e-05  max_mem: 27639M
[01/29 08:57:28] d2.utils.events INFO:  eta: 1 day, 10:01:39  iter: 13019  total_loss: 64.17  loss_mask: 6.502  loss_mask_0: 6.373  loss_mask_1: 6.341  loss_mask_2: 6.36  loss_mask_3: 6.352  loss_mask_4: 6.354  loss_mask_5: 6.344  loss_mask_6: 6.338  loss_mask_7: 6.494  loss_mask_8: 6.492  time: 2.6077  data_time: 0.0596  lr: 8.0241e-05  max_mem: 27639M
[01/29 08:58:20] d2.utils.events INFO:  eta: 1 day, 10:00:25  iter: 13039  total_loss: 53.63  loss_mask: 5.605  loss_mask_0: 5.318  loss_mask_1: 5.33  loss_mask_2: 5.295  loss_mask_3: 5.237  loss_mask_4: 5.246  loss_mask_5: 5.297  loss_mask_6: 5.316  loss_mask_7: 5.578  loss_mask_8: 5.585  time: 2.6076  data_time: 0.0545  lr: 8.021e-05  max_mem: 27639M
[01/29 08:59:12] d2.utils.events INFO:  eta: 1 day, 9:59:27  iter: 13059  total_loss: 54.55  loss_mask: 5.698  loss_mask_0: 5.48  loss_mask_1: 5.373  loss_mask_2: 5.375  loss_mask_3: 5.359  loss_mask_4: 5.36  loss_mask_5: 5.365  loss_mask_6: 5.378  loss_mask_7: 5.696  loss_mask_8: 5.694  time: 2.6076  data_time: 0.0524  lr: 8.0179e-05  max_mem: 27639M
[01/29 09:00:05] d2.utils.events INFO:  eta: 1 day, 9:58:31  iter: 13079  total_loss: 55.83  loss_mask: 5.787  loss_mask_0: 5.682  loss_mask_1: 5.521  loss_mask_2: 5.479  loss_mask_3: 5.515  loss_mask_4: 5.482  loss_mask_5: 5.46  loss_mask_6: 5.452  loss_mask_7: 5.748  loss_mask_8: 5.796  time: 2.6077  data_time: 0.0487  lr: 8.0148e-05  max_mem: 27639M
[01/29 09:00:57] d2.utils.events INFO:  eta: 1 day, 9:57:46  iter: 13099  total_loss: 54.89  loss_mask: 5.736  loss_mask_0: 5.419  loss_mask_1: 5.349  loss_mask_2: 5.381  loss_mask_3: 5.4  loss_mask_4: 5.398  loss_mask_5: 5.423  loss_mask_6: 5.372  loss_mask_7: 5.676  loss_mask_8: 5.738  time: 2.6077  data_time: 0.0651  lr: 8.0118e-05  max_mem: 27639M
[01/29 09:01:49] d2.utils.events INFO:  eta: 1 day, 9:56:54  iter: 13119  total_loss: 59.85  loss_mask: 6.15  loss_mask_0: 5.991  loss_mask_1: 5.925  loss_mask_2: 5.892  loss_mask_3: 5.915  loss_mask_4: 5.908  loss_mask_5: 5.933  loss_mask_6: 5.937  loss_mask_7: 6.154  loss_mask_8: 6.157  time: 2.6077  data_time: 0.0613  lr: 8.0087e-05  max_mem: 27639M
[01/29 09:02:42] d2.utils.events INFO:  eta: 1 day, 9:56:06  iter: 13139  total_loss: 51.1  loss_mask: 5.402  loss_mask_0: 5.176  loss_mask_1: 5.045  loss_mask_2: 5.027  loss_mask_3: 5.012  loss_mask_4: 5.016  loss_mask_5: 5.033  loss_mask_6: 4.989  loss_mask_7: 5.405  loss_mask_8: 5.407  time: 2.6077  data_time: 0.0523  lr: 8.0056e-05  max_mem: 27639M
[01/29 09:03:34] d2.utils.events INFO:  eta: 1 day, 9:54:58  iter: 13159  total_loss: 52.11  loss_mask: 5.39  loss_mask_0: 5.131  loss_mask_1: 5.092  loss_mask_2: 5.098  loss_mask_3: 5.116  loss_mask_4: 5.096  loss_mask_5: 5.076  loss_mask_6: 5.115  loss_mask_7: 5.38  loss_mask_8: 5.398  time: 2.6077  data_time: 0.0652  lr: 8.0025e-05  max_mem: 27639M
[01/29 09:04:26] d2.utils.events INFO:  eta: 1 day, 9:54:06  iter: 13179  total_loss: 52.05  loss_mask: 5.387  loss_mask_0: 5.167  loss_mask_1: 5.126  loss_mask_2: 5.107  loss_mask_3: 5.107  loss_mask_4: 5.117  loss_mask_5: 5.11  loss_mask_6: 5.108  loss_mask_7: 5.36  loss_mask_8: 5.386  time: 2.6077  data_time: 0.0583  lr: 7.9995e-05  max_mem: 27639M
[01/29 09:05:18] d2.utils.events INFO:  eta: 1 day, 9:53:19  iter: 13199  total_loss: 54.75  loss_mask: 5.565  loss_mask_0: 5.464  loss_mask_1: 5.391  loss_mask_2: 5.419  loss_mask_3: 5.432  loss_mask_4: 5.411  loss_mask_5: 5.398  loss_mask_6: 5.416  loss_mask_7: 5.587  loss_mask_8: 5.594  time: 2.6077  data_time: 0.0542  lr: 7.9964e-05  max_mem: 27639M
[01/29 09:06:11] d2.utils.events INFO:  eta: 1 day, 9:52:34  iter: 13219  total_loss: 61.82  loss_mask: 6.404  loss_mask_0: 6.103  loss_mask_1: 6.046  loss_mask_2: 6.053  loss_mask_3: 6.063  loss_mask_4: 6.095  loss_mask_5: 6.099  loss_mask_6: 6.092  loss_mask_7: 6.414  loss_mask_8: 6.429  time: 2.6077  data_time: 0.0571  lr: 7.9933e-05  max_mem: 27639M
[01/29 09:07:03] d2.utils.events INFO:  eta: 1 day, 9:51:44  iter: 13239  total_loss: 56.03  loss_mask: 5.734  loss_mask_0: 5.59  loss_mask_1: 5.504  loss_mask_2: 5.518  loss_mask_3: 5.533  loss_mask_4: 5.523  loss_mask_5: 5.53  loss_mask_6: 5.556  loss_mask_7: 5.766  loss_mask_8: 5.752  time: 2.6077  data_time: 0.0593  lr: 7.9902e-05  max_mem: 27639M
[01/29 09:07:55] d2.utils.events INFO:  eta: 1 day, 9:50:47  iter: 13259  total_loss: 51.46  loss_mask: 5.424  loss_mask_0: 5.106  loss_mask_1: 5.067  loss_mask_2: 5.054  loss_mask_3: 5.046  loss_mask_4: 5.076  loss_mask_5: 5.077  loss_mask_6: 5.092  loss_mask_7: 5.427  loss_mask_8: 5.428  time: 2.6077  data_time: 0.0600  lr: 7.9872e-05  max_mem: 27639M
[01/29 09:08:48] d2.utils.events INFO:  eta: 1 day, 9:49:55  iter: 13279  total_loss: 50.95  loss_mask: 5.358  loss_mask_0: 5.034  loss_mask_1: 5.007  loss_mask_2: 4.994  loss_mask_3: 5.016  loss_mask_4: 5.019  loss_mask_5: 5.005  loss_mask_6: 4.99  loss_mask_7: 5.359  loss_mask_8: 5.376  time: 2.6077  data_time: 0.0573  lr: 7.9841e-05  max_mem: 27639M
[01/29 09:09:40] d2.utils.events INFO:  eta: 1 day, 9:49:05  iter: 13299  total_loss: 55.79  loss_mask: 5.803  loss_mask_0: 5.549  loss_mask_1: 5.423  loss_mask_2: 5.438  loss_mask_3: 5.45  loss_mask_4: 5.45  loss_mask_5: 5.458  loss_mask_6: 5.449  loss_mask_7: 5.802  loss_mask_8: 5.802  time: 2.6078  data_time: 0.0518  lr: 7.981e-05  max_mem: 27639M
[01/29 09:10:32] d2.utils.events INFO:  eta: 1 day, 9:48:15  iter: 13319  total_loss: 54.16  loss_mask: 5.581  loss_mask_0: 5.416  loss_mask_1: 5.306  loss_mask_2: 5.31  loss_mask_3: 5.33  loss_mask_4: 5.326  loss_mask_5: 5.336  loss_mask_6: 5.335  loss_mask_7: 5.578  loss_mask_8: 5.577  time: 2.6078  data_time: 0.0558  lr: 7.9779e-05  max_mem: 27639M
[01/29 09:11:24] d2.utils.events INFO:  eta: 1 day, 9:47:10  iter: 13339  total_loss: 52.63  loss_mask: 5.468  loss_mask_0: 5.311  loss_mask_1: 5.158  loss_mask_2: 5.163  loss_mask_3: 5.176  loss_mask_4: 5.157  loss_mask_5: 5.175  loss_mask_6: 5.183  loss_mask_7: 5.472  loss_mask_8: 5.456  time: 2.6078  data_time: 0.0552  lr: 7.9748e-05  max_mem: 27639M
[01/29 09:12:17] d2.utils.events INFO:  eta: 1 day, 9:46:18  iter: 13359  total_loss: 49.63  loss_mask: 5.084  loss_mask_0: 5.005  loss_mask_1: 4.944  loss_mask_2: 4.94  loss_mask_3: 4.906  loss_mask_4: 4.897  loss_mask_5: 4.904  loss_mask_6: 4.905  loss_mask_7: 5.092  loss_mask_8: 5.087  time: 2.6078  data_time: 0.0521  lr: 7.9718e-05  max_mem: 27639M
[01/29 09:13:09] d2.utils.events INFO:  eta: 1 day, 9:45:13  iter: 13379  total_loss: 47.84  loss_mask: 5.107  loss_mask_0: 4.71  loss_mask_1: 4.632  loss_mask_2: 4.649  loss_mask_3: 4.647  loss_mask_4: 4.667  loss_mask_5: 4.693  loss_mask_6: 4.699  loss_mask_7: 5.114  loss_mask_8: 5.108  time: 2.6078  data_time: 0.0547  lr: 7.9687e-05  max_mem: 27639M
[01/29 09:14:01] d2.utils.events INFO:  eta: 1 day, 9:44:37  iter: 13399  total_loss: 49.72  loss_mask: 5.127  loss_mask_0: 4.959  loss_mask_1: 4.886  loss_mask_2: 4.893  loss_mask_3: 4.912  loss_mask_4: 4.893  loss_mask_5: 4.885  loss_mask_6: 4.9  loss_mask_7: 5.134  loss_mask_8: 5.128  time: 2.6078  data_time: 0.0663  lr: 7.9656e-05  max_mem: 27639M
[01/29 09:14:53] d2.utils.events INFO:  eta: 1 day, 9:43:36  iter: 13419  total_loss: 50.35  loss_mask: 5.173  loss_mask_0: 5.108  loss_mask_1: 4.945  loss_mask_2: 4.945  loss_mask_3: 4.948  loss_mask_4: 4.935  loss_mask_5: 4.964  loss_mask_6: 4.97  loss_mask_7: 5.187  loss_mask_8: 5.177  time: 2.6078  data_time: 0.0582  lr: 7.9625e-05  max_mem: 27639M
[01/29 09:15:46] d2.utils.events INFO:  eta: 1 day, 9:42:36  iter: 13439  total_loss: 54.63  loss_mask: 5.669  loss_mask_0: 5.425  loss_mask_1: 5.388  loss_mask_2: 5.402  loss_mask_3: 5.408  loss_mask_4: 5.37  loss_mask_5: 5.413  loss_mask_6: 5.412  loss_mask_7: 5.659  loss_mask_8: 5.667  time: 2.6078  data_time: 0.0578  lr: 7.9595e-05  max_mem: 27639M
[01/29 09:16:38] d2.utils.events INFO:  eta: 1 day, 9:41:40  iter: 13459  total_loss: 52.83  loss_mask: 5.439  loss_mask_0: 5.235  loss_mask_1: 5.228  loss_mask_2: 5.201  loss_mask_3: 5.202  loss_mask_4: 5.221  loss_mask_5: 5.218  loss_mask_6: 5.218  loss_mask_7: 5.432  loss_mask_8: 5.434  time: 2.6078  data_time: 0.0589  lr: 7.9564e-05  max_mem: 27639M
[01/29 09:17:31] d2.utils.events INFO:  eta: 1 day, 9:40:47  iter: 13479  total_loss: 50.62  loss_mask: 5.203  loss_mask_0: 5.077  loss_mask_1: 4.983  loss_mask_2: 4.977  loss_mask_3: 4.977  loss_mask_4: 4.967  loss_mask_5: 4.965  loss_mask_6: 4.964  loss_mask_7: 5.187  loss_mask_8: 5.208  time: 2.6078  data_time: 0.0568  lr: 7.9533e-05  max_mem: 27639M
[01/29 09:18:23] d2.utils.events INFO:  eta: 1 day, 9:39:55  iter: 13499  total_loss: 54.59  loss_mask: 5.628  loss_mask_0: 5.44  loss_mask_1: 5.399  loss_mask_2: 5.358  loss_mask_3: 5.351  loss_mask_4: 5.365  loss_mask_5: 5.384  loss_mask_6: 5.373  loss_mask_7: 5.603  loss_mask_8: 5.599  time: 2.6078  data_time: 0.0534  lr: 7.9502e-05  max_mem: 27639M
[01/29 09:19:15] d2.utils.events INFO:  eta: 1 day, 9:38:57  iter: 13519  total_loss: 52.77  loss_mask: 5.515  loss_mask_0: 5.336  loss_mask_1: 5.175  loss_mask_2: 5.119  loss_mask_3: 5.104  loss_mask_4: 5.086  loss_mask_5: 5.122  loss_mask_6: 5.111  loss_mask_7: 5.539  loss_mask_8: 5.523  time: 2.6078  data_time: 0.0583  lr: 7.9472e-05  max_mem: 27639M
[01/29 09:20:08] d2.utils.events INFO:  eta: 1 day, 9:38:05  iter: 13539  total_loss: 54.04  loss_mask: 5.523  loss_mask_0: 5.558  loss_mask_1: 5.358  loss_mask_2: 5.38  loss_mask_3: 5.325  loss_mask_4: 5.346  loss_mask_5: 5.372  loss_mask_6: 5.336  loss_mask_7: 5.53  loss_mask_8: 5.542  time: 2.6078  data_time: 0.0537  lr: 7.9441e-05  max_mem: 27639M
[01/29 09:21:00] d2.utils.events INFO:  eta: 1 day, 9:37:17  iter: 13559  total_loss: 51.48  loss_mask: 5.341  loss_mask_0: 5.038  loss_mask_1: 5.077  loss_mask_2: 5.075  loss_mask_3: 5.095  loss_mask_4: 5.093  loss_mask_5: 5.095  loss_mask_6: 5.111  loss_mask_7: 5.328  loss_mask_8: 5.331  time: 2.6079  data_time: 0.0516  lr: 7.941e-05  max_mem: 27639M
[01/29 09:21:52] d2.utils.events INFO:  eta: 1 day, 9:36:21  iter: 13579  total_loss: 57.18  loss_mask: 5.845  loss_mask_0: 5.66  loss_mask_1: 5.615  loss_mask_2: 5.651  loss_mask_3: 5.646  loss_mask_4: 5.645  loss_mask_5: 5.645  loss_mask_6: 5.623  loss_mask_7: 5.843  loss_mask_8: 5.869  time: 2.6079  data_time: 0.0515  lr: 7.9379e-05  max_mem: 27639M
[01/29 09:22:45] d2.utils.events INFO:  eta: 1 day, 9:35:36  iter: 13599  total_loss: 56.26  loss_mask: 5.73  loss_mask_0: 5.689  loss_mask_1: 5.524  loss_mask_2: 5.493  loss_mask_3: 5.553  loss_mask_4: 5.529  loss_mask_5: 5.536  loss_mask_6: 5.535  loss_mask_7: 5.746  loss_mask_8: 5.756  time: 2.6079  data_time: 0.0542  lr: 7.9348e-05  max_mem: 27639M
[01/29 09:23:37] d2.utils.events INFO:  eta: 1 day, 9:34:43  iter: 13619  total_loss: 51.06  loss_mask: 5.278  loss_mask_0: 5.124  loss_mask_1: 5.004  loss_mask_2: 4.976  loss_mask_3: 4.978  loss_mask_4: 4.991  loss_mask_5: 4.985  loss_mask_6: 5.007  loss_mask_7: 5.288  loss_mask_8: 5.282  time: 2.6079  data_time: 0.0488  lr: 7.9318e-05  max_mem: 27639M
[01/29 09:24:29] d2.utils.events INFO:  eta: 1 day, 9:33:51  iter: 13639  total_loss: 53.92  loss_mask: 5.577  loss_mask_0: 5.443  loss_mask_1: 5.284  loss_mask_2: 5.268  loss_mask_3: 5.266  loss_mask_4: 5.29  loss_mask_5: 5.294  loss_mask_6: 5.324  loss_mask_7: 5.586  loss_mask_8: 5.591  time: 2.6079  data_time: 0.0564  lr: 7.9287e-05  max_mem: 27639M
[01/29 09:25:21] d2.utils.events INFO:  eta: 1 day, 9:32:49  iter: 13659  total_loss: 57.83  loss_mask: 6.004  loss_mask_0: 5.676  loss_mask_1: 5.708  loss_mask_2: 5.689  loss_mask_3: 5.707  loss_mask_4: 5.712  loss_mask_5: 5.732  loss_mask_6: 5.719  loss_mask_7: 6.023  loss_mask_8: 6.018  time: 2.6079  data_time: 0.0602  lr: 7.9256e-05  max_mem: 27639M
[01/29 09:26:14] d2.utils.events INFO:  eta: 1 day, 9:32:08  iter: 13679  total_loss: 57.07  loss_mask: 5.9  loss_mask_0: 5.697  loss_mask_1: 5.621  loss_mask_2: 5.629  loss_mask_3: 5.616  loss_mask_4: 5.601  loss_mask_5: 5.612  loss_mask_6: 5.583  loss_mask_7: 5.906  loss_mask_8: 5.879  time: 2.6079  data_time: 0.0623  lr: 7.9225e-05  max_mem: 27639M
[01/29 09:27:06] d2.utils.events INFO:  eta: 1 day, 9:31:18  iter: 13699  total_loss: 55.99  loss_mask: 5.765  loss_mask_0: 5.623  loss_mask_1: 5.5  loss_mask_2: 5.506  loss_mask_3: 5.506  loss_mask_4: 5.502  loss_mask_5: 5.49  loss_mask_6: 5.5  loss_mask_7: 5.77  loss_mask_8: 5.771  time: 2.6079  data_time: 0.0640  lr: 7.9195e-05  max_mem: 27639M
[01/29 09:27:58] d2.utils.events INFO:  eta: 1 day, 9:30:28  iter: 13719  total_loss: 59.03  loss_mask: 6.108  loss_mask_0: 5.809  loss_mask_1: 5.809  loss_mask_2: 5.81  loss_mask_3: 5.837  loss_mask_4: 5.817  loss_mask_5: 5.79  loss_mask_6: 5.813  loss_mask_7: 6.132  loss_mask_8: 6.109  time: 2.6079  data_time: 0.0517  lr: 7.9164e-05  max_mem: 27639M
[01/29 09:28:51] d2.utils.events INFO:  eta: 1 day, 9:29:56  iter: 13739  total_loss: 54.63  loss_mask: 5.608  loss_mask_0: 5.402  loss_mask_1: 5.425  loss_mask_2: 5.413  loss_mask_3: 5.378  loss_mask_4: 5.368  loss_mask_5: 5.362  loss_mask_6: 5.318  loss_mask_7: 5.63  loss_mask_8: 5.638  time: 2.6080  data_time: 0.0608  lr: 7.9133e-05  max_mem: 27639M
[01/29 09:29:43] d2.utils.events INFO:  eta: 1 day, 9:28:51  iter: 13759  total_loss: 54.87  loss_mask: 5.74  loss_mask_0: 5.402  loss_mask_1: 5.404  loss_mask_2: 5.399  loss_mask_3: 5.419  loss_mask_4: 5.408  loss_mask_5: 5.384  loss_mask_6: 5.389  loss_mask_7: 5.734  loss_mask_8: 5.736  time: 2.6080  data_time: 0.0585  lr: 7.9102e-05  max_mem: 27639M
[01/29 09:30:35] d2.utils.events INFO:  eta: 1 day, 9:28:15  iter: 13779  total_loss: 58  loss_mask: 5.936  loss_mask_0: 5.921  loss_mask_1: 5.712  loss_mask_2: 5.72  loss_mask_3: 5.714  loss_mask_4: 5.724  loss_mask_5: 5.703  loss_mask_6: 5.692  loss_mask_7: 5.94  loss_mask_8: 5.936  time: 2.6080  data_time: 0.0571  lr: 7.9071e-05  max_mem: 27639M
[01/29 09:31:27] d2.utils.events INFO:  eta: 1 day, 9:27:16  iter: 13799  total_loss: 47.85  loss_mask: 4.894  loss_mask_0: 4.835  loss_mask_1: 4.741  loss_mask_2: 4.729  loss_mask_3: 4.722  loss_mask_4: 4.732  loss_mask_5: 4.736  loss_mask_6: 4.739  loss_mask_7: 4.887  loss_mask_8: 4.892  time: 2.6079  data_time: 0.0538  lr: 7.9041e-05  max_mem: 27639M
[01/29 09:32:20] d2.utils.events INFO:  eta: 1 day, 9:26:39  iter: 13819  total_loss: 56.57  loss_mask: 5.856  loss_mask_0: 5.692  loss_mask_1: 5.56  loss_mask_2: 5.535  loss_mask_3: 5.53  loss_mask_4: 5.563  loss_mask_5: 5.555  loss_mask_6: 5.555  loss_mask_7: 5.836  loss_mask_8: 5.815  time: 2.6080  data_time: 0.0561  lr: 7.901e-05  max_mem: 27639M
[01/29 09:33:12] d2.utils.events INFO:  eta: 1 day, 9:25:48  iter: 13839  total_loss: 53.05  loss_mask: 5.561  loss_mask_0: 5.158  loss_mask_1: 5.179  loss_mask_2: 5.182  loss_mask_3: 5.179  loss_mask_4: 5.178  loss_mask_5: 5.208  loss_mask_6: 5.193  loss_mask_7: 5.52  loss_mask_8: 5.521  time: 2.6080  data_time: 0.0594  lr: 7.8979e-05  max_mem: 27639M
[01/29 09:34:05] d2.utils.events INFO:  eta: 1 day, 9:24:58  iter: 13859  total_loss: 59.21  loss_mask: 6.136  loss_mask_0: 5.898  loss_mask_1: 5.83  loss_mask_2: 5.837  loss_mask_3: 5.783  loss_mask_4: 5.818  loss_mask_5: 5.805  loss_mask_6: 5.824  loss_mask_7: 6.126  loss_mask_8: 6.128  time: 2.6080  data_time: 0.0629  lr: 7.8948e-05  max_mem: 27639M
[01/29 09:34:57] d2.utils.events INFO:  eta: 1 day, 9:24:23  iter: 13879  total_loss: 49.7  loss_mask: 5.099  loss_mask_0: 4.934  loss_mask_1: 4.91  loss_mask_2: 4.912  loss_mask_3: 4.893  loss_mask_4: 4.883  loss_mask_5: 4.879  loss_mask_6: 4.866  loss_mask_7: 5.095  loss_mask_8: 5.112  time: 2.6080  data_time: 0.0560  lr: 7.8917e-05  max_mem: 27639M
[01/29 09:35:49] d2.utils.events INFO:  eta: 1 day, 9:23:30  iter: 13899  total_loss: 49.82  loss_mask: 5.262  loss_mask_0: 4.915  loss_mask_1: 4.851  loss_mask_2: 4.863  loss_mask_3: 4.864  loss_mask_4: 4.84  loss_mask_5: 4.837  loss_mask_6: 4.837  loss_mask_7: 5.276  loss_mask_8: 5.273  time: 2.6080  data_time: 0.0509  lr: 7.8887e-05  max_mem: 27639M
[01/29 09:36:42] d2.utils.events INFO:  eta: 1 day, 9:22:22  iter: 13919  total_loss: 51.09  loss_mask: 5.237  loss_mask_0: 5.168  loss_mask_1: 5.031  loss_mask_2: 5.03  loss_mask_3: 5.022  loss_mask_4: 5.018  loss_mask_5: 5.019  loss_mask_6: 5.015  loss_mask_7: 5.251  loss_mask_8: 5.238  time: 2.6080  data_time: 0.0590  lr: 7.8856e-05  max_mem: 27639M
[01/29 09:37:34] d2.utils.events INFO:  eta: 1 day, 9:21:44  iter: 13939  total_loss: 50.62  loss_mask: 5.272  loss_mask_0: 5.042  loss_mask_1: 4.945  loss_mask_2: 4.947  loss_mask_3: 4.966  loss_mask_4: 5.001  loss_mask_5: 4.989  loss_mask_6: 4.987  loss_mask_7: 5.261  loss_mask_8: 5.246  time: 2.6080  data_time: 0.0585  lr: 7.8825e-05  max_mem: 27639M
[01/29 09:38:26] d2.utils.events INFO:  eta: 1 day, 9:20:57  iter: 13959  total_loss: 50.51  loss_mask: 5.238  loss_mask_0: 5.101  loss_mask_1: 4.954  loss_mask_2: 4.96  loss_mask_3: 4.96  loss_mask_4: 4.97  loss_mask_5: 4.962  loss_mask_6: 4.972  loss_mask_7: 5.243  loss_mask_8: 5.242  time: 2.6080  data_time: 0.0581  lr: 7.8794e-05  max_mem: 27639M
[01/29 09:39:19] d2.utils.events INFO:  eta: 1 day, 9:20:14  iter: 13979  total_loss: 54.44  loss_mask: 5.72  loss_mask_0: 5.419  loss_mask_1: 5.278  loss_mask_2: 5.307  loss_mask_3: 5.323  loss_mask_4: 5.332  loss_mask_5: 5.322  loss_mask_6: 5.324  loss_mask_7: 5.695  loss_mask_8: 5.699  time: 2.6080  data_time: 0.0599  lr: 7.8763e-05  max_mem: 27639M
[01/29 09:40:11] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 09:40:12] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 09:40:12] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 09:54:38] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.730934191869453, 'error_1pix': 0.5824593130825755, 'error_3pix': 0.33620286151257445, 'mIoU': 4.863578947205613, 'fwIoU': 8.81526333531932, 'IoU-0': 0.02313930501361043, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.09659688943806925, 'IoU-7': 0.4847653595338989, 'IoU-8': 2.432088453494136, 'IoU-9': 8.167145048872767, 'IoU-10': 11.787368400724823, 'IoU-11': 18.270388460590343, 'IoU-12': 19.423463833865682, 'IoU-13': 17.544940012465386, 'IoU-14': 18.330085673497372, 'IoU-15': 17.4368172112612, 'IoU-16': 17.555736423775183, 'IoU-17': 14.565286926919157, 'IoU-18': 14.382686644647213, 'IoU-19': 14.652981361528028, 'IoU-20': 14.027403476792767, 'IoU-21': 13.667213134022859, 'IoU-22': 13.453417706281282, 'IoU-23': 12.01607336982965, 'IoU-24': 11.936951674868705, 'IoU-25': 12.294655251116481, 'IoU-26': 11.789486092264294, 'IoU-27': 12.563329374301818, 'IoU-28': 11.753577652862159, 'IoU-29': 11.948534115799198, 'IoU-30': 12.649670689940926, 'IoU-31': 13.356400622744363, 'IoU-32': 12.960627938952584, 'IoU-33': 12.20995721513995, 'IoU-34': 11.458612963938922, 'IoU-35': 11.778994330802165, 'IoU-36': 11.523678424722018, 'IoU-37': 10.196956845114505, 'IoU-38': 9.266504244114621, 'IoU-39': 8.297735330871356, 'IoU-40': 7.615414582809868, 'IoU-41': 6.967405835827665, 'IoU-42': 6.619453235251386, 'IoU-43': 6.624867794840888, 'IoU-44': 6.442305133202768, 'IoU-45': 6.293023876240254, 'IoU-46': 5.908343702111027, 'IoU-47': 5.7238761604638855, 'IoU-48': 5.586075360328813, 'IoU-49': 5.997721162769191, 'IoU-50': 6.100842650687622, 'IoU-51': 6.000219421436412, 'IoU-52': 6.210725797144137, 'IoU-53': 6.541257382690572, 'IoU-54': 6.866401281871985, 'IoU-55': 7.173827435224927, 'IoU-56': 7.5177409846062595, 'IoU-57': 7.682168990868847, 'IoU-58': 7.5734205183835765, 'IoU-59': 7.168244420328233, 'IoU-60': 7.026710550720539, 'IoU-61': 6.945770127725923, 'IoU-62': 6.912005047001303, 'IoU-63': 6.921128753229273, 'IoU-64': 7.171566960466359, 'IoU-65': 7.138198325486337, 'IoU-66': 6.8853436174533105, 'IoU-67': 6.5360664225860665, 'IoU-68': 6.452569207020953, 'IoU-69': 6.403516793288048, 'IoU-70': 6.212218276622068, 'IoU-71': 5.82624565428026, 'IoU-72': 5.639413178441439, 'IoU-73': 5.541088012719598, 'IoU-74': 5.584927896337923, 'IoU-75': 5.491595471178177, 'IoU-76': 5.469367751654463, 'IoU-77': 5.350881820711395, 'IoU-78': 5.187463845031258, 'IoU-79': 5.1981969130187595, 'IoU-80': 5.340789943178467, 'IoU-81': 5.260101259787296, 'IoU-82': 5.30451518468365, 'IoU-83': 5.2638658375740235, 'IoU-84': 5.192084699446166, 'IoU-85': 5.169027825132112, 'IoU-86': 5.080975714798023, 'IoU-87': 5.010731662800986, 'IoU-88': 5.107636759655191, 'IoU-89': 5.140373193582084, 'IoU-90': 5.218449918615296, 'IoU-91': 5.260592971551635, 'IoU-92': 5.157658847925934, 'IoU-93': 5.202143927341252, 'IoU-94': 5.301008794804163, 'IoU-95': 5.1773229608249505, 'IoU-96': 5.1493346883243305, 'IoU-97': 5.126723557237396, 'IoU-98': 5.011437586497808, 'IoU-99': 4.885590495629915, 'IoU-100': 4.682404912908647, 'IoU-101': 4.704131984790261, 'IoU-102': 4.75389809726874, 'IoU-103': 4.710553467177863, 'IoU-104': 4.602235168226197, 'IoU-105': 4.371309601774423, 'IoU-106': 4.251404383918166, 'IoU-107': 4.124288960245962, 'IoU-108': 4.2647835010833175, 'IoU-109': 4.280683736642756, 'IoU-110': 4.048255429238563, 'IoU-111': 3.8678920593688924, 'IoU-112': 3.79714731723051, 'IoU-113': 3.533721656048522, 'IoU-114': 3.310598969578149, 'IoU-115': 3.371663192525924, 'IoU-116': 2.9979657928084995, 'IoU-117': 3.1672733210065287, 'IoU-118': 2.8610783467447574, 'IoU-119': 2.5249075748520813, 'IoU-120': 2.5171238250618697, 'IoU-121': 2.3500491070650247, 'IoU-122': 2.245347284917982, 'IoU-123': 2.120747503230454, 'IoU-124': 1.9480244751018148, 'IoU-125': 1.8246423660945896, 'IoU-126': 1.8867064124839743, 'IoU-127': 1.9645152445026823, 'IoU-128': 1.9271180088347661, 'IoU-129': 1.9364345576099486, 'IoU-130': 1.8246713428307633, 'IoU-131': 1.8089843499753746, 'IoU-132': 1.8166874044776433, 'IoU-133': 1.6678350213075608, 'IoU-134': 1.8019519676280102, 'IoU-135': 1.8115111728203677, 'IoU-136': 1.6608729678018832, 'IoU-137': 1.7368503388017542, 'IoU-138': 1.6041740801584523, 'IoU-139': 1.6664296040913462, 'IoU-140': 1.5391274480940966, 'IoU-141': 1.5630823075718212, 'IoU-142': 1.4483370765732997, 'IoU-143': 1.4654314349790503, 'IoU-144': 1.4822440527544956, 'IoU-145': 1.556978808977789, 'IoU-146': 1.3454679857341032, 'IoU-147': 1.580256578924778, 'IoU-148': 1.6789140160216254, 'IoU-149': 1.567578775172537, 'IoU-150': 1.3929862955274002, 'IoU-151': 1.5439285567063703, 'IoU-152': 1.335262057002925, 'IoU-153': 1.262530128559886, 'IoU-154': 1.1913793638183305, 'IoU-155': 1.2146400089565552, 'IoU-156': 1.2279639201782908, 'IoU-157': 1.1501416827363518, 'IoU-158': 1.1810235840905163, 'IoU-159': 1.2287677581240537, 'IoU-160': 1.1352335776754021, 'IoU-161': 1.0954574069395926, 'IoU-162': 1.13208410471558, 'IoU-163': 1.5404047370160225, 'IoU-164': 1.5355748963354954, 'IoU-165': 1.501532100101381, 'IoU-166': 1.3610346621863068, 'IoU-167': 1.3949074364825165, 'IoU-168': 1.3285102180669546, 'IoU-169': 1.2189759960428508, 'IoU-170': 0.9977691869086922, 'IoU-171': 0.9247688792681915, 'IoU-172': 0.8104954175669421, 'IoU-173': 0.7365575724452667, 'IoU-174': 0.917653680794242, 'IoU-175': 0.7154989307068973, 'IoU-176': 0.5004054974531462, 'IoU-177': 0.29157509157509154, 'IoU-178': 0.1947178819756531, 'IoU-179': 0.22354535300328987, 'IoU-180': 0.2023990003903745, 'IoU-181': 0.18375344876494915, 'IoU-182': 0.14881124711931534, 'IoU-183': 0.0945688117439151, 'IoU-184': 0.010055910864406098, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0002827742415287907, 'mACC': 9.415209278509934, 'pACC': 15.743815885365855, 'ACC-0': 0.02313946201836439, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 36.15809270536375, 'ACC-7': 8.994133111638607, 'ACC-8': 14.680529044479757, 'ACC-9': 22.313035544296167, 'ACC-10': 23.51635410601336, 'ACC-11': 29.500713968416893, 'ACC-12': 31.53461843265697, 'ACC-13': 28.094981353916822, 'ACC-14': 29.686699479124183, 'ACC-15': 29.31320407224215, 'ACC-16': 29.46434499189101, 'ACC-17': 25.609449092055513, 'ACC-18': 23.762461849425534, 'ACC-19': 24.211418201833038, 'ACC-20': 23.790924012005313, 'ACC-21': 23.213635142996466, 'ACC-22': 22.201474172465108, 'ACC-23': 21.076306539454556, 'ACC-24': 21.517676136426175, 'ACC-25': 22.47517314745776, 'ACC-26': 21.393460258040875, 'ACC-27': 21.890140458284733, 'ACC-28': 20.944687267077768, 'ACC-29': 20.774041751345884, 'ACC-30': 22.727723950982607, 'ACC-31': 23.56374995481736, 'ACC-32': 23.19378903568325, 'ACC-33': 22.355812909268153, 'ACC-34': 20.754994300521474, 'ACC-35': 20.693255617735563, 'ACC-36': 20.244380100591833, 'ACC-37': 18.13500158951539, 'ACC-38': 16.37148339157649, 'ACC-39': 14.783367207459039, 'ACC-40': 13.779721936689945, 'ACC-41': 13.313738588981339, 'ACC-42': 12.870977753168624, 'ACC-43': 12.98344598140605, 'ACC-44': 12.279437029167859, 'ACC-45': 12.100080195205111, 'ACC-46': 11.662930734710422, 'ACC-47': 11.291673214679996, 'ACC-48': 11.125384423859257, 'ACC-49': 12.09947195348516, 'ACC-50': 12.455080469219249, 'ACC-51': 12.39028485514705, 'ACC-52': 12.703332378696691, 'ACC-53': 13.320697640439441, 'ACC-54': 14.05673309779501, 'ACC-55': 14.835130631179192, 'ACC-56': 15.629166885467557, 'ACC-57': 15.455647239275331, 'ACC-58': 15.095779835628676, 'ACC-59': 14.316409382286682, 'ACC-60': 13.917885223141791, 'ACC-61': 13.690380398200777, 'ACC-62': 13.728651763764061, 'ACC-63': 13.87281658985903, 'ACC-64': 14.40466240888146, 'ACC-65': 14.482688696252561, 'ACC-66': 13.966697478486575, 'ACC-67': 13.166247085378954, 'ACC-68': 12.805523370866537, 'ACC-69': 12.342391552455192, 'ACC-70': 11.799650012983664, 'ACC-71': 11.183550204062282, 'ACC-72': 10.793271308133034, 'ACC-73': 10.503414481503105, 'ACC-74': 10.479138615165299, 'ACC-75': 10.355275902850048, 'ACC-76': 10.148041205494122, 'ACC-77': 10.009062647983043, 'ACC-78': 9.745688170189581, 'ACC-79': 9.76101601524504, 'ACC-80': 9.902777005253984, 'ACC-81': 9.749544883919084, 'ACC-82': 9.840292133936424, 'ACC-83': 9.651634671214355, 'ACC-84': 9.5859674926191, 'ACC-85': 9.567170445587202, 'ACC-86': 9.42375341443993, 'ACC-87': 9.351059862639218, 'ACC-88': 9.588112581924142, 'ACC-89': 9.672095796506355, 'ACC-90': 9.800421963354115, 'ACC-91': 9.991410844924111, 'ACC-92': 9.867130690394559, 'ACC-93': 9.923288622965151, 'ACC-94': 10.062528737309968, 'ACC-95': 9.820552210004752, 'ACC-96': 9.840630994614537, 'ACC-97': 9.749403723341327, 'ACC-98': 9.604421144645643, 'ACC-99': 9.501529997909607, 'ACC-100': 9.104287647782462, 'ACC-101': 9.134869173325356, 'ACC-102': 9.317942908926144, 'ACC-103': 9.356923585529422, 'ACC-104': 9.153611568825164, 'ACC-105': 8.726204817661678, 'ACC-106': 8.419585282639188, 'ACC-107': 8.247936329734692, 'ACC-108': 8.487887139909137, 'ACC-109': 8.559724330706764, 'ACC-110': 8.121748697521866, 'ACC-111': 7.688534921860138, 'ACC-112': 7.573142907858921, 'ACC-113': 7.055610750752937, 'ACC-114': 6.747711458868213, 'ACC-115': 6.928983807676695, 'ACC-116': 6.175767303734843, 'ACC-117': 6.438379943535742, 'ACC-118': 5.772564688119437, 'ACC-119': 5.0230384506014705, 'ACC-120': 4.8969611036731715, 'ACC-121': 4.5918314046839, 'ACC-122': 4.37280043778954, 'ACC-123': 4.106527140993429, 'ACC-124': 3.7774738812669106, 'ACC-125': 3.5213511964262216, 'ACC-126': 3.6974949680780336, 'ACC-127': 3.858086702987599, 'ACC-128': 3.772269728537086, 'ACC-129': 3.7504729978620186, 'ACC-130': 3.5521730045428397, 'ACC-131': 3.546789321285853, 'ACC-132': 3.5315485585413504, 'ACC-133': 3.2344676015704206, 'ACC-134': 3.4504437742352434, 'ACC-135': 3.44749444159398, 'ACC-136': 3.191827012672382, 'ACC-137': 3.338683592107262, 'ACC-138': 3.1145296596187526, 'ACC-139': 3.2177006328330404, 'ACC-140': 2.90978603150308, 'ACC-141': 2.922548427219893, 'ACC-142': 2.7488491879471924, 'ACC-143': 2.8483546344395894, 'ACC-144': 2.8887184115523468, 'ACC-145': 2.959905185715244, 'ACC-146': 2.5615133307441003, 'ACC-147': 2.9912264167586673, 'ACC-148': 3.2186652548212966, 'ACC-149': 3.059221067918237, 'ACC-150': 2.7506517032881703, 'ACC-151': 3.1135595550596142, 'ACC-152': 2.6474728572391935, 'ACC-153': 2.5444768134264097, 'ACC-154': 2.345400256203422, 'ACC-155': 2.4203587707037615, 'ACC-156': 2.5450690660409676, 'ACC-157': 2.458852399443063, 'ACC-158': 2.5656586470134117, 'ACC-159': 2.702679713173437, 'ACC-160': 2.574311179477899, 'ACC-161': 2.660941313255279, 'ACC-162': 2.871011987468053, 'ACC-163': 4.0119724779758075, 'ACC-164': 4.196328628642278, 'ACC-165': 4.189284908854704, 'ACC-166': 4.009199956350572, 'ACC-167': 4.166992375800593, 'ACC-168': 4.049335396300725, 'ACC-169': 3.7361399420592987, 'ACC-170': 3.049533625793262, 'ACC-171': 2.970198821472131, 'ACC-172': 2.426010297440456, 'ACC-173': 2.2009158880614708, 'ACC-174': 2.2852626654066035, 'ACC-175': 1.4548540431408872, 'ACC-176': 0.8808335268168099, 'ACC-177': 0.4406969212115843, 'ACC-178': 0.26153587619347474, 'ACC-179': 0.29723198906023973, 'ACC-180': 0.2732483321480578, 'ACC-181': 0.24089193971306147, 'ACC-182': 0.18266289810916655, 'ACC-183': 0.10759244828146372, 'ACC-184': 0.010612782034682572, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.00028299030192235317})])
[01/29 09:54:38] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 09:54:38] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 09:54:38] d2.evaluation.testing INFO: copypaste: 4.7309,0.5825,0.3362,4.8636,8.8153,9.4152,15.7438
[01/29 09:54:38] d2.utils.events INFO:  eta: 1 day, 9:19:16  iter: 13999  total_loss: 53.76  loss_mask: 5.615  loss_mask_0: 5.324  loss_mask_1: 5.28  loss_mask_2: 5.26  loss_mask_3: 5.263  loss_mask_4: 5.257  loss_mask_5: 5.254  loss_mask_6: 5.264  loss_mask_7: 5.616  loss_mask_8: 5.625  time: 2.6081  data_time: 0.0552  lr: 7.8733e-05  max_mem: 27639M
[01/29 09:55:30] d2.utils.events INFO:  eta: 1 day, 9:18:46  iter: 14019  total_loss: 50.56  loss_mask: 5.33  loss_mask_0: 4.988  loss_mask_1: 4.941  loss_mask_2: 4.942  loss_mask_3: 4.938  loss_mask_4: 4.924  loss_mask_5: 4.943  loss_mask_6: 4.946  loss_mask_7: 5.3  loss_mask_8: 5.335  time: 2.6081  data_time: 0.0584  lr: 7.8702e-05  max_mem: 27639M
[01/29 09:56:22] d2.utils.events INFO:  eta: 1 day, 9:18:09  iter: 14039  total_loss: 52.42  loss_mask: 5.405  loss_mask_0: 5.326  loss_mask_1: 5.156  loss_mask_2: 5.134  loss_mask_3: 5.136  loss_mask_4: 5.166  loss_mask_5: 5.123  loss_mask_6: 5.138  loss_mask_7: 5.413  loss_mask_8: 5.398  time: 2.6080  data_time: 0.0518  lr: 7.8671e-05  max_mem: 27639M
[01/29 09:57:15] d2.utils.events INFO:  eta: 1 day, 9:17:47  iter: 14059  total_loss: 50.51  loss_mask: 5.203  loss_mask_0: 5.065  loss_mask_1: 4.957  loss_mask_2: 4.942  loss_mask_3: 4.909  loss_mask_4: 4.938  loss_mask_5: 4.944  loss_mask_6: 4.939  loss_mask_7: 5.183  loss_mask_8: 5.198  time: 2.6081  data_time: 0.0586  lr: 7.864e-05  max_mem: 27639M
[01/29 09:58:07] d2.utils.events INFO:  eta: 1 day, 9:16:51  iter: 14079  total_loss: 52.5  loss_mask: 5.367  loss_mask_0: 5.323  loss_mask_1: 5.211  loss_mask_2: 5.188  loss_mask_3: 5.184  loss_mask_4: 5.179  loss_mask_5: 5.178  loss_mask_6: 5.193  loss_mask_7: 5.37  loss_mask_8: 5.375  time: 2.6080  data_time: 0.0581  lr: 7.8609e-05  max_mem: 27639M
[01/29 09:58:59] d2.utils.events INFO:  eta: 1 day, 9:15:09  iter: 14099  total_loss: 55.12  loss_mask: 5.631  loss_mask_0: 5.507  loss_mask_1: 5.462  loss_mask_2: 5.431  loss_mask_3: 5.425  loss_mask_4: 5.445  loss_mask_5: 5.46  loss_mask_6: 5.458  loss_mask_7: 5.636  loss_mask_8: 5.655  time: 2.6080  data_time: 0.0554  lr: 7.8579e-05  max_mem: 27639M
[01/29 09:59:51] d2.utils.events INFO:  eta: 1 day, 9:14:23  iter: 14119  total_loss: 52.68  loss_mask: 5.513  loss_mask_0: 5.313  loss_mask_1: 5.183  loss_mask_2: 5.187  loss_mask_3: 5.169  loss_mask_4: 5.182  loss_mask_5: 5.181  loss_mask_6: 5.161  loss_mask_7: 5.541  loss_mask_8: 5.519  time: 2.6081  data_time: 0.0662  lr: 7.8548e-05  max_mem: 27639M
[01/29 10:00:44] d2.utils.events INFO:  eta: 1 day, 9:13:31  iter: 14139  total_loss: 52.75  loss_mask: 5.452  loss_mask_0: 5.375  loss_mask_1: 5.177  loss_mask_2: 5.176  loss_mask_3: 5.191  loss_mask_4: 5.192  loss_mask_5: 5.208  loss_mask_6: 5.189  loss_mask_7: 5.437  loss_mask_8: 5.427  time: 2.6081  data_time: 0.0563  lr: 7.8517e-05  max_mem: 27639M
[01/29 10:01:36] d2.utils.events INFO:  eta: 1 day, 9:12:39  iter: 14159  total_loss: 52.38  loss_mask: 5.445  loss_mask_0: 5.158  loss_mask_1: 5.122  loss_mask_2: 5.137  loss_mask_3: 5.139  loss_mask_4: 5.149  loss_mask_5: 5.144  loss_mask_6: 5.166  loss_mask_7: 5.461  loss_mask_8: 5.457  time: 2.6081  data_time: 0.0556  lr: 7.8486e-05  max_mem: 27639M
[01/29 10:02:28] d2.utils.events INFO:  eta: 1 day, 9:11:46  iter: 14179  total_loss: 52.89  loss_mask: 5.402  loss_mask_0: 5.282  loss_mask_1: 5.228  loss_mask_2: 5.212  loss_mask_3: 5.203  loss_mask_4: 5.203  loss_mask_5: 5.207  loss_mask_6: 5.201  loss_mask_7: 5.409  loss_mask_8: 5.412  time: 2.6081  data_time: 0.0573  lr: 7.8455e-05  max_mem: 27639M
[01/29 10:03:20] d2.utils.events INFO:  eta: 1 day, 9:10:37  iter: 14199  total_loss: 46.47  loss_mask: 4.813  loss_mask_0: 4.656  loss_mask_1: 4.548  loss_mask_2: 4.552  loss_mask_3: 4.537  loss_mask_4: 4.551  loss_mask_5: 4.563  loss_mask_6: 4.564  loss_mask_7: 4.821  loss_mask_8: 4.804  time: 2.6081  data_time: 0.0553  lr: 7.8424e-05  max_mem: 27639M
[01/29 10:04:12] d2.utils.events INFO:  eta: 1 day, 9:09:39  iter: 14219  total_loss: 50.34  loss_mask: 5.215  loss_mask_0: 5.026  loss_mask_1: 4.914  loss_mask_2: 4.95  loss_mask_3: 4.938  loss_mask_4: 4.938  loss_mask_5: 4.943  loss_mask_6: 4.932  loss_mask_7: 5.229  loss_mask_8: 5.231  time: 2.6081  data_time: 0.0530  lr: 7.8394e-05  max_mem: 27639M
[01/29 10:05:04] d2.utils.events INFO:  eta: 1 day, 9:08:35  iter: 14239  total_loss: 52.53  loss_mask: 5.483  loss_mask_0: 5.207  loss_mask_1: 5.149  loss_mask_2: 5.142  loss_mask_3: 5.144  loss_mask_4: 5.164  loss_mask_5: 5.162  loss_mask_6: 5.174  loss_mask_7: 5.459  loss_mask_8: 5.462  time: 2.6081  data_time: 0.0621  lr: 7.8363e-05  max_mem: 27639M
[01/29 10:05:56] d2.utils.events INFO:  eta: 1 day, 9:07:30  iter: 14259  total_loss: 48.9  loss_mask: 5.064  loss_mask_0: 4.873  loss_mask_1: 4.795  loss_mask_2: 4.792  loss_mask_3: 4.792  loss_mask_4: 4.8  loss_mask_5: 4.791  loss_mask_6: 4.791  loss_mask_7: 5.076  loss_mask_8: 5.079  time: 2.6080  data_time: 0.0505  lr: 7.8332e-05  max_mem: 27639M
[01/29 10:06:49] d2.utils.events INFO:  eta: 1 day, 9:06:42  iter: 14279  total_loss: 51.16  loss_mask: 5.312  loss_mask_0: 5.105  loss_mask_1: 5.021  loss_mask_2: 5.024  loss_mask_3: 5.049  loss_mask_4: 5.066  loss_mask_5: 5.036  loss_mask_6: 5.04  loss_mask_7: 5.313  loss_mask_8: 5.33  time: 2.6080  data_time: 0.0639  lr: 7.8301e-05  max_mem: 27639M
[01/29 10:07:41] d2.utils.events INFO:  eta: 1 day, 9:05:48  iter: 14299  total_loss: 49.88  loss_mask: 5.146  loss_mask_0: 4.963  loss_mask_1: 4.901  loss_mask_2: 4.877  loss_mask_3: 4.873  loss_mask_4: 4.909  loss_mask_5: 4.894  loss_mask_6: 4.9  loss_mask_7: 5.142  loss_mask_8: 5.151  time: 2.6081  data_time: 0.0647  lr: 7.827e-05  max_mem: 27639M
[01/29 10:08:34] d2.utils.events INFO:  eta: 1 day, 9:05:00  iter: 14319  total_loss: 48.68  loss_mask: 5.093  loss_mask_0: 4.897  loss_mask_1: 4.763  loss_mask_2: 4.752  loss_mask_3: 4.776  loss_mask_4: 4.764  loss_mask_5: 4.766  loss_mask_6: 4.755  loss_mask_7: 5.099  loss_mask_8: 5.106  time: 2.6081  data_time: 0.0616  lr: 7.8239e-05  max_mem: 27639M
[01/29 10:09:26] d2.utils.events INFO:  eta: 1 day, 9:04:29  iter: 14339  total_loss: 48.71  loss_mask: 5.102  loss_mask_0: 4.76  loss_mask_1: 4.759  loss_mask_2: 4.736  loss_mask_3: 4.742  loss_mask_4: 4.764  loss_mask_5: 4.755  loss_mask_6: 4.737  loss_mask_7: 5.075  loss_mask_8: 5.083  time: 2.6081  data_time: 0.0533  lr: 7.8209e-05  max_mem: 27639M
[01/29 10:10:18] d2.utils.events INFO:  eta: 1 day, 9:03:37  iter: 14359  total_loss: 54.51  loss_mask: 5.649  loss_mask_0: 5.359  loss_mask_1: 5.379  loss_mask_2: 5.364  loss_mask_3: 5.354  loss_mask_4: 5.37  loss_mask_5: 5.368  loss_mask_6: 5.374  loss_mask_7: 5.665  loss_mask_8: 5.66  time: 2.6081  data_time: 0.0581  lr: 7.8178e-05  max_mem: 27639M
[01/29 10:11:11] d2.utils.events INFO:  eta: 1 day, 9:03:01  iter: 14379  total_loss: 53.88  loss_mask: 5.599  loss_mask_0: 5.379  loss_mask_1: 5.28  loss_mask_2: 5.284  loss_mask_3: 5.279  loss_mask_4: 5.289  loss_mask_5: 5.296  loss_mask_6: 5.289  loss_mask_7: 5.585  loss_mask_8: 5.59  time: 2.6081  data_time: 0.0543  lr: 7.8147e-05  max_mem: 27639M
[01/29 10:12:03] d2.utils.events INFO:  eta: 1 day, 9:01:50  iter: 14399  total_loss: 50.87  loss_mask: 5.388  loss_mask_0: 5.015  loss_mask_1: 4.951  loss_mask_2: 4.947  loss_mask_3: 4.931  loss_mask_4: 4.969  loss_mask_5: 4.955  loss_mask_6: 4.937  loss_mask_7: 5.387  loss_mask_8: 5.387  time: 2.6081  data_time: 0.0519  lr: 7.8116e-05  max_mem: 27639M
[01/29 10:12:55] d2.utils.events INFO:  eta: 1 day, 9:01:03  iter: 14419  total_loss: 49.54  loss_mask: 5.151  loss_mask_0: 5.039  loss_mask_1: 4.868  loss_mask_2: 4.867  loss_mask_3: 4.867  loss_mask_4: 4.855  loss_mask_5: 4.849  loss_mask_6: 4.851  loss_mask_7: 5.139  loss_mask_8: 5.162  time: 2.6081  data_time: 0.0566  lr: 7.8085e-05  max_mem: 27639M
[01/29 10:13:48] d2.utils.events INFO:  eta: 1 day, 9:00:08  iter: 14439  total_loss: 53.33  loss_mask: 5.46  loss_mask_0: 5.37  loss_mask_1: 5.263  loss_mask_2: 5.253  loss_mask_3: 5.266  loss_mask_4: 5.269  loss_mask_5: 5.248  loss_mask_6: 5.217  loss_mask_7: 5.463  loss_mask_8: 5.469  time: 2.6081  data_time: 0.0647  lr: 7.8054e-05  max_mem: 27639M
[01/29 10:14:40] d2.utils.events INFO:  eta: 1 day, 8:59:16  iter: 14459  total_loss: 49.46  loss_mask: 5.162  loss_mask_0: 4.923  loss_mask_1: 4.841  loss_mask_2: 4.809  loss_mask_3: 4.84  loss_mask_4: 4.827  loss_mask_5: 4.805  loss_mask_6: 4.81  loss_mask_7: 5.162  loss_mask_8: 5.161  time: 2.6081  data_time: 0.0492  lr: 7.8024e-05  max_mem: 27639M
[01/29 10:15:32] d2.utils.events INFO:  eta: 1 day, 8:58:27  iter: 14479  total_loss: 46.09  loss_mask: 4.753  loss_mask_0: 4.609  loss_mask_1: 4.547  loss_mask_2: 4.538  loss_mask_3: 4.521  loss_mask_4: 4.538  loss_mask_5: 4.53  loss_mask_6: 4.534  loss_mask_7: 4.752  loss_mask_8: 4.749  time: 2.6081  data_time: 0.0571  lr: 7.7993e-05  max_mem: 27639M
[01/29 10:16:25] d2.utils.events INFO:  eta: 1 day, 8:57:35  iter: 14499  total_loss: 49.21  loss_mask: 5.089  loss_mask_0: 4.962  loss_mask_1: 4.812  loss_mask_2: 4.827  loss_mask_3: 4.832  loss_mask_4: 4.819  loss_mask_5: 4.864  loss_mask_6: 4.83  loss_mask_7: 5.078  loss_mask_8: 5.102  time: 2.6082  data_time: 0.0608  lr: 7.7962e-05  max_mem: 27639M
[01/29 10:17:17] d2.utils.events INFO:  eta: 1 day, 8:56:44  iter: 14519  total_loss: 49.47  loss_mask: 5.151  loss_mask_0: 4.948  loss_mask_1: 4.882  loss_mask_2: 4.888  loss_mask_3: 4.89  loss_mask_4: 4.883  loss_mask_5: 4.885  loss_mask_6: 4.883  loss_mask_7: 5.153  loss_mask_8: 5.166  time: 2.6082  data_time: 0.0643  lr: 7.7931e-05  max_mem: 27639M
[01/29 10:18:10] d2.utils.events INFO:  eta: 1 day, 8:56:09  iter: 14539  total_loss: 50.52  loss_mask: 5.275  loss_mask_0: 4.994  loss_mask_1: 4.957  loss_mask_2: 4.928  loss_mask_3: 4.927  loss_mask_4: 4.962  loss_mask_5: 4.942  loss_mask_6: 4.918  loss_mask_7: 5.222  loss_mask_8: 5.237  time: 2.6082  data_time: 0.0519  lr: 7.79e-05  max_mem: 27639M
[01/29 10:19:02] d2.utils.events INFO:  eta: 1 day, 8:55:16  iter: 14559  total_loss: 55.18  loss_mask: 5.689  loss_mask_0: 5.505  loss_mask_1: 5.453  loss_mask_2: 5.434  loss_mask_3: 5.441  loss_mask_4: 5.447  loss_mask_5: 5.434  loss_mask_6: 5.43  loss_mask_7: 5.686  loss_mask_8: 5.689  time: 2.6082  data_time: 0.0507  lr: 7.7869e-05  max_mem: 27639M
[01/29 10:19:55] d2.utils.events INFO:  eta: 1 day, 8:54:07  iter: 14579  total_loss: 51.48  loss_mask: 5.308  loss_mask_0: 5.211  loss_mask_1: 5.072  loss_mask_2: 5.05  loss_mask_3: 5.038  loss_mask_4: 5.034  loss_mask_5: 5.054  loss_mask_6: 5.038  loss_mask_7: 5.284  loss_mask_8: 5.303  time: 2.6082  data_time: 0.0614  lr: 7.7839e-05  max_mem: 27639M
[01/29 10:20:47] d2.utils.events INFO:  eta: 1 day, 8:53:11  iter: 14599  total_loss: 50.28  loss_mask: 5.203  loss_mask_0: 5.05  loss_mask_1: 4.971  loss_mask_2: 4.944  loss_mask_3: 4.928  loss_mask_4: 4.921  loss_mask_5: 4.922  loss_mask_6: 4.924  loss_mask_7: 5.2  loss_mask_8: 5.214  time: 2.6083  data_time: 0.0544  lr: 7.7808e-05  max_mem: 27639M
[01/29 10:21:39] d2.utils.events INFO:  eta: 1 day, 8:52:22  iter: 14619  total_loss: 51.23  loss_mask: 5.301  loss_mask_0: 5.119  loss_mask_1: 5.056  loss_mask_2: 5.015  loss_mask_3: 5.017  loss_mask_4: 5.029  loss_mask_5: 5.026  loss_mask_6: 5.018  loss_mask_7: 5.308  loss_mask_8: 5.312  time: 2.6083  data_time: 0.0602  lr: 7.7777e-05  max_mem: 27639M
[01/29 10:22:32] d2.utils.events INFO:  eta: 1 day, 8:51:35  iter: 14639  total_loss: 48.8  loss_mask: 5.101  loss_mask_0: 4.989  loss_mask_1: 4.798  loss_mask_2: 4.775  loss_mask_3: 4.79  loss_mask_4: 4.787  loss_mask_5: 4.789  loss_mask_6: 4.79  loss_mask_7: 5.086  loss_mask_8: 5.092  time: 2.6083  data_time: 0.0538  lr: 7.7746e-05  max_mem: 27639M
[01/29 10:23:24] d2.utils.events INFO:  eta: 1 day, 8:51:43  iter: 14659  total_loss: 53.49  loss_mask: 5.563  loss_mask_0: 5.366  loss_mask_1: 5.281  loss_mask_2: 5.266  loss_mask_3: 5.257  loss_mask_4: 5.264  loss_mask_5: 5.255  loss_mask_6: 5.249  loss_mask_7: 5.562  loss_mask_8: 5.564  time: 2.6083  data_time: 0.0542  lr: 7.7715e-05  max_mem: 27639M
[01/29 10:24:16] d2.utils.events INFO:  eta: 1 day, 8:50:03  iter: 14679  total_loss: 54.13  loss_mask: 5.524  loss_mask_0: 5.469  loss_mask_1: 5.323  loss_mask_2: 5.336  loss_mask_3: 5.338  loss_mask_4: 5.37  loss_mask_5: 5.357  loss_mask_6: 5.352  loss_mask_7: 5.535  loss_mask_8: 5.536  time: 2.6083  data_time: 0.0568  lr: 7.7684e-05  max_mem: 27639M
[01/29 10:25:09] d2.utils.events INFO:  eta: 1 day, 8:49:25  iter: 14699  total_loss: 49.67  loss_mask: 5.142  loss_mask_0: 5.003  loss_mask_1: 4.877  loss_mask_2: 4.874  loss_mask_3: 4.863  loss_mask_4: 4.847  loss_mask_5: 4.873  loss_mask_6: 4.857  loss_mask_7: 5.115  loss_mask_8: 5.127  time: 2.6083  data_time: 0.0531  lr: 7.7653e-05  max_mem: 27639M
[01/29 10:26:01] d2.utils.events INFO:  eta: 1 day, 8:48:33  iter: 14719  total_loss: 51.77  loss_mask: 5.344  loss_mask_0: 5.265  loss_mask_1: 5.087  loss_mask_2: 5.063  loss_mask_3: 5.056  loss_mask_4: 5.064  loss_mask_5: 5.067  loss_mask_6: 5.076  loss_mask_7: 5.363  loss_mask_8: 5.333  time: 2.6083  data_time: 0.0551  lr: 7.7623e-05  max_mem: 27639M
[01/29 10:26:53] d2.utils.events INFO:  eta: 1 day, 8:47:41  iter: 14739  total_loss: 45.18  loss_mask: 4.756  loss_mask_0: 4.641  loss_mask_1: 4.439  loss_mask_2: 4.41  loss_mask_3: 4.41  loss_mask_4: 4.396  loss_mask_5: 4.387  loss_mask_6: 4.411  loss_mask_7: 4.754  loss_mask_8: 4.744  time: 2.6083  data_time: 0.0628  lr: 7.7592e-05  max_mem: 27639M
[01/29 10:27:46] d2.utils.events INFO:  eta: 1 day, 8:47:22  iter: 14759  total_loss: 50.53  loss_mask: 5.235  loss_mask_0: 5.006  loss_mask_1: 4.944  loss_mask_2: 4.961  loss_mask_3: 4.952  loss_mask_4: 4.967  loss_mask_5: 4.968  loss_mask_6: 4.964  loss_mask_7: 5.261  loss_mask_8: 5.265  time: 2.6083  data_time: 0.0612  lr: 7.7561e-05  max_mem: 27639M
[01/29 10:28:38] d2.utils.events INFO:  eta: 1 day, 8:46:38  iter: 14779  total_loss: 45.79  loss_mask: 4.781  loss_mask_0: 4.518  loss_mask_1: 4.491  loss_mask_2: 4.455  loss_mask_3: 4.453  loss_mask_4: 4.456  loss_mask_5: 4.463  loss_mask_6: 4.463  loss_mask_7: 4.797  loss_mask_8: 4.787  time: 2.6084  data_time: 0.0543  lr: 7.753e-05  max_mem: 27639M
[01/29 10:29:31] d2.utils.events INFO:  eta: 1 day, 8:46:18  iter: 14799  total_loss: 53.88  loss_mask: 5.628  loss_mask_0: 5.367  loss_mask_1: 5.292  loss_mask_2: 5.279  loss_mask_3: 5.279  loss_mask_4: 5.279  loss_mask_5: 5.28  loss_mask_6: 5.28  loss_mask_7: 5.632  loss_mask_8: 5.615  time: 2.6084  data_time: 0.0524  lr: 7.7499e-05  max_mem: 27639M
[01/29 10:30:23] d2.utils.events INFO:  eta: 1 day, 8:45:19  iter: 14819  total_loss: 51.63  loss_mask: 5.345  loss_mask_0: 5.121  loss_mask_1: 5.053  loss_mask_2: 5.068  loss_mask_3: 5.067  loss_mask_4: 5.098  loss_mask_5: 5.088  loss_mask_6: 5.072  loss_mask_7: 5.353  loss_mask_8: 5.361  time: 2.6084  data_time: 0.0601  lr: 7.7468e-05  max_mem: 27639M
[01/29 10:31:15] d2.utils.events INFO:  eta: 1 day, 8:44:26  iter: 14839  total_loss: 48.52  loss_mask: 5.054  loss_mask_0: 4.8  loss_mask_1: 4.771  loss_mask_2: 4.77  loss_mask_3: 4.762  loss_mask_4: 4.766  loss_mask_5: 4.768  loss_mask_6: 4.787  loss_mask_7: 5.057  loss_mask_8: 5.061  time: 2.6084  data_time: 0.0544  lr: 7.7437e-05  max_mem: 27639M
[01/29 10:32:08] d2.utils.events INFO:  eta: 1 day, 8:43:32  iter: 14859  total_loss: 54.75  loss_mask: 5.673  loss_mask_0: 5.437  loss_mask_1: 5.341  loss_mask_2: 5.397  loss_mask_3: 5.392  loss_mask_4: 5.396  loss_mask_5: 5.413  loss_mask_6: 5.404  loss_mask_7: 5.687  loss_mask_8: 5.671  time: 2.6084  data_time: 0.0604  lr: 7.7407e-05  max_mem: 27639M
[01/29 10:33:00] d2.utils.events INFO:  eta: 1 day, 8:42:34  iter: 14879  total_loss: 46.97  loss_mask: 4.921  loss_mask_0: 4.701  loss_mask_1: 4.601  loss_mask_2: 4.617  loss_mask_3: 4.612  loss_mask_4: 4.62  loss_mask_5: 4.608  loss_mask_6: 4.621  loss_mask_7: 4.926  loss_mask_8: 4.923  time: 2.6084  data_time: 0.0518  lr: 7.7376e-05  max_mem: 27639M
[01/29 10:33:53] d2.utils.events INFO:  eta: 1 day, 8:41:48  iter: 14899  total_loss: 48.17  loss_mask: 5.025  loss_mask_0: 4.866  loss_mask_1: 4.709  loss_mask_2: 4.723  loss_mask_3: 4.735  loss_mask_4: 4.735  loss_mask_5: 4.703  loss_mask_6: 4.709  loss_mask_7: 5.043  loss_mask_8: 5.033  time: 2.6084  data_time: 0.0520  lr: 7.7345e-05  max_mem: 27639M
[01/29 10:34:45] d2.utils.events INFO:  eta: 1 day, 8:41:00  iter: 14919  total_loss: 54.37  loss_mask: 5.605  loss_mask_0: 5.394  loss_mask_1: 5.31  loss_mask_2: 5.326  loss_mask_3: 5.35  loss_mask_4: 5.312  loss_mask_5: 5.323  loss_mask_6: 5.349  loss_mask_7: 5.593  loss_mask_8: 5.61  time: 2.6084  data_time: 0.0520  lr: 7.7314e-05  max_mem: 27639M
[01/29 10:35:37] d2.utils.events INFO:  eta: 1 day, 8:40:04  iter: 14939  total_loss: 49.79  loss_mask: 5.125  loss_mask_0: 5.007  loss_mask_1: 4.918  loss_mask_2: 4.912  loss_mask_3: 4.892  loss_mask_4: 4.9  loss_mask_5: 4.891  loss_mask_6: 4.9  loss_mask_7: 5.121  loss_mask_8: 5.121  time: 2.6085  data_time: 0.0621  lr: 7.7283e-05  max_mem: 27639M
[01/29 10:36:29] d2.utils.events INFO:  eta: 1 day, 8:39:10  iter: 14959  total_loss: 51.56  loss_mask: 5.351  loss_mask_0: 5.151  loss_mask_1: 5.045  loss_mask_2: 5.043  loss_mask_3: 5.055  loss_mask_4: 5.024  loss_mask_5: 5.024  loss_mask_6: 5.038  loss_mask_7: 5.355  loss_mask_8: 5.353  time: 2.6084  data_time: 0.0600  lr: 7.7252e-05  max_mem: 27639M
[01/29 10:37:22] d2.utils.events INFO:  eta: 1 day, 8:38:09  iter: 14979  total_loss: 52.47  loss_mask: 5.477  loss_mask_0: 5.224  loss_mask_1: 5.135  loss_mask_2: 5.141  loss_mask_3: 5.142  loss_mask_4: 5.163  loss_mask_5: 5.159  loss_mask_6: 5.149  loss_mask_7: 5.464  loss_mask_8: 5.469  time: 2.6085  data_time: 0.0524  lr: 7.7221e-05  max_mem: 27639M
[01/29 10:38:14] fvcore.common.checkpoint INFO: Saving checkpoint to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_nopretrain_instancenorm/model_0014999.pth
[01/29 10:38:15] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 10:38:16] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 10:38:16] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 10:52:33] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.425379613679791, 'error_1pix': 0.5235991635173587, 'error_3pix': 0.3169847370510912, 'mIoU': 5.903267581526155, 'fwIoU': 11.213845492146058, 'IoU-0': 0.0, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.09290379705487138, 'IoU-7': 0.4491977123440961, 'IoU-8': 2.655823701513077, 'IoU-9': 9.22773602642258, 'IoU-10': 12.485808439580843, 'IoU-11': 19.90925968811607, 'IoU-12': 21.04573018174945, 'IoU-13': 18.903648120897927, 'IoU-14': 19.787177159915636, 'IoU-15': 18.782978769808903, 'IoU-16': 18.191741562520015, 'IoU-17': 14.854062132324271, 'IoU-18': 14.79015349452557, 'IoU-19': 15.904710776019451, 'IoU-20': 16.432710471460336, 'IoU-21': 17.10324995931701, 'IoU-22': 17.28884905482634, 'IoU-23': 16.4098212775445, 'IoU-24': 16.526261743041715, 'IoU-25': 16.77793623171664, 'IoU-26': 15.792158385382058, 'IoU-27': 16.067176719710677, 'IoU-28': 15.628688380335372, 'IoU-29': 15.967812540263212, 'IoU-30': 15.90109716479444, 'IoU-31': 16.8188642501889, 'IoU-32': 16.59449036439432, 'IoU-33': 15.34732714314174, 'IoU-34': 14.582721590444041, 'IoU-35': 15.651467915977662, 'IoU-36': 15.798591438132933, 'IoU-37': 14.987292064139664, 'IoU-38': 14.741200181250885, 'IoU-39': 14.573674757748508, 'IoU-40': 14.353573460733562, 'IoU-41': 13.465184474022982, 'IoU-42': 13.44364906311492, 'IoU-43': 13.423583688969051, 'IoU-44': 13.633090231314975, 'IoU-45': 13.232348596673893, 'IoU-46': 12.680093240809395, 'IoU-47': 12.21991276293983, 'IoU-48': 12.397213572394314, 'IoU-49': 11.754135625653117, 'IoU-50': 11.735658257138981, 'IoU-51': 11.300649917157891, 'IoU-52': 11.009406846668563, 'IoU-53': 10.609811762248917, 'IoU-54': 10.58217924273435, 'IoU-55': 9.952231015036899, 'IoU-56': 9.20939741219052, 'IoU-57': 9.008203876504197, 'IoU-58': 8.490893177474543, 'IoU-59': 8.34097908298667, 'IoU-60': 8.153514783294538, 'IoU-61': 8.002727004403145, 'IoU-62': 7.722175766090597, 'IoU-63': 7.646406327327074, 'IoU-64': 7.646894072233438, 'IoU-65': 7.350288505531455, 'IoU-66': 6.97042261211043, 'IoU-67': 6.6652335763609685, 'IoU-68': 6.295362821650269, 'IoU-69': 6.134114909810089, 'IoU-70': 6.094196191882174, 'IoU-71': 5.819811543737984, 'IoU-72': 5.856657412732625, 'IoU-73': 5.512664406148648, 'IoU-74': 5.468429477990024, 'IoU-75': 5.4296164120252035, 'IoU-76': 5.154068953099398, 'IoU-77': 4.854987698315382, 'IoU-78': 4.682347454978958, 'IoU-79': 4.437015726847869, 'IoU-80': 4.470379931878184, 'IoU-81': 4.357278430427775, 'IoU-82': 4.406442174056532, 'IoU-83': 4.579846567337205, 'IoU-84': 4.5041138937988405, 'IoU-85': 4.542749054406661, 'IoU-86': 4.148245138240524, 'IoU-87': 4.0397892046396935, 'IoU-88': 3.9510425588853537, 'IoU-89': 3.834173246687967, 'IoU-90': 3.808178391357687, 'IoU-91': 3.6250653123933154, 'IoU-92': 3.5665881737612004, 'IoU-93': 3.6721275261962476, 'IoU-94': 3.616422257979256, 'IoU-95': 3.7061918459342333, 'IoU-96': 3.552529217163939, 'IoU-97': 3.5365131091690123, 'IoU-98': 3.4277857507596625, 'IoU-99': 3.276754006370079, 'IoU-100': 3.421904530315291, 'IoU-101': 3.3658218977231495, 'IoU-102': 3.4104915117879915, 'IoU-103': 3.5526734690628925, 'IoU-104': 3.629728614413715, 'IoU-105': 3.720780576340138, 'IoU-106': 3.896146041752345, 'IoU-107': 3.808293830288774, 'IoU-108': 3.802864941251147, 'IoU-109': 3.6830774856250184, 'IoU-110': 3.855130810438989, 'IoU-111': 3.8151721865595443, 'IoU-112': 3.5769091956018038, 'IoU-113': 3.776080705877758, 'IoU-114': 3.6152826815806014, 'IoU-115': 3.653210567725388, 'IoU-116': 3.6892378941301374, 'IoU-117': 3.9443735879653814, 'IoU-118': 3.668707310553239, 'IoU-119': 3.5785193609003825, 'IoU-120': 3.376516254134772, 'IoU-121': 3.1815833625600725, 'IoU-122': 3.2316778732123748, 'IoU-123': 3.054145090102098, 'IoU-124': 3.0818447290731807, 'IoU-125': 3.01128296280503, 'IoU-126': 2.9306726400361796, 'IoU-127': 2.9199742997595735, 'IoU-128': 2.7734351292016433, 'IoU-129': 3.025493683304865, 'IoU-130': 2.921517446591208, 'IoU-131': 2.4976516916265106, 'IoU-132': 2.4699095671253217, 'IoU-133': 2.4284125173556634, 'IoU-134': 2.310926102321132, 'IoU-135': 2.3584813670575664, 'IoU-136': 2.4965849898770958, 'IoU-137': 2.5097397025224186, 'IoU-138': 2.2903301068066884, 'IoU-139': 2.2974538748363473, 'IoU-140': 2.4616762745745513, 'IoU-141': 2.5386062422935454, 'IoU-142': 2.1747508694315623, 'IoU-143': 2.1161685016490743, 'IoU-144': 2.0735804397074222, 'IoU-145': 2.2112431956133434, 'IoU-146': 1.9932805639708833, 'IoU-147': 2.179496755798389, 'IoU-148': 2.166793103125322, 'IoU-149': 2.07834341193816, 'IoU-150': 2.1099075824342495, 'IoU-151': 2.191632349052677, 'IoU-152': 2.3427713725389947, 'IoU-153': 1.927166640982448, 'IoU-154': 2.146813295544207, 'IoU-155': 2.0606485737718567, 'IoU-156': 1.8347744717522936, 'IoU-157': 1.48333556330789, 'IoU-158': 1.4544108348170628, 'IoU-159': 1.6217250146635207, 'IoU-160': 1.259715340271854, 'IoU-161': 1.2866449944313165, 'IoU-162': 1.3501970185445427, 'IoU-163': 1.4599290308366013, 'IoU-164': 1.2596358193771686, 'IoU-165': 1.4237921315521755, 'IoU-166': 1.5441347289616878, 'IoU-167': 1.5270440282181628, 'IoU-168': 1.4438058172352024, 'IoU-169': 1.3134416438821088, 'IoU-170': 1.3354062668455366, 'IoU-171': 1.2758800890772584, 'IoU-172': 1.0382723277677952, 'IoU-173': 1.245330101546593, 'IoU-174': 1.2152751710904444, 'IoU-175': 1.0840251554369007, 'IoU-176': 1.3053304962048666, 'IoU-177': 1.3853209511840838, 'IoU-178': 1.2737672402662954, 'IoU-179': 0.902142873374287, 'IoU-180': 0.7510596601174792, 'IoU-181': 0.44953050304060604, 'IoU-182': 0.31868351111206117, 'IoU-183': 0.28888235395872613, 'IoU-184': 0.17930072716406015, 'IoU-185': 0.09126315658770989, 'IoU-186': 0.04227616631838115, 'IoU-187': 0.04772033158813264, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 11.102670852526343, 'pACC': 19.710572293878947, 'ACC-0': 0.0, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 34.831685456429994, 'ACC-7': 8.133060590480982, 'ACC-8': 15.386750791445833, 'ACC-9': 23.59488249607579, 'ACC-10': 23.536895706026325, 'ACC-11': 31.702443276515357, 'ACC-12': 34.551754531646125, 'ACC-13': 30.954559844346303, 'ACC-14': 32.972094424344334, 'ACC-15': 32.6750245798687, 'ACC-16': 31.300489505243068, 'ACC-17': 26.777931178894086, 'ACC-18': 25.300367078257345, 'ACC-19': 26.85476404241762, 'ACC-20': 28.432251863267133, 'ACC-21': 29.787284097345612, 'ACC-22': 28.787221495859484, 'ACC-23': 28.472077021708287, 'ACC-24': 28.932343206487243, 'ACC-25': 29.498680681393918, 'ACC-26': 27.748664447270848, 'ACC-27': 27.404590741882632, 'ACC-28': 27.0309089742175, 'ACC-29': 26.78346811485042, 'ACC-30': 27.414597922356272, 'ACC-31': 28.53176588425177, 'ACC-32': 28.509257475250955, 'ACC-33': 26.761552859004446, 'ACC-34': 25.253138975125943, 'ACC-35': 26.748212114942206, 'ACC-36': 27.014637179079372, 'ACC-37': 25.998532260736706, 'ACC-38': 25.56894335581162, 'ACC-39': 25.627067554683563, 'ACC-40': 25.402796322460524, 'ACC-41': 24.782400040036908, 'ACC-42': 24.94994004258901, 'ACC-43': 24.892501419971165, 'ACC-44': 24.622341212729943, 'ACC-45': 24.177739940719952, 'ACC-46': 23.64235464536081, 'ACC-47': 22.698367102622, 'ACC-48': 23.028274342774335, 'ACC-49': 21.595709957479052, 'ACC-50': 21.327580820305773, 'ACC-51': 20.80811423487387, 'ACC-52': 20.393798067174366, 'ACC-53': 19.733464152479403, 'ACC-54': 19.657652710035116, 'ACC-55': 18.474604032910793, 'ACC-56': 17.106482944274624, 'ACC-57': 16.21886788149791, 'ACC-58': 15.306729870635783, 'ACC-59': 15.192214653929936, 'ACC-60': 15.013291477572151, 'ACC-61': 14.903014017693064, 'ACC-62': 14.576911833878597, 'ACC-63': 14.670193841518032, 'ACC-64': 14.60929132628808, 'ACC-65': 14.186203284357632, 'ACC-66': 13.583382630882438, 'ACC-67': 13.135437115391166, 'ACC-68': 12.461855255520302, 'ACC-69': 12.01070136454261, 'ACC-70': 11.917339607287627, 'ACC-71': 11.586977722672662, 'ACC-72': 11.648979862746303, 'ACC-73': 10.96839477602672, 'ACC-74': 10.876228597210522, 'ACC-75': 10.79694104979694, 'ACC-76': 9.997970819623657, 'ACC-77': 9.523923884236517, 'ACC-78': 9.206120183957799, 'ACC-79': 8.726134932507684, 'ACC-80': 8.70693229001891, 'ACC-81': 8.432716502847038, 'ACC-82': 8.532773145928129, 'ACC-83': 8.8025380745122, 'ACC-84': 8.7210714104652, 'ACC-85': 8.732646290538279, 'ACC-86': 7.956269080693732, 'ACC-87': 7.709121856063832, 'ACC-88': 7.472557471011555, 'ACC-89': 7.212849505812385, 'ACC-90': 7.079779628622225, 'ACC-91': 6.749304172299104, 'ACC-92': 6.597620527504199, 'ACC-93': 6.749337167207997, 'ACC-94': 6.601294608211633, 'ACC-95': 6.7312831909944, 'ACC-96': 6.445752605094299, 'ACC-97': 6.278560800187781, 'ACC-98': 6.075102194378646, 'ACC-99': 5.797060645306605, 'ACC-100': 6.059537103037999, 'ACC-101': 5.967715033933948, 'ACC-102': 6.087041232442229, 'ACC-103': 6.324241994899404, 'ACC-104': 6.411721305427806, 'ACC-105': 6.609491231246892, 'ACC-106': 6.926063651670352, 'ACC-107': 6.841578223655296, 'ACC-108': 6.781897216663483, 'ACC-109': 6.544792716479349, 'ACC-110': 6.898474603370078, 'ACC-111': 6.8656900711747, 'ACC-112': 6.497828885334315, 'ACC-113': 6.839430524273461, 'ACC-114': 6.6605029087130925, 'ACC-115': 6.843060755040368, 'ACC-116': 7.023798481663787, 'ACC-117': 7.539376707248175, 'ACC-118': 7.1280267809045395, 'ACC-119': 6.9304068517891855, 'ACC-120': 6.4982412492928106, 'ACC-121': 6.0981719428404535, 'ACC-122': 6.159764876824516, 'ACC-123': 5.896206399049478, 'ACC-124': 6.1580596888499874, 'ACC-125': 6.0220500498714875, 'ACC-126': 5.901977704714979, 'ACC-127': 5.895356932594455, 'ACC-128': 5.657093442908875, 'ACC-129': 6.150007624443149, 'ACC-130': 5.925555214462792, 'ACC-131': 5.1104762170593325, 'ACC-132': 4.994487505571138, 'ACC-133': 4.907836453081304, 'ACC-134': 4.636001723395088, 'ACC-135': 4.739966364517416, 'ACC-136': 5.022508619083116, 'ACC-137': 5.212266365037242, 'ACC-138': 4.8199260095946395, 'ACC-139': 4.904435570152318, 'ACC-140': 5.180333517203452, 'ACC-141': 5.307007282807558, 'ACC-142': 4.578096712751548, 'ACC-143': 4.418732752663649, 'ACC-144': 4.275902527075813, 'ACC-145': 4.471388000626132, 'ACC-146': 4.0711886865733025, 'ACC-147': 4.416132845179543, 'ACC-148': 4.398170811110868, 'ACC-149': 4.321604269072448, 'ACC-150': 4.32088921408909, 'ACC-151': 4.461020822076069, 'ACC-152': 4.731543765594443, 'ACC-153': 4.15292511771927, 'ACC-154': 4.565281970535432, 'ACC-155': 4.301476841614838, 'ACC-156': 3.6881330515102744, 'ACC-157': 3.093232507591193, 'ACC-158': 3.1715430505355293, 'ACC-159': 3.617938852296796, 'ACC-160': 2.586894312989187, 'ACC-161': 2.7187939687202487, 'ACC-162': 2.91579019401906, 'ACC-163': 3.170444244359621, 'ACC-164': 2.7327585386813125, 'ACC-165': 3.389639389251875, 'ACC-166': 3.961353468030991, 'ACC-167': 4.360333317699295, 'ACC-168': 3.9396230395949083, 'ACC-169': 3.63980606885854, 'ACC-170': 3.679706688246234, 'ACC-171': 3.740223289236342, 'ACC-172': 2.8573545208726894, 'ACC-173': 3.2750335838165516, 'ACC-174': 3.0174414378142003, 'ACC-175': 2.8076519887072706, 'ACC-176': 3.8300658811237525, 'ACC-177': 3.9160756566624038, 'ACC-178': 2.839421994124135, 'ACC-179': 1.691483339791958, 'ACC-180': 1.2053828439838803, 'ACC-181': 0.6532743065178206, 'ACC-182': 0.42384426033372113, 'ACC-183': 0.3538543758578555, 'ACC-184': 0.20376541506590537, 'ACC-185': 0.10185275002425065, 'ACC-186': 0.04556045258289996, 'ACC-187': 0.05073750588917479, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 10:52:33] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 10:52:33] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 10:52:33] d2.evaluation.testing INFO: copypaste: 4.4254,0.5236,0.3170,5.9033,11.2138,11.1027,19.7106
[01/29 10:52:33] d2.utils.events INFO:  eta: 1 day, 8:37:27  iter: 14999  total_loss: 51.61  loss_mask: 5.396  loss_mask_0: 5.156  loss_mask_1: 5.081  loss_mask_2: 5.054  loss_mask_3: 5.081  loss_mask_4: 5.066  loss_mask_5: 5.057  loss_mask_6: 5.062  loss_mask_7: 5.414  loss_mask_8: 5.406  time: 2.6085  data_time: 0.0571  lr: 7.719e-05  max_mem: 27639M
[01/29 10:53:26] d2.utils.events INFO:  eta: 1 day, 8:36:45  iter: 15019  total_loss: 45.33  loss_mask: 4.789  loss_mask_0: 4.472  loss_mask_1: 4.425  loss_mask_2: 4.424  loss_mask_3: 4.441  loss_mask_4: 4.462  loss_mask_5: 4.476  loss_mask_6: 4.461  loss_mask_7: 4.781  loss_mask_8: 4.784  time: 2.6085  data_time: 0.0542  lr: 7.716e-05  max_mem: 27639M
[01/29 10:54:18] d2.utils.events INFO:  eta: 1 day, 8:36:00  iter: 15039  total_loss: 58.24  loss_mask: 5.966  loss_mask_0: 5.872  loss_mask_1: 5.724  loss_mask_2: 5.742  loss_mask_3: 5.76  loss_mask_4: 5.74  loss_mask_5: 5.77  loss_mask_6: 5.773  loss_mask_7: 5.939  loss_mask_8: 5.957  time: 2.6085  data_time: 0.0538  lr: 7.7129e-05  max_mem: 27639M
[01/29 10:55:10] d2.utils.events INFO:  eta: 1 day, 8:35:00  iter: 15059  total_loss: 52.45  loss_mask: 5.459  loss_mask_0: 5.277  loss_mask_1: 5.148  loss_mask_2: 5.146  loss_mask_3: 5.151  loss_mask_4: 5.133  loss_mask_5: 5.139  loss_mask_6: 5.136  loss_mask_7: 5.467  loss_mask_8: 5.486  time: 2.6085  data_time: 0.0606  lr: 7.7098e-05  max_mem: 27639M
[01/29 10:56:03] d2.utils.events INFO:  eta: 1 day, 8:34:35  iter: 15079  total_loss: 48.21  loss_mask: 5.043  loss_mask_0: 4.725  loss_mask_1: 4.702  loss_mask_2: 4.723  loss_mask_3: 4.706  loss_mask_4: 4.713  loss_mask_5: 4.695  loss_mask_6: 4.713  loss_mask_7: 5.053  loss_mask_8: 5.078  time: 2.6085  data_time: 0.0624  lr: 7.7067e-05  max_mem: 27639M
[01/29 10:56:55] d2.utils.events INFO:  eta: 1 day, 8:33:56  iter: 15099  total_loss: 50.77  loss_mask: 5.271  loss_mask_0: 5.059  loss_mask_1: 4.971  loss_mask_2: 4.978  loss_mask_3: 4.954  loss_mask_4: 4.964  loss_mask_5: 4.965  loss_mask_6: 4.945  loss_mask_7: 5.276  loss_mask_8: 5.274  time: 2.6085  data_time: 0.0582  lr: 7.7036e-05  max_mem: 27639M
[01/29 10:57:48] d2.utils.events INFO:  eta: 1 day, 8:33:18  iter: 15119  total_loss: 58.44  loss_mask: 6.002  loss_mask_0: 5.803  loss_mask_1: 5.787  loss_mask_2: 5.778  loss_mask_3: 5.779  loss_mask_4: 5.758  loss_mask_5: 5.796  loss_mask_6: 5.804  loss_mask_7: 5.969  loss_mask_8: 5.964  time: 2.6086  data_time: 0.0582  lr: 7.7005e-05  max_mem: 27639M
[01/29 10:58:40] d2.utils.events INFO:  eta: 1 day, 8:32:14  iter: 15139  total_loss: 47.83  loss_mask: 5.077  loss_mask_0: 4.709  loss_mask_1: 4.696  loss_mask_2: 4.649  loss_mask_3: 4.646  loss_mask_4: 4.646  loss_mask_5: 4.642  loss_mask_6: 4.645  loss_mask_7: 5.081  loss_mask_8: 5.068  time: 2.6086  data_time: 0.0582  lr: 7.6974e-05  max_mem: 27639M
[01/29 10:59:32] d2.utils.events INFO:  eta: 1 day, 8:31:22  iter: 15159  total_loss: 46.24  loss_mask: 4.758  loss_mask_0: 4.632  loss_mask_1: 4.57  loss_mask_2: 4.595  loss_mask_3: 4.555  loss_mask_4: 4.558  loss_mask_5: 4.551  loss_mask_6: 4.556  loss_mask_7: 4.748  loss_mask_8: 4.746  time: 2.6086  data_time: 0.0525  lr: 7.6943e-05  max_mem: 27639M
[01/29 11:00:25] d2.utils.events INFO:  eta: 1 day, 8:30:34  iter: 15179  total_loss: 48.83  loss_mask: 5.038  loss_mask_0: 4.923  loss_mask_1: 4.824  loss_mask_2: 4.815  loss_mask_3: 4.809  loss_mask_4: 4.806  loss_mask_5: 4.819  loss_mask_6: 4.796  loss_mask_7: 5.038  loss_mask_8: 5.031  time: 2.6086  data_time: 0.0517  lr: 7.6913e-05  max_mem: 27639M
[01/29 11:01:17] d2.utils.events INFO:  eta: 1 day, 8:29:47  iter: 15199  total_loss: 49.21  loss_mask: 5.077  loss_mask_0: 4.962  loss_mask_1: 4.855  loss_mask_2: 4.833  loss_mask_3: 4.83  loss_mask_4: 4.85  loss_mask_5: 4.836  loss_mask_6: 4.85  loss_mask_7: 5.066  loss_mask_8: 5.08  time: 2.6086  data_time: 0.0479  lr: 7.6882e-05  max_mem: 27639M
[01/29 11:02:09] d2.utils.events INFO:  eta: 1 day, 8:28:45  iter: 15219  total_loss: 50.38  loss_mask: 5.252  loss_mask_0: 5.085  loss_mask_1: 4.969  loss_mask_2: 4.925  loss_mask_3: 4.922  loss_mask_4: 4.943  loss_mask_5: 4.92  loss_mask_6: 4.939  loss_mask_7: 5.239  loss_mask_8: 5.257  time: 2.6086  data_time: 0.0579  lr: 7.6851e-05  max_mem: 27639M
[01/29 11:03:01] d2.utils.events INFO:  eta: 1 day, 8:27:57  iter: 15239  total_loss: 49.27  loss_mask: 5.055  loss_mask_0: 4.988  loss_mask_1: 4.853  loss_mask_2: 4.849  loss_mask_3: 4.833  loss_mask_4: 4.837  loss_mask_5: 4.843  loss_mask_6: 4.835  loss_mask_7: 5.065  loss_mask_8: 5.056  time: 2.6086  data_time: 0.0524  lr: 7.682e-05  max_mem: 27639M
[01/29 11:03:54] d2.utils.events INFO:  eta: 1 day, 8:27:27  iter: 15259  total_loss: 53.68  loss_mask: 5.55  loss_mask_0: 5.239  loss_mask_1: 5.292  loss_mask_2: 5.281  loss_mask_3: 5.268  loss_mask_4: 5.272  loss_mask_5: 5.295  loss_mask_6: 5.28  loss_mask_7: 5.541  loss_mask_8: 5.538  time: 2.6086  data_time: 0.0566  lr: 7.6789e-05  max_mem: 27639M
[01/29 11:04:46] d2.utils.events INFO:  eta: 1 day, 8:26:24  iter: 15279  total_loss: 47.41  loss_mask: 4.91  loss_mask_0: 4.71  loss_mask_1: 4.649  loss_mask_2: 4.659  loss_mask_3: 4.645  loss_mask_4: 4.662  loss_mask_5: 4.662  loss_mask_6: 4.667  loss_mask_7: 4.92  loss_mask_8: 4.927  time: 2.6086  data_time: 0.0565  lr: 7.6758e-05  max_mem: 27639M
[01/29 11:05:39] d2.utils.events INFO:  eta: 1 day, 8:25:34  iter: 15299  total_loss: 50.54  loss_mask: 5.164  loss_mask_0: 5.09  loss_mask_1: 5.022  loss_mask_2: 5.003  loss_mask_3: 5.008  loss_mask_4: 5.02  loss_mask_5: 5.019  loss_mask_6: 4.999  loss_mask_7: 5.155  loss_mask_8: 5.153  time: 2.6086  data_time: 0.0593  lr: 7.6727e-05  max_mem: 27639M
[01/29 11:06:31] d2.utils.events INFO:  eta: 1 day, 8:24:33  iter: 15319  total_loss: 48.52  loss_mask: 5.026  loss_mask_0: 4.838  loss_mask_1: 4.792  loss_mask_2: 4.763  loss_mask_3: 4.774  loss_mask_4: 4.763  loss_mask_5: 4.771  loss_mask_6: 4.788  loss_mask_7: 5.034  loss_mask_8: 5.032  time: 2.6086  data_time: 0.0531  lr: 7.6696e-05  max_mem: 27639M
[01/29 11:07:24] d2.utils.events INFO:  eta: 1 day, 8:23:41  iter: 15339  total_loss: 54.33  loss_mask: 5.617  loss_mask_0: 5.473  loss_mask_1: 5.341  loss_mask_2: 5.322  loss_mask_3: 5.324  loss_mask_4: 5.332  loss_mask_5: 5.334  loss_mask_6: 5.314  loss_mask_7: 5.624  loss_mask_8: 5.631  time: 2.6086  data_time: 0.0576  lr: 7.6665e-05  max_mem: 27639M
[01/29 11:08:16] d2.utils.events INFO:  eta: 1 day, 8:22:57  iter: 15359  total_loss: 51.54  loss_mask: 5.363  loss_mask_0: 5.181  loss_mask_1: 5.042  loss_mask_2: 5.035  loss_mask_3: 5.04  loss_mask_4: 5.045  loss_mask_5: 5.045  loss_mask_6: 5.031  loss_mask_7: 5.377  loss_mask_8: 5.375  time: 2.6087  data_time: 0.0606  lr: 7.6635e-05  max_mem: 27639M
[01/29 11:09:08] d2.utils.events INFO:  eta: 1 day, 8:21:56  iter: 15379  total_loss: 54.08  loss_mask: 5.553  loss_mask_0: 5.477  loss_mask_1: 5.358  loss_mask_2: 5.331  loss_mask_3: 5.337  loss_mask_4: 5.325  loss_mask_5: 5.305  loss_mask_6: 5.316  loss_mask_7: 5.55  loss_mask_8: 5.531  time: 2.6087  data_time: 0.0536  lr: 7.6604e-05  max_mem: 27639M
[01/29 11:10:01] d2.utils.events INFO:  eta: 1 day, 8:21:12  iter: 15399  total_loss: 47.68  loss_mask: 4.909  loss_mask_0: 4.678  loss_mask_1: 4.711  loss_mask_2: 4.712  loss_mask_3: 4.717  loss_mask_4: 4.714  loss_mask_5: 4.728  loss_mask_6: 4.736  loss_mask_7: 4.906  loss_mask_8: 4.904  time: 2.6087  data_time: 0.0550  lr: 7.6573e-05  max_mem: 27639M
[01/29 11:10:53] d2.utils.events INFO:  eta: 1 day, 8:20:24  iter: 15419  total_loss: 53.21  loss_mask: 5.495  loss_mask_0: 5.337  loss_mask_1: 5.337  loss_mask_2: 5.244  loss_mask_3: 5.211  loss_mask_4: 5.236  loss_mask_5: 5.22  loss_mask_6: 5.184  loss_mask_7: 5.493  loss_mask_8: 5.512  time: 2.6087  data_time: 0.0552  lr: 7.6542e-05  max_mem: 27639M
[01/29 11:11:45] d2.utils.events INFO:  eta: 1 day, 8:19:27  iter: 15439  total_loss: 49.62  loss_mask: 5.184  loss_mask_0: 4.992  loss_mask_1: 4.855  loss_mask_2: 4.859  loss_mask_3: 4.856  loss_mask_4: 4.884  loss_mask_5: 4.899  loss_mask_6: 4.866  loss_mask_7: 5.178  loss_mask_8: 5.194  time: 2.6087  data_time: 0.0573  lr: 7.6511e-05  max_mem: 27639M
[01/29 11:12:38] d2.utils.events INFO:  eta: 1 day, 8:18:37  iter: 15459  total_loss: 46.97  loss_mask: 4.908  loss_mask_0: 4.618  loss_mask_1: 4.594  loss_mask_2: 4.597  loss_mask_3: 4.596  loss_mask_4: 4.61  loss_mask_5: 4.617  loss_mask_6: 4.603  loss_mask_7: 4.896  loss_mask_8: 4.927  time: 2.6087  data_time: 0.0573  lr: 7.648e-05  max_mem: 27639M
[01/29 11:13:30] d2.utils.events INFO:  eta: 1 day, 8:17:40  iter: 15479  total_loss: 49.49  loss_mask: 5.105  loss_mask_0: 4.939  loss_mask_1: 4.837  loss_mask_2: 4.847  loss_mask_3: 4.844  loss_mask_4: 4.844  loss_mask_5: 4.836  loss_mask_6: 4.84  loss_mask_7: 5.1  loss_mask_8: 5.109  time: 2.6087  data_time: 0.0569  lr: 7.6449e-05  max_mem: 27639M
[01/29 11:14:22] d2.utils.events INFO:  eta: 1 day, 8:16:43  iter: 15499  total_loss: 48.8  loss_mask: 5.059  loss_mask_0: 4.878  loss_mask_1: 4.82  loss_mask_2: 4.795  loss_mask_3: 4.791  loss_mask_4: 4.823  loss_mask_5: 4.815  loss_mask_6: 4.817  loss_mask_7: 5.075  loss_mask_8: 5.079  time: 2.6087  data_time: 0.0586  lr: 7.6418e-05  max_mem: 27639M
[01/29 11:15:15] d2.utils.events INFO:  eta: 1 day, 8:15:53  iter: 15519  total_loss: 54.05  loss_mask: 5.565  loss_mask_0: 5.502  loss_mask_1: 5.309  loss_mask_2: 5.304  loss_mask_3: 5.31  loss_mask_4: 5.335  loss_mask_5: 5.326  loss_mask_6: 5.292  loss_mask_7: 5.564  loss_mask_8: 5.567  time: 2.6087  data_time: 0.0520  lr: 7.6387e-05  max_mem: 27639M
[01/29 11:16:07] d2.utils.events INFO:  eta: 1 day, 8:15:01  iter: 15539  total_loss: 45.96  loss_mask: 4.868  loss_mask_0: 4.597  loss_mask_1: 4.506  loss_mask_2: 4.487  loss_mask_3: 4.484  loss_mask_4: 4.48  loss_mask_5: 4.488  loss_mask_6: 4.484  loss_mask_7: 4.85  loss_mask_8: 4.875  time: 2.6087  data_time: 0.0540  lr: 7.6356e-05  max_mem: 27639M
[01/29 11:16:59] d2.utils.events INFO:  eta: 1 day, 8:14:16  iter: 15559  total_loss: 52.09  loss_mask: 5.364  loss_mask_0: 5.166  loss_mask_1: 5.131  loss_mask_2: 5.142  loss_mask_3: 5.131  loss_mask_4: 5.124  loss_mask_5: 5.146  loss_mask_6: 5.116  loss_mask_7: 5.351  loss_mask_8: 5.367  time: 2.6087  data_time: 0.0642  lr: 7.6325e-05  max_mem: 27639M
[01/29 11:17:52] d2.utils.events INFO:  eta: 1 day, 8:13:26  iter: 15579  total_loss: 47.79  loss_mask: 4.993  loss_mask_0: 4.806  loss_mask_1: 4.693  loss_mask_2: 4.67  loss_mask_3: 4.675  loss_mask_4: 4.675  loss_mask_5: 4.662  loss_mask_6: 4.671  loss_mask_7: 5.004  loss_mask_8: 5.003  time: 2.6088  data_time: 0.0599  lr: 7.6295e-05  max_mem: 27639M
[01/29 11:18:44] d2.utils.events INFO:  eta: 1 day, 8:12:29  iter: 15599  total_loss: 50.58  loss_mask: 5.287  loss_mask_0: 5.082  loss_mask_1: 4.936  loss_mask_2: 4.906  loss_mask_3: 4.902  loss_mask_4: 4.885  loss_mask_5: 4.926  loss_mask_6: 4.923  loss_mask_7: 5.323  loss_mask_8: 5.314  time: 2.6088  data_time: 0.0552  lr: 7.6264e-05  max_mem: 27639M
[01/29 11:19:37] d2.utils.events INFO:  eta: 1 day, 8:11:35  iter: 15619  total_loss: 52.34  loss_mask: 5.438  loss_mask_0: 5.28  loss_mask_1: 5.152  loss_mask_2: 5.144  loss_mask_3: 5.147  loss_mask_4: 5.132  loss_mask_5: 5.126  loss_mask_6: 5.134  loss_mask_7: 5.454  loss_mask_8: 5.446  time: 2.6088  data_time: 0.0612  lr: 7.6233e-05  max_mem: 27639M
[01/29 11:20:29] d2.utils.events INFO:  eta: 1 day, 8:10:47  iter: 15639  total_loss: 48.99  loss_mask: 5.201  loss_mask_0: 4.949  loss_mask_1: 4.802  loss_mask_2: 4.766  loss_mask_3: 4.736  loss_mask_4: 4.746  loss_mask_5: 4.768  loss_mask_6: 4.755  loss_mask_7: 5.185  loss_mask_8: 5.191  time: 2.6088  data_time: 0.0549  lr: 7.6202e-05  max_mem: 27639M
[01/29 11:21:21] d2.utils.events INFO:  eta: 1 day, 8:09:51  iter: 15659  total_loss: 48.58  loss_mask: 4.937  loss_mask_0: 4.937  loss_mask_1: 4.766  loss_mask_2: 4.79  loss_mask_3: 4.78  loss_mask_4: 4.779  loss_mask_5: 4.741  loss_mask_6: 4.759  loss_mask_7: 4.915  loss_mask_8: 4.92  time: 2.6088  data_time: 0.0523  lr: 7.6171e-05  max_mem: 27639M
[01/29 11:22:14] d2.utils.events INFO:  eta: 1 day, 8:09:02  iter: 15679  total_loss: 46.36  loss_mask: 4.86  loss_mask_0: 4.565  loss_mask_1: 4.519  loss_mask_2: 4.525  loss_mask_3: 4.531  loss_mask_4: 4.522  loss_mask_5: 4.522  loss_mask_6: 4.518  loss_mask_7: 4.864  loss_mask_8: 4.868  time: 2.6088  data_time: 0.0523  lr: 7.614e-05  max_mem: 27639M
[01/29 11:23:06] d2.utils.events INFO:  eta: 1 day, 8:08:18  iter: 15699  total_loss: 50.43  loss_mask: 5.212  loss_mask_0: 5.115  loss_mask_1: 4.932  loss_mask_2: 4.929  loss_mask_3: 4.911  loss_mask_4: 4.911  loss_mask_5: 4.951  loss_mask_6: 4.935  loss_mask_7: 5.217  loss_mask_8: 5.223  time: 2.6088  data_time: 0.0539  lr: 7.6109e-05  max_mem: 27639M
[01/29 11:23:59] d2.utils.events INFO:  eta: 1 day, 8:07:34  iter: 15719  total_loss: 51.46  loss_mask: 5.381  loss_mask_0: 5.233  loss_mask_1: 5.006  loss_mask_2: 5.035  loss_mask_3: 5.035  loss_mask_4: 5.03  loss_mask_5: 5.034  loss_mask_6: 5.022  loss_mask_7: 5.405  loss_mask_8: 5.369  time: 2.6088  data_time: 0.0542  lr: 7.6078e-05  max_mem: 27639M
[01/29 11:24:51] d2.utils.events INFO:  eta: 1 day, 8:06:19  iter: 15739  total_loss: 48.44  loss_mask: 5.03  loss_mask_0: 4.966  loss_mask_1: 4.777  loss_mask_2: 4.784  loss_mask_3: 4.761  loss_mask_4: 4.779  loss_mask_5: 4.743  loss_mask_6: 4.769  loss_mask_7: 5.015  loss_mask_8: 5.031  time: 2.6088  data_time: 0.0582  lr: 7.6047e-05  max_mem: 27639M
[01/29 11:25:43] d2.utils.events INFO:  eta: 1 day, 8:05:34  iter: 15759  total_loss: 49.6  loss_mask: 5.132  loss_mask_0: 5.052  loss_mask_1: 4.878  loss_mask_2: 4.87  loss_mask_3: 4.888  loss_mask_4: 4.878  loss_mask_5: 4.899  loss_mask_6: 4.889  loss_mask_7: 5.141  loss_mask_8: 5.155  time: 2.6089  data_time: 0.0581  lr: 7.6016e-05  max_mem: 27639M
[01/29 11:26:35] d2.utils.events INFO:  eta: 1 day, 8:04:34  iter: 15779  total_loss: 46.17  loss_mask: 4.804  loss_mask_0: 4.623  loss_mask_1: 4.495  loss_mask_2: 4.498  loss_mask_3: 4.495  loss_mask_4: 4.489  loss_mask_5: 4.497  loss_mask_6: 4.515  loss_mask_7: 4.816  loss_mask_8: 4.808  time: 2.6088  data_time: 0.0559  lr: 7.5985e-05  max_mem: 27639M
[01/29 11:27:27] d2.utils.events INFO:  eta: 1 day, 8:03:22  iter: 15799  total_loss: 49.3  loss_mask: 5.251  loss_mask_0: 4.869  loss_mask_1: 4.803  loss_mask_2: 4.793  loss_mask_3: 4.781  loss_mask_4: 4.772  loss_mask_5: 4.782  loss_mask_6: 4.784  loss_mask_7: 5.26  loss_mask_8: 5.264  time: 2.6088  data_time: 0.0487  lr: 7.5954e-05  max_mem: 27639M
[01/29 11:28:20] d2.utils.events INFO:  eta: 1 day, 8:02:32  iter: 15819  total_loss: 50.68  loss_mask: 5.244  loss_mask_0: 5.018  loss_mask_1: 4.965  loss_mask_2: 4.949  loss_mask_3: 4.967  loss_mask_4: 4.962  loss_mask_5: 4.978  loss_mask_6: 4.962  loss_mask_7: 5.221  loss_mask_8: 5.234  time: 2.6089  data_time: 0.0574  lr: 7.5923e-05  max_mem: 27639M
[01/29 11:29:12] d2.utils.events INFO:  eta: 1 day, 8:01:39  iter: 15839  total_loss: 48.34  loss_mask: 5.036  loss_mask_0: 4.791  loss_mask_1: 4.717  loss_mask_2: 4.725  loss_mask_3: 4.734  loss_mask_4: 4.745  loss_mask_5: 4.759  loss_mask_6: 4.754  loss_mask_7: 5.036  loss_mask_8: 5.036  time: 2.6089  data_time: 0.0518  lr: 7.5893e-05  max_mem: 27639M
[01/29 11:30:05] d2.utils.events INFO:  eta: 1 day, 8:00:54  iter: 15859  total_loss: 49.16  loss_mask: 5.026  loss_mask_0: 4.929  loss_mask_1: 4.847  loss_mask_2: 4.84  loss_mask_3: 4.828  loss_mask_4: 4.846  loss_mask_5: 4.84  loss_mask_6: 4.829  loss_mask_7: 5.038  loss_mask_8: 5.037  time: 2.6089  data_time: 0.0610  lr: 7.5862e-05  max_mem: 27639M
[01/29 11:30:57] d2.utils.events INFO:  eta: 1 day, 7:59:54  iter: 15879  total_loss: 49.48  loss_mask: 5.155  loss_mask_0: 4.941  loss_mask_1: 4.876  loss_mask_2: 4.886  loss_mask_3: 4.885  loss_mask_4: 4.871  loss_mask_5: 4.865  loss_mask_6: 4.877  loss_mask_7: 5.154  loss_mask_8: 5.144  time: 2.6089  data_time: 0.0611  lr: 7.5831e-05  max_mem: 27639M
[01/29 11:31:49] d2.utils.events INFO:  eta: 1 day, 7:58:56  iter: 15899  total_loss: 52.92  loss_mask: 5.489  loss_mask_0: 5.373  loss_mask_1: 5.191  loss_mask_2: 5.18  loss_mask_3: 5.176  loss_mask_4: 5.161  loss_mask_5: 5.212  loss_mask_6: 5.193  loss_mask_7: 5.467  loss_mask_8: 5.482  time: 2.6089  data_time: 0.0514  lr: 7.58e-05  max_mem: 27639M
[01/29 11:32:41] d2.utils.events INFO:  eta: 1 day, 7:57:56  iter: 15919  total_loss: 50.18  loss_mask: 5.211  loss_mask_0: 5.051  loss_mask_1: 4.908  loss_mask_2: 4.888  loss_mask_3: 4.893  loss_mask_4: 4.894  loss_mask_5: 4.904  loss_mask_6: 4.893  loss_mask_7: 5.189  loss_mask_8: 5.207  time: 2.6089  data_time: 0.0553  lr: 7.5769e-05  max_mem: 27639M
[01/29 11:33:34] d2.utils.events INFO:  eta: 1 day, 7:57:12  iter: 15939  total_loss: 49.89  loss_mask: 5.253  loss_mask_0: 4.951  loss_mask_1: 4.861  loss_mask_2: 4.844  loss_mask_3: 4.862  loss_mask_4: 4.886  loss_mask_5: 4.845  loss_mask_6: 4.865  loss_mask_7: 5.234  loss_mask_8: 5.247  time: 2.6089  data_time: 0.0593  lr: 7.5738e-05  max_mem: 27639M
[01/29 11:34:26] d2.utils.events INFO:  eta: 1 day, 7:56:16  iter: 15959  total_loss: 53.35  loss_mask: 5.572  loss_mask_0: 5.239  loss_mask_1: 5.238  loss_mask_2: 5.234  loss_mask_3: 5.236  loss_mask_4: 5.247  loss_mask_5: 5.246  loss_mask_6: 5.253  loss_mask_7: 5.566  loss_mask_8: 5.568  time: 2.6089  data_time: 0.0603  lr: 7.5707e-05  max_mem: 27639M
[01/29 11:35:19] d2.utils.events INFO:  eta: 1 day, 7:55:17  iter: 15979  total_loss: 46.74  loss_mask: 4.892  loss_mask_0: 4.648  loss_mask_1: 4.57  loss_mask_2: 4.568  loss_mask_3: 4.591  loss_mask_4: 4.577  loss_mask_5: 4.595  loss_mask_6: 4.576  loss_mask_7: 4.88  loss_mask_8: 4.891  time: 2.6089  data_time: 0.0509  lr: 7.5676e-05  max_mem: 27639M
[01/29 11:36:11] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 11:36:12] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 11:36:12] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 11:50:26] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.687390582017153, 'error_1pix': 0.6730824429283753, 'error_3pix': 0.3359116833618966, 'mIoU': 4.132271978215341, 'fwIoU': 5.261842275155766, 'IoU-0': 0.021455657409833802, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0783288226535533, 'IoU-7': 0.5567194792115904, 'IoU-8': 3.7169113267844036, 'IoU-9': 9.940538516869026, 'IoU-10': 12.771855498800665, 'IoU-11': 15.47827599193537, 'IoU-12': 13.082463778434647, 'IoU-13': 10.019442953969659, 'IoU-14': 7.774898804059776, 'IoU-15': 6.070131312836778, 'IoU-16': 5.083897936976445, 'IoU-17': 4.35702239075754, 'IoU-18': 3.5498045988956632, 'IoU-19': 3.023447705875955, 'IoU-20': 3.017003759889749, 'IoU-21': 3.306119803649912, 'IoU-22': 3.1224981259335762, 'IoU-23': 3.024527125420314, 'IoU-24': 2.8466661573395053, 'IoU-25': 2.8044059357812174, 'IoU-26': 2.927695262957034, 'IoU-27': 3.246121976992174, 'IoU-28': 3.2160247933493347, 'IoU-29': 3.4920962190374176, 'IoU-30': 3.5565721254697715, 'IoU-31': 3.716796678726065, 'IoU-32': 3.6732365485857157, 'IoU-33': 3.856665827502239, 'IoU-34': 4.170427529353062, 'IoU-35': 4.30560832779051, 'IoU-36': 4.512470445550589, 'IoU-37': 5.082423783675827, 'IoU-38': 5.432543869225341, 'IoU-39': 6.1251020578666635, 'IoU-40': 6.356582087436317, 'IoU-41': 6.2194877179695265, 'IoU-42': 6.224201829457555, 'IoU-43': 6.690325089732879, 'IoU-44': 7.330858296671466, 'IoU-45': 7.567112044601178, 'IoU-46': 7.7380418565125995, 'IoU-47': 8.221898275780747, 'IoU-48': 8.462029054422715, 'IoU-49': 8.595633534731084, 'IoU-50': 8.804042329247567, 'IoU-51': 9.169193650368932, 'IoU-52': 9.128248544998598, 'IoU-53': 9.027129356172475, 'IoU-54': 8.848371727218627, 'IoU-55': 8.234781070686497, 'IoU-56': 7.975758056007197, 'IoU-57': 7.996773536247923, 'IoU-58': 7.731682827162974, 'IoU-59': 7.906090628926092, 'IoU-60': 7.895212233650568, 'IoU-61': 7.913635748804264, 'IoU-62': 7.727851126767561, 'IoU-63': 7.82401848452887, 'IoU-64': 7.707091980644313, 'IoU-65': 7.5374316015332425, 'IoU-66': 7.481631898479411, 'IoU-67': 7.214868489160797, 'IoU-68': 7.124356248908299, 'IoU-69': 7.135428678721804, 'IoU-70': 7.1137901231795615, 'IoU-71': 6.831550323213792, 'IoU-72': 6.59903801239967, 'IoU-73': 6.357001371702233, 'IoU-74': 6.440671665302229, 'IoU-75': 6.44445286481853, 'IoU-76': 6.494016906608409, 'IoU-77': 6.3289400374289375, 'IoU-78': 6.221203404220152, 'IoU-79': 6.075375647420286, 'IoU-80': 6.41270641761405, 'IoU-81': 6.177248726286531, 'IoU-82': 6.319058902781652, 'IoU-83': 6.354368472660547, 'IoU-84': 6.344100733255884, 'IoU-85': 6.320123793096928, 'IoU-86': 6.195600864667865, 'IoU-87': 6.014802408987437, 'IoU-88': 5.948960755397019, 'IoU-89': 5.707996200238584, 'IoU-90': 6.098999265155467, 'IoU-91': 5.8842507562214585, 'IoU-92': 6.060055443134997, 'IoU-93': 5.973266531852354, 'IoU-94': 6.162762790242195, 'IoU-95': 6.176054962708901, 'IoU-96': 6.050427816425316, 'IoU-97': 5.823931056533254, 'IoU-98': 5.842157545641033, 'IoU-99': 5.445770349586855, 'IoU-100': 5.405287039010475, 'IoU-101': 5.2474081658485305, 'IoU-102': 5.3271471816077405, 'IoU-103': 5.252895533723645, 'IoU-104': 5.0257545570847695, 'IoU-105': 4.922676269212576, 'IoU-106': 4.8191399437070075, 'IoU-107': 4.967739730459852, 'IoU-108': 4.934462742076706, 'IoU-109': 4.920524667759823, 'IoU-110': 5.069709898426375, 'IoU-111': 4.623811344388236, 'IoU-112': 4.446032357702414, 'IoU-113': 4.407039045057386, 'IoU-114': 4.49136230365623, 'IoU-115': 4.285745172332708, 'IoU-116': 4.2818118603382995, 'IoU-117': 4.124084643794645, 'IoU-118': 4.224920675095584, 'IoU-119': 3.87307080760913, 'IoU-120': 3.3990397279953513, 'IoU-121': 3.2961468968787115, 'IoU-122': 3.3499903326263554, 'IoU-123': 3.1383254755190557, 'IoU-124': 3.125434684663466, 'IoU-125': 3.090794303644204, 'IoU-126': 3.014157697669942, 'IoU-127': 2.817010098453361, 'IoU-128': 2.657380790963348, 'IoU-129': 2.7285713288417295, 'IoU-130': 2.3455438735892145, 'IoU-131': 2.370608188674813, 'IoU-132': 2.231424079171644, 'IoU-133': 2.262302134793122, 'IoU-134': 2.3515366367066215, 'IoU-135': 2.2823639596816583, 'IoU-136': 2.277741896483704, 'IoU-137': 2.032835589510427, 'IoU-138': 2.119442190191687, 'IoU-139': 2.0573777764128183, 'IoU-140': 2.1854586429432574, 'IoU-141': 1.9720541191288263, 'IoU-142': 1.9335113058160496, 'IoU-143': 1.9825337003672672, 'IoU-144': 1.9483079055359571, 'IoU-145': 1.6357223605221696, 'IoU-146': 1.6657994628799224, 'IoU-147': 1.5326653747131729, 'IoU-148': 1.5514159798882379, 'IoU-149': 1.3883172435337092, 'IoU-150': 1.284540150751629, 'IoU-151': 1.5048236237843327, 'IoU-152': 1.2373497538461362, 'IoU-153': 0.9574868213196619, 'IoU-154': 1.0148844855377275, 'IoU-155': 0.9475053408565004, 'IoU-156': 1.0399213506909546, 'IoU-157': 1.0383976021963075, 'IoU-158': 1.1364687066585035, 'IoU-159': 1.1401354941859934, 'IoU-160': 1.1156622589493645, 'IoU-161': 1.030942207712306, 'IoU-162': 1.1687132617466272, 'IoU-163': 1.130325675233001, 'IoU-164': 1.2817570641164666, 'IoU-165': 1.1344146996641933, 'IoU-166': 1.0694568115532121, 'IoU-167': 0.8601491279810136, 'IoU-168': 0.8305372321922401, 'IoU-169': 1.0942826412561832, 'IoU-170': 0.9796242926836687, 'IoU-171': 1.045549600423748, 'IoU-172': 1.4510909382493025, 'IoU-173': 1.4078168383419967, 'IoU-174': 1.4721964669078393, 'IoU-175': 1.3855575864232343, 'IoU-176': 1.537956651554466, 'IoU-177': 1.5595707774050747, 'IoU-178': 1.3857587837054095, 'IoU-179': 2.112134530861838, 'IoU-180': 3.055742280234507, 'IoU-181': 0.4474828204891817, 'IoU-182': 0.3029950061115051, 'IoU-183': 0.3546295400185264, 'IoU-184': 0.26379259929033155, 'IoU-185': 0.2978417539148379, 'IoU-186': 0.03525768426631454, 'IoU-187': 0.052648353853599804, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 8.32911458542249, 'pACC': 9.995725017167857, 'ACC-0': 0.021456577474277018, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 29.512604404341218, 'ACC-7': 10.33651654870903, 'ACC-8': 24.324175769265363, 'ACC-9': 31.0045206409451, 'ACC-10': 34.46589346297088, 'ACC-11': 31.43857567879892, 'ACC-12': 24.729338272731884, 'ACC-13': 18.77360456450559, 'ACC-14': 14.494846371714232, 'ACC-15': 11.476039877936977, 'ACC-16': 9.609421991452653, 'ACC-17': 9.017157224684713, 'ACC-18': 7.164247708950833, 'ACC-19': 6.1188626075154655, 'ACC-20': 6.1132325221404615, 'ACC-21': 6.441740120291422, 'ACC-22': 5.895183392181664, 'ACC-23': 6.035355625809914, 'ACC-24': 5.714922779416546, 'ACC-25': 5.628253724940676, 'ACC-26': 5.812544426561896, 'ACC-27': 6.191563706122822, 'ACC-28': 6.348055730928436, 'ACC-29': 6.785191852966321, 'ACC-30': 6.985474406654553, 'ACC-31': 6.933455531638587, 'ACC-32': 6.79478647387539, 'ACC-33': 7.422168048841053, 'ACC-34': 8.090336619402922, 'ACC-35': 8.009971251723732, 'ACC-36': 8.230253932396515, 'ACC-37': 9.301850891941186, 'ACC-38': 9.815411194008192, 'ACC-39': 11.043691069518871, 'ACC-40': 11.347944569931787, 'ACC-41': 11.409466148918273, 'ACC-42': 11.400417123006532, 'ACC-43': 12.18729369642023, 'ACC-44': 12.81363235613825, 'ACC-45': 13.203363090157794, 'ACC-46': 13.883531103845465, 'ACC-47': 14.866430539164519, 'ACC-48': 15.380126381417483, 'ACC-49': 15.440944015664279, 'ACC-50': 15.646233258400338, 'ACC-51': 16.567399146733724, 'ACC-52': 16.663053680542344, 'ACC-53': 16.633110249685537, 'ACC-54': 16.05799660674242, 'ACC-55': 14.888227636976726, 'ACC-56': 14.53816525377449, 'ACC-57': 14.124781284893507, 'ACC-58': 13.745865850323625, 'ACC-59': 14.242365266139645, 'ACC-60': 14.344849666900005, 'ACC-61': 14.420922101371852, 'ACC-62': 14.14578489095514, 'ACC-63': 14.352163378178368, 'ACC-64': 14.150093756178023, 'ACC-65': 13.938317417176865, 'ACC-66': 13.910057540165589, 'ACC-67': 13.629549893000952, 'ACC-68': 13.494072130307202, 'ACC-69': 13.222858887217582, 'ACC-70': 13.11783343503518, 'ACC-71': 12.78405404115074, 'ACC-72': 12.35982772013152, 'ACC-73': 11.887231259517668, 'ACC-74': 12.002849148398084, 'ACC-75': 12.053554560851946, 'ACC-76': 11.981918265970053, 'ACC-77': 11.884305943293718, 'ACC-78': 11.756248595481628, 'ACC-79': 11.446544621248092, 'ACC-80': 11.93509266765385, 'ACC-81': 11.446643110323684, 'ACC-82': 11.719212176267762, 'ACC-83': 11.755511554211154, 'ACC-84': 11.759073055693579, 'ACC-85': 11.757935223927717, 'ACC-86': 11.588954498048427, 'ACC-87': 11.250219000106686, 'ACC-88': 11.077822937527634, 'ACC-89': 10.61925188737399, 'ACC-90': 11.3308207286241, 'ACC-91': 11.116111170228834, 'ACC-92': 11.557521124725715, 'ACC-93': 11.39073567699989, 'ACC-94': 11.67380994085892, 'ACC-95': 11.69223311056477, 'ACC-96': 11.513323604561565, 'ACC-97': 10.955533880550176, 'ACC-98': 11.015509643181261, 'ACC-99': 10.404815000227552, 'ACC-100': 10.308868285776148, 'ACC-101': 10.00630189607116, 'ACC-102': 10.247847757136384, 'ACC-103': 10.139085671106074, 'ACC-104': 9.70782813998672, 'ACC-105': 9.53342198837405, 'ACC-106': 9.301758446292773, 'ACC-107': 9.645319591486844, 'ACC-108': 9.572336266560027, 'ACC-109': 9.4871173366332, 'ACC-110': 9.902778208516338, 'ACC-111': 9.028227627417005, 'ACC-112': 8.719359322646925, 'ACC-113': 8.626090394128386, 'ACC-114': 8.8735519754577, 'ACC-115': 8.419181212695262, 'ACC-116': 8.523662494831715, 'ACC-117': 8.187277138565667, 'ACC-118': 8.466484191733876, 'ACC-119': 7.60678470897095, 'ACC-120': 6.597291769890047, 'ACC-121': 6.3247770853100915, 'ACC-122': 6.44093143498731, 'ACC-123': 6.021682794881865, 'ACC-124': 6.0090000484790105, 'ACC-125': 5.865583017806895, 'ACC-126': 5.731040355558794, 'ACC-127': 5.330159145492435, 'ACC-128': 5.058050399382357, 'ACC-129': 5.1506721746731685, 'ACC-130': 4.386252299151539, 'ACC-131': 4.426226130830265, 'ACC-132': 4.117649030035555, 'ACC-133': 4.150455544441949, 'ACC-134': 4.305661352865144, 'ACC-135': 4.199090701784391, 'ACC-136': 4.169263068393589, 'ACC-137': 3.783037466312832, 'ACC-138': 4.033381348833667, 'ACC-139': 3.9543251789501648, 'ACC-140': 4.134841399599462, 'ACC-141': 3.6999759315581033, 'ACC-142': 3.700239550556695, 'ACC-143': 3.8189230742964257, 'ACC-144': 3.724909747292419, 'ACC-145': 2.9780630157203873, 'ACC-146': 2.972470357085742, 'ACC-147': 2.744982975590144, 'ACC-148': 2.8167835969929214, 'ACC-149': 2.5689885799066796, 'ACC-150': 2.35801415246261, 'ACC-151': 2.793080552455922, 'ACC-152': 2.2883791894261245, 'ACC-153': 1.8948450869381996, 'ACC-154': 2.121016782380907, 'ACC-155': 1.99858010220306, 'ACC-156': 2.205717905459999, 'ACC-157': 2.2444888143039714, 'ACC-158': 2.567352244228009, 'ACC-159': 2.6456886701239344, 'ACC-160': 2.5135162647604394, 'ACC-161': 2.3882474857966116, 'ACC-162': 3.1195979779887595, 'ACC-163': 2.922189593788742, 'ACC-164': 3.480160705735368, 'ACC-165': 3.2501977276408947, 'ACC-166': 2.86927835743845, 'ACC-167': 2.246958745246818, 'ACC-168': 2.262641535972994, 'ACC-169': 3.4562628423230324, 'ACC-170': 3.200732569530219, 'ACC-171': 3.488002586290822, 'ACC-172': 5.513390376708523, 'ACC-173': 5.243967142421722, 'ACC-174': 5.507930383368656, 'ACC-175': 4.524117224000192, 'ACC-176': 5.55092001393081, 'ACC-177': 5.259758354879131, 'ACC-178': 4.730631568577836, 'ACC-179': 5.606221380008562, 'ACC-180': 7.601002404415998, 'ACC-181': 0.8967717637695681, 'ACC-182': 0.48686414476567735, 'ACC-183': 0.48310657302749144, 'ACC-184': 0.29998797218036066, 'ACC-185': 0.32634452558790517, 'ACC-186': 0.03706212982132276, 'ACC-187': 0.053878399110885614, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 11:50:26] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 11:50:26] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 11:50:26] d2.evaluation.testing INFO: copypaste: 4.6874,0.6731,0.3359,4.1323,5.2618,8.3291,9.9957
[01/29 11:50:26] d2.utils.events INFO:  eta: 1 day, 7:54:20  iter: 15999  total_loss: 46.76  loss_mask: 4.818  loss_mask_0: 4.756  loss_mask_1: 4.592  loss_mask_2: 4.589  loss_mask_3: 4.61  loss_mask_4: 4.597  loss_mask_5: 4.606  loss_mask_6: 4.608  loss_mask_7: 4.822  loss_mask_8: 4.815  time: 2.6089  data_time: 0.0518  lr: 7.5645e-05  max_mem: 27639M
[01/29 11:51:19] d2.utils.events INFO:  eta: 1 day, 7:53:23  iter: 16019  total_loss: 44.27  loss_mask: 4.636  loss_mask_0: 4.452  loss_mask_1: 4.309  loss_mask_2: 4.323  loss_mask_3: 4.328  loss_mask_4: 4.317  loss_mask_5: 4.321  loss_mask_6: 4.328  loss_mask_7: 4.632  loss_mask_8: 4.629  time: 2.6090  data_time: 0.0670  lr: 7.5614e-05  max_mem: 27639M
[01/29 11:52:12] d2.utils.events INFO:  eta: 1 day, 7:52:33  iter: 16039  total_loss: 49.14  loss_mask: 5.035  loss_mask_0: 4.885  loss_mask_1: 4.83  loss_mask_2: 4.838  loss_mask_3: 4.858  loss_mask_4: 4.849  loss_mask_5: 4.846  loss_mask_6: 4.836  loss_mask_7: 5.059  loss_mask_8: 5.059  time: 2.6090  data_time: 0.0622  lr: 7.5583e-05  max_mem: 27639M
[01/29 11:53:04] d2.utils.events INFO:  eta: 1 day, 7:51:40  iter: 16059  total_loss: 44.17  loss_mask: 4.674  loss_mask_0: 4.274  loss_mask_1: 4.279  loss_mask_2: 4.282  loss_mask_3: 4.284  loss_mask_4: 4.273  loss_mask_5: 4.284  loss_mask_6: 4.268  loss_mask_7: 4.681  loss_mask_8: 4.676  time: 2.6090  data_time: 0.0583  lr: 7.5552e-05  max_mem: 27639M
[01/29 11:53:57] d2.utils.events INFO:  eta: 1 day, 7:50:56  iter: 16079  total_loss: 48.14  loss_mask: 4.989  loss_mask_0: 4.748  loss_mask_1: 4.733  loss_mask_2: 4.7  loss_mask_3: 4.715  loss_mask_4: 4.702  loss_mask_5: 4.71  loss_mask_6: 4.731  loss_mask_7: 5  loss_mask_8: 4.988  time: 2.6090  data_time: 0.0597  lr: 7.5521e-05  max_mem: 27639M
[01/29 11:54:49] d2.utils.events INFO:  eta: 1 day, 7:50:06  iter: 16099  total_loss: 51.6  loss_mask: 5.333  loss_mask_0: 5.157  loss_mask_1: 5.08  loss_mask_2: 5.071  loss_mask_3: 5.098  loss_mask_4: 5.093  loss_mask_5: 5.085  loss_mask_6: 5.079  loss_mask_7: 5.327  loss_mask_8: 5.334  time: 2.6090  data_time: 0.0683  lr: 7.549e-05  max_mem: 27639M
[01/29 11:55:42] d2.utils.events INFO:  eta: 1 day, 7:49:12  iter: 16119  total_loss: 47.48  loss_mask: 4.916  loss_mask_0: 4.781  loss_mask_1: 4.686  loss_mask_2: 4.667  loss_mask_3: 4.645  loss_mask_4: 4.648  loss_mask_5: 4.672  loss_mask_6: 4.674  loss_mask_7: 4.897  loss_mask_8: 4.905  time: 2.6091  data_time: 0.0651  lr: 7.5459e-05  max_mem: 27639M
[01/29 11:56:34] d2.utils.events INFO:  eta: 1 day, 7:48:21  iter: 16139  total_loss: 46.14  loss_mask: 4.832  loss_mask_0: 4.546  loss_mask_1: 4.517  loss_mask_2: 4.518  loss_mask_3: 4.533  loss_mask_4: 4.524  loss_mask_5: 4.52  loss_mask_6: 4.524  loss_mask_7: 4.82  loss_mask_8: 4.828  time: 2.6091  data_time: 0.0567  lr: 7.5428e-05  max_mem: 27639M
[01/29 11:57:26] d2.utils.events INFO:  eta: 1 day, 7:47:31  iter: 16159  total_loss: 45.19  loss_mask: 4.725  loss_mask_0: 4.484  loss_mask_1: 4.434  loss_mask_2: 4.422  loss_mask_3: 4.422  loss_mask_4: 4.428  loss_mask_5: 4.429  loss_mask_6: 4.416  loss_mask_7: 4.758  loss_mask_8: 4.751  time: 2.6091  data_time: 0.0536  lr: 7.5397e-05  max_mem: 27639M
[01/29 11:58:19] d2.utils.events INFO:  eta: 1 day, 7:46:38  iter: 16179  total_loss: 51.31  loss_mask: 5.312  loss_mask_0: 5.119  loss_mask_1: 5.005  loss_mask_2: 5.006  loss_mask_3: 5.007  loss_mask_4: 4.991  loss_mask_5: 4.993  loss_mask_6: 4.998  loss_mask_7: 5.31  loss_mask_8: 5.329  time: 2.6091  data_time: 0.0616  lr: 7.5366e-05  max_mem: 27639M
[01/29 11:59:11] d2.utils.events INFO:  eta: 1 day, 7:45:56  iter: 16199  total_loss: 49.85  loss_mask: 5.116  loss_mask_0: 5.009  loss_mask_1: 4.904  loss_mask_2: 4.905  loss_mask_3: 4.894  loss_mask_4: 4.89  loss_mask_5: 4.91  loss_mask_6: 4.905  loss_mask_7: 5.135  loss_mask_8: 5.121  time: 2.6091  data_time: 0.0499  lr: 7.5335e-05  max_mem: 27639M
[01/29 12:00:04] d2.utils.events INFO:  eta: 1 day, 7:45:02  iter: 16219  total_loss: 49.1  loss_mask: 5.076  loss_mask_0: 4.973  loss_mask_1: 4.859  loss_mask_2: 4.842  loss_mask_3: 4.834  loss_mask_4: 4.853  loss_mask_5: 4.827  loss_mask_6: 4.843  loss_mask_7: 5.098  loss_mask_8: 5.086  time: 2.6091  data_time: 0.0605  lr: 7.5305e-05  max_mem: 27639M
[01/29 12:00:56] d2.utils.events INFO:  eta: 1 day, 7:44:12  iter: 16239  total_loss: 44.53  loss_mask: 4.631  loss_mask_0: 4.472  loss_mask_1: 4.401  loss_mask_2: 4.367  loss_mask_3: 4.372  loss_mask_4: 4.367  loss_mask_5: 4.356  loss_mask_6: 4.376  loss_mask_7: 4.643  loss_mask_8: 4.636  time: 2.6091  data_time: 0.0588  lr: 7.5274e-05  max_mem: 27639M
[01/29 12:01:48] d2.utils.events INFO:  eta: 1 day, 7:43:10  iter: 16259  total_loss: 47.47  loss_mask: 4.879  loss_mask_0: 4.763  loss_mask_1: 4.679  loss_mask_2: 4.692  loss_mask_3: 4.67  loss_mask_4: 4.671  loss_mask_5: 4.689  loss_mask_6: 4.693  loss_mask_7: 4.882  loss_mask_8: 4.894  time: 2.6091  data_time: 0.0541  lr: 7.5243e-05  max_mem: 27639M
[01/29 12:02:40] d2.utils.events INFO:  eta: 1 day, 7:42:21  iter: 16279  total_loss: 49.55  loss_mask: 5.115  loss_mask_0: 4.94  loss_mask_1: 4.83  loss_mask_2: 4.892  loss_mask_3: 4.88  loss_mask_4: 4.878  loss_mask_5: 4.883  loss_mask_6: 4.896  loss_mask_7: 5.119  loss_mask_8: 5.118  time: 2.6091  data_time: 0.0538  lr: 7.5212e-05  max_mem: 27639M
[01/29 12:03:32] d2.utils.events INFO:  eta: 1 day, 7:41:25  iter: 16299  total_loss: 42.91  loss_mask: 4.453  loss_mask_0: 4.375  loss_mask_1: 4.24  loss_mask_2: 4.209  loss_mask_3: 4.21  loss_mask_4: 4.202  loss_mask_5: 4.221  loss_mask_6: 4.217  loss_mask_7: 4.447  loss_mask_8: 4.465  time: 2.6091  data_time: 0.0592  lr: 7.5181e-05  max_mem: 27639M
[01/29 12:04:25] d2.utils.events INFO:  eta: 1 day, 7:40:39  iter: 16319  total_loss: 49.25  loss_mask: 5.084  loss_mask_0: 4.896  loss_mask_1: 4.841  loss_mask_2: 4.856  loss_mask_3: 4.844  loss_mask_4: 4.849  loss_mask_5: 4.845  loss_mask_6: 4.831  loss_mask_7: 5.098  loss_mask_8: 5.091  time: 2.6091  data_time: 0.0494  lr: 7.515e-05  max_mem: 27639M
[01/29 12:05:17] d2.utils.events INFO:  eta: 1 day, 7:39:48  iter: 16339  total_loss: 45.8  loss_mask: 4.757  loss_mask_0: 4.556  loss_mask_1: 4.505  loss_mask_2: 4.504  loss_mask_3: 4.491  loss_mask_4: 4.496  loss_mask_5: 4.506  loss_mask_6: 4.508  loss_mask_7: 4.762  loss_mask_8: 4.759  time: 2.6091  data_time: 0.0629  lr: 7.5119e-05  max_mem: 27639M
[01/29 12:06:10] d2.utils.events INFO:  eta: 1 day, 7:38:56  iter: 16359  total_loss: 51.42  loss_mask: 5.325  loss_mask_0: 5.136  loss_mask_1: 5.048  loss_mask_2: 5.026  loss_mask_3: 5.012  loss_mask_4: 5.022  loss_mask_5: 5.037  loss_mask_6: 5.013  loss_mask_7: 5.307  loss_mask_8: 5.332  time: 2.6091  data_time: 0.0585  lr: 7.5088e-05  max_mem: 27639M
[01/29 12:07:02] d2.utils.events INFO:  eta: 1 day, 7:38:18  iter: 16379  total_loss: 51.23  loss_mask: 5.235  loss_mask_0: 5.085  loss_mask_1: 5.039  loss_mask_2: 5.036  loss_mask_3: 5.049  loss_mask_4: 5.032  loss_mask_5: 5.035  loss_mask_6: 5.067  loss_mask_7: 5.249  loss_mask_8: 5.249  time: 2.6091  data_time: 0.0576  lr: 7.5057e-05  max_mem: 27639M
[01/29 12:07:55] d2.utils.events INFO:  eta: 1 day, 7:37:47  iter: 16399  total_loss: 50.53  loss_mask: 5.336  loss_mask_0: 4.978  loss_mask_1: 4.911  loss_mask_2: 4.897  loss_mask_3: 4.906  loss_mask_4: 4.917  loss_mask_5: 4.931  loss_mask_6: 4.882  loss_mask_7: 5.323  loss_mask_8: 5.339  time: 2.6092  data_time: 0.0570  lr: 7.5026e-05  max_mem: 27639M
[01/29 12:08:47] d2.utils.events INFO:  eta: 1 day, 7:37:04  iter: 16419  total_loss: 45.65  loss_mask: 4.786  loss_mask_0: 4.605  loss_mask_1: 4.448  loss_mask_2: 4.453  loss_mask_3: 4.44  loss_mask_4: 4.43  loss_mask_5: 4.422  loss_mask_6: 4.457  loss_mask_7: 4.808  loss_mask_8: 4.779  time: 2.6092  data_time: 0.0595  lr: 7.4995e-05  max_mem: 27639M
[01/29 12:09:40] d2.utils.events INFO:  eta: 1 day, 7:36:12  iter: 16439  total_loss: 49.64  loss_mask: 5.051  loss_mask_0: 4.995  loss_mask_1: 4.893  loss_mask_2: 4.92  loss_mask_3: 4.902  loss_mask_4: 4.903  loss_mask_5: 4.912  loss_mask_6: 4.878  loss_mask_7: 5.051  loss_mask_8: 5.044  time: 2.6092  data_time: 0.0544  lr: 7.4964e-05  max_mem: 27639M
[01/29 12:10:32] d2.utils.events INFO:  eta: 1 day, 7:35:28  iter: 16459  total_loss: 46.2  loss_mask: 4.84  loss_mask_0: 4.668  loss_mask_1: 4.51  loss_mask_2: 4.499  loss_mask_3: 4.495  loss_mask_4: 4.488  loss_mask_5: 4.479  loss_mask_6: 4.482  loss_mask_7: 4.84  loss_mask_8: 4.831  time: 2.6092  data_time: 0.0589  lr: 7.4933e-05  max_mem: 27639M
[01/29 12:11:24] d2.utils.events INFO:  eta: 1 day, 7:34:45  iter: 16479  total_loss: 47.6  loss_mask: 4.936  loss_mask_0: 4.78  loss_mask_1: 4.684  loss_mask_2: 4.669  loss_mask_3: 4.673  loss_mask_4: 4.658  loss_mask_5: 4.658  loss_mask_6: 4.667  loss_mask_7: 4.934  loss_mask_8: 4.954  time: 2.6092  data_time: 0.0588  lr: 7.4902e-05  max_mem: 27639M
[01/29 12:12:17] d2.utils.events INFO:  eta: 1 day, 7:33:57  iter: 16499  total_loss: 46.08  loss_mask: 4.812  loss_mask_0: 4.635  loss_mask_1: 4.531  loss_mask_2: 4.488  loss_mask_3: 4.482  loss_mask_4: 4.487  loss_mask_5: 4.487  loss_mask_6: 4.503  loss_mask_7: 4.809  loss_mask_8: 4.806  time: 2.6092  data_time: 0.0562  lr: 7.4871e-05  max_mem: 27639M
[01/29 12:13:09] d2.utils.events INFO:  eta: 1 day, 7:32:56  iter: 16519  total_loss: 48.81  loss_mask: 5.109  loss_mask_0: 4.848  loss_mask_1: 4.774  loss_mask_2: 4.775  loss_mask_3: 4.77  loss_mask_4: 4.776  loss_mask_5: 4.755  loss_mask_6: 4.764  loss_mask_7: 5.1  loss_mask_8: 5.134  time: 2.6092  data_time: 0.0597  lr: 7.484e-05  max_mem: 27639M
[01/29 12:14:02] d2.utils.events INFO:  eta: 1 day, 7:31:59  iter: 16539  total_loss: 50.61  loss_mask: 5.263  loss_mask_0: 5.13  loss_mask_1: 4.983  loss_mask_2: 4.967  loss_mask_3: 5.008  loss_mask_4: 5.002  loss_mask_5: 5.009  loss_mask_6: 5.013  loss_mask_7: 5.267  loss_mask_8: 5.269  time: 2.6093  data_time: 0.0603  lr: 7.4809e-05  max_mem: 27639M
[01/29 12:14:54] d2.utils.events INFO:  eta: 1 day, 7:30:45  iter: 16559  total_loss: 45.91  loss_mask: 4.731  loss_mask_0: 4.55  loss_mask_1: 4.513  loss_mask_2: 4.53  loss_mask_3: 4.508  loss_mask_4: 4.489  loss_mask_5: 4.517  loss_mask_6: 4.515  loss_mask_7: 4.708  loss_mask_8: 4.716  time: 2.6093  data_time: 0.0551  lr: 7.4778e-05  max_mem: 27639M
[01/29 12:15:46] d2.utils.events INFO:  eta: 1 day, 7:29:36  iter: 16579  total_loss: 47.66  loss_mask: 4.904  loss_mask_0: 4.832  loss_mask_1: 4.715  loss_mask_2: 4.703  loss_mask_3: 4.705  loss_mask_4: 4.693  loss_mask_5: 4.709  loss_mask_6: 4.7  loss_mask_7: 4.919  loss_mask_8: 4.901  time: 2.6092  data_time: 0.0537  lr: 7.4747e-05  max_mem: 27639M
[01/29 12:16:39] d2.utils.events INFO:  eta: 1 day, 7:29:00  iter: 16599  total_loss: 48.57  loss_mask: 5.035  loss_mask_0: 4.935  loss_mask_1: 4.799  loss_mask_2: 4.76  loss_mask_3: 4.768  loss_mask_4: 4.778  loss_mask_5: 4.77  loss_mask_6: 4.757  loss_mask_7: 5.038  loss_mask_8: 5.041  time: 2.6093  data_time: 0.0569  lr: 7.4716e-05  max_mem: 27639M
[01/29 12:17:31] d2.utils.events INFO:  eta: 1 day, 7:28:33  iter: 16619  total_loss: 46  loss_mask: 4.808  loss_mask_0: 4.642  loss_mask_1: 4.51  loss_mask_2: 4.485  loss_mask_3: 4.48  loss_mask_4: 4.487  loss_mask_5: 4.474  loss_mask_6: 4.483  loss_mask_7: 4.808  loss_mask_8: 4.807  time: 2.6093  data_time: 0.0642  lr: 7.4685e-05  max_mem: 27639M
[01/29 12:18:23] d2.utils.events INFO:  eta: 1 day, 7:27:25  iter: 16639  total_loss: 46.21  loss_mask: 4.902  loss_mask_0: 4.605  loss_mask_1: 4.499  loss_mask_2: 4.498  loss_mask_3: 4.501  loss_mask_4: 4.506  loss_mask_5: 4.513  loss_mask_6: 4.478  loss_mask_7: 4.906  loss_mask_8: 4.91  time: 2.6093  data_time: 0.0618  lr: 7.4654e-05  max_mem: 27641M
[01/29 12:19:16] d2.utils.events INFO:  eta: 1 day, 7:26:51  iter: 16659  total_loss: 46.06  loss_mask: 4.815  loss_mask_0: 4.647  loss_mask_1: 4.519  loss_mask_2: 4.49  loss_mask_3: 4.459  loss_mask_4: 4.457  loss_mask_5: 4.472  loss_mask_6: 4.465  loss_mask_7: 4.821  loss_mask_8: 4.799  time: 2.6093  data_time: 0.0553  lr: 7.4623e-05  max_mem: 27641M
[01/29 12:20:08] d2.utils.events INFO:  eta: 1 day, 7:26:00  iter: 16679  total_loss: 49.01  loss_mask: 5.082  loss_mask_0: 4.88  loss_mask_1: 4.761  loss_mask_2: 4.758  loss_mask_3: 4.754  loss_mask_4: 4.752  loss_mask_5: 4.767  loss_mask_6: 4.767  loss_mask_7: 5.078  loss_mask_8: 5.08  time: 2.6093  data_time: 0.0584  lr: 7.4592e-05  max_mem: 27641M
[01/29 12:21:01] d2.utils.events INFO:  eta: 1 day, 7:25:14  iter: 16699  total_loss: 49.87  loss_mask: 5.305  loss_mask_0: 4.966  loss_mask_1: 4.833  loss_mask_2: 4.831  loss_mask_3: 4.839  loss_mask_4: 4.837  loss_mask_5: 4.827  loss_mask_6: 4.822  loss_mask_7: 5.304  loss_mask_8: 5.31  time: 2.6094  data_time: 0.0584  lr: 7.4561e-05  max_mem: 27641M
[01/29 12:21:54] d2.utils.events INFO:  eta: 1 day, 7:24:23  iter: 16719  total_loss: 44.06  loss_mask: 4.668  loss_mask_0: 4.43  loss_mask_1: 4.328  loss_mask_2: 4.321  loss_mask_3: 4.36  loss_mask_4: 4.321  loss_mask_5: 4.311  loss_mask_6: 4.399  loss_mask_7: 4.66  loss_mask_8: 4.67  time: 2.6094  data_time: 0.0628  lr: 7.453e-05  max_mem: 27641M
[01/29 12:22:46] d2.utils.events INFO:  eta: 1 day, 7:23:52  iter: 16739  total_loss: 46.88  loss_mask: 4.823  loss_mask_0: 4.62  loss_mask_1: 4.6  loss_mask_2: 4.618  loss_mask_3: 4.6  loss_mask_4: 4.614  loss_mask_5: 4.602  loss_mask_6: 4.579  loss_mask_7: 4.811  loss_mask_8: 4.827  time: 2.6094  data_time: 0.0548  lr: 7.4499e-05  max_mem: 27641M
[01/29 12:23:38] d2.utils.events INFO:  eta: 1 day, 7:22:46  iter: 16759  total_loss: 41.48  loss_mask: 4.385  loss_mask_0: 4.095  loss_mask_1: 4.086  loss_mask_2: 4.049  loss_mask_3: 4.064  loss_mask_4: 4.054  loss_mask_5: 4.045  loss_mask_6: 4.052  loss_mask_7: 4.402  loss_mask_8: 4.382  time: 2.6094  data_time: 0.0447  lr: 7.4468e-05  max_mem: 27641M
[01/29 12:24:31] d2.utils.events INFO:  eta: 1 day, 7:21:46  iter: 16779  total_loss: 49.07  loss_mask: 5.249  loss_mask_0: 4.934  loss_mask_1: 4.776  loss_mask_2: 4.783  loss_mask_3: 4.766  loss_mask_4: 4.769  loss_mask_5: 4.78  loss_mask_6: 4.774  loss_mask_7: 5.239  loss_mask_8: 5.239  time: 2.6094  data_time: 0.0525  lr: 7.4437e-05  max_mem: 27641M
[01/29 12:25:23] d2.utils.events INFO:  eta: 1 day, 7:21:21  iter: 16799  total_loss: 49.19  loss_mask: 5.135  loss_mask_0: 5.012  loss_mask_1: 4.823  loss_mask_2: 4.836  loss_mask_3: 4.805  loss_mask_4: 4.816  loss_mask_5: 4.806  loss_mask_6: 4.798  loss_mask_7: 5.13  loss_mask_8: 5.15  time: 2.6094  data_time: 0.0635  lr: 7.4406e-05  max_mem: 27641M
[01/29 12:26:16] d2.utils.events INFO:  eta: 1 day, 7:20:35  iter: 16819  total_loss: 47.4  loss_mask: 4.997  loss_mask_0: 4.721  loss_mask_1: 4.615  loss_mask_2: 4.601  loss_mask_3: 4.612  loss_mask_4: 4.6  loss_mask_5: 4.609  loss_mask_6: 4.598  loss_mask_7: 4.996  loss_mask_8: 5.009  time: 2.6094  data_time: 0.0524  lr: 7.4375e-05  max_mem: 27641M
[01/29 12:27:08] d2.utils.events INFO:  eta: 1 day, 7:19:42  iter: 16839  total_loss: 44.42  loss_mask: 4.727  loss_mask_0: 4.39  loss_mask_1: 4.333  loss_mask_2: 4.346  loss_mask_3: 4.349  loss_mask_4: 4.354  loss_mask_5: 4.341  loss_mask_6: 4.349  loss_mask_7: 4.728  loss_mask_8: 4.729  time: 2.6094  data_time: 0.0645  lr: 7.4344e-05  max_mem: 27641M
[01/29 12:28:00] d2.utils.events INFO:  eta: 1 day, 7:18:40  iter: 16859  total_loss: 42.58  loss_mask: 4.476  loss_mask_0: 4.224  loss_mask_1: 4.188  loss_mask_2: 4.165  loss_mask_3: 4.169  loss_mask_4: 4.183  loss_mask_5: 4.194  loss_mask_6: 4.207  loss_mask_7: 4.464  loss_mask_8: 4.475  time: 2.6094  data_time: 0.0560  lr: 7.4313e-05  max_mem: 27641M
[01/29 12:28:53] d2.utils.events INFO:  eta: 1 day, 7:18:04  iter: 16879  total_loss: 45.98  loss_mask: 4.807  loss_mask_0: 4.64  loss_mask_1: 4.465  loss_mask_2: 4.458  loss_mask_3: 4.461  loss_mask_4: 4.475  loss_mask_5: 4.481  loss_mask_6: 4.484  loss_mask_7: 4.81  loss_mask_8: 4.815  time: 2.6094  data_time: 0.0493  lr: 7.4282e-05  max_mem: 27641M
[01/29 12:29:45] d2.utils.events INFO:  eta: 1 day, 7:17:24  iter: 16899  total_loss: 50.64  loss_mask: 5.344  loss_mask_0: 5.105  loss_mask_1: 4.976  loss_mask_2: 4.97  loss_mask_3: 4.956  loss_mask_4: 4.963  loss_mask_5: 4.978  loss_mask_6: 4.986  loss_mask_7: 5.339  loss_mask_8: 5.335  time: 2.6095  data_time: 0.0581  lr: 7.4251e-05  max_mem: 27641M
[01/29 12:30:37] d2.utils.events INFO:  eta: 1 day, 7:16:25  iter: 16919  total_loss: 44.01  loss_mask: 4.627  loss_mask_0: 4.423  loss_mask_1: 4.291  loss_mask_2: 4.296  loss_mask_3: 4.271  loss_mask_4: 4.292  loss_mask_5: 4.308  loss_mask_6: 4.31  loss_mask_7: 4.64  loss_mask_8: 4.633  time: 2.6095  data_time: 0.0575  lr: 7.422e-05  max_mem: 27641M
[01/29 12:31:30] d2.utils.events INFO:  eta: 1 day, 7:15:32  iter: 16939  total_loss: 53.68  loss_mask: 5.607  loss_mask_0: 5.355  loss_mask_1: 5.236  loss_mask_2: 5.239  loss_mask_3: 5.246  loss_mask_4: 5.243  loss_mask_5: 5.248  loss_mask_6: 5.26  loss_mask_7: 5.59  loss_mask_8: 5.61  time: 2.6095  data_time: 0.0476  lr: 7.4189e-05  max_mem: 27641M
[01/29 12:32:22] d2.utils.events INFO:  eta: 1 day, 7:15:05  iter: 16959  total_loss: 47.62  loss_mask: 4.937  loss_mask_0: 4.708  loss_mask_1: 4.658  loss_mask_2: 4.65  loss_mask_3: 4.647  loss_mask_4: 4.645  loss_mask_5: 4.657  loss_mask_6: 4.638  loss_mask_7: 4.94  loss_mask_8: 4.937  time: 2.6095  data_time: 0.0609  lr: 7.4158e-05  max_mem: 27641M
[01/29 12:33:14] d2.utils.events INFO:  eta: 1 day, 7:13:55  iter: 16979  total_loss: 44.16  loss_mask: 4.672  loss_mask_0: 4.37  loss_mask_1: 4.295  loss_mask_2: 4.289  loss_mask_3: 4.287  loss_mask_4: 4.305  loss_mask_5: 4.3  loss_mask_6: 4.332  loss_mask_7: 4.682  loss_mask_8: 4.675  time: 2.6095  data_time: 0.0577  lr: 7.4127e-05  max_mem: 27641M
[01/29 12:34:07] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 12:34:07] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 12:34:07] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 12:48:23] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 4.239256754456116, 'error_1pix': 0.5169548689017286, 'error_3pix': 0.3000549556578309, 'mIoU': 5.8261742644975785, 'fwIoU': 10.601251297573635, 'IoU-0': 0.0, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.08726073904120062, 'IoU-7': 0.5376524562165719, 'IoU-8': 3.458879633045569, 'IoU-9': 9.722345410009272, 'IoU-10': 12.695193262516192, 'IoU-11': 20.089138441586883, 'IoU-12': 19.94402959282275, 'IoU-13': 18.81786111123329, 'IoU-14': 18.87002304957446, 'IoU-15': 17.637715911672448, 'IoU-16': 16.427968831401806, 'IoU-17': 13.475037574767656, 'IoU-18': 12.815453039677374, 'IoU-19': 12.096433963998965, 'IoU-20': 10.96005799672848, 'IoU-21': 9.932250125872283, 'IoU-22': 10.246598408503745, 'IoU-23': 8.71624922733845, 'IoU-24': 8.737565411081565, 'IoU-25': 9.790618173960503, 'IoU-26': 10.690449932295767, 'IoU-27': 12.409022688498016, 'IoU-28': 12.978804072235942, 'IoU-29': 13.94689834155966, 'IoU-30': 14.676840697663657, 'IoU-31': 16.38143879111815, 'IoU-32': 16.634503098372313, 'IoU-33': 15.940513945784417, 'IoU-34': 15.506355463043686, 'IoU-35': 16.668032924451694, 'IoU-36': 16.645579136593298, 'IoU-37': 16.12758187998348, 'IoU-38': 15.628187411681965, 'IoU-39': 15.232324357925247, 'IoU-40': 15.143305610827726, 'IoU-41': 14.181955586255906, 'IoU-42': 13.957800341657078, 'IoU-43': 13.804122660262832, 'IoU-44': 13.865814556229724, 'IoU-45': 13.226713165841566, 'IoU-46': 12.568990972240698, 'IoU-47': 12.486193212893275, 'IoU-48': 12.551510555436346, 'IoU-49': 12.108906122984806, 'IoU-50': 11.810825399006381, 'IoU-51': 11.369146866573203, 'IoU-52': 11.376884811375229, 'IoU-53': 11.10208347596232, 'IoU-54': 11.108739079303952, 'IoU-55': 10.607332985813109, 'IoU-56': 9.91674404242931, 'IoU-57': 10.204087242273255, 'IoU-58': 9.470187574703315, 'IoU-59': 9.356263940080426, 'IoU-60': 9.304944624540944, 'IoU-61': 9.170490854985317, 'IoU-62': 8.94358405298827, 'IoU-63': 8.808472086025185, 'IoU-64': 8.605653322077584, 'IoU-65': 8.109612578886352, 'IoU-66': 7.894501435220387, 'IoU-67': 7.608471601518474, 'IoU-68': 7.445683404073232, 'IoU-69': 7.406574125090273, 'IoU-70': 7.4303726088267945, 'IoU-71': 6.895719139216888, 'IoU-72': 6.626828497087722, 'IoU-73': 6.571999538074795, 'IoU-74': 6.599896463048939, 'IoU-75': 6.7069740534397555, 'IoU-76': 6.703338857594497, 'IoU-77': 6.451676719890212, 'IoU-78': 6.365559302413011, 'IoU-79': 6.202045003178776, 'IoU-80': 6.520285926057265, 'IoU-81': 6.6086268302334785, 'IoU-82': 6.781108835718226, 'IoU-83': 6.675259464634687, 'IoU-84': 6.667940594829435, 'IoU-85': 6.629043327957332, 'IoU-86': 6.588636027514233, 'IoU-87': 6.42711804702028, 'IoU-88': 6.407981762024876, 'IoU-89': 6.491386135661243, 'IoU-90': 6.420361081165623, 'IoU-91': 6.447002614584914, 'IoU-92': 6.204924517494581, 'IoU-93': 5.977323922868477, 'IoU-94': 5.9944755670384815, 'IoU-95': 5.95854760538942, 'IoU-96': 5.641181139534483, 'IoU-97': 5.536423929276717, 'IoU-98': 5.190040680910659, 'IoU-99': 4.938611094595398, 'IoU-100': 4.641464693751171, 'IoU-101': 4.5756545967960776, 'IoU-102': 4.499777684247519, 'IoU-103': 4.362473046544375, 'IoU-104': 4.295402321297218, 'IoU-105': 4.029541531098775, 'IoU-106': 4.112053168734458, 'IoU-107': 4.070325249081283, 'IoU-108': 3.9335050612851634, 'IoU-109': 3.977867327688392, 'IoU-110': 3.8911805901552667, 'IoU-111': 3.920883315256496, 'IoU-112': 4.145280839966966, 'IoU-113': 3.9225635766833404, 'IoU-114': 3.8098017654117204, 'IoU-115': 3.5129491339487484, 'IoU-116': 3.46656485088101, 'IoU-117': 3.428584236037751, 'IoU-118': 3.162577010903077, 'IoU-119': 3.0072621568119016, 'IoU-120': 2.84765880049012, 'IoU-121': 2.7085919433936145, 'IoU-122': 2.5124834346025513, 'IoU-123': 2.4477819893034387, 'IoU-124': 2.4849280496927824, 'IoU-125': 2.5735973217127817, 'IoU-126': 2.2427032460431833, 'IoU-127': 2.167149409909137, 'IoU-128': 2.0674654479174976, 'IoU-129': 2.0224466526789806, 'IoU-130': 1.9578456688161363, 'IoU-131': 2.0428603964552945, 'IoU-132': 2.094729488391981, 'IoU-133': 2.2653433221478845, 'IoU-134': 2.086789359501139, 'IoU-135': 1.9726418743846605, 'IoU-136': 2.0727203283003726, 'IoU-137': 1.9684347987590147, 'IoU-138': 1.8050915001482735, 'IoU-139': 1.7110712645268664, 'IoU-140': 1.6184701841187858, 'IoU-141': 1.5947877687611887, 'IoU-142': 1.4773423401049686, 'IoU-143': 1.5250665204641594, 'IoU-144': 1.4650656210169517, 'IoU-145': 1.0775443145381434, 'IoU-146': 1.112095844430414, 'IoU-147': 1.2628217371412187, 'IoU-148': 1.350269721700364, 'IoU-149': 1.2306420034450203, 'IoU-150': 1.4182307748013456, 'IoU-151': 1.250622346963029, 'IoU-152': 1.4145661768111883, 'IoU-153': 1.253296494892353, 'IoU-154': 1.2931825716250538, 'IoU-155': 1.0989889301842306, 'IoU-156': 1.1609668233189219, 'IoU-157': 1.0177761814912214, 'IoU-158': 1.0289010506614273, 'IoU-159': 1.1127271968832106, 'IoU-160': 1.1779390967745242, 'IoU-161': 1.26536260584454, 'IoU-162': 1.0193376485651917, 'IoU-163': 1.0044313898496282, 'IoU-164': 1.0849299522941664, 'IoU-165': 1.1677936990701547, 'IoU-166': 0.9428437096242767, 'IoU-167': 0.897348633709886, 'IoU-168': 0.9541878785523548, 'IoU-169': 0.8637405107879091, 'IoU-170': 0.5910819715351147, 'IoU-171': 0.8727975269095412, 'IoU-172': 0.7897563875853868, 'IoU-173': 0.6483828429746845, 'IoU-174': 0.7669633346676673, 'IoU-175': 1.2331445657211548, 'IoU-176': 1.0230707024311825, 'IoU-177': 0.3445348479043176, 'IoU-178': 0.3113716758485475, 'IoU-179': 0.07061803390025922, 'IoU-180': 0.043610810543942, 'IoU-181': 0.048286521591468304, 'IoU-182': 0.04639514351333572, 'IoU-183': 0.0011418236293549153, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 10.953123963726277, 'pACC': 18.778703571277227, 'ACC-0': 0.0, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 33.86779388000421, 'ACC-7': 8.117746152247394, 'ACC-8': 17.105001626752923, 'ACC-9': 21.786981320079047, 'ACC-10': 22.030837960128725, 'ACC-11': 29.771247922749485, 'ACC-12': 30.56412655410896, 'ACC-13': 29.37321895834895, 'ACC-14': 30.569150338047958, 'ACC-15': 30.11583597735909, 'ACC-16': 28.403321728031393, 'ACC-17': 24.46846669463828, 'ACC-18': 21.644018707753805, 'ACC-19': 20.644973966256, 'ACC-20': 19.24901331088085, 'ACC-21': 17.373807085717186, 'ACC-22': 17.701628453192097, 'ACC-23': 16.39951871795319, 'ACC-24': 16.677273802579805, 'ACC-25': 18.821091758480872, 'ACC-26': 20.496117831215937, 'ACC-27': 22.55708681786437, 'ACC-28': 24.036224475224575, 'ACC-29': 24.994415056244886, 'ACC-30': 26.964619396056587, 'ACC-31': 29.488467032912347, 'ACC-32': 30.544741878680387, 'ACC-33': 29.398827911397824, 'ACC-34': 28.16609890737725, 'ACC-35': 30.012409724803867, 'ACC-36': 29.647787740406166, 'ACC-37': 28.869167771480086, 'ACC-38': 27.636664999018663, 'ACC-39': 26.97254289460434, 'ACC-40': 26.49601856484517, 'ACC-41': 25.545620558384186, 'ACC-42': 25.16827261887629, 'ACC-43': 24.868560056215603, 'ACC-44': 24.232367581911095, 'ACC-45': 23.23127910425063, 'ACC-46': 22.49160392674089, 'ACC-47': 22.3708606455957, 'ACC-48': 22.583785776259695, 'ACC-49': 21.634715379600486, 'ACC-50': 20.791150754715932, 'ACC-51': 20.211518652278507, 'ACC-52': 20.29390091707831, 'ACC-53': 20.01406686741202, 'ACC-54': 19.80940150142237, 'ACC-55': 18.95514584131445, 'ACC-56': 17.94501907668271, 'ACC-57': 18.03908033853075, 'ACC-58': 16.893928878079674, 'ACC-59': 16.92005960458283, 'ACC-60': 16.920205666630984, 'ACC-61': 16.8559804238429, 'ACC-62': 16.551354236840204, 'ACC-63': 16.413168267010196, 'ACC-64': 15.990857454976931, 'ACC-65': 15.098183033967775, 'ACC-66': 14.720418506552043, 'ACC-67': 14.356176372688909, 'ACC-68': 14.06244319886312, 'ACC-69': 13.654768294040517, 'ACC-70': 13.537226257583157, 'ACC-71': 12.76276016355855, 'ACC-72': 12.307051023344533, 'ACC-73': 12.129873166299017, 'ACC-74': 12.122159143826332, 'ACC-75': 12.391893323315923, 'ACC-76': 12.290415109302499, 'ACC-77': 12.032777486557219, 'ACC-78': 11.944700853392574, 'ACC-79': 11.719775147015532, 'ACC-80': 12.313242910636696, 'ACC-81': 12.5899899946483, 'ACC-82': 13.043776661013338, 'ACC-83': 12.819030305687908, 'ACC-84': 12.89392450708647, 'ACC-85': 12.970444013326093, 'ACC-86': 13.027469084014049, 'ACC-87': 12.750724535548489, 'ACC-88': 12.652973450709023, 'ACC-89': 12.745964669419822, 'ACC-90': 12.59858664682428, 'ACC-91': 12.803365773087913, 'ACC-92': 12.389612705422431, 'ACC-93': 11.833861699129526, 'ACC-94': 11.740422721268164, 'ACC-95': 11.56696120804989, 'ACC-96': 10.97063066654743, 'ACC-97': 10.53141600276262, 'ACC-98': 9.770437927938678, 'ACC-99': 9.354411847513937, 'ACC-100': 8.732677450458056, 'ACC-101': 8.661732617341649, 'ACC-102': 8.586384231989125, 'ACC-103': 8.27500708415982, 'ACC-104': 8.114212636187009, 'ACC-105': 7.6328721040793495, 'ACC-106': 7.795099405092961, 'ACC-107': 7.776593823566527, 'ACC-108': 7.448982665672128, 'ACC-109': 7.4558848335112256, 'ACC-110': 7.374481696053407, 'ACC-111': 7.4920061262077775, 'ACC-112': 8.072395846888202, 'ACC-113': 7.685564230737888, 'ACC-114': 7.559228381080592, 'ACC-115': 7.048396554057101, 'ACC-116': 7.054729590577449, 'ACC-117': 6.945883196298079, 'ACC-118': 6.51640405979434, 'ACC-119': 6.148090294084975, 'ACC-120': 5.729951823232376, 'ACC-121': 5.42126345652556, 'ACC-122': 4.952258295828734, 'ACC-123': 4.812806783126657, 'ACC-124': 5.039846017875436, 'ACC-125': 5.1753768641983635, 'ACC-126': 4.5098316013807045, 'ACC-127': 4.336784756422357, 'ACC-128': 4.221658732685198, 'ACC-129': 4.144057421156042, 'ACC-130': 4.017033714010056, 'ACC-131': 4.226387357589122, 'ACC-132': 4.294518000221171, 'ACC-133': 4.651792579286507, 'ACC-134': 4.2205256355019385, 'ACC-135': 3.99357220226897, 'ACC-136': 4.23492534010436, 'ACC-137': 4.15778455019283, 'ACC-138': 3.833651673985329, 'ACC-139': 3.6495913516916954, 'ACC-140': 3.4072292429686244, 'ACC-141': 3.345934200582692, 'ACC-142': 3.1170391795720924, 'ACC-143': 3.269434507522557, 'ACC-144': 3.134025270758123, 'ACC-145': 2.280909680449026, 'ACC-146': 2.2487034794727103, 'ACC-147': 2.4372715261057976, 'ACC-148': 2.5495912270412746, 'ACC-149': 2.3120085916908453, 'ACC-150': 2.694471283884141, 'ACC-151': 2.4281586685466965, 'ACC-152': 2.7994133117539954, 'ACC-153': 2.5692116015317246, 'ACC-154': 2.771036097441841, 'ACC-155': 2.372659079087814, 'ACC-156': 2.4897386672871944, 'ACC-157': 2.2523828383916333, 'ACC-158': 2.3089375359007325, 'ACC-159': 2.5715436066540587, 'ACC-160': 2.599053295932679, 'ACC-161': 2.829865450450324, 'ACC-162': 2.3994275530272153, 'ACC-163': 2.411922337873968, 'ACC-164': 2.7890435979312467, 'ACC-165': 2.6617793264237184, 'ACC-166': 2.1378146746019087, 'ACC-167': 2.1458586300760683, 'ACC-168': 2.4175399113861733, 'ACC-169': 1.8415737691110439, 'ACC-170': 1.2413575251643312, 'ACC-171': 1.7907492344909803, 'ACC-172': 1.7196355150572287, 'ACC-173': 1.2359220780198152, 'ACC-174': 1.453546351128931, 'ACC-175': 2.17923047483818, 'ACC-176': 1.5191476085442304, 'ACC-177': 0.42316500851681865, 'ACC-178': 0.3776238094226315, 'ACC-179': 0.07953238205570919, 'ACC-180': 0.044871143621524605, 'ACC-181': 0.04950483323503427, 'ACC-182': 0.047620288612117354, 'ACC-183': 0.0011771602656615286, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 12:48:23] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 12:48:23] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 12:48:23] d2.evaluation.testing INFO: copypaste: 4.2393,0.5170,0.3001,5.8262,10.6013,10.9531,18.7787
[01/29 12:48:23] d2.utils.events INFO:  eta: 1 day, 7:12:48  iter: 16999  total_loss: 45.25  loss_mask: 4.722  loss_mask_0: 4.468  loss_mask_1: 4.429  loss_mask_2: 4.42  loss_mask_3: 4.417  loss_mask_4: 4.424  loss_mask_5: 4.416  loss_mask_6: 4.399  loss_mask_7: 4.735  loss_mask_8: 4.712  time: 2.6095  data_time: 0.0533  lr: 7.4096e-05  max_mem: 27641M
[01/29 12:49:16] d2.utils.events INFO:  eta: 1 day, 7:11:46  iter: 17019  total_loss: 47.15  loss_mask: 4.888  loss_mask_0: 4.715  loss_mask_1: 4.662  loss_mask_2: 4.675  loss_mask_3: 4.669  loss_mask_4: 4.651  loss_mask_5: 4.648  loss_mask_6: 4.657  loss_mask_7: 4.888  loss_mask_8: 4.882  time: 2.6095  data_time: 0.0615  lr: 7.4065e-05  max_mem: 27641M
[01/29 12:50:08] d2.utils.events INFO:  eta: 1 day, 7:10:50  iter: 17039  total_loss: 47.97  loss_mask: 4.997  loss_mask_0: 4.848  loss_mask_1: 4.719  loss_mask_2: 4.713  loss_mask_3: 4.707  loss_mask_4: 4.706  loss_mask_5: 4.709  loss_mask_6: 4.707  loss_mask_7: 4.992  loss_mask_8: 4.981  time: 2.6095  data_time: 0.0688  lr: 7.4034e-05  max_mem: 27641M
[01/29 12:50:30] d2.engine.hooks INFO: Overall training speed: 17046 iterations in 12:21:22 (2.6096 s / it)
[01/29 12:50:30] d2.engine.hooks INFO: Total training time: 15:59:47 (3:38:25 on hooks)
[01/29 12:50:30] d2.utils.events INFO:  eta: 1 day, 7:10:25  iter: 17048  total_loss: 46.27  loss_mask: 4.735  loss_mask_0: 4.656  loss_mask_1: 4.558  loss_mask_2: 4.538  loss_mask_3: 4.533  loss_mask_4: 4.531  loss_mask_5: 4.522  loss_mask_6: 4.533  loss_mask_7: 4.726  loss_mask_8: 4.726  time: 2.6095  data_time: 0.0638  lr: 7.4022e-05  max_mem: 27641M
[01/29 14:27:18] detectron2 INFO: Rank of current process: 0. World size: 4
[01/29 14:27:23] detectron2 INFO: Environment info:
----------------------  ----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/home/nstarli/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.5
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-32GB (arch=7.0)
Driver version          495.29.05
CUDA_HOME               /usr/local/cuda-11
Pillow                  8.4.0
torchvision             0.10.0 @/home/nstarli/anaconda3/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20211023
iopath                  0.1.9
cv2                     4.5.4
----------------------  ----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/29 14:27:23] detectron2 INFO: Command line arguments: Namespace(config_file='configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml', dist_url='tcp://127.0.0.1:65530', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[01/29 14:27:23] detectron2 INFO: Contents of args.config_file=configs/sceneflow/semantic-segmentation/maskformer2stereo_R50_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBase-SceneFlow-SemanticSegmentationStereo.yaml[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerStereo[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMaskFormerHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGN[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;242m# pixel decoder[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMSDeformAttnPixelDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mres3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mres5[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mMultiScaleMaskedTransformerDecoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmulti_scale_pixel_decoder[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m[38;5;15m  [39m[38;5;242m# 9 decoder layers, add one for the loss on learnable query[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m

[01/29 14:27:23] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mROOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m/home/Datasets/sceneflow[39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_test[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141msceneflow_train[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mabsolute[39m
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmask_former_sceneflow[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m270[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m324[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m378[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m432[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m486[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m594[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m648[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m702[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m756[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLASS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2048[39m
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mIMPORTANCE_SAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.75[39m
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;197mOVERSAMPLE_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3.0[39m
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mINSTANCE_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.8[39m
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m      [39m[38;5;197mSEMANTIC_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mTRAIN_NUM_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12544[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMultiScaleMaskedTransformerDecoder[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmulti_scale_pixel_decoder[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerStereo[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSyncBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbasic[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRes5ROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m12000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_IN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_HEADS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;197mDEFORMABLE_TRANSFORMER_ENCODER_N_POINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhard_pixel_mining[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskFormerHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m193[39m
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMSDeformAttnPixelDecoder[39m
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m48[39m
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m96[39m
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4.0[39m
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m    [39m[38;5;197mUSE_CHECKPOINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_nopretrain_instancenorm[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfull_model[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupPolyLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30000[39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m384[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m540[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[01/29 14:27:23] detectron2 INFO: Full config saved to ./work_dirs/argsoftmax_sigmoid_smoothl1_noMasked_conv3upsample_nopretrain_instancenorm/config.yaml
[01/29 14:27:23] d2.utils.env INFO: Using a generated random seed 23796836
[01/29 14:27:25] d2.engine.defaults INFO: Model:
MaskFormerStereo(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): MSDeformAttnPixelDecoder(
      (input_proj): ModuleList(
        (0): Sequential(
          (0): Conv2d(4096, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (1): Sequential(
          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (2): Sequential(
          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (transformer): MSDeformAttnTransformerEncoderOnly(
        (encoder): MSDeformAttnTransformerEncoder(
          (layers): ModuleList(
            (0): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (1): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (2): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (3): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (4): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
            (5): MSDeformAttnTransformerEncoderLayer(
              (self_attn): MSDeformAttn(
                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)
                (attention_weights): Linear(in_features=256, out_features=96, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (dropout1): Dropout(p=0.0, inplace=False)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (linear1): Linear(in_features=256, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.0, inplace=False)
              (linear2): Linear(in_features=1024, out_features=256, bias=True)
              (dropout3): Dropout(p=0.0, inplace=False)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (adapter_1): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (predictor): MultiScaleMaskedTransformerDecoder(
      (pe_layer): Positional encoding PositionEmbeddingSine
          num_pos_feats: 128
          temperature: 10000
          normalize: True
          scale: 6.283185307179586
      (transformer_self_attention_layers): ModuleList(
        (0): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): SelfAttentionLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_cross_attention_layers): ModuleList(
        (0): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (1): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (2): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (3): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (4): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (5): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (6): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (7): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (8): CrossAttentionLayer(
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
      )
      (transformer_ffn_layers): ModuleList(
        (0): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (1): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (2): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (3): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (4): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (5): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (6): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (7): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (8): FFNLayer(
          (linear1): Linear(in_features=256, out_features=2048, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (linear2): Linear(in_features=2048, out_features=256, bias=True)
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (query_feat): Embedding(300, 256)
      (query_embed): Embedding(300, 256)
      (level_embed): Embedding(3, 256)
      (input_proj): ModuleList(
        (0): Sequential()
        (1): Sequential()
        (2): Sequential()
      )
      (class_embed): Linear(in_features=256, out_features=194, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): Criterion SetCriterionStereo
      matcher: Matcher HungarianMatcher
          cost_class: 1.0
          cost_mask: 1.0
          cost_dice: 0.1
      losses: ['masks']
      weight_dict: {'loss_mask': 1.0, 'loss_mask_0': 1.0, 'loss_mask_1': 1.0, 'loss_mask_2': 1.0, 'loss_mask_3': 1.0, 'loss_mask_4': 1.0, 'loss_mask_5': 1.0, 'loss_mask_6': 1.0, 'loss_mask_7': 1.0, 'loss_mask_8': 1.0}
      num_classes: 193
      eos_coef: 0.1
      num_points: 12544
      oversample_ratio: 3.0
      importance_sample_ratio: 0.75
  (upsampler): UpsampleMasks(
    (conv2d): Conv2d(300, 300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
[01/29 14:27:25] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in training: [RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[256, 512], single_category_max_area=1.0, ignored_category=0)]
[01/29 14:27:30] d2.data.build INFO: Using training sampler TrainingSampler
[01/29 14:27:30] d2.data.common INFO: Serializing 35454 elements to byte tensors and concatenating them all ...
[01/29 14:27:30] d2.data.common INFO: Serialized dataset takes 10.76 MiB
[01/29 14:27:30] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[01/29 14:27:30] d2.engine.train_loop INFO: Starting training from iteration 0
[01/29 14:28:34] d2.utils.events INFO:  eta: 1 day, 19:42:29  iter: 19  total_loss: 1.434e+05  loss_mask: 1.454e+04  loss_mask_0: 1.428e+04  loss_mask_1: 1.462e+04  loss_mask_2: 1.448e+04  loss_mask_3: 1.439e+04  loss_mask_4: 1.409e+04  loss_mask_5: 1.4e+04  loss_mask_6: 1.431e+04  loss_mask_7: 1.427e+04  loss_mask_8: 1.447e+04  time: 2.6496  data_time: 0.4711  lr: 0.00099971  max_mem: 27554M
[01/29 14:29:27] d2.utils.events INFO:  eta: 1 day, 19:27:56  iter: 39  total_loss: 4.193e+04  loss_mask: 1325  loss_mask_0: 2.409e+04  loss_mask_1: 2934  loss_mask_2: 2933  loss_mask_3: 2933  loss_mask_4: 2934  loss_mask_5: 1064  loss_mask_6: 1063  loss_mask_7: 1325  loss_mask_8: 1325  time: 2.6277  data_time: 0.0536  lr: 0.00099941  max_mem: 27560M
[01/29 14:30:19] d2.utils.events INFO:  eta: 1 day, 19:27:04  iter: 59  total_loss: 1073  loss_mask: 64.82  loss_mask_0: 45.17  loss_mask_1: 184.5  loss_mask_2: 184.4  loss_mask_3: 184.4  loss_mask_4: 184.4  loss_mask_5: 48.62  loss_mask_6: 48.62  loss_mask_7: 64.82  loss_mask_8: 64.82  time: 2.6232  data_time: 0.0609  lr: 0.00099911  max_mem: 27582M
[01/29 14:31:11] d2.utils.events INFO:  eta: 1 day, 19:20:03  iter: 79  total_loss: 544.4  loss_mask: 56.71  loss_mask_0: 27.48  loss_mask_1: 160  loss_mask_2: 29.74  loss_mask_3: 30.64  loss_mask_4: 43.58  loss_mask_5: 43.29  loss_mask_6: 43.29  loss_mask_7: 56.71  loss_mask_8: 56.71  time: 2.6181  data_time: 0.0672  lr: 0.00099881  max_mem: 27582M
[01/29 14:32:03] d2.utils.events INFO:  eta: 1 day, 19:18:57  iter: 99  total_loss: 391.3  loss_mask: 57.2  loss_mask_0: 26.69  loss_mask_1: 28.09  loss_mask_2: 26.51  loss_mask_3: 27.2  loss_mask_4: 26.7  loss_mask_5: 43.32  loss_mask_6: 43.32  loss_mask_7: 57.2  loss_mask_8: 57.2  time: 2.6146  data_time: 0.0567  lr: 0.00099851  max_mem: 27582M
[01/29 14:32:55] d2.utils.events INFO:  eta: 1 day, 19:18:05  iter: 119  total_loss: 292.7  loss_mask: 29.31  loss_mask_0: 26.15  loss_mask_1: 26.48  loss_mask_2: 26.47  loss_mask_3: 26.14  loss_mask_4: 26.39  loss_mask_5: 28.26  loss_mask_6: 27.71  loss_mask_7: 30.19  loss_mask_8: 28.26  time: 2.6133  data_time: 0.0658  lr: 0.00099821  max_mem: 27582M
[01/29 14:33:47] d2.utils.events INFO:  eta: 1 day, 19:16:50  iter: 139  total_loss: 267.7  loss_mask: 26.36  loss_mask_0: 25.88  loss_mask_1: 26.35  loss_mask_2: 26.35  loss_mask_3: 26.29  loss_mask_4: 27.22  loss_mask_5: 26.36  loss_mask_6: 26.36  loss_mask_7: 27.15  loss_mask_8: 26.36  time: 2.6122  data_time: 0.0717  lr: 0.00099791  max_mem: 27586M
[01/29 14:34:40] d2.utils.events INFO:  eta: 1 day, 19:16:31  iter: 159  total_loss: 261  loss_mask: 25.95  loss_mask_0: 25.99  loss_mask_1: 25.92  loss_mask_2: 26.4  loss_mask_3: 26.08  loss_mask_4: 26.85  loss_mask_5: 25.95  loss_mask_6: 25.95  loss_mask_7: 25.88  loss_mask_8: 25.95  time: 2.6124  data_time: 0.0647  lr: 0.00099761  max_mem: 27586M
[01/29 14:35:32] d2.utils.events INFO:  eta: 1 day, 19:15:19  iter: 179  total_loss: 259.8  loss_mask: 26.17  loss_mask_0: 25.57  loss_mask_1: 25.7  loss_mask_2: 26.03  loss_mask_3: 25.67  loss_mask_4: 26.12  loss_mask_5: 26.17  loss_mask_6: 26.17  loss_mask_7: 25.67  loss_mask_8: 26.17  time: 2.6112  data_time: 0.0531  lr: 0.00099731  max_mem: 27586M
[01/29 14:36:24] d2.utils.events INFO:  eta: 1 day, 19:14:26  iter: 199  total_loss: 267.2  loss_mask: 26.95  loss_mask_0: 26.35  loss_mask_1: 26.69  loss_mask_2: 26.56  loss_mask_3: 26.62  loss_mask_4: 26.68  loss_mask_5: 26.95  loss_mask_6: 26.95  loss_mask_7: 26.76  loss_mask_8: 26.83  time: 2.6105  data_time: 0.0564  lr: 0.00099701  max_mem: 27586M
[01/29 14:37:16] d2.utils.events INFO:  eta: 1 day, 19:13:22  iter: 219  total_loss: 251.4  loss_mask: 25.1  loss_mask_0: 25.19  loss_mask_1: 25.11  loss_mask_2: 25.17  loss_mask_3: 25.19  loss_mask_4: 25.13  loss_mask_5: 25.11  loss_mask_6: 25.11  loss_mask_7: 25.18  loss_mask_8: 25.12  time: 2.6100  data_time: 0.0603  lr: 0.00099671  max_mem: 27586M
[01/29 14:38:08] d2.utils.events INFO:  eta: 1 day, 19:12:03  iter: 239  total_loss: 267.7  loss_mask: 26.71  loss_mask_0: 26.75  loss_mask_1: 26.9  loss_mask_2: 26.78  loss_mask_3: 26.76  loss_mask_4: 26.87  loss_mask_5: 26.71  loss_mask_6: 26.71  loss_mask_7: 26.74  loss_mask_8: 26.83  time: 2.6094  data_time: 0.0559  lr: 0.00099641  max_mem: 27586M
[01/29 14:39:00] d2.utils.events INFO:  eta: 1 day, 19:11:00  iter: 259  total_loss: 285.3  loss_mask: 28.8  loss_mask_0: 28.53  loss_mask_1: 28.49  loss_mask_2: 28.41  loss_mask_3: 28.45  loss_mask_4: 28.49  loss_mask_5: 28.8  loss_mask_6: 28.76  loss_mask_7: 28.44  loss_mask_8: 28.7  time: 2.6096  data_time: 0.0707  lr: 0.00099611  max_mem: 27617M
[01/29 14:39:53] d2.utils.events INFO:  eta: 1 day, 19:10:08  iter: 279  total_loss: 274  loss_mask: 27.27  loss_mask_0: 27.39  loss_mask_1: 27.54  loss_mask_2: 27.52  loss_mask_3: 27.44  loss_mask_4: 27.43  loss_mask_5: 27.28  loss_mask_6: 27.34  loss_mask_7: 27.61  loss_mask_8: 27.32  time: 2.6093  data_time: 0.0676  lr: 0.00099581  max_mem: 27617M
[01/29 14:40:45] d2.utils.events INFO:  eta: 1 day, 19:09:27  iter: 299  total_loss: 271.2  loss_mask: 27.41  loss_mask_0: 27.09  loss_mask_1: 27.09  loss_mask_2: 27.09  loss_mask_3: 27.09  loss_mask_4: 27.08  loss_mask_5: 27.22  loss_mask_6: 27.11  loss_mask_7: 27.09  loss_mask_8: 27.12  time: 2.6091  data_time: 0.0621  lr: 0.00099551  max_mem: 27617M
[01/29 14:41:37] d2.utils.events INFO:  eta: 1 day, 19:08:24  iter: 319  total_loss: 262.1  loss_mask: 26.34  loss_mask_0: 26.19  loss_mask_1: 26.19  loss_mask_2: 26.19  loss_mask_3: 26.19  loss_mask_4: 26.19  loss_mask_5: 26.19  loss_mask_6: 26.19  loss_mask_7: 26.19  loss_mask_8: 26.2  time: 2.6088  data_time: 0.0638  lr: 0.00099521  max_mem: 27617M
[01/29 14:42:29] d2.utils.events INFO:  eta: 1 day, 19:07:43  iter: 339  total_loss: 272.6  loss_mask: 27.52  loss_mask_0: 27.13  loss_mask_1: 27.24  loss_mask_2: 27.23  loss_mask_3: 27.24  loss_mask_4: 27.23  loss_mask_5: 27.21  loss_mask_6: 27.27  loss_mask_7: 27.25  loss_mask_8: 27.25  time: 2.6088  data_time: 0.0610  lr: 0.00099491  max_mem: 27617M
[01/29 14:43:21] d2.utils.events INFO:  eta: 1 day, 19:06:23  iter: 359  total_loss: 258.2  loss_mask: 26.28  loss_mask_0: 26.01  loss_mask_1: 25.72  loss_mask_2: 25.7  loss_mask_3: 25.7  loss_mask_4: 25.7  loss_mask_5: 25.76  loss_mask_6: 25.75  loss_mask_7: 25.72  loss_mask_8: 25.72  time: 2.6079  data_time: 0.0621  lr: 0.00099461  max_mem: 27617M
[01/29 14:44:13] d2.utils.events INFO:  eta: 1 day, 19:05:31  iter: 379  total_loss: 263.5  loss_mask: 26.55  loss_mask_0: 26.36  loss_mask_1: 26.36  loss_mask_2: 26.35  loss_mask_3: 26.36  loss_mask_4: 26.37  loss_mask_5: 26.39  loss_mask_6: 26.4  loss_mask_7: 26.36  loss_mask_8: 26.36  time: 2.6079  data_time: 0.0626  lr: 0.00099431  max_mem: 27617M
[01/29 14:45:05] d2.utils.events INFO:  eta: 1 day, 19:04:55  iter: 399  total_loss: 253.2  loss_mask: 25.7  loss_mask_0: 25.26  loss_mask_1: 25.28  loss_mask_2: 25.28  loss_mask_3: 25.27  loss_mask_4: 25.28  loss_mask_5: 25.32  loss_mask_6: 25.32  loss_mask_7: 25.29  loss_mask_8: 25.28  time: 2.6081  data_time: 0.0634  lr: 0.00099401  max_mem: 27617M
[01/29 14:45:58] d2.utils.events INFO:  eta: 1 day, 19:04:27  iter: 419  total_loss: 264.8  loss_mask: 26.51  loss_mask_0: 26.44  loss_mask_1: 26.49  loss_mask_2: 26.46  loss_mask_3: 26.45  loss_mask_4: 26.44  loss_mask_5: 26.55  loss_mask_6: 26.52  loss_mask_7: 26.5  loss_mask_8: 26.47  time: 2.6081  data_time: 0.0588  lr: 0.00099371  max_mem: 27617M
[01/29 14:46:50] d2.utils.events INFO:  eta: 1 day, 19:03:41  iter: 439  total_loss: 266  loss_mask: 26.61  loss_mask_0: 26.6  loss_mask_1: 26.6  loss_mask_2: 26.6  loss_mask_3: 26.6  loss_mask_4: 26.6  loss_mask_5: 26.6  loss_mask_6: 26.6  loss_mask_7: 26.6  loss_mask_8: 26.6  time: 2.6085  data_time: 0.0567  lr: 0.00099341  max_mem: 27617M
[01/29 14:47:42] d2.utils.events INFO:  eta: 1 day, 19:02:49  iter: 459  total_loss: 264.2  loss_mask: 26.41  loss_mask_0: 26.39  loss_mask_1: 26.43  loss_mask_2: 26.43  loss_mask_3: 26.43  loss_mask_4: 26.42  loss_mask_5: 26.43  loss_mask_6: 26.42  loss_mask_7: 26.43  loss_mask_8: 26.42  time: 2.6082  data_time: 0.0556  lr: 0.00099311  max_mem: 27617M
[01/29 14:48:34] d2.utils.events INFO:  eta: 1 day, 19:01:38  iter: 479  total_loss: 260.1  loss_mask: 26.01  loss_mask_0: 26.06  loss_mask_1: 26  loss_mask_2: 26  loss_mask_3: 26  loss_mask_4: 26  loss_mask_5: 26.01  loss_mask_6: 26.01  loss_mask_7: 26.01  loss_mask_8: 26  time: 2.6080  data_time: 0.0620  lr: 0.00099281  max_mem: 27617M
[01/29 14:49:27] d2.utils.events INFO:  eta: 1 day, 19:00:59  iter: 499  total_loss: 265.3  loss_mask: 26.53  loss_mask_0: 26.58  loss_mask_1: 26.53  loss_mask_2: 26.53  loss_mask_3: 26.53  loss_mask_4: 26.52  loss_mask_5: 26.53  loss_mask_6: 26.53  loss_mask_7: 26.53  loss_mask_8: 26.53  time: 2.6082  data_time: 0.0573  lr: 0.00099251  max_mem: 27617M
[01/29 14:50:19] d2.utils.events INFO:  eta: 1 day, 19:00:21  iter: 519  total_loss: 255.7  loss_mask: 25.59  loss_mask_0: 25.58  loss_mask_1: 25.57  loss_mask_2: 25.57  loss_mask_3: 25.57  loss_mask_4: 25.56  loss_mask_5: 25.58  loss_mask_6: 25.57  loss_mask_7: 25.57  loss_mask_8: 25.56  time: 2.6088  data_time: 0.0663  lr: 0.00099221  max_mem: 27617M
[01/29 14:51:11] d2.utils.events INFO:  eta: 1 day, 18:59:21  iter: 539  total_loss: 257.5  loss_mask: 25.78  loss_mask_0: 25.75  loss_mask_1: 25.75  loss_mask_2: 25.75  loss_mask_3: 25.75  loss_mask_4: 25.76  loss_mask_5: 25.77  loss_mask_6: 25.76  loss_mask_7: 25.76  loss_mask_8: 25.76  time: 2.6091  data_time: 0.0692  lr: 0.00099191  max_mem: 27617M
[01/29 14:52:04] d2.utils.events INFO:  eta: 1 day, 18:58:37  iter: 559  total_loss: 269.4  loss_mask: 26.95  loss_mask_0: 26.9  loss_mask_1: 26.94  loss_mask_2: 26.93  loss_mask_3: 26.94  loss_mask_4: 26.93  loss_mask_5: 26.96  loss_mask_6: 26.94  loss_mask_7: 26.94  loss_mask_8: 26.93  time: 2.6090  data_time: 0.0651  lr: 0.00099161  max_mem: 27617M
[01/29 14:52:56] d2.utils.events INFO:  eta: 1 day, 18:57:37  iter: 579  total_loss: 258  loss_mask: 25.83  loss_mask_0: 25.75  loss_mask_1: 25.82  loss_mask_2: 25.8  loss_mask_3: 25.8  loss_mask_4: 25.76  loss_mask_5: 25.86  loss_mask_6: 25.83  loss_mask_7: 25.83  loss_mask_8: 25.8  time: 2.6087  data_time: 0.0628  lr: 0.00099131  max_mem: 27617M
[01/29 14:53:48] d2.utils.events INFO:  eta: 1 day, 18:56:45  iter: 599  total_loss: 262.5  loss_mask: 26.28  loss_mask_0: 26.16  loss_mask_1: 26.26  loss_mask_2: 26.24  loss_mask_3: 26.24  loss_mask_4: 26.23  loss_mask_5: 26.29  loss_mask_6: 26.26  loss_mask_7: 26.27  loss_mask_8: 26.24  time: 2.6088  data_time: 0.0672  lr: 0.00099101  max_mem: 27617M
[01/29 14:54:40] d2.utils.events INFO:  eta: 1 day, 18:55:44  iter: 619  total_loss: 258.3  loss_mask: 25.89  loss_mask_0: 25.48  loss_mask_1: 25.87  loss_mask_2: 25.81  loss_mask_3: 25.8  loss_mask_4: 25.79  loss_mask_5: 25.91  loss_mask_6: 25.88  loss_mask_7: 25.89  loss_mask_8: 25.82  time: 2.6084  data_time: 0.0593  lr: 0.00099071  max_mem: 27617M
[01/29 14:55:32] d2.utils.events INFO:  eta: 1 day, 18:54:52  iter: 639  total_loss: 280.8  loss_mask: 28.06  loss_mask_0: 28.14  loss_mask_1: 28.07  loss_mask_2: 28.07  loss_mask_3: 28.07  loss_mask_4: 28.07  loss_mask_5: 28.07  loss_mask_6: 28.06  loss_mask_7: 28.06  loss_mask_8: 28.07  time: 2.6083  data_time: 0.0638  lr: 0.00099041  max_mem: 27617M
[01/29 14:56:25] d2.utils.events INFO:  eta: 1 day, 18:54:22  iter: 659  total_loss: 281.7  loss_mask: 28.19  loss_mask_0: 28.05  loss_mask_1: 28.19  loss_mask_2: 28.19  loss_mask_3: 28.19  loss_mask_4: 28.16  loss_mask_5: 28.19  loss_mask_6: 28.16  loss_mask_7: 28.2  loss_mask_8: 28.18  time: 2.6088  data_time: 0.0727  lr: 0.00099011  max_mem: 27617M
[01/29 14:57:17] d2.utils.events INFO:  eta: 1 day, 18:53:30  iter: 679  total_loss: 266.1  loss_mask: 26.58  loss_mask_0: 26.78  loss_mask_1: 26.58  loss_mask_2: 26.58  loss_mask_3: 26.59  loss_mask_4: 26.59  loss_mask_5: 26.59  loss_mask_6: 26.59  loss_mask_7: 26.58  loss_mask_8: 26.58  time: 2.6088  data_time: 0.0711  lr: 0.00098981  max_mem: 27629M
[01/29 14:58:09] d2.utils.events INFO:  eta: 1 day, 18:52:33  iter: 699  total_loss: 261.1  loss_mask: 26.06  loss_mask_0: 26.34  loss_mask_1: 26.07  loss_mask_2: 26.07  loss_mask_3: 26.08  loss_mask_4: 26.1  loss_mask_5: 26.1  loss_mask_6: 26.1  loss_mask_7: 26.07  loss_mask_8: 26.07  time: 2.6088  data_time: 0.0607  lr: 0.00098951  max_mem: 27629M
[01/29 14:59:01] d2.utils.events INFO:  eta: 1 day, 18:51:33  iter: 719  total_loss: 253.7  loss_mask: 25.37  loss_mask_0: 25.38  loss_mask_1: 25.37  loss_mask_2: 25.37  loss_mask_3: 25.37  loss_mask_4: 25.37  loss_mask_5: 25.36  loss_mask_6: 25.36  loss_mask_7: 25.36  loss_mask_8: 25.37  time: 2.6090  data_time: 0.0630  lr: 0.00098921  max_mem: 27629M
[01/29 14:59:54] d2.utils.events INFO:  eta: 1 day, 18:50:41  iter: 739  total_loss: 270.3  loss_mask: 27.01  loss_mask_0: 27.1  loss_mask_1: 27.01  loss_mask_2: 27.02  loss_mask_3: 27.02  loss_mask_4: 27.03  loss_mask_5: 27.01  loss_mask_6: 27.02  loss_mask_7: 27.01  loss_mask_8: 27.02  time: 2.6093  data_time: 0.0683  lr: 0.00098891  max_mem: 27629M
[01/29 15:00:46] d2.utils.events INFO:  eta: 1 day, 18:49:56  iter: 759  total_loss: 273.8  loss_mask: 27.39  loss_mask_0: 27.29  loss_mask_1: 27.39  loss_mask_2: 27.38  loss_mask_3: 27.38  loss_mask_4: 27.38  loss_mask_5: 27.42  loss_mask_6: 27.4  loss_mask_7: 27.41  loss_mask_8: 27.38  time: 2.6095  data_time: 0.0595  lr: 0.00098861  max_mem: 27629M
[01/29 15:01:39] d2.utils.events INFO:  eta: 1 day, 18:49:18  iter: 779  total_loss: 265.7  loss_mask: 26.54  loss_mask_0: 26.64  loss_mask_1: 26.54  loss_mask_2: 26.55  loss_mask_3: 26.54  loss_mask_4: 26.55  loss_mask_5: 26.53  loss_mask_6: 26.54  loss_mask_7: 26.53  loss_mask_8: 26.55  time: 2.6098  data_time: 0.0633  lr: 0.00098831  max_mem: 27629M
[01/29 15:02:31] d2.utils.events INFO:  eta: 1 day, 18:48:35  iter: 799  total_loss: 262.6  loss_mask: 26.27  loss_mask_0: 26.22  loss_mask_1: 26.27  loss_mask_2: 26.27  loss_mask_3: 26.27  loss_mask_4: 26.27  loss_mask_5: 26.26  loss_mask_6: 26.27  loss_mask_7: 26.26  loss_mask_8: 26.27  time: 2.6098  data_time: 0.0658  lr: 0.00098801  max_mem: 27629M
[01/29 15:03:23] d2.utils.events INFO:  eta: 1 day, 18:47:44  iter: 819  total_loss: 268.1  loss_mask: 26.79  loss_mask_0: 26.94  loss_mask_1: 26.79  loss_mask_2: 26.79  loss_mask_3: 26.79  loss_mask_4: 26.79  loss_mask_5: 26.79  loss_mask_6: 26.79  loss_mask_7: 26.79  loss_mask_8: 26.79  time: 2.6098  data_time: 0.0697  lr: 0.00098771  max_mem: 27629M
[01/29 15:04:15] d2.utils.events INFO:  eta: 1 day, 18:46:52  iter: 839  total_loss: 261.9  loss_mask: 26.19  loss_mask_0: 26.15  loss_mask_1: 26.2  loss_mask_2: 26.19  loss_mask_3: 26.19  loss_mask_4: 26.19  loss_mask_5: 26.2  loss_mask_6: 26.2  loss_mask_7: 26.2  loss_mask_8: 26.19  time: 2.6097  data_time: 0.0629  lr: 0.00098741  max_mem: 27629M
[01/29 15:05:08] d2.utils.events INFO:  eta: 1 day, 18:46:12  iter: 859  total_loss: 260.4  loss_mask: 26.03  loss_mask_0: 26.15  loss_mask_1: 26.03  loss_mask_2: 26.03  loss_mask_3: 26.03  loss_mask_4: 26.03  loss_mask_5: 26.03  loss_mask_6: 26.04  loss_mask_7: 26.03  loss_mask_8: 26.03  time: 2.6098  data_time: 0.0622  lr: 0.00098711  max_mem: 27629M
[01/29 15:06:00] d2.utils.events INFO:  eta: 1 day, 18:45:20  iter: 879  total_loss: 262.8  loss_mask: 26.29  loss_mask_0: 26.29  loss_mask_1: 26.28  loss_mask_2: 26.29  loss_mask_3: 26.28  loss_mask_4: 26.28  loss_mask_5: 26.27  loss_mask_6: 26.28  loss_mask_7: 26.27  loss_mask_8: 26.29  time: 2.6098  data_time: 0.0676  lr: 0.00098681  max_mem: 27629M
[01/29 15:06:52] d2.utils.events INFO:  eta: 1 day, 18:44:32  iter: 899  total_loss: 282.4  loss_mask: 28.23  loss_mask_0: 28.17  loss_mask_1: 28.27  loss_mask_2: 28.26  loss_mask_3: 28.27  loss_mask_4: 28.24  loss_mask_5: 28.25  loss_mask_6: 28.23  loss_mask_7: 28.29  loss_mask_8: 28.24  time: 2.6098  data_time: 0.0631  lr: 0.0009865  max_mem: 27629M
[01/29 15:07:44] d2.utils.events INFO:  eta: 1 day, 18:43:40  iter: 919  total_loss: 268.2  loss_mask: 26.81  loss_mask_0: 26.8  loss_mask_1: 26.84  loss_mask_2: 26.83  loss_mask_3: 26.83  loss_mask_4: 26.82  loss_mask_5: 26.83  loss_mask_6: 26.81  loss_mask_7: 26.83  loss_mask_8: 26.81  time: 2.6098  data_time: 0.0720  lr: 0.0009862  max_mem: 27629M
[01/29 15:08:36] d2.utils.events INFO:  eta: 1 day, 18:42:54  iter: 939  total_loss: 274.6  loss_mask: 27.46  loss_mask_0: 27.53  loss_mask_1: 27.45  loss_mask_2: 27.45  loss_mask_3: 27.45  loss_mask_4: 27.47  loss_mask_5: 27.47  loss_mask_6: 27.48  loss_mask_7: 27.45  loss_mask_8: 27.46  time: 2.6097  data_time: 0.0568  lr: 0.0009859  max_mem: 27629M
[01/29 15:09:29] d2.utils.events INFO:  eta: 1 day, 18:42:11  iter: 959  total_loss: 262.7  loss_mask: 26.27  loss_mask_0: 26.34  loss_mask_1: 26.26  loss_mask_2: 26.26  loss_mask_3: 26.26  loss_mask_4: 26.27  loss_mask_5: 26.25  loss_mask_6: 26.26  loss_mask_7: 26.25  loss_mask_8: 26.27  time: 2.6099  data_time: 0.0726  lr: 0.0009856  max_mem: 27629M
[01/29 15:10:21] d2.utils.events INFO:  eta: 1 day, 18:41:49  iter: 979  total_loss: 261.8  loss_mask: 26.18  loss_mask_0: 26.16  loss_mask_1: 26.18  loss_mask_2: 26.17  loss_mask_3: 26.17  loss_mask_4: 26.18  loss_mask_5: 26.18  loss_mask_6: 26.18  loss_mask_7: 26.18  loss_mask_8: 26.19  time: 2.6101  data_time: 0.0601  lr: 0.0009853  max_mem: 27629M
[01/29 15:11:13] mask2former.data.dataset_mappers.mask_former_sceneflow_dataset_mapper INFO: [MaskFormerSceneFlowDatasetMapper] Augmentations used in inference: []
[01/29 15:11:14] d2.data.common INFO: Serializing 4370 elements to byte tensors and concatenating them all ...
[01/29 15:11:14] d2.data.common INFO: Serialized dataset takes 1.22 MiB
[01/29 15:21:24] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'epe': 24.053184149460545, 'error_1pix': 0.9520194865147684, 'error_3pix': 0.8867449060692092, 'mIoU': 0.007942382927858557, 'fwIoU': 0.02349720803387957, 'IoU-0': 0.0, 'IoU-1': 0.0, 'IoU-2': 0.0, 'IoU-3': 0.0, 'IoU-4': 0.0, 'IoU-5': 0.0, 'IoU-6': 0.0, 'IoU-7': 0.0, 'IoU-8': 0.0, 'IoU-9': 0.0, 'IoU-10': 0.0, 'IoU-11': 0.0, 'IoU-12': 0.0, 'IoU-13': 0.0, 'IoU-14': 0.0, 'IoU-15': 0.0, 'IoU-16': 0.0, 'IoU-17': 0.0, 'IoU-18': 0.0, 'IoU-19': 0.0, 'IoU-20': 0.0, 'IoU-21': 0.0, 'IoU-22': 0.0, 'IoU-23': 0.0, 'IoU-24': 0.0, 'IoU-25': 0.0, 'IoU-26': 0.0, 'IoU-27': 0.0, 'IoU-28': 0.0, 'IoU-29': 0.0, 'IoU-30': 0.0, 'IoU-31': 0.0, 'IoU-32': 0.0, 'IoU-33': 0.0, 'IoU-34': 1.5328799050767015, 'IoU-35': 0.0, 'IoU-36': 0.0, 'IoU-37': 0.0, 'IoU-38': 0.0, 'IoU-39': 0.0, 'IoU-40': 0.0, 'IoU-41': 0.0, 'IoU-42': 0.0, 'IoU-43': 0.0, 'IoU-44': 0.0, 'IoU-45': 0.0, 'IoU-46': 0.0, 'IoU-47': 0.0, 'IoU-48': 0.0, 'IoU-49': 0.0, 'IoU-50': 0.0, 'IoU-51': 0.0, 'IoU-52': 0.0, 'IoU-53': 0.0, 'IoU-54': 0.0, 'IoU-55': 0.0, 'IoU-56': 0.0, 'IoU-57': 0.0, 'IoU-58': 0.0, 'IoU-59': 0.0, 'IoU-60': 0.0, 'IoU-61': 0.0, 'IoU-62': 0.0, 'IoU-63': 0.0, 'IoU-64': 0.0, 'IoU-65': 0.0, 'IoU-66': 0.0, 'IoU-67': 0.0, 'IoU-68': 0.0, 'IoU-69': 0.0, 'IoU-70': 0.0, 'IoU-71': 0.0, 'IoU-72': 0.0, 'IoU-73': 0.0, 'IoU-74': 0.0, 'IoU-75': 0.0, 'IoU-76': 0.0, 'IoU-77': 0.0, 'IoU-78': 0.0, 'IoU-79': 0.0, 'IoU-80': 0.0, 'IoU-81': 0.0, 'IoU-82': 0.0, 'IoU-83': 0.0, 'IoU-84': 0.0, 'IoU-85': 0.0, 'IoU-86': 0.0, 'IoU-87': 0.0, 'IoU-88': 0.0, 'IoU-89': 0.0, 'IoU-90': 0.0, 'IoU-91': 0.0, 'IoU-92': 0.0, 'IoU-93': 0.0, 'IoU-94': 0.0, 'IoU-95': 0.0, 'IoU-96': 0.0, 'IoU-97': 0.0, 'IoU-98': 0.0, 'IoU-99': 0.0, 'IoU-100': 0.0, 'IoU-101': 0.0, 'IoU-102': 0.0, 'IoU-103': 0.0, 'IoU-104': 0.0, 'IoU-105': 0.0, 'IoU-106': 0.0, 'IoU-107': 0.0, 'IoU-108': 0.0, 'IoU-109': 0.0, 'IoU-110': 0.0, 'IoU-111': 0.0, 'IoU-112': 0.0, 'IoU-113': 0.0, 'IoU-114': 0.0, 'IoU-115': 0.0, 'IoU-116': 0.0, 'IoU-117': 0.0, 'IoU-118': 0.0, 'IoU-119': 0.0, 'IoU-120': 0.0, 'IoU-121': 0.0, 'IoU-122': 0.0, 'IoU-123': 0.0, 'IoU-124': 0.0, 'IoU-125': 0.0, 'IoU-126': 0.0, 'IoU-127': 0.0, 'IoU-128': 0.0, 'IoU-129': 0.0, 'IoU-130': 0.0, 'IoU-131': 0.0, 'IoU-132': 0.0, 'IoU-133': 0.0, 'IoU-134': 0.0, 'IoU-135': 0.0, 'IoU-136': 0.0, 'IoU-137': 0.0, 'IoU-138': 0.0, 'IoU-139': 0.0, 'IoU-140': 0.0, 'IoU-141': 0.0, 'IoU-142': 0.0, 'IoU-143': 0.0, 'IoU-144': 0.0, 'IoU-145': 0.0, 'IoU-146': 0.0, 'IoU-147': 0.0, 'IoU-148': 0.0, 'IoU-149': 0.0, 'IoU-150': 0.0, 'IoU-151': 0.0, 'IoU-152': 0.0, 'IoU-153': 0.0, 'IoU-154': 0.0, 'IoU-155': 0.0, 'IoU-156': 0.0, 'IoU-157': 0.0, 'IoU-158': 0.0, 'IoU-159': 0.0, 'IoU-160': 0.0, 'IoU-161': 0.0, 'IoU-162': 0.0, 'IoU-163': 0.0, 'IoU-164': 0.0, 'IoU-165': 0.0, 'IoU-166': 0.0, 'IoU-167': 0.0, 'IoU-168': 0.0, 'IoU-169': 0.0, 'IoU-170': 0.0, 'IoU-171': 0.0, 'IoU-172': 0.0, 'IoU-173': 0.0, 'IoU-174': 0.0, 'IoU-175': 0.0, 'IoU-176': 0.0, 'IoU-177': 0.0, 'IoU-178': 0.0, 'IoU-179': 0.0, 'IoU-180': 0.0, 'IoU-181': 0.0, 'IoU-182': 0.0, 'IoU-183': 0.0, 'IoU-184': 0.0, 'IoU-185': 0.0, 'IoU-186': 0.0, 'IoU-187': 0.0, 'IoU-188': 0.0, 'IoU-189': 0.0, 'IoU-190': 0.0, 'IoU-191': 0.0, 'IoU-192': 0.0, 'mACC': 0.5181347150259068, 'pACC': 1.5328799050767015, 'ACC-0': 0.0, 'ACC-1': 0.0, 'ACC-2': 0.0, 'ACC-3': 0.0, 'ACC-4': 0.0, 'ACC-5': 0.0, 'ACC-6': 0.0, 'ACC-7': 0.0, 'ACC-8': 0.0, 'ACC-9': 0.0, 'ACC-10': 0.0, 'ACC-11': 0.0, 'ACC-12': 0.0, 'ACC-13': 0.0, 'ACC-14': 0.0, 'ACC-15': 0.0, 'ACC-16': 0.0, 'ACC-17': 0.0, 'ACC-18': 0.0, 'ACC-19': 0.0, 'ACC-20': 0.0, 'ACC-21': 0.0, 'ACC-22': 0.0, 'ACC-23': 0.0, 'ACC-24': 0.0, 'ACC-25': 0.0, 'ACC-26': 0.0, 'ACC-27': 0.0, 'ACC-28': 0.0, 'ACC-29': 0.0, 'ACC-30': 0.0, 'ACC-31': 0.0, 'ACC-32': 0.0, 'ACC-33': 0.0, 'ACC-34': 100.0, 'ACC-35': 0.0, 'ACC-36': 0.0, 'ACC-37': 0.0, 'ACC-38': 0.0, 'ACC-39': 0.0, 'ACC-40': 0.0, 'ACC-41': 0.0, 'ACC-42': 0.0, 'ACC-43': 0.0, 'ACC-44': 0.0, 'ACC-45': 0.0, 'ACC-46': 0.0, 'ACC-47': 0.0, 'ACC-48': 0.0, 'ACC-49': 0.0, 'ACC-50': 0.0, 'ACC-51': 0.0, 'ACC-52': 0.0, 'ACC-53': 0.0, 'ACC-54': 0.0, 'ACC-55': 0.0, 'ACC-56': 0.0, 'ACC-57': 0.0, 'ACC-58': 0.0, 'ACC-59': 0.0, 'ACC-60': 0.0, 'ACC-61': 0.0, 'ACC-62': 0.0, 'ACC-63': 0.0, 'ACC-64': 0.0, 'ACC-65': 0.0, 'ACC-66': 0.0, 'ACC-67': 0.0, 'ACC-68': 0.0, 'ACC-69': 0.0, 'ACC-70': 0.0, 'ACC-71': 0.0, 'ACC-72': 0.0, 'ACC-73': 0.0, 'ACC-74': 0.0, 'ACC-75': 0.0, 'ACC-76': 0.0, 'ACC-77': 0.0, 'ACC-78': 0.0, 'ACC-79': 0.0, 'ACC-80': 0.0, 'ACC-81': 0.0, 'ACC-82': 0.0, 'ACC-83': 0.0, 'ACC-84': 0.0, 'ACC-85': 0.0, 'ACC-86': 0.0, 'ACC-87': 0.0, 'ACC-88': 0.0, 'ACC-89': 0.0, 'ACC-90': 0.0, 'ACC-91': 0.0, 'ACC-92': 0.0, 'ACC-93': 0.0, 'ACC-94': 0.0, 'ACC-95': 0.0, 'ACC-96': 0.0, 'ACC-97': 0.0, 'ACC-98': 0.0, 'ACC-99': 0.0, 'ACC-100': 0.0, 'ACC-101': 0.0, 'ACC-102': 0.0, 'ACC-103': 0.0, 'ACC-104': 0.0, 'ACC-105': 0.0, 'ACC-106': 0.0, 'ACC-107': 0.0, 'ACC-108': 0.0, 'ACC-109': 0.0, 'ACC-110': 0.0, 'ACC-111': 0.0, 'ACC-112': 0.0, 'ACC-113': 0.0, 'ACC-114': 0.0, 'ACC-115': 0.0, 'ACC-116': 0.0, 'ACC-117': 0.0, 'ACC-118': 0.0, 'ACC-119': 0.0, 'ACC-120': 0.0, 'ACC-121': 0.0, 'ACC-122': 0.0, 'ACC-123': 0.0, 'ACC-124': 0.0, 'ACC-125': 0.0, 'ACC-126': 0.0, 'ACC-127': 0.0, 'ACC-128': 0.0, 'ACC-129': 0.0, 'ACC-130': 0.0, 'ACC-131': 0.0, 'ACC-132': 0.0, 'ACC-133': 0.0, 'ACC-134': 0.0, 'ACC-135': 0.0, 'ACC-136': 0.0, 'ACC-137': 0.0, 'ACC-138': 0.0, 'ACC-139': 0.0, 'ACC-140': 0.0, 'ACC-141': 0.0, 'ACC-142': 0.0, 'ACC-143': 0.0, 'ACC-144': 0.0, 'ACC-145': 0.0, 'ACC-146': 0.0, 'ACC-147': 0.0, 'ACC-148': 0.0, 'ACC-149': 0.0, 'ACC-150': 0.0, 'ACC-151': 0.0, 'ACC-152': 0.0, 'ACC-153': 0.0, 'ACC-154': 0.0, 'ACC-155': 0.0, 'ACC-156': 0.0, 'ACC-157': 0.0, 'ACC-158': 0.0, 'ACC-159': 0.0, 'ACC-160': 0.0, 'ACC-161': 0.0, 'ACC-162': 0.0, 'ACC-163': 0.0, 'ACC-164': 0.0, 'ACC-165': 0.0, 'ACC-166': 0.0, 'ACC-167': 0.0, 'ACC-168': 0.0, 'ACC-169': 0.0, 'ACC-170': 0.0, 'ACC-171': 0.0, 'ACC-172': 0.0, 'ACC-173': 0.0, 'ACC-174': 0.0, 'ACC-175': 0.0, 'ACC-176': 0.0, 'ACC-177': 0.0, 'ACC-178': 0.0, 'ACC-179': 0.0, 'ACC-180': 0.0, 'ACC-181': 0.0, 'ACC-182': 0.0, 'ACC-183': 0.0, 'ACC-184': 0.0, 'ACC-185': 0.0, 'ACC-186': 0.0, 'ACC-187': 0.0, 'ACC-188': 0.0, 'ACC-189': 0.0, 'ACC-190': 0.0, 'ACC-191': 0.0, 'ACC-192': 0.0})])
[01/29 15:21:24] d2.evaluation.testing INFO: copypaste: Task: sem_seg
[01/29 15:21:24] d2.evaluation.testing INFO: copypaste: epe,error_1pix,error_3pix,mIoU,fwIoU,mACC,pACC
[01/29 15:21:24] d2.evaluation.testing INFO: copypaste: 24.0532,0.9520,0.8867,0.0079,0.0235,0.5181,1.5329
[01/29 15:21:24] d2.utils.events INFO:  eta: 1 day, 18:40:57  iter: 999  total_loss: 254.9  loss_mask: 25.48  loss_mask_0: 25.51  loss_mask_1: 25.48  loss_mask_2: 25.49  loss_mask_3: 25.49  loss_mask_4: 25.49  loss_mask_5: 25.48  loss_mask_6: 25.48  loss_mask_7: 25.48  loss_mask_8: 25.48  time: 2.6100  data_time: 0.0622  lr: 0.000985  max_mem: 27629M
[01/29 15:22:17] d2.utils.events INFO:  eta: 1 day, 18:39:40  iter: 1019  total_loss: 271.8  loss_mask: 27.16  loss_mask_0: 27.35  loss_mask_1: 27.16  loss_mask_2: 27.16  loss_mask_3: 27.16  loss_mask_4: 27.17  loss_mask_5: 27.16  loss_mask_6: 27.16  loss_mask_7: 27.15  loss_mask_8: 27.16  time: 2.6104  data_time: 0.0709  lr: 0.0009847  max_mem: 27629M
[01/29 15:23:09] d2.utils.events INFO:  eta: 1 day, 18:39:01  iter: 1039  total_loss: 269.7  loss_mask: 27.03  loss_mask_0: 26.6  loss_mask_1: 27  loss_mask_2: 27.02  loss_mask_3: 27.01  loss_mask_4: 27  loss_mask_5: 26.96  loss_mask_6: 26.98  loss_mask_7: 26.93  loss_mask_8: 27.03  time: 2.6105  data_time: 0.0677  lr: 0.0009844  max_mem: 27629M
[01/29 15:24:01] d2.utils.events INFO:  eta: 1 day, 18:37:55  iter: 1059  total_loss: 266.2  loss_mask: 26.62  loss_mask_0: 26.63  loss_mask_1: 26.62  loss_mask_2: 26.62  loss_mask_3: 26.62  loss_mask_4: 26.63  loss_mask_5: 26.62  loss_mask_6: 26.62  loss_mask_7: 26.62  loss_mask_8: 26.62  time: 2.6105  data_time: 0.0592  lr: 0.0009841  max_mem: 27629M
[01/29 15:24:53] d2.utils.events INFO:  eta: 1 day, 18:37:17  iter: 1079  total_loss: 268.3  loss_mask: 26.82  loss_mask_0: 26.84  loss_mask_1: 26.81  loss_mask_2: 26.81  loss_mask_3: 26.81  loss_mask_4: 26.84  loss_mask_5: 26.83  loss_mask_6: 26.84  loss_mask_7: 26.85  loss_mask_8: 26.81  time: 2.6103  data_time: 0.0642  lr: 0.0009838  max_mem: 27629M
[01/29 15:25:45] d2.utils.events INFO:  eta: 1 day, 18:36:11  iter: 1099  total_loss: 259.6  loss_mask: 25.97  loss_mask_0: 25.89  loss_mask_1: 25.97  loss_mask_2: 25.97  loss_mask_3: 25.97  loss_mask_4: 25.97  loss_mask_5: 25.97  loss_mask_6: 25.98  loss_mask_7: 25.97  loss_mask_8: 25.97  time: 2.6102  data_time: 0.0574  lr: 0.0009835  max_mem: 27629M
[01/29 15:26:38] d2.utils.events INFO:  eta: 1 day, 18:35:45  iter: 1119  total_loss: 269.3  loss_mask: 26.93  loss_mask_0: 26.92  loss_mask_1: 26.92  loss_mask_2: 26.92  loss_mask_3: 26.92  loss_mask_4: 26.93  loss_mask_5: 26.93  loss_mask_6: 26.93  loss_mask_7: 26.93  loss_mask_8: 26.93  time: 2.6103  data_time: 0.0686  lr: 0.0009832  max_mem: 27629M
[01/29 15:27:30] d2.utils.events INFO:  eta: 1 day, 18:34:44  iter: 1139  total_loss: 257.5  loss_mask: 25.75  loss_mask_0: 25.8  loss_mask_1: 25.75  loss_mask_2: 25.75  loss_mask_3: 25.75  loss_mask_4: 25.74  loss_mask_5: 25.75  loss_mask_6: 25.75  loss_mask_7: 25.75  loss_mask_8: 25.75  time: 2.6102  data_time: 0.0665  lr: 0.0009829  max_mem: 27629M
[01/29 15:28:22] d2.utils.events INFO:  eta: 1 day, 18:33:11  iter: 1159  total_loss: 257.9  loss_mask: 25.79  loss_mask_0: 25.8  loss_mask_1: 25.79  loss_mask_2: 25.79  loss_mask_3: 25.79  loss_mask_4: 25.79  loss_mask_5: 25.79  loss_mask_6: 25.79  loss_mask_7: 25.79  loss_mask_8: 25.79  time: 2.6099  data_time: 0.0582  lr: 0.0009826  max_mem: 27629M
[01/29 15:29:14] d2.utils.events INFO:  eta: 1 day, 18:32:15  iter: 1179  total_loss: 270.7  loss_mask: 27.07  loss_mask_0: 27.07  loss_mask_1: 27.07  loss_mask_2: 27.07  loss_mask_3: 27.07  loss_mask_4: 27.07  loss_mask_5: 27.08  loss_mask_6: 27.07  loss_mask_7: 27.08  loss_mask_8: 27.07  time: 2.6096  data_time: 0.0578  lr: 0.0009823  max_mem: 27629M
[01/29 15:30:06] d2.utils.events INFO:  eta: 1 day, 18:31:27  iter: 1199  total_loss: 270.6  loss_mask: 27.04  loss_mask_0: 27.03  loss_mask_1: 27.05  loss_mask_2: 27.04  loss_mask_3: 27.04  loss_mask_4: 27.05  loss_mask_5: 27.04  loss_mask_6: 27.04  loss_mask_7: 27.05  loss_mask_8: 27.05  time: 2.6097  data_time: 0.0710  lr: 0.000982  max_mem: 27629M
[01/29 15:30:58] d2.utils.events INFO:  eta: 1 day, 18:30:33  iter: 1219  total_loss: 281.7  loss_mask: 28.18  loss_mask_0: 28.16  loss_mask_1: 28.17  loss_mask_2: 28.17  loss_mask_3: 28.16  loss_mask_4: 28.17  loss_mask_5: 28.17  loss_mask_6: 28.17  loss_mask_7: 28.18  loss_mask_8: 28.18  time: 2.6097  data_time: 0.0741  lr: 0.0009817  max_mem: 27629M
[01/29 15:31:50] d2.utils.events INFO:  eta: 1 day, 18:29:55  iter: 1239  total_loss: 262  loss_mask: 26.2  loss_mask_0: 26.15  loss_mask_1: 26.2  loss_mask_2: 26.2  loss_mask_3: 26.21  loss_mask_4: 26.2  loss_mask_5: 26.2  loss_mask_6: 26.2  loss_mask_7: 26.2  loss_mask_8: 26.2  time: 2.6097  data_time: 0.0697  lr: 0.0009814  max_mem: 27629M
[01/29 15:32:42] d2.utils.events INFO:  eta: 1 day, 18:28:49  iter: 1259  total_loss: 274.3  loss_mask: 27.43  loss_mask_0: 27.43  loss_mask_1: 27.43  loss_mask_2: 27.43  loss_mask_3: 27.43  loss_mask_4: 27.43  loss_mask_5: 27.43  loss_mask_6: 27.43  loss_mask_7: 27.43  loss_mask_8: 27.43  time: 2.6095  data_time: 0.0653  lr: 0.0009811  max_mem: 27629M
[01/29 15:33:34] d2.utils.events INFO:  eta: 1 day, 18:27:48  iter: 1279  total_loss: 271.2  loss_mask: 27.12  loss_mask_0: 27.06  loss_mask_1: 27.12  loss_mask_2: 27.12  loss_mask_3: 27.12  loss_mask_4: 27.12  loss_mask_5: 27.13  loss_mask_6: 27.12  loss_mask_7: 27.13  loss_mask_8: 27.12  time: 2.6094  data_time: 0.0538  lr: 0.00098079  max_mem: 27629M
[01/29 15:34:26] d2.utils.events INFO:  eta: 1 day, 18:26:42  iter: 1299  total_loss: 271.1  loss_mask: 27.11  loss_mask_0: 27.1  loss_mask_1: 27.1  loss_mask_2: 27.1  loss_mask_3: 27.1  loss_mask_4: 27.12  loss_mask_5: 27.11  loss_mask_6: 27.12  loss_mask_7: 27.1  loss_mask_8: 27.11  time: 2.6092  data_time: 0.0569  lr: 0.00098049  max_mem: 27629M
[01/29 15:35:19] d2.utils.events INFO:  eta: 1 day, 18:26:00  iter: 1319  total_loss: 266  loss_mask: 26.58  loss_mask_0: 26.83  loss_mask_1: 26.57  loss_mask_2: 26.57  loss_mask_3: 26.58  loss_mask_4: 26.57  loss_mask_5: 26.58  loss_mask_6: 26.59  loss_mask_7: 26.58  loss_mask_8: 26.57  time: 2.6092  data_time: 0.0640  lr: 0.00098019  max_mem: 27629M
[01/29 15:36:10] d2.utils.events INFO:  eta: 1 day, 18:24:58  iter: 1339  total_loss: 270.6  loss_mask: 27.08  loss_mask_0: 27.19  loss_mask_1: 27.08  loss_mask_2: 27.08  loss_mask_3: 27.06  loss_mask_4: 27.07  loss_mask_5: 27.05  loss_mask_6: 27.06  loss_mask_7: 27.05  loss_mask_8: 27.08  time: 2.6089  data_time: 0.0632  lr: 0.00097989  max_mem: 27629M
[01/29 15:37:03] d2.utils.events INFO:  eta: 1 day, 18:24:29  iter: 1359  total_loss: 269.4  loss_mask: 26.95  loss_mask_0: 26.9  loss_mask_1: 26.94  loss_mask_2: 26.95  loss_mask_3: 26.94  loss_mask_4: 26.95  loss_mask_5: 26.94  loss_mask_6: 26.95  loss_mask_7: 26.93  loss_mask_8: 26.95  time: 2.6089  data_time: 0.0622  lr: 0.00097959  max_mem: 27629M
[01/29 15:37:55] d2.utils.events INFO:  eta: 1 day, 18:23:11  iter: 1379  total_loss: 257.9  loss_mask: 25.77  loss_mask_0: 25.94  loss_mask_1: 25.77  loss_mask_2: 25.77  loss_mask_3: 25.77  loss_mask_4: 25.77  loss_mask_5: 25.77  loss_mask_6: 25.77  loss_mask_7: 25.77  loss_mask_8: 25.77  time: 2.6089  data_time: 0.0734  lr: 0.00097929  max_mem: 27629M
[01/29 15:38:47] d2.utils.events INFO:  eta: 1 day, 18:21:53  iter: 1399  total_loss: 260.3  loss_mask: 26.02  loss_mask_0: 26.08  loss_mask_1: 26.02  loss_mask_2: 26.02  loss_mask_3: 26.03  loss_mask_4: 26.03  loss_mask_5: 26.03  loss_mask_6: 26.03  loss_mask_7: 26.03  loss_mask_8: 26.03  time: 2.6086  data_time: 0.0629  lr: 0.00097899  max_mem: 27629M
[01/29 15:39:39] d2.utils.events INFO:  eta: 1 day, 18:20:23  iter: 1419  total_loss: 273.4  loss_mask: 27.35  loss_mask_0: 27.22  loss_mask_1: 27.35  loss_mask_2: 27.35  loss_mask_3: 27.35  loss_mask_4: 27.34  loss_mask_5: 27.34  loss_mask_6: 27.35  loss_mask_7: 27.35  loss_mask_8: 27.35  time: 2.6085  data_time: 0.0610  lr: 0.00097869  max_mem: 27629M
[01/29 15:40:31] d2.utils.events INFO:  eta: 1 day, 18:19:19  iter: 1439  total_loss: 251  loss_mask: 25.1  loss_mask_0: 25.18  loss_mask_1: 25.1  loss_mask_2: 25.1  loss_mask_3: 25.1  loss_mask_4: 25.1  loss_mask_5: 25.1  loss_mask_6: 25.1  loss_mask_7: 25.1  loss_mask_8: 25.1  time: 2.6084  data_time: 0.0687  lr: 0.00097839  max_mem: 27629M
[01/29 15:41:23] d2.utils.events INFO:  eta: 1 day, 18:18:09  iter: 1459  total_loss: 249.8  loss_mask: 24.96  loss_mask_0: 25.24  loss_mask_1: 24.95  loss_mask_2: 24.95  loss_mask_3: 24.94  loss_mask_4: 24.94  loss_mask_5: 24.93  loss_mask_6: 24.95  loss_mask_7: 24.95  loss_mask_8: 24.95  time: 2.6081  data_time: 0.0574  lr: 0.00097809  max_mem: 27629M
[01/29 15:42:14] d2.utils.events INFO:  eta: 1 day, 18:17:13  iter: 1479  total_loss: 266.2  loss_mask: 26.62  loss_mask_0: 26.59  loss_mask_1: 26.62  loss_mask_2: 26.62  loss_mask_3: 26.63  loss_mask_4: 26.62  loss_mask_5: 26.63  loss_mask_6: 26.61  loss_mask_7: 26.63  loss_mask_8: 26.62  time: 2.6078  data_time: 0.0644  lr: 0.00097779  max_mem: 27629M
[01/29 15:43:06] d2.utils.events INFO:  eta: 1 day, 18:15:49  iter: 1499  total_loss: 274  loss_mask: 27.41  loss_mask_0: 27.4  loss_mask_1: 27.41  loss_mask_2: 27.41  loss_mask_3: 27.41  loss_mask_4: 27.4  loss_mask_5: 27.4  loss_mask_6: 27.4  loss_mask_7: 27.4  loss_mask_8: 27.4  time: 2.6076  data_time: 0.0603  lr: 0.00097749  max_mem: 27629M
[01/29 15:43:58] d2.utils.events INFO:  eta: 1 day, 18:14:38  iter: 1519  total_loss: 269.1  loss_mask: 26.91  loss_mask_0: 26.94  loss_mask_1: 26.9  loss_mask_2: 26.9  loss_mask_3: 26.9  loss_mask_4: 26.9  loss_mask_5: 26.9  loss_mask_6: 26.9  loss_mask_7: 26.91  loss_mask_8: 26.9  time: 2.6075  data_time: 0.0705  lr: 0.00097719  max_mem: 27629M
[01/29 15:44:50] d2.utils.events INFO:  eta: 1 day, 18:13:46  iter: 1539  total_loss: 281.3  loss_mask: 28.12  loss_mask_0: 28.24  loss_mask_1: 28.12  loss_mask_2: 28.12  loss_mask_3: 28.12  loss_mask_4: 28.12  loss_mask_5: 28.12  loss_mask_6: 28.12  loss_mask_7: 28.12  loss_mask_8: 28.12  time: 2.6075  data_time: 0.0709  lr: 0.00097689  max_mem: 27629M
[01/29 15:45:43] d2.utils.events INFO:  eta: 1 day, 18:12:54  iter: 1559  total_loss: 252.4  loss_mask: 25.24  loss_mask_0: 25.22  loss_mask_1: 25.24  loss_mask_2: 25.24  loss_mask_3: 25.24  loss_mask_4: 25.24  loss_mask_5: 25.23  loss_mask_6: 25.23  loss_mask_7: 25.24  loss_mask_8: 25.24  time: 2.6075  data_time: 0.0646  lr: 0.00097658  max_mem: 27629M
[01/29 15:46:35] d2.utils.events INFO:  eta: 1 day, 18:11:43  iter: 1579  total_loss: 258.7  loss_mask: 25.87  loss_mask_0: 25.87  loss_mask_1: 25.87  loss_mask_2: 25.87  loss_mask_3: 25.88  loss_mask_4: 25.87  loss_mask_5: 25.88  loss_mask_6: 25.88  loss_mask_7: 25.88  loss_mask_8: 25.87  time: 2.6074  data_time: 0.0604  lr: 0.00097628  max_mem: 27629M
[01/29 15:47:26] d2.utils.events INFO:  eta: 1 day, 18:10:25  iter: 1599  total_loss: 264.1  loss_mask: 26.41  loss_mask_0: 26.39  loss_mask_1: 26.41  loss_mask_2: 26.41  loss_mask_3: 26.41  loss_mask_4: 26.41  loss_mask_5: 26.42  loss_mask_6: 26.41  loss_mask_7: 26.42  loss_mask_8: 26.41  time: 2.6072  data_time: 0.0620  lr: 0.00097598  max_mem: 27629M
[01/29 15:48:19] d2.utils.events INFO:  eta: 1 day, 18:09:13  iter: 1619  total_loss: 274.8  loss_mask: 27.48  loss_mask_0: 27.49  loss_mask_1: 27.48  loss_mask_2: 27.48  loss_mask_3: 27.48  loss_mask_4: 27.48  loss_mask_5: 27.47  loss_mask_6: 27.48  loss_mask_7: 27.48  loss_mask_8: 27.48  time: 2.6072  data_time: 0.0610  lr: 0.00097568  max_mem: 27629M
[01/29 15:49:11] d2.utils.events INFO:  eta: 1 day, 18:08:11  iter: 1639  total_loss: 262.5  loss_mask: 25.94  loss_mask_0: 26.51  loss_mask_1: 25.94  loss_mask_2: 25.94  loss_mask_3: 25.94  loss_mask_4: 25.94  loss_mask_5: 25.94  loss_mask_6: 25.94  loss_mask_7: 25.94  loss_mask_8: 25.94  time: 2.6070  data_time: 0.0645  lr: 0.00097538  max_mem: 27629M
[01/29 15:50:03] d2.utils.events INFO:  eta: 1 day, 18:07:02  iter: 1659  total_loss: 311.6  loss_mask: 29.96  loss_mask_0: 30.98  loss_mask_1: 29.97  loss_mask_2: 29.97  loss_mask_3: 29.97  loss_mask_4: 29.96  loss_mask_5: 29.97  loss_mask_6: 29.96  loss_mask_7: 29.96  loss_mask_8: 29.97  time: 2.6070  data_time: 0.0732  lr: 0.00097508  max_mem: 27629M
[01/29 15:50:55] d2.utils.events INFO:  eta: 1 day, 18:06:07  iter: 1679  total_loss: 266.9  loss_mask: 26.68  loss_mask_0: 26.71  loss_mask_1: 26.67  loss_mask_2: 26.7  loss_mask_3: 26.68  loss_mask_4: 26.72  loss_mask_5: 26.71  loss_mask_6: 26.71  loss_mask_7: 26.65  loss_mask_8: 26.72  time: 2.6069  data_time: 0.0626  lr: 0.00097478  max_mem: 27629M
[01/29 15:51:47] d2.utils.events INFO:  eta: 1 day, 18:05:15  iter: 1699  total_loss: 286.3  loss_mask: 27.74  loss_mask_0: 29.23  loss_mask_1: 27.78  loss_mask_2: 27.77  loss_mask_3: 27.78  loss_mask_4: 27.75  loss_mask_5: 27.75  loss_mask_6: 27.76  loss_mask_7: 27.75  loss_mask_8: 27.75  time: 2.6068  data_time: 0.0651  lr: 0.00097448  max_mem: 27629M
[01/29 15:52:39] d2.utils.events INFO:  eta: 1 day, 18:04:02  iter: 1719  total_loss: 275.6  loss_mask: 25.92  loss_mask_0: 29.88  loss_mask_1: 25.92  loss_mask_2: 25.92  loss_mask_3: 25.92  loss_mask_4: 25.92  loss_mask_5: 25.92  loss_mask_6: 25.92  loss_mask_7: 25.92  loss_mask_8: 25.92  time: 2.6067  data_time: 0.0592  lr: 0.00097418  max_mem: 27629M
[01/29 15:53:31] d2.utils.events INFO:  eta: 1 day, 18:02:59  iter: 1739  total_loss: 263.7  loss_mask: 26.38  loss_mask_0: 26.33  loss_mask_1: 26.38  loss_mask_2: 26.38  loss_mask_3: 26.38  loss_mask_4: 26.38  loss_mask_5: 26.38  loss_mask_6: 26.38  loss_mask_7: 26.38  loss_mask_8: 26.38  time: 2.6067  data_time: 0.0589  lr: 0.00097388  max_mem: 27629M
[01/29 15:54:23] d2.utils.events INFO:  eta: 1 day, 18:01:56  iter: 1759  total_loss: 269.1  loss_mask: 26.87  loss_mask_0: 28.05  loss_mask_1: 26.87  loss_mask_2: 26.87  loss_mask_3: 26.87  loss_mask_4: 26.87  loss_mask_5: 26.87  loss_mask_6: 26.87  loss_mask_7: 26.87  loss_mask_8: 26.87  time: 2.6067  data_time: 0.0660  lr: 0.00097358  max_mem: 27629M
[01/29 15:55:15] d2.utils.events INFO:  eta: 1 day, 18:00:59  iter: 1779  total_loss: 277.2  loss_mask: 27.72  loss_mask_0: 27.7  loss_mask_1: 27.72  loss_mask_2: 27.72  loss_mask_3: 27.72  loss_mask_4: 27.72  loss_mask_5: 27.72  loss_mask_6: 27.72  loss_mask_7: 27.73  loss_mask_8: 27.72  time: 2.6067  data_time: 0.0671  lr: 0.00097328  max_mem: 27629M
[01/29 15:56:08] d2.utils.events INFO:  eta: 1 day, 18:00:07  iter: 1799  total_loss: 266.7  loss_mask: 26.66  loss_mask_0: 26.64  loss_mask_1: 26.67  loss_mask_2: 26.67  loss_mask_3: 26.67  loss_mask_4: 26.67  loss_mask_5: 26.66  loss_mask_6: 26.67  loss_mask_7: 26.67  loss_mask_8: 26.67  time: 2.6068  data_time: 0.0645  lr: 0.00097297  max_mem: 27629M
[01/29 15:57:00] d2.utils.events INFO:  eta: 1 day, 17:58:53  iter: 1819  total_loss: 260.4  loss_mask: 26.08  loss_mask_0: 26.11  loss_mask_1: 26  loss_mask_2: 25.99  loss_mask_3: 26.01  loss_mask_4: 26.04  loss_mask_5: 26.06  loss_mask_6: 26.03  loss_mask_7: 26.07  loss_mask_8: 26.01  time: 2.6069  data_time: 0.0616  lr: 0.00097267  max_mem: 27629M
[01/29 15:57:52] d2.utils.events INFO:  eta: 1 day, 17:58:08  iter: 1839  total_loss: 258.9  loss_mask: 25.9  loss_mask_0: 25.95  loss_mask_1: 25.87  loss_mask_2: 25.87  loss_mask_3: 25.88  loss_mask_4: 25.88  loss_mask_5: 25.89  loss_mask_6: 25.88  loss_mask_7: 25.89  loss_mask_8: 25.87  time: 2.6068  data_time: 0.0653  lr: 0.00097237  max_mem: 27629M
[01/29 15:58:44] d2.utils.events INFO:  eta: 1 day, 17:56:53  iter: 1859  total_loss: 256.4  loss_mask: 25.63  loss_mask_0: 25.7  loss_mask_1: 25.64  loss_mask_2: 25.64  loss_mask_3: 25.64  loss_mask_4: 25.63  loss_mask_5: 25.63  loss_mask_6: 25.64  loss_mask_7: 25.63  loss_mask_8: 25.64  time: 2.6068  data_time: 0.0594  lr: 0.00097207  max_mem: 27629M
[01/29 15:59:36] d2.utils.events INFO:  eta: 1 day, 17:56:05  iter: 1879  total_loss: 261.4  loss_mask: 26.15  loss_mask_0: 26.13  loss_mask_1: 26.14  loss_mask_2: 26.14  loss_mask_3: 26.14  loss_mask_4: 26.15  loss_mask_5: 26.15  loss_mask_6: 26.14  loss_mask_7: 26.15  loss_mask_8: 26.15  time: 2.6069  data_time: 0.0600  lr: 0.00097177  max_mem: 27629M
[01/29 16:00:28] d2.utils.events INFO:  eta: 1 day, 17:54:52  iter: 1899  total_loss: 262.9  loss_mask: 26.27  loss_mask_0: 26.42  loss_mask_1: 26.28  loss_mask_2: 26.29  loss_mask_3: 26.29  loss_mask_4: 26.27  loss_mask_5: 26.27  loss_mask_6: 26.27  loss_mask_7: 26.27  loss_mask_8: 26.27  time: 2.6067  data_time: 0.0666  lr: 0.00097147  max_mem: 27645M
[01/29 16:01:08] d2.engine.hooks INFO: Overall training speed: 1913 iterations in 1:23:07 (2.6072 s / it)
[01/29 16:01:08] d2.engine.hooks INFO: Total training time: 1:33:21 (0:10:13 on hooks)
[01/29 16:01:08] d2.utils.events INFO:  eta: 1 day, 17:53:54  iter: 1915  total_loss: 260  loss_mask: 26  loss_mask_0: 25.99  loss_mask_1: 26  loss_mask_2: 26  loss_mask_3: 26  loss_mask_4: 26  loss_mask_5: 26  loss_mask_6: 26  loss_mask_7: 26  loss_mask_8: 26  time: 2.6068  data_time: 0.0690  lr: 0.00097124  max_mem: 27645M
